{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "052aaffa-d670-4d3f-bed9-c07e12c063cf",
   "metadata": {},
   "source": [
    "## Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "732c2405-3fcb-489a-b931-15d9a7eb7845",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "from tqdm.notebook import tqdm\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "from qucumber.nn_states import DensityMatrix\n",
    "from qucumber.nn_states import ComplexWaveFunction\n",
    "from qucumber.callbacks import MetricEvaluator\n",
    "import qucumber.utils.unitaries as unitaries\n",
    "import qucumber.utils.training_statistics as ts\n",
    "import qucumber.utils.cplx as cplx\n",
    "import qucumber.utils.data as data\n",
    "from qucumber.observables import ObservableBase, to_pm1\n",
    "from qucumber.observables.pauli import flip_spin\n",
    "import qucumber\n",
    "\n",
    "from qulacs.gate import Pauli\n",
    "\n",
    "with open('./params_setting.yaml', 'r') as yml:\n",
    "    params = yaml.safe_load(yml)\n",
    "    \n",
    "# quantum circuit parameter\n",
    "n_qubit = params[\"circuit_info\"][\"n_qubit\"]\n",
    "each_n_shot = params[\"circuit_info\"][\"each_n_shot\"]\n",
    "state_name = params[\"circuit_info\"][\"state_name\"]\n",
    "error_model = params[\"circuit_info\"][\"error_model\"]\n",
    "error_rate = params[\"circuit_info\"][\"error_rate\"]\n",
    "# RBM architecture parameter\n",
    "n_visible_unit = params[\"architecture_info\"][\"n_visible_unit\"]\n",
    "n_hidden_unit = params[\"architecture_info\"][\"n_hidden_unit\"] \n",
    "n_aux_unit = params[\"architecture_info\"][\"n_aux_unit\"]\n",
    "# train parameter\n",
    "lr = params[\"train_info\"][\"lr\"]\n",
    "pbs = params[\"train_info\"][\"positive_batch_size\"]\n",
    "nbs = params[\"train_info\"][\"negative_batch_size\"]\n",
    "n_gibbs_step = params[\"train_info\"][\"n_gibbs_step\"]\n",
    "period = 1\n",
    "epoch = params[\"train_info\"][\"n_epoch\"]\n",
    "lr_drop_epoch = params[\"train_info\"][\"lr_drop_epoch\"]\n",
    "lr_drop_factor = params[\"train_info\"][\"lr_drop_factor\"]\n",
    "seed = params[\"train_info\"][\"seed\"]\n",
    "# sampling parameter\n",
    "n_sampling = params[\"sampling_info\"][\"n_sample\"]\n",
    "n_copy = params[\"sampling_info\"][\"n_copy\"]\n",
    "# data path info\n",
    "environment = \"local\"\n",
    "if environment == \"local\":\n",
    "    train_data_path = f\"./data/{error_model}/error_prob_{100*error_rate}%/num_of_data_{each_n_shot}/\"\n",
    "    ideal_state_path = f\"./target_state/\"\n",
    "if environment == \"colab\":\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive/\")\n",
    "    rive_path = \"/content/drive/MyDrive/NQS4QEM/Bell\"\n",
    "    train_data_path = drive_path + f\"/data/{error_model}/error_prob_{100*error_rate}%/num_of_data_{each_n_shot}/\"\n",
    "    ideal_state_path = drive_path + f\"/target_state/\"\n",
    "\n",
    "# settings\n",
    "## warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "## seaborn layout\n",
    "sns.set()\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "## seed\n",
    "def seed_settings(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    qucumber.set_random_seed(seed, cpu=True, gpu=False)\n",
    "\n",
    "seed_settings(seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f117e73d-0af0-430e-8a7c-3b2d47ef109a",
   "metadata": {},
   "source": [
    "## caluculate ideal state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d800bd19-5c39-4fcf-9f48-49451f4574a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ideal state data is exsisted !\n"
     ]
    }
   ],
   "source": [
    "# calculate ideal state\n",
    "is_ideal_state_file = os.path.exists(ideal_state_path)\n",
    "if is_ideal_state_file:\n",
    "    print(\"ideal state data is exsisted !\")\n",
    "else:\n",
    "    print(\"caluculate ideal state data ...\")\n",
    "    subprocess.run(\"python caluculate_ideal_state.py\", shell=True)\n",
    "    print(\"ideal state data is ready !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3a9677-cd6b-41d8-92a1-47a74a019756",
   "metadata": {},
   "source": [
    "## generate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8227038-435d-419b-a558-f30b8643125e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data is exsisted !\n"
     ]
    }
   ],
   "source": [
    "# generate train data\n",
    "is_train_data_file = os.path.exists(train_data_path)\n",
    "if is_train_data_file:\n",
    "    print(\"train data is exsisted !\")\n",
    "else:\n",
    "    print(\"generate directries & train data ...\")\n",
    "    os.makedirs(train_data_path, exist_ok = True)\n",
    "    subprocess.run(\"python generate_dataset.py\", shell=True)\n",
    "    print(\"train data is ready !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b90a855-f64f-4d31-9dff-25973fd5bbfb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## estimate observable expectation value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f385a22-df7a-49b0-880d-39dadb7f6922",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneralPauliDistill(ObservableBase):\n",
    "    def __init__(self, pauli_dict: dict, m: int) -> None:\n",
    "        self.name = \"distilled_pauli\"\n",
    "        self.symbol = \"distilled_general_pauli\"\n",
    "        self.pauli_dict = pauli_dict\n",
    "        self.num_copy = m\n",
    "        \n",
    "    def apply(self, nn_state, samples):\n",
    "        \"\"\"\n",
    "        This function calcualte <x1 x2 ... xm | rho^{\\otimes m} O | xm x1 x2 ... xm-1> / <x1 x2 ... xm | rho^{\\otimes m} | x1 x2 ... xm>\n",
    "        where O acts only on the first register.\n",
    "        \"\"\"\n",
    "        \n",
    "        # [num_sample, num_visible_node]\n",
    "        # samples = [s1, s2, s3 ... sN]\n",
    "        #  where num_sample = N, and si is num_visible_node-bits\n",
    "        samples = samples.to(device=nn_state.device)\n",
    "        \n",
    "        num_sample, num_visible_node = samples.shape\n",
    "        \n",
    "        # [num_sample, num_visible_node * num_copy]\n",
    "        # samples_array = [[s1 sN sN-1], [s2 s1 sN], [s3 s2 s1],.. [sN sN-1 sN-2]]\n",
    "        #  each row is num_copy*num_visible_node bits the above example is for num_copy=3\n",
    "        samples_array = []\n",
    "        for copy_index in range(self.num_copy):\n",
    "            rolled_samples = torch.roll(samples, shifts=copy_index, dims=0)\n",
    "            samples_array.append(rolled_samples)\n",
    "        samples_array = torch.hstack(samples_array)\n",
    "        assert(samples_array.shape[0] == num_sample)\n",
    "        assert(samples_array.shape[1] == num_visible_node * self.num_copy)\n",
    "        \n",
    "        # roll second dim of [num_sample, num_visible_node * num_copy] by num_visible_node\n",
    "        # swapped_samples_array = [[sN-1 s1 sN], [sN s2 s1], [s1 s3 s2],.. [sN-2 sN sN-1]]\n",
    "        swapped_samples_array = torch.roll(samples_array, shifts = num_visible_node, dims=1)\n",
    "\n",
    "        # pick copy of first block\n",
    "        #  first_block_sample = [sN-1, sN, s1, s2, ... sN-2]\n",
    "        first_block_sample = swapped_samples_array[:, :num_visible_node].clone()\n",
    "\n",
    "        # calculate coefficient for first block [num_samples, 0:num_visible_node]\n",
    "        total_prod = cplx.make_complex(torch.ones_like(samples[:,0]), torch.zeros_like(samples[:,0]))\n",
    "        for index, pauli in self.pauli_dict.items():\n",
    "            assert(index < num_visible_node)\n",
    "            coeff = to_pm1(first_block_sample[:, index])\n",
    "            if pauli == \"Z\":\n",
    "                coeff = cplx.make_complex(coeff, torch.zeros_like(coeff))\n",
    "                total_prod = cplx.elementwise_mult(coeff, total_prod)\n",
    "            elif pauli == \"Y\":\n",
    "                coeff = cplx.make_complex(torch.zeros_like(coeff), coeff)\n",
    "                total_prod = cplx.elementwise_mult(coeff, total_prod)\n",
    "        \n",
    "        # flip samples for for first block [num_samples, 0:num_visible_node]\n",
    "        # first_block_sample -> [OsN-1, OsN, Os1, Os2, ... OsN-2]\n",
    "        #  where Osi is bit array after Pauli bit-flips \n",
    "        for index, pauli in self.pauli_dict.items():\n",
    "            assert(index < num_visible_node)\n",
    "            if pauli in [\"X\", \"Y\"]:\n",
    "                first_block_sample = flip_spin(index, first_block_sample)\n",
    "\n",
    "\n",
    "        # store flipped first block\n",
    "        swapped_samples_array[:, :num_visible_node] = first_block_sample\n",
    "\n",
    "        # calculate product of coefficients\n",
    "        # samples_array = [[s1 sN sN-1], [s2 s1 sN], [s3 s2 s1],.. [sN sN-1 sN-2]]\n",
    "        # swapped_samples_array = [[OsN-1 s1 sN], [OsN s2 s1], [Os1 s3 s2],.. [OsN-2 sN sN-1]]\n",
    "        \"\"\"\n",
    "        total_prod = [\n",
    "            <s1 sN sN-1 | rho^{\\otimes 3} | OsN-1 s1 sN> / <s1 sN sN-1 | rho^{\\otimes 3} | s1 sN sN-1> , \n",
    "            <s2 s1 sN   | rho^{\\otimes 3} | OsN s2 s1>   / <s2 s1 sN   | rho^{\\otimes 3} | s2 s1 sN> , \n",
    "            <s3 s2 s1   | rho^{\\otimes 3} | Os1 s3 s2>   / <s3 s2 s1   | rho^{\\otimes 3} | s3 s2 s1> , \n",
    "\n",
    "        e.g. \n",
    "        <s3 s2 s1   | rho^{\\otimes 3} | Os1 s3 s2>   / <s3 s2 s1   | rho^{\\otimes 3} | s3 s2 s1>\n",
    "         = <s3 | rho | Os1> <s2 | rho | s3> < s1| rho | s2> / (<s3 | rho | s3> <s2 | rho | s2> < s1| rho | s1>)\n",
    "         =  (<s3 | rho | Os1> / <s3 | rho | s3>)\n",
    "          * (<s2 | rho | s3> / <s2 | rho | s2> )\n",
    "          * (< s1| rho | s2> / < s1| rho | s1>)\n",
    "         \n",
    "        importance_sampling_numerator(s3, Os1)  provides <s3 | rho | Os1>\n",
    "        importance_sampling_denominator(s3)     provides <s3 | rho | s3>\n",
    "        \"\"\"\n",
    "        for copy_index in range(self.num_copy):\n",
    "            st = copy_index * samples.shape[1]\n",
    "            en = (copy_index+1) * samples.shape[1]\n",
    "            # numerator is []\n",
    "            numerator = nn_state.importance_sampling_numerator(swapped_samples_array[:, st:en], samples_array[:, st:en])\n",
    "            denominator = nn_state.importance_sampling_denominator(samples_array[:, st:en])\n",
    "            values = cplx.elementwise_division(numerator, denominator)\n",
    "            total_prod = cplx.elementwise_mult(total_prod, values)\n",
    "\n",
    "        value = cplx.real(total_prod)\n",
    "        return value\n",
    "\n",
    "def calculate_distilled_expectation_value(pauli_dict: dict, num_samples: int, num_copies: int):\n",
    "    obs_num = GeneralPauliDistill(pauli_dict, num_copies)\n",
    "    obs_div = GeneralPauliDistill({}, num_copies)\n",
    "    num_stat = obs_num.statistics(nn_state_dm, num_samples=num_samples)\n",
    "    div_stat = obs_div.statistics(nn_state_dm, num_samples=num_samples)\n",
    "\n",
    "    from uncertainties import ufloat\n",
    "    num = ufloat(num_stat[\"mean\"], num_stat[\"std_error\"])\n",
    "    div = ufloat(div_stat[\"mean\"], div_stat[\"std_error\"])\n",
    "    val = num/div\n",
    "    result_dict = {\"mean\": val.n , \"std_error\": val.s, \"num_samples\": num_samples, \"num_copies\": num_copies}\n",
    "    return result_dict\n",
    "\n",
    "def get_density_matrix(nn_state):\n",
    "    space = nn_state.generate_hilbert_space()\n",
    "    Z = nn_state.normalization(space)\n",
    "    tensor = nn_state.rho(space, space)/Z\n",
    "    matrix = cplx.numpy(tensor)\n",
    "    return matrix\n",
    "\n",
    "def get_max_eigvec(matrix):\n",
    "    e_val, e_vec = np.linalg.eigh(matrix)\n",
    "    me_val = e_val[-1]\n",
    "    me_vec = e_vec[:,-1]\n",
    "    return me_vec\n",
    "\n",
    "def get_eigvec(nn_state, obs, space, **kwargs):\n",
    "    dm = get_density_matrix(nn_state)\n",
    "    ev = get_max_eigvec(dm)\n",
    "    ev = np.atleast_2d(ev)\n",
    "    val = ev@obs@ev.T.conj()\n",
    "    val = val[0,0].real\n",
    "    return val\n",
    "\n",
    "def observable_XX():\n",
    "    target_list = [0, 1]\n",
    "    pauli_index = [1, 1] # 1:X , 2:Y, 3:Z\n",
    "    gate = Pauli(target_list, pauli_index) # = X_1 X_2\n",
    "    return gate.get_matrix()\n",
    "\n",
    "def observable_XZ():\n",
    "    target_list = [0, 1]\n",
    "    pauli_index = [1, 3] # 1:X , 2:Y, 3:Z\n",
    "    gate = Pauli(target_list, pauli_index) # = X_1 Z_2\n",
    "    return gate.get_matrix()\n",
    "\n",
    "def observable_XX_ev(nn_state, **kwargs):\n",
    "    obs_stat = calculate_distilled_expectation_value({0: \"X\", 1: \"X\"}, n_sampling, n_copy)\n",
    "    return obs_stat[\"mean\"]\n",
    "\n",
    "def observable_XZ_ev(nn_state, **kwargs):\n",
    "    obs_stat = calculate_distilled_expectation_value({0: \"X\", 1: \"Z\"}, n_sampling, n_copy)\n",
    "    return obs_stat[\"mean\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064b4095-4a33-4938-9e25-f9d6cce67c73",
   "metadata": {},
   "source": [
    "## callback setting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6433a987-cec4-4698-8170-cf2955012fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_callback_dm(nn_state):\n",
    "    metric_dict = {\n",
    "        \"Fidelity\": ts.fidelity,\n",
    "        \"KL_Divergence\": ts.KL,\n",
    "        #\"Observable_XX_ev\": observable_XX_ev,\n",
    "        #\"Observable_XZ_ev\": observable_XZ_ev,\n",
    "    }\n",
    "\n",
    "    space = nn_state.generate_hilbert_space()\n",
    "    callbacks = [\n",
    "        MetricEvaluator(\n",
    "            period,\n",
    "            metric_dict,\n",
    "            target = ideal_rho,\n",
    "            bases = meas_pattern,\n",
    "            verbose = True,\n",
    "            space = space,\n",
    "        )\n",
    "    ]\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fd8047-5824-410e-a1cb-1851fcfc3f35",
   "metadata": {},
   "source": [
    "## experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "990cd783-aada-493b-b806-c64e330c1c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error_model : unitary, each_n_shot : 1000\n",
      "Epoch: 1\tFidelity = 0.396602\tKL_Divergence = 0.644483\n",
      "Epoch: 2\tFidelity = 0.396240\tKL_Divergence = 0.639487\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m nn_state_dm \u001b[38;5;241m=\u001b[39m DensityMatrix(num_visible \u001b[38;5;241m=\u001b[39m n_visible_unit, \n\u001b[1;32m     23\u001b[0m                             num_hidden \u001b[38;5;241m=\u001b[39m n_hidden_unit, \n\u001b[1;32m     24\u001b[0m                             num_aux \u001b[38;5;241m=\u001b[39m n_aux_unit, \n\u001b[1;32m     25\u001b[0m                             unitary_dict \u001b[38;5;241m=\u001b[39m unitaries\u001b[38;5;241m.\u001b[39mcreate_dict(),\n\u001b[1;32m     26\u001b[0m                             gpu \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     28\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m create_callback_dm(nn_state_dm)\n\u001b[0;32m---> 30\u001b[0m \u001b[43mnn_state_dm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmeas_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m                \u001b[49m\u001b[43minput_bases\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmeas_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m                \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m                \u001b[49m\u001b[43mpos_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpbs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m                \u001b[49m\u001b[43mneg_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnbs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m                \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m                \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_gibbs_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m                \u001b[49m\u001b[43mbases\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmeas_pattern\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m                \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdadelta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m                \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_scheduler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStepLR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m                \u001b[49m\u001b[43mscheduler_args\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstep_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_drop_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgamma\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_drop_factor\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m               \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# save model\u001b[39;00m\n\u001b[1;32m     46\u001b[0m nn_state_dm\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./exp_mixed_state_varying_n_shot/model_n_pattern_shot=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00meach_n_shot\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_model\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_5%.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/density_matrix.py:354\u001b[0m, in \u001b[0;36mDensityMatrix.fit\u001b[0;34m(self, data, epochs, pos_batch_size, neg_batch_size, k, lr, input_bases, progbar, starting_epoch, time, callbacks, optimizer, optimizer_args, scheduler, scheduler_args, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_bases must be provided to train a DensityMatrix!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 354\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneg_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneg_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_bases\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_bases\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstarting_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstarting_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtime\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscheduler_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/neural_state.py:614\u001b[0m, in \u001b[0;36mNeuralStateBase.fit\u001b[0;34m(self, data, epochs, pos_batch_size, neg_batch_size, k, lr, input_bases, progbar, starting_epoch, time, callbacks, optimizer, optimizer_args, scheduler, scheduler_args, **kwargs)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m b, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_iterator):\n\u001b[1;32m    612\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_batch_start(\u001b[38;5;28mself\u001b[39m, ep, b)\n\u001b[0;32m--> 614\u001b[0m     all_grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_batch_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    616\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()  \u001b[38;5;66;03m# clear any cached gradients\u001b[39;00m\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;66;03m# assign gradients to corresponding parameters\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/neural_state.py:439\u001b[0m, in \u001b[0;36mNeuralStateBase.compute_batch_gradients\u001b[0;34m(self, k, samples_batch, neg_batch, bases_batch)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;124;03m\"\"\"Compute the gradients of a batch of the training data (`samples_batch`).\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \n\u001b[1;32m    420\u001b[0m \u001b[38;5;124;03mIf measurements are taken in bases other than the reference basis,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;124;03m:rtype: list[torch.Tensor]\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;66;03m# Positive phase: learning signal driven by the data (and bases)\u001b[39;00m\n\u001b[0;32m--> 439\u001b[0m grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpositive_phase_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbases_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbases_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;66;03m# Negative phase: learning signal driven by the amplitude RBM of\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;66;03m# the NN state\u001b[39;00m\n\u001b[1;32m    443\u001b[0m vk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrbm_am\u001b[38;5;241m.\u001b[39mgibbs_steps(k, neg_batch)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/neural_state.py:382\u001b[0m, in \u001b[0;36mNeuralStateBase.positive_phase_gradients\u001b[0;34m(self, samples_batch, bases_batch)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpositive_phase_gradients\u001b[39m(\u001b[38;5;28mself\u001b[39m, samples_batch, bases_batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Computes the positive phase of the gradients of the parameters.\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \n\u001b[1;32m    374\u001b[0m \u001b[38;5;124;03m    :param samples_batch: The measurements\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;124;03m    :rtype: list[torch.Tensor]\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 382\u001b[0m     grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbases\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbases_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    383\u001b[0m     grad \u001b[38;5;241m=\u001b[39m [gr \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mfloat\u001b[39m(samples_batch\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m gr \u001b[38;5;129;01min\u001b[39;00m grad]\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m grad\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/neural_state.py:359\u001b[0m, in \u001b[0;36mNeuralStateBase.gradient\u001b[0;34m(self, samples, bases)\u001b[0m\n\u001b[1;32m    356\u001b[0m rot_sites \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(basis \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZ\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rot_sites\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 359\u001b[0m     sample_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrotated_gradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbasis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    361\u001b[0m     sample_grad \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    362\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrbm_am\u001b[38;5;241m.\u001b[39meffective_energy_gradient(samples[indices \u001b[38;5;241m==\u001b[39m i, :]),\n\u001b[1;32m    363\u001b[0m         \u001b[38;5;241m0.0\u001b[39m,\n\u001b[1;32m    364\u001b[0m     ]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/density_matrix.py:298\u001b[0m, in \u001b[0;36mDensityMatrix.rotated_gradient\u001b[0;34m(self, basis, sample)\u001b[0m\n\u001b[1;32m    293\u001b[0m UrhoU, UrhoU_v, v \u001b[38;5;241m=\u001b[39m unitaries\u001b[38;5;241m.\u001b[39mrotate_rho_probs(\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28mself\u001b[39m, basis, sample, include_extras\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    295\u001b[0m )\n\u001b[1;32m    296\u001b[0m inv_UrhoU \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m (UrhoU \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-8\u001b[39m)  \u001b[38;5;66;03m# avoid dividing by zero\u001b[39;00m\n\u001b[0;32m--> 298\u001b[0m raw_grads \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mam_grads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mph_grads(v)]\n\u001b[1;32m    300\u001b[0m rotated_grad \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;241m-\u001b[39mcplx\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mijb,ijbg->bg\u001b[39m\u001b[38;5;124m\"\u001b[39m, UrhoU_v, g, imag_part\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m raw_grads\n\u001b[1;32m    302\u001b[0m ]\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [torch\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb,bg->g\u001b[39m\u001b[38;5;124m\"\u001b[39m, inv_UrhoU, g) \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m rotated_grad]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/density_matrix.py:315\u001b[0m, in \u001b[0;36mDensityMatrix.am_grads\u001b[0;34m(self, v)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mam_grads\u001b[39m(\u001b[38;5;28mself\u001b[39m, v):\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Computes the gradients of the amplitude RBM for given input states\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    :param v: The first input state, :math:`\\sigma`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;124;03m    :rtype: torch.Tensor\u001b[39;00m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrbm_am\u001b[38;5;241m.\u001b[39mgamma_grad(v, v, eta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, expand\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpi_grad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/density_matrix.py:182\u001b[0m, in \u001b[0;36mDensityMatrix.pi_grad\u001b[0;34m(self, v, vp, phase, expand)\u001b[0m\n\u001b[1;32m    177\u001b[0m vp \u001b[38;5;241m=\u001b[39m (vp\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m vp\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m vp)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrbm_am\u001b[38;5;241m.\u001b[39mweights_W)\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m expand:\n\u001b[1;32m    180\u001b[0m     arg_real \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m (\n\u001b[1;32m    181\u001b[0m         F\u001b[38;5;241m.\u001b[39mlinear(v, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrbm_am\u001b[38;5;241m.\u001b[39mweights_U, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrbm_am\u001b[38;5;241m.\u001b[39maux_bias)\u001b[38;5;241m.\u001b[39munsqueeze_(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 182\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrbm_am\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights_U\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrbm_am\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maux_bias\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39munsqueeze_(\n\u001b[1;32m    183\u001b[0m             \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    184\u001b[0m         )\n\u001b[1;32m    185\u001b[0m     )\n\u001b[1;32m    186\u001b[0m     arg_imag \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m (\n\u001b[1;32m    187\u001b[0m         F\u001b[38;5;241m.\u001b[39mlinear(v, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrbm_ph\u001b[38;5;241m.\u001b[39mweights_U)\u001b[38;5;241m.\u001b[39munsqueeze_(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;241m-\u001b[39m F\u001b[38;5;241m.\u001b[39mlinear(vp, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrbm_ph\u001b[38;5;241m.\u001b[39mweights_U)\u001b[38;5;241m.\u001b[39munsqueeze_(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    189\u001b[0m     )\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# experiment params\n",
    "#each_n_shot_list = [10, 50, 100, 500, 1000, 5000, 10000]\n",
    "each_n_shot_list = [1000]\n",
    "#error_model_list = [\"depolarizing\", \"unitary\", \"depolarizing&unitary\"]\n",
    "error_model_list = [\"unitary\"]\n",
    "\n",
    "for error_model in error_model_list:\n",
    "    for each_n_shot in each_n_shot_list:\n",
    "        print(f\"error_model : {error_model}, each_n_shot : {each_n_shot}\")\n",
    "        train_data_path = f\"./data/{error_model}/error_prob_{100*error_rate}%/num_of_data_{each_n_shot}/\"\n",
    "        meas_pattern_path = train_data_path + \"/measurement_pattern.txt\"\n",
    "        meas_label_path = train_data_path + \"/measurement_label.txt\"\n",
    "        meas_result_path = train_data_path + \"/measurement_result.txt\"\n",
    "        ideal_rho_re_path = ideal_state_path + \"/rho_real.txt\"\n",
    "        ideal_rho_im_path = ideal_state_path + \"/rho_imag.txt\"\n",
    "        meas_result, ideal_rho, meas_label, meas_pattern = data.load_data_DM(meas_result_path,\n",
    "                                                                             ideal_rho_re_path,\n",
    "                                                                             ideal_rho_im_path,\n",
    "                                                                             meas_label_path,\n",
    "                                                                             meas_pattern_path)\n",
    "        \n",
    "        nn_state_dm = DensityMatrix(num_visible = n_visible_unit, \n",
    "                                    num_hidden = n_hidden_unit, \n",
    "                                    num_aux = n_aux_unit, \n",
    "                                    unitary_dict = unitaries.create_dict(),\n",
    "                                    gpu = True)\n",
    "        \n",
    "        callbacks = create_callback_dm(nn_state_dm)\n",
    "        \n",
    "        nn_state_dm.fit(data = meas_result,\n",
    "                        input_bases = meas_label,\n",
    "                        epochs = epoch,\n",
    "                        pos_batch_size = pbs,\n",
    "                        neg_batch_size = nbs,\n",
    "                        lr = lr,\n",
    "                        k = n_gibbs_step,\n",
    "                        bases = meas_pattern,\n",
    "                        callbacks = callbacks,\n",
    "                        time = True,\n",
    "                        optimizer = torch.optim.Adadelta,\n",
    "                        scheduler = torch.optim.lr_scheduler.StepLR,\n",
    "                        scheduler_args = {\"step_size\": lr_drop_epoch, \"gamma\": lr_drop_factor},\n",
    "                       )\n",
    "        \n",
    "        # save model\n",
    "        nn_state_dm.save(f\"./exp_varying_state/model_n_pattern_shot={each_n_shot}_{error_model}_1%.pt\")\n",
    "        # save train log\n",
    "        train_log_df = pd.DataFrame()\n",
    "        train_log_df[\"epoch\"] = np.arange(period, epoch+1, period)\n",
    "        train_log_df[\"Fidelity\"] = callbacks[0][\"Fidelity\"]\n",
    "        train_log_df[\"KL_Divergence\"] = callbacks[0][\"KL_Divergence\"]\n",
    "        #train_log_df[\"Observable_XX_ev\"] = callbacks[0][\"Observable_XX_ev\"]\n",
    "        #train_log_df[\"Observable_ZZ_ev\"] = callbacks[0][\"Observable_ZZ_ev\"]\n",
    "        train_log_df.to_csv(f\"./exp_varying_state/model_n_pattern_shot={each_n_shot}_{error_model}_1%.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db257420-43c9-4fbb-881e-3d5618e037fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
