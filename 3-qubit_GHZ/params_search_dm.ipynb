{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cfd6da35-81e5-44b3-95c1-d30d0fc177c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import random\n",
    "import warnings\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "from tqdm.notebook import tqdm\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "from qucumber.nn_states import DensityMatrix\n",
    "from qucumber.nn_states import ComplexWaveFunction\n",
    "from qucumber.callbacks import MetricEvaluator\n",
    "import qucumber.utils.unitaries as unitaries\n",
    "import qucumber.utils.training_statistics as ts\n",
    "import qucumber.utils.cplx as cplx\n",
    "import qucumber.utils.data as data\n",
    "from qucumber.observables import ObservableBase, to_pm1\n",
    "from qucumber.observables.pauli import flip_spin\n",
    "import qucumber\n",
    "\n",
    "from qulacs.gate import Pauli\n",
    "\n",
    "import optuna\n",
    "\n",
    "with open('./params_setting.yaml', 'r') as yml:\n",
    "    params = yaml.safe_load(yml)\n",
    "    \n",
    "# quantum circuit parameter\n",
    "n_qubit = params[\"circuit_info\"][\"n_qubit\"]\n",
    "each_n_shot = params[\"circuit_info\"][\"each_n_shot\"]\n",
    "state_name = params[\"circuit_info\"][\"state_name\"]\n",
    "error_model = params[\"circuit_info\"][\"error_model\"]\n",
    "error_rate = params[\"circuit_info\"][\"error_rate\"]\n",
    "# RBM architecture parameter\n",
    "n_visible_unit = params[\"architecture_info\"][\"n_visible_unit\"]\n",
    "n_hidden_unit = params[\"architecture_info\"][\"n_hidden_unit\"] \n",
    "n_aux_unit = params[\"architecture_info\"][\"n_aux_unit\"]\n",
    "# train parameter\n",
    "lr = params[\"train_info\"][\"lr\"]\n",
    "pbs = params[\"train_info\"][\"positive_batch_size\"]\n",
    "nbs = params[\"train_info\"][\"negative_batch_size\"]\n",
    "n_gibbs_step = params[\"train_info\"][\"n_gibbs_step\"]\n",
    "period = 1\n",
    "epoch = params[\"train_info\"][\"n_epoch\"]\n",
    "lr_drop_epoch = params[\"train_info\"][\"lr_drop_epoch\"]\n",
    "lr_drop_factor = params[\"train_info\"][\"lr_drop_factor\"]\n",
    "seed = params[\"train_info\"][\"seed\"]\n",
    "# sampling parameter\n",
    "n_sampling = params[\"sampling_info\"][\"n_sample\"]\n",
    "n_copy = params[\"sampling_info\"][\"n_copy\"]\n",
    "# data path info\n",
    "train_data_path = f\"./data/{error_model}/error_prob_{100*error_rate}%/num_of_data_{each_n_shot}/\"\n",
    "ideal_state_path = f\"./target_state/\"\n",
    "\n",
    "# settings\n",
    "## warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "## seaborn layout\n",
    "sns.set()\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "## seed\n",
    "def seed_settings(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    qucumber.set_random_seed(seed, cpu=True, gpu=False)\n",
    "\n",
    "seed_settings(seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da0f212c-ba12-4c7c-ae2e-4795a0e50148",
   "metadata": {},
   "outputs": [],
   "source": [
    "meas_pattern_path = train_data_path + \"/measurement_pattern.txt\"\n",
    "meas_label_path = train_data_path + \"/measurement_label.txt\"\n",
    "meas_result_path = train_data_path + \"/measurement_result.txt\"\n",
    "ideal_rho_re_path = ideal_state_path + \"/rho_real.txt\"\n",
    "ideal_rho_im_path = ideal_state_path + \"/rho_imag.txt\"\n",
    "meas_result, ideal_rho, meas_label, meas_pattern = data.load_data_DM(meas_result_path,\n",
    "                                                                     ideal_rho_re_path,\n",
    "                                                                     ideal_rho_im_path,\n",
    "                                                                     meas_label_path,\n",
    "                                                                     meas_pattern_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b43214ba-75bd-4c68-84da-d896eb0d0868",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_state_dm = DensityMatrix(\n",
    "    num_visible = n_visible_unit, \n",
    "    num_hidden = n_hidden_unit, \n",
    "    num_aux = n_aux_unit, \n",
    "    unitary_dict = unitaries.create_dict(),\n",
    "    gpu = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8d8b377-3aa4-4227-9ca9-dfa48bcd98b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_callback_dm(nn_state):\n",
    "    metric_dict = {\n",
    "        \"Fidelity\": ts.fidelity,\n",
    "        \"KL_Divergence\": ts.KL,\n",
    "        #\"Observable_XXX_ev\": observable_XXX_ev,\n",
    "        #\"Observable_XZZ_ev\": observable_XZZ_ev,\n",
    "    }\n",
    "\n",
    "    space = nn_state.generate_hilbert_space()\n",
    "    callbacks = [\n",
    "        MetricEvaluator(\n",
    "            period,\n",
    "            metric_dict,\n",
    "            target = ideal_rho,\n",
    "            bases = meas_pattern,\n",
    "            verbose = True,\n",
    "            space = space,\n",
    "        )\n",
    "    ]\n",
    "    return callbacks\n",
    "\n",
    "callbacks = create_callback_dm(nn_state_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26954cf1-d071-468c-b0d3-987a32e314c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # load dataset\n",
    "    meas_pattern_path = train_data_path + \"/measurement_pattern.txt\"\n",
    "    meas_label_path = train_data_path + \"/measurement_label.txt\"\n",
    "    meas_result_path = train_data_path + \"/measurement_result.txt\"\n",
    "    ideal_rho_re_path = ideal_state_path + \"/rho_real.txt\"\n",
    "    ideal_rho_im_path = ideal_state_path + \"/rho_imag.txt\"\n",
    "    meas_result, ideal_rho, meas_label, meas_pattern = data.load_data_DM(meas_result_path, ideal_rho_re_path, ideal_rho_im_path, meas_label_path, meas_pattern_path)\n",
    "    # search params\n",
    "    lr = trial.suggest_float(\"lr\", 5, 20, log=True)\n",
    "    #n_gibbs_step = trial.suggest_int(\"k\", 10, 5000, log=True)\n",
    "    pbs = trial.suggest_categorical(\"pbs\", [1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000])\n",
    "    nbs = trial.suggest_categorical(\"nbs\", [1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000])\n",
    "    \n",
    "    nn_state_dm.fit(data = meas_result,\n",
    "                            input_bases = meas_label,\n",
    "                            epochs = epoch,\n",
    "                            pos_batch_size = pbs,\n",
    "                            neg_batch_size = nbs,\n",
    "                            lr = lr,\n",
    "                            k = n_gibbs_step,\n",
    "                            bases = meas_pattern,\n",
    "                            callbacks = callbacks,\n",
    "                            time = True,\n",
    "                            optimizer = torch.optim.Adadelta,\n",
    "                            schexduler = torch.optim.lr_scheduler.StepLR,\n",
    "                            scheduler_args = {\"step_size\": lr_drop_epoch, \"gamma\": lr_drop_factor},\n",
    "                            )\n",
    "        \n",
    "    loss = callbacks[0][\"KL_Divergence\"][-1]\n",
    "    trial.report(loss, epoch)\n",
    "    if trial.should_prune():\n",
    "        raise optuna.TrialPruned()\n",
    "        \n",
    "    return callbacks[0][\"KL_Divergence\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d76d1e0-79f5-4f78-9cda-f24256a1ccce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 03:32:31,509] A new study created in memory with name: no-name-075b6853-ca40-4e03-8bc8-3b460519de42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A new study created in memory with name: no-name-075b6853-ca40-4e03-8bc8-3b460519de42\n",
      "A new study created in memory with name: no-name-075b6853-ca40-4e03-8bc8-3b460519de42\n",
      "A new study created in memory with name: no-name-075b6853-ca40-4e03-8bc8-3b460519de42\n",
      "A new study created in memory with name: no-name-075b6853-ca40-4e03-8bc8-3b460519de42\n",
      "A new study created in memory with name: no-name-075b6853-ca40-4e03-8bc8-3b460519de42\n",
      "A new study created in memory with name: no-name-075b6853-ca40-4e03-8bc8-3b460519de42\n",
      "Epoch: 1\tFidelity = 0.063938\tKL_Divergence = 0.607791\n",
      "Epoch: 2\tFidelity = 0.117828\tKL_Divergence = 0.538327\n",
      "Epoch: 3\tFidelity = 0.167501\tKL_Divergence = 0.398902\n",
      "Epoch: 4\tFidelity = 0.264585\tKL_Divergence = 0.422170\n",
      "Epoch: 5\tFidelity = 0.258448\tKL_Divergence = 0.338810\n",
      "Epoch: 6\tFidelity = 0.240563\tKL_Divergence = 0.274546\n",
      "Epoch: 7\tFidelity = 0.289468\tKL_Divergence = 0.337020\n",
      "Epoch: 8\tFidelity = 0.293571\tKL_Divergence = 0.306379\n",
      "Epoch: 9\tFidelity = 0.328036\tKL_Divergence = 0.259922\n",
      "Epoch: 10\tFidelity = 0.329554\tKL_Divergence = 0.244704\n",
      "Epoch: 11\tFidelity = 0.398823\tKL_Divergence = 0.272304\n",
      "Epoch: 12\tFidelity = 0.379937\tKL_Divergence = 0.240812\n",
      "Epoch: 13\tFidelity = 0.444456\tKL_Divergence = 0.220032\n",
      "Epoch: 14\tFidelity = 0.418460\tKL_Divergence = 0.219016\n",
      "Epoch: 15\tFidelity = 0.455403\tKL_Divergence = 0.252916\n",
      "Epoch: 16\tFidelity = 0.419651\tKL_Divergence = 0.268881\n",
      "Epoch: 17\tFidelity = 0.466575\tKL_Divergence = 0.206419\n",
      "Epoch: 18\tFidelity = 0.404358\tKL_Divergence = 0.231139\n",
      "Epoch: 19\tFidelity = 0.485347\tKL_Divergence = 0.218267\n",
      "Epoch: 20\tFidelity = 0.438422\tKL_Divergence = 0.232108\n",
      "Epoch: 21\tFidelity = 0.472109\tKL_Divergence = 0.174044\n",
      "Epoch: 22\tFidelity = 0.457869\tKL_Divergence = 0.204208\n",
      "Epoch: 23\tFidelity = 0.489428\tKL_Divergence = 0.202280\n",
      "Epoch: 24\tFidelity = 0.462772\tKL_Divergence = 0.230893\n",
      "Epoch: 25\tFidelity = 0.517118\tKL_Divergence = 0.205342\n",
      "Epoch: 26\tFidelity = 0.481631\tKL_Divergence = 0.237514\n",
      "Epoch: 27\tFidelity = 0.546472\tKL_Divergence = 0.178487\n",
      "Epoch: 28\tFidelity = 0.492112\tKL_Divergence = 0.257152\n",
      "Epoch: 29\tFidelity = 0.520436\tKL_Divergence = 0.183704\n",
      "Epoch: 30\tFidelity = 0.494942\tKL_Divergence = 0.242910\n",
      "Epoch: 31\tFidelity = 0.541520\tKL_Divergence = 0.207866\n",
      "Epoch: 32\tFidelity = 0.499285\tKL_Divergence = 0.233640\n",
      "Epoch: 33\tFidelity = 0.534214\tKL_Divergence = 0.176344\n",
      "Epoch: 34\tFidelity = 0.532299\tKL_Divergence = 0.226640\n",
      "Epoch: 35\tFidelity = 0.568410\tKL_Divergence = 0.196426\n",
      "Epoch: 36\tFidelity = 0.479852\tKL_Divergence = 0.202444\n",
      "Epoch: 37\tFidelity = 0.548258\tKL_Divergence = 0.193233\n",
      "Epoch: 38\tFidelity = 0.478051\tKL_Divergence = 0.210617\n",
      "Epoch: 39\tFidelity = 0.540466\tKL_Divergence = 0.173941\n",
      "Epoch: 40\tFidelity = 0.573626\tKL_Divergence = 0.231499\n",
      "Epoch: 41\tFidelity = 0.652574\tKL_Divergence = 0.189169\n",
      "Epoch: 42\tFidelity = 0.509201\tKL_Divergence = 0.223632\n",
      "Epoch: 43\tFidelity = 0.544927\tKL_Divergence = 0.173513\n",
      "Epoch: 44\tFidelity = 0.550088\tKL_Divergence = 0.236773\n",
      "Epoch: 45\tFidelity = 0.651974\tKL_Divergence = 0.169306\n",
      "Epoch: 46\tFidelity = 0.586437\tKL_Divergence = 0.246551\n",
      "Epoch: 47\tFidelity = 0.561512\tKL_Divergence = 0.186101\n",
      "Epoch: 48\tFidelity = 0.589582\tKL_Divergence = 0.222163\n",
      "Epoch: 49\tFidelity = 0.627889\tKL_Divergence = 0.181895\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 03:39:31,204] Trial 0 finished with value: 0.19101943833623586 and parameters: {'lr': 19.912493032980915, 'pbs': 3000, 'nbs': 4000}. Best is trial 0 with value: 0.19101943833623586.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.615808\tKL_Divergence = 0.191019\n",
      "Total time elapsed during training: 419.403 s\n",
      "Trial 0 finished with value: 0.19101943833623586 and parameters: {'lr': 19.912493032980915, 'pbs': 3000, 'nbs': 4000}. Best is trial 0 with value: 0.19101943833623586.\n",
      "Trial 0 finished with value: 0.19101943833623586 and parameters: {'lr': 19.912493032980915, 'pbs': 3000, 'nbs': 4000}. Best is trial 0 with value: 0.19101943833623586.\n",
      "Trial 0 finished with value: 0.19101943833623586 and parameters: {'lr': 19.912493032980915, 'pbs': 3000, 'nbs': 4000}. Best is trial 0 with value: 0.19101943833623586.\n",
      "Trial 0 finished with value: 0.19101943833623586 and parameters: {'lr': 19.912493032980915, 'pbs': 3000, 'nbs': 4000}. Best is trial 0 with value: 0.19101943833623586.\n",
      "Trial 0 finished with value: 0.19101943833623586 and parameters: {'lr': 19.912493032980915, 'pbs': 3000, 'nbs': 4000}. Best is trial 0 with value: 0.19101943833623586.\n",
      "Trial 0 finished with value: 0.19101943833623586 and parameters: {'lr': 19.912493032980915, 'pbs': 3000, 'nbs': 4000}. Best is trial 0 with value: 0.19101943833623586.\n",
      "Epoch: 1\tFidelity = 0.697349\tKL_Divergence = 0.089717\n",
      "Epoch: 2\tFidelity = 0.714365\tKL_Divergence = 0.082408\n",
      "Epoch: 3\tFidelity = 0.735655\tKL_Divergence = 0.079849\n",
      "Epoch: 4\tFidelity = 0.750701\tKL_Divergence = 0.070030\n",
      "Epoch: 5\tFidelity = 0.759670\tKL_Divergence = 0.069770\n",
      "Epoch: 6\tFidelity = 0.784525\tKL_Divergence = 0.062957\n",
      "Epoch: 7\tFidelity = 0.800588\tKL_Divergence = 0.056760\n",
      "Epoch: 8\tFidelity = 0.806551\tKL_Divergence = 0.055543\n",
      "Epoch: 9\tFidelity = 0.823938\tKL_Divergence = 0.050636\n",
      "Epoch: 10\tFidelity = 0.827596\tKL_Divergence = 0.048645\n",
      "Epoch: 11\tFidelity = 0.841124\tKL_Divergence = 0.052642\n",
      "Epoch: 12\tFidelity = 0.844932\tKL_Divergence = 0.043769\n",
      "Epoch: 13\tFidelity = 0.845190\tKL_Divergence = 0.045559\n",
      "Epoch: 14\tFidelity = 0.858250\tKL_Divergence = 0.040072\n",
      "Epoch: 15\tFidelity = 0.859787\tKL_Divergence = 0.040345\n",
      "Epoch: 16\tFidelity = 0.866889\tKL_Divergence = 0.038849\n",
      "Epoch: 17\tFidelity = 0.869381\tKL_Divergence = 0.039706\n",
      "Epoch: 18\tFidelity = 0.877460\tKL_Divergence = 0.035589\n",
      "Epoch: 19\tFidelity = 0.883347\tKL_Divergence = 0.034034\n",
      "Epoch: 20\tFidelity = 0.883280\tKL_Divergence = 0.034851\n",
      "Epoch: 21\tFidelity = 0.887368\tKL_Divergence = 0.033195\n",
      "Epoch: 22\tFidelity = 0.888868\tKL_Divergence = 0.033375\n",
      "Epoch: 23\tFidelity = 0.890933\tKL_Divergence = 0.036418\n",
      "Epoch: 24\tFidelity = 0.885775\tKL_Divergence = 0.038933\n",
      "Epoch: 25\tFidelity = 0.895251\tKL_Divergence = 0.031994\n",
      "Epoch: 26\tFidelity = 0.896795\tKL_Divergence = 0.042915\n",
      "Epoch: 27\tFidelity = 0.902527\tKL_Divergence = 0.037242\n",
      "Epoch: 28\tFidelity = 0.897446\tKL_Divergence = 0.035184\n",
      "Epoch: 29\tFidelity = 0.896915\tKL_Divergence = 0.034047\n",
      "Epoch: 30\tFidelity = 0.902858\tKL_Divergence = 0.030186\n",
      "Epoch: 31\tFidelity = 0.886427\tKL_Divergence = 0.051924\n",
      "Epoch: 32\tFidelity = 0.912412\tKL_Divergence = 0.027517\n",
      "Epoch: 33\tFidelity = 0.888238\tKL_Divergence = 0.037165\n",
      "Epoch: 34\tFidelity = 0.912629\tKL_Divergence = 0.036021\n",
      "Epoch: 35\tFidelity = 0.902355\tKL_Divergence = 0.039087\n",
      "Epoch: 36\tFidelity = 0.906592\tKL_Divergence = 0.032194\n",
      "Epoch: 37\tFidelity = 0.906471\tKL_Divergence = 0.036001\n",
      "Epoch: 38\tFidelity = 0.916914\tKL_Divergence = 0.026594\n",
      "Epoch: 39\tFidelity = 0.915076\tKL_Divergence = 0.027076\n",
      "Epoch: 40\tFidelity = 0.918428\tKL_Divergence = 0.035869\n",
      "Epoch: 41\tFidelity = 0.919925\tKL_Divergence = 0.024865\n",
      "Epoch: 42\tFidelity = 0.918103\tKL_Divergence = 0.026145\n",
      "Epoch: 43\tFidelity = 0.919377\tKL_Divergence = 0.032808\n",
      "Epoch: 44\tFidelity = 0.918646\tKL_Divergence = 0.026070\n",
      "Epoch: 45\tFidelity = 0.922180\tKL_Divergence = 0.024500\n",
      "Epoch: 46\tFidelity = 0.921973\tKL_Divergence = 0.024562\n",
      "Epoch: 47\tFidelity = 0.916679\tKL_Divergence = 0.027161\n",
      "Epoch: 48\tFidelity = 0.923931\tKL_Divergence = 0.023874\n",
      "Epoch: 49\tFidelity = 0.925326\tKL_Divergence = 0.026870\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 03:47:56,151] Trial 1 finished with value: 0.03225167903284687 and parameters: {'lr': 8.106539690177215, 'pbs': 2000, 'nbs': 1000}. Best is trial 1 with value: 0.03225167903284687.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.916703\tKL_Divergence = 0.032252\n",
      "Total time elapsed during training: 504.624 s\n",
      "Trial 1 finished with value: 0.03225167903284687 and parameters: {'lr': 8.106539690177215, 'pbs': 2000, 'nbs': 1000}. Best is trial 1 with value: 0.03225167903284687.\n",
      "Trial 1 finished with value: 0.03225167903284687 and parameters: {'lr': 8.106539690177215, 'pbs': 2000, 'nbs': 1000}. Best is trial 1 with value: 0.03225167903284687.\n",
      "Trial 1 finished with value: 0.03225167903284687 and parameters: {'lr': 8.106539690177215, 'pbs': 2000, 'nbs': 1000}. Best is trial 1 with value: 0.03225167903284687.\n",
      "Trial 1 finished with value: 0.03225167903284687 and parameters: {'lr': 8.106539690177215, 'pbs': 2000, 'nbs': 1000}. Best is trial 1 with value: 0.03225167903284687.\n",
      "Trial 1 finished with value: 0.03225167903284687 and parameters: {'lr': 8.106539690177215, 'pbs': 2000, 'nbs': 1000}. Best is trial 1 with value: 0.03225167903284687.\n",
      "Trial 1 finished with value: 0.03225167903284687 and parameters: {'lr': 8.106539690177215, 'pbs': 2000, 'nbs': 1000}. Best is trial 1 with value: 0.03225167903284687.\n",
      "Epoch: 1\tFidelity = 0.918209\tKL_Divergence = 0.030743\n",
      "Epoch: 2\tFidelity = 0.909505\tKL_Divergence = 0.044699\n",
      "Epoch: 3\tFidelity = 0.927336\tKL_Divergence = 0.027517\n",
      "Epoch: 4\tFidelity = 0.927861\tKL_Divergence = 0.023884\n",
      "Epoch: 5\tFidelity = 0.928264\tKL_Divergence = 0.023436\n",
      "Epoch: 6\tFidelity = 0.930528\tKL_Divergence = 0.025450\n",
      "Epoch: 7\tFidelity = 0.920204\tKL_Divergence = 0.028519\n",
      "Epoch: 8\tFidelity = 0.927780\tKL_Divergence = 0.028919\n",
      "Epoch: 9\tFidelity = 0.920390\tKL_Divergence = 0.035676\n",
      "Epoch: 10\tFidelity = 0.913659\tKL_Divergence = 0.046624\n",
      "Epoch: 11\tFidelity = 0.932769\tKL_Divergence = 0.029700\n",
      "Epoch: 12\tFidelity = 0.922847\tKL_Divergence = 0.033336\n",
      "Epoch: 13\tFidelity = 0.933579\tKL_Divergence = 0.022800\n",
      "Epoch: 14\tFidelity = 0.900871\tKL_Divergence = 0.066668\n",
      "Epoch: 15\tFidelity = 0.935788\tKL_Divergence = 0.023295\n",
      "Epoch: 16\tFidelity = 0.933664\tKL_Divergence = 0.022491\n",
      "Epoch: 17\tFidelity = 0.924007\tKL_Divergence = 0.047907\n",
      "Epoch: 18\tFidelity = 0.919902\tKL_Divergence = 0.030220\n",
      "Epoch: 19\tFidelity = 0.934390\tKL_Divergence = 0.028685\n",
      "Epoch: 20\tFidelity = 0.936466\tKL_Divergence = 0.022390\n",
      "Epoch: 21\tFidelity = 0.936019\tKL_Divergence = 0.021871\n",
      "Epoch: 22\tFidelity = 0.931762\tKL_Divergence = 0.026641\n",
      "Epoch: 23\tFidelity = 0.932566\tKL_Divergence = 0.023984\n",
      "Epoch: 24\tFidelity = 0.931186\tKL_Divergence = 0.036429\n",
      "Epoch: 25\tFidelity = 0.922424\tKL_Divergence = 0.032441\n",
      "Epoch: 26\tFidelity = 0.932078\tKL_Divergence = 0.030799\n",
      "Epoch: 27\tFidelity = 0.909165\tKL_Divergence = 0.045570\n",
      "Epoch: 28\tFidelity = 0.920235\tKL_Divergence = 0.039864\n",
      "Epoch: 29\tFidelity = 0.922489\tKL_Divergence = 0.029041\n",
      "Epoch: 30\tFidelity = 0.932442\tKL_Divergence = 0.026024\n",
      "Epoch: 31\tFidelity = 0.935132\tKL_Divergence = 0.023743\n",
      "Epoch: 32\tFidelity = 0.930935\tKL_Divergence = 0.028942\n",
      "Epoch: 33\tFidelity = 0.928295\tKL_Divergence = 0.028553\n",
      "Epoch: 34\tFidelity = 0.924513\tKL_Divergence = 0.028662\n",
      "Epoch: 35\tFidelity = 0.931200\tKL_Divergence = 0.038112\n",
      "Epoch: 36\tFidelity = 0.932946\tKL_Divergence = 0.024269\n",
      "Epoch: 37\tFidelity = 0.936214\tKL_Divergence = 0.025795\n",
      "Epoch: 38\tFidelity = 0.926243\tKL_Divergence = 0.041850\n",
      "Epoch: 39\tFidelity = 0.927236\tKL_Divergence = 0.028333\n",
      "Epoch: 40\tFidelity = 0.930650\tKL_Divergence = 0.024760\n",
      "Epoch: 41\tFidelity = 0.926033\tKL_Divergence = 0.028224\n",
      "Epoch: 42\tFidelity = 0.917670\tKL_Divergence = 0.038964\n",
      "Epoch: 43\tFidelity = 0.933467\tKL_Divergence = 0.023523\n",
      "Epoch: 44\tFidelity = 0.931105\tKL_Divergence = 0.025129\n",
      "Epoch: 45\tFidelity = 0.921697\tKL_Divergence = 0.035994\n",
      "Epoch: 46\tFidelity = 0.929108\tKL_Divergence = 0.041603\n",
      "Epoch: 47\tFidelity = 0.929927\tKL_Divergence = 0.024961\n",
      "Epoch: 48\tFidelity = 0.935329\tKL_Divergence = 0.022884\n",
      "Epoch: 49\tFidelity = 0.937241\tKL_Divergence = 0.023231\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 03:59:53,019] Trial 2 finished with value: 0.025703336080851083 and parameters: {'lr': 12.759771292878021, 'pbs': 1000, 'nbs': 9000}. Best is trial 2 with value: 0.025703336080851083.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.928332\tKL_Divergence = 0.025703\n",
      "Total time elapsed during training: 716.531 s\n",
      "Trial 2 finished with value: 0.025703336080851083 and parameters: {'lr': 12.759771292878021, 'pbs': 1000, 'nbs': 9000}. Best is trial 2 with value: 0.025703336080851083.\n",
      "Trial 2 finished with value: 0.025703336080851083 and parameters: {'lr': 12.759771292878021, 'pbs': 1000, 'nbs': 9000}. Best is trial 2 with value: 0.025703336080851083.\n",
      "Trial 2 finished with value: 0.025703336080851083 and parameters: {'lr': 12.759771292878021, 'pbs': 1000, 'nbs': 9000}. Best is trial 2 with value: 0.025703336080851083.\n",
      "Trial 2 finished with value: 0.025703336080851083 and parameters: {'lr': 12.759771292878021, 'pbs': 1000, 'nbs': 9000}. Best is trial 2 with value: 0.025703336080851083.\n",
      "Trial 2 finished with value: 0.025703336080851083 and parameters: {'lr': 12.759771292878021, 'pbs': 1000, 'nbs': 9000}. Best is trial 2 with value: 0.025703336080851083.\n",
      "Trial 2 finished with value: 0.025703336080851083 and parameters: {'lr': 12.759771292878021, 'pbs': 1000, 'nbs': 9000}. Best is trial 2 with value: 0.025703336080851083.\n",
      "Epoch: 1\tFidelity = 0.932344\tKL_Divergence = 0.027733\n",
      "Epoch: 2\tFidelity = 0.930902\tKL_Divergence = 0.028771\n",
      "Epoch: 3\tFidelity = 0.936329\tKL_Divergence = 0.023968\n",
      "Epoch: 4\tFidelity = 0.932807\tKL_Divergence = 0.024291\n",
      "Epoch: 5\tFidelity = 0.934807\tKL_Divergence = 0.022357\n",
      "Epoch: 6\tFidelity = 0.933680\tKL_Divergence = 0.023220\n",
      "Epoch: 7\tFidelity = 0.930637\tKL_Divergence = 0.033350\n",
      "Epoch: 8\tFidelity = 0.933913\tKL_Divergence = 0.022723\n",
      "Epoch: 9\tFidelity = 0.933714\tKL_Divergence = 0.022539\n",
      "Epoch: 10\tFidelity = 0.925019\tKL_Divergence = 0.027708\n",
      "Epoch: 11\tFidelity = 0.933983\tKL_Divergence = 0.023907\n",
      "Epoch: 12\tFidelity = 0.933329\tKL_Divergence = 0.023257\n",
      "Epoch: 13\tFidelity = 0.929446\tKL_Divergence = 0.027551\n",
      "Epoch: 14\tFidelity = 0.929509\tKL_Divergence = 0.025160\n",
      "Epoch: 15\tFidelity = 0.932313\tKL_Divergence = 0.023871\n",
      "Epoch: 16\tFidelity = 0.930646\tKL_Divergence = 0.024192\n",
      "Epoch: 17\tFidelity = 0.932503\tKL_Divergence = 0.023224\n",
      "Epoch: 18\tFidelity = 0.929979\tKL_Divergence = 0.025064\n",
      "Epoch: 19\tFidelity = 0.934189\tKL_Divergence = 0.023107\n",
      "Epoch: 20\tFidelity = 0.932870\tKL_Divergence = 0.024452\n",
      "Epoch: 21\tFidelity = 0.932659\tKL_Divergence = 0.023992\n",
      "Epoch: 22\tFidelity = 0.931731\tKL_Divergence = 0.024048\n",
      "Epoch: 23\tFidelity = 0.929694\tKL_Divergence = 0.025025\n",
      "Epoch: 24\tFidelity = 0.928398\tKL_Divergence = 0.026549\n",
      "Epoch: 25\tFidelity = 0.929156\tKL_Divergence = 0.032981\n",
      "Epoch: 26\tFidelity = 0.934101\tKL_Divergence = 0.023119\n",
      "Epoch: 27\tFidelity = 0.932646\tKL_Divergence = 0.022830\n",
      "Epoch: 28\tFidelity = 0.933288\tKL_Divergence = 0.024762\n",
      "Epoch: 29\tFidelity = 0.930184\tKL_Divergence = 0.026414\n",
      "Epoch: 30\tFidelity = 0.926296\tKL_Divergence = 0.028285\n",
      "Epoch: 31\tFidelity = 0.931605\tKL_Divergence = 0.023843\n",
      "Epoch: 32\tFidelity = 0.927247\tKL_Divergence = 0.029308\n",
      "Epoch: 33\tFidelity = 0.927884\tKL_Divergence = 0.026670\n",
      "Epoch: 34\tFidelity = 0.932522\tKL_Divergence = 0.023296\n",
      "Epoch: 35\tFidelity = 0.933350\tKL_Divergence = 0.022644\n",
      "Epoch: 36\tFidelity = 0.925686\tKL_Divergence = 0.028299\n",
      "Epoch: 37\tFidelity = 0.933139\tKL_Divergence = 0.024667\n",
      "Epoch: 38\tFidelity = 0.933593\tKL_Divergence = 0.024811\n",
      "Epoch: 39\tFidelity = 0.932599\tKL_Divergence = 0.023438\n",
      "Epoch: 40\tFidelity = 0.929918\tKL_Divergence = 0.024276\n",
      "Epoch: 41\tFidelity = 0.930767\tKL_Divergence = 0.025410\n",
      "Epoch: 42\tFidelity = 0.932664\tKL_Divergence = 0.026328\n",
      "Epoch: 43\tFidelity = 0.931054\tKL_Divergence = 0.024874\n",
      "Epoch: 44\tFidelity = 0.929563\tKL_Divergence = 0.024882\n",
      "Epoch: 45\tFidelity = 0.928418\tKL_Divergence = 0.026665\n",
      "Epoch: 46\tFidelity = 0.930653\tKL_Divergence = 0.024816\n",
      "Epoch: 47\tFidelity = 0.931470\tKL_Divergence = 0.023717\n",
      "Epoch: 48\tFidelity = 0.933123\tKL_Divergence = 0.023043\n",
      "Epoch: 49\tFidelity = 0.931383\tKL_Divergence = 0.027960\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:05:51,580] Trial 3 finished with value: 0.023935205937259667 and parameters: {'lr': 6.217882819555931, 'pbs': 5000, 'nbs': 9000}. Best is trial 3 with value: 0.023935205937259667.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.931399\tKL_Divergence = 0.023935\n",
      "Total time elapsed during training: 357.626 s\n",
      "Trial 3 finished with value: 0.023935205937259667 and parameters: {'lr': 6.217882819555931, 'pbs': 5000, 'nbs': 9000}. Best is trial 3 with value: 0.023935205937259667.\n",
      "Trial 3 finished with value: 0.023935205937259667 and parameters: {'lr': 6.217882819555931, 'pbs': 5000, 'nbs': 9000}. Best is trial 3 with value: 0.023935205937259667.\n",
      "Trial 3 finished with value: 0.023935205937259667 and parameters: {'lr': 6.217882819555931, 'pbs': 5000, 'nbs': 9000}. Best is trial 3 with value: 0.023935205937259667.\n",
      "Trial 3 finished with value: 0.023935205937259667 and parameters: {'lr': 6.217882819555931, 'pbs': 5000, 'nbs': 9000}. Best is trial 3 with value: 0.023935205937259667.\n",
      "Trial 3 finished with value: 0.023935205937259667 and parameters: {'lr': 6.217882819555931, 'pbs': 5000, 'nbs': 9000}. Best is trial 3 with value: 0.023935205937259667.\n",
      "Trial 3 finished with value: 0.023935205937259667 and parameters: {'lr': 6.217882819555931, 'pbs': 5000, 'nbs': 9000}. Best is trial 3 with value: 0.023935205937259667.\n",
      "Epoch: 1\tFidelity = 0.921163\tKL_Divergence = 0.031772\n",
      "Epoch: 2\tFidelity = 0.930268\tKL_Divergence = 0.030856\n",
      "Epoch: 3\tFidelity = 0.936138\tKL_Divergence = 0.023095\n",
      "Epoch: 4\tFidelity = 0.932613\tKL_Divergence = 0.032474\n",
      "Epoch: 5\tFidelity = 0.929986\tKL_Divergence = 0.025092\n",
      "Epoch: 6\tFidelity = 0.926195\tKL_Divergence = 0.028139\n",
      "Epoch: 7\tFidelity = 0.933559\tKL_Divergence = 0.030052\n",
      "Epoch: 8\tFidelity = 0.928793\tKL_Divergence = 0.028182\n",
      "Epoch: 9\tFidelity = 0.916808\tKL_Divergence = 0.038449\n",
      "Epoch: 10\tFidelity = 0.929935\tKL_Divergence = 0.024464\n",
      "Epoch: 11\tFidelity = 0.934056\tKL_Divergence = 0.026628\n",
      "Epoch: 12\tFidelity = 0.931444\tKL_Divergence = 0.024946\n",
      "Epoch: 13\tFidelity = 0.936370\tKL_Divergence = 0.023528\n",
      "Epoch: 14\tFidelity = 0.934265\tKL_Divergence = 0.022926\n",
      "Epoch: 15\tFidelity = 0.934571\tKL_Divergence = 0.022871\n",
      "Epoch: 16\tFidelity = 0.935920\tKL_Divergence = 0.023208\n",
      "Epoch: 17\tFidelity = 0.934848\tKL_Divergence = 0.024824\n",
      "Epoch: 18\tFidelity = 0.935786\tKL_Divergence = 0.022335\n",
      "Epoch: 19\tFidelity = 0.928068\tKL_Divergence = 0.025761\n",
      "Epoch: 20\tFidelity = 0.934697\tKL_Divergence = 0.023356\n",
      "Epoch: 21\tFidelity = 0.935619\tKL_Divergence = 0.023186\n",
      "Epoch: 22\tFidelity = 0.929338\tKL_Divergence = 0.026167\n",
      "Epoch: 23\tFidelity = 0.934293\tKL_Divergence = 0.028807\n",
      "Epoch: 24\tFidelity = 0.917992\tKL_Divergence = 0.038819\n",
      "Epoch: 25\tFidelity = 0.929867\tKL_Divergence = 0.025321\n",
      "Epoch: 26\tFidelity = 0.932875\tKL_Divergence = 0.023915\n",
      "Epoch: 27\tFidelity = 0.926158\tKL_Divergence = 0.028931\n",
      "Epoch: 28\tFidelity = 0.930892\tKL_Divergence = 0.025195\n",
      "Epoch: 29\tFidelity = 0.932634\tKL_Divergence = 0.025331\n",
      "Epoch: 30\tFidelity = 0.932266\tKL_Divergence = 0.025549\n",
      "Epoch: 31\tFidelity = 0.934298\tKL_Divergence = 0.027572\n",
      "Epoch: 32\tFidelity = 0.932859\tKL_Divergence = 0.023917\n",
      "Epoch: 33\tFidelity = 0.931293\tKL_Divergence = 0.024549\n",
      "Epoch: 34\tFidelity = 0.933937\tKL_Divergence = 0.023444\n",
      "Epoch: 35\tFidelity = 0.931695\tKL_Divergence = 0.026658\n",
      "Epoch: 36\tFidelity = 0.934840\tKL_Divergence = 0.022481\n",
      "Epoch: 37\tFidelity = 0.934494\tKL_Divergence = 0.024495\n",
      "Epoch: 38\tFidelity = 0.934064\tKL_Divergence = 0.023025\n",
      "Epoch: 39\tFidelity = 0.924145\tKL_Divergence = 0.032019\n",
      "Epoch: 40\tFidelity = 0.932221\tKL_Divergence = 0.026047\n",
      "Epoch: 41\tFidelity = 0.937030\tKL_Divergence = 0.022668\n",
      "Epoch: 42\tFidelity = 0.935240\tKL_Divergence = 0.022587\n",
      "Epoch: 43\tFidelity = 0.929252\tKL_Divergence = 0.025647\n",
      "Epoch: 44\tFidelity = 0.936949\tKL_Divergence = 0.024100\n",
      "Epoch: 45\tFidelity = 0.934647\tKL_Divergence = 0.022917\n",
      "Epoch: 46\tFidelity = 0.930818\tKL_Divergence = 0.024579\n",
      "Epoch: 47\tFidelity = 0.934935\tKL_Divergence = 0.022423\n",
      "Epoch: 48\tFidelity = 0.931858\tKL_Divergence = 0.024714\n",
      "Epoch: 49\tFidelity = 0.925353\tKL_Divergence = 0.034784\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:17:33,413] Trial 4 finished with value: 0.02338123011135712 and parameters: {'lr': 8.328576967325219, 'pbs': 1000, 'nbs': 5000}. Best is trial 4 with value: 0.02338123011135712.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.934330\tKL_Divergence = 0.023381\n",
      "Total time elapsed during training: 701.530 s\n",
      "Trial 4 finished with value: 0.02338123011135712 and parameters: {'lr': 8.328576967325219, 'pbs': 1000, 'nbs': 5000}. Best is trial 4 with value: 0.02338123011135712.\n",
      "Trial 4 finished with value: 0.02338123011135712 and parameters: {'lr': 8.328576967325219, 'pbs': 1000, 'nbs': 5000}. Best is trial 4 with value: 0.02338123011135712.\n",
      "Trial 4 finished with value: 0.02338123011135712 and parameters: {'lr': 8.328576967325219, 'pbs': 1000, 'nbs': 5000}. Best is trial 4 with value: 0.02338123011135712.\n",
      "Trial 4 finished with value: 0.02338123011135712 and parameters: {'lr': 8.328576967325219, 'pbs': 1000, 'nbs': 5000}. Best is trial 4 with value: 0.02338123011135712.\n",
      "Trial 4 finished with value: 0.02338123011135712 and parameters: {'lr': 8.328576967325219, 'pbs': 1000, 'nbs': 5000}. Best is trial 4 with value: 0.02338123011135712.\n",
      "Trial 4 finished with value: 0.02338123011135712 and parameters: {'lr': 8.328576967325219, 'pbs': 1000, 'nbs': 5000}. Best is trial 4 with value: 0.02338123011135712.\n",
      "Epoch: 1\tFidelity = 0.938066\tKL_Divergence = 0.022615\n",
      "Epoch: 2\tFidelity = 0.936214\tKL_Divergence = 0.022231\n",
      "Epoch: 3\tFidelity = 0.937720\tKL_Divergence = 0.023719\n",
      "Epoch: 4\tFidelity = 0.931311\tKL_Divergence = 0.029088\n",
      "Epoch: 5\tFidelity = 0.932567\tKL_Divergence = 0.024535\n",
      "Epoch: 6\tFidelity = 0.936022\tKL_Divergence = 0.022184\n",
      "Epoch: 7\tFidelity = 0.933767\tKL_Divergence = 0.023060\n",
      "Epoch: 8\tFidelity = 0.934189\tKL_Divergence = 0.023474\n",
      "Epoch: 9\tFidelity = 0.930618\tKL_Divergence = 0.026923\n",
      "Epoch: 10\tFidelity = 0.933405\tKL_Divergence = 0.023036\n",
      "Epoch: 11\tFidelity = 0.936181\tKL_Divergence = 0.022704\n",
      "Epoch: 12\tFidelity = 0.932926\tKL_Divergence = 0.024610\n",
      "Epoch: 13\tFidelity = 0.934114\tKL_Divergence = 0.023456\n",
      "Epoch: 14\tFidelity = 0.934627\tKL_Divergence = 0.023327\n",
      "Epoch: 15\tFidelity = 0.932330\tKL_Divergence = 0.026935\n",
      "Epoch: 16\tFidelity = 0.935335\tKL_Divergence = 0.022214\n",
      "Epoch: 17\tFidelity = 0.932222\tKL_Divergence = 0.024508\n",
      "Epoch: 18\tFidelity = 0.935387\tKL_Divergence = 0.022111\n",
      "Epoch: 19\tFidelity = 0.935801\tKL_Divergence = 0.023232\n",
      "Epoch: 20\tFidelity = 0.928160\tKL_Divergence = 0.026089\n",
      "Epoch: 21\tFidelity = 0.932104\tKL_Divergence = 0.025802\n",
      "Epoch: 22\tFidelity = 0.936165\tKL_Divergence = 0.021817\n",
      "Epoch: 23\tFidelity = 0.930894\tKL_Divergence = 0.028313\n",
      "Epoch: 24\tFidelity = 0.933001\tKL_Divergence = 0.023388\n",
      "Epoch: 25\tFidelity = 0.930714\tKL_Divergence = 0.026817\n",
      "Epoch: 26\tFidelity = 0.933246\tKL_Divergence = 0.023220\n",
      "Epoch: 27\tFidelity = 0.934830\tKL_Divergence = 0.023929\n",
      "Epoch: 28\tFidelity = 0.933544\tKL_Divergence = 0.025068\n",
      "Epoch: 29\tFidelity = 0.934142\tKL_Divergence = 0.025447\n",
      "Epoch: 30\tFidelity = 0.925859\tKL_Divergence = 0.031212\n",
      "Epoch: 31\tFidelity = 0.932514\tKL_Divergence = 0.023509\n",
      "Epoch: 32\tFidelity = 0.937493\tKL_Divergence = 0.021338\n",
      "Epoch: 33\tFidelity = 0.935849\tKL_Divergence = 0.022556\n",
      "Epoch: 34\tFidelity = 0.930622\tKL_Divergence = 0.030121\n",
      "Epoch: 35\tFidelity = 0.934710\tKL_Divergence = 0.022403\n",
      "Epoch: 36\tFidelity = 0.938360\tKL_Divergence = 0.024149\n",
      "Epoch: 37\tFidelity = 0.932542\tKL_Divergence = 0.024376\n",
      "Epoch: 38\tFidelity = 0.934319\tKL_Divergence = 0.024365\n",
      "Epoch: 39\tFidelity = 0.935423\tKL_Divergence = 0.023150\n",
      "Epoch: 40\tFidelity = 0.930504\tKL_Divergence = 0.025540\n",
      "Epoch: 41\tFidelity = 0.931442\tKL_Divergence = 0.024421\n",
      "Epoch: 42\tFidelity = 0.931769\tKL_Divergence = 0.025147\n",
      "Epoch: 43\tFidelity = 0.929275\tKL_Divergence = 0.029381\n",
      "Epoch: 44\tFidelity = 0.932481\tKL_Divergence = 0.025180\n",
      "Epoch: 45\tFidelity = 0.933360\tKL_Divergence = 0.023409\n",
      "Epoch: 46\tFidelity = 0.932689\tKL_Divergence = 0.023737\n",
      "Epoch: 47\tFidelity = 0.934797\tKL_Divergence = 0.022996\n",
      "Epoch: 48\tFidelity = 0.932550\tKL_Divergence = 0.024051\n",
      "Epoch: 49\tFidelity = 0.930551\tKL_Divergence = 0.027524\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:22:55,293] Trial 5 finished with value: 0.022214973653203376 and parameters: {'lr': 6.347747910478959, 'pbs': 7000, 'nbs': 1000}. Best is trial 5 with value: 0.022214973653203376.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.936306\tKL_Divergence = 0.022215\n",
      "Total time elapsed during training: 321.540 s\n",
      "Trial 5 finished with value: 0.022214973653203376 and parameters: {'lr': 6.347747910478959, 'pbs': 7000, 'nbs': 1000}. Best is trial 5 with value: 0.022214973653203376.\n",
      "Trial 5 finished with value: 0.022214973653203376 and parameters: {'lr': 6.347747910478959, 'pbs': 7000, 'nbs': 1000}. Best is trial 5 with value: 0.022214973653203376.\n",
      "Trial 5 finished with value: 0.022214973653203376 and parameters: {'lr': 6.347747910478959, 'pbs': 7000, 'nbs': 1000}. Best is trial 5 with value: 0.022214973653203376.\n",
      "Trial 5 finished with value: 0.022214973653203376 and parameters: {'lr': 6.347747910478959, 'pbs': 7000, 'nbs': 1000}. Best is trial 5 with value: 0.022214973653203376.\n",
      "Trial 5 finished with value: 0.022214973653203376 and parameters: {'lr': 6.347747910478959, 'pbs': 7000, 'nbs': 1000}. Best is trial 5 with value: 0.022214973653203376.\n",
      "Trial 5 finished with value: 0.022214973653203376 and parameters: {'lr': 6.347747910478959, 'pbs': 7000, 'nbs': 1000}. Best is trial 5 with value: 0.022214973653203376.\n",
      "Epoch: 1\tFidelity = 0.916423\tKL_Divergence = 0.037485\n",
      "Epoch: 2\tFidelity = 0.924722\tKL_Divergence = 0.029593\n",
      "Epoch: 3\tFidelity = 0.928503\tKL_Divergence = 0.027483\n",
      "Epoch: 4\tFidelity = 0.938463\tKL_Divergence = 0.023480\n",
      "Epoch: 5\tFidelity = 0.921091\tKL_Divergence = 0.029550\n",
      "Epoch: 6\tFidelity = 0.936107\tKL_Divergence = 0.022987\n",
      "Epoch: 7\tFidelity = 0.924666\tKL_Divergence = 0.034960\n",
      "Epoch: 8\tFidelity = 0.912287\tKL_Divergence = 0.047651\n",
      "Epoch: 9\tFidelity = 0.905869\tKL_Divergence = 0.036831\n",
      "Epoch: 10\tFidelity = 0.929131\tKL_Divergence = 0.032638\n",
      "Epoch: 11\tFidelity = 0.934619\tKL_Divergence = 0.028160\n",
      "Epoch: 12\tFidelity = 0.935389\tKL_Divergence = 0.033358\n",
      "Epoch: 13\tFidelity = 0.929301\tKL_Divergence = 0.027710\n",
      "Epoch: 14\tFidelity = 0.926141\tKL_Divergence = 0.036074\n",
      "Epoch: 15\tFidelity = 0.938364\tKL_Divergence = 0.024667\n",
      "Epoch: 16\tFidelity = 0.926985\tKL_Divergence = 0.039597\n",
      "Epoch: 17\tFidelity = 0.934489\tKL_Divergence = 0.025394\n",
      "Epoch: 18\tFidelity = 0.922011\tKL_Divergence = 0.042663\n",
      "Epoch: 19\tFidelity = 0.932752\tKL_Divergence = 0.024246\n",
      "Epoch: 20\tFidelity = 0.932537\tKL_Divergence = 0.024170\n",
      "Epoch: 21\tFidelity = 0.930946\tKL_Divergence = 0.031350\n",
      "Epoch: 22\tFidelity = 0.932775\tKL_Divergence = 0.035060\n",
      "Epoch: 23\tFidelity = 0.926851\tKL_Divergence = 0.030018\n",
      "Epoch: 24\tFidelity = 0.936788\tKL_Divergence = 0.026572\n",
      "Epoch: 25\tFidelity = 0.928310\tKL_Divergence = 0.036403\n",
      "Epoch: 26\tFidelity = 0.924473\tKL_Divergence = 0.030702\n",
      "Epoch: 27\tFidelity = 0.935280\tKL_Divergence = 0.023413\n",
      "Epoch: 28\tFidelity = 0.905438\tKL_Divergence = 0.050561\n",
      "Epoch: 29\tFidelity = 0.923954\tKL_Divergence = 0.045016\n",
      "Epoch: 30\tFidelity = 0.935577\tKL_Divergence = 0.026562\n",
      "Epoch: 31\tFidelity = 0.940749\tKL_Divergence = 0.023416\n",
      "Epoch: 32\tFidelity = 0.924852\tKL_Divergence = 0.028040\n",
      "Epoch: 33\tFidelity = 0.936858\tKL_Divergence = 0.023200\n",
      "Epoch: 34\tFidelity = 0.917020\tKL_Divergence = 0.042532\n",
      "Epoch: 35\tFidelity = 0.939040\tKL_Divergence = 0.023103\n",
      "Epoch: 36\tFidelity = 0.936988\tKL_Divergence = 0.022672\n",
      "Epoch: 37\tFidelity = 0.933986\tKL_Divergence = 0.025585\n",
      "Epoch: 38\tFidelity = 0.930262\tKL_Divergence = 0.033954\n",
      "Epoch: 39\tFidelity = 0.935112\tKL_Divergence = 0.024308\n",
      "Epoch: 40\tFidelity = 0.923585\tKL_Divergence = 0.041976\n",
      "Epoch: 41\tFidelity = 0.917618\tKL_Divergence = 0.048823\n",
      "Epoch: 42\tFidelity = 0.935597\tKL_Divergence = 0.023952\n",
      "Epoch: 43\tFidelity = 0.935748\tKL_Divergence = 0.025536\n",
      "Epoch: 44\tFidelity = 0.939112\tKL_Divergence = 0.021673\n",
      "Epoch: 45\tFidelity = 0.925593\tKL_Divergence = 0.040762\n",
      "Epoch: 46\tFidelity = 0.928931\tKL_Divergence = 0.030573\n",
      "Epoch: 47\tFidelity = 0.908565\tKL_Divergence = 0.053881\n",
      "Epoch: 48\tFidelity = 0.927580\tKL_Divergence = 0.034442\n",
      "Epoch: 49\tFidelity = 0.918870\tKL_Divergence = 0.037602\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:28:37,954] Trial 6 finished with value: 0.02443990826142394 and parameters: {'lr': 13.587436691301798, 'pbs': 6000, 'nbs': 10000}. Best is trial 5 with value: 0.022214973653203376.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.939844\tKL_Divergence = 0.024440\n",
      "Total time elapsed during training: 342.359 s\n",
      "Trial 6 finished with value: 0.02443990826142394 and parameters: {'lr': 13.587436691301798, 'pbs': 6000, 'nbs': 10000}. Best is trial 5 with value: 0.022214973653203376.\n",
      "Trial 6 finished with value: 0.02443990826142394 and parameters: {'lr': 13.587436691301798, 'pbs': 6000, 'nbs': 10000}. Best is trial 5 with value: 0.022214973653203376.\n",
      "Trial 6 finished with value: 0.02443990826142394 and parameters: {'lr': 13.587436691301798, 'pbs': 6000, 'nbs': 10000}. Best is trial 5 with value: 0.022214973653203376.\n",
      "Trial 6 finished with value: 0.02443990826142394 and parameters: {'lr': 13.587436691301798, 'pbs': 6000, 'nbs': 10000}. Best is trial 5 with value: 0.022214973653203376.\n",
      "Trial 6 finished with value: 0.02443990826142394 and parameters: {'lr': 13.587436691301798, 'pbs': 6000, 'nbs': 10000}. Best is trial 5 with value: 0.022214973653203376.\n",
      "Trial 6 finished with value: 0.02443990826142394 and parameters: {'lr': 13.587436691301798, 'pbs': 6000, 'nbs': 10000}. Best is trial 5 with value: 0.022214973653203376.\n",
      "Epoch: 1\tFidelity = 0.939825\tKL_Divergence = 0.022070\n",
      "Epoch: 2\tFidelity = 0.937825\tKL_Divergence = 0.022639\n",
      "Epoch: 3\tFidelity = 0.934982\tKL_Divergence = 0.025128\n",
      "Epoch: 4\tFidelity = 0.937417\tKL_Divergence = 0.023178\n",
      "Epoch: 5\tFidelity = 0.936201\tKL_Divergence = 0.022740\n",
      "Epoch: 6\tFidelity = 0.935710\tKL_Divergence = 0.023122\n",
      "Epoch: 7\tFidelity = 0.937687\tKL_Divergence = 0.022018\n",
      "Epoch: 8\tFidelity = 0.935415\tKL_Divergence = 0.023761\n",
      "Epoch: 9\tFidelity = 0.936384\tKL_Divergence = 0.023581\n",
      "Epoch: 10\tFidelity = 0.937556\tKL_Divergence = 0.021681\n",
      "Epoch: 11\tFidelity = 0.934951\tKL_Divergence = 0.022746\n",
      "Epoch: 12\tFidelity = 0.935583\tKL_Divergence = 0.022728\n",
      "Epoch: 13\tFidelity = 0.933093\tKL_Divergence = 0.025991\n",
      "Epoch: 14\tFidelity = 0.936250\tKL_Divergence = 0.022172\n",
      "Epoch: 15\tFidelity = 0.934210\tKL_Divergence = 0.022936\n",
      "Epoch: 16\tFidelity = 0.931813\tKL_Divergence = 0.025994\n",
      "Epoch: 17\tFidelity = 0.935111\tKL_Divergence = 0.022387\n",
      "Epoch: 18\tFidelity = 0.933766\tKL_Divergence = 0.023037\n",
      "Epoch: 19\tFidelity = 0.935200\tKL_Divergence = 0.023387\n",
      "Epoch: 20\tFidelity = 0.932814\tKL_Divergence = 0.023427\n",
      "Epoch: 21\tFidelity = 0.932519\tKL_Divergence = 0.025100\n",
      "Epoch: 22\tFidelity = 0.935139\tKL_Divergence = 0.022304\n",
      "Epoch: 23\tFidelity = 0.932449\tKL_Divergence = 0.024678\n",
      "Epoch: 24\tFidelity = 0.935241\tKL_Divergence = 0.022411\n",
      "Epoch: 25\tFidelity = 0.935930\tKL_Divergence = 0.021740\n",
      "Epoch: 26\tFidelity = 0.934060\tKL_Divergence = 0.022487\n",
      "Epoch: 27\tFidelity = 0.935088\tKL_Divergence = 0.022612\n",
      "Epoch: 28\tFidelity = 0.934616\tKL_Divergence = 0.022365\n",
      "Epoch: 29\tFidelity = 0.932814\tKL_Divergence = 0.024373\n",
      "Epoch: 30\tFidelity = 0.932096\tKL_Divergence = 0.025689\n",
      "Epoch: 31\tFidelity = 0.929645\tKL_Divergence = 0.027843\n",
      "Epoch: 32\tFidelity = 0.934716\tKL_Divergence = 0.022551\n",
      "Epoch: 33\tFidelity = 0.932955\tKL_Divergence = 0.024275\n",
      "Epoch: 34\tFidelity = 0.931966\tKL_Divergence = 0.024289\n",
      "Epoch: 35\tFidelity = 0.934052\tKL_Divergence = 0.023004\n",
      "Epoch: 36\tFidelity = 0.934936\tKL_Divergence = 0.023269\n",
      "Epoch: 37\tFidelity = 0.935814\tKL_Divergence = 0.022187\n",
      "Epoch: 38\tFidelity = 0.935211\tKL_Divergence = 0.022023\n",
      "Epoch: 39\tFidelity = 0.936375\tKL_Divergence = 0.021584\n",
      "Epoch: 40\tFidelity = 0.934408\tKL_Divergence = 0.022260\n",
      "Epoch: 41\tFidelity = 0.930672\tKL_Divergence = 0.027322\n",
      "Epoch: 42\tFidelity = 0.933810\tKL_Divergence = 0.023541\n",
      "Epoch: 43\tFidelity = 0.935774\tKL_Divergence = 0.022892\n",
      "Epoch: 44\tFidelity = 0.935780\tKL_Divergence = 0.021644\n",
      "Epoch: 45\tFidelity = 0.936217\tKL_Divergence = 0.021894\n",
      "Epoch: 46\tFidelity = 0.934469\tKL_Divergence = 0.024675\n",
      "Epoch: 47\tFidelity = 0.935127\tKL_Divergence = 0.022000\n",
      "Epoch: 48\tFidelity = 0.933049\tKL_Divergence = 0.023901\n",
      "Epoch: 49\tFidelity = 0.935680\tKL_Divergence = 0.022086\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:34:22,340] Trial 7 finished with value: 0.023100893864101954 and parameters: {'lr': 5.266182338783335, 'pbs': 6000, 'nbs': 7000}. Best is trial 5 with value: 0.022214973653203376.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.933988\tKL_Divergence = 0.023101\n",
      "Total time elapsed during training: 344.027 s\n",
      "Trial 7 finished with value: 0.023100893864101954 and parameters: {'lr': 5.266182338783335, 'pbs': 6000, 'nbs': 7000}. Best is trial 5 with value: 0.022214973653203376.\n",
      "Trial 7 finished with value: 0.023100893864101954 and parameters: {'lr': 5.266182338783335, 'pbs': 6000, 'nbs': 7000}. Best is trial 5 with value: 0.022214973653203376.\n",
      "Trial 7 finished with value: 0.023100893864101954 and parameters: {'lr': 5.266182338783335, 'pbs': 6000, 'nbs': 7000}. Best is trial 5 with value: 0.022214973653203376.\n",
      "Trial 7 finished with value: 0.023100893864101954 and parameters: {'lr': 5.266182338783335, 'pbs': 6000, 'nbs': 7000}. Best is trial 5 with value: 0.022214973653203376.\n",
      "Trial 7 finished with value: 0.023100893864101954 and parameters: {'lr': 5.266182338783335, 'pbs': 6000, 'nbs': 7000}. Best is trial 5 with value: 0.022214973653203376.\n",
      "Trial 7 finished with value: 0.023100893864101954 and parameters: {'lr': 5.266182338783335, 'pbs': 6000, 'nbs': 7000}. Best is trial 5 with value: 0.022214973653203376.\n",
      "Epoch: 1\tFidelity = 0.928253\tKL_Divergence = 0.028029\n",
      "Epoch: 2\tFidelity = 0.936536\tKL_Divergence = 0.022579\n",
      "Epoch: 3\tFidelity = 0.922769\tKL_Divergence = 0.028616\n",
      "Epoch: 4\tFidelity = 0.921058\tKL_Divergence = 0.031314\n",
      "Epoch: 5\tFidelity = 0.922731\tKL_Divergence = 0.030763\n",
      "Epoch: 6\tFidelity = 0.927940\tKL_Divergence = 0.028527\n",
      "Epoch: 7\tFidelity = 0.929683\tKL_Divergence = 0.025439\n",
      "Epoch: 8\tFidelity = 0.933907\tKL_Divergence = 0.025529\n",
      "Epoch: 9\tFidelity = 0.921678\tKL_Divergence = 0.036106\n",
      "Epoch: 10\tFidelity = 0.933205\tKL_Divergence = 0.031795\n",
      "Epoch: 11\tFidelity = 0.928229\tKL_Divergence = 0.032284\n",
      "Epoch: 12\tFidelity = 0.936325\tKL_Divergence = 0.025610\n",
      "Epoch: 13\tFidelity = 0.933284\tKL_Divergence = 0.026119\n",
      "Epoch: 14\tFidelity = 0.934786\tKL_Divergence = 0.026354\n",
      "Epoch: 15\tFidelity = 0.929614\tKL_Divergence = 0.025626\n",
      "Epoch: 16\tFidelity = 0.936120\tKL_Divergence = 0.022558\n",
      "Epoch: 17\tFidelity = 0.937117\tKL_Divergence = 0.022435\n",
      "Epoch: 18\tFidelity = 0.936891\tKL_Divergence = 0.023112\n",
      "Epoch: 19\tFidelity = 0.934838\tKL_Divergence = 0.027872\n",
      "Epoch: 20\tFidelity = 0.931365\tKL_Divergence = 0.024391\n",
      "Epoch: 21\tFidelity = 0.928465\tKL_Divergence = 0.027736\n",
      "Epoch: 22\tFidelity = 0.935084\tKL_Divergence = 0.023307\n",
      "Epoch: 23\tFidelity = 0.933329\tKL_Divergence = 0.023604\n",
      "Epoch: 24\tFidelity = 0.936773\tKL_Divergence = 0.021936\n",
      "Epoch: 25\tFidelity = 0.933337\tKL_Divergence = 0.024221\n",
      "Epoch: 26\tFidelity = 0.933742\tKL_Divergence = 0.023087\n",
      "Epoch: 27\tFidelity = 0.935490\tKL_Divergence = 0.022534\n",
      "Epoch: 28\tFidelity = 0.934372\tKL_Divergence = 0.023234\n",
      "Epoch: 29\tFidelity = 0.935166\tKL_Divergence = 0.023262\n",
      "Epoch: 30\tFidelity = 0.928289\tKL_Divergence = 0.026599\n",
      "Epoch: 31\tFidelity = 0.929734\tKL_Divergence = 0.025184\n",
      "Epoch: 32\tFidelity = 0.918902\tKL_Divergence = 0.030597\n",
      "Epoch: 33\tFidelity = 0.929309\tKL_Divergence = 0.025637\n",
      "Epoch: 34\tFidelity = 0.935305\tKL_Divergence = 0.023559\n",
      "Epoch: 35\tFidelity = 0.930012\tKL_Divergence = 0.029774\n",
      "Epoch: 36\tFidelity = 0.929313\tKL_Divergence = 0.029137\n",
      "Epoch: 37\tFidelity = 0.938034\tKL_Divergence = 0.024508\n",
      "Epoch: 38\tFidelity = 0.937035\tKL_Divergence = 0.022667\n",
      "Epoch: 39\tFidelity = 0.936362\tKL_Divergence = 0.022621\n",
      "Epoch: 40\tFidelity = 0.931785\tKL_Divergence = 0.027960\n",
      "Epoch: 41\tFidelity = 0.930157\tKL_Divergence = 0.037612\n",
      "Epoch: 42\tFidelity = 0.931520\tKL_Divergence = 0.029471\n",
      "Epoch: 43\tFidelity = 0.930797\tKL_Divergence = 0.026731\n",
      "Epoch: 44\tFidelity = 0.937147\tKL_Divergence = 0.022867\n",
      "Epoch: 45\tFidelity = 0.933244\tKL_Divergence = 0.024746\n",
      "Epoch: 46\tFidelity = 0.932309\tKL_Divergence = 0.024133\n",
      "Epoch: 47\tFidelity = 0.929544\tKL_Divergence = 0.027625\n",
      "Epoch: 48\tFidelity = 0.933433\tKL_Divergence = 0.024903\n",
      "Epoch: 49\tFidelity = 0.934807\tKL_Divergence = 0.023365\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:39:27,507] Trial 8 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.925841\tKL_Divergence = 0.029712\n",
      "Total time elapsed during training: 304.843 s\n",
      "Trial 8 pruned. \n",
      "Trial 8 pruned. \n",
      "Trial 8 pruned. \n",
      "Trial 8 pruned. \n",
      "Trial 8 pruned. \n",
      "Trial 8 pruned. \n",
      "Epoch: 1\tFidelity = 0.929413\tKL_Divergence = 0.032539\n",
      "Epoch: 2\tFidelity = 0.930412\tKL_Divergence = 0.037425\n",
      "Epoch: 3\tFidelity = 0.928144\tKL_Divergence = 0.026338\n",
      "Epoch: 4\tFidelity = 0.925833\tKL_Divergence = 0.027107\n",
      "Epoch: 5\tFidelity = 0.931782\tKL_Divergence = 0.024762\n",
      "Epoch: 6\tFidelity = 0.928338\tKL_Divergence = 0.034691\n",
      "Epoch: 7\tFidelity = 0.934924\tKL_Divergence = 0.032719\n",
      "Epoch: 8\tFidelity = 0.938594\tKL_Divergence = 0.022030\n",
      "Epoch: 9\tFidelity = 0.934411\tKL_Divergence = 0.024117\n",
      "Epoch: 10\tFidelity = 0.928605\tKL_Divergence = 0.027053\n",
      "Epoch: 11\tFidelity = 0.934813\tKL_Divergence = 0.024799\n",
      "Epoch: 12\tFidelity = 0.925004\tKL_Divergence = 0.035814\n",
      "Epoch: 13\tFidelity = 0.928640\tKL_Divergence = 0.025617\n",
      "Epoch: 14\tFidelity = 0.918108\tKL_Divergence = 0.032073\n",
      "Epoch: 15\tFidelity = 0.932768\tKL_Divergence = 0.028862\n",
      "Epoch: 16\tFidelity = 0.929228\tKL_Divergence = 0.030026\n",
      "Epoch: 17\tFidelity = 0.923421\tKL_Divergence = 0.039321\n",
      "Epoch: 18\tFidelity = 0.924819\tKL_Divergence = 0.027844\n",
      "Epoch: 19\tFidelity = 0.933291\tKL_Divergence = 0.023301\n",
      "Epoch: 20\tFidelity = 0.920579\tKL_Divergence = 0.029177\n",
      "Epoch: 21\tFidelity = 0.931825\tKL_Divergence = 0.025728\n",
      "Epoch: 22\tFidelity = 0.937074\tKL_Divergence = 0.023898\n",
      "Epoch: 23\tFidelity = 0.924866\tKL_Divergence = 0.036806\n",
      "Epoch: 24\tFidelity = 0.921835\tKL_Divergence = 0.041461\n",
      "Epoch: 25\tFidelity = 0.917061\tKL_Divergence = 0.046784\n",
      "Epoch: 26\tFidelity = 0.935453\tKL_Divergence = 0.022425\n",
      "Epoch: 27\tFidelity = 0.929096\tKL_Divergence = 0.028014\n",
      "Epoch: 28\tFidelity = 0.935792\tKL_Divergence = 0.023900\n",
      "Epoch: 29\tFidelity = 0.934835\tKL_Divergence = 0.023144\n",
      "Epoch: 30\tFidelity = 0.935643\tKL_Divergence = 0.028434\n",
      "Epoch: 31\tFidelity = 0.931829\tKL_Divergence = 0.026374\n",
      "Epoch: 32\tFidelity = 0.933465\tKL_Divergence = 0.023573\n",
      "Epoch: 33\tFidelity = 0.926783\tKL_Divergence = 0.030615\n",
      "Epoch: 34\tFidelity = 0.920898\tKL_Divergence = 0.033696\n",
      "Epoch: 35\tFidelity = 0.936909\tKL_Divergence = 0.021972\n",
      "Epoch: 36\tFidelity = 0.935885\tKL_Divergence = 0.022684\n",
      "Epoch: 37\tFidelity = 0.936879\tKL_Divergence = 0.022613\n",
      "Epoch: 38\tFidelity = 0.938180\tKL_Divergence = 0.021840\n",
      "Epoch: 39\tFidelity = 0.930684\tKL_Divergence = 0.025142\n",
      "Epoch: 40\tFidelity = 0.931578\tKL_Divergence = 0.027515\n",
      "Epoch: 41\tFidelity = 0.931202\tKL_Divergence = 0.033448\n",
      "Epoch: 42\tFidelity = 0.928634\tKL_Divergence = 0.029429\n",
      "Epoch: 43\tFidelity = 0.932661\tKL_Divergence = 0.027786\n",
      "Epoch: 44\tFidelity = 0.934260\tKL_Divergence = 0.024299\n",
      "Epoch: 45\tFidelity = 0.922668\tKL_Divergence = 0.028552\n",
      "Epoch: 46\tFidelity = 0.936584\tKL_Divergence = 0.029604\n",
      "Epoch: 47\tFidelity = 0.914002\tKL_Divergence = 0.040925\n",
      "Epoch: 48\tFidelity = 0.931603\tKL_Divergence = 0.030048\n",
      "Epoch: 49\tFidelity = 0.934622\tKL_Divergence = 0.024011\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:47:43,601] Trial 9 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.924088\tKL_Divergence = 0.038423\n",
      "Total time elapsed during training: 495.715 s\n",
      "Trial 9 pruned. \n",
      "Trial 9 pruned. \n",
      "Trial 9 pruned. \n",
      "Trial 9 pruned. \n",
      "Trial 9 pruned. \n",
      "Trial 9 pruned. \n",
      "Epoch: 1\tFidelity = 0.936223\tKL_Divergence = 0.023553\n",
      "Epoch: 2\tFidelity = 0.936608\tKL_Divergence = 0.022537\n",
      "Epoch: 3\tFidelity = 0.935272\tKL_Divergence = 0.022746\n",
      "Epoch: 4\tFidelity = 0.934686\tKL_Divergence = 0.022958\n",
      "Epoch: 5\tFidelity = 0.933948\tKL_Divergence = 0.023178\n",
      "Epoch: 6\tFidelity = 0.934003\tKL_Divergence = 0.023150\n",
      "Epoch: 7\tFidelity = 0.933452\tKL_Divergence = 0.023258\n",
      "Epoch: 8\tFidelity = 0.932823\tKL_Divergence = 0.027592\n",
      "Epoch: 9\tFidelity = 0.932038\tKL_Divergence = 0.025753\n",
      "Epoch: 10\tFidelity = 0.933566\tKL_Divergence = 0.025497\n",
      "Epoch: 11\tFidelity = 0.936057\tKL_Divergence = 0.022391\n",
      "Epoch: 12\tFidelity = 0.935292\tKL_Divergence = 0.024838\n",
      "Epoch: 13\tFidelity = 0.936766\tKL_Divergence = 0.022813\n",
      "Epoch: 14\tFidelity = 0.934176\tKL_Divergence = 0.023547\n",
      "Epoch: 15\tFidelity = 0.930436\tKL_Divergence = 0.026552\n",
      "Epoch: 16\tFidelity = 0.935285\tKL_Divergence = 0.023357\n",
      "Epoch: 17\tFidelity = 0.934986\tKL_Divergence = 0.022671\n",
      "Epoch: 18\tFidelity = 0.933881\tKL_Divergence = 0.023213\n",
      "Epoch: 19\tFidelity = 0.932718\tKL_Divergence = 0.023638\n",
      "Epoch: 20\tFidelity = 0.932800\tKL_Divergence = 0.023873\n",
      "Epoch: 21\tFidelity = 0.932452\tKL_Divergence = 0.027179\n",
      "Epoch: 22\tFidelity = 0.933278\tKL_Divergence = 0.023914\n",
      "Epoch: 23\tFidelity = 0.932101\tKL_Divergence = 0.023961\n",
      "Epoch: 24\tFidelity = 0.935309\tKL_Divergence = 0.022795\n",
      "Epoch: 25\tFidelity = 0.932531\tKL_Divergence = 0.032055\n",
      "Epoch: 26\tFidelity = 0.937295\tKL_Divergence = 0.021570\n",
      "Epoch: 27\tFidelity = 0.933608\tKL_Divergence = 0.023904\n",
      "Epoch: 28\tFidelity = 0.932288\tKL_Divergence = 0.026025\n",
      "Epoch: 29\tFidelity = 0.933815\tKL_Divergence = 0.024329\n",
      "Epoch: 30\tFidelity = 0.935925\tKL_Divergence = 0.022969\n",
      "Epoch: 31\tFidelity = 0.937973\tKL_Divergence = 0.021154\n",
      "Epoch: 32\tFidelity = 0.936332\tKL_Divergence = 0.021893\n",
      "Epoch: 33\tFidelity = 0.936242\tKL_Divergence = 0.022079\n",
      "Epoch: 34\tFidelity = 0.932771\tKL_Divergence = 0.024107\n",
      "Epoch: 35\tFidelity = 0.935827\tKL_Divergence = 0.022168\n",
      "Epoch: 36\tFidelity = 0.932258\tKL_Divergence = 0.027375\n",
      "Epoch: 37\tFidelity = 0.935469\tKL_Divergence = 0.023296\n",
      "Epoch: 38\tFidelity = 0.935827\tKL_Divergence = 0.023440\n",
      "Epoch: 39\tFidelity = 0.936701\tKL_Divergence = 0.023309\n",
      "Epoch: 40\tFidelity = 0.934632\tKL_Divergence = 0.028321\n",
      "Epoch: 41\tFidelity = 0.935200\tKL_Divergence = 0.022790\n",
      "Epoch: 42\tFidelity = 0.936164\tKL_Divergence = 0.022212\n",
      "Epoch: 43\tFidelity = 0.936321\tKL_Divergence = 0.021852\n",
      "Epoch: 44\tFidelity = 0.936094\tKL_Divergence = 0.022138\n",
      "Epoch: 45\tFidelity = 0.929463\tKL_Divergence = 0.030059\n",
      "Epoch: 46\tFidelity = 0.939081\tKL_Divergence = 0.020760\n",
      "Epoch: 47\tFidelity = 0.936817\tKL_Divergence = 0.021790\n",
      "Epoch: 48\tFidelity = 0.936823\tKL_Divergence = 0.021676\n",
      "Epoch: 49\tFidelity = 0.937305\tKL_Divergence = 0.022233\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:53:13,212] Trial 10 finished with value: 0.022073338087463618 and parameters: {'lr': 5.252511136920952, 'pbs': 7000, 'nbs': 1000}. Best is trial 10 with value: 0.022073338087463618.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.936060\tKL_Divergence = 0.022073\n",
      "Total time elapsed during training: 329.220 s\n",
      "Trial 10 finished with value: 0.022073338087463618 and parameters: {'lr': 5.252511136920952, 'pbs': 7000, 'nbs': 1000}. Best is trial 10 with value: 0.022073338087463618.\n",
      "Trial 10 finished with value: 0.022073338087463618 and parameters: {'lr': 5.252511136920952, 'pbs': 7000, 'nbs': 1000}. Best is trial 10 with value: 0.022073338087463618.\n",
      "Trial 10 finished with value: 0.022073338087463618 and parameters: {'lr': 5.252511136920952, 'pbs': 7000, 'nbs': 1000}. Best is trial 10 with value: 0.022073338087463618.\n",
      "Trial 10 finished with value: 0.022073338087463618 and parameters: {'lr': 5.252511136920952, 'pbs': 7000, 'nbs': 1000}. Best is trial 10 with value: 0.022073338087463618.\n",
      "Trial 10 finished with value: 0.022073338087463618 and parameters: {'lr': 5.252511136920952, 'pbs': 7000, 'nbs': 1000}. Best is trial 10 with value: 0.022073338087463618.\n",
      "Trial 10 finished with value: 0.022073338087463618 and parameters: {'lr': 5.252511136920952, 'pbs': 7000, 'nbs': 1000}. Best is trial 10 with value: 0.022073338087463618.\n",
      "Epoch: 1\tFidelity = 0.934840\tKL_Divergence = 0.022776\n",
      "Epoch: 2\tFidelity = 0.936770\tKL_Divergence = 0.021639\n",
      "Epoch: 3\tFidelity = 0.936751\tKL_Divergence = 0.021695\n",
      "Epoch: 4\tFidelity = 0.934593\tKL_Divergence = 0.024590\n",
      "Epoch: 5\tFidelity = 0.938252\tKL_Divergence = 0.021124\n",
      "Epoch: 6\tFidelity = 0.937532\tKL_Divergence = 0.021554\n",
      "Epoch: 7\tFidelity = 0.937229\tKL_Divergence = 0.022018\n",
      "Epoch: 8\tFidelity = 0.937116\tKL_Divergence = 0.021580\n",
      "Epoch: 9\tFidelity = 0.931581\tKL_Divergence = 0.028124\n",
      "Epoch: 10\tFidelity = 0.934014\tKL_Divergence = 0.023215\n",
      "Epoch: 11\tFidelity = 0.933967\tKL_Divergence = 0.022769\n",
      "Epoch: 12\tFidelity = 0.933738\tKL_Divergence = 0.023515\n",
      "Epoch: 13\tFidelity = 0.927930\tKL_Divergence = 0.032175\n",
      "Epoch: 14\tFidelity = 0.933265\tKL_Divergence = 0.023453\n",
      "Epoch: 15\tFidelity = 0.934316\tKL_Divergence = 0.022910\n",
      "Epoch: 16\tFidelity = 0.934926\tKL_Divergence = 0.022544\n",
      "Epoch: 17\tFidelity = 0.935905\tKL_Divergence = 0.022082\n",
      "Epoch: 18\tFidelity = 0.929774\tKL_Divergence = 0.030615\n",
      "Epoch: 19\tFidelity = 0.936371\tKL_Divergence = 0.022004\n",
      "Epoch: 20\tFidelity = 0.934807\tKL_Divergence = 0.024500\n",
      "Epoch: 21\tFidelity = 0.934162\tKL_Divergence = 0.023030\n",
      "Epoch: 22\tFidelity = 0.933965\tKL_Divergence = 0.025149\n",
      "Epoch: 23\tFidelity = 0.937384\tKL_Divergence = 0.022148\n",
      "Epoch: 24\tFidelity = 0.935984\tKL_Divergence = 0.022792\n",
      "Epoch: 25\tFidelity = 0.935152\tKL_Divergence = 0.022472\n",
      "Epoch: 26\tFidelity = 0.934303\tKL_Divergence = 0.023789\n",
      "Epoch: 27\tFidelity = 0.934996\tKL_Divergence = 0.022698\n",
      "Epoch: 28\tFidelity = 0.932471\tKL_Divergence = 0.023874\n",
      "Epoch: 29\tFidelity = 0.930193\tKL_Divergence = 0.025040\n",
      "Epoch: 30\tFidelity = 0.930997\tKL_Divergence = 0.024603\n",
      "Epoch: 31\tFidelity = 0.933099\tKL_Divergence = 0.025195\n",
      "Epoch: 32\tFidelity = 0.933327\tKL_Divergence = 0.023336\n",
      "Epoch: 33\tFidelity = 0.931082\tKL_Divergence = 0.026165\n",
      "Epoch: 34\tFidelity = 0.933061\tKL_Divergence = 0.023452\n",
      "Epoch: 35\tFidelity = 0.934137\tKL_Divergence = 0.023785\n",
      "Epoch: 36\tFidelity = 0.933911\tKL_Divergence = 0.023015\n",
      "Epoch: 37\tFidelity = 0.930326\tKL_Divergence = 0.027107\n",
      "Epoch: 38\tFidelity = 0.930828\tKL_Divergence = 0.026009\n",
      "Epoch: 39\tFidelity = 0.930909\tKL_Divergence = 0.025596\n",
      "Epoch: 40\tFidelity = 0.933411\tKL_Divergence = 0.023642\n",
      "Epoch: 41\tFidelity = 0.931899\tKL_Divergence = 0.026892\n",
      "Epoch: 42\tFidelity = 0.934887\tKL_Divergence = 0.023848\n",
      "Epoch: 43\tFidelity = 0.936660\tKL_Divergence = 0.022026\n",
      "Epoch: 44\tFidelity = 0.929639\tKL_Divergence = 0.026571\n",
      "Epoch: 45\tFidelity = 0.933531\tKL_Divergence = 0.024297\n",
      "Epoch: 46\tFidelity = 0.935356\tKL_Divergence = 0.023007\n",
      "Epoch: 47\tFidelity = 0.935321\tKL_Divergence = 0.022838\n",
      "Epoch: 48\tFidelity = 0.933646\tKL_Divergence = 0.023025\n",
      "Epoch: 49\tFidelity = 0.932259\tKL_Divergence = 0.026365\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:58:39,973] Trial 11 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.931412\tKL_Divergence = 0.024339\n",
      "Total time elapsed during training: 326.413 s\n",
      "Trial 11 pruned. \n",
      "Trial 11 pruned. \n",
      "Trial 11 pruned. \n",
      "Trial 11 pruned. \n",
      "Trial 11 pruned. \n",
      "Trial 11 pruned. \n",
      "Epoch: 1\tFidelity = 0.929163\tKL_Divergence = 0.025172\n",
      "Epoch: 2\tFidelity = 0.933808\tKL_Divergence = 0.026102\n",
      "Epoch: 3\tFidelity = 0.933980\tKL_Divergence = 0.023742\n",
      "Epoch: 4\tFidelity = 0.925639\tKL_Divergence = 0.033041\n",
      "Epoch: 5\tFidelity = 0.934865\tKL_Divergence = 0.022615\n",
      "Epoch: 6\tFidelity = 0.932412\tKL_Divergence = 0.023675\n",
      "Epoch: 7\tFidelity = 0.934569\tKL_Divergence = 0.022820\n",
      "Epoch: 8\tFidelity = 0.933922\tKL_Divergence = 0.023228\n",
      "Epoch: 9\tFidelity = 0.932687\tKL_Divergence = 0.025281\n",
      "Epoch: 10\tFidelity = 0.933741\tKL_Divergence = 0.023367\n",
      "Epoch: 11\tFidelity = 0.933752\tKL_Divergence = 0.023987\n",
      "Epoch: 12\tFidelity = 0.932892\tKL_Divergence = 0.024014\n",
      "Epoch: 13\tFidelity = 0.931975\tKL_Divergence = 0.028233\n",
      "Epoch: 14\tFidelity = 0.932656\tKL_Divergence = 0.027120\n",
      "Epoch: 15\tFidelity = 0.936229\tKL_Divergence = 0.022416\n",
      "Epoch: 16\tFidelity = 0.933876\tKL_Divergence = 0.024010\n",
      "Epoch: 17\tFidelity = 0.937227\tKL_Divergence = 0.021778\n",
      "Epoch: 18\tFidelity = 0.937757\tKL_Divergence = 0.021431\n",
      "Epoch: 19\tFidelity = 0.933340\tKL_Divergence = 0.026254\n",
      "Epoch: 20\tFidelity = 0.937218\tKL_Divergence = 0.021673\n",
      "Epoch: 21\tFidelity = 0.934634\tKL_Divergence = 0.022919\n",
      "Epoch: 22\tFidelity = 0.936207\tKL_Divergence = 0.023960\n",
      "Epoch: 23\tFidelity = 0.935182\tKL_Divergence = 0.023072\n",
      "Epoch: 24\tFidelity = 0.934299\tKL_Divergence = 0.024739\n",
      "Epoch: 25\tFidelity = 0.936271\tKL_Divergence = 0.022380\n",
      "Epoch: 26\tFidelity = 0.933668\tKL_Divergence = 0.024749\n",
      "Epoch: 27\tFidelity = 0.936437\tKL_Divergence = 0.022672\n",
      "Epoch: 28\tFidelity = 0.937308\tKL_Divergence = 0.023481\n",
      "Epoch: 29\tFidelity = 0.937853\tKL_Divergence = 0.021482\n",
      "Epoch: 30\tFidelity = 0.936287\tKL_Divergence = 0.022372\n",
      "Epoch: 31\tFidelity = 0.936262\tKL_Divergence = 0.024137\n",
      "Epoch: 32\tFidelity = 0.936097\tKL_Divergence = 0.023476\n",
      "Epoch: 33\tFidelity = 0.934473\tKL_Divergence = 0.022778\n",
      "Epoch: 34\tFidelity = 0.930424\tKL_Divergence = 0.026867\n",
      "Epoch: 35\tFidelity = 0.922302\tKL_Divergence = 0.038067\n",
      "Epoch: 36\tFidelity = 0.935440\tKL_Divergence = 0.022578\n",
      "Epoch: 37\tFidelity = 0.933318\tKL_Divergence = 0.023288\n",
      "Epoch: 38\tFidelity = 0.931642\tKL_Divergence = 0.024465\n",
      "Epoch: 39\tFidelity = 0.935590\tKL_Divergence = 0.022673\n",
      "Epoch: 40\tFidelity = 0.930792\tKL_Divergence = 0.027528\n",
      "Epoch: 41\tFidelity = 0.929774\tKL_Divergence = 0.029837\n",
      "Epoch: 42\tFidelity = 0.935369\tKL_Divergence = 0.022874\n",
      "Epoch: 43\tFidelity = 0.932486\tKL_Divergence = 0.025202\n",
      "Epoch: 44\tFidelity = 0.936582\tKL_Divergence = 0.021910\n",
      "Epoch: 45\tFidelity = 0.934585\tKL_Divergence = 0.025526\n",
      "Epoch: 46\tFidelity = 0.935536\tKL_Divergence = 0.022546\n",
      "Epoch: 47\tFidelity = 0.934016\tKL_Divergence = 0.023242\n",
      "Epoch: 48\tFidelity = 0.935376\tKL_Divergence = 0.022988\n",
      "Epoch: 49\tFidelity = 0.931467\tKL_Divergence = 0.027108\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:04:03,324] Trial 12 finished with value: 0.022141725391492863 and parameters: {'lr': 6.517702062784943, 'pbs': 7000, 'nbs': 1000}. Best is trial 10 with value: 0.022073338087463618.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.937034\tKL_Divergence = 0.022142\n",
      "Total time elapsed during training: 323.015 s\n",
      "Trial 12 finished with value: 0.022141725391492863 and parameters: {'lr': 6.517702062784943, 'pbs': 7000, 'nbs': 1000}. Best is trial 10 with value: 0.022073338087463618.\n",
      "Trial 12 finished with value: 0.022141725391492863 and parameters: {'lr': 6.517702062784943, 'pbs': 7000, 'nbs': 1000}. Best is trial 10 with value: 0.022073338087463618.\n",
      "Trial 12 finished with value: 0.022141725391492863 and parameters: {'lr': 6.517702062784943, 'pbs': 7000, 'nbs': 1000}. Best is trial 10 with value: 0.022073338087463618.\n",
      "Trial 12 finished with value: 0.022141725391492863 and parameters: {'lr': 6.517702062784943, 'pbs': 7000, 'nbs': 1000}. Best is trial 10 with value: 0.022073338087463618.\n",
      "Trial 12 finished with value: 0.022141725391492863 and parameters: {'lr': 6.517702062784943, 'pbs': 7000, 'nbs': 1000}. Best is trial 10 with value: 0.022073338087463618.\n",
      "Trial 12 finished with value: 0.022141725391492863 and parameters: {'lr': 6.517702062784943, 'pbs': 7000, 'nbs': 1000}. Best is trial 10 with value: 0.022073338087463618.\n",
      "Epoch: 1\tFidelity = 0.936741\tKL_Divergence = 0.021949\n",
      "Epoch: 2\tFidelity = 0.935464\tKL_Divergence = 0.022226\n",
      "Epoch: 3\tFidelity = 0.937236\tKL_Divergence = 0.022276\n",
      "Epoch: 4\tFidelity = 0.936039\tKL_Divergence = 0.023862\n",
      "Epoch: 5\tFidelity = 0.935885\tKL_Divergence = 0.022310\n",
      "Epoch: 6\tFidelity = 0.933452\tKL_Divergence = 0.025823\n",
      "Epoch: 7\tFidelity = 0.934646\tKL_Divergence = 0.026373\n",
      "Epoch: 8\tFidelity = 0.935202\tKL_Divergence = 0.022361\n",
      "Epoch: 9\tFidelity = 0.930844\tKL_Divergence = 0.024237\n",
      "Epoch: 10\tFidelity = 0.929717\tKL_Divergence = 0.030111\n",
      "Epoch: 11\tFidelity = 0.935481\tKL_Divergence = 0.022259\n",
      "Epoch: 12\tFidelity = 0.933299\tKL_Divergence = 0.023155\n",
      "Epoch: 13\tFidelity = 0.936114\tKL_Divergence = 0.022040\n",
      "Epoch: 14\tFidelity = 0.933553\tKL_Divergence = 0.025274\n",
      "Epoch: 15\tFidelity = 0.934793\tKL_Divergence = 0.023555\n",
      "Epoch: 16\tFidelity = 0.929432\tKL_Divergence = 0.026338\n",
      "Epoch: 17\tFidelity = 0.931519\tKL_Divergence = 0.026870\n",
      "Epoch: 18\tFidelity = 0.935938\tKL_Divergence = 0.022169\n",
      "Epoch: 19\tFidelity = 0.930733\tKL_Divergence = 0.028851\n",
      "Epoch: 20\tFidelity = 0.936678\tKL_Divergence = 0.021683\n",
      "Epoch: 21\tFidelity = 0.934079\tKL_Divergence = 0.024294\n",
      "Epoch: 22\tFidelity = 0.935644\tKL_Divergence = 0.022424\n",
      "Epoch: 23\tFidelity = 0.935720\tKL_Divergence = 0.022412\n",
      "Epoch: 24\tFidelity = 0.934253\tKL_Divergence = 0.023347\n",
      "Epoch: 25\tFidelity = 0.935124\tKL_Divergence = 0.024049\n",
      "Epoch: 26\tFidelity = 0.935369\tKL_Divergence = 0.022993\n",
      "Epoch: 27\tFidelity = 0.931308\tKL_Divergence = 0.026503\n",
      "Epoch: 28\tFidelity = 0.936495\tKL_Divergence = 0.022192\n",
      "Epoch: 29\tFidelity = 0.927266\tKL_Divergence = 0.027516\n",
      "Epoch: 30\tFidelity = 0.933919\tKL_Divergence = 0.024736\n",
      "Epoch: 31\tFidelity = 0.935430\tKL_Divergence = 0.022436\n",
      "Epoch: 32\tFidelity = 0.934167\tKL_Divergence = 0.023556\n",
      "Epoch: 33\tFidelity = 0.935959\tKL_Divergence = 0.024326\n",
      "Epoch: 34\tFidelity = 0.933757\tKL_Divergence = 0.023500\n",
      "Epoch: 35\tFidelity = 0.936730\tKL_Divergence = 0.022855\n",
      "Epoch: 36\tFidelity = 0.936001\tKL_Divergence = 0.023902\n",
      "Epoch: 37\tFidelity = 0.937324\tKL_Divergence = 0.021773\n",
      "Epoch: 38\tFidelity = 0.934334\tKL_Divergence = 0.024254\n",
      "Epoch: 39\tFidelity = 0.936881\tKL_Divergence = 0.021518\n",
      "Epoch: 40\tFidelity = 0.934076\tKL_Divergence = 0.024105\n",
      "Epoch: 41\tFidelity = 0.935517\tKL_Divergence = 0.022126\n",
      "Epoch: 42\tFidelity = 0.936058\tKL_Divergence = 0.022630\n",
      "Epoch: 43\tFidelity = 0.933345\tKL_Divergence = 0.024981\n",
      "Epoch: 44\tFidelity = 0.934828\tKL_Divergence = 0.022455\n",
      "Epoch: 45\tFidelity = 0.927604\tKL_Divergence = 0.032480\n",
      "Epoch: 46\tFidelity = 0.935794\tKL_Divergence = 0.024685\n",
      "Epoch: 47\tFidelity = 0.935965\tKL_Divergence = 0.022201\n",
      "Epoch: 48\tFidelity = 0.933020\tKL_Divergence = 0.023888\n",
      "Epoch: 49\tFidelity = 0.934023\tKL_Divergence = 0.023281\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:09:30,639] Trial 13 finished with value: 0.021682285414175304 and parameters: {'lr': 6.549342730249502, 'pbs': 7000, 'nbs': 3000}. Best is trial 13 with value: 0.021682285414175304.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.937646\tKL_Divergence = 0.021682\n",
      "Total time elapsed during training: 326.995 s\n",
      "Trial 13 finished with value: 0.021682285414175304 and parameters: {'lr': 6.549342730249502, 'pbs': 7000, 'nbs': 3000}. Best is trial 13 with value: 0.021682285414175304.\n",
      "Trial 13 finished with value: 0.021682285414175304 and parameters: {'lr': 6.549342730249502, 'pbs': 7000, 'nbs': 3000}. Best is trial 13 with value: 0.021682285414175304.\n",
      "Trial 13 finished with value: 0.021682285414175304 and parameters: {'lr': 6.549342730249502, 'pbs': 7000, 'nbs': 3000}. Best is trial 13 with value: 0.021682285414175304.\n",
      "Trial 13 finished with value: 0.021682285414175304 and parameters: {'lr': 6.549342730249502, 'pbs': 7000, 'nbs': 3000}. Best is trial 13 with value: 0.021682285414175304.\n",
      "Trial 13 finished with value: 0.021682285414175304 and parameters: {'lr': 6.549342730249502, 'pbs': 7000, 'nbs': 3000}. Best is trial 13 with value: 0.021682285414175304.\n",
      "Trial 13 finished with value: 0.021682285414175304 and parameters: {'lr': 6.549342730249502, 'pbs': 7000, 'nbs': 3000}. Best is trial 13 with value: 0.021682285414175304.\n",
      "Epoch: 1\tFidelity = 0.938413\tKL_Divergence = 0.021294\n",
      "Epoch: 2\tFidelity = 0.935454\tKL_Divergence = 0.023080\n",
      "Epoch: 3\tFidelity = 0.935239\tKL_Divergence = 0.023595\n",
      "Epoch: 4\tFidelity = 0.933849\tKL_Divergence = 0.024827\n",
      "Epoch: 5\tFidelity = 0.937074\tKL_Divergence = 0.021871\n",
      "Epoch: 6\tFidelity = 0.936289\tKL_Divergence = 0.022105\n",
      "Epoch: 7\tFidelity = 0.930589\tKL_Divergence = 0.024814\n",
      "Epoch: 8\tFidelity = 0.934040\tKL_Divergence = 0.023409\n",
      "Epoch: 9\tFidelity = 0.935370\tKL_Divergence = 0.022711\n",
      "Epoch: 10\tFidelity = 0.933160\tKL_Divergence = 0.025250\n",
      "Epoch: 11\tFidelity = 0.932229\tKL_Divergence = 0.023893\n",
      "Epoch: 12\tFidelity = 0.935668\tKL_Divergence = 0.022097\n",
      "Epoch: 13\tFidelity = 0.936914\tKL_Divergence = 0.021647\n",
      "Epoch: 14\tFidelity = 0.935664\tKL_Divergence = 0.022770\n",
      "Epoch: 15\tFidelity = 0.932562\tKL_Divergence = 0.025325\n",
      "Epoch: 16\tFidelity = 0.930681\tKL_Divergence = 0.030063\n",
      "Epoch: 17\tFidelity = 0.935823\tKL_Divergence = 0.022853\n",
      "Epoch: 18\tFidelity = 0.935128\tKL_Divergence = 0.022288\n",
      "Epoch: 19\tFidelity = 0.933220\tKL_Divergence = 0.023976\n",
      "Epoch: 20\tFidelity = 0.934950\tKL_Divergence = 0.022390\n",
      "Epoch: 21\tFidelity = 0.931167\tKL_Divergence = 0.024365\n",
      "Epoch: 22\tFidelity = 0.929321\tKL_Divergence = 0.025021\n",
      "Epoch: 23\tFidelity = 0.933705\tKL_Divergence = 0.023269\n",
      "Epoch: 24\tFidelity = 0.934480\tKL_Divergence = 0.022616\n",
      "Epoch: 25\tFidelity = 0.934870\tKL_Divergence = 0.022481\n",
      "Epoch: 26\tFidelity = 0.933735\tKL_Divergence = 0.022941\n",
      "Epoch: 27\tFidelity = 0.936357\tKL_Divergence = 0.023258\n",
      "Epoch: 28\tFidelity = 0.930547\tKL_Divergence = 0.026138\n",
      "Epoch: 29\tFidelity = 0.931548\tKL_Divergence = 0.027532\n",
      "Epoch: 30\tFidelity = 0.935473\tKL_Divergence = 0.022280\n",
      "Epoch: 31\tFidelity = 0.936018\tKL_Divergence = 0.022024\n",
      "Epoch: 32\tFidelity = 0.936932\tKL_Divergence = 0.021652\n",
      "Epoch: 33\tFidelity = 0.930038\tKL_Divergence = 0.024657\n",
      "Epoch: 34\tFidelity = 0.934233\tKL_Divergence = 0.023422\n",
      "Epoch: 35\tFidelity = 0.936770\tKL_Divergence = 0.021821\n",
      "Epoch: 36\tFidelity = 0.937069\tKL_Divergence = 0.021610\n",
      "Epoch: 37\tFidelity = 0.933455\tKL_Divergence = 0.023306\n",
      "Epoch: 38\tFidelity = 0.934935\tKL_Divergence = 0.023099\n",
      "Epoch: 39\tFidelity = 0.936620\tKL_Divergence = 0.021976\n",
      "Epoch: 40\tFidelity = 0.934198\tKL_Divergence = 0.022833\n",
      "Epoch: 41\tFidelity = 0.934679\tKL_Divergence = 0.022572\n",
      "Epoch: 42\tFidelity = 0.930624\tKL_Divergence = 0.025408\n",
      "Epoch: 43\tFidelity = 0.931730\tKL_Divergence = 0.026395\n",
      "Epoch: 44\tFidelity = 0.935074\tKL_Divergence = 0.024998\n",
      "Epoch: 45\tFidelity = 0.934960\tKL_Divergence = 0.022563\n",
      "Epoch: 46\tFidelity = 0.934344\tKL_Divergence = 0.022650\n",
      "Epoch: 47\tFidelity = 0.930775\tKL_Divergence = 0.025462\n",
      "Epoch: 48\tFidelity = 0.933190\tKL_Divergence = 0.024709\n",
      "Epoch: 49\tFidelity = 0.935342\tKL_Divergence = 0.022718\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:15:01,454] Trial 14 finished with value: 0.022843067539801334 and parameters: {'lr': 5.093540681124867, 'pbs': 8000, 'nbs': 3000}. Best is trial 13 with value: 0.021682285414175304.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.934453\tKL_Divergence = 0.022843\n",
      "Total time elapsed during training: 330.493 s\n",
      "Trial 14 finished with value: 0.022843067539801334 and parameters: {'lr': 5.093540681124867, 'pbs': 8000, 'nbs': 3000}. Best is trial 13 with value: 0.021682285414175304.\n",
      "Trial 14 finished with value: 0.022843067539801334 and parameters: {'lr': 5.093540681124867, 'pbs': 8000, 'nbs': 3000}. Best is trial 13 with value: 0.021682285414175304.\n",
      "Trial 14 finished with value: 0.022843067539801334 and parameters: {'lr': 5.093540681124867, 'pbs': 8000, 'nbs': 3000}. Best is trial 13 with value: 0.021682285414175304.\n",
      "Trial 14 finished with value: 0.022843067539801334 and parameters: {'lr': 5.093540681124867, 'pbs': 8000, 'nbs': 3000}. Best is trial 13 with value: 0.021682285414175304.\n",
      "Trial 14 finished with value: 0.022843067539801334 and parameters: {'lr': 5.093540681124867, 'pbs': 8000, 'nbs': 3000}. Best is trial 13 with value: 0.021682285414175304.\n",
      "Trial 14 finished with value: 0.022843067539801334 and parameters: {'lr': 5.093540681124867, 'pbs': 8000, 'nbs': 3000}. Best is trial 13 with value: 0.021682285414175304.\n",
      "Epoch: 1\tFidelity = 0.936194\tKL_Divergence = 0.022197\n",
      "Epoch: 2\tFidelity = 0.936116\tKL_Divergence = 0.022295\n",
      "Epoch: 3\tFidelity = 0.934823\tKL_Divergence = 0.022757\n",
      "Epoch: 4\tFidelity = 0.933391\tKL_Divergence = 0.024774\n",
      "Epoch: 5\tFidelity = 0.932971\tKL_Divergence = 0.027689\n",
      "Epoch: 6\tFidelity = 0.930185\tKL_Divergence = 0.029744\n",
      "Epoch: 7\tFidelity = 0.933970\tKL_Divergence = 0.023075\n",
      "Epoch: 8\tFidelity = 0.933732\tKL_Divergence = 0.023167\n",
      "Epoch: 9\tFidelity = 0.933313\tKL_Divergence = 0.024134\n",
      "Epoch: 10\tFidelity = 0.936176\tKL_Divergence = 0.024331\n",
      "Epoch: 11\tFidelity = 0.932492\tKL_Divergence = 0.023662\n",
      "Epoch: 12\tFidelity = 0.933292\tKL_Divergence = 0.023823\n",
      "Epoch: 13\tFidelity = 0.932049\tKL_Divergence = 0.024261\n",
      "Epoch: 14\tFidelity = 0.936357\tKL_Divergence = 0.023394\n",
      "Epoch: 15\tFidelity = 0.934180\tKL_Divergence = 0.025133\n",
      "Epoch: 16\tFidelity = 0.933789\tKL_Divergence = 0.023072\n",
      "Epoch: 17\tFidelity = 0.929846\tKL_Divergence = 0.027263\n",
      "Epoch: 18\tFidelity = 0.934133\tKL_Divergence = 0.023145\n",
      "Epoch: 19\tFidelity = 0.932128\tKL_Divergence = 0.026399\n",
      "Epoch: 20\tFidelity = 0.934518\tKL_Divergence = 0.022903\n",
      "Epoch: 21\tFidelity = 0.936158\tKL_Divergence = 0.023504\n",
      "Epoch: 22\tFidelity = 0.934699\tKL_Divergence = 0.023453\n",
      "Epoch: 23\tFidelity = 0.932018\tKL_Divergence = 0.026080\n",
      "Epoch: 24\tFidelity = 0.934468\tKL_Divergence = 0.023467\n",
      "Epoch: 25\tFidelity = 0.932665\tKL_Divergence = 0.025072\n",
      "Epoch: 26\tFidelity = 0.931919\tKL_Divergence = 0.025087\n",
      "Epoch: 27\tFidelity = 0.932166\tKL_Divergence = 0.024809\n",
      "Epoch: 28\tFidelity = 0.933093\tKL_Divergence = 0.023646\n",
      "Epoch: 29\tFidelity = 0.936431\tKL_Divergence = 0.022873\n",
      "Epoch: 30\tFidelity = 0.934986\tKL_Divergence = 0.023326\n",
      "Epoch: 31\tFidelity = 0.935087\tKL_Divergence = 0.025621\n",
      "Epoch: 32\tFidelity = 0.926246\tKL_Divergence = 0.030889\n",
      "Epoch: 33\tFidelity = 0.935071\tKL_Divergence = 0.022742\n",
      "Epoch: 34\tFidelity = 0.930246\tKL_Divergence = 0.025073\n",
      "Epoch: 35\tFidelity = 0.934547\tKL_Divergence = 0.025021\n",
      "Epoch: 36\tFidelity = 0.935348\tKL_Divergence = 0.025916\n",
      "Epoch: 37\tFidelity = 0.934950\tKL_Divergence = 0.024019\n",
      "Epoch: 38\tFidelity = 0.934982\tKL_Divergence = 0.022877\n",
      "Epoch: 39\tFidelity = 0.934652\tKL_Divergence = 0.028535\n",
      "Epoch: 40\tFidelity = 0.935326\tKL_Divergence = 0.023438\n",
      "Epoch: 41\tFidelity = 0.933566\tKL_Divergence = 0.025461\n",
      "Epoch: 42\tFidelity = 0.934987\tKL_Divergence = 0.022817\n",
      "Epoch: 43\tFidelity = 0.930487\tKL_Divergence = 0.026249\n",
      "Epoch: 44\tFidelity = 0.931368\tKL_Divergence = 0.024342\n",
      "Epoch: 45\tFidelity = 0.936544\tKL_Divergence = 0.022165\n",
      "Epoch: 46\tFidelity = 0.930207\tKL_Divergence = 0.025672\n",
      "Epoch: 47\tFidelity = 0.936771\tKL_Divergence = 0.022360\n",
      "Epoch: 48\tFidelity = 0.934898\tKL_Divergence = 0.026025\n",
      "Epoch: 49\tFidelity = 0.936189\tKL_Divergence = 0.022149\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:20:08,436] Trial 15 finished with value: 0.021841216497805897 and parameters: {'lr': 7.36795737211324, 'pbs': 10000, 'nbs': 3000}. Best is trial 13 with value: 0.021682285414175304.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.937017\tKL_Divergence = 0.021841\n",
      "Total time elapsed during training: 306.652 s\n",
      "Trial 15 finished with value: 0.021841216497805897 and parameters: {'lr': 7.36795737211324, 'pbs': 10000, 'nbs': 3000}. Best is trial 13 with value: 0.021682285414175304.\n",
      "Trial 15 finished with value: 0.021841216497805897 and parameters: {'lr': 7.36795737211324, 'pbs': 10000, 'nbs': 3000}. Best is trial 13 with value: 0.021682285414175304.\n",
      "Trial 15 finished with value: 0.021841216497805897 and parameters: {'lr': 7.36795737211324, 'pbs': 10000, 'nbs': 3000}. Best is trial 13 with value: 0.021682285414175304.\n",
      "Trial 15 finished with value: 0.021841216497805897 and parameters: {'lr': 7.36795737211324, 'pbs': 10000, 'nbs': 3000}. Best is trial 13 with value: 0.021682285414175304.\n",
      "Trial 15 finished with value: 0.021841216497805897 and parameters: {'lr': 7.36795737211324, 'pbs': 10000, 'nbs': 3000}. Best is trial 13 with value: 0.021682285414175304.\n",
      "Trial 15 finished with value: 0.021841216497805897 and parameters: {'lr': 7.36795737211324, 'pbs': 10000, 'nbs': 3000}. Best is trial 13 with value: 0.021682285414175304.\n",
      "Epoch: 1\tFidelity = 0.935016\tKL_Divergence = 0.024742\n",
      "Epoch: 2\tFidelity = 0.936890\tKL_Divergence = 0.022053\n",
      "Epoch: 3\tFidelity = 0.934165\tKL_Divergence = 0.025384\n",
      "Epoch: 4\tFidelity = 0.932947\tKL_Divergence = 0.023484\n",
      "Epoch: 5\tFidelity = 0.935498\tKL_Divergence = 0.023428\n",
      "Epoch: 6\tFidelity = 0.932705\tKL_Divergence = 0.026127\n",
      "Epoch: 7\tFidelity = 0.933301\tKL_Divergence = 0.024653\n",
      "Epoch: 8\tFidelity = 0.930999\tKL_Divergence = 0.024589\n",
      "Epoch: 9\tFidelity = 0.934867\tKL_Divergence = 0.025398\n",
      "Epoch: 10\tFidelity = 0.934372\tKL_Divergence = 0.023073\n",
      "Epoch: 11\tFidelity = 0.929377\tKL_Divergence = 0.028698\n",
      "Epoch: 12\tFidelity = 0.933977\tKL_Divergence = 0.024059\n",
      "Epoch: 13\tFidelity = 0.935430\tKL_Divergence = 0.022882\n",
      "Epoch: 14\tFidelity = 0.936826\tKL_Divergence = 0.023235\n",
      "Epoch: 15\tFidelity = 0.935748\tKL_Divergence = 0.022562\n",
      "Epoch: 16\tFidelity = 0.932918\tKL_Divergence = 0.023866\n",
      "Epoch: 17\tFidelity = 0.935493\tKL_Divergence = 0.022341\n",
      "Epoch: 18\tFidelity = 0.928780\tKL_Divergence = 0.030072\n",
      "Epoch: 19\tFidelity = 0.933774\tKL_Divergence = 0.023532\n",
      "Epoch: 20\tFidelity = 0.930854\tKL_Divergence = 0.028809\n",
      "Epoch: 21\tFidelity = 0.932745\tKL_Divergence = 0.028191\n",
      "Epoch: 22\tFidelity = 0.932369\tKL_Divergence = 0.024364\n",
      "Epoch: 23\tFidelity = 0.933592\tKL_Divergence = 0.027451\n",
      "Epoch: 24\tFidelity = 0.934644\tKL_Divergence = 0.023163\n",
      "Epoch: 25\tFidelity = 0.935260\tKL_Divergence = 0.023057\n",
      "Epoch: 26\tFidelity = 0.934515\tKL_Divergence = 0.023555\n",
      "Epoch: 27\tFidelity = 0.937285\tKL_Divergence = 0.021554\n",
      "Epoch: 28\tFidelity = 0.932813\tKL_Divergence = 0.026009\n",
      "Epoch: 29\tFidelity = 0.928748\tKL_Divergence = 0.027852\n",
      "Epoch: 30\tFidelity = 0.935101\tKL_Divergence = 0.024175\n",
      "Epoch: 31\tFidelity = 0.934194\tKL_Divergence = 0.023569\n",
      "Epoch: 32\tFidelity = 0.931817\tKL_Divergence = 0.023887\n",
      "Epoch: 33\tFidelity = 0.934192\tKL_Divergence = 0.022968\n",
      "Epoch: 34\tFidelity = 0.931772\tKL_Divergence = 0.025044\n",
      "Epoch: 35\tFidelity = 0.934685\tKL_Divergence = 0.022825\n",
      "Epoch: 36\tFidelity = 0.932676\tKL_Divergence = 0.025550\n",
      "Epoch: 37\tFidelity = 0.927828\tKL_Divergence = 0.029394\n",
      "Epoch: 38\tFidelity = 0.932529\tKL_Divergence = 0.023739\n",
      "Epoch: 39\tFidelity = 0.933925\tKL_Divergence = 0.025682\n",
      "Epoch: 40\tFidelity = 0.934950\tKL_Divergence = 0.023029\n",
      "Epoch: 41\tFidelity = 0.933306\tKL_Divergence = 0.026839\n",
      "Epoch: 42\tFidelity = 0.932672\tKL_Divergence = 0.023766\n",
      "Epoch: 43\tFidelity = 0.934336\tKL_Divergence = 0.024972\n",
      "Epoch: 44\tFidelity = 0.925321\tKL_Divergence = 0.034427\n",
      "Epoch: 45\tFidelity = 0.930940\tKL_Divergence = 0.025719\n",
      "Epoch: 46\tFidelity = 0.936037\tKL_Divergence = 0.022233\n",
      "Epoch: 47\tFidelity = 0.927583\tKL_Divergence = 0.033188\n",
      "Epoch: 48\tFidelity = 0.936180\tKL_Divergence = 0.024780\n",
      "Epoch: 49\tFidelity = 0.936654\tKL_Divergence = 0.022056\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:25:13,760] Trial 16 finished with value: 0.02150957396361379 and parameters: {'lr': 7.709486544162145, 'pbs': 10000, 'nbs': 3000}. Best is trial 16 with value: 0.02150957396361379.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.937826\tKL_Divergence = 0.021510\n",
      "Total time elapsed during training: 305.007 s\n",
      "Trial 16 finished with value: 0.02150957396361379 and parameters: {'lr': 7.709486544162145, 'pbs': 10000, 'nbs': 3000}. Best is trial 16 with value: 0.02150957396361379.\n",
      "Trial 16 finished with value: 0.02150957396361379 and parameters: {'lr': 7.709486544162145, 'pbs': 10000, 'nbs': 3000}. Best is trial 16 with value: 0.02150957396361379.\n",
      "Trial 16 finished with value: 0.02150957396361379 and parameters: {'lr': 7.709486544162145, 'pbs': 10000, 'nbs': 3000}. Best is trial 16 with value: 0.02150957396361379.\n",
      "Trial 16 finished with value: 0.02150957396361379 and parameters: {'lr': 7.709486544162145, 'pbs': 10000, 'nbs': 3000}. Best is trial 16 with value: 0.02150957396361379.\n",
      "Trial 16 finished with value: 0.02150957396361379 and parameters: {'lr': 7.709486544162145, 'pbs': 10000, 'nbs': 3000}. Best is trial 16 with value: 0.02150957396361379.\n",
      "Trial 16 finished with value: 0.02150957396361379 and parameters: {'lr': 7.709486544162145, 'pbs': 10000, 'nbs': 3000}. Best is trial 16 with value: 0.02150957396361379.\n",
      "Epoch: 1\tFidelity = 0.937566\tKL_Divergence = 0.021530\n",
      "Epoch: 2\tFidelity = 0.933352\tKL_Divergence = 0.024459\n",
      "Epoch: 3\tFidelity = 0.935414\tKL_Divergence = 0.022324\n",
      "Epoch: 4\tFidelity = 0.930402\tKL_Divergence = 0.027453\n",
      "Epoch: 5\tFidelity = 0.933917\tKL_Divergence = 0.023605\n",
      "Epoch: 6\tFidelity = 0.935002\tKL_Divergence = 0.022969\n",
      "Epoch: 7\tFidelity = 0.934197\tKL_Divergence = 0.022893\n",
      "Epoch: 8\tFidelity = 0.931768\tKL_Divergence = 0.030047\n",
      "Epoch: 9\tFidelity = 0.936491\tKL_Divergence = 0.022151\n",
      "Epoch: 10\tFidelity = 0.930755\tKL_Divergence = 0.028652\n",
      "Epoch: 11\tFidelity = 0.936086\tKL_Divergence = 0.022717\n",
      "Epoch: 12\tFidelity = 0.934004\tKL_Divergence = 0.023476\n",
      "Epoch: 13\tFidelity = 0.936320\tKL_Divergence = 0.024077\n",
      "Epoch: 14\tFidelity = 0.933255\tKL_Divergence = 0.023487\n",
      "Epoch: 15\tFidelity = 0.933957\tKL_Divergence = 0.024221\n",
      "Epoch: 16\tFidelity = 0.932253\tKL_Divergence = 0.025960\n",
      "Epoch: 17\tFidelity = 0.935187\tKL_Divergence = 0.023584\n",
      "Epoch: 18\tFidelity = 0.936474\tKL_Divergence = 0.024090\n",
      "Epoch: 19\tFidelity = 0.937139\tKL_Divergence = 0.023222\n",
      "Epoch: 20\tFidelity = 0.934672\tKL_Divergence = 0.025461\n",
      "Epoch: 21\tFidelity = 0.937352\tKL_Divergence = 0.022690\n",
      "Epoch: 22\tFidelity = 0.934628\tKL_Divergence = 0.028550\n",
      "Epoch: 23\tFidelity = 0.935236\tKL_Divergence = 0.025302\n",
      "Epoch: 24\tFidelity = 0.935607\tKL_Divergence = 0.022548\n",
      "Epoch: 25\tFidelity = 0.931491\tKL_Divergence = 0.024700\n",
      "Epoch: 26\tFidelity = 0.925436\tKL_Divergence = 0.030213\n",
      "Epoch: 27\tFidelity = 0.936219\tKL_Divergence = 0.024275\n",
      "Epoch: 28\tFidelity = 0.936353\tKL_Divergence = 0.024505\n",
      "Epoch: 29\tFidelity = 0.933191\tKL_Divergence = 0.025546\n",
      "Epoch: 30\tFidelity = 0.936289\tKL_Divergence = 0.022293\n",
      "Epoch: 31\tFidelity = 0.934526\tKL_Divergence = 0.023748\n",
      "Epoch: 32\tFidelity = 0.932746\tKL_Divergence = 0.024027\n",
      "Epoch: 33\tFidelity = 0.933193\tKL_Divergence = 0.024976\n",
      "Epoch: 34\tFidelity = 0.936009\tKL_Divergence = 0.022395\n",
      "Epoch: 35\tFidelity = 0.927354\tKL_Divergence = 0.028470\n",
      "Epoch: 36\tFidelity = 0.930029\tKL_Divergence = 0.032811\n",
      "Epoch: 37\tFidelity = 0.935417\tKL_Divergence = 0.022824\n",
      "Epoch: 38\tFidelity = 0.933728\tKL_Divergence = 0.023850\n",
      "Epoch: 39\tFidelity = 0.936177\tKL_Divergence = 0.023070\n",
      "Epoch: 40\tFidelity = 0.931863\tKL_Divergence = 0.026568\n",
      "Epoch: 41\tFidelity = 0.934518\tKL_Divergence = 0.024419\n",
      "Epoch: 42\tFidelity = 0.935165\tKL_Divergence = 0.023116\n",
      "Epoch: 43\tFidelity = 0.929912\tKL_Divergence = 0.026905\n",
      "Epoch: 44\tFidelity = 0.922076\tKL_Divergence = 0.029066\n",
      "Epoch: 45\tFidelity = 0.934149\tKL_Divergence = 0.023350\n",
      "Epoch: 46\tFidelity = 0.932384\tKL_Divergence = 0.025390\n",
      "Epoch: 47\tFidelity = 0.934060\tKL_Divergence = 0.023170\n",
      "Epoch: 48\tFidelity = 0.932008\tKL_Divergence = 0.024033\n",
      "Epoch: 49\tFidelity = 0.933596\tKL_Divergence = 0.025722\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:31:43,424] Trial 17 finished with value: 0.022182392983637098 and parameters: {'lr': 8.847236950014986, 'pbs': 4000, 'nbs': 8000}. Best is trial 16 with value: 0.02150957396361379.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.936560\tKL_Divergence = 0.022182\n",
      "Total time elapsed during training: 389.323 s\n",
      "Trial 17 finished with value: 0.022182392983637098 and parameters: {'lr': 8.847236950014986, 'pbs': 4000, 'nbs': 8000}. Best is trial 16 with value: 0.02150957396361379.\n",
      "Trial 17 finished with value: 0.022182392983637098 and parameters: {'lr': 8.847236950014986, 'pbs': 4000, 'nbs': 8000}. Best is trial 16 with value: 0.02150957396361379.\n",
      "Trial 17 finished with value: 0.022182392983637098 and parameters: {'lr': 8.847236950014986, 'pbs': 4000, 'nbs': 8000}. Best is trial 16 with value: 0.02150957396361379.\n",
      "Trial 17 finished with value: 0.022182392983637098 and parameters: {'lr': 8.847236950014986, 'pbs': 4000, 'nbs': 8000}. Best is trial 16 with value: 0.02150957396361379.\n",
      "Trial 17 finished with value: 0.022182392983637098 and parameters: {'lr': 8.847236950014986, 'pbs': 4000, 'nbs': 8000}. Best is trial 16 with value: 0.02150957396361379.\n",
      "Trial 17 finished with value: 0.022182392983637098 and parameters: {'lr': 8.847236950014986, 'pbs': 4000, 'nbs': 8000}. Best is trial 16 with value: 0.02150957396361379.\n",
      "Epoch: 1\tFidelity = 0.929101\tKL_Divergence = 0.032106\n",
      "Epoch: 2\tFidelity = 0.935749\tKL_Divergence = 0.022794\n",
      "Epoch: 3\tFidelity = 0.933245\tKL_Divergence = 0.028567\n",
      "Epoch: 4\tFidelity = 0.935863\tKL_Divergence = 0.022555\n",
      "Epoch: 5\tFidelity = 0.936121\tKL_Divergence = 0.022627\n",
      "Epoch: 6\tFidelity = 0.931720\tKL_Divergence = 0.026621\n",
      "Epoch: 7\tFidelity = 0.933369\tKL_Divergence = 0.023354\n",
      "Epoch: 8\tFidelity = 0.931764\tKL_Divergence = 0.027806\n",
      "Epoch: 9\tFidelity = 0.930992\tKL_Divergence = 0.025382\n",
      "Epoch: 10\tFidelity = 0.931559\tKL_Divergence = 0.026744\n",
      "Epoch: 11\tFidelity = 0.930118\tKL_Divergence = 0.024800\n",
      "Epoch: 12\tFidelity = 0.927897\tKL_Divergence = 0.031935\n",
      "Epoch: 13\tFidelity = 0.932540\tKL_Divergence = 0.024090\n",
      "Epoch: 14\tFidelity = 0.933836\tKL_Divergence = 0.026017\n",
      "Epoch: 15\tFidelity = 0.934402\tKL_Divergence = 0.025955\n",
      "Epoch: 16\tFidelity = 0.928399\tKL_Divergence = 0.026337\n",
      "Epoch: 17\tFidelity = 0.931080\tKL_Divergence = 0.025523\n",
      "Epoch: 18\tFidelity = 0.932335\tKL_Divergence = 0.024045\n",
      "Epoch: 19\tFidelity = 0.927908\tKL_Divergence = 0.026298\n",
      "Epoch: 20\tFidelity = 0.933433\tKL_Divergence = 0.023744\n",
      "Epoch: 21\tFidelity = 0.927810\tKL_Divergence = 0.026475\n",
      "Epoch: 22\tFidelity = 0.934040\tKL_Divergence = 0.023739\n",
      "Epoch: 23\tFidelity = 0.934632\tKL_Divergence = 0.022905\n",
      "Epoch: 24\tFidelity = 0.935072\tKL_Divergence = 0.022669\n",
      "Epoch: 25\tFidelity = 0.934488\tKL_Divergence = 0.023378\n",
      "Epoch: 26\tFidelity = 0.932113\tKL_Divergence = 0.023899\n",
      "Epoch: 27\tFidelity = 0.933736\tKL_Divergence = 0.025057\n",
      "Epoch: 28\tFidelity = 0.933494\tKL_Divergence = 0.023181\n",
      "Epoch: 29\tFidelity = 0.935276\tKL_Divergence = 0.022897\n",
      "Epoch: 30\tFidelity = 0.936175\tKL_Divergence = 0.023461\n",
      "Epoch: 31\tFidelity = 0.937548\tKL_Divergence = 0.021730\n",
      "Epoch: 32\tFidelity = 0.938141\tKL_Divergence = 0.021401\n",
      "Epoch: 33\tFidelity = 0.936598\tKL_Divergence = 0.022798\n",
      "Epoch: 34\tFidelity = 0.933490\tKL_Divergence = 0.025078\n",
      "Epoch: 35\tFidelity = 0.934182\tKL_Divergence = 0.025266\n",
      "Epoch: 36\tFidelity = 0.933613\tKL_Divergence = 0.025384\n",
      "Epoch: 37\tFidelity = 0.937160\tKL_Divergence = 0.022586\n",
      "Epoch: 38\tFidelity = 0.934681\tKL_Divergence = 0.024372\n",
      "Epoch: 39\tFidelity = 0.930018\tKL_Divergence = 0.026064\n",
      "Epoch: 40\tFidelity = 0.932692\tKL_Divergence = 0.030722\n",
      "Epoch: 41\tFidelity = 0.938150\tKL_Divergence = 0.022015\n",
      "Epoch: 42\tFidelity = 0.935918\tKL_Divergence = 0.022693\n",
      "Epoch: 43\tFidelity = 0.933070\tKL_Divergence = 0.024224\n",
      "Epoch: 44\tFidelity = 0.936468\tKL_Divergence = 0.022334\n",
      "Epoch: 45\tFidelity = 0.937735\tKL_Divergence = 0.021773\n",
      "Epoch: 46\tFidelity = 0.937211\tKL_Divergence = 0.022325\n",
      "Epoch: 47\tFidelity = 0.935930\tKL_Divergence = 0.022545\n",
      "Epoch: 48\tFidelity = 0.927081\tKL_Divergence = 0.029672\n",
      "Epoch: 49\tFidelity = 0.936604\tKL_Divergence = 0.021929\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:36:47,554] Trial 18 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.934776\tKL_Divergence = 0.023761\n",
      "Total time elapsed during training: 303.782 s\n",
      "Trial 18 pruned. \n",
      "Trial 18 pruned. \n",
      "Trial 18 pruned. \n",
      "Trial 18 pruned. \n",
      "Trial 18 pruned. \n",
      "Trial 18 pruned. \n",
      "Epoch: 1\tFidelity = 0.936190\tKL_Divergence = 0.022502\n",
      "Epoch: 2\tFidelity = 0.929722\tKL_Divergence = 0.025964\n",
      "Epoch: 3\tFidelity = 0.931378\tKL_Divergence = 0.025687\n",
      "Epoch: 4\tFidelity = 0.926794\tKL_Divergence = 0.030848\n",
      "Epoch: 5\tFidelity = 0.932015\tKL_Divergence = 0.028161\n",
      "Epoch: 6\tFidelity = 0.935383\tKL_Divergence = 0.023323\n",
      "Epoch: 7\tFidelity = 0.931806\tKL_Divergence = 0.026617\n",
      "Epoch: 8\tFidelity = 0.938907\tKL_Divergence = 0.021448\n",
      "Epoch: 9\tFidelity = 0.929155\tKL_Divergence = 0.026558\n",
      "Epoch: 10\tFidelity = 0.939066\tKL_Divergence = 0.021289\n",
      "Epoch: 11\tFidelity = 0.937570\tKL_Divergence = 0.021923\n",
      "Epoch: 12\tFidelity = 0.930149\tKL_Divergence = 0.026971\n",
      "Epoch: 13\tFidelity = 0.935900\tKL_Divergence = 0.023239\n",
      "Epoch: 14\tFidelity = 0.931157\tKL_Divergence = 0.025237\n",
      "Epoch: 15\tFidelity = 0.932654\tKL_Divergence = 0.025141\n",
      "Epoch: 16\tFidelity = 0.925343\tKL_Divergence = 0.031703\n",
      "Epoch: 17\tFidelity = 0.933013\tKL_Divergence = 0.033159\n",
      "Epoch: 18\tFidelity = 0.938634\tKL_Divergence = 0.022275\n",
      "Epoch: 19\tFidelity = 0.935577\tKL_Divergence = 0.023534\n",
      "Epoch: 20\tFidelity = 0.934325\tKL_Divergence = 0.023779\n",
      "Epoch: 21\tFidelity = 0.935499\tKL_Divergence = 0.031021\n",
      "Epoch: 22\tFidelity = 0.937002\tKL_Divergence = 0.022753\n",
      "Epoch: 23\tFidelity = 0.935781\tKL_Divergence = 0.023475\n",
      "Epoch: 24\tFidelity = 0.936894\tKL_Divergence = 0.024120\n",
      "Epoch: 25\tFidelity = 0.939280\tKL_Divergence = 0.021344\n",
      "Epoch: 26\tFidelity = 0.935288\tKL_Divergence = 0.024227\n",
      "Epoch: 27\tFidelity = 0.933535\tKL_Divergence = 0.026958\n",
      "Epoch: 28\tFidelity = 0.939106\tKL_Divergence = 0.021406\n",
      "Epoch: 29\tFidelity = 0.937946\tKL_Divergence = 0.022185\n",
      "Epoch: 30\tFidelity = 0.936435\tKL_Divergence = 0.024014\n",
      "Epoch: 31\tFidelity = 0.937323\tKL_Divergence = 0.021806\n",
      "Epoch: 32\tFidelity = 0.936222\tKL_Divergence = 0.022153\n",
      "Epoch: 33\tFidelity = 0.935203\tKL_Divergence = 0.024599\n",
      "Epoch: 34\tFidelity = 0.928380\tKL_Divergence = 0.027920\n",
      "Epoch: 35\tFidelity = 0.933733\tKL_Divergence = 0.025734\n",
      "Epoch: 36\tFidelity = 0.926916\tKL_Divergence = 0.027188\n",
      "Epoch: 37\tFidelity = 0.929696\tKL_Divergence = 0.025421\n",
      "Epoch: 38\tFidelity = 0.933332\tKL_Divergence = 0.026032\n",
      "Epoch: 39\tFidelity = 0.936710\tKL_Divergence = 0.022679\n",
      "Epoch: 40\tFidelity = 0.933533\tKL_Divergence = 0.023624\n",
      "Epoch: 41\tFidelity = 0.934462\tKL_Divergence = 0.023620\n",
      "Epoch: 42\tFidelity = 0.931656\tKL_Divergence = 0.024999\n",
      "Epoch: 43\tFidelity = 0.939035\tKL_Divergence = 0.021512\n",
      "Epoch: 44\tFidelity = 0.937751\tKL_Divergence = 0.021731\n",
      "Epoch: 45\tFidelity = 0.937947\tKL_Divergence = 0.022082\n",
      "Epoch: 46\tFidelity = 0.936076\tKL_Divergence = 0.024358\n",
      "Epoch: 47\tFidelity = 0.936877\tKL_Divergence = 0.023116\n",
      "Epoch: 48\tFidelity = 0.933535\tKL_Divergence = 0.028084\n",
      "Epoch: 49\tFidelity = 0.931034\tKL_Divergence = 0.026961\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:41:54,261] Trial 19 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.933718\tKL_Divergence = 0.023802\n",
      "Total time elapsed during training: 306.256 s\n",
      "Trial 19 pruned. \n",
      "Trial 19 pruned. \n",
      "Trial 19 pruned. \n",
      "Trial 19 pruned. \n",
      "Trial 19 pruned. \n",
      "Trial 19 pruned. \n",
      "Epoch: 1\tFidelity = 0.937033\tKL_Divergence = 0.022266\n",
      "Epoch: 2\tFidelity = 0.936684\tKL_Divergence = 0.024526\n",
      "Epoch: 3\tFidelity = 0.930277\tKL_Divergence = 0.036528\n",
      "Epoch: 4\tFidelity = 0.930607\tKL_Divergence = 0.029524\n",
      "Epoch: 5\tFidelity = 0.934942\tKL_Divergence = 0.023161\n",
      "Epoch: 6\tFidelity = 0.926129\tKL_Divergence = 0.033742\n",
      "Epoch: 7\tFidelity = 0.937506\tKL_Divergence = 0.021724\n",
      "Epoch: 8\tFidelity = 0.921877\tKL_Divergence = 0.034822\n",
      "Epoch: 9\tFidelity = 0.937819\tKL_Divergence = 0.022716\n",
      "Epoch: 10\tFidelity = 0.934914\tKL_Divergence = 0.022669\n",
      "Epoch: 11\tFidelity = 0.929386\tKL_Divergence = 0.031059\n",
      "Epoch: 12\tFidelity = 0.935453\tKL_Divergence = 0.023568\n",
      "Epoch: 13\tFidelity = 0.937122\tKL_Divergence = 0.022759\n",
      "Epoch: 14\tFidelity = 0.934619\tKL_Divergence = 0.022852\n",
      "Epoch: 15\tFidelity = 0.931060\tKL_Divergence = 0.027824\n",
      "Epoch: 16\tFidelity = 0.935044\tKL_Divergence = 0.028014\n",
      "Epoch: 17\tFidelity = 0.936570\tKL_Divergence = 0.022924\n",
      "Epoch: 18\tFidelity = 0.932344\tKL_Divergence = 0.026515\n",
      "Epoch: 19\tFidelity = 0.936206\tKL_Divergence = 0.022004\n",
      "Epoch: 20\tFidelity = 0.937113\tKL_Divergence = 0.024168\n",
      "Epoch: 21\tFidelity = 0.928227\tKL_Divergence = 0.030191\n",
      "Epoch: 22\tFidelity = 0.937078\tKL_Divergence = 0.022282\n",
      "Epoch: 23\tFidelity = 0.937926\tKL_Divergence = 0.021334\n",
      "Epoch: 24\tFidelity = 0.932963\tKL_Divergence = 0.027675\n",
      "Epoch: 25\tFidelity = 0.937363\tKL_Divergence = 0.021580\n",
      "Epoch: 26\tFidelity = 0.935008\tKL_Divergence = 0.023027\n",
      "Epoch: 27\tFidelity = 0.937204\tKL_Divergence = 0.022361\n",
      "Epoch: 28\tFidelity = 0.936682\tKL_Divergence = 0.021697\n",
      "Epoch: 29\tFidelity = 0.935819\tKL_Divergence = 0.022666\n",
      "Epoch: 30\tFidelity = 0.929825\tKL_Divergence = 0.025377\n",
      "Epoch: 31\tFidelity = 0.935158\tKL_Divergence = 0.022367\n",
      "Epoch: 32\tFidelity = 0.936598\tKL_Divergence = 0.022198\n",
      "Epoch: 33\tFidelity = 0.933250\tKL_Divergence = 0.024016\n",
      "Epoch: 34\tFidelity = 0.935575\tKL_Divergence = 0.022183\n",
      "Epoch: 35\tFidelity = 0.933000\tKL_Divergence = 0.023735\n",
      "Epoch: 36\tFidelity = 0.936627\tKL_Divergence = 0.022188\n",
      "Epoch: 37\tFidelity = 0.932817\tKL_Divergence = 0.024181\n",
      "Epoch: 38\tFidelity = 0.933209\tKL_Divergence = 0.026666\n",
      "Epoch: 39\tFidelity = 0.933248\tKL_Divergence = 0.028689\n",
      "Epoch: 40\tFidelity = 0.934528\tKL_Divergence = 0.023349\n",
      "Epoch: 41\tFidelity = 0.932364\tKL_Divergence = 0.027318\n",
      "Epoch: 42\tFidelity = 0.930837\tKL_Divergence = 0.024402\n",
      "Epoch: 43\tFidelity = 0.935281\tKL_Divergence = 0.024059\n",
      "Epoch: 44\tFidelity = 0.933540\tKL_Divergence = 0.023461\n",
      "Epoch: 45\tFidelity = 0.932251\tKL_Divergence = 0.025112\n",
      "Epoch: 46\tFidelity = 0.930898\tKL_Divergence = 0.025086\n",
      "Epoch: 47\tFidelity = 0.935882\tKL_Divergence = 0.023366\n",
      "Epoch: 48\tFidelity = 0.936562\tKL_Divergence = 0.022184\n",
      "Epoch: 49\tFidelity = 0.929048\tKL_Divergence = 0.026975\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:47:20,110] Trial 20 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.931883\tKL_Divergence = 0.024792\n",
      "Total time elapsed during training: 325.522 s\n",
      "Trial 20 pruned. \n",
      "Trial 20 pruned. \n",
      "Trial 20 pruned. \n",
      "Trial 20 pruned. \n",
      "Trial 20 pruned. \n",
      "Trial 20 pruned. \n",
      "Epoch: 1\tFidelity = 0.935843\tKL_Divergence = 0.022276\n",
      "Epoch: 2\tFidelity = 0.934737\tKL_Divergence = 0.022870\n",
      "Epoch: 3\tFidelity = 0.935301\tKL_Divergence = 0.022719\n",
      "Epoch: 4\tFidelity = 0.929712\tKL_Divergence = 0.028155\n",
      "Epoch: 5\tFidelity = 0.930961\tKL_Divergence = 0.025496\n",
      "Epoch: 6\tFidelity = 0.933865\tKL_Divergence = 0.023232\n",
      "Epoch: 7\tFidelity = 0.935982\tKL_Divergence = 0.022246\n",
      "Epoch: 8\tFidelity = 0.932437\tKL_Divergence = 0.024566\n",
      "Epoch: 9\tFidelity = 0.934587\tKL_Divergence = 0.022776\n",
      "Epoch: 10\tFidelity = 0.932444\tKL_Divergence = 0.026363\n",
      "Epoch: 11\tFidelity = 0.933729\tKL_Divergence = 0.023914\n",
      "Epoch: 12\tFidelity = 0.935141\tKL_Divergence = 0.022874\n",
      "Epoch: 13\tFidelity = 0.934531\tKL_Divergence = 0.022863\n",
      "Epoch: 14\tFidelity = 0.932175\tKL_Divergence = 0.023983\n",
      "Epoch: 15\tFidelity = 0.930656\tKL_Divergence = 0.027616\n",
      "Epoch: 16\tFidelity = 0.934398\tKL_Divergence = 0.022829\n",
      "Epoch: 17\tFidelity = 0.932727\tKL_Divergence = 0.024308\n",
      "Epoch: 18\tFidelity = 0.935478\tKL_Divergence = 0.022709\n",
      "Epoch: 19\tFidelity = 0.935077\tKL_Divergence = 0.022843\n",
      "Epoch: 20\tFidelity = 0.933142\tKL_Divergence = 0.025884\n",
      "Epoch: 21\tFidelity = 0.934076\tKL_Divergence = 0.023074\n",
      "Epoch: 22\tFidelity = 0.930254\tKL_Divergence = 0.025955\n",
      "Epoch: 23\tFidelity = 0.927230\tKL_Divergence = 0.032800\n",
      "Epoch: 24\tFidelity = 0.930895\tKL_Divergence = 0.027222\n",
      "Epoch: 25\tFidelity = 0.934308\tKL_Divergence = 0.023047\n",
      "Epoch: 26\tFidelity = 0.937093\tKL_Divergence = 0.022297\n",
      "Epoch: 27\tFidelity = 0.934743\tKL_Divergence = 0.024349\n",
      "Epoch: 28\tFidelity = 0.934240\tKL_Divergence = 0.023665\n",
      "Epoch: 29\tFidelity = 0.936524\tKL_Divergence = 0.022288\n",
      "Epoch: 30\tFidelity = 0.934462\tKL_Divergence = 0.022906\n",
      "Epoch: 31\tFidelity = 0.933952\tKL_Divergence = 0.023202\n",
      "Epoch: 32\tFidelity = 0.929597\tKL_Divergence = 0.029326\n",
      "Epoch: 33\tFidelity = 0.930722\tKL_Divergence = 0.028636\n",
      "Epoch: 34\tFidelity = 0.935966\tKL_Divergence = 0.022796\n",
      "Epoch: 35\tFidelity = 0.934543\tKL_Divergence = 0.022974\n",
      "Epoch: 36\tFidelity = 0.934318\tKL_Divergence = 0.023665\n",
      "Epoch: 37\tFidelity = 0.932065\tKL_Divergence = 0.027268\n",
      "Epoch: 38\tFidelity = 0.935024\tKL_Divergence = 0.022808\n",
      "Epoch: 39\tFidelity = 0.934053\tKL_Divergence = 0.023066\n",
      "Epoch: 40\tFidelity = 0.935425\tKL_Divergence = 0.022360\n",
      "Epoch: 41\tFidelity = 0.935365\tKL_Divergence = 0.022781\n",
      "Epoch: 42\tFidelity = 0.935861\tKL_Divergence = 0.022452\n",
      "Epoch: 43\tFidelity = 0.932632\tKL_Divergence = 0.024580\n",
      "Epoch: 44\tFidelity = 0.934328\tKL_Divergence = 0.023990\n",
      "Epoch: 45\tFidelity = 0.936470\tKL_Divergence = 0.021973\n",
      "Epoch: 46\tFidelity = 0.934375\tKL_Divergence = 0.022966\n",
      "Epoch: 47\tFidelity = 0.934318\tKL_Divergence = 0.023592\n",
      "Epoch: 48\tFidelity = 0.935271\tKL_Divergence = 0.023188\n",
      "Epoch: 49\tFidelity = 0.932400\tKL_Divergence = 0.027105\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:52:31,469] Trial 21 finished with value: 0.022107857523616638 and parameters: {'lr': 7.238422976431698, 'pbs': 10000, 'nbs': 3000}. Best is trial 16 with value: 0.02150957396361379.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.938195\tKL_Divergence = 0.022108\n",
      "Total time elapsed during training: 311.020 s\n",
      "Trial 21 finished with value: 0.022107857523616638 and parameters: {'lr': 7.238422976431698, 'pbs': 10000, 'nbs': 3000}. Best is trial 16 with value: 0.02150957396361379.\n",
      "Trial 21 finished with value: 0.022107857523616638 and parameters: {'lr': 7.238422976431698, 'pbs': 10000, 'nbs': 3000}. Best is trial 16 with value: 0.02150957396361379.\n",
      "Trial 21 finished with value: 0.022107857523616638 and parameters: {'lr': 7.238422976431698, 'pbs': 10000, 'nbs': 3000}. Best is trial 16 with value: 0.02150957396361379.\n",
      "Trial 21 finished with value: 0.022107857523616638 and parameters: {'lr': 7.238422976431698, 'pbs': 10000, 'nbs': 3000}. Best is trial 16 with value: 0.02150957396361379.\n",
      "Trial 21 finished with value: 0.022107857523616638 and parameters: {'lr': 7.238422976431698, 'pbs': 10000, 'nbs': 3000}. Best is trial 16 with value: 0.02150957396361379.\n",
      "Trial 21 finished with value: 0.022107857523616638 and parameters: {'lr': 7.238422976431698, 'pbs': 10000, 'nbs': 3000}. Best is trial 16 with value: 0.02150957396361379.\n",
      "Epoch: 1\tFidelity = 0.933367\tKL_Divergence = 0.026106\n",
      "Epoch: 2\tFidelity = 0.936897\tKL_Divergence = 0.024151\n",
      "Epoch: 3\tFidelity = 0.935424\tKL_Divergence = 0.022611\n",
      "Epoch: 4\tFidelity = 0.936625\tKL_Divergence = 0.022815\n",
      "Epoch: 5\tFidelity = 0.937196\tKL_Divergence = 0.021800\n",
      "Epoch: 6\tFidelity = 0.937585\tKL_Divergence = 0.021431\n",
      "Epoch: 7\tFidelity = 0.937459\tKL_Divergence = 0.021575\n",
      "Epoch: 8\tFidelity = 0.936215\tKL_Divergence = 0.021988\n",
      "Epoch: 9\tFidelity = 0.936722\tKL_Divergence = 0.021763\n",
      "Epoch: 10\tFidelity = 0.933993\tKL_Divergence = 0.023826\n",
      "Epoch: 11\tFidelity = 0.936454\tKL_Divergence = 0.021922\n",
      "Epoch: 12\tFidelity = 0.935369\tKL_Divergence = 0.024585\n",
      "Epoch: 13\tFidelity = 0.936196\tKL_Divergence = 0.023515\n",
      "Epoch: 14\tFidelity = 0.935948\tKL_Divergence = 0.022223\n",
      "Epoch: 15\tFidelity = 0.935063\tKL_Divergence = 0.023788\n",
      "Epoch: 16\tFidelity = 0.932251\tKL_Divergence = 0.026617\n",
      "Epoch: 17\tFidelity = 0.934106\tKL_Divergence = 0.026449\n",
      "Epoch: 18\tFidelity = 0.932790\tKL_Divergence = 0.025876\n",
      "Epoch: 19\tFidelity = 0.933938\tKL_Divergence = 0.023635\n",
      "Epoch: 20\tFidelity = 0.934057\tKL_Divergence = 0.023313\n",
      "Epoch: 21\tFidelity = 0.936241\tKL_Divergence = 0.023069\n",
      "Epoch: 22\tFidelity = 0.932948\tKL_Divergence = 0.023582\n",
      "Epoch: 23\tFidelity = 0.934423\tKL_Divergence = 0.024066\n",
      "Epoch: 24\tFidelity = 0.934852\tKL_Divergence = 0.023631\n",
      "Epoch: 25\tFidelity = 0.937975\tKL_Divergence = 0.022047\n",
      "Epoch: 26\tFidelity = 0.938303\tKL_Divergence = 0.022011\n",
      "Epoch: 27\tFidelity = 0.937702\tKL_Divergence = 0.022275\n",
      "Epoch: 28\tFidelity = 0.937896\tKL_Divergence = 0.021726\n",
      "Epoch: 29\tFidelity = 0.936613\tKL_Divergence = 0.022352\n",
      "Epoch: 30\tFidelity = 0.937322\tKL_Divergence = 0.021429\n",
      "Epoch: 31\tFidelity = 0.936887\tKL_Divergence = 0.021811\n",
      "Epoch: 32\tFidelity = 0.937232\tKL_Divergence = 0.021587\n",
      "Epoch: 33\tFidelity = 0.936342\tKL_Divergence = 0.022195\n",
      "Epoch: 34\tFidelity = 0.935516\tKL_Divergence = 0.022981\n",
      "Epoch: 35\tFidelity = 0.935640\tKL_Divergence = 0.022354\n",
      "Epoch: 36\tFidelity = 0.937100\tKL_Divergence = 0.021718\n",
      "Epoch: 37\tFidelity = 0.931288\tKL_Divergence = 0.026395\n",
      "Epoch: 38\tFidelity = 0.926741\tKL_Divergence = 0.028501\n",
      "Epoch: 39\tFidelity = 0.936871\tKL_Divergence = 0.021999\n",
      "Epoch: 40\tFidelity = 0.932397\tKL_Divergence = 0.024077\n",
      "Epoch: 41\tFidelity = 0.934310\tKL_Divergence = 0.025343\n",
      "Epoch: 42\tFidelity = 0.933951\tKL_Divergence = 0.024569\n",
      "Epoch: 43\tFidelity = 0.934513\tKL_Divergence = 0.022650\n",
      "Epoch: 44\tFidelity = 0.932222\tKL_Divergence = 0.026963\n",
      "Epoch: 45\tFidelity = 0.935681\tKL_Divergence = 0.022964\n",
      "Epoch: 46\tFidelity = 0.927039\tKL_Divergence = 0.032517\n",
      "Epoch: 47\tFidelity = 0.934296\tKL_Divergence = 0.023393\n",
      "Epoch: 48\tFidelity = 0.929975\tKL_Divergence = 0.025682\n",
      "Epoch: 49\tFidelity = 0.934660\tKL_Divergence = 0.023227\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:57:36,917] Trial 22 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.933069\tKL_Divergence = 0.023315\n",
      "Total time elapsed during training: 305.093 s\n",
      "Trial 22 pruned. \n",
      "Trial 22 pruned. \n",
      "Trial 22 pruned. \n",
      "Trial 22 pruned. \n",
      "Trial 22 pruned. \n",
      "Trial 22 pruned. \n",
      "Epoch: 1\tFidelity = 0.930410\tKL_Divergence = 0.032900\n",
      "Epoch: 2\tFidelity = 0.923076\tKL_Divergence = 0.040928\n",
      "Epoch: 3\tFidelity = 0.934102\tKL_Divergence = 0.026931\n",
      "Epoch: 4\tFidelity = 0.936251\tKL_Divergence = 0.022523\n",
      "Epoch: 5\tFidelity = 0.931650\tKL_Divergence = 0.026092\n",
      "Epoch: 6\tFidelity = 0.936188\tKL_Divergence = 0.022216\n",
      "Epoch: 7\tFidelity = 0.933027\tKL_Divergence = 0.023958\n",
      "Epoch: 8\tFidelity = 0.933943\tKL_Divergence = 0.023085\n",
      "Epoch: 9\tFidelity = 0.929287\tKL_Divergence = 0.026903\n",
      "Epoch: 10\tFidelity = 0.931651\tKL_Divergence = 0.025484\n",
      "Epoch: 11\tFidelity = 0.934830\tKL_Divergence = 0.022924\n",
      "Epoch: 12\tFidelity = 0.934259\tKL_Divergence = 0.027481\n",
      "Epoch: 13\tFidelity = 0.937636\tKL_Divergence = 0.022133\n",
      "Epoch: 14\tFidelity = 0.934938\tKL_Divergence = 0.025567\n",
      "Epoch: 15\tFidelity = 0.937857\tKL_Divergence = 0.021878\n",
      "Epoch: 16\tFidelity = 0.935282\tKL_Divergence = 0.024742\n",
      "Epoch: 17\tFidelity = 0.936535\tKL_Divergence = 0.024504\n",
      "Epoch: 18\tFidelity = 0.936840\tKL_Divergence = 0.022660\n",
      "Epoch: 19\tFidelity = 0.929885\tKL_Divergence = 0.027238\n",
      "Epoch: 20\tFidelity = 0.936773\tKL_Divergence = 0.022014\n",
      "Epoch: 21\tFidelity = 0.938518\tKL_Divergence = 0.020997\n",
      "Epoch: 22\tFidelity = 0.931540\tKL_Divergence = 0.024176\n",
      "Epoch: 23\tFidelity = 0.937539\tKL_Divergence = 0.022040\n",
      "Epoch: 24\tFidelity = 0.936630\tKL_Divergence = 0.022795\n",
      "Epoch: 25\tFidelity = 0.937636\tKL_Divergence = 0.021304\n",
      "Epoch: 26\tFidelity = 0.934588\tKL_Divergence = 0.022694\n",
      "Epoch: 27\tFidelity = 0.938055\tKL_Divergence = 0.021237\n",
      "Epoch: 28\tFidelity = 0.934785\tKL_Divergence = 0.026612\n",
      "Epoch: 29\tFidelity = 0.935750\tKL_Divergence = 0.024797\n",
      "Epoch: 30\tFidelity = 0.937584\tKL_Divergence = 0.021658\n",
      "Epoch: 31\tFidelity = 0.935598\tKL_Divergence = 0.027160\n",
      "Epoch: 32\tFidelity = 0.935415\tKL_Divergence = 0.024003\n",
      "Epoch: 33\tFidelity = 0.935233\tKL_Divergence = 0.025117\n",
      "Epoch: 34\tFidelity = 0.936204\tKL_Divergence = 0.022607\n",
      "Epoch: 35\tFidelity = 0.937094\tKL_Divergence = 0.022423\n",
      "Epoch: 36\tFidelity = 0.938360\tKL_Divergence = 0.021142\n",
      "Epoch: 37\tFidelity = 0.938115\tKL_Divergence = 0.021198\n",
      "Epoch: 38\tFidelity = 0.931794\tKL_Divergence = 0.024109\n",
      "Epoch: 39\tFidelity = 0.937338\tKL_Divergence = 0.022154\n",
      "Epoch: 40\tFidelity = 0.938290\tKL_Divergence = 0.022420\n",
      "Epoch: 41\tFidelity = 0.937244\tKL_Divergence = 0.022829\n",
      "Epoch: 42\tFidelity = 0.935043\tKL_Divergence = 0.024662\n",
      "Epoch: 43\tFidelity = 0.937021\tKL_Divergence = 0.021832\n",
      "Epoch: 44\tFidelity = 0.937265\tKL_Divergence = 0.022583\n",
      "Epoch: 45\tFidelity = 0.933959\tKL_Divergence = 0.025496\n",
      "Epoch: 46\tFidelity = 0.936753\tKL_Divergence = 0.021811\n",
      "Epoch: 47\tFidelity = 0.937169\tKL_Divergence = 0.022767\n",
      "Epoch: 48\tFidelity = 0.933629\tKL_Divergence = 0.025656\n",
      "Epoch: 49\tFidelity = 0.933023\tKL_Divergence = 0.023528\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:02:50,032] Trial 23 finished with value: 0.022092955163967042 and parameters: {'lr': 7.5030704050824975, 'pbs': 10000, 'nbs': 3000}. Best is trial 16 with value: 0.02150957396361379.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.936900\tKL_Divergence = 0.022093\n",
      "Total time elapsed during training: 312.796 s\n",
      "Trial 23 finished with value: 0.022092955163967042 and parameters: {'lr': 7.5030704050824975, 'pbs': 10000, 'nbs': 3000}. Best is trial 16 with value: 0.02150957396361379.\n",
      "Trial 23 finished with value: 0.022092955163967042 and parameters: {'lr': 7.5030704050824975, 'pbs': 10000, 'nbs': 3000}. Best is trial 16 with value: 0.02150957396361379.\n",
      "Trial 23 finished with value: 0.022092955163967042 and parameters: {'lr': 7.5030704050824975, 'pbs': 10000, 'nbs': 3000}. Best is trial 16 with value: 0.02150957396361379.\n",
      "Trial 23 finished with value: 0.022092955163967042 and parameters: {'lr': 7.5030704050824975, 'pbs': 10000, 'nbs': 3000}. Best is trial 16 with value: 0.02150957396361379.\n",
      "Trial 23 finished with value: 0.022092955163967042 and parameters: {'lr': 7.5030704050824975, 'pbs': 10000, 'nbs': 3000}. Best is trial 16 with value: 0.02150957396361379.\n",
      "Trial 23 finished with value: 0.022092955163967042 and parameters: {'lr': 7.5030704050824975, 'pbs': 10000, 'nbs': 3000}. Best is trial 16 with value: 0.02150957396361379.\n",
      "Epoch: 1\tFidelity = 0.931948\tKL_Divergence = 0.029437\n",
      "Epoch: 2\tFidelity = 0.937417\tKL_Divergence = 0.021614\n",
      "Epoch: 3\tFidelity = 0.936455\tKL_Divergence = 0.025785\n",
      "Epoch: 4\tFidelity = 0.936041\tKL_Divergence = 0.023052\n",
      "Epoch: 5\tFidelity = 0.937540\tKL_Divergence = 0.023379\n",
      "Epoch: 6\tFidelity = 0.937723\tKL_Divergence = 0.021732\n",
      "Epoch: 7\tFidelity = 0.937935\tKL_Divergence = 0.022263\n",
      "Epoch: 8\tFidelity = 0.937104\tKL_Divergence = 0.022782\n",
      "Epoch: 9\tFidelity = 0.932581\tKL_Divergence = 0.026874\n",
      "Epoch: 10\tFidelity = 0.936073\tKL_Divergence = 0.022243\n",
      "Epoch: 11\tFidelity = 0.932503\tKL_Divergence = 0.024895\n",
      "Epoch: 12\tFidelity = 0.935725\tKL_Divergence = 0.024676\n",
      "Epoch: 13\tFidelity = 0.935527\tKL_Divergence = 0.022396\n",
      "Epoch: 14\tFidelity = 0.936215\tKL_Divergence = 0.022651\n",
      "Epoch: 15\tFidelity = 0.932545\tKL_Divergence = 0.023754\n",
      "Epoch: 16\tFidelity = 0.929174\tKL_Divergence = 0.028673\n",
      "Epoch: 17\tFidelity = 0.934972\tKL_Divergence = 0.022941\n",
      "Epoch: 18\tFidelity = 0.933070\tKL_Divergence = 0.026524\n",
      "Epoch: 19\tFidelity = 0.932586\tKL_Divergence = 0.026712\n",
      "Epoch: 20\tFidelity = 0.934141\tKL_Divergence = 0.028319\n",
      "Epoch: 21\tFidelity = 0.935382\tKL_Divergence = 0.022613\n",
      "Epoch: 22\tFidelity = 0.929632\tKL_Divergence = 0.030522\n",
      "Epoch: 23\tFidelity = 0.934332\tKL_Divergence = 0.023268\n",
      "Epoch: 24\tFidelity = 0.933929\tKL_Divergence = 0.027406\n",
      "Epoch: 25\tFidelity = 0.932615\tKL_Divergence = 0.028106\n",
      "Epoch: 26\tFidelity = 0.936320\tKL_Divergence = 0.022287\n",
      "Epoch: 27\tFidelity = 0.935406\tKL_Divergence = 0.023474\n",
      "Epoch: 28\tFidelity = 0.935833\tKL_Divergence = 0.023404\n",
      "Epoch: 29\tFidelity = 0.933398\tKL_Divergence = 0.024613\n",
      "Epoch: 30\tFidelity = 0.931838\tKL_Divergence = 0.026489\n",
      "Epoch: 31\tFidelity = 0.933087\tKL_Divergence = 0.024706\n",
      "Epoch: 32\tFidelity = 0.932404\tKL_Divergence = 0.025550\n",
      "Epoch: 33\tFidelity = 0.932132\tKL_Divergence = 0.024091\n",
      "Epoch: 34\tFidelity = 0.933751\tKL_Divergence = 0.024134\n",
      "Epoch: 35\tFidelity = 0.934617\tKL_Divergence = 0.022977\n",
      "Epoch: 36\tFidelity = 0.934692\tKL_Divergence = 0.026090\n",
      "Epoch: 37\tFidelity = 0.934582\tKL_Divergence = 0.023932\n",
      "Epoch: 38\tFidelity = 0.932857\tKL_Divergence = 0.026021\n",
      "Epoch: 39\tFidelity = 0.935065\tKL_Divergence = 0.023810\n",
      "Epoch: 40\tFidelity = 0.931592\tKL_Divergence = 0.028745\n",
      "Epoch: 41\tFidelity = 0.937038\tKL_Divergence = 0.023858\n",
      "Epoch: 42\tFidelity = 0.935138\tKL_Divergence = 0.023238\n",
      "Epoch: 43\tFidelity = 0.931291\tKL_Divergence = 0.025560\n",
      "Epoch: 44\tFidelity = 0.935181\tKL_Divergence = 0.023374\n",
      "Epoch: 45\tFidelity = 0.936045\tKL_Divergence = 0.022326\n",
      "Epoch: 46\tFidelity = 0.935294\tKL_Divergence = 0.022503\n",
      "Epoch: 47\tFidelity = 0.934762\tKL_Divergence = 0.023454\n",
      "Epoch: 48\tFidelity = 0.936997\tKL_Divergence = 0.022479\n",
      "Epoch: 49\tFidelity = 0.935187\tKL_Divergence = 0.023715\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:07:51,483] Trial 24 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.934636\tKL_Divergence = 0.024384\n",
      "Total time elapsed during training: 301.124 s\n",
      "Trial 24 pruned. \n",
      "Trial 24 pruned. \n",
      "Trial 24 pruned. \n",
      "Trial 24 pruned. \n",
      "Trial 24 pruned. \n",
      "Trial 24 pruned. \n",
      "Epoch: 1\tFidelity = 0.932879\tKL_Divergence = 0.024464\n",
      "Epoch: 2\tFidelity = 0.934600\tKL_Divergence = 0.023600\n",
      "Epoch: 3\tFidelity = 0.930406\tKL_Divergence = 0.026476\n",
      "Epoch: 4\tFidelity = 0.933863\tKL_Divergence = 0.023666\n",
      "Epoch: 5\tFidelity = 0.931361\tKL_Divergence = 0.025830\n",
      "Epoch: 6\tFidelity = 0.930938\tKL_Divergence = 0.024446\n",
      "Epoch: 7\tFidelity = 0.933763\tKL_Divergence = 0.023650\n",
      "Epoch: 8\tFidelity = 0.935563\tKL_Divergence = 0.022500\n",
      "Epoch: 9\tFidelity = 0.935997\tKL_Divergence = 0.022498\n",
      "Epoch: 10\tFidelity = 0.934942\tKL_Divergence = 0.022903\n",
      "Epoch: 11\tFidelity = 0.933019\tKL_Divergence = 0.024435\n",
      "Epoch: 12\tFidelity = 0.932292\tKL_Divergence = 0.025907\n",
      "Epoch: 13\tFidelity = 0.931995\tKL_Divergence = 0.024671\n",
      "Epoch: 14\tFidelity = 0.935321\tKL_Divergence = 0.023772\n",
      "Epoch: 15\tFidelity = 0.934659\tKL_Divergence = 0.023688\n",
      "Epoch: 16\tFidelity = 0.935008\tKL_Divergence = 0.022666\n",
      "Epoch: 17\tFidelity = 0.935801\tKL_Divergence = 0.022253\n",
      "Epoch: 18\tFidelity = 0.937185\tKL_Divergence = 0.021582\n",
      "Epoch: 19\tFidelity = 0.931009\tKL_Divergence = 0.030401\n",
      "Epoch: 20\tFidelity = 0.932884\tKL_Divergence = 0.024092\n",
      "Epoch: 21\tFidelity = 0.937454\tKL_Divergence = 0.021426\n",
      "Epoch: 22\tFidelity = 0.936568\tKL_Divergence = 0.021924\n",
      "Epoch: 23\tFidelity = 0.936664\tKL_Divergence = 0.022230\n",
      "Epoch: 24\tFidelity = 0.938401\tKL_Divergence = 0.021253\n",
      "Epoch: 25\tFidelity = 0.933846\tKL_Divergence = 0.023119\n",
      "Epoch: 26\tFidelity = 0.937675\tKL_Divergence = 0.021287\n",
      "Epoch: 27\tFidelity = 0.934637\tKL_Divergence = 0.023065\n",
      "Epoch: 28\tFidelity = 0.936149\tKL_Divergence = 0.022615\n",
      "Epoch: 29\tFidelity = 0.934654\tKL_Divergence = 0.024293\n",
      "Epoch: 30\tFidelity = 0.934047\tKL_Divergence = 0.022830\n",
      "Epoch: 31\tFidelity = 0.935447\tKL_Divergence = 0.022929\n",
      "Epoch: 32\tFidelity = 0.936209\tKL_Divergence = 0.022930\n",
      "Epoch: 33\tFidelity = 0.930011\tKL_Divergence = 0.032559\n",
      "Epoch: 34\tFidelity = 0.936438\tKL_Divergence = 0.022043\n",
      "Epoch: 35\tFidelity = 0.937609\tKL_Divergence = 0.021322\n",
      "Epoch: 36\tFidelity = 0.934556\tKL_Divergence = 0.023685\n",
      "Epoch: 37\tFidelity = 0.936659\tKL_Divergence = 0.022168\n",
      "Epoch: 38\tFidelity = 0.933935\tKL_Divergence = 0.023778\n",
      "Epoch: 39\tFidelity = 0.933849\tKL_Divergence = 0.023077\n",
      "Epoch: 40\tFidelity = 0.931540\tKL_Divergence = 0.028705\n",
      "Epoch: 41\tFidelity = 0.936927\tKL_Divergence = 0.022037\n",
      "Epoch: 42\tFidelity = 0.937510\tKL_Divergence = 0.023889\n",
      "Epoch: 43\tFidelity = 0.935174\tKL_Divergence = 0.023974\n",
      "Epoch: 44\tFidelity = 0.936520\tKL_Divergence = 0.022800\n",
      "Epoch: 45\tFidelity = 0.935160\tKL_Divergence = 0.023448\n",
      "Epoch: 46\tFidelity = 0.932185\tKL_Divergence = 0.024872\n",
      "Epoch: 47\tFidelity = 0.932021\tKL_Divergence = 0.023852\n",
      "Epoch: 48\tFidelity = 0.934704\tKL_Divergence = 0.022732\n",
      "Epoch: 49\tFidelity = 0.932346\tKL_Divergence = 0.023934\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:14:13,191] Trial 25 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.934479\tKL_Divergence = 0.023480\n",
      "Total time elapsed during training: 381.394 s\n",
      "Trial 25 pruned. \n",
      "Trial 25 pruned. \n",
      "Trial 25 pruned. \n",
      "Trial 25 pruned. \n",
      "Trial 25 pruned. \n",
      "Trial 25 pruned. \n",
      "Epoch: 1\tFidelity = 0.930801\tKL_Divergence = 0.025075\n",
      "Epoch: 2\tFidelity = 0.935194\tKL_Divergence = 0.023262\n",
      "Epoch: 3\tFidelity = 0.932438\tKL_Divergence = 0.023661\n",
      "Epoch: 4\tFidelity = 0.936093\tKL_Divergence = 0.022417\n",
      "Epoch: 5\tFidelity = 0.936393\tKL_Divergence = 0.022043\n",
      "Epoch: 6\tFidelity = 0.933433\tKL_Divergence = 0.025415\n",
      "Epoch: 7\tFidelity = 0.932667\tKL_Divergence = 0.023703\n",
      "Epoch: 8\tFidelity = 0.928505\tKL_Divergence = 0.034058\n",
      "Epoch: 9\tFidelity = 0.934143\tKL_Divergence = 0.023803\n",
      "Epoch: 10\tFidelity = 0.934623\tKL_Divergence = 0.030101\n",
      "Epoch: 11\tFidelity = 0.932420\tKL_Divergence = 0.027731\n",
      "Epoch: 12\tFidelity = 0.936920\tKL_Divergence = 0.022721\n",
      "Epoch: 13\tFidelity = 0.937944\tKL_Divergence = 0.022368\n",
      "Epoch: 14\tFidelity = 0.934901\tKL_Divergence = 0.025899\n",
      "Epoch: 15\tFidelity = 0.929336\tKL_Divergence = 0.032414\n",
      "Epoch: 16\tFidelity = 0.936901\tKL_Divergence = 0.022020\n",
      "Epoch: 17\tFidelity = 0.933739\tKL_Divergence = 0.024272\n",
      "Epoch: 18\tFidelity = 0.936058\tKL_Divergence = 0.022213\n",
      "Epoch: 19\tFidelity = 0.934911\tKL_Divergence = 0.023910\n",
      "Epoch: 20\tFidelity = 0.936528\tKL_Divergence = 0.022209\n",
      "Epoch: 21\tFidelity = 0.928125\tKL_Divergence = 0.027867\n",
      "Epoch: 22\tFidelity = 0.932531\tKL_Divergence = 0.024150\n",
      "Epoch: 23\tFidelity = 0.933946\tKL_Divergence = 0.027870\n",
      "Epoch: 24\tFidelity = 0.935076\tKL_Divergence = 0.025901\n",
      "Epoch: 25\tFidelity = 0.931284\tKL_Divergence = 0.028000\n",
      "Epoch: 26\tFidelity = 0.925749\tKL_Divergence = 0.026868\n",
      "Epoch: 27\tFidelity = 0.933439\tKL_Divergence = 0.026355\n",
      "Epoch: 28\tFidelity = 0.931734\tKL_Divergence = 0.025814\n",
      "Epoch: 29\tFidelity = 0.932818\tKL_Divergence = 0.024001\n",
      "Epoch: 30\tFidelity = 0.937408\tKL_Divergence = 0.021782\n",
      "Epoch: 31\tFidelity = 0.935956\tKL_Divergence = 0.023556\n",
      "Epoch: 32\tFidelity = 0.934595\tKL_Divergence = 0.023498\n",
      "Epoch: 33\tFidelity = 0.935522\tKL_Divergence = 0.022872\n",
      "Epoch: 34\tFidelity = 0.936916\tKL_Divergence = 0.021898\n",
      "Epoch: 35\tFidelity = 0.936336\tKL_Divergence = 0.023294\n",
      "Epoch: 36\tFidelity = 0.934654\tKL_Divergence = 0.022673\n",
      "Epoch: 37\tFidelity = 0.937837\tKL_Divergence = 0.021580\n",
      "Epoch: 38\tFidelity = 0.936247\tKL_Divergence = 0.026387\n",
      "Epoch: 39\tFidelity = 0.929535\tKL_Divergence = 0.028005\n",
      "Epoch: 40\tFidelity = 0.932914\tKL_Divergence = 0.025490\n",
      "Epoch: 41\tFidelity = 0.932740\tKL_Divergence = 0.032572\n",
      "Epoch: 42\tFidelity = 0.933787\tKL_Divergence = 0.026854\n",
      "Epoch: 43\tFidelity = 0.936044\tKL_Divergence = 0.025316\n",
      "Epoch: 44\tFidelity = 0.931987\tKL_Divergence = 0.024307\n",
      "Epoch: 45\tFidelity = 0.927785\tKL_Divergence = 0.026932\n",
      "Epoch: 46\tFidelity = 0.929618\tKL_Divergence = 0.026017\n",
      "Epoch: 47\tFidelity = 0.926520\tKL_Divergence = 0.026654\n",
      "Epoch: 48\tFidelity = 0.937278\tKL_Divergence = 0.021979\n",
      "Epoch: 49\tFidelity = 0.932903\tKL_Divergence = 0.026901\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:20:16,019] Trial 26 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.936011\tKL_Divergence = 0.024155\n",
      "Total time elapsed during training: 362.498 s\n",
      "Trial 26 pruned. \n",
      "Trial 26 pruned. \n",
      "Trial 26 pruned. \n",
      "Trial 26 pruned. \n",
      "Trial 26 pruned. \n",
      "Trial 26 pruned. \n",
      "Epoch: 1\tFidelity = 0.935478\tKL_Divergence = 0.023174\n",
      "Epoch: 2\tFidelity = 0.935512\tKL_Divergence = 0.023074\n",
      "Epoch: 3\tFidelity = 0.935228\tKL_Divergence = 0.024750\n",
      "Epoch: 4\tFidelity = 0.936023\tKL_Divergence = 0.022442\n",
      "Epoch: 5\tFidelity = 0.936182\tKL_Divergence = 0.022602\n",
      "Epoch: 6\tFidelity = 0.931323\tKL_Divergence = 0.025459\n",
      "Epoch: 7\tFidelity = 0.934263\tKL_Divergence = 0.023189\n",
      "Epoch: 8\tFidelity = 0.932008\tKL_Divergence = 0.026982\n",
      "Epoch: 9\tFidelity = 0.933643\tKL_Divergence = 0.025100\n",
      "Epoch: 10\tFidelity = 0.933076\tKL_Divergence = 0.023723\n",
      "Epoch: 11\tFidelity = 0.934870\tKL_Divergence = 0.024287\n",
      "Epoch: 12\tFidelity = 0.934234\tKL_Divergence = 0.023841\n",
      "Epoch: 13\tFidelity = 0.935561\tKL_Divergence = 0.022787\n",
      "Epoch: 14\tFidelity = 0.937148\tKL_Divergence = 0.021773\n",
      "Epoch: 15\tFidelity = 0.937392\tKL_Divergence = 0.021779\n",
      "Epoch: 16\tFidelity = 0.935934\tKL_Divergence = 0.022868\n",
      "Epoch: 17\tFidelity = 0.936113\tKL_Divergence = 0.025119\n",
      "Epoch: 18\tFidelity = 0.936920\tKL_Divergence = 0.022895\n",
      "Epoch: 19\tFidelity = 0.938213\tKL_Divergence = 0.021207\n",
      "Epoch: 20\tFidelity = 0.937925\tKL_Divergence = 0.021365\n",
      "Epoch: 21\tFidelity = 0.935772\tKL_Divergence = 0.023041\n",
      "Epoch: 22\tFidelity = 0.932767\tKL_Divergence = 0.024623\n",
      "Epoch: 23\tFidelity = 0.936378\tKL_Divergence = 0.022519\n",
      "Epoch: 24\tFidelity = 0.933378\tKL_Divergence = 0.025486\n",
      "Epoch: 25\tFidelity = 0.930125\tKL_Divergence = 0.029790\n",
      "Epoch: 26\tFidelity = 0.933951\tKL_Divergence = 0.026235\n",
      "Epoch: 27\tFidelity = 0.933573\tKL_Divergence = 0.026396\n",
      "Epoch: 28\tFidelity = 0.936669\tKL_Divergence = 0.022084\n",
      "Epoch: 29\tFidelity = 0.932973\tKL_Divergence = 0.028294\n",
      "Epoch: 30\tFidelity = 0.933019\tKL_Divergence = 0.023813\n",
      "Epoch: 31\tFidelity = 0.935163\tKL_Divergence = 0.022676\n",
      "Epoch: 32\tFidelity = 0.932947\tKL_Divergence = 0.024232\n",
      "Epoch: 33\tFidelity = 0.930119\tKL_Divergence = 0.025291\n",
      "Epoch: 34\tFidelity = 0.936556\tKL_Divergence = 0.022546\n",
      "Epoch: 35\tFidelity = 0.934844\tKL_Divergence = 0.023213\n",
      "Epoch: 36\tFidelity = 0.935314\tKL_Divergence = 0.023306\n",
      "Epoch: 37\tFidelity = 0.930677\tKL_Divergence = 0.025937\n",
      "Epoch: 38\tFidelity = 0.933917\tKL_Divergence = 0.023147\n",
      "Epoch: 39\tFidelity = 0.935473\tKL_Divergence = 0.022863\n",
      "Epoch: 40\tFidelity = 0.934567\tKL_Divergence = 0.023337\n",
      "Epoch: 41\tFidelity = 0.934710\tKL_Divergence = 0.022928\n",
      "Epoch: 42\tFidelity = 0.937084\tKL_Divergence = 0.021741\n",
      "Epoch: 43\tFidelity = 0.931783\tKL_Divergence = 0.026657\n",
      "Epoch: 44\tFidelity = 0.936266\tKL_Divergence = 0.022720\n",
      "Epoch: 45\tFidelity = 0.934144\tKL_Divergence = 0.023593\n",
      "Epoch: 46\tFidelity = 0.931792\tKL_Divergence = 0.026530\n",
      "Epoch: 47\tFidelity = 0.933935\tKL_Divergence = 0.023714\n",
      "Epoch: 48\tFidelity = 0.934807\tKL_Divergence = 0.022924\n",
      "Epoch: 49\tFidelity = 0.933332\tKL_Divergence = 0.023625\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:27:12,510] Trial 27 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.937403\tKL_Divergence = 0.023046\n",
      "Total time elapsed during training: 416.181 s\n",
      "Trial 27 pruned. \n",
      "Trial 27 pruned. \n",
      "Trial 27 pruned. \n",
      "Trial 27 pruned. \n",
      "Trial 27 pruned. \n",
      "Trial 27 pruned. \n",
      "Epoch: 1\tFidelity = 0.932499\tKL_Divergence = 0.023657\n",
      "Epoch: 2\tFidelity = 0.933526\tKL_Divergence = 0.026245\n",
      "Epoch: 3\tFidelity = 0.933478\tKL_Divergence = 0.023231\n",
      "Epoch: 4\tFidelity = 0.932486\tKL_Divergence = 0.025238\n",
      "Epoch: 5\tFidelity = 0.935755\tKL_Divergence = 0.022290\n",
      "Epoch: 6\tFidelity = 0.936243\tKL_Divergence = 0.022052\n",
      "Epoch: 7\tFidelity = 0.929682\tKL_Divergence = 0.026715\n",
      "Epoch: 8\tFidelity = 0.934043\tKL_Divergence = 0.024658\n",
      "Epoch: 9\tFidelity = 0.931287\tKL_Divergence = 0.027166\n",
      "Epoch: 10\tFidelity = 0.935505\tKL_Divergence = 0.023231\n",
      "Epoch: 11\tFidelity = 0.934660\tKL_Divergence = 0.024505\n",
      "Epoch: 12\tFidelity = 0.932573\tKL_Divergence = 0.026489\n",
      "Epoch: 13\tFidelity = 0.933959\tKL_Divergence = 0.028083\n",
      "Epoch: 14\tFidelity = 0.931993\tKL_Divergence = 0.027149\n",
      "Epoch: 15\tFidelity = 0.931647\tKL_Divergence = 0.030886\n",
      "Epoch: 16\tFidelity = 0.928862\tKL_Divergence = 0.026049\n",
      "Epoch: 17\tFidelity = 0.935516\tKL_Divergence = 0.023723\n",
      "Epoch: 18\tFidelity = 0.935006\tKL_Divergence = 0.022805\n",
      "Epoch: 19\tFidelity = 0.932925\tKL_Divergence = 0.023841\n",
      "Epoch: 20\tFidelity = 0.931070\tKL_Divergence = 0.025517\n",
      "Epoch: 21\tFidelity = 0.931217\tKL_Divergence = 0.025100\n",
      "Epoch: 22\tFidelity = 0.926213\tKL_Divergence = 0.030097\n",
      "Epoch: 23\tFidelity = 0.932664\tKL_Divergence = 0.025338\n",
      "Epoch: 24\tFidelity = 0.936339\tKL_Divergence = 0.023078\n",
      "Epoch: 25\tFidelity = 0.935018\tKL_Divergence = 0.026502\n",
      "Epoch: 26\tFidelity = 0.937578\tKL_Divergence = 0.021958\n",
      "Epoch: 27\tFidelity = 0.935293\tKL_Divergence = 0.023733\n",
      "Epoch: 28\tFidelity = 0.936293\tKL_Divergence = 0.023072\n",
      "Epoch: 29\tFidelity = 0.932504\tKL_Divergence = 0.024230\n",
      "Epoch: 30\tFidelity = 0.931442\tKL_Divergence = 0.028300\n",
      "Epoch: 31\tFidelity = 0.931254\tKL_Divergence = 0.031997\n",
      "Epoch: 32\tFidelity = 0.935525\tKL_Divergence = 0.022544\n",
      "Epoch: 33\tFidelity = 0.935986\tKL_Divergence = 0.022603\n",
      "Epoch: 34\tFidelity = 0.934002\tKL_Divergence = 0.026232\n",
      "Epoch: 35\tFidelity = 0.936072\tKL_Divergence = 0.022594\n",
      "Epoch: 36\tFidelity = 0.933742\tKL_Divergence = 0.027051\n",
      "Epoch: 37\tFidelity = 0.933334\tKL_Divergence = 0.026917\n",
      "Epoch: 38\tFidelity = 0.933250\tKL_Divergence = 0.025418\n",
      "Epoch: 39\tFidelity = 0.932661\tKL_Divergence = 0.023948\n",
      "Epoch: 40\tFidelity = 0.937206\tKL_Divergence = 0.021994\n",
      "Epoch: 41\tFidelity = 0.934126\tKL_Divergence = 0.024845\n",
      "Epoch: 42\tFidelity = 0.935039\tKL_Divergence = 0.023157\n",
      "Epoch: 43\tFidelity = 0.934347\tKL_Divergence = 0.024206\n",
      "Epoch: 44\tFidelity = 0.933701\tKL_Divergence = 0.023363\n",
      "Epoch: 45\tFidelity = 0.931910\tKL_Divergence = 0.024837\n",
      "Epoch: 46\tFidelity = 0.930257\tKL_Divergence = 0.025118\n",
      "Epoch: 47\tFidelity = 0.933376\tKL_Divergence = 0.023667\n",
      "Epoch: 48\tFidelity = 0.936000\tKL_Divergence = 0.023194\n",
      "Epoch: 49\tFidelity = 0.935466\tKL_Divergence = 0.023940\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:32:18,593] Trial 28 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.935192\tKL_Divergence = 0.022950\n",
      "Total time elapsed during training: 305.744 s\n",
      "Trial 28 pruned. \n",
      "Trial 28 pruned. \n",
      "Trial 28 pruned. \n",
      "Trial 28 pruned. \n",
      "Trial 28 pruned. \n",
      "Trial 28 pruned. \n",
      "Epoch: 1\tFidelity = 0.932140\tKL_Divergence = 0.026475\n",
      "Epoch: 2\tFidelity = 0.933368\tKL_Divergence = 0.026137\n",
      "Epoch: 3\tFidelity = 0.935572\tKL_Divergence = 0.022329\n",
      "Epoch: 4\tFidelity = 0.934825\tKL_Divergence = 0.023093\n",
      "Epoch: 5\tFidelity = 0.935583\tKL_Divergence = 0.022291\n",
      "Epoch: 6\tFidelity = 0.935996\tKL_Divergence = 0.022160\n",
      "Epoch: 7\tFidelity = 0.935994\tKL_Divergence = 0.024070\n",
      "Epoch: 8\tFidelity = 0.934687\tKL_Divergence = 0.024030\n",
      "Epoch: 9\tFidelity = 0.932114\tKL_Divergence = 0.029120\n",
      "Epoch: 10\tFidelity = 0.937654\tKL_Divergence = 0.023814\n",
      "Epoch: 11\tFidelity = 0.937617\tKL_Divergence = 0.022326\n",
      "Epoch: 12\tFidelity = 0.938358\tKL_Divergence = 0.021111\n",
      "Epoch: 13\tFidelity = 0.936491\tKL_Divergence = 0.022544\n",
      "Epoch: 14\tFidelity = 0.935238\tKL_Divergence = 0.023717\n",
      "Epoch: 15\tFidelity = 0.938046\tKL_Divergence = 0.021214\n",
      "Epoch: 16\tFidelity = 0.934910\tKL_Divergence = 0.022825\n",
      "Epoch: 17\tFidelity = 0.936666\tKL_Divergence = 0.021669\n",
      "Epoch: 18\tFidelity = 0.934709\tKL_Divergence = 0.022699\n",
      "Epoch: 19\tFidelity = 0.939027\tKL_Divergence = 0.021380\n",
      "Epoch: 20\tFidelity = 0.937792\tKL_Divergence = 0.021735\n",
      "Epoch: 21\tFidelity = 0.930922\tKL_Divergence = 0.026214\n",
      "Epoch: 22\tFidelity = 0.936211\tKL_Divergence = 0.022008\n",
      "Epoch: 23\tFidelity = 0.937903\tKL_Divergence = 0.021929\n",
      "Epoch: 24\tFidelity = 0.936140\tKL_Divergence = 0.022207\n",
      "Epoch: 25\tFidelity = 0.934461\tKL_Divergence = 0.023059\n",
      "Epoch: 26\tFidelity = 0.932517\tKL_Divergence = 0.023737\n",
      "Epoch: 27\tFidelity = 0.935625\tKL_Divergence = 0.022354\n",
      "Epoch: 28\tFidelity = 0.931694\tKL_Divergence = 0.025467\n",
      "Epoch: 29\tFidelity = 0.928975\tKL_Divergence = 0.025357\n",
      "Epoch: 30\tFidelity = 0.935041\tKL_Divergence = 0.023643\n",
      "Epoch: 31\tFidelity = 0.935352\tKL_Divergence = 0.022999\n",
      "Epoch: 32\tFidelity = 0.936887\tKL_Divergence = 0.021880\n",
      "Epoch: 33\tFidelity = 0.935421\tKL_Divergence = 0.024001\n",
      "Epoch: 34\tFidelity = 0.931626\tKL_Divergence = 0.027570\n",
      "Epoch: 35\tFidelity = 0.934230\tKL_Divergence = 0.023109\n",
      "Epoch: 36\tFidelity = 0.934521\tKL_Divergence = 0.023318\n",
      "Epoch: 37\tFidelity = 0.933634\tKL_Divergence = 0.025209\n",
      "Epoch: 38\tFidelity = 0.931881\tKL_Divergence = 0.025632\n",
      "Epoch: 39\tFidelity = 0.933165\tKL_Divergence = 0.024019\n",
      "Epoch: 40\tFidelity = 0.930799\tKL_Divergence = 0.028573\n",
      "Epoch: 41\tFidelity = 0.935453\tKL_Divergence = 0.022410\n",
      "Epoch: 42\tFidelity = 0.935421\tKL_Divergence = 0.023018\n",
      "Epoch: 43\tFidelity = 0.936473\tKL_Divergence = 0.022809\n",
      "Epoch: 44\tFidelity = 0.936118\tKL_Divergence = 0.025869\n",
      "Epoch: 45\tFidelity = 0.934126\tKL_Divergence = 0.026320\n",
      "Epoch: 46\tFidelity = 0.934435\tKL_Divergence = 0.023268\n",
      "Epoch: 47\tFidelity = 0.936027\tKL_Divergence = 0.022729\n",
      "Epoch: 48\tFidelity = 0.936223\tKL_Divergence = 0.022726\n",
      "Epoch: 49\tFidelity = 0.934789\tKL_Divergence = 0.024415\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:39:16,142] Trial 29 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.933776\tKL_Divergence = 0.023570\n",
      "Total time elapsed during training: 417.227 s\n",
      "Trial 29 pruned. \n",
      "Trial 29 pruned. \n",
      "Trial 29 pruned. \n",
      "Trial 29 pruned. \n",
      "Trial 29 pruned. \n",
      "Trial 29 pruned. \n",
      "Epoch: 1\tFidelity = 0.931374\tKL_Divergence = 0.024913\n",
      "Epoch: 2\tFidelity = 0.933579\tKL_Divergence = 0.023937\n",
      "Epoch: 3\tFidelity = 0.933148\tKL_Divergence = 0.023675\n",
      "Epoch: 4\tFidelity = 0.934250\tKL_Divergence = 0.023076\n",
      "Epoch: 5\tFidelity = 0.931156\tKL_Divergence = 0.025061\n",
      "Epoch: 6\tFidelity = 0.933351\tKL_Divergence = 0.023775\n",
      "Epoch: 7\tFidelity = 0.932828\tKL_Divergence = 0.023837\n",
      "Epoch: 8\tFidelity = 0.934978\tKL_Divergence = 0.023755\n",
      "Epoch: 9\tFidelity = 0.934954\tKL_Divergence = 0.023739\n",
      "Epoch: 10\tFidelity = 0.935549\tKL_Divergence = 0.024088\n",
      "Epoch: 11\tFidelity = 0.930461\tKL_Divergence = 0.024986\n",
      "Epoch: 12\tFidelity = 0.932852\tKL_Divergence = 0.026278\n",
      "Epoch: 13\tFidelity = 0.931091\tKL_Divergence = 0.026554\n",
      "Epoch: 14\tFidelity = 0.936584\tKL_Divergence = 0.022468\n",
      "Epoch: 15\tFidelity = 0.933387\tKL_Divergence = 0.024813\n",
      "Epoch: 16\tFidelity = 0.934712\tKL_Divergence = 0.023062\n",
      "Epoch: 17\tFidelity = 0.934218\tKL_Divergence = 0.023383\n",
      "Epoch: 18\tFidelity = 0.936257\tKL_Divergence = 0.022237\n",
      "Epoch: 19\tFidelity = 0.935439\tKL_Divergence = 0.022793\n",
      "Epoch: 20\tFidelity = 0.934024\tKL_Divergence = 0.024248\n",
      "Epoch: 21\tFidelity = 0.937629\tKL_Divergence = 0.021689\n",
      "Epoch: 22\tFidelity = 0.934672\tKL_Divergence = 0.024929\n",
      "Epoch: 23\tFidelity = 0.931363\tKL_Divergence = 0.028622\n",
      "Epoch: 24\tFidelity = 0.936590\tKL_Divergence = 0.021915\n",
      "Epoch: 25\tFidelity = 0.927807\tKL_Divergence = 0.031924\n",
      "Epoch: 26\tFidelity = 0.936872\tKL_Divergence = 0.023821\n",
      "Epoch: 27\tFidelity = 0.929313\tKL_Divergence = 0.030651\n",
      "Epoch: 28\tFidelity = 0.934666\tKL_Divergence = 0.026502\n",
      "Epoch: 29\tFidelity = 0.934207\tKL_Divergence = 0.026419\n",
      "Epoch: 30\tFidelity = 0.931599\tKL_Divergence = 0.026783\n",
      "Epoch: 31\tFidelity = 0.936784\tKL_Divergence = 0.022192\n",
      "Epoch: 32\tFidelity = 0.936448\tKL_Divergence = 0.023782\n",
      "Epoch: 33\tFidelity = 0.933915\tKL_Divergence = 0.023463\n",
      "Epoch: 34\tFidelity = 0.936326\tKL_Divergence = 0.023508\n",
      "Epoch: 35\tFidelity = 0.929581\tKL_Divergence = 0.025191\n",
      "Epoch: 36\tFidelity = 0.937214\tKL_Divergence = 0.021914\n",
      "Epoch: 37\tFidelity = 0.931178\tKL_Divergence = 0.032795\n",
      "Epoch: 38\tFidelity = 0.933940\tKL_Divergence = 0.023545\n",
      "Epoch: 39\tFidelity = 0.935583\tKL_Divergence = 0.023288\n",
      "Epoch: 40\tFidelity = 0.937607\tKL_Divergence = 0.021984\n",
      "Epoch: 41\tFidelity = 0.932667\tKL_Divergence = 0.024033\n",
      "Epoch: 42\tFidelity = 0.935417\tKL_Divergence = 0.023345\n",
      "Epoch: 43\tFidelity = 0.936224\tKL_Divergence = 0.023768\n",
      "Epoch: 44\tFidelity = 0.935076\tKL_Divergence = 0.023345\n",
      "Epoch: 45\tFidelity = 0.936641\tKL_Divergence = 0.023156\n",
      "Epoch: 46\tFidelity = 0.933583\tKL_Divergence = 0.023337\n",
      "Epoch: 47\tFidelity = 0.931596\tKL_Divergence = 0.026081\n",
      "Epoch: 48\tFidelity = 0.934344\tKL_Divergence = 0.023533\n",
      "Epoch: 49\tFidelity = 0.931571\tKL_Divergence = 0.024430\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:44:21,445] Trial 30 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.934477\tKL_Divergence = 0.023580\n",
      "Total time elapsed during training: 304.981 s\n",
      "Trial 30 pruned. \n",
      "Trial 30 pruned. \n",
      "Trial 30 pruned. \n",
      "Trial 30 pruned. \n",
      "Trial 30 pruned. \n",
      "Trial 30 pruned. \n",
      "Epoch: 1\tFidelity = 0.935850\tKL_Divergence = 0.022283\n",
      "Epoch: 2\tFidelity = 0.933839\tKL_Divergence = 0.024077\n",
      "Epoch: 3\tFidelity = 0.934210\tKL_Divergence = 0.023656\n",
      "Epoch: 4\tFidelity = 0.933817\tKL_Divergence = 0.023114\n",
      "Epoch: 5\tFidelity = 0.934502\tKL_Divergence = 0.023186\n",
      "Epoch: 6\tFidelity = 0.931539\tKL_Divergence = 0.026914\n",
      "Epoch: 7\tFidelity = 0.935938\tKL_Divergence = 0.022509\n",
      "Epoch: 8\tFidelity = 0.934384\tKL_Divergence = 0.023471\n",
      "Epoch: 9\tFidelity = 0.935643\tKL_Divergence = 0.022626\n",
      "Epoch: 10\tFidelity = 0.934835\tKL_Divergence = 0.022893\n",
      "Epoch: 11\tFidelity = 0.934514\tKL_Divergence = 0.023131\n",
      "Epoch: 12\tFidelity = 0.934975\tKL_Divergence = 0.022849\n",
      "Epoch: 13\tFidelity = 0.933949\tKL_Divergence = 0.023962\n",
      "Epoch: 14\tFidelity = 0.935595\tKL_Divergence = 0.022792\n",
      "Epoch: 15\tFidelity = 0.936259\tKL_Divergence = 0.022040\n",
      "Epoch: 16\tFidelity = 0.935182\tKL_Divergence = 0.023208\n",
      "Epoch: 17\tFidelity = 0.934654\tKL_Divergence = 0.024072\n",
      "Epoch: 18\tFidelity = 0.936047\tKL_Divergence = 0.023087\n",
      "Epoch: 19\tFidelity = 0.934933\tKL_Divergence = 0.022642\n",
      "Epoch: 20\tFidelity = 0.934151\tKL_Divergence = 0.022892\n",
      "Epoch: 21\tFidelity = 0.932844\tKL_Divergence = 0.023530\n",
      "Epoch: 22\tFidelity = 0.933236\tKL_Divergence = 0.025121\n",
      "Epoch: 23\tFidelity = 0.936380\tKL_Divergence = 0.022105\n",
      "Epoch: 24\tFidelity = 0.934268\tKL_Divergence = 0.023050\n",
      "Epoch: 25\tFidelity = 0.936038\tKL_Divergence = 0.022442\n",
      "Epoch: 26\tFidelity = 0.935502\tKL_Divergence = 0.022545\n",
      "Epoch: 27\tFidelity = 0.935156\tKL_Divergence = 0.023121\n",
      "Epoch: 28\tFidelity = 0.932003\tKL_Divergence = 0.024250\n",
      "Epoch: 29\tFidelity = 0.934233\tKL_Divergence = 0.023979\n",
      "Epoch: 30\tFidelity = 0.936608\tKL_Divergence = 0.021809\n",
      "Epoch: 31\tFidelity = 0.930413\tKL_Divergence = 0.026531\n",
      "Epoch: 32\tFidelity = 0.936418\tKL_Divergence = 0.021903\n",
      "Epoch: 33\tFidelity = 0.934933\tKL_Divergence = 0.022651\n",
      "Epoch: 34\tFidelity = 0.933629\tKL_Divergence = 0.023848\n",
      "Epoch: 35\tFidelity = 0.933633\tKL_Divergence = 0.023797\n",
      "Epoch: 36\tFidelity = 0.932947\tKL_Divergence = 0.023483\n",
      "Epoch: 37\tFidelity = 0.932211\tKL_Divergence = 0.024082\n",
      "Epoch: 38\tFidelity = 0.934765\tKL_Divergence = 0.023126\n",
      "Epoch: 39\tFidelity = 0.935655\tKL_Divergence = 0.022469\n",
      "Epoch: 40\tFidelity = 0.935015\tKL_Divergence = 0.024908\n",
      "Epoch: 41\tFidelity = 0.935077\tKL_Divergence = 0.022635\n",
      "Epoch: 42\tFidelity = 0.936496\tKL_Divergence = 0.022038\n",
      "Epoch: 43\tFidelity = 0.935477\tKL_Divergence = 0.022764\n",
      "Epoch: 44\tFidelity = 0.935634\tKL_Divergence = 0.023549\n",
      "Epoch: 45\tFidelity = 0.931701\tKL_Divergence = 0.026394\n",
      "Epoch: 46\tFidelity = 0.937092\tKL_Divergence = 0.021816\n",
      "Epoch: 47\tFidelity = 0.934618\tKL_Divergence = 0.023786\n",
      "Epoch: 48\tFidelity = 0.936632\tKL_Divergence = 0.021858\n",
      "Epoch: 49\tFidelity = 0.936285\tKL_Divergence = 0.021971\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:49:47,693] Trial 31 finished with value: 0.022147046645199796 and parameters: {'lr': 5.641288148982728, 'pbs': 7000, 'nbs': 7000}. Best is trial 16 with value: 0.02150957396361379.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.936360\tKL_Divergence = 0.022147\n",
      "Total time elapsed during training: 325.925 s\n",
      "Trial 31 finished with value: 0.022147046645199796 and parameters: {'lr': 5.641288148982728, 'pbs': 7000, 'nbs': 7000}. Best is trial 16 with value: 0.02150957396361379.\n",
      "Trial 31 finished with value: 0.022147046645199796 and parameters: {'lr': 5.641288148982728, 'pbs': 7000, 'nbs': 7000}. Best is trial 16 with value: 0.02150957396361379.\n",
      "Trial 31 finished with value: 0.022147046645199796 and parameters: {'lr': 5.641288148982728, 'pbs': 7000, 'nbs': 7000}. Best is trial 16 with value: 0.02150957396361379.\n",
      "Trial 31 finished with value: 0.022147046645199796 and parameters: {'lr': 5.641288148982728, 'pbs': 7000, 'nbs': 7000}. Best is trial 16 with value: 0.02150957396361379.\n",
      "Trial 31 finished with value: 0.022147046645199796 and parameters: {'lr': 5.641288148982728, 'pbs': 7000, 'nbs': 7000}. Best is trial 16 with value: 0.02150957396361379.\n",
      "Trial 31 finished with value: 0.022147046645199796 and parameters: {'lr': 5.641288148982728, 'pbs': 7000, 'nbs': 7000}. Best is trial 16 with value: 0.02150957396361379.\n",
      "Epoch: 1\tFidelity = 0.933297\tKL_Divergence = 0.025229\n",
      "Epoch: 2\tFidelity = 0.931149\tKL_Divergence = 0.028688\n",
      "Epoch: 3\tFidelity = 0.932730\tKL_Divergence = 0.023727\n",
      "Epoch: 4\tFidelity = 0.936925\tKL_Divergence = 0.021776\n",
      "Epoch: 5\tFidelity = 0.937628\tKL_Divergence = 0.021394\n",
      "Epoch: 6\tFidelity = 0.937926\tKL_Divergence = 0.021844\n",
      "Epoch: 7\tFidelity = 0.937136\tKL_Divergence = 0.021724\n",
      "Epoch: 8\tFidelity = 0.937336\tKL_Divergence = 0.021563\n",
      "Epoch: 9\tFidelity = 0.934975\tKL_Divergence = 0.022777\n",
      "Epoch: 10\tFidelity = 0.934817\tKL_Divergence = 0.023741\n",
      "Epoch: 11\tFidelity = 0.936668\tKL_Divergence = 0.023190\n",
      "Epoch: 12\tFidelity = 0.934822\tKL_Divergence = 0.025347\n",
      "Epoch: 13\tFidelity = 0.936746\tKL_Divergence = 0.021748\n",
      "Epoch: 14\tFidelity = 0.932330\tKL_Divergence = 0.023883\n",
      "Epoch: 15\tFidelity = 0.933973\tKL_Divergence = 0.024391\n",
      "Epoch: 16\tFidelity = 0.936486\tKL_Divergence = 0.022416\n",
      "Epoch: 17\tFidelity = 0.935028\tKL_Divergence = 0.023512\n",
      "Epoch: 18\tFidelity = 0.937000\tKL_Divergence = 0.021829\n",
      "Epoch: 19\tFidelity = 0.934543\tKL_Divergence = 0.023312\n",
      "Epoch: 20\tFidelity = 0.929906\tKL_Divergence = 0.025389\n",
      "Epoch: 21\tFidelity = 0.932966\tKL_Divergence = 0.026025\n",
      "Epoch: 22\tFidelity = 0.932658\tKL_Divergence = 0.026002\n",
      "Epoch: 23\tFidelity = 0.934532\tKL_Divergence = 0.023365\n",
      "Epoch: 24\tFidelity = 0.929732\tKL_Divergence = 0.025915\n",
      "Epoch: 25\tFidelity = 0.936656\tKL_Divergence = 0.022170\n",
      "Epoch: 26\tFidelity = 0.931761\tKL_Divergence = 0.024372\n",
      "Epoch: 27\tFidelity = 0.934485\tKL_Divergence = 0.023021\n",
      "Epoch: 28\tFidelity = 0.932099\tKL_Divergence = 0.026354\n",
      "Epoch: 29\tFidelity = 0.935893\tKL_Divergence = 0.022608\n",
      "Epoch: 30\tFidelity = 0.934473\tKL_Divergence = 0.024260\n",
      "Epoch: 31\tFidelity = 0.933287\tKL_Divergence = 0.023678\n",
      "Epoch: 32\tFidelity = 0.937441\tKL_Divergence = 0.022611\n",
      "Epoch: 33\tFidelity = 0.937872\tKL_Divergence = 0.021516\n",
      "Epoch: 34\tFidelity = 0.938515\tKL_Divergence = 0.021217\n",
      "Epoch: 35\tFidelity = 0.935818\tKL_Divergence = 0.022739\n",
      "Epoch: 36\tFidelity = 0.937695\tKL_Divergence = 0.021970\n",
      "Epoch: 37\tFidelity = 0.937859\tKL_Divergence = 0.021423\n",
      "Epoch: 38\tFidelity = 0.936761\tKL_Divergence = 0.022307\n",
      "Epoch: 39\tFidelity = 0.929902\tKL_Divergence = 0.026663\n",
      "Epoch: 40\tFidelity = 0.937657\tKL_Divergence = 0.021481\n",
      "Epoch: 41\tFidelity = 0.939188\tKL_Divergence = 0.021035\n",
      "Epoch: 42\tFidelity = 0.935055\tKL_Divergence = 0.022993\n",
      "Epoch: 43\tFidelity = 0.936361\tKL_Divergence = 0.022297\n",
      "Epoch: 44\tFidelity = 0.934351\tKL_Divergence = 0.028872\n",
      "Epoch: 45\tFidelity = 0.932954\tKL_Divergence = 0.023728\n",
      "Epoch: 46\tFidelity = 0.931269\tKL_Divergence = 0.028212\n",
      "Epoch: 47\tFidelity = 0.937598\tKL_Divergence = 0.022295\n",
      "Epoch: 48\tFidelity = 0.937419\tKL_Divergence = 0.024101\n",
      "Epoch: 49\tFidelity = 0.936040\tKL_Divergence = 0.026680\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:55:14,797] Trial 32 finished with value: 0.021666268310884574 and parameters: {'lr': 6.818821099818826, 'pbs': 7000, 'nbs': 3000}. Best is trial 16 with value: 0.02150957396361379.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.937307\tKL_Divergence = 0.021666\n",
      "Total time elapsed during training: 326.779 s\n",
      "Trial 32 finished with value: 0.021666268310884574 and parameters: {'lr': 6.818821099818826, 'pbs': 7000, 'nbs': 3000}. Best is trial 16 with value: 0.02150957396361379.\n",
      "Trial 32 finished with value: 0.021666268310884574 and parameters: {'lr': 6.818821099818826, 'pbs': 7000, 'nbs': 3000}. Best is trial 16 with value: 0.02150957396361379.\n",
      "Trial 32 finished with value: 0.021666268310884574 and parameters: {'lr': 6.818821099818826, 'pbs': 7000, 'nbs': 3000}. Best is trial 16 with value: 0.02150957396361379.\n",
      "Trial 32 finished with value: 0.021666268310884574 and parameters: {'lr': 6.818821099818826, 'pbs': 7000, 'nbs': 3000}. Best is trial 16 with value: 0.02150957396361379.\n",
      "Trial 32 finished with value: 0.021666268310884574 and parameters: {'lr': 6.818821099818826, 'pbs': 7000, 'nbs': 3000}. Best is trial 16 with value: 0.02150957396361379.\n",
      "Trial 32 finished with value: 0.021666268310884574 and parameters: {'lr': 6.818821099818826, 'pbs': 7000, 'nbs': 3000}. Best is trial 16 with value: 0.02150957396361379.\n",
      "Epoch: 1\tFidelity = 0.937507\tKL_Divergence = 0.023676\n",
      "Epoch: 2\tFidelity = 0.935349\tKL_Divergence = 0.024510\n",
      "Epoch: 3\tFidelity = 0.936187\tKL_Divergence = 0.022689\n",
      "Epoch: 4\tFidelity = 0.934920\tKL_Divergence = 0.024726\n",
      "Epoch: 5\tFidelity = 0.935255\tKL_Divergence = 0.028693\n",
      "Epoch: 6\tFidelity = 0.935862\tKL_Divergence = 0.023288\n",
      "Epoch: 7\tFidelity = 0.935198\tKL_Divergence = 0.023667\n",
      "Epoch: 8\tFidelity = 0.936952\tKL_Divergence = 0.021893\n",
      "Epoch: 9\tFidelity = 0.937783\tKL_Divergence = 0.022148\n",
      "Epoch: 10\tFidelity = 0.938764\tKL_Divergence = 0.021636\n",
      "Epoch: 11\tFidelity = 0.935383\tKL_Divergence = 0.022970\n",
      "Epoch: 12\tFidelity = 0.933504\tKL_Divergence = 0.023642\n",
      "Epoch: 13\tFidelity = 0.931930\tKL_Divergence = 0.032634\n",
      "Epoch: 14\tFidelity = 0.931811\tKL_Divergence = 0.028625\n",
      "Epoch: 15\tFidelity = 0.936904\tKL_Divergence = 0.022618\n",
      "Epoch: 16\tFidelity = 0.936416\tKL_Divergence = 0.022708\n",
      "Epoch: 17\tFidelity = 0.934971\tKL_Divergence = 0.025314\n",
      "Epoch: 18\tFidelity = 0.936832\tKL_Divergence = 0.022272\n",
      "Epoch: 19\tFidelity = 0.937976\tKL_Divergence = 0.021630\n",
      "Epoch: 20\tFidelity = 0.938234\tKL_Divergence = 0.021352\n",
      "Epoch: 21\tFidelity = 0.938162\tKL_Divergence = 0.021341\n",
      "Epoch: 22\tFidelity = 0.937484\tKL_Divergence = 0.022139\n",
      "Epoch: 23\tFidelity = 0.932201\tKL_Divergence = 0.024068\n",
      "Epoch: 24\tFidelity = 0.935603\tKL_Divergence = 0.022417\n",
      "Epoch: 25\tFidelity = 0.935233\tKL_Divergence = 0.025897\n",
      "Epoch: 26\tFidelity = 0.932700\tKL_Divergence = 0.023861\n",
      "Epoch: 27\tFidelity = 0.929217\tKL_Divergence = 0.031746\n",
      "Epoch: 28\tFidelity = 0.926984\tKL_Divergence = 0.026716\n",
      "Epoch: 29\tFidelity = 0.935066\tKL_Divergence = 0.022758\n",
      "Epoch: 30\tFidelity = 0.933172\tKL_Divergence = 0.023855\n",
      "Epoch: 31\tFidelity = 0.932323\tKL_Divergence = 0.025101\n",
      "Epoch: 32\tFidelity = 0.934927\tKL_Divergence = 0.023145\n",
      "Epoch: 33\tFidelity = 0.933084\tKL_Divergence = 0.025939\n",
      "Epoch: 34\tFidelity = 0.932751\tKL_Divergence = 0.025984\n",
      "Epoch: 35\tFidelity = 0.934527\tKL_Divergence = 0.023861\n",
      "Epoch: 36\tFidelity = 0.936135\tKL_Divergence = 0.022249\n",
      "Epoch: 37\tFidelity = 0.936403\tKL_Divergence = 0.022172\n",
      "Epoch: 38\tFidelity = 0.937239\tKL_Divergence = 0.021932\n",
      "Epoch: 39\tFidelity = 0.932984\tKL_Divergence = 0.028285\n",
      "Epoch: 40\tFidelity = 0.938302\tKL_Divergence = 0.021972\n",
      "Epoch: 41\tFidelity = 0.938319\tKL_Divergence = 0.021434\n",
      "Epoch: 42\tFidelity = 0.931911\tKL_Divergence = 0.027475\n",
      "Epoch: 43\tFidelity = 0.936056\tKL_Divergence = 0.022831\n",
      "Epoch: 44\tFidelity = 0.932987\tKL_Divergence = 0.024323\n",
      "Epoch: 45\tFidelity = 0.936293\tKL_Divergence = 0.022897\n",
      "Epoch: 46\tFidelity = 0.934407\tKL_Divergence = 0.023548\n",
      "Epoch: 47\tFidelity = 0.935154\tKL_Divergence = 0.023667\n",
      "Epoch: 48\tFidelity = 0.934244\tKL_Divergence = 0.023026\n",
      "Epoch: 49\tFidelity = 0.932406\tKL_Divergence = 0.024093\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:00:41,681] Trial 33 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.933167\tKL_Divergence = 0.025000\n",
      "Total time elapsed during training: 326.575 s\n",
      "Trial 33 pruned. \n",
      "Trial 33 pruned. \n",
      "Trial 33 pruned. \n",
      "Trial 33 pruned. \n",
      "Trial 33 pruned. \n",
      "Trial 33 pruned. \n",
      "Epoch: 1\tFidelity = 0.934354\tKL_Divergence = 0.023596\n",
      "Epoch: 2\tFidelity = 0.932469\tKL_Divergence = 0.025009\n",
      "Epoch: 3\tFidelity = 0.937335\tKL_Divergence = 0.022421\n",
      "Epoch: 4\tFidelity = 0.937372\tKL_Divergence = 0.022976\n",
      "Epoch: 5\tFidelity = 0.935773\tKL_Divergence = 0.022856\n",
      "Epoch: 6\tFidelity = 0.928747\tKL_Divergence = 0.026375\n",
      "Epoch: 7\tFidelity = 0.929150\tKL_Divergence = 0.025049\n",
      "Epoch: 8\tFidelity = 0.935767\tKL_Divergence = 0.026098\n",
      "Epoch: 9\tFidelity = 0.933925\tKL_Divergence = 0.025194\n",
      "Epoch: 10\tFidelity = 0.927748\tKL_Divergence = 0.026064\n",
      "Epoch: 11\tFidelity = 0.926812\tKL_Divergence = 0.031297\n",
      "Epoch: 12\tFidelity = 0.933123\tKL_Divergence = 0.023999\n",
      "Epoch: 13\tFidelity = 0.929385\tKL_Divergence = 0.034803\n",
      "Epoch: 14\tFidelity = 0.935105\tKL_Divergence = 0.025143\n",
      "Epoch: 15\tFidelity = 0.933398\tKL_Divergence = 0.023504\n",
      "Epoch: 16\tFidelity = 0.929924\tKL_Divergence = 0.027927\n",
      "Epoch: 17\tFidelity = 0.934956\tKL_Divergence = 0.022997\n",
      "Epoch: 18\tFidelity = 0.933969\tKL_Divergence = 0.023330\n",
      "Epoch: 19\tFidelity = 0.929676\tKL_Divergence = 0.030194\n",
      "Epoch: 20\tFidelity = 0.933770\tKL_Divergence = 0.023567\n",
      "Epoch: 21\tFidelity = 0.937026\tKL_Divergence = 0.022119\n",
      "Epoch: 22\tFidelity = 0.920410\tKL_Divergence = 0.037931\n",
      "Epoch: 23\tFidelity = 0.931676\tKL_Divergence = 0.027616\n",
      "Epoch: 24\tFidelity = 0.938107\tKL_Divergence = 0.022000\n",
      "Epoch: 25\tFidelity = 0.933644\tKL_Divergence = 0.023546\n",
      "Epoch: 26\tFidelity = 0.924277\tKL_Divergence = 0.035075\n",
      "Epoch: 27\tFidelity = 0.935380\tKL_Divergence = 0.022849\n",
      "Epoch: 28\tFidelity = 0.930750\tKL_Divergence = 0.025896\n",
      "Epoch: 29\tFidelity = 0.934894\tKL_Divergence = 0.024161\n",
      "Epoch: 30\tFidelity = 0.936053\tKL_Divergence = 0.025075\n",
      "Epoch: 31\tFidelity = 0.933429\tKL_Divergence = 0.024429\n",
      "Epoch: 32\tFidelity = 0.935179\tKL_Divergence = 0.023133\n",
      "Epoch: 33\tFidelity = 0.937102\tKL_Divergence = 0.021652\n",
      "Epoch: 34\tFidelity = 0.932043\tKL_Divergence = 0.027133\n",
      "Epoch: 35\tFidelity = 0.935376\tKL_Divergence = 0.022924\n",
      "Epoch: 36\tFidelity = 0.936433\tKL_Divergence = 0.022178\n",
      "Epoch: 37\tFidelity = 0.934553\tKL_Divergence = 0.025073\n",
      "Epoch: 38\tFidelity = 0.935839\tKL_Divergence = 0.022472\n",
      "Epoch: 39\tFidelity = 0.935406\tKL_Divergence = 0.023059\n",
      "Epoch: 40\tFidelity = 0.930366\tKL_Divergence = 0.028091\n",
      "Epoch: 41\tFidelity = 0.929412\tKL_Divergence = 0.025294\n",
      "Epoch: 42\tFidelity = 0.937151\tKL_Divergence = 0.022779\n",
      "Epoch: 43\tFidelity = 0.933553\tKL_Divergence = 0.026421\n",
      "Epoch: 44\tFidelity = 0.934186\tKL_Divergence = 0.025580\n",
      "Epoch: 45\tFidelity = 0.926455\tKL_Divergence = 0.026342\n",
      "Epoch: 46\tFidelity = 0.928395\tKL_Divergence = 0.029095\n",
      "Epoch: 47\tFidelity = 0.932733\tKL_Divergence = 0.024662\n",
      "Epoch: 48\tFidelity = 0.928624\tKL_Divergence = 0.031019\n",
      "Epoch: 49\tFidelity = 0.936442\tKL_Divergence = 0.023419\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:09:10,708] Trial 34 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.933081\tKL_Divergence = 0.024769\n",
      "Total time elapsed during training: 508.702 s\n",
      "Trial 34 pruned. \n",
      "Trial 34 pruned. \n",
      "Trial 34 pruned. \n",
      "Trial 34 pruned. \n",
      "Trial 34 pruned. \n",
      "Trial 34 pruned. \n",
      "Epoch: 1\tFidelity = 0.927357\tKL_Divergence = 0.038924\n",
      "Epoch: 2\tFidelity = 0.922066\tKL_Divergence = 0.029111\n",
      "Epoch: 3\tFidelity = 0.936961\tKL_Divergence = 0.023224\n",
      "Epoch: 4\tFidelity = 0.934285\tKL_Divergence = 0.027125\n",
      "Epoch: 5\tFidelity = 0.930962\tKL_Divergence = 0.028295\n",
      "Epoch: 6\tFidelity = 0.934762\tKL_Divergence = 0.023662\n",
      "Epoch: 7\tFidelity = 0.919141\tKL_Divergence = 0.047512\n",
      "Epoch: 8\tFidelity = 0.931618\tKL_Divergence = 0.029205\n",
      "Epoch: 9\tFidelity = 0.937629\tKL_Divergence = 0.022775\n",
      "Epoch: 10\tFidelity = 0.938175\tKL_Divergence = 0.022335\n",
      "Epoch: 11\tFidelity = 0.930639\tKL_Divergence = 0.027800\n",
      "Epoch: 12\tFidelity = 0.930747\tKL_Divergence = 0.026504\n",
      "Epoch: 13\tFidelity = 0.930343\tKL_Divergence = 0.024910\n",
      "Epoch: 14\tFidelity = 0.936755\tKL_Divergence = 0.022882\n",
      "Epoch: 15\tFidelity = 0.937374\tKL_Divergence = 0.023007\n",
      "Epoch: 16\tFidelity = 0.936224\tKL_Divergence = 0.021703\n",
      "Epoch: 17\tFidelity = 0.939467\tKL_Divergence = 0.021075\n",
      "Epoch: 18\tFidelity = 0.935236\tKL_Divergence = 0.024106\n",
      "Epoch: 19\tFidelity = 0.934972\tKL_Divergence = 0.023757\n",
      "Epoch: 20\tFidelity = 0.928105\tKL_Divergence = 0.031587\n",
      "Epoch: 21\tFidelity = 0.933573\tKL_Divergence = 0.025626\n",
      "Epoch: 22\tFidelity = 0.930402\tKL_Divergence = 0.025065\n",
      "Epoch: 23\tFidelity = 0.938572\tKL_Divergence = 0.026776\n",
      "Epoch: 24\tFidelity = 0.937186\tKL_Divergence = 0.023910\n",
      "Epoch: 25\tFidelity = 0.934826\tKL_Divergence = 0.023706\n",
      "Epoch: 26\tFidelity = 0.937542\tKL_Divergence = 0.022171\n",
      "Epoch: 27\tFidelity = 0.927025\tKL_Divergence = 0.032232\n",
      "Epoch: 28\tFidelity = 0.925880\tKL_Divergence = 0.027596\n",
      "Epoch: 29\tFidelity = 0.933777\tKL_Divergence = 0.023746\n",
      "Epoch: 30\tFidelity = 0.935103\tKL_Divergence = 0.023504\n",
      "Epoch: 31\tFidelity = 0.936238\tKL_Divergence = 0.023028\n",
      "Epoch: 32\tFidelity = 0.936624\tKL_Divergence = 0.024004\n",
      "Epoch: 33\tFidelity = 0.935450\tKL_Divergence = 0.022532\n",
      "Epoch: 34\tFidelity = 0.937292\tKL_Divergence = 0.022215\n",
      "Epoch: 35\tFidelity = 0.936514\tKL_Divergence = 0.023342\n",
      "Epoch: 36\tFidelity = 0.929432\tKL_Divergence = 0.025583\n",
      "Epoch: 37\tFidelity = 0.937552\tKL_Divergence = 0.021943\n",
      "Epoch: 38\tFidelity = 0.935391\tKL_Divergence = 0.027789\n",
      "Epoch: 39\tFidelity = 0.936627\tKL_Divergence = 0.023334\n",
      "Epoch: 40\tFidelity = 0.935571\tKL_Divergence = 0.024462\n",
      "Epoch: 41\tFidelity = 0.935237\tKL_Divergence = 0.025025\n",
      "Epoch: 42\tFidelity = 0.935000\tKL_Divergence = 0.023075\n",
      "Epoch: 43\tFidelity = 0.927174\tKL_Divergence = 0.042920\n",
      "Epoch: 44\tFidelity = 0.937655\tKL_Divergence = 0.024219\n",
      "Epoch: 45\tFidelity = 0.937874\tKL_Divergence = 0.021959\n",
      "Epoch: 46\tFidelity = 0.934624\tKL_Divergence = 0.023648\n",
      "Epoch: 47\tFidelity = 0.936041\tKL_Divergence = 0.023056\n",
      "Epoch: 48\tFidelity = 0.934643\tKL_Divergence = 0.021963\n",
      "Epoch: 49\tFidelity = 0.936234\tKL_Divergence = 0.022613\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:21:19,658] Trial 35 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.933692\tKL_Divergence = 0.026120\n",
      "Total time elapsed during training: 728.635 s\n",
      "Trial 35 pruned. \n",
      "Trial 35 pruned. \n",
      "Trial 35 pruned. \n",
      "Trial 35 pruned. \n",
      "Trial 35 pruned. \n",
      "Trial 35 pruned. \n",
      "Epoch: 1\tFidelity = 0.934534\tKL_Divergence = 0.025622\n",
      "Epoch: 2\tFidelity = 0.934956\tKL_Divergence = 0.023522\n",
      "Epoch: 3\tFidelity = 0.936043\tKL_Divergence = 0.022340\n",
      "Epoch: 4\tFidelity = 0.935126\tKL_Divergence = 0.023829\n",
      "Epoch: 5\tFidelity = 0.928455\tKL_Divergence = 0.033952\n",
      "Epoch: 6\tFidelity = 0.932022\tKL_Divergence = 0.024258\n",
      "Epoch: 7\tFidelity = 0.935324\tKL_Divergence = 0.024122\n",
      "Epoch: 8\tFidelity = 0.934482\tKL_Divergence = 0.025172\n",
      "Epoch: 9\tFidelity = 0.937562\tKL_Divergence = 0.021762\n",
      "Epoch: 10\tFidelity = 0.933992\tKL_Divergence = 0.023225\n",
      "Epoch: 11\tFidelity = 0.932916\tKL_Divergence = 0.024353\n",
      "Epoch: 12\tFidelity = 0.936432\tKL_Divergence = 0.022744\n",
      "Epoch: 13\tFidelity = 0.935121\tKL_Divergence = 0.023782\n",
      "Epoch: 14\tFidelity = 0.935620\tKL_Divergence = 0.023560\n",
      "Epoch: 15\tFidelity = 0.930757\tKL_Divergence = 0.030547\n",
      "Epoch: 16\tFidelity = 0.934960\tKL_Divergence = 0.022874\n",
      "Epoch: 17\tFidelity = 0.936226\tKL_Divergence = 0.022322\n",
      "Epoch: 18\tFidelity = 0.932997\tKL_Divergence = 0.031480\n",
      "Epoch: 19\tFidelity = 0.936290\tKL_Divergence = 0.022290\n",
      "Epoch: 20\tFidelity = 0.931883\tKL_Divergence = 0.026533\n",
      "Epoch: 21\tFidelity = 0.936699\tKL_Divergence = 0.022382\n",
      "Epoch: 22\tFidelity = 0.931782\tKL_Divergence = 0.026213\n",
      "Epoch: 23\tFidelity = 0.937050\tKL_Divergence = 0.022868\n",
      "Epoch: 24\tFidelity = 0.935635\tKL_Divergence = 0.022659\n",
      "Epoch: 25\tFidelity = 0.935801\tKL_Divergence = 0.023802\n",
      "Epoch: 26\tFidelity = 0.937298\tKL_Divergence = 0.023422\n",
      "Epoch: 27\tFidelity = 0.936042\tKL_Divergence = 0.023059\n",
      "Epoch: 28\tFidelity = 0.937677\tKL_Divergence = 0.021629\n",
      "Epoch: 29\tFidelity = 0.932971\tKL_Divergence = 0.024689\n",
      "Epoch: 30\tFidelity = 0.935945\tKL_Divergence = 0.022285\n",
      "Epoch: 31\tFidelity = 0.935212\tKL_Divergence = 0.025044\n",
      "Epoch: 32\tFidelity = 0.935319\tKL_Divergence = 0.023295\n",
      "Epoch: 33\tFidelity = 0.929128\tKL_Divergence = 0.030395\n",
      "Epoch: 34\tFidelity = 0.936317\tKL_Divergence = 0.023255\n",
      "Epoch: 35\tFidelity = 0.932857\tKL_Divergence = 0.027522\n",
      "Epoch: 36\tFidelity = 0.932131\tKL_Divergence = 0.024577\n",
      "Epoch: 37\tFidelity = 0.933932\tKL_Divergence = 0.023857\n",
      "Epoch: 38\tFidelity = 0.934809\tKL_Divergence = 0.023016\n",
      "Epoch: 39\tFidelity = 0.934011\tKL_Divergence = 0.023469\n",
      "Epoch: 40\tFidelity = 0.930007\tKL_Divergence = 0.025497\n",
      "Epoch: 41\tFidelity = 0.933413\tKL_Divergence = 0.024008\n",
      "Epoch: 42\tFidelity = 0.935487\tKL_Divergence = 0.023087\n",
      "Epoch: 43\tFidelity = 0.935166\tKL_Divergence = 0.023535\n",
      "Epoch: 44\tFidelity = 0.935504\tKL_Divergence = 0.023111\n",
      "Epoch: 45\tFidelity = 0.931117\tKL_Divergence = 0.027971\n",
      "Epoch: 46\tFidelity = 0.937171\tKL_Divergence = 0.023314\n",
      "Epoch: 47\tFidelity = 0.931311\tKL_Divergence = 0.028066\n",
      "Epoch: 48\tFidelity = 0.937910\tKL_Divergence = 0.023259\n",
      "Epoch: 49\tFidelity = 0.937048\tKL_Divergence = 0.022330\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:26:43,540] Trial 36 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.931997\tKL_Divergence = 0.028519\n",
      "Total time elapsed during training: 323.448 s\n",
      "Trial 36 pruned. \n",
      "Trial 36 pruned. \n",
      "Trial 36 pruned. \n",
      "Trial 36 pruned. \n",
      "Trial 36 pruned. \n",
      "Trial 36 pruned. \n",
      "Epoch: 1\tFidelity = 0.936922\tKL_Divergence = 0.021958\n",
      "Epoch: 2\tFidelity = 0.935922\tKL_Divergence = 0.022409\n",
      "Epoch: 3\tFidelity = 0.936434\tKL_Divergence = 0.024849\n",
      "Epoch: 4\tFidelity = 0.933025\tKL_Divergence = 0.024419\n",
      "Epoch: 5\tFidelity = 0.932082\tKL_Divergence = 0.028523\n",
      "Epoch: 6\tFidelity = 0.932347\tKL_Divergence = 0.026161\n",
      "Epoch: 7\tFidelity = 0.936031\tKL_Divergence = 0.022231\n",
      "Epoch: 8\tFidelity = 0.932976\tKL_Divergence = 0.026598\n",
      "Epoch: 9\tFidelity = 0.935400\tKL_Divergence = 0.022815\n",
      "Epoch: 10\tFidelity = 0.936343\tKL_Divergence = 0.022831\n",
      "Epoch: 11\tFidelity = 0.933877\tKL_Divergence = 0.023196\n",
      "Epoch: 12\tFidelity = 0.937407\tKL_Divergence = 0.021817\n",
      "Epoch: 13\tFidelity = 0.936990\tKL_Divergence = 0.021708\n",
      "Epoch: 14\tFidelity = 0.936994\tKL_Divergence = 0.022759\n",
      "Epoch: 15\tFidelity = 0.938586\tKL_Divergence = 0.021215\n",
      "Epoch: 16\tFidelity = 0.937283\tKL_Divergence = 0.023026\n",
      "Epoch: 17\tFidelity = 0.938674\tKL_Divergence = 0.021575\n",
      "Epoch: 18\tFidelity = 0.933289\tKL_Divergence = 0.030261\n",
      "Epoch: 19\tFidelity = 0.938460\tKL_Divergence = 0.021317\n",
      "Epoch: 20\tFidelity = 0.935437\tKL_Divergence = 0.022601\n",
      "Epoch: 21\tFidelity = 0.937991\tKL_Divergence = 0.021666\n",
      "Epoch: 22\tFidelity = 0.936564\tKL_Divergence = 0.022564\n",
      "Epoch: 23\tFidelity = 0.934879\tKL_Divergence = 0.022653\n",
      "Epoch: 24\tFidelity = 0.933587\tKL_Divergence = 0.023981\n",
      "Epoch: 25\tFidelity = 0.936385\tKL_Divergence = 0.022815\n",
      "Epoch: 26\tFidelity = 0.936504\tKL_Divergence = 0.022665\n",
      "Epoch: 27\tFidelity = 0.936863\tKL_Divergence = 0.023090\n",
      "Epoch: 28\tFidelity = 0.936869\tKL_Divergence = 0.022178\n",
      "Epoch: 29\tFidelity = 0.935611\tKL_Divergence = 0.023209\n",
      "Epoch: 30\tFidelity = 0.935736\tKL_Divergence = 0.023329\n",
      "Epoch: 31\tFidelity = 0.936903\tKL_Divergence = 0.022308\n",
      "Epoch: 32\tFidelity = 0.938402\tKL_Divergence = 0.021901\n",
      "Epoch: 33\tFidelity = 0.936535\tKL_Divergence = 0.023384\n",
      "Epoch: 34\tFidelity = 0.938035\tKL_Divergence = 0.021820\n",
      "Epoch: 35\tFidelity = 0.937146\tKL_Divergence = 0.021840\n",
      "Epoch: 36\tFidelity = 0.935941\tKL_Divergence = 0.023059\n",
      "Epoch: 37\tFidelity = 0.934067\tKL_Divergence = 0.024499\n",
      "Epoch: 38\tFidelity = 0.935916\tKL_Divergence = 0.023991\n",
      "Epoch: 39\tFidelity = 0.932156\tKL_Divergence = 0.025723\n",
      "Epoch: 40\tFidelity = 0.932129\tKL_Divergence = 0.023865\n",
      "Epoch: 41\tFidelity = 0.930612\tKL_Divergence = 0.024686\n",
      "Epoch: 42\tFidelity = 0.926720\tKL_Divergence = 0.032760\n",
      "Epoch: 43\tFidelity = 0.932207\tKL_Divergence = 0.024234\n",
      "Epoch: 44\tFidelity = 0.932573\tKL_Divergence = 0.026381\n",
      "Epoch: 45\tFidelity = 0.931886\tKL_Divergence = 0.024201\n",
      "Epoch: 46\tFidelity = 0.930123\tKL_Divergence = 0.030436\n",
      "Epoch: 47\tFidelity = 0.934989\tKL_Divergence = 0.023205\n",
      "Epoch: 48\tFidelity = 0.934978\tKL_Divergence = 0.023175\n",
      "Epoch: 49\tFidelity = 0.935257\tKL_Divergence = 0.022844\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:32:10,487] Trial 37 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.931694\tKL_Divergence = 0.028201\n",
      "Total time elapsed during training: 326.597 s\n",
      "Trial 37 pruned. \n",
      "Trial 37 pruned. \n",
      "Trial 37 pruned. \n",
      "Trial 37 pruned. \n",
      "Trial 37 pruned. \n",
      "Trial 37 pruned. \n",
      "Epoch: 1\tFidelity = 0.935151\tKL_Divergence = 0.024551\n",
      "Epoch: 2\tFidelity = 0.935237\tKL_Divergence = 0.023549\n",
      "Epoch: 3\tFidelity = 0.933406\tKL_Divergence = 0.023629\n",
      "Epoch: 4\tFidelity = 0.934562\tKL_Divergence = 0.025021\n",
      "Epoch: 5\tFidelity = 0.934288\tKL_Divergence = 0.023302\n",
      "Epoch: 6\tFidelity = 0.930928\tKL_Divergence = 0.027887\n",
      "Epoch: 7\tFidelity = 0.937057\tKL_Divergence = 0.023646\n",
      "Epoch: 8\tFidelity = 0.934986\tKL_Divergence = 0.023371\n",
      "Epoch: 9\tFidelity = 0.935040\tKL_Divergence = 0.023030\n",
      "Epoch: 10\tFidelity = 0.936092\tKL_Divergence = 0.023290\n",
      "Epoch: 11\tFidelity = 0.936342\tKL_Divergence = 0.023113\n",
      "Epoch: 12\tFidelity = 0.936457\tKL_Divergence = 0.022278\n",
      "Epoch: 13\tFidelity = 0.935569\tKL_Divergence = 0.023265\n",
      "Epoch: 14\tFidelity = 0.933250\tKL_Divergence = 0.024582\n",
      "Epoch: 15\tFidelity = 0.934095\tKL_Divergence = 0.024025\n",
      "Epoch: 16\tFidelity = 0.934361\tKL_Divergence = 0.022832\n",
      "Epoch: 17\tFidelity = 0.936893\tKL_Divergence = 0.022011\n",
      "Epoch: 18\tFidelity = 0.936575\tKL_Divergence = 0.021904\n",
      "Epoch: 19\tFidelity = 0.936278\tKL_Divergence = 0.022205\n",
      "Epoch: 20\tFidelity = 0.933633\tKL_Divergence = 0.023448\n",
      "Epoch: 21\tFidelity = 0.930945\tKL_Divergence = 0.024381\n",
      "Epoch: 22\tFidelity = 0.932185\tKL_Divergence = 0.024364\n",
      "Epoch: 23\tFidelity = 0.932165\tKL_Divergence = 0.027300\n",
      "Epoch: 24\tFidelity = 0.932148\tKL_Divergence = 0.028528\n",
      "Epoch: 25\tFidelity = 0.934741\tKL_Divergence = 0.022933\n",
      "Epoch: 26\tFidelity = 0.935903\tKL_Divergence = 0.022239\n",
      "Epoch: 27\tFidelity = 0.933030\tKL_Divergence = 0.023560\n",
      "Epoch: 28\tFidelity = 0.932535\tKL_Divergence = 0.025775\n",
      "Epoch: 29\tFidelity = 0.935294\tKL_Divergence = 0.023504\n",
      "Epoch: 30\tFidelity = 0.931841\tKL_Divergence = 0.024025\n",
      "Epoch: 31\tFidelity = 0.933174\tKL_Divergence = 0.028870\n",
      "Epoch: 32\tFidelity = 0.934603\tKL_Divergence = 0.022845\n",
      "Epoch: 33\tFidelity = 0.933228\tKL_Divergence = 0.023873\n",
      "Epoch: 34\tFidelity = 0.933394\tKL_Divergence = 0.025136\n",
      "Epoch: 35\tFidelity = 0.936584\tKL_Divergence = 0.022577\n",
      "Epoch: 36\tFidelity = 0.934739\tKL_Divergence = 0.023077\n",
      "Epoch: 37\tFidelity = 0.935799\tKL_Divergence = 0.024190\n",
      "Epoch: 38\tFidelity = 0.929682\tKL_Divergence = 0.025507\n",
      "Epoch: 39\tFidelity = 0.933860\tKL_Divergence = 0.024309\n",
      "Epoch: 40\tFidelity = 0.937051\tKL_Divergence = 0.022133\n",
      "Epoch: 41\tFidelity = 0.934034\tKL_Divergence = 0.024861\n",
      "Epoch: 42\tFidelity = 0.930847\tKL_Divergence = 0.028992\n",
      "Epoch: 43\tFidelity = 0.932247\tKL_Divergence = 0.026569\n",
      "Epoch: 44\tFidelity = 0.930069\tKL_Divergence = 0.030699\n",
      "Epoch: 45\tFidelity = 0.929105\tKL_Divergence = 0.026515\n",
      "Epoch: 46\tFidelity = 0.933013\tKL_Divergence = 0.025782\n",
      "Epoch: 47\tFidelity = 0.930351\tKL_Divergence = 0.026905\n",
      "Epoch: 48\tFidelity = 0.935151\tKL_Divergence = 0.022772\n",
      "Epoch: 49\tFidelity = 0.935036\tKL_Divergence = 0.022885\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:38:12,900] Trial 38 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.927912\tKL_Divergence = 0.028436\n",
      "Total time elapsed during training: 362.098 s\n",
      "Trial 38 pruned. \n",
      "Trial 38 pruned. \n",
      "Trial 38 pruned. \n",
      "Trial 38 pruned. \n",
      "Trial 38 pruned. \n",
      "Trial 38 pruned. \n",
      "Epoch: 1\tFidelity = 0.934316\tKL_Divergence = 0.023039\n",
      "Epoch: 2\tFidelity = 0.936763\tKL_Divergence = 0.022466\n",
      "Epoch: 3\tFidelity = 0.932549\tKL_Divergence = 0.025866\n",
      "Epoch: 4\tFidelity = 0.934942\tKL_Divergence = 0.026059\n",
      "Epoch: 5\tFidelity = 0.933489\tKL_Divergence = 0.024968\n",
      "Epoch: 6\tFidelity = 0.932460\tKL_Divergence = 0.024002\n",
      "Epoch: 7\tFidelity = 0.935705\tKL_Divergence = 0.022469\n",
      "Epoch: 8\tFidelity = 0.933441\tKL_Divergence = 0.025698\n",
      "Epoch: 9\tFidelity = 0.937402\tKL_Divergence = 0.021906\n",
      "Epoch: 10\tFidelity = 0.935669\tKL_Divergence = 0.023168\n",
      "Epoch: 11\tFidelity = 0.935923\tKL_Divergence = 0.022604\n",
      "Epoch: 12\tFidelity = 0.936271\tKL_Divergence = 0.022335\n",
      "Epoch: 13\tFidelity = 0.935397\tKL_Divergence = 0.023242\n",
      "Epoch: 14\tFidelity = 0.934863\tKL_Divergence = 0.022714\n",
      "Epoch: 15\tFidelity = 0.929451\tKL_Divergence = 0.026099\n",
      "Epoch: 16\tFidelity = 0.936613\tKL_Divergence = 0.022011\n",
      "Epoch: 17\tFidelity = 0.934589\tKL_Divergence = 0.024525\n",
      "Epoch: 18\tFidelity = 0.935532\tKL_Divergence = 0.022575\n",
      "Epoch: 19\tFidelity = 0.935309\tKL_Divergence = 0.022577\n",
      "Epoch: 20\tFidelity = 0.933670\tKL_Divergence = 0.023952\n",
      "Epoch: 21\tFidelity = 0.929527\tKL_Divergence = 0.029324\n",
      "Epoch: 22\tFidelity = 0.933036\tKL_Divergence = 0.024096\n",
      "Epoch: 23\tFidelity = 0.932713\tKL_Divergence = 0.023884\n",
      "Epoch: 24\tFidelity = 0.927878\tKL_Divergence = 0.028050\n",
      "Epoch: 25\tFidelity = 0.935832\tKL_Divergence = 0.023527\n",
      "Epoch: 26\tFidelity = 0.935766\tKL_Divergence = 0.024662\n",
      "Epoch: 27\tFidelity = 0.935065\tKL_Divergence = 0.022894\n",
      "Epoch: 28\tFidelity = 0.934635\tKL_Divergence = 0.023248\n",
      "Epoch: 29\tFidelity = 0.936216\tKL_Divergence = 0.023512\n",
      "Epoch: 30\tFidelity = 0.934550\tKL_Divergence = 0.024167\n",
      "Epoch: 31\tFidelity = 0.937600\tKL_Divergence = 0.021907\n",
      "Epoch: 32\tFidelity = 0.938035\tKL_Divergence = 0.022067\n",
      "Epoch: 33\tFidelity = 0.932525\tKL_Divergence = 0.025004\n",
      "Epoch: 34\tFidelity = 0.928934\tKL_Divergence = 0.035184\n",
      "Epoch: 35\tFidelity = 0.936806\tKL_Divergence = 0.022143\n",
      "Epoch: 36\tFidelity = 0.933297\tKL_Divergence = 0.029984\n",
      "Epoch: 37\tFidelity = 0.934336\tKL_Divergence = 0.023364\n",
      "Epoch: 38\tFidelity = 0.930601\tKL_Divergence = 0.025090\n",
      "Epoch: 39\tFidelity = 0.930731\tKL_Divergence = 0.027137\n",
      "Epoch: 40\tFidelity = 0.936304\tKL_Divergence = 0.022696\n",
      "Epoch: 41\tFidelity = 0.932375\tKL_Divergence = 0.024037\n",
      "Epoch: 42\tFidelity = 0.933477\tKL_Divergence = 0.024543\n",
      "Epoch: 43\tFidelity = 0.934435\tKL_Divergence = 0.023473\n",
      "Epoch: 44\tFidelity = 0.929271\tKL_Divergence = 0.028697\n",
      "Epoch: 45\tFidelity = 0.933726\tKL_Divergence = 0.023600\n",
      "Epoch: 46\tFidelity = 0.936225\tKL_Divergence = 0.022378\n",
      "Epoch: 47\tFidelity = 0.934086\tKL_Divergence = 0.025118\n",
      "Epoch: 48\tFidelity = 0.936959\tKL_Divergence = 0.021793\n",
      "Epoch: 49\tFidelity = 0.933882\tKL_Divergence = 0.025275\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:43:57,376] Trial 39 finished with value: 0.02199352070156067 and parameters: {'lr': 6.840618983070659, 'pbs': 6000, 'nbs': 9000}. Best is trial 16 with value: 0.02150957396361379.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.936642\tKL_Divergence = 0.021994\n",
      "Total time elapsed during training: 344.144 s\n",
      "Trial 39 finished with value: 0.02199352070156067 and parameters: {'lr': 6.840618983070659, 'pbs': 6000, 'nbs': 9000}. Best is trial 16 with value: 0.02150957396361379.\n",
      "Trial 39 finished with value: 0.02199352070156067 and parameters: {'lr': 6.840618983070659, 'pbs': 6000, 'nbs': 9000}. Best is trial 16 with value: 0.02150957396361379.\n",
      "Trial 39 finished with value: 0.02199352070156067 and parameters: {'lr': 6.840618983070659, 'pbs': 6000, 'nbs': 9000}. Best is trial 16 with value: 0.02150957396361379.\n",
      "Trial 39 finished with value: 0.02199352070156067 and parameters: {'lr': 6.840618983070659, 'pbs': 6000, 'nbs': 9000}. Best is trial 16 with value: 0.02150957396361379.\n",
      "Trial 39 finished with value: 0.02199352070156067 and parameters: {'lr': 6.840618983070659, 'pbs': 6000, 'nbs': 9000}. Best is trial 16 with value: 0.02150957396361379.\n",
      "Trial 39 finished with value: 0.02199352070156067 and parameters: {'lr': 6.840618983070659, 'pbs': 6000, 'nbs': 9000}. Best is trial 16 with value: 0.02150957396361379.\n",
      "Epoch: 1\tFidelity = 0.932794\tKL_Divergence = 0.024629\n",
      "Epoch: 2\tFidelity = 0.939444\tKL_Divergence = 0.021094\n",
      "Epoch: 3\tFidelity = 0.935164\tKL_Divergence = 0.022667\n",
      "Epoch: 4\tFidelity = 0.927327\tKL_Divergence = 0.036242\n",
      "Epoch: 5\tFidelity = 0.937906\tKL_Divergence = 0.021912\n",
      "Epoch: 6\tFidelity = 0.932996\tKL_Divergence = 0.032448\n",
      "Epoch: 7\tFidelity = 0.935690\tKL_Divergence = 0.025323\n",
      "Epoch: 8\tFidelity = 0.932972\tKL_Divergence = 0.023140\n",
      "Epoch: 9\tFidelity = 0.938295\tKL_Divergence = 0.022554\n",
      "Epoch: 10\tFidelity = 0.936182\tKL_Divergence = 0.022400\n",
      "Epoch: 11\tFidelity = 0.934689\tKL_Divergence = 0.028331\n",
      "Epoch: 12\tFidelity = 0.936842\tKL_Divergence = 0.022507\n",
      "Epoch: 13\tFidelity = 0.939752\tKL_Divergence = 0.021428\n",
      "Epoch: 14\tFidelity = 0.929474\tKL_Divergence = 0.031570\n",
      "Epoch: 15\tFidelity = 0.934540\tKL_Divergence = 0.026835\n",
      "Epoch: 16\tFidelity = 0.937900\tKL_Divergence = 0.024454\n",
      "Epoch: 17\tFidelity = 0.934249\tKL_Divergence = 0.025040\n",
      "Epoch: 18\tFidelity = 0.935783\tKL_Divergence = 0.024016\n",
      "Epoch: 19\tFidelity = 0.935297\tKL_Divergence = 0.024556\n",
      "Epoch: 20\tFidelity = 0.935403\tKL_Divergence = 0.025920\n",
      "Epoch: 21\tFidelity = 0.938368\tKL_Divergence = 0.022728\n",
      "Epoch: 22\tFidelity = 0.935001\tKL_Divergence = 0.027590\n",
      "Epoch: 23\tFidelity = 0.938729\tKL_Divergence = 0.022166\n",
      "Epoch: 24\tFidelity = 0.935666\tKL_Divergence = 0.026895\n",
      "Epoch: 25\tFidelity = 0.933547\tKL_Divergence = 0.027978\n",
      "Epoch: 26\tFidelity = 0.930632\tKL_Divergence = 0.029364\n",
      "Epoch: 27\tFidelity = 0.933649\tKL_Divergence = 0.025114\n",
      "Epoch: 28\tFidelity = 0.931835\tKL_Divergence = 0.025593\n",
      "Epoch: 29\tFidelity = 0.935010\tKL_Divergence = 0.025093\n",
      "Epoch: 30\tFidelity = 0.936428\tKL_Divergence = 0.022542\n",
      "Epoch: 31\tFidelity = 0.937011\tKL_Divergence = 0.022610\n",
      "Epoch: 32\tFidelity = 0.937218\tKL_Divergence = 0.025138\n",
      "Epoch: 33\tFidelity = 0.935222\tKL_Divergence = 0.023507\n",
      "Epoch: 34\tFidelity = 0.935055\tKL_Divergence = 0.023292\n",
      "Epoch: 35\tFidelity = 0.937635\tKL_Divergence = 0.022065\n",
      "Epoch: 36\tFidelity = 0.934583\tKL_Divergence = 0.023233\n",
      "Epoch: 37\tFidelity = 0.938786\tKL_Divergence = 0.021832\n",
      "Epoch: 38\tFidelity = 0.936467\tKL_Divergence = 0.022524\n",
      "Epoch: 39\tFidelity = 0.928938\tKL_Divergence = 0.026863\n",
      "Epoch: 40\tFidelity = 0.934074\tKL_Divergence = 0.025713\n",
      "Epoch: 41\tFidelity = 0.937847\tKL_Divergence = 0.022674\n",
      "Epoch: 42\tFidelity = 0.934247\tKL_Divergence = 0.029331\n",
      "Epoch: 43\tFidelity = 0.939341\tKL_Divergence = 0.021655\n",
      "Epoch: 44\tFidelity = 0.939127\tKL_Divergence = 0.024332\n",
      "Epoch: 45\tFidelity = 0.932048\tKL_Divergence = 0.026098\n",
      "Epoch: 46\tFidelity = 0.935254\tKL_Divergence = 0.023787\n",
      "Epoch: 47\tFidelity = 0.923795\tKL_Divergence = 0.028540\n",
      "Epoch: 48\tFidelity = 0.933261\tKL_Divergence = 0.027485\n",
      "Epoch: 49\tFidelity = 0.937729\tKL_Divergence = 0.022939\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:56:01,173] Trial 40 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.936645\tKL_Divergence = 0.023471\n",
      "Total time elapsed during training: 723.465 s\n",
      "Trial 40 pruned. \n",
      "Trial 40 pruned. \n",
      "Trial 40 pruned. \n",
      "Trial 40 pruned. \n",
      "Trial 40 pruned. \n",
      "Trial 40 pruned. \n",
      "Epoch: 1\tFidelity = 0.930606\tKL_Divergence = 0.031121\n",
      "Epoch: 2\tFidelity = 0.936150\tKL_Divergence = 0.023913\n",
      "Epoch: 3\tFidelity = 0.933942\tKL_Divergence = 0.023878\n",
      "Epoch: 4\tFidelity = 0.931384\tKL_Divergence = 0.024772\n",
      "Epoch: 5\tFidelity = 0.936390\tKL_Divergence = 0.023976\n",
      "Epoch: 6\tFidelity = 0.936915\tKL_Divergence = 0.022336\n",
      "Epoch: 7\tFidelity = 0.936740\tKL_Divergence = 0.022637\n",
      "Epoch: 8\tFidelity = 0.935201\tKL_Divergence = 0.024063\n",
      "Epoch: 9\tFidelity = 0.934607\tKL_Divergence = 0.023321\n",
      "Epoch: 10\tFidelity = 0.936558\tKL_Divergence = 0.023559\n",
      "Epoch: 11\tFidelity = 0.934463\tKL_Divergence = 0.023442\n",
      "Epoch: 12\tFidelity = 0.934408\tKL_Divergence = 0.023268\n",
      "Epoch: 13\tFidelity = 0.935573\tKL_Divergence = 0.022907\n",
      "Epoch: 14\tFidelity = 0.936565\tKL_Divergence = 0.023829\n",
      "Epoch: 15\tFidelity = 0.935164\tKL_Divergence = 0.025257\n",
      "Epoch: 16\tFidelity = 0.937030\tKL_Divergence = 0.022103\n",
      "Epoch: 17\tFidelity = 0.930964\tKL_Divergence = 0.024725\n",
      "Epoch: 18\tFidelity = 0.937556\tKL_Divergence = 0.021828\n",
      "Epoch: 19\tFidelity = 0.933064\tKL_Divergence = 0.025541\n",
      "Epoch: 20\tFidelity = 0.936230\tKL_Divergence = 0.022530\n",
      "Epoch: 21\tFidelity = 0.931635\tKL_Divergence = 0.025022\n",
      "Epoch: 22\tFidelity = 0.933209\tKL_Divergence = 0.026066\n",
      "Epoch: 23\tFidelity = 0.935566\tKL_Divergence = 0.022556\n",
      "Epoch: 24\tFidelity = 0.935403\tKL_Divergence = 0.022859\n",
      "Epoch: 25\tFidelity = 0.932872\tKL_Divergence = 0.025220\n",
      "Epoch: 26\tFidelity = 0.934067\tKL_Divergence = 0.025278\n",
      "Epoch: 27\tFidelity = 0.934186\tKL_Divergence = 0.024829\n",
      "Epoch: 28\tFidelity = 0.935002\tKL_Divergence = 0.022920\n",
      "Epoch: 29\tFidelity = 0.936491\tKL_Divergence = 0.022224\n",
      "Epoch: 30\tFidelity = 0.935668\tKL_Divergence = 0.022606\n",
      "Epoch: 31\tFidelity = 0.937343\tKL_Divergence = 0.021797\n",
      "Epoch: 32\tFidelity = 0.937076\tKL_Divergence = 0.022583\n",
      "Epoch: 33\tFidelity = 0.935746\tKL_Divergence = 0.022858\n",
      "Epoch: 34\tFidelity = 0.935696\tKL_Divergence = 0.022899\n",
      "Epoch: 35\tFidelity = 0.936486\tKL_Divergence = 0.022858\n",
      "Epoch: 36\tFidelity = 0.936423\tKL_Divergence = 0.022189\n",
      "Epoch: 37\tFidelity = 0.935406\tKL_Divergence = 0.023085\n",
      "Epoch: 38\tFidelity = 0.933711\tKL_Divergence = 0.023864\n",
      "Epoch: 39\tFidelity = 0.935098\tKL_Divergence = 0.023885\n",
      "Epoch: 40\tFidelity = 0.935055\tKL_Divergence = 0.023033\n",
      "Epoch: 41\tFidelity = 0.934578\tKL_Divergence = 0.023876\n",
      "Epoch: 42\tFidelity = 0.934268\tKL_Divergence = 0.024150\n",
      "Epoch: 43\tFidelity = 0.934155\tKL_Divergence = 0.025577\n",
      "Epoch: 44\tFidelity = 0.934953\tKL_Divergence = 0.022972\n",
      "Epoch: 45\tFidelity = 0.937188\tKL_Divergence = 0.022473\n",
      "Epoch: 46\tFidelity = 0.932927\tKL_Divergence = 0.028458\n",
      "Epoch: 47\tFidelity = 0.937487\tKL_Divergence = 0.021639\n",
      "Epoch: 48\tFidelity = 0.931853\tKL_Divergence = 0.026220\n",
      "Epoch: 49\tFidelity = 0.935080\tKL_Divergence = 0.027512\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:01:43,192] Trial 41 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.932753\tKL_Divergence = 0.027813\n",
      "Total time elapsed during training: 341.682 s\n",
      "Trial 41 pruned. \n",
      "Trial 41 pruned. \n",
      "Trial 41 pruned. \n",
      "Trial 41 pruned. \n",
      "Trial 41 pruned. \n",
      "Trial 41 pruned. \n",
      "Epoch: 1\tFidelity = 0.935641\tKL_Divergence = 0.025083\n",
      "Epoch: 2\tFidelity = 0.928656\tKL_Divergence = 0.030238\n",
      "Epoch: 3\tFidelity = 0.930612\tKL_Divergence = 0.034823\n",
      "Epoch: 4\tFidelity = 0.932336\tKL_Divergence = 0.024681\n",
      "Epoch: 5\tFidelity = 0.926581\tKL_Divergence = 0.029981\n",
      "Epoch: 6\tFidelity = 0.933761\tKL_Divergence = 0.023322\n",
      "Epoch: 7\tFidelity = 0.933087\tKL_Divergence = 0.023885\n",
      "Epoch: 8\tFidelity = 0.929556\tKL_Divergence = 0.025777\n",
      "Epoch: 9\tFidelity = 0.917650\tKL_Divergence = 0.043875\n",
      "Epoch: 10\tFidelity = 0.937934\tKL_Divergence = 0.022010\n",
      "Epoch: 11\tFidelity = 0.935717\tKL_Divergence = 0.024162\n",
      "Epoch: 12\tFidelity = 0.933806\tKL_Divergence = 0.025160\n",
      "Epoch: 13\tFidelity = 0.937335\tKL_Divergence = 0.021814\n",
      "Epoch: 14\tFidelity = 0.934089\tKL_Divergence = 0.025412\n",
      "Epoch: 15\tFidelity = 0.935023\tKL_Divergence = 0.023249\n",
      "Epoch: 16\tFidelity = 0.934730\tKL_Divergence = 0.022965\n",
      "Epoch: 17\tFidelity = 0.934786\tKL_Divergence = 0.022925\n",
      "Epoch: 18\tFidelity = 0.927495\tKL_Divergence = 0.031195\n",
      "Epoch: 19\tFidelity = 0.931955\tKL_Divergence = 0.027586\n",
      "Epoch: 20\tFidelity = 0.935321\tKL_Divergence = 0.026261\n",
      "Epoch: 21\tFidelity = 0.934034\tKL_Divergence = 0.024257\n",
      "Epoch: 22\tFidelity = 0.937362\tKL_Divergence = 0.022318\n",
      "Epoch: 23\tFidelity = 0.934529\tKL_Divergence = 0.024857\n",
      "Epoch: 24\tFidelity = 0.936167\tKL_Divergence = 0.022307\n",
      "Epoch: 25\tFidelity = 0.935561\tKL_Divergence = 0.023625\n",
      "Epoch: 26\tFidelity = 0.935601\tKL_Divergence = 0.023163\n",
      "Epoch: 27\tFidelity = 0.936538\tKL_Divergence = 0.022891\n",
      "Epoch: 28\tFidelity = 0.932651\tKL_Divergence = 0.024913\n",
      "Epoch: 29\tFidelity = 0.926507\tKL_Divergence = 0.030664\n",
      "Epoch: 30\tFidelity = 0.932310\tKL_Divergence = 0.028271\n",
      "Epoch: 31\tFidelity = 0.935330\tKL_Divergence = 0.028007\n",
      "Epoch: 32\tFidelity = 0.934626\tKL_Divergence = 0.023211\n",
      "Epoch: 33\tFidelity = 0.935716\tKL_Divergence = 0.023086\n",
      "Epoch: 34\tFidelity = 0.934281\tKL_Divergence = 0.023719\n",
      "Epoch: 35\tFidelity = 0.938520\tKL_Divergence = 0.021644\n",
      "Epoch: 36\tFidelity = 0.938874\tKL_Divergence = 0.021640\n",
      "Epoch: 37\tFidelity = 0.935913\tKL_Divergence = 0.022623\n",
      "Epoch: 38\tFidelity = 0.933998\tKL_Divergence = 0.024032\n",
      "Epoch: 39\tFidelity = 0.934844\tKL_Divergence = 0.027141\n",
      "Epoch: 40\tFidelity = 0.931792\tKL_Divergence = 0.028688\n",
      "Epoch: 41\tFidelity = 0.933727\tKL_Divergence = 0.023536\n",
      "Epoch: 42\tFidelity = 0.936277\tKL_Divergence = 0.022233\n",
      "Epoch: 43\tFidelity = 0.937491\tKL_Divergence = 0.021789\n",
      "Epoch: 44\tFidelity = 0.930699\tKL_Divergence = 0.030929\n",
      "Epoch: 45\tFidelity = 0.932944\tKL_Divergence = 0.026800\n",
      "Epoch: 46\tFidelity = 0.926634\tKL_Divergence = 0.028461\n",
      "Epoch: 47\tFidelity = 0.933907\tKL_Divergence = 0.026929\n",
      "Epoch: 48\tFidelity = 0.938022\tKL_Divergence = 0.021564\n",
      "Epoch: 49\tFidelity = 0.935517\tKL_Divergence = 0.024425\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:07:26,140] Trial 42 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.935465\tKL_Divergence = 0.022755\n",
      "Total time elapsed during training: 342.629 s\n",
      "Trial 42 pruned. \n",
      "Trial 42 pruned. \n",
      "Trial 42 pruned. \n",
      "Trial 42 pruned. \n",
      "Trial 42 pruned. \n",
      "Trial 42 pruned. \n",
      "Epoch: 1\tFidelity = 0.932027\tKL_Divergence = 0.026843\n",
      "Epoch: 2\tFidelity = 0.930893\tKL_Divergence = 0.028411\n",
      "Epoch: 3\tFidelity = 0.929478\tKL_Divergence = 0.030290\n",
      "Epoch: 4\tFidelity = 0.928254\tKL_Divergence = 0.032275\n",
      "Epoch: 5\tFidelity = 0.935680\tKL_Divergence = 0.023538\n",
      "Epoch: 6\tFidelity = 0.929463\tKL_Divergence = 0.026245\n",
      "Epoch: 7\tFidelity = 0.937603\tKL_Divergence = 0.021930\n",
      "Epoch: 8\tFidelity = 0.932887\tKL_Divergence = 0.028930\n",
      "Epoch: 9\tFidelity = 0.934217\tKL_Divergence = 0.023449\n",
      "Epoch: 10\tFidelity = 0.933848\tKL_Divergence = 0.026766\n",
      "Epoch: 11\tFidelity = 0.937252\tKL_Divergence = 0.021952\n",
      "Epoch: 12\tFidelity = 0.932440\tKL_Divergence = 0.024753\n",
      "Epoch: 13\tFidelity = 0.935728\tKL_Divergence = 0.022738\n",
      "Epoch: 14\tFidelity = 0.932400\tKL_Divergence = 0.030430\n",
      "Epoch: 15\tFidelity = 0.933554\tKL_Divergence = 0.023692\n",
      "Epoch: 16\tFidelity = 0.935163\tKL_Divergence = 0.022943\n",
      "Epoch: 17\tFidelity = 0.928686\tKL_Divergence = 0.031943\n",
      "Epoch: 18\tFidelity = 0.936453\tKL_Divergence = 0.023059\n",
      "Epoch: 19\tFidelity = 0.937432\tKL_Divergence = 0.021997\n",
      "Epoch: 20\tFidelity = 0.935912\tKL_Divergence = 0.023438\n",
      "Epoch: 21\tFidelity = 0.933038\tKL_Divergence = 0.024514\n",
      "Epoch: 22\tFidelity = 0.930263\tKL_Divergence = 0.031024\n",
      "Epoch: 23\tFidelity = 0.927187\tKL_Divergence = 0.032295\n",
      "Epoch: 24\tFidelity = 0.927118\tKL_Divergence = 0.029679\n",
      "Epoch: 25\tFidelity = 0.936656\tKL_Divergence = 0.022882\n",
      "Epoch: 26\tFidelity = 0.935716\tKL_Divergence = 0.022293\n",
      "Epoch: 27\tFidelity = 0.935136\tKL_Divergence = 0.023359\n",
      "Epoch: 28\tFidelity = 0.935365\tKL_Divergence = 0.022793\n",
      "Epoch: 29\tFidelity = 0.932865\tKL_Divergence = 0.023805\n",
      "Epoch: 30\tFidelity = 0.930274\tKL_Divergence = 0.025709\n",
      "Epoch: 31\tFidelity = 0.931383\tKL_Divergence = 0.026795\n",
      "Epoch: 32\tFidelity = 0.935571\tKL_Divergence = 0.024507\n",
      "Epoch: 33\tFidelity = 0.933970\tKL_Divergence = 0.023683\n",
      "Epoch: 34\tFidelity = 0.934772\tKL_Divergence = 0.024736\n",
      "Epoch: 35\tFidelity = 0.936210\tKL_Divergence = 0.022162\n",
      "Epoch: 36\tFidelity = 0.936494\tKL_Divergence = 0.022218\n",
      "Epoch: 37\tFidelity = 0.936267\tKL_Divergence = 0.022142\n",
      "Epoch: 38\tFidelity = 0.933860\tKL_Divergence = 0.025822\n",
      "Epoch: 39\tFidelity = 0.930765\tKL_Divergence = 0.024604\n",
      "Epoch: 40\tFidelity = 0.931238\tKL_Divergence = 0.026432\n",
      "Epoch: 41\tFidelity = 0.934415\tKL_Divergence = 0.024062\n",
      "Epoch: 42\tFidelity = 0.934551\tKL_Divergence = 0.024480\n",
      "Epoch: 43\tFidelity = 0.936261\tKL_Divergence = 0.022347\n",
      "Epoch: 44\tFidelity = 0.934703\tKL_Divergence = 0.024724\n",
      "Epoch: 45\tFidelity = 0.936711\tKL_Divergence = 0.022048\n",
      "Epoch: 46\tFidelity = 0.933342\tKL_Divergence = 0.026158\n",
      "Epoch: 47\tFidelity = 0.935485\tKL_Divergence = 0.024209\n",
      "Epoch: 48\tFidelity = 0.932672\tKL_Divergence = 0.023885\n",
      "Epoch: 49\tFidelity = 0.933234\tKL_Divergence = 0.026192\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:13:15,518] Trial 43 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.933750\tKL_Divergence = 0.025347\n",
      "Total time elapsed during training: 349.047 s\n",
      "Trial 43 pruned. \n",
      "Trial 43 pruned. \n",
      "Trial 43 pruned. \n",
      "Trial 43 pruned. \n",
      "Trial 43 pruned. \n",
      "Trial 43 pruned. \n",
      "Epoch: 1\tFidelity = 0.935056\tKL_Divergence = 0.023494\n",
      "Epoch: 2\tFidelity = 0.937423\tKL_Divergence = 0.022003\n",
      "Epoch: 3\tFidelity = 0.934455\tKL_Divergence = 0.023667\n",
      "Epoch: 4\tFidelity = 0.935252\tKL_Divergence = 0.024134\n",
      "Epoch: 5\tFidelity = 0.934827\tKL_Divergence = 0.023973\n",
      "Epoch: 6\tFidelity = 0.936100\tKL_Divergence = 0.022189\n",
      "Epoch: 7\tFidelity = 0.931821\tKL_Divergence = 0.024239\n",
      "Epoch: 8\tFidelity = 0.934872\tKL_Divergence = 0.024265\n",
      "Epoch: 9\tFidelity = 0.933727\tKL_Divergence = 0.025873\n",
      "Epoch: 10\tFidelity = 0.930432\tKL_Divergence = 0.024788\n",
      "Epoch: 11\tFidelity = 0.935388\tKL_Divergence = 0.023650\n",
      "Epoch: 12\tFidelity = 0.929293\tKL_Divergence = 0.031021\n",
      "Epoch: 13\tFidelity = 0.932825\tKL_Divergence = 0.023979\n",
      "Epoch: 14\tFidelity = 0.937838\tKL_Divergence = 0.022226\n",
      "Epoch: 15\tFidelity = 0.936447\tKL_Divergence = 0.022451\n",
      "Epoch: 16\tFidelity = 0.933041\tKL_Divergence = 0.025266\n",
      "Epoch: 17\tFidelity = 0.937225\tKL_Divergence = 0.021907\n",
      "Epoch: 18\tFidelity = 0.938399\tKL_Divergence = 0.021732\n",
      "Epoch: 19\tFidelity = 0.935451\tKL_Divergence = 0.023803\n",
      "Epoch: 20\tFidelity = 0.937065\tKL_Divergence = 0.022535\n",
      "Epoch: 21\tFidelity = 0.935739\tKL_Divergence = 0.022547\n",
      "Epoch: 22\tFidelity = 0.932785\tKL_Divergence = 0.027223\n",
      "Epoch: 23\tFidelity = 0.935789\tKL_Divergence = 0.023623\n",
      "Epoch: 24\tFidelity = 0.935757\tKL_Divergence = 0.022911\n",
      "Epoch: 25\tFidelity = 0.937708\tKL_Divergence = 0.022366\n",
      "Epoch: 26\tFidelity = 0.937527\tKL_Divergence = 0.022263\n",
      "Epoch: 27\tFidelity = 0.937156\tKL_Divergence = 0.022532\n",
      "Epoch: 28\tFidelity = 0.935002\tKL_Divergence = 0.023667\n",
      "Epoch: 29\tFidelity = 0.936174\tKL_Divergence = 0.023447\n",
      "Epoch: 30\tFidelity = 0.937709\tKL_Divergence = 0.022311\n",
      "Epoch: 31\tFidelity = 0.935815\tKL_Divergence = 0.022427\n",
      "Epoch: 32\tFidelity = 0.935869\tKL_Divergence = 0.023296\n",
      "Epoch: 33\tFidelity = 0.936657\tKL_Divergence = 0.022045\n",
      "Epoch: 34\tFidelity = 0.935190\tKL_Divergence = 0.024243\n",
      "Epoch: 35\tFidelity = 0.934109\tKL_Divergence = 0.023366\n",
      "Epoch: 36\tFidelity = 0.936932\tKL_Divergence = 0.022489\n",
      "Epoch: 37\tFidelity = 0.935414\tKL_Divergence = 0.022570\n",
      "Epoch: 38\tFidelity = 0.934120\tKL_Divergence = 0.023310\n",
      "Epoch: 39\tFidelity = 0.936022\tKL_Divergence = 0.022652\n",
      "Epoch: 40\tFidelity = 0.934206\tKL_Divergence = 0.024451\n",
      "Epoch: 41\tFidelity = 0.932165\tKL_Divergence = 0.024160\n",
      "Epoch: 42\tFidelity = 0.935078\tKL_Divergence = 0.023222\n",
      "Epoch: 43\tFidelity = 0.933463\tKL_Divergence = 0.028790\n",
      "Epoch: 44\tFidelity = 0.930869\tKL_Divergence = 0.028643\n",
      "Epoch: 45\tFidelity = 0.936841\tKL_Divergence = 0.022221\n",
      "Epoch: 46\tFidelity = 0.936372\tKL_Divergence = 0.022398\n",
      "Epoch: 47\tFidelity = 0.934768\tKL_Divergence = 0.025422\n",
      "Epoch: 48\tFidelity = 0.933811\tKL_Divergence = 0.024640\n",
      "Epoch: 49\tFidelity = 0.936841\tKL_Divergence = 0.021967\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:19:01,813] Trial 44 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.936392\tKL_Divergence = 0.023499\n",
      "Total time elapsed during training: 345.942 s\n",
      "Trial 44 pruned. \n",
      "Trial 44 pruned. \n",
      "Trial 44 pruned. \n",
      "Trial 44 pruned. \n",
      "Trial 44 pruned. \n",
      "Trial 44 pruned. \n",
      "Epoch: 1\tFidelity = 0.938089\tKL_Divergence = 0.021468\n",
      "Epoch: 2\tFidelity = 0.936878\tKL_Divergence = 0.022049\n",
      "Epoch: 3\tFidelity = 0.936508\tKL_Divergence = 0.023535\n",
      "Epoch: 4\tFidelity = 0.932759\tKL_Divergence = 0.024345\n",
      "Epoch: 5\tFidelity = 0.934033\tKL_Divergence = 0.026900\n",
      "Epoch: 6\tFidelity = 0.936545\tKL_Divergence = 0.022571\n",
      "Epoch: 7\tFidelity = 0.937659\tKL_Divergence = 0.022535\n",
      "Epoch: 8\tFidelity = 0.936461\tKL_Divergence = 0.024625\n",
      "Epoch: 9\tFidelity = 0.930895\tKL_Divergence = 0.027112\n",
      "Epoch: 10\tFidelity = 0.938156\tKL_Divergence = 0.022110\n",
      "Epoch: 11\tFidelity = 0.935968\tKL_Divergence = 0.023087\n",
      "Epoch: 12\tFidelity = 0.936959\tKL_Divergence = 0.022014\n",
      "Epoch: 13\tFidelity = 0.933284\tKL_Divergence = 0.025491\n",
      "Epoch: 14\tFidelity = 0.930113\tKL_Divergence = 0.026949\n",
      "Epoch: 15\tFidelity = 0.933269\tKL_Divergence = 0.024865\n",
      "Epoch: 16\tFidelity = 0.931255\tKL_Divergence = 0.024677\n",
      "Epoch: 17\tFidelity = 0.936288\tKL_Divergence = 0.023127\n",
      "Epoch: 18\tFidelity = 0.930206\tKL_Divergence = 0.026769\n",
      "Epoch: 19\tFidelity = 0.936007\tKL_Divergence = 0.023112\n",
      "Epoch: 20\tFidelity = 0.936105\tKL_Divergence = 0.023820\n",
      "Epoch: 21\tFidelity = 0.934584\tKL_Divergence = 0.024329\n",
      "Epoch: 22\tFidelity = 0.928258\tKL_Divergence = 0.026696\n",
      "Epoch: 23\tFidelity = 0.932530\tKL_Divergence = 0.027976\n",
      "Epoch: 24\tFidelity = 0.930409\tKL_Divergence = 0.028002\n",
      "Epoch: 25\tFidelity = 0.931512\tKL_Divergence = 0.025389\n",
      "Epoch: 26\tFidelity = 0.936684\tKL_Divergence = 0.022986\n",
      "Epoch: 27\tFidelity = 0.937012\tKL_Divergence = 0.022397\n",
      "Epoch: 28\tFidelity = 0.936434\tKL_Divergence = 0.023039\n",
      "Epoch: 29\tFidelity = 0.934952\tKL_Divergence = 0.025701\n",
      "Epoch: 30\tFidelity = 0.934651\tKL_Divergence = 0.026488\n",
      "Epoch: 31\tFidelity = 0.930739\tKL_Divergence = 0.029997\n",
      "Epoch: 32\tFidelity = 0.934944\tKL_Divergence = 0.023787\n",
      "Epoch: 33\tFidelity = 0.935696\tKL_Divergence = 0.023098\n",
      "Epoch: 34\tFidelity = 0.931253\tKL_Divergence = 0.024762\n",
      "Epoch: 35\tFidelity = 0.936339\tKL_Divergence = 0.022588\n",
      "Epoch: 36\tFidelity = 0.935370\tKL_Divergence = 0.022944\n",
      "Epoch: 37\tFidelity = 0.937190\tKL_Divergence = 0.022517\n",
      "Epoch: 38\tFidelity = 0.936044\tKL_Divergence = 0.024278\n",
      "Epoch: 39\tFidelity = 0.930278\tKL_Divergence = 0.027753\n",
      "Epoch: 40\tFidelity = 0.936067\tKL_Divergence = 0.023032\n",
      "Epoch: 41\tFidelity = 0.937888\tKL_Divergence = 0.021974\n",
      "Epoch: 42\tFidelity = 0.938117\tKL_Divergence = 0.021726\n",
      "Epoch: 43\tFidelity = 0.934182\tKL_Divergence = 0.023510\n",
      "Epoch: 44\tFidelity = 0.938278\tKL_Divergence = 0.022038\n",
      "Epoch: 45\tFidelity = 0.935084\tKL_Divergence = 0.025059\n",
      "Epoch: 46\tFidelity = 0.933470\tKL_Divergence = 0.024734\n",
      "Epoch: 47\tFidelity = 0.935175\tKL_Divergence = 0.023419\n",
      "Epoch: 48\tFidelity = 0.935401\tKL_Divergence = 0.023734\n",
      "Epoch: 49\tFidelity = 0.935203\tKL_Divergence = 0.025651\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:24:10,945] Trial 45 finished with value: 0.022000159744519233 and parameters: {'lr': 8.17575835460519, 'pbs': 9000, 'nbs': 6000}. Best is trial 16 with value: 0.02150957396361379.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.937165\tKL_Divergence = 0.022000\n",
      "Total time elapsed during training: 308.789 s\n",
      "Trial 45 finished with value: 0.022000159744519233 and parameters: {'lr': 8.17575835460519, 'pbs': 9000, 'nbs': 6000}. Best is trial 16 with value: 0.02150957396361379.\n",
      "Trial 45 finished with value: 0.022000159744519233 and parameters: {'lr': 8.17575835460519, 'pbs': 9000, 'nbs': 6000}. Best is trial 16 with value: 0.02150957396361379.\n",
      "Trial 45 finished with value: 0.022000159744519233 and parameters: {'lr': 8.17575835460519, 'pbs': 9000, 'nbs': 6000}. Best is trial 16 with value: 0.02150957396361379.\n",
      "Trial 45 finished with value: 0.022000159744519233 and parameters: {'lr': 8.17575835460519, 'pbs': 9000, 'nbs': 6000}. Best is trial 16 with value: 0.02150957396361379.\n",
      "Trial 45 finished with value: 0.022000159744519233 and parameters: {'lr': 8.17575835460519, 'pbs': 9000, 'nbs': 6000}. Best is trial 16 with value: 0.02150957396361379.\n",
      "Trial 45 finished with value: 0.022000159744519233 and parameters: {'lr': 8.17575835460519, 'pbs': 9000, 'nbs': 6000}. Best is trial 16 with value: 0.02150957396361379.\n",
      "Epoch: 1\tFidelity = 0.936942\tKL_Divergence = 0.022991\n",
      "Epoch: 2\tFidelity = 0.937174\tKL_Divergence = 0.022422\n",
      "Epoch: 3\tFidelity = 0.936878\tKL_Divergence = 0.022452\n",
      "Epoch: 4\tFidelity = 0.936366\tKL_Divergence = 0.024269\n",
      "Epoch: 5\tFidelity = 0.935467\tKL_Divergence = 0.024685\n",
      "Epoch: 6\tFidelity = 0.935338\tKL_Divergence = 0.022768\n",
      "Epoch: 7\tFidelity = 0.935248\tKL_Divergence = 0.022679\n",
      "Epoch: 8\tFidelity = 0.933075\tKL_Divergence = 0.024179\n",
      "Epoch: 9\tFidelity = 0.934286\tKL_Divergence = 0.023879\n",
      "Epoch: 10\tFidelity = 0.937203\tKL_Divergence = 0.022097\n",
      "Epoch: 11\tFidelity = 0.937392\tKL_Divergence = 0.021955\n",
      "Epoch: 12\tFidelity = 0.936887\tKL_Divergence = 0.023151\n",
      "Epoch: 13\tFidelity = 0.937958\tKL_Divergence = 0.022673\n",
      "Epoch: 14\tFidelity = 0.935686\tKL_Divergence = 0.023363\n",
      "Epoch: 15\tFidelity = 0.936469\tKL_Divergence = 0.022599\n",
      "Epoch: 16\tFidelity = 0.935663\tKL_Divergence = 0.023701\n",
      "Epoch: 17\tFidelity = 0.935672\tKL_Divergence = 0.022705\n",
      "Epoch: 18\tFidelity = 0.934063\tKL_Divergence = 0.024493\n",
      "Epoch: 19\tFidelity = 0.930878\tKL_Divergence = 0.029389\n",
      "Epoch: 20\tFidelity = 0.935223\tKL_Divergence = 0.022616\n",
      "Epoch: 21\tFidelity = 0.935218\tKL_Divergence = 0.023026\n",
      "Epoch: 22\tFidelity = 0.934973\tKL_Divergence = 0.022740\n",
      "Epoch: 23\tFidelity = 0.930322\tKL_Divergence = 0.025621\n",
      "Epoch: 24\tFidelity = 0.933442\tKL_Divergence = 0.023477\n",
      "Epoch: 25\tFidelity = 0.931871\tKL_Divergence = 0.025023\n",
      "Epoch: 26\tFidelity = 0.931603\tKL_Divergence = 0.024262\n",
      "Epoch: 27\tFidelity = 0.932858\tKL_Divergence = 0.024631\n",
      "Epoch: 28\tFidelity = 0.933133\tKL_Divergence = 0.024584\n",
      "Epoch: 29\tFidelity = 0.933568\tKL_Divergence = 0.024758\n",
      "Epoch: 30\tFidelity = 0.935033\tKL_Divergence = 0.023272\n",
      "Epoch: 31\tFidelity = 0.934403\tKL_Divergence = 0.023367\n",
      "Epoch: 32\tFidelity = 0.936183\tKL_Divergence = 0.023564\n",
      "Epoch: 33\tFidelity = 0.935598\tKL_Divergence = 0.025117\n",
      "Epoch: 34\tFidelity = 0.936157\tKL_Divergence = 0.022483\n",
      "Epoch: 35\tFidelity = 0.932224\tKL_Divergence = 0.024425\n",
      "Epoch: 36\tFidelity = 0.933542\tKL_Divergence = 0.025928\n",
      "Epoch: 37\tFidelity = 0.934738\tKL_Divergence = 0.024638\n",
      "Epoch: 38\tFidelity = 0.936720\tKL_Divergence = 0.022474\n",
      "Epoch: 39\tFidelity = 0.936097\tKL_Divergence = 0.022662\n",
      "Epoch: 40\tFidelity = 0.935268\tKL_Divergence = 0.025271\n",
      "Epoch: 41\tFidelity = 0.936880\tKL_Divergence = 0.022184\n",
      "Epoch: 42\tFidelity = 0.935938\tKL_Divergence = 0.023409\n",
      "Epoch: 43\tFidelity = 0.935499\tKL_Divergence = 0.022561\n",
      "Epoch: 44\tFidelity = 0.936722\tKL_Divergence = 0.022305\n",
      "Epoch: 45\tFidelity = 0.933356\tKL_Divergence = 0.026807\n",
      "Epoch: 46\tFidelity = 0.934904\tKL_Divergence = 0.023552\n",
      "Epoch: 47\tFidelity = 0.932688\tKL_Divergence = 0.025087\n",
      "Epoch: 48\tFidelity = 0.936083\tKL_Divergence = 0.022436\n",
      "Epoch: 49\tFidelity = 0.936550\tKL_Divergence = 0.022168\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:29:32,456] Trial 46 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.937164\tKL_Divergence = 0.022235\n",
      "Total time elapsed during training: 321.188 s\n",
      "Trial 46 pruned. \n",
      "Trial 46 pruned. \n",
      "Trial 46 pruned. \n",
      "Trial 46 pruned. \n",
      "Trial 46 pruned. \n",
      "Trial 46 pruned. \n",
      "Epoch: 1\tFidelity = 0.930932\tKL_Divergence = 0.025104\n",
      "Epoch: 2\tFidelity = 0.932971\tKL_Divergence = 0.024825\n",
      "Epoch: 3\tFidelity = 0.935003\tKL_Divergence = 0.022722\n",
      "Epoch: 4\tFidelity = 0.933000\tKL_Divergence = 0.024762\n",
      "Epoch: 5\tFidelity = 0.936637\tKL_Divergence = 0.024130\n",
      "Epoch: 6\tFidelity = 0.934980\tKL_Divergence = 0.022685\n",
      "Epoch: 7\tFidelity = 0.933448\tKL_Divergence = 0.023713\n",
      "Epoch: 8\tFidelity = 0.936506\tKL_Divergence = 0.022821\n",
      "Epoch: 9\tFidelity = 0.928388\tKL_Divergence = 0.028077\n",
      "Epoch: 10\tFidelity = 0.934003\tKL_Divergence = 0.023881\n",
      "Epoch: 11\tFidelity = 0.933666\tKL_Divergence = 0.023253\n",
      "Epoch: 12\tFidelity = 0.933685\tKL_Divergence = 0.025378\n",
      "Epoch: 13\tFidelity = 0.935663\tKL_Divergence = 0.023387\n",
      "Epoch: 14\tFidelity = 0.936109\tKL_Divergence = 0.025030\n",
      "Epoch: 15\tFidelity = 0.937663\tKL_Divergence = 0.021845\n",
      "Epoch: 16\tFidelity = 0.933590\tKL_Divergence = 0.031855\n",
      "Epoch: 17\tFidelity = 0.925854\tKL_Divergence = 0.030063\n",
      "Epoch: 18\tFidelity = 0.938542\tKL_Divergence = 0.022330\n",
      "Epoch: 19\tFidelity = 0.932220\tKL_Divergence = 0.024326\n",
      "Epoch: 20\tFidelity = 0.933405\tKL_Divergence = 0.026635\n",
      "Epoch: 21\tFidelity = 0.933582\tKL_Divergence = 0.025805\n",
      "Epoch: 22\tFidelity = 0.936384\tKL_Divergence = 0.025534\n",
      "Epoch: 23\tFidelity = 0.931039\tKL_Divergence = 0.025522\n",
      "Epoch: 24\tFidelity = 0.934655\tKL_Divergence = 0.023705\n",
      "Epoch: 25\tFidelity = 0.932644\tKL_Divergence = 0.026469\n",
      "Epoch: 26\tFidelity = 0.931874\tKL_Divergence = 0.024518\n",
      "Epoch: 27\tFidelity = 0.928957\tKL_Divergence = 0.039743\n",
      "Epoch: 28\tFidelity = 0.936134\tKL_Divergence = 0.024121\n",
      "Epoch: 29\tFidelity = 0.937819\tKL_Divergence = 0.021623\n",
      "Epoch: 30\tFidelity = 0.936542\tKL_Divergence = 0.022449\n",
      "Epoch: 31\tFidelity = 0.931108\tKL_Divergence = 0.029789\n",
      "Epoch: 32\tFidelity = 0.930298\tKL_Divergence = 0.028750\n",
      "Epoch: 33\tFidelity = 0.930099\tKL_Divergence = 0.031326\n",
      "Epoch: 34\tFidelity = 0.934970\tKL_Divergence = 0.024295\n",
      "Epoch: 35\tFidelity = 0.937240\tKL_Divergence = 0.023363\n",
      "Epoch: 36\tFidelity = 0.938442\tKL_Divergence = 0.022846\n",
      "Epoch: 37\tFidelity = 0.932854\tKL_Divergence = 0.025552\n",
      "Epoch: 38\tFidelity = 0.928325\tKL_Divergence = 0.027327\n",
      "Epoch: 39\tFidelity = 0.933409\tKL_Divergence = 0.024183\n",
      "Epoch: 40\tFidelity = 0.934070\tKL_Divergence = 0.024387\n",
      "Epoch: 41\tFidelity = 0.930130\tKL_Divergence = 0.025615\n",
      "Epoch: 42\tFidelity = 0.935792\tKL_Divergence = 0.024445\n",
      "Epoch: 43\tFidelity = 0.934301\tKL_Divergence = 0.023660\n",
      "Epoch: 44\tFidelity = 0.932123\tKL_Divergence = 0.029878\n",
      "Epoch: 45\tFidelity = 0.915691\tKL_Divergence = 0.058355\n",
      "Epoch: 46\tFidelity = 0.935201\tKL_Divergence = 0.023488\n",
      "Epoch: 47\tFidelity = 0.935262\tKL_Divergence = 0.025191\n",
      "Epoch: 48\tFidelity = 0.934300\tKL_Divergence = 0.024905\n",
      "Epoch: 49\tFidelity = 0.932880\tKL_Divergence = 0.027169\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:37:55,930] Trial 47 finished with value: 0.021663471098399105 and parameters: {'lr': 7.575695953131704, 'pbs': 2000, 'nbs': 3000}. Best is trial 16 with value: 0.02150957396361379.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.937449\tKL_Divergence = 0.021663\n",
      "Total time elapsed during training: 503.149 s\n",
      "Trial 47 finished with value: 0.021663471098399105 and parameters: {'lr': 7.575695953131704, 'pbs': 2000, 'nbs': 3000}. Best is trial 16 with value: 0.02150957396361379.\n",
      "Trial 47 finished with value: 0.021663471098399105 and parameters: {'lr': 7.575695953131704, 'pbs': 2000, 'nbs': 3000}. Best is trial 16 with value: 0.02150957396361379.\n",
      "Trial 47 finished with value: 0.021663471098399105 and parameters: {'lr': 7.575695953131704, 'pbs': 2000, 'nbs': 3000}. Best is trial 16 with value: 0.02150957396361379.\n",
      "Trial 47 finished with value: 0.021663471098399105 and parameters: {'lr': 7.575695953131704, 'pbs': 2000, 'nbs': 3000}. Best is trial 16 with value: 0.02150957396361379.\n",
      "Trial 47 finished with value: 0.021663471098399105 and parameters: {'lr': 7.575695953131704, 'pbs': 2000, 'nbs': 3000}. Best is trial 16 with value: 0.02150957396361379.\n",
      "Trial 47 finished with value: 0.021663471098399105 and parameters: {'lr': 7.575695953131704, 'pbs': 2000, 'nbs': 3000}. Best is trial 16 with value: 0.02150957396361379.\n",
      "Epoch: 1\tFidelity = 0.932119\tKL_Divergence = 0.026321\n",
      "Epoch: 2\tFidelity = 0.927852\tKL_Divergence = 0.039583\n",
      "Epoch: 3\tFidelity = 0.929546\tKL_Divergence = 0.027808\n",
      "Epoch: 4\tFidelity = 0.935859\tKL_Divergence = 0.023217\n",
      "Epoch: 5\tFidelity = 0.935122\tKL_Divergence = 0.024273\n",
      "Epoch: 6\tFidelity = 0.923711\tKL_Divergence = 0.029730\n",
      "Epoch: 7\tFidelity = 0.940058\tKL_Divergence = 0.021552\n",
      "Epoch: 8\tFidelity = 0.931173\tKL_Divergence = 0.024536\n",
      "Epoch: 9\tFidelity = 0.933735\tKL_Divergence = 0.023692\n",
      "Epoch: 10\tFidelity = 0.938064\tKL_Divergence = 0.022849\n",
      "Epoch: 11\tFidelity = 0.938579\tKL_Divergence = 0.022859\n",
      "Epoch: 12\tFidelity = 0.939730\tKL_Divergence = 0.021670\n",
      "Epoch: 13\tFidelity = 0.926568\tKL_Divergence = 0.039073\n",
      "Epoch: 14\tFidelity = 0.931484\tKL_Divergence = 0.027057\n",
      "Epoch: 15\tFidelity = 0.924805\tKL_Divergence = 0.040368\n",
      "Epoch: 16\tFidelity = 0.935849\tKL_Divergence = 0.027913\n",
      "Epoch: 17\tFidelity = 0.934116\tKL_Divergence = 0.023122\n",
      "Epoch: 18\tFidelity = 0.931090\tKL_Divergence = 0.024745\n",
      "Epoch: 19\tFidelity = 0.925465\tKL_Divergence = 0.029607\n",
      "Epoch: 20\tFidelity = 0.939543\tKL_Divergence = 0.023209\n",
      "Epoch: 21\tFidelity = 0.940500\tKL_Divergence = 0.021566\n",
      "Epoch: 22\tFidelity = 0.932271\tKL_Divergence = 0.030155\n",
      "Epoch: 23\tFidelity = 0.935610\tKL_Divergence = 0.022667\n",
      "Epoch: 24\tFidelity = 0.933371\tKL_Divergence = 0.023809\n",
      "Epoch: 25\tFidelity = 0.933597\tKL_Divergence = 0.025024\n",
      "Epoch: 26\tFidelity = 0.937424\tKL_Divergence = 0.022525\n",
      "Epoch: 27\tFidelity = 0.936336\tKL_Divergence = 0.022256\n",
      "Epoch: 28\tFidelity = 0.935287\tKL_Divergence = 0.024692\n",
      "Epoch: 29\tFidelity = 0.936249\tKL_Divergence = 0.024407\n",
      "Epoch: 30\tFidelity = 0.939038\tKL_Divergence = 0.021416\n",
      "Epoch: 31\tFidelity = 0.933904\tKL_Divergence = 0.023795\n",
      "Epoch: 32\tFidelity = 0.933736\tKL_Divergence = 0.026096\n",
      "Epoch: 33\tFidelity = 0.934663\tKL_Divergence = 0.026118\n",
      "Epoch: 34\tFidelity = 0.934756\tKL_Divergence = 0.024465\n",
      "Epoch: 35\tFidelity = 0.937870\tKL_Divergence = 0.022049\n",
      "Epoch: 36\tFidelity = 0.936048\tKL_Divergence = 0.023968\n",
      "Epoch: 37\tFidelity = 0.940232\tKL_Divergence = 0.020828\n",
      "Epoch: 38\tFidelity = 0.932823\tKL_Divergence = 0.024497\n",
      "Epoch: 39\tFidelity = 0.937933\tKL_Divergence = 0.022732\n",
      "Epoch: 40\tFidelity = 0.925200\tKL_Divergence = 0.038919\n",
      "Epoch: 41\tFidelity = 0.938370\tKL_Divergence = 0.021643\n",
      "Epoch: 42\tFidelity = 0.936711\tKL_Divergence = 0.023494\n",
      "Epoch: 43\tFidelity = 0.931872\tKL_Divergence = 0.024944\n",
      "Epoch: 44\tFidelity = 0.930579\tKL_Divergence = 0.028245\n",
      "Epoch: 45\tFidelity = 0.926907\tKL_Divergence = 0.027664\n",
      "Epoch: 46\tFidelity = 0.928459\tKL_Divergence = 0.028124\n",
      "Epoch: 47\tFidelity = 0.937049\tKL_Divergence = 0.023067\n",
      "Epoch: 48\tFidelity = 0.934055\tKL_Divergence = 0.024496\n",
      "Epoch: 49\tFidelity = 0.934353\tKL_Divergence = 0.023781\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:46:15,202] Trial 48 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.934527\tKL_Divergence = 0.025939\n",
      "Total time elapsed during training: 498.929 s\n",
      "Trial 48 pruned. \n",
      "Trial 48 pruned. \n",
      "Trial 48 pruned. \n",
      "Trial 48 pruned. \n",
      "Trial 48 pruned. \n",
      "Trial 48 pruned. \n",
      "Epoch: 1\tFidelity = 0.923540\tKL_Divergence = 0.038203\n",
      "Epoch: 2\tFidelity = 0.938083\tKL_Divergence = 0.022058\n",
      "Epoch: 3\tFidelity = 0.935700\tKL_Divergence = 0.023184\n",
      "Epoch: 4\tFidelity = 0.938800\tKL_Divergence = 0.021872\n",
      "Epoch: 5\tFidelity = 0.935550\tKL_Divergence = 0.022979\n",
      "Epoch: 6\tFidelity = 0.939469\tKL_Divergence = 0.021588\n",
      "Epoch: 7\tFidelity = 0.937108\tKL_Divergence = 0.024680\n",
      "Epoch: 8\tFidelity = 0.932416\tKL_Divergence = 0.026385\n",
      "Epoch: 9\tFidelity = 0.936399\tKL_Divergence = 0.022256\n",
      "Epoch: 10\tFidelity = 0.936688\tKL_Divergence = 0.022491\n",
      "Epoch: 11\tFidelity = 0.930901\tKL_Divergence = 0.029392\n",
      "Epoch: 12\tFidelity = 0.932290\tKL_Divergence = 0.025341\n",
      "Epoch: 13\tFidelity = 0.936491\tKL_Divergence = 0.022364\n",
      "Epoch: 14\tFidelity = 0.934433\tKL_Divergence = 0.023209\n",
      "Epoch: 15\tFidelity = 0.933759\tKL_Divergence = 0.028963\n",
      "Epoch: 16\tFidelity = 0.932456\tKL_Divergence = 0.026460\n",
      "Epoch: 17\tFidelity = 0.933812\tKL_Divergence = 0.029347\n",
      "Epoch: 18\tFidelity = 0.919273\tKL_Divergence = 0.041791\n",
      "Epoch: 19\tFidelity = 0.938280\tKL_Divergence = 0.024042\n",
      "Epoch: 20\tFidelity = 0.940097\tKL_Divergence = 0.021764\n",
      "Epoch: 21\tFidelity = 0.930292\tKL_Divergence = 0.033195\n",
      "Epoch: 22\tFidelity = 0.936903\tKL_Divergence = 0.024232\n",
      "Epoch: 23\tFidelity = 0.928877\tKL_Divergence = 0.032974\n",
      "Epoch: 24\tFidelity = 0.934834\tKL_Divergence = 0.026370\n",
      "Epoch: 25\tFidelity = 0.934449\tKL_Divergence = 0.027014\n",
      "Epoch: 26\tFidelity = 0.932949\tKL_Divergence = 0.027355\n",
      "Epoch: 27\tFidelity = 0.936341\tKL_Divergence = 0.022481\n",
      "Epoch: 28\tFidelity = 0.929279\tKL_Divergence = 0.025997\n",
      "Epoch: 29\tFidelity = 0.920534\tKL_Divergence = 0.035509\n",
      "Epoch: 30\tFidelity = 0.927762\tKL_Divergence = 0.026031\n",
      "Epoch: 31\tFidelity = 0.935033\tKL_Divergence = 0.025017\n",
      "Epoch: 32\tFidelity = 0.932516\tKL_Divergence = 0.026956\n",
      "Epoch: 33\tFidelity = 0.934097\tKL_Divergence = 0.023359\n",
      "Epoch: 34\tFidelity = 0.926970\tKL_Divergence = 0.038277\n",
      "Epoch: 35\tFidelity = 0.932755\tKL_Divergence = 0.029525\n",
      "Epoch: 36\tFidelity = 0.923874\tKL_Divergence = 0.032605\n",
      "Epoch: 37\tFidelity = 0.927054\tKL_Divergence = 0.031102\n",
      "Epoch: 38\tFidelity = 0.929784\tKL_Divergence = 0.029687\n",
      "Epoch: 39\tFidelity = 0.929616\tKL_Divergence = 0.033457\n",
      "Epoch: 40\tFidelity = 0.938401\tKL_Divergence = 0.023517\n",
      "Epoch: 41\tFidelity = 0.922823\tKL_Divergence = 0.044183\n",
      "Epoch: 42\tFidelity = 0.937693\tKL_Divergence = 0.022222\n",
      "Epoch: 43\tFidelity = 0.936778\tKL_Divergence = 0.022483\n",
      "Epoch: 44\tFidelity = 0.931019\tKL_Divergence = 0.025659\n",
      "Epoch: 45\tFidelity = 0.933241\tKL_Divergence = 0.026679\n",
      "Epoch: 46\tFidelity = 0.933289\tKL_Divergence = 0.026592\n",
      "Epoch: 47\tFidelity = 0.930661\tKL_Divergence = 0.025758\n",
      "Epoch: 48\tFidelity = 0.934241\tKL_Divergence = 0.023060\n",
      "Epoch: 49\tFidelity = 0.934398\tKL_Divergence = 0.023836\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:54:53,472] Trial 49 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.933261\tKL_Divergence = 0.028388\n",
      "Total time elapsed during training: 517.955 s\n",
      "Trial 49 pruned. \n",
      "Trial 49 pruned. \n",
      "Trial 49 pruned. \n",
      "Trial 49 pruned. \n",
      "Trial 49 pruned. \n",
      "Trial 49 pruned. \n",
      "Epoch: 1\tFidelity = 0.931069\tKL_Divergence = 0.024944\n",
      "Epoch: 2\tFidelity = 0.936495\tKL_Divergence = 0.023381\n",
      "Epoch: 3\tFidelity = 0.932849\tKL_Divergence = 0.024476\n",
      "Epoch: 4\tFidelity = 0.935053\tKL_Divergence = 0.024036\n",
      "Epoch: 5\tFidelity = 0.932085\tKL_Divergence = 0.026372\n",
      "Epoch: 6\tFidelity = 0.936249\tKL_Divergence = 0.022500\n",
      "Epoch: 7\tFidelity = 0.935549\tKL_Divergence = 0.023791\n",
      "Epoch: 8\tFidelity = 0.939150\tKL_Divergence = 0.023656\n",
      "Epoch: 9\tFidelity = 0.930485\tKL_Divergence = 0.024797\n",
      "Epoch: 10\tFidelity = 0.938764\tKL_Divergence = 0.021488\n",
      "Epoch: 11\tFidelity = 0.935657\tKL_Divergence = 0.027526\n",
      "Epoch: 12\tFidelity = 0.923839\tKL_Divergence = 0.035654\n",
      "Epoch: 13\tFidelity = 0.931815\tKL_Divergence = 0.024749\n",
      "Epoch: 14\tFidelity = 0.933471\tKL_Divergence = 0.024038\n",
      "Epoch: 15\tFidelity = 0.937065\tKL_Divergence = 0.022848\n",
      "Epoch: 16\tFidelity = 0.934080\tKL_Divergence = 0.023339\n",
      "Epoch: 17\tFidelity = 0.933053\tKL_Divergence = 0.024467\n",
      "Epoch: 18\tFidelity = 0.938017\tKL_Divergence = 0.021902\n",
      "Epoch: 19\tFidelity = 0.923710\tKL_Divergence = 0.030062\n",
      "Epoch: 20\tFidelity = 0.928978\tKL_Divergence = 0.027145\n",
      "Epoch: 21\tFidelity = 0.934204\tKL_Divergence = 0.026518\n",
      "Epoch: 22\tFidelity = 0.933654\tKL_Divergence = 0.026164\n",
      "Epoch: 23\tFidelity = 0.936244\tKL_Divergence = 0.022544\n",
      "Epoch: 24\tFidelity = 0.932747\tKL_Divergence = 0.025334\n",
      "Epoch: 25\tFidelity = 0.934267\tKL_Divergence = 0.024683\n",
      "Epoch: 26\tFidelity = 0.935448\tKL_Divergence = 0.023282\n",
      "Epoch: 27\tFidelity = 0.936037\tKL_Divergence = 0.023527\n",
      "Epoch: 28\tFidelity = 0.936401\tKL_Divergence = 0.022628\n",
      "Epoch: 29\tFidelity = 0.937505\tKL_Divergence = 0.021917\n",
      "Epoch: 30\tFidelity = 0.935644\tKL_Divergence = 0.023686\n",
      "Epoch: 31\tFidelity = 0.932596\tKL_Divergence = 0.027090\n",
      "Epoch: 32\tFidelity = 0.937940\tKL_Divergence = 0.022835\n",
      "Epoch: 33\tFidelity = 0.938247\tKL_Divergence = 0.021538\n",
      "Epoch: 34\tFidelity = 0.932383\tKL_Divergence = 0.027214\n",
      "Epoch: 35\tFidelity = 0.936255\tKL_Divergence = 0.022438\n",
      "Epoch: 36\tFidelity = 0.923502\tKL_Divergence = 0.040484\n",
      "Epoch: 37\tFidelity = 0.936187\tKL_Divergence = 0.022891\n",
      "Epoch: 38\tFidelity = 0.936337\tKL_Divergence = 0.022029\n",
      "Epoch: 39\tFidelity = 0.922754\tKL_Divergence = 0.040391\n",
      "Epoch: 40\tFidelity = 0.924553\tKL_Divergence = 0.029717\n",
      "Epoch: 41\tFidelity = 0.932106\tKL_Divergence = 0.029216\n",
      "Epoch: 42\tFidelity = 0.933095\tKL_Divergence = 0.025003\n",
      "Epoch: 43\tFidelity = 0.936566\tKL_Divergence = 0.022697\n",
      "Epoch: 44\tFidelity = 0.932530\tKL_Divergence = 0.025120\n",
      "Epoch: 45\tFidelity = 0.933186\tKL_Divergence = 0.024694\n",
      "Epoch: 46\tFidelity = 0.935714\tKL_Divergence = 0.023447\n",
      "Epoch: 47\tFidelity = 0.937082\tKL_Divergence = 0.022267\n",
      "Epoch: 48\tFidelity = 0.934372\tKL_Divergence = 0.025379\n",
      "Epoch: 49\tFidelity = 0.937148\tKL_Divergence = 0.022199\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:03:14,923] Trial 50 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.931919\tKL_Divergence = 0.025466\n",
      "Total time elapsed during training: 501.134 s\n",
      "Trial 50 pruned. \n",
      "Trial 50 pruned. \n",
      "Trial 50 pruned. \n",
      "Trial 50 pruned. \n",
      "Trial 50 pruned. \n",
      "Trial 50 pruned. \n",
      "Epoch: 1\tFidelity = 0.935612\tKL_Divergence = 0.025993\n",
      "Epoch: 2\tFidelity = 0.939206\tKL_Divergence = 0.021233\n",
      "Epoch: 3\tFidelity = 0.936710\tKL_Divergence = 0.023143\n",
      "Epoch: 4\tFidelity = 0.934165\tKL_Divergence = 0.024339\n",
      "Epoch: 5\tFidelity = 0.929605\tKL_Divergence = 0.032190\n",
      "Epoch: 6\tFidelity = 0.934804\tKL_Divergence = 0.024099\n",
      "Epoch: 7\tFidelity = 0.933932\tKL_Divergence = 0.025476\n",
      "Epoch: 8\tFidelity = 0.936385\tKL_Divergence = 0.022577\n",
      "Epoch: 9\tFidelity = 0.935721\tKL_Divergence = 0.024405\n",
      "Epoch: 10\tFidelity = 0.935996\tKL_Divergence = 0.022298\n",
      "Epoch: 11\tFidelity = 0.934575\tKL_Divergence = 0.024561\n",
      "Epoch: 12\tFidelity = 0.935568\tKL_Divergence = 0.023437\n",
      "Epoch: 13\tFidelity = 0.934802\tKL_Divergence = 0.023826\n",
      "Epoch: 14\tFidelity = 0.935414\tKL_Divergence = 0.023352\n",
      "Epoch: 15\tFidelity = 0.932033\tKL_Divergence = 0.024185\n",
      "Epoch: 16\tFidelity = 0.933585\tKL_Divergence = 0.025357\n",
      "Epoch: 17\tFidelity = 0.930911\tKL_Divergence = 0.027916\n",
      "Epoch: 18\tFidelity = 0.935985\tKL_Divergence = 0.022433\n",
      "Epoch: 19\tFidelity = 0.936725\tKL_Divergence = 0.022599\n",
      "Epoch: 20\tFidelity = 0.935981\tKL_Divergence = 0.023390\n",
      "Epoch: 21\tFidelity = 0.936390\tKL_Divergence = 0.022715\n",
      "Epoch: 22\tFidelity = 0.928290\tKL_Divergence = 0.033165\n",
      "Epoch: 23\tFidelity = 0.934933\tKL_Divergence = 0.023049\n",
      "Epoch: 24\tFidelity = 0.934011\tKL_Divergence = 0.025567\n",
      "Epoch: 25\tFidelity = 0.933958\tKL_Divergence = 0.024724\n",
      "Epoch: 26\tFidelity = 0.936154\tKL_Divergence = 0.022252\n",
      "Epoch: 27\tFidelity = 0.937734\tKL_Divergence = 0.021609\n",
      "Epoch: 28\tFidelity = 0.936265\tKL_Divergence = 0.022275\n",
      "Epoch: 29\tFidelity = 0.937795\tKL_Divergence = 0.021806\n",
      "Epoch: 30\tFidelity = 0.933066\tKL_Divergence = 0.024357\n",
      "Epoch: 31\tFidelity = 0.936053\tKL_Divergence = 0.024493\n",
      "Epoch: 32\tFidelity = 0.935638\tKL_Divergence = 0.022842\n",
      "Epoch: 33\tFidelity = 0.935362\tKL_Divergence = 0.023098\n",
      "Epoch: 34\tFidelity = 0.936059\tKL_Divergence = 0.022873\n",
      "Epoch: 35\tFidelity = 0.933961\tKL_Divergence = 0.023433\n",
      "Epoch: 36\tFidelity = 0.937051\tKL_Divergence = 0.023121\n",
      "Epoch: 37\tFidelity = 0.936701\tKL_Divergence = 0.022445\n",
      "Epoch: 38\tFidelity = 0.937575\tKL_Divergence = 0.022623\n",
      "Epoch: 39\tFidelity = 0.934562\tKL_Divergence = 0.023842\n",
      "Epoch: 40\tFidelity = 0.935954\tKL_Divergence = 0.022581\n",
      "Epoch: 41\tFidelity = 0.929061\tKL_Divergence = 0.031942\n",
      "Epoch: 42\tFidelity = 0.937306\tKL_Divergence = 0.022680\n",
      "Epoch: 43\tFidelity = 0.937289\tKL_Divergence = 0.022316\n",
      "Epoch: 44\tFidelity = 0.935052\tKL_Divergence = 0.023355\n",
      "Epoch: 45\tFidelity = 0.933014\tKL_Divergence = 0.023943\n",
      "Epoch: 46\tFidelity = 0.934112\tKL_Divergence = 0.025076\n",
      "Epoch: 47\tFidelity = 0.938315\tKL_Divergence = 0.021549\n",
      "Epoch: 48\tFidelity = 0.938369\tKL_Divergence = 0.021601\n",
      "Epoch: 49\tFidelity = 0.935424\tKL_Divergence = 0.024809\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:09:37,622] Trial 51 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.934485\tKL_Divergence = 0.025725\n",
      "Total time elapsed during training: 382.373 s\n",
      "Trial 51 pruned. \n",
      "Trial 51 pruned. \n",
      "Trial 51 pruned. \n",
      "Trial 51 pruned. \n",
      "Trial 51 pruned. \n",
      "Trial 51 pruned. \n",
      "Epoch: 1\tFidelity = 0.937651\tKL_Divergence = 0.021890\n",
      "Epoch: 2\tFidelity = 0.933975\tKL_Divergence = 0.025018\n",
      "Epoch: 3\tFidelity = 0.933259\tKL_Divergence = 0.027260\n",
      "Epoch: 4\tFidelity = 0.936352\tKL_Divergence = 0.022355\n",
      "Epoch: 5\tFidelity = 0.935533\tKL_Divergence = 0.024588\n",
      "Epoch: 6\tFidelity = 0.935589\tKL_Divergence = 0.023531\n",
      "Epoch: 7\tFidelity = 0.932412\tKL_Divergence = 0.029685\n",
      "Epoch: 8\tFidelity = 0.935835\tKL_Divergence = 0.022900\n",
      "Epoch: 9\tFidelity = 0.933389\tKL_Divergence = 0.024908\n",
      "Epoch: 10\tFidelity = 0.935660\tKL_Divergence = 0.022666\n",
      "Epoch: 11\tFidelity = 0.936543\tKL_Divergence = 0.022111\n",
      "Epoch: 12\tFidelity = 0.934706\tKL_Divergence = 0.023807\n",
      "Epoch: 13\tFidelity = 0.932565\tKL_Divergence = 0.025023\n",
      "Epoch: 14\tFidelity = 0.936302\tKL_Divergence = 0.022589\n",
      "Epoch: 15\tFidelity = 0.936781\tKL_Divergence = 0.021927\n",
      "Epoch: 16\tFidelity = 0.935852\tKL_Divergence = 0.022354\n",
      "Epoch: 17\tFidelity = 0.936379\tKL_Divergence = 0.022117\n",
      "Epoch: 18\tFidelity = 0.935373\tKL_Divergence = 0.022668\n",
      "Epoch: 19\tFidelity = 0.934660\tKL_Divergence = 0.023583\n",
      "Epoch: 20\tFidelity = 0.933256\tKL_Divergence = 0.023434\n",
      "Epoch: 21\tFidelity = 0.935131\tKL_Divergence = 0.022608\n",
      "Epoch: 22\tFidelity = 0.934688\tKL_Divergence = 0.022820\n",
      "Epoch: 23\tFidelity = 0.931418\tKL_Divergence = 0.025102\n",
      "Epoch: 24\tFidelity = 0.934300\tKL_Divergence = 0.024516\n",
      "Epoch: 25\tFidelity = 0.935003\tKL_Divergence = 0.022810\n",
      "Epoch: 26\tFidelity = 0.934438\tKL_Divergence = 0.023861\n",
      "Epoch: 27\tFidelity = 0.933293\tKL_Divergence = 0.025063\n",
      "Epoch: 28\tFidelity = 0.934021\tKL_Divergence = 0.024318\n",
      "Epoch: 29\tFidelity = 0.932837\tKL_Divergence = 0.023828\n",
      "Epoch: 30\tFidelity = 0.935417\tKL_Divergence = 0.023248\n",
      "Epoch: 31\tFidelity = 0.935870\tKL_Divergence = 0.022864\n",
      "Epoch: 32\tFidelity = 0.936801\tKL_Divergence = 0.022185\n",
      "Epoch: 33\tFidelity = 0.935630\tKL_Divergence = 0.022660\n",
      "Epoch: 34\tFidelity = 0.934065\tKL_Divergence = 0.025501\n",
      "Epoch: 35\tFidelity = 0.936031\tKL_Divergence = 0.024537\n",
      "Epoch: 36\tFidelity = 0.936049\tKL_Divergence = 0.022486\n",
      "Epoch: 37\tFidelity = 0.936596\tKL_Divergence = 0.022433\n",
      "Epoch: 38\tFidelity = 0.935593\tKL_Divergence = 0.023174\n",
      "Epoch: 39\tFidelity = 0.935648\tKL_Divergence = 0.022936\n",
      "Epoch: 40\tFidelity = 0.930107\tKL_Divergence = 0.032219\n",
      "Epoch: 41\tFidelity = 0.935858\tKL_Divergence = 0.022937\n",
      "Epoch: 42\tFidelity = 0.935370\tKL_Divergence = 0.023888\n",
      "Epoch: 43\tFidelity = 0.933484\tKL_Divergence = 0.025356\n",
      "Epoch: 44\tFidelity = 0.934425\tKL_Divergence = 0.023386\n",
      "Epoch: 45\tFidelity = 0.936263\tKL_Divergence = 0.022208\n",
      "Epoch: 46\tFidelity = 0.935593\tKL_Divergence = 0.022718\n",
      "Epoch: 47\tFidelity = 0.933902\tKL_Divergence = 0.023382\n",
      "Epoch: 48\tFidelity = 0.932258\tKL_Divergence = 0.026441\n",
      "Epoch: 49\tFidelity = 0.935018\tKL_Divergence = 0.023843\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:14:43,878] Trial 52 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.936193\tKL_Divergence = 0.022370\n",
      "Total time elapsed during training: 305.851 s\n",
      "Trial 52 pruned. \n",
      "Trial 52 pruned. \n",
      "Trial 52 pruned. \n",
      "Trial 52 pruned. \n",
      "Trial 52 pruned. \n",
      "Trial 52 pruned. \n",
      "Epoch: 1\tFidelity = 0.937141\tKL_Divergence = 0.022715\n",
      "Epoch: 2\tFidelity = 0.935724\tKL_Divergence = 0.023858\n",
      "Epoch: 3\tFidelity = 0.936246\tKL_Divergence = 0.022320\n",
      "Epoch: 4\tFidelity = 0.932864\tKL_Divergence = 0.028194\n",
      "Epoch: 5\tFidelity = 0.925929\tKL_Divergence = 0.041786\n",
      "Epoch: 6\tFidelity = 0.931482\tKL_Divergence = 0.027100\n",
      "Epoch: 7\tFidelity = 0.933312\tKL_Divergence = 0.024833\n",
      "Epoch: 8\tFidelity = 0.933376\tKL_Divergence = 0.026156\n",
      "Epoch: 9\tFidelity = 0.936234\tKL_Divergence = 0.023012\n",
      "Epoch: 10\tFidelity = 0.934234\tKL_Divergence = 0.023653\n",
      "Epoch: 11\tFidelity = 0.928263\tKL_Divergence = 0.030890\n",
      "Epoch: 12\tFidelity = 0.930720\tKL_Divergence = 0.028226\n",
      "Epoch: 13\tFidelity = 0.928884\tKL_Divergence = 0.033069\n",
      "Epoch: 14\tFidelity = 0.936929\tKL_Divergence = 0.022601\n",
      "Epoch: 15\tFidelity = 0.936948\tKL_Divergence = 0.022573\n",
      "Epoch: 16\tFidelity = 0.931487\tKL_Divergence = 0.028293\n",
      "Epoch: 17\tFidelity = 0.929137\tKL_Divergence = 0.031648\n",
      "Epoch: 18\tFidelity = 0.934957\tKL_Divergence = 0.025482\n",
      "Epoch: 19\tFidelity = 0.932311\tKL_Divergence = 0.028649\n",
      "Epoch: 20\tFidelity = 0.936343\tKL_Divergence = 0.022706\n",
      "Epoch: 21\tFidelity = 0.937850\tKL_Divergence = 0.022845\n",
      "Epoch: 22\tFidelity = 0.937106\tKL_Divergence = 0.023582\n",
      "Epoch: 23\tFidelity = 0.939102\tKL_Divergence = 0.021664\n",
      "Epoch: 24\tFidelity = 0.937754\tKL_Divergence = 0.022019\n",
      "Epoch: 25\tFidelity = 0.937363\tKL_Divergence = 0.023621\n",
      "Epoch: 26\tFidelity = 0.934014\tKL_Divergence = 0.030351\n",
      "Epoch: 27\tFidelity = 0.934831\tKL_Divergence = 0.024195\n",
      "Epoch: 28\tFidelity = 0.936404\tKL_Divergence = 0.024025\n",
      "Epoch: 29\tFidelity = 0.937039\tKL_Divergence = 0.022526\n",
      "Epoch: 30\tFidelity = 0.935037\tKL_Divergence = 0.023430\n",
      "Epoch: 31\tFidelity = 0.931526\tKL_Divergence = 0.027506\n",
      "Epoch: 32\tFidelity = 0.937135\tKL_Divergence = 0.022424\n",
      "Epoch: 33\tFidelity = 0.934423\tKL_Divergence = 0.028269\n",
      "Epoch: 34\tFidelity = 0.934969\tKL_Divergence = 0.024960\n",
      "Epoch: 35\tFidelity = 0.936538\tKL_Divergence = 0.022505\n",
      "Epoch: 36\tFidelity = 0.926054\tKL_Divergence = 0.037323\n",
      "Epoch: 37\tFidelity = 0.937414\tKL_Divergence = 0.022332\n",
      "Epoch: 38\tFidelity = 0.937327\tKL_Divergence = 0.022380\n",
      "Epoch: 39\tFidelity = 0.936692\tKL_Divergence = 0.022607\n",
      "Epoch: 40\tFidelity = 0.936586\tKL_Divergence = 0.022623\n",
      "Epoch: 41\tFidelity = 0.935934\tKL_Divergence = 0.022765\n",
      "Epoch: 42\tFidelity = 0.931404\tKL_Divergence = 0.028017\n",
      "Epoch: 43\tFidelity = 0.935913\tKL_Divergence = 0.022874\n",
      "Epoch: 44\tFidelity = 0.929619\tKL_Divergence = 0.029010\n",
      "Epoch: 45\tFidelity = 0.936493\tKL_Divergence = 0.022378\n",
      "Epoch: 46\tFidelity = 0.930790\tKL_Divergence = 0.025104\n",
      "Epoch: 47\tFidelity = 0.934442\tKL_Divergence = 0.023324\n",
      "Epoch: 48\tFidelity = 0.930183\tKL_Divergence = 0.033687\n",
      "Epoch: 49\tFidelity = 0.930208\tKL_Divergence = 0.025389\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:20:14,688] Trial 53 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.930301\tKL_Divergence = 0.028298\n",
      "Total time elapsed during training: 330.480 s\n",
      "Trial 53 pruned. \n",
      "Trial 53 pruned. \n",
      "Trial 53 pruned. \n",
      "Trial 53 pruned. \n",
      "Trial 53 pruned. \n",
      "Trial 53 pruned. \n",
      "Epoch: 1\tFidelity = 0.933036\tKL_Divergence = 0.024419\n",
      "Epoch: 2\tFidelity = 0.929483\tKL_Divergence = 0.026038\n",
      "Epoch: 3\tFidelity = 0.929738\tKL_Divergence = 0.025149\n",
      "Epoch: 4\tFidelity = 0.930447\tKL_Divergence = 0.029305\n",
      "Epoch: 5\tFidelity = 0.932469\tKL_Divergence = 0.024144\n",
      "Epoch: 6\tFidelity = 0.931025\tKL_Divergence = 0.024615\n",
      "Epoch: 7\tFidelity = 0.931480\tKL_Divergence = 0.027123\n",
      "Epoch: 8\tFidelity = 0.932973\tKL_Divergence = 0.024075\n",
      "Epoch: 9\tFidelity = 0.929014\tKL_Divergence = 0.028786\n",
      "Epoch: 10\tFidelity = 0.931363\tKL_Divergence = 0.026071\n",
      "Epoch: 11\tFidelity = 0.934306\tKL_Divergence = 0.023391\n",
      "Epoch: 12\tFidelity = 0.934381\tKL_Divergence = 0.023843\n",
      "Epoch: 13\tFidelity = 0.935278\tKL_Divergence = 0.023101\n",
      "Epoch: 14\tFidelity = 0.936354\tKL_Divergence = 0.022438\n",
      "Epoch: 15\tFidelity = 0.938171\tKL_Divergence = 0.021696\n",
      "Epoch: 16\tFidelity = 0.936643\tKL_Divergence = 0.022211\n",
      "Epoch: 17\tFidelity = 0.931232\tKL_Divergence = 0.030317\n",
      "Epoch: 18\tFidelity = 0.934509\tKL_Divergence = 0.024792\n",
      "Epoch: 19\tFidelity = 0.937190\tKL_Divergence = 0.024128\n",
      "Epoch: 20\tFidelity = 0.938662\tKL_Divergence = 0.022075\n",
      "Epoch: 21\tFidelity = 0.936876\tKL_Divergence = 0.022133\n",
      "Epoch: 22\tFidelity = 0.936715\tKL_Divergence = 0.022415\n",
      "Epoch: 23\tFidelity = 0.937429\tKL_Divergence = 0.021724\n",
      "Epoch: 24\tFidelity = 0.931443\tKL_Divergence = 0.026652\n",
      "Epoch: 25\tFidelity = 0.930188\tKL_Divergence = 0.030480\n",
      "Epoch: 26\tFidelity = 0.933755\tKL_Divergence = 0.025769\n",
      "Epoch: 27\tFidelity = 0.928467\tKL_Divergence = 0.031511\n",
      "Epoch: 28\tFidelity = 0.930470\tKL_Divergence = 0.027340\n",
      "Epoch: 29\tFidelity = 0.932121\tKL_Divergence = 0.029695\n",
      "Epoch: 30\tFidelity = 0.937203\tKL_Divergence = 0.022987\n",
      "Epoch: 31\tFidelity = 0.936127\tKL_Divergence = 0.024087\n",
      "Epoch: 32\tFidelity = 0.936527\tKL_Divergence = 0.024165\n",
      "Epoch: 33\tFidelity = 0.936823\tKL_Divergence = 0.023094\n",
      "Epoch: 34\tFidelity = 0.933092\tKL_Divergence = 0.028613\n",
      "Epoch: 35\tFidelity = 0.935257\tKL_Divergence = 0.023702\n",
      "Epoch: 36\tFidelity = 0.935052\tKL_Divergence = 0.023516\n",
      "Epoch: 37\tFidelity = 0.934914\tKL_Divergence = 0.025263\n",
      "Epoch: 38\tFidelity = 0.931348\tKL_Divergence = 0.028704\n",
      "Epoch: 39\tFidelity = 0.932283\tKL_Divergence = 0.024452\n",
      "Epoch: 40\tFidelity = 0.933873\tKL_Divergence = 0.023593\n",
      "Epoch: 41\tFidelity = 0.935429\tKL_Divergence = 0.022737\n",
      "Epoch: 42\tFidelity = 0.935614\tKL_Divergence = 0.022927\n",
      "Epoch: 43\tFidelity = 0.935878\tKL_Divergence = 0.023458\n",
      "Epoch: 44\tFidelity = 0.934290\tKL_Divergence = 0.023192\n",
      "Epoch: 45\tFidelity = 0.933356\tKL_Divergence = 0.029564\n",
      "Epoch: 46\tFidelity = 0.935998\tKL_Divergence = 0.022643\n",
      "Epoch: 47\tFidelity = 0.932451\tKL_Divergence = 0.024931\n",
      "Epoch: 48\tFidelity = 0.937086\tKL_Divergence = 0.022107\n",
      "Epoch: 49\tFidelity = 0.933295\tKL_Divergence = 0.029966\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:25:22,698] Trial 54 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.934478\tKL_Divergence = 0.023751\n",
      "Total time elapsed during training: 307.680 s\n",
      "Trial 54 pruned. \n",
      "Trial 54 pruned. \n",
      "Trial 54 pruned. \n",
      "Trial 54 pruned. \n",
      "Trial 54 pruned. \n",
      "Trial 54 pruned. \n",
      "Epoch: 1\tFidelity = 0.934431\tKL_Divergence = 0.024036\n",
      "Epoch: 2\tFidelity = 0.929802\tKL_Divergence = 0.027361\n",
      "Epoch: 3\tFidelity = 0.932115\tKL_Divergence = 0.027645\n",
      "Epoch: 4\tFidelity = 0.934085\tKL_Divergence = 0.023776\n",
      "Epoch: 5\tFidelity = 0.932544\tKL_Divergence = 0.024132\n",
      "Epoch: 6\tFidelity = 0.936250\tKL_Divergence = 0.024429\n",
      "Epoch: 7\tFidelity = 0.937375\tKL_Divergence = 0.024880\n",
      "Epoch: 8\tFidelity = 0.930706\tKL_Divergence = 0.032169\n",
      "Epoch: 9\tFidelity = 0.933019\tKL_Divergence = 0.024440\n",
      "Epoch: 10\tFidelity = 0.924327\tKL_Divergence = 0.031126\n",
      "Epoch: 11\tFidelity = 0.932028\tKL_Divergence = 0.024944\n",
      "Epoch: 12\tFidelity = 0.933753\tKL_Divergence = 0.025885\n",
      "Epoch: 13\tFidelity = 0.937184\tKL_Divergence = 0.023637\n",
      "Epoch: 14\tFidelity = 0.933463\tKL_Divergence = 0.024613\n",
      "Epoch: 15\tFidelity = 0.931445\tKL_Divergence = 0.025079\n",
      "Epoch: 16\tFidelity = 0.935622\tKL_Divergence = 0.023093\n",
      "Epoch: 17\tFidelity = 0.936473\tKL_Divergence = 0.023175\n",
      "Epoch: 18\tFidelity = 0.935786\tKL_Divergence = 0.024219\n",
      "Epoch: 19\tFidelity = 0.929582\tKL_Divergence = 0.025440\n",
      "Epoch: 20\tFidelity = 0.932165\tKL_Divergence = 0.024414\n",
      "Epoch: 21\tFidelity = 0.934660\tKL_Divergence = 0.025280\n",
      "Epoch: 22\tFidelity = 0.930539\tKL_Divergence = 0.036826\n",
      "Epoch: 23\tFidelity = 0.937448\tKL_Divergence = 0.022719\n",
      "Epoch: 24\tFidelity = 0.931802\tKL_Divergence = 0.024861\n",
      "Epoch: 25\tFidelity = 0.930317\tKL_Divergence = 0.028470\n",
      "Epoch: 26\tFidelity = 0.935847\tKL_Divergence = 0.023345\n",
      "Epoch: 27\tFidelity = 0.934231\tKL_Divergence = 0.023627\n",
      "Epoch: 28\tFidelity = 0.929988\tKL_Divergence = 0.028458\n",
      "Epoch: 29\tFidelity = 0.936528\tKL_Divergence = 0.024237\n",
      "Epoch: 30\tFidelity = 0.940130\tKL_Divergence = 0.021720\n",
      "Epoch: 31\tFidelity = 0.935739\tKL_Divergence = 0.026285\n",
      "Epoch: 32\tFidelity = 0.937417\tKL_Divergence = 0.022473\n",
      "Epoch: 33\tFidelity = 0.937708\tKL_Divergence = 0.025804\n",
      "Epoch: 34\tFidelity = 0.935706\tKL_Divergence = 0.024590\n",
      "Epoch: 35\tFidelity = 0.930514\tKL_Divergence = 0.031137\n",
      "Epoch: 36\tFidelity = 0.940676\tKL_Divergence = 0.020910\n",
      "Epoch: 37\tFidelity = 0.938560\tKL_Divergence = 0.023928\n",
      "Epoch: 38\tFidelity = 0.939895\tKL_Divergence = 0.021010\n",
      "Epoch: 39\tFidelity = 0.938785\tKL_Divergence = 0.021113\n",
      "Epoch: 40\tFidelity = 0.933907\tKL_Divergence = 0.028540\n",
      "Epoch: 41\tFidelity = 0.936745\tKL_Divergence = 0.025300\n",
      "Epoch: 42\tFidelity = 0.929094\tKL_Divergence = 0.029651\n",
      "Epoch: 43\tFidelity = 0.929364\tKL_Divergence = 0.030003\n",
      "Epoch: 44\tFidelity = 0.928369\tKL_Divergence = 0.031634\n",
      "Epoch: 45\tFidelity = 0.932000\tKL_Divergence = 0.028066\n",
      "Epoch: 46\tFidelity = 0.932205\tKL_Divergence = 0.027601\n",
      "Epoch: 47\tFidelity = 0.930499\tKL_Divergence = 0.025286\n",
      "Epoch: 48\tFidelity = 0.932933\tKL_Divergence = 0.024909\n",
      "Epoch: 49\tFidelity = 0.933926\tKL_Divergence = 0.023739\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:31:10,630] Trial 55 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.927313\tKL_Divergence = 0.033713\n",
      "Total time elapsed during training: 347.611 s\n",
      "Trial 55 pruned. \n",
      "Trial 55 pruned. \n",
      "Trial 55 pruned. \n",
      "Trial 55 pruned. \n",
      "Trial 55 pruned. \n",
      "Trial 55 pruned. \n",
      "Epoch: 1\tFidelity = 0.934777\tKL_Divergence = 0.024754\n",
      "Epoch: 2\tFidelity = 0.932971\tKL_Divergence = 0.025659\n",
      "Epoch: 3\tFidelity = 0.937482\tKL_Divergence = 0.021768\n",
      "Epoch: 4\tFidelity = 0.937914\tKL_Divergence = 0.021810\n",
      "Epoch: 5\tFidelity = 0.936414\tKL_Divergence = 0.024202\n",
      "Epoch: 6\tFidelity = 0.939195\tKL_Divergence = 0.021339\n",
      "Epoch: 7\tFidelity = 0.935537\tKL_Divergence = 0.024199\n",
      "Epoch: 8\tFidelity = 0.938143\tKL_Divergence = 0.021399\n",
      "Epoch: 9\tFidelity = 0.936531\tKL_Divergence = 0.022043\n",
      "Epoch: 10\tFidelity = 0.937323\tKL_Divergence = 0.022248\n",
      "Epoch: 11\tFidelity = 0.935548\tKL_Divergence = 0.023945\n",
      "Epoch: 12\tFidelity = 0.933925\tKL_Divergence = 0.023141\n",
      "Epoch: 13\tFidelity = 0.936029\tKL_Divergence = 0.024111\n",
      "Epoch: 14\tFidelity = 0.936410\tKL_Divergence = 0.022091\n",
      "Epoch: 15\tFidelity = 0.936409\tKL_Divergence = 0.023007\n",
      "Epoch: 16\tFidelity = 0.936681\tKL_Divergence = 0.022215\n",
      "Epoch: 17\tFidelity = 0.937364\tKL_Divergence = 0.021492\n",
      "Epoch: 18\tFidelity = 0.936720\tKL_Divergence = 0.021801\n",
      "Epoch: 19\tFidelity = 0.935251\tKL_Divergence = 0.023062\n",
      "Epoch: 20\tFidelity = 0.934367\tKL_Divergence = 0.024585\n",
      "Epoch: 21\tFidelity = 0.933855\tKL_Divergence = 0.026343\n",
      "Epoch: 22\tFidelity = 0.929366\tKL_Divergence = 0.031163\n",
      "Epoch: 23\tFidelity = 0.933676\tKL_Divergence = 0.024944\n",
      "Epoch: 24\tFidelity = 0.934567\tKL_Divergence = 0.026432\n",
      "Epoch: 25\tFidelity = 0.938405\tKL_Divergence = 0.021785\n",
      "Epoch: 26\tFidelity = 0.930543\tKL_Divergence = 0.025319\n",
      "Epoch: 27\tFidelity = 0.938923\tKL_Divergence = 0.021106\n",
      "Epoch: 28\tFidelity = 0.934715\tKL_Divergence = 0.025796\n",
      "Epoch: 29\tFidelity = 0.936866\tKL_Divergence = 0.021804\n",
      "Epoch: 30\tFidelity = 0.933946\tKL_Divergence = 0.023299\n",
      "Epoch: 31\tFidelity = 0.935713\tKL_Divergence = 0.022241\n",
      "Epoch: 32\tFidelity = 0.936671\tKL_Divergence = 0.021894\n",
      "Epoch: 33\tFidelity = 0.935937\tKL_Divergence = 0.022577\n",
      "Epoch: 34\tFidelity = 0.931326\tKL_Divergence = 0.024814\n",
      "Epoch: 35\tFidelity = 0.934102\tKL_Divergence = 0.023587\n",
      "Epoch: 36\tFidelity = 0.935979\tKL_Divergence = 0.023887\n",
      "Epoch: 37\tFidelity = 0.936751\tKL_Divergence = 0.021989\n",
      "Epoch: 38\tFidelity = 0.932482\tKL_Divergence = 0.025264\n",
      "Epoch: 39\tFidelity = 0.935299\tKL_Divergence = 0.023591\n",
      "Epoch: 40\tFidelity = 0.935840\tKL_Divergence = 0.023643\n",
      "Epoch: 41\tFidelity = 0.934919\tKL_Divergence = 0.023070\n",
      "Epoch: 42\tFidelity = 0.934039\tKL_Divergence = 0.024152\n",
      "Epoch: 43\tFidelity = 0.934642\tKL_Divergence = 0.024729\n",
      "Epoch: 44\tFidelity = 0.937881\tKL_Divergence = 0.021562\n",
      "Epoch: 45\tFidelity = 0.936567\tKL_Divergence = 0.023695\n",
      "Epoch: 46\tFidelity = 0.929358\tKL_Divergence = 0.033096\n",
      "Epoch: 47\tFidelity = 0.934632\tKL_Divergence = 0.028508\n",
      "Epoch: 48\tFidelity = 0.934479\tKL_Divergence = 0.023724\n",
      "Epoch: 49\tFidelity = 0.936638\tKL_Divergence = 0.022793\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:36:37,525] Trial 56 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.933089\tKL_Divergence = 0.027513\n",
      "Total time elapsed during training: 326.551 s\n",
      "Trial 56 pruned. \n",
      "Trial 56 pruned. \n",
      "Trial 56 pruned. \n",
      "Trial 56 pruned. \n",
      "Trial 56 pruned. \n",
      "Trial 56 pruned. \n",
      "Epoch: 1\tFidelity = 0.938026\tKL_Divergence = 0.021616\n",
      "Epoch: 2\tFidelity = 0.933669\tKL_Divergence = 0.025948\n",
      "Epoch: 3\tFidelity = 0.933530\tKL_Divergence = 0.026215\n",
      "Epoch: 4\tFidelity = 0.935028\tKL_Divergence = 0.023275\n",
      "Epoch: 5\tFidelity = 0.935781\tKL_Divergence = 0.022425\n",
      "Epoch: 6\tFidelity = 0.933643\tKL_Divergence = 0.024220\n",
      "Epoch: 7\tFidelity = 0.931115\tKL_Divergence = 0.029371\n",
      "Epoch: 8\tFidelity = 0.935073\tKL_Divergence = 0.023586\n",
      "Epoch: 9\tFidelity = 0.930384\tKL_Divergence = 0.030582\n",
      "Epoch: 10\tFidelity = 0.936966\tKL_Divergence = 0.022105\n",
      "Epoch: 11\tFidelity = 0.935137\tKL_Divergence = 0.022833\n",
      "Epoch: 12\tFidelity = 0.933984\tKL_Divergence = 0.025097\n",
      "Epoch: 13\tFidelity = 0.932330\tKL_Divergence = 0.026972\n",
      "Epoch: 14\tFidelity = 0.935362\tKL_Divergence = 0.022892\n",
      "Epoch: 15\tFidelity = 0.935676\tKL_Divergence = 0.023012\n",
      "Epoch: 16\tFidelity = 0.936061\tKL_Divergence = 0.023318\n",
      "Epoch: 17\tFidelity = 0.935725\tKL_Divergence = 0.022537\n",
      "Epoch: 18\tFidelity = 0.931242\tKL_Divergence = 0.026335\n",
      "Epoch: 19\tFidelity = 0.927139\tKL_Divergence = 0.028660\n",
      "Epoch: 20\tFidelity = 0.936635\tKL_Divergence = 0.022578\n",
      "Epoch: 21\tFidelity = 0.934860\tKL_Divergence = 0.026257\n",
      "Epoch: 22\tFidelity = 0.933658\tKL_Divergence = 0.027257\n",
      "Epoch: 23\tFidelity = 0.937287\tKL_Divergence = 0.022160\n",
      "Epoch: 24\tFidelity = 0.937870\tKL_Divergence = 0.021971\n",
      "Epoch: 25\tFidelity = 0.936999\tKL_Divergence = 0.023008\n",
      "Epoch: 26\tFidelity = 0.936719\tKL_Divergence = 0.022025\n",
      "Epoch: 27\tFidelity = 0.935070\tKL_Divergence = 0.023099\n",
      "Epoch: 28\tFidelity = 0.931469\tKL_Divergence = 0.024332\n",
      "Epoch: 29\tFidelity = 0.932217\tKL_Divergence = 0.033232\n",
      "Epoch: 30\tFidelity = 0.927981\tKL_Divergence = 0.029356\n",
      "Epoch: 31\tFidelity = 0.934608\tKL_Divergence = 0.022911\n",
      "Epoch: 32\tFidelity = 0.932578\tKL_Divergence = 0.025636\n",
      "Epoch: 33\tFidelity = 0.934684\tKL_Divergence = 0.025218\n",
      "Epoch: 34\tFidelity = 0.934557\tKL_Divergence = 0.025159\n",
      "Epoch: 35\tFidelity = 0.935107\tKL_Divergence = 0.023429\n",
      "Epoch: 36\tFidelity = 0.935465\tKL_Divergence = 0.022692\n",
      "Epoch: 37\tFidelity = 0.932827\tKL_Divergence = 0.024513\n",
      "Epoch: 38\tFidelity = 0.933124\tKL_Divergence = 0.024725\n",
      "Epoch: 39\tFidelity = 0.934222\tKL_Divergence = 0.023472\n",
      "Epoch: 40\tFidelity = 0.935946\tKL_Divergence = 0.022888\n",
      "Epoch: 41\tFidelity = 0.935374\tKL_Divergence = 0.022735\n",
      "Epoch: 42\tFidelity = 0.933736\tKL_Divergence = 0.025354\n",
      "Epoch: 43\tFidelity = 0.934859\tKL_Divergence = 0.023604\n",
      "Epoch: 44\tFidelity = 0.932970\tKL_Divergence = 0.026340\n",
      "Epoch: 45\tFidelity = 0.936067\tKL_Divergence = 0.025856\n",
      "Epoch: 46\tFidelity = 0.936905\tKL_Divergence = 0.022157\n",
      "Epoch: 47\tFidelity = 0.936669\tKL_Divergence = 0.022143\n",
      "Epoch: 48\tFidelity = 0.931679\tKL_Divergence = 0.027824\n",
      "Epoch: 49\tFidelity = 0.924252\tKL_Divergence = 0.038455\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:44:57,048] Trial 57 finished with value: 0.02145553797915265 and parameters: {'lr': 5.37842092161061, 'pbs': 2000, 'nbs': 3000}. Best is trial 57 with value: 0.02145553797915265.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.938846\tKL_Divergence = 0.021456\n",
      "Total time elapsed during training: 499.185 s\n",
      "Trial 57 finished with value: 0.02145553797915265 and parameters: {'lr': 5.37842092161061, 'pbs': 2000, 'nbs': 3000}. Best is trial 57 with value: 0.02145553797915265.\n",
      "Trial 57 finished with value: 0.02145553797915265 and parameters: {'lr': 5.37842092161061, 'pbs': 2000, 'nbs': 3000}. Best is trial 57 with value: 0.02145553797915265.\n",
      "Trial 57 finished with value: 0.02145553797915265 and parameters: {'lr': 5.37842092161061, 'pbs': 2000, 'nbs': 3000}. Best is trial 57 with value: 0.02145553797915265.\n",
      "Trial 57 finished with value: 0.02145553797915265 and parameters: {'lr': 5.37842092161061, 'pbs': 2000, 'nbs': 3000}. Best is trial 57 with value: 0.02145553797915265.\n",
      "Trial 57 finished with value: 0.02145553797915265 and parameters: {'lr': 5.37842092161061, 'pbs': 2000, 'nbs': 3000}. Best is trial 57 with value: 0.02145553797915265.\n",
      "Trial 57 finished with value: 0.02145553797915265 and parameters: {'lr': 5.37842092161061, 'pbs': 2000, 'nbs': 3000}. Best is trial 57 with value: 0.02145553797915265.\n",
      "Epoch: 1\tFidelity = 0.932436\tKL_Divergence = 0.026777\n",
      "Epoch: 2\tFidelity = 0.931494\tKL_Divergence = 0.026277\n",
      "Epoch: 3\tFidelity = 0.932173\tKL_Divergence = 0.024803\n",
      "Epoch: 4\tFidelity = 0.936694\tKL_Divergence = 0.022338\n",
      "Epoch: 5\tFidelity = 0.936022\tKL_Divergence = 0.022363\n",
      "Epoch: 6\tFidelity = 0.932493\tKL_Divergence = 0.028057\n",
      "Epoch: 7\tFidelity = 0.934861\tKL_Divergence = 0.023797\n",
      "Epoch: 8\tFidelity = 0.937419\tKL_Divergence = 0.021961\n",
      "Epoch: 9\tFidelity = 0.934454\tKL_Divergence = 0.024955\n",
      "Epoch: 10\tFidelity = 0.930722\tKL_Divergence = 0.027329\n",
      "Epoch: 11\tFidelity = 0.936718\tKL_Divergence = 0.022213\n",
      "Epoch: 12\tFidelity = 0.935731\tKL_Divergence = 0.024254\n",
      "Epoch: 13\tFidelity = 0.931008\tKL_Divergence = 0.026857\n",
      "Epoch: 14\tFidelity = 0.932223\tKL_Divergence = 0.024162\n",
      "Epoch: 15\tFidelity = 0.934922\tKL_Divergence = 0.025210\n",
      "Epoch: 16\tFidelity = 0.937840\tKL_Divergence = 0.023501\n",
      "Epoch: 17\tFidelity = 0.935752\tKL_Divergence = 0.024430\n",
      "Epoch: 18\tFidelity = 0.933948\tKL_Divergence = 0.023520\n",
      "Epoch: 19\tFidelity = 0.936329\tKL_Divergence = 0.023700\n",
      "Epoch: 20\tFidelity = 0.938354\tKL_Divergence = 0.021472\n",
      "Epoch: 21\tFidelity = 0.934604\tKL_Divergence = 0.024215\n",
      "Epoch: 22\tFidelity = 0.931709\tKL_Divergence = 0.024581\n",
      "Epoch: 23\tFidelity = 0.935523\tKL_Divergence = 0.022784\n",
      "Epoch: 24\tFidelity = 0.929766\tKL_Divergence = 0.038127\n",
      "Epoch: 25\tFidelity = 0.935496\tKL_Divergence = 0.024723\n",
      "Epoch: 26\tFidelity = 0.937335\tKL_Divergence = 0.023233\n",
      "Epoch: 27\tFidelity = 0.936836\tKL_Divergence = 0.022450\n",
      "Epoch: 28\tFidelity = 0.936784\tKL_Divergence = 0.022859\n",
      "Epoch: 29\tFidelity = 0.935481\tKL_Divergence = 0.022693\n",
      "Epoch: 30\tFidelity = 0.930865\tKL_Divergence = 0.029269\n",
      "Epoch: 31\tFidelity = 0.930379\tKL_Divergence = 0.025781\n",
      "Epoch: 32\tFidelity = 0.933871\tKL_Divergence = 0.026430\n",
      "Epoch: 33\tFidelity = 0.932472\tKL_Divergence = 0.023908\n",
      "Epoch: 34\tFidelity = 0.936493\tKL_Divergence = 0.024496\n",
      "Epoch: 35\tFidelity = 0.934909\tKL_Divergence = 0.025536\n",
      "Epoch: 36\tFidelity = 0.932007\tKL_Divergence = 0.030602\n",
      "Epoch: 37\tFidelity = 0.931544\tKL_Divergence = 0.030033\n",
      "Epoch: 38\tFidelity = 0.936804\tKL_Divergence = 0.021832\n",
      "Epoch: 39\tFidelity = 0.931148\tKL_Divergence = 0.024580\n",
      "Epoch: 40\tFidelity = 0.933635\tKL_Divergence = 0.023582\n",
      "Epoch: 41\tFidelity = 0.934562\tKL_Divergence = 0.024188\n",
      "Epoch: 42\tFidelity = 0.936771\tKL_Divergence = 0.022172\n",
      "Epoch: 43\tFidelity = 0.924272\tKL_Divergence = 0.043948\n",
      "Epoch: 44\tFidelity = 0.936129\tKL_Divergence = 0.025168\n",
      "Epoch: 45\tFidelity = 0.938054\tKL_Divergence = 0.022009\n",
      "Epoch: 46\tFidelity = 0.925334\tKL_Divergence = 0.037678\n",
      "Epoch: 47\tFidelity = 0.934103\tKL_Divergence = 0.025331\n",
      "Epoch: 48\tFidelity = 0.935360\tKL_Divergence = 0.022623\n",
      "Epoch: 49\tFidelity = 0.930221\tKL_Divergence = 0.030364\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:53:19,881] Trial 58 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.931206\tKL_Divergence = 0.029662\n",
      "Total time elapsed during training: 502.500 s\n",
      "Trial 58 pruned. \n",
      "Trial 58 pruned. \n",
      "Trial 58 pruned. \n",
      "Trial 58 pruned. \n",
      "Trial 58 pruned. \n",
      "Trial 58 pruned. \n",
      "Epoch: 1\tFidelity = 0.934659\tKL_Divergence = 0.023928\n",
      "Epoch: 2\tFidelity = 0.930542\tKL_Divergence = 0.030222\n",
      "Epoch: 3\tFidelity = 0.934941\tKL_Divergence = 0.023185\n",
      "Epoch: 4\tFidelity = 0.933777\tKL_Divergence = 0.023753\n",
      "Epoch: 5\tFidelity = 0.932598\tKL_Divergence = 0.026208\n",
      "Epoch: 6\tFidelity = 0.919709\tKL_Divergence = 0.049325\n",
      "Epoch: 7\tFidelity = 0.936419\tKL_Divergence = 0.024116\n",
      "Epoch: 8\tFidelity = 0.935501\tKL_Divergence = 0.026259\n",
      "Epoch: 9\tFidelity = 0.937988\tKL_Divergence = 0.021902\n",
      "Epoch: 10\tFidelity = 0.937077\tKL_Divergence = 0.024975\n",
      "Epoch: 11\tFidelity = 0.937635\tKL_Divergence = 0.022199\n",
      "Epoch: 12\tFidelity = 0.935506\tKL_Divergence = 0.024360\n",
      "Epoch: 13\tFidelity = 0.934944\tKL_Divergence = 0.022994\n",
      "Epoch: 14\tFidelity = 0.935880\tKL_Divergence = 0.022467\n",
      "Epoch: 15\tFidelity = 0.932919\tKL_Divergence = 0.023830\n",
      "Epoch: 16\tFidelity = 0.929547\tKL_Divergence = 0.026542\n",
      "Epoch: 17\tFidelity = 0.934361\tKL_Divergence = 0.023645\n",
      "Epoch: 18\tFidelity = 0.934063\tKL_Divergence = 0.023577\n",
      "Epoch: 19\tFidelity = 0.934429\tKL_Divergence = 0.025114\n",
      "Epoch: 20\tFidelity = 0.931641\tKL_Divergence = 0.025368\n",
      "Epoch: 21\tFidelity = 0.937234\tKL_Divergence = 0.023844\n",
      "Epoch: 22\tFidelity = 0.937184\tKL_Divergence = 0.022233\n",
      "Epoch: 23\tFidelity = 0.934972\tKL_Divergence = 0.023762\n",
      "Epoch: 24\tFidelity = 0.936498\tKL_Divergence = 0.022511\n",
      "Epoch: 25\tFidelity = 0.938686\tKL_Divergence = 0.021859\n",
      "Epoch: 26\tFidelity = 0.933085\tKL_Divergence = 0.024950\n",
      "Epoch: 27\tFidelity = 0.927917\tKL_Divergence = 0.031868\n",
      "Epoch: 28\tFidelity = 0.936515\tKL_Divergence = 0.022163\n",
      "Epoch: 29\tFidelity = 0.935528\tKL_Divergence = 0.025444\n",
      "Epoch: 30\tFidelity = 0.931251\tKL_Divergence = 0.032412\n",
      "Epoch: 31\tFidelity = 0.937376\tKL_Divergence = 0.021773\n",
      "Epoch: 32\tFidelity = 0.938219\tKL_Divergence = 0.021906\n",
      "Epoch: 33\tFidelity = 0.937711\tKL_Divergence = 0.022060\n",
      "Epoch: 34\tFidelity = 0.934135\tKL_Divergence = 0.025841\n",
      "Epoch: 35\tFidelity = 0.940040\tKL_Divergence = 0.021296\n",
      "Epoch: 36\tFidelity = 0.939312\tKL_Divergence = 0.020702\n",
      "Epoch: 37\tFidelity = 0.926860\tKL_Divergence = 0.027709\n",
      "Epoch: 38\tFidelity = 0.926825\tKL_Divergence = 0.031921\n",
      "Epoch: 39\tFidelity = 0.932643\tKL_Divergence = 0.024699\n",
      "Epoch: 40\tFidelity = 0.936859\tKL_Divergence = 0.021981\n",
      "Epoch: 41\tFidelity = 0.937907\tKL_Divergence = 0.021967\n",
      "Epoch: 42\tFidelity = 0.937530\tKL_Divergence = 0.021757\n",
      "Epoch: 43\tFidelity = 0.934767\tKL_Divergence = 0.025456\n",
      "Epoch: 44\tFidelity = 0.933611\tKL_Divergence = 0.025459\n",
      "Epoch: 45\tFidelity = 0.935973\tKL_Divergence = 0.023810\n",
      "Epoch: 46\tFidelity = 0.936906\tKL_Divergence = 0.022247\n",
      "Epoch: 47\tFidelity = 0.936179\tKL_Divergence = 0.026038\n",
      "Epoch: 48\tFidelity = 0.933453\tKL_Divergence = 0.026978\n",
      "Epoch: 49\tFidelity = 0.934029\tKL_Divergence = 0.023293\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:01:44,022] Trial 59 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.931713\tKL_Divergence = 0.027743\n",
      "Total time elapsed during training: 503.819 s\n",
      "Trial 59 pruned. \n",
      "Trial 59 pruned. \n",
      "Trial 59 pruned. \n",
      "Trial 59 pruned. \n",
      "Trial 59 pruned. \n",
      "Trial 59 pruned. \n",
      "Epoch: 1\tFidelity = 0.935741\tKL_Divergence = 0.022856\n",
      "Epoch: 2\tFidelity = 0.934493\tKL_Divergence = 0.024614\n",
      "Epoch: 3\tFidelity = 0.936554\tKL_Divergence = 0.022143\n",
      "Epoch: 4\tFidelity = 0.931004\tKL_Divergence = 0.026258\n",
      "Epoch: 5\tFidelity = 0.936756\tKL_Divergence = 0.022428\n",
      "Epoch: 6\tFidelity = 0.934980\tKL_Divergence = 0.024822\n",
      "Epoch: 7\tFidelity = 0.936391\tKL_Divergence = 0.023465\n",
      "Epoch: 8\tFidelity = 0.935698\tKL_Divergence = 0.022801\n",
      "Epoch: 9\tFidelity = 0.933167\tKL_Divergence = 0.026877\n",
      "Epoch: 10\tFidelity = 0.933739\tKL_Divergence = 0.032018\n",
      "Epoch: 11\tFidelity = 0.935965\tKL_Divergence = 0.022932\n",
      "Epoch: 12\tFidelity = 0.934362\tKL_Divergence = 0.024537\n",
      "Epoch: 13\tFidelity = 0.933417\tKL_Divergence = 0.025751\n",
      "Epoch: 14\tFidelity = 0.935678\tKL_Divergence = 0.025642\n",
      "Epoch: 15\tFidelity = 0.936890\tKL_Divergence = 0.022393\n",
      "Epoch: 16\tFidelity = 0.936318\tKL_Divergence = 0.023355\n",
      "Epoch: 17\tFidelity = 0.927614\tKL_Divergence = 0.034950\n",
      "Epoch: 18\tFidelity = 0.933835\tKL_Divergence = 0.023992\n",
      "Epoch: 19\tFidelity = 0.932924\tKL_Divergence = 0.031429\n",
      "Epoch: 20\tFidelity = 0.928470\tKL_Divergence = 0.032409\n",
      "Epoch: 21\tFidelity = 0.933987\tKL_Divergence = 0.023609\n",
      "Epoch: 22\tFidelity = 0.934011\tKL_Divergence = 0.023362\n",
      "Epoch: 23\tFidelity = 0.932187\tKL_Divergence = 0.024186\n",
      "Epoch: 24\tFidelity = 0.938270\tKL_Divergence = 0.021888\n",
      "Epoch: 25\tFidelity = 0.939221\tKL_Divergence = 0.021191\n",
      "Epoch: 26\tFidelity = 0.937008\tKL_Divergence = 0.022229\n",
      "Epoch: 27\tFidelity = 0.936574\tKL_Divergence = 0.022806\n",
      "Epoch: 28\tFidelity = 0.935759\tKL_Divergence = 0.022692\n",
      "Epoch: 29\tFidelity = 0.933223\tKL_Divergence = 0.025918\n",
      "Epoch: 30\tFidelity = 0.936393\tKL_Divergence = 0.022696\n",
      "Epoch: 31\tFidelity = 0.936622\tKL_Divergence = 0.022493\n",
      "Epoch: 32\tFidelity = 0.931063\tKL_Divergence = 0.026770\n",
      "Epoch: 33\tFidelity = 0.937337\tKL_Divergence = 0.025043\n",
      "Epoch: 34\tFidelity = 0.937059\tKL_Divergence = 0.022432\n",
      "Epoch: 35\tFidelity = 0.936558\tKL_Divergence = 0.022288\n",
      "Epoch: 36\tFidelity = 0.937802\tKL_Divergence = 0.021668\n",
      "Epoch: 37\tFidelity = 0.933932\tKL_Divergence = 0.023213\n",
      "Epoch: 38\tFidelity = 0.937693\tKL_Divergence = 0.021551\n",
      "Epoch: 39\tFidelity = 0.936397\tKL_Divergence = 0.022378\n",
      "Epoch: 40\tFidelity = 0.936693\tKL_Divergence = 0.022128\n",
      "Epoch: 41\tFidelity = 0.937539\tKL_Divergence = 0.021999\n",
      "Epoch: 42\tFidelity = 0.933632\tKL_Divergence = 0.029193\n",
      "Epoch: 43\tFidelity = 0.933577\tKL_Divergence = 0.028275\n",
      "Epoch: 44\tFidelity = 0.937180\tKL_Divergence = 0.022761\n",
      "Epoch: 45\tFidelity = 0.932456\tKL_Divergence = 0.026249\n",
      "Epoch: 46\tFidelity = 0.937742\tKL_Divergence = 0.021751\n",
      "Epoch: 47\tFidelity = 0.936039\tKL_Divergence = 0.022576\n",
      "Epoch: 48\tFidelity = 0.936992\tKL_Divergence = 0.025289\n",
      "Epoch: 49\tFidelity = 0.935589\tKL_Divergence = 0.023144\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:10:01,361] Trial 60 finished with value: 0.021789177401485102 and parameters: {'lr': 5.48219438587806, 'pbs': 2000, 'nbs': 3000}. Best is trial 57 with value: 0.02145553797915265.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.938284\tKL_Divergence = 0.021789\n",
      "Total time elapsed during training: 497.034 s\n",
      "Trial 60 finished with value: 0.021789177401485102 and parameters: {'lr': 5.48219438587806, 'pbs': 2000, 'nbs': 3000}. Best is trial 57 with value: 0.02145553797915265.\n",
      "Trial 60 finished with value: 0.021789177401485102 and parameters: {'lr': 5.48219438587806, 'pbs': 2000, 'nbs': 3000}. Best is trial 57 with value: 0.02145553797915265.\n",
      "Trial 60 finished with value: 0.021789177401485102 and parameters: {'lr': 5.48219438587806, 'pbs': 2000, 'nbs': 3000}. Best is trial 57 with value: 0.02145553797915265.\n",
      "Trial 60 finished with value: 0.021789177401485102 and parameters: {'lr': 5.48219438587806, 'pbs': 2000, 'nbs': 3000}. Best is trial 57 with value: 0.02145553797915265.\n",
      "Trial 60 finished with value: 0.021789177401485102 and parameters: {'lr': 5.48219438587806, 'pbs': 2000, 'nbs': 3000}. Best is trial 57 with value: 0.02145553797915265.\n",
      "Trial 60 finished with value: 0.021789177401485102 and parameters: {'lr': 5.48219438587806, 'pbs': 2000, 'nbs': 3000}. Best is trial 57 with value: 0.02145553797915265.\n",
      "Epoch: 1\tFidelity = 0.938479\tKL_Divergence = 0.022031\n",
      "Epoch: 2\tFidelity = 0.938359\tKL_Divergence = 0.022138\n",
      "Epoch: 3\tFidelity = 0.935847\tKL_Divergence = 0.024619\n",
      "Epoch: 4\tFidelity = 0.936834\tKL_Divergence = 0.024020\n",
      "Epoch: 5\tFidelity = 0.930338\tKL_Divergence = 0.028376\n",
      "Epoch: 6\tFidelity = 0.934519\tKL_Divergence = 0.023609\n",
      "Epoch: 7\tFidelity = 0.935189\tKL_Divergence = 0.025800\n",
      "Epoch: 8\tFidelity = 0.937686\tKL_Divergence = 0.022117\n",
      "Epoch: 9\tFidelity = 0.935487\tKL_Divergence = 0.022819\n",
      "Epoch: 10\tFidelity = 0.934639\tKL_Divergence = 0.023741\n",
      "Epoch: 11\tFidelity = 0.935071\tKL_Divergence = 0.024785\n",
      "Epoch: 12\tFidelity = 0.932942\tKL_Divergence = 0.025503\n",
      "Epoch: 13\tFidelity = 0.932883\tKL_Divergence = 0.027454\n",
      "Epoch: 14\tFidelity = 0.935188\tKL_Divergence = 0.023095\n",
      "Epoch: 15\tFidelity = 0.938760\tKL_Divergence = 0.021399\n",
      "Epoch: 16\tFidelity = 0.936063\tKL_Divergence = 0.023110\n",
      "Epoch: 17\tFidelity = 0.934354\tKL_Divergence = 0.023340\n",
      "Epoch: 18\tFidelity = 0.931648\tKL_Divergence = 0.030760\n",
      "Epoch: 19\tFidelity = 0.936852\tKL_Divergence = 0.022408\n",
      "Epoch: 20\tFidelity = 0.935807\tKL_Divergence = 0.022993\n",
      "Epoch: 21\tFidelity = 0.936374\tKL_Divergence = 0.022131\n",
      "Epoch: 22\tFidelity = 0.935097\tKL_Divergence = 0.023444\n",
      "Epoch: 23\tFidelity = 0.934320\tKL_Divergence = 0.022907\n",
      "Epoch: 24\tFidelity = 0.934474\tKL_Divergence = 0.023060\n",
      "Epoch: 25\tFidelity = 0.932298\tKL_Divergence = 0.023922\n",
      "Epoch: 26\tFidelity = 0.933872\tKL_Divergence = 0.024370\n",
      "Epoch: 27\tFidelity = 0.934304\tKL_Divergence = 0.024743\n",
      "Epoch: 28\tFidelity = 0.936493\tKL_Divergence = 0.022539\n",
      "Epoch: 29\tFidelity = 0.933408\tKL_Divergence = 0.026300\n",
      "Epoch: 30\tFidelity = 0.925772\tKL_Divergence = 0.037671\n",
      "Epoch: 31\tFidelity = 0.931484\tKL_Divergence = 0.024768\n",
      "Epoch: 32\tFidelity = 0.933362\tKL_Divergence = 0.029599\n",
      "Epoch: 33\tFidelity = 0.931188\tKL_Divergence = 0.026157\n",
      "Epoch: 34\tFidelity = 0.934054\tKL_Divergence = 0.023430\n",
      "Epoch: 35\tFidelity = 0.927390\tKL_Divergence = 0.030619\n",
      "Epoch: 36\tFidelity = 0.936603\tKL_Divergence = 0.024191\n",
      "Epoch: 37\tFidelity = 0.930597\tKL_Divergence = 0.025173\n",
      "Epoch: 38\tFidelity = 0.936759\tKL_Divergence = 0.022485\n",
      "Epoch: 39\tFidelity = 0.938339\tKL_Divergence = 0.021776\n",
      "Epoch: 40\tFidelity = 0.936227\tKL_Divergence = 0.022578\n",
      "Epoch: 41\tFidelity = 0.936308\tKL_Divergence = 0.022766\n",
      "Epoch: 42\tFidelity = 0.933683\tKL_Divergence = 0.024926\n",
      "Epoch: 43\tFidelity = 0.934024\tKL_Divergence = 0.025132\n",
      "Epoch: 44\tFidelity = 0.932559\tKL_Divergence = 0.025633\n",
      "Epoch: 45\tFidelity = 0.934549\tKL_Divergence = 0.024074\n",
      "Epoch: 46\tFidelity = 0.935160\tKL_Divergence = 0.025544\n",
      "Epoch: 47\tFidelity = 0.934254\tKL_Divergence = 0.023276\n",
      "Epoch: 48\tFidelity = 0.936743\tKL_Divergence = 0.022372\n",
      "Epoch: 49\tFidelity = 0.933704\tKL_Divergence = 0.026178\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:18:22,179] Trial 61 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.936800\tKL_Divergence = 0.022378\n",
      "Total time elapsed during training: 500.497 s\n",
      "Trial 61 pruned. \n",
      "Trial 61 pruned. \n",
      "Trial 61 pruned. \n",
      "Trial 61 pruned. \n",
      "Trial 61 pruned. \n",
      "Trial 61 pruned. \n",
      "Epoch: 1\tFidelity = 0.934922\tKL_Divergence = 0.022924\n",
      "Epoch: 2\tFidelity = 0.931710\tKL_Divergence = 0.027373\n",
      "Epoch: 3\tFidelity = 0.934204\tKL_Divergence = 0.025037\n",
      "Epoch: 4\tFidelity = 0.934993\tKL_Divergence = 0.023918\n",
      "Epoch: 5\tFidelity = 0.935096\tKL_Divergence = 0.024688\n",
      "Epoch: 6\tFidelity = 0.934954\tKL_Divergence = 0.022993\n",
      "Epoch: 7\tFidelity = 0.934203\tKL_Divergence = 0.025821\n",
      "Epoch: 8\tFidelity = 0.928939\tKL_Divergence = 0.029998\n",
      "Epoch: 9\tFidelity = 0.936065\tKL_Divergence = 0.023168\n",
      "Epoch: 10\tFidelity = 0.936737\tKL_Divergence = 0.022538\n",
      "Epoch: 11\tFidelity = 0.933624\tKL_Divergence = 0.028597\n",
      "Epoch: 12\tFidelity = 0.934549\tKL_Divergence = 0.024993\n",
      "Epoch: 13\tFidelity = 0.935567\tKL_Divergence = 0.022667\n",
      "Epoch: 14\tFidelity = 0.935609\tKL_Divergence = 0.022692\n",
      "Epoch: 15\tFidelity = 0.935455\tKL_Divergence = 0.022878\n",
      "Epoch: 16\tFidelity = 0.934511\tKL_Divergence = 0.024214\n",
      "Epoch: 17\tFidelity = 0.934183\tKL_Divergence = 0.023804\n",
      "Epoch: 18\tFidelity = 0.936684\tKL_Divergence = 0.022443\n",
      "Epoch: 19\tFidelity = 0.938074\tKL_Divergence = 0.022375\n",
      "Epoch: 20\tFidelity = 0.928585\tKL_Divergence = 0.026082\n",
      "Epoch: 21\tFidelity = 0.931281\tKL_Divergence = 0.028271\n",
      "Epoch: 22\tFidelity = 0.936790\tKL_Divergence = 0.022190\n",
      "Epoch: 23\tFidelity = 0.937824\tKL_Divergence = 0.022073\n",
      "Epoch: 24\tFidelity = 0.936801\tKL_Divergence = 0.022301\n",
      "Epoch: 25\tFidelity = 0.934024\tKL_Divergence = 0.029623\n",
      "Epoch: 26\tFidelity = 0.935367\tKL_Divergence = 0.023123\n",
      "Epoch: 27\tFidelity = 0.937479\tKL_Divergence = 0.021840\n",
      "Epoch: 28\tFidelity = 0.934316\tKL_Divergence = 0.024952\n",
      "Epoch: 29\tFidelity = 0.937791\tKL_Divergence = 0.021976\n",
      "Epoch: 30\tFidelity = 0.937179\tKL_Divergence = 0.022101\n",
      "Epoch: 31\tFidelity = 0.933312\tKL_Divergence = 0.029323\n",
      "Epoch: 32\tFidelity = 0.937414\tKL_Divergence = 0.021796\n",
      "Epoch: 33\tFidelity = 0.933894\tKL_Divergence = 0.023703\n",
      "Epoch: 34\tFidelity = 0.936834\tKL_Divergence = 0.022217\n",
      "Epoch: 35\tFidelity = 0.938901\tKL_Divergence = 0.021797\n",
      "Epoch: 36\tFidelity = 0.936801\tKL_Divergence = 0.022742\n",
      "Epoch: 37\tFidelity = 0.935606\tKL_Divergence = 0.023370\n",
      "Epoch: 38\tFidelity = 0.935439\tKL_Divergence = 0.022505\n",
      "Epoch: 39\tFidelity = 0.936062\tKL_Divergence = 0.023005\n",
      "Epoch: 40\tFidelity = 0.925194\tKL_Divergence = 0.034816\n",
      "Epoch: 41\tFidelity = 0.934529\tKL_Divergence = 0.028464\n",
      "Epoch: 42\tFidelity = 0.937318\tKL_Divergence = 0.022165\n",
      "Epoch: 43\tFidelity = 0.935946\tKL_Divergence = 0.024701\n",
      "Epoch: 44\tFidelity = 0.937311\tKL_Divergence = 0.022143\n",
      "Epoch: 45\tFidelity = 0.936323\tKL_Divergence = 0.025613\n",
      "Epoch: 46\tFidelity = 0.934627\tKL_Divergence = 0.023448\n",
      "Epoch: 47\tFidelity = 0.936248\tKL_Divergence = 0.022166\n",
      "Epoch: 48\tFidelity = 0.938165\tKL_Divergence = 0.021760\n",
      "Epoch: 49\tFidelity = 0.939196\tKL_Divergence = 0.021433\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:26:43,618] Trial 62 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.929565\tKL_Divergence = 0.033591\n",
      "Total time elapsed during training: 501.096 s\n",
      "Trial 62 pruned. \n",
      "Trial 62 pruned. \n",
      "Trial 62 pruned. \n",
      "Trial 62 pruned. \n",
      "Trial 62 pruned. \n",
      "Trial 62 pruned. \n",
      "Epoch: 1\tFidelity = 0.929535\tKL_Divergence = 0.032424\n",
      "Epoch: 2\tFidelity = 0.934238\tKL_Divergence = 0.023608\n",
      "Epoch: 3\tFidelity = 0.930356\tKL_Divergence = 0.036698\n",
      "Epoch: 4\tFidelity = 0.933964\tKL_Divergence = 0.026495\n",
      "Epoch: 5\tFidelity = 0.933647\tKL_Divergence = 0.029914\n",
      "Epoch: 6\tFidelity = 0.934570\tKL_Divergence = 0.024219\n",
      "Epoch: 7\tFidelity = 0.935552\tKL_Divergence = 0.023191\n",
      "Epoch: 8\tFidelity = 0.932656\tKL_Divergence = 0.024155\n",
      "Epoch: 9\tFidelity = 0.933942\tKL_Divergence = 0.028975\n",
      "Epoch: 10\tFidelity = 0.936851\tKL_Divergence = 0.022443\n",
      "Epoch: 11\tFidelity = 0.933745\tKL_Divergence = 0.032263\n",
      "Epoch: 12\tFidelity = 0.937563\tKL_Divergence = 0.021851\n",
      "Epoch: 13\tFidelity = 0.937666\tKL_Divergence = 0.021740\n",
      "Epoch: 14\tFidelity = 0.938645\tKL_Divergence = 0.022235\n",
      "Epoch: 15\tFidelity = 0.937327\tKL_Divergence = 0.023062\n",
      "Epoch: 16\tFidelity = 0.930507\tKL_Divergence = 0.031757\n",
      "Epoch: 17\tFidelity = 0.938061\tKL_Divergence = 0.022505\n",
      "Epoch: 18\tFidelity = 0.937282\tKL_Divergence = 0.023929\n",
      "Epoch: 19\tFidelity = 0.937999\tKL_Divergence = 0.022777\n",
      "Epoch: 20\tFidelity = 0.937179\tKL_Divergence = 0.023110\n",
      "Epoch: 21\tFidelity = 0.930664\tKL_Divergence = 0.028426\n",
      "Epoch: 22\tFidelity = 0.927601\tKL_Divergence = 0.025887\n",
      "Epoch: 23\tFidelity = 0.931045\tKL_Divergence = 0.029880\n",
      "Epoch: 24\tFidelity = 0.932745\tKL_Divergence = 0.025027\n",
      "Epoch: 25\tFidelity = 0.934075\tKL_Divergence = 0.023436\n",
      "Epoch: 26\tFidelity = 0.937286\tKL_Divergence = 0.021976\n",
      "Epoch: 27\tFidelity = 0.934374\tKL_Divergence = 0.023280\n",
      "Epoch: 28\tFidelity = 0.932581\tKL_Divergence = 0.024883\n",
      "Epoch: 29\tFidelity = 0.934500\tKL_Divergence = 0.026447\n",
      "Epoch: 30\tFidelity = 0.934237\tKL_Divergence = 0.024501\n",
      "Epoch: 31\tFidelity = 0.936067\tKL_Divergence = 0.022543\n",
      "Epoch: 32\tFidelity = 0.934192\tKL_Divergence = 0.026935\n",
      "Epoch: 33\tFidelity = 0.933866\tKL_Divergence = 0.024014\n",
      "Epoch: 34\tFidelity = 0.932416\tKL_Divergence = 0.027088\n",
      "Epoch: 35\tFidelity = 0.932934\tKL_Divergence = 0.026973\n",
      "Epoch: 36\tFidelity = 0.935417\tKL_Divergence = 0.024773\n",
      "Epoch: 37\tFidelity = 0.935478\tKL_Divergence = 0.023919\n",
      "Epoch: 38\tFidelity = 0.935855\tKL_Divergence = 0.024225\n",
      "Epoch: 39\tFidelity = 0.930031\tKL_Divergence = 0.028535\n",
      "Epoch: 40\tFidelity = 0.937139\tKL_Divergence = 0.022370\n",
      "Epoch: 41\tFidelity = 0.931900\tKL_Divergence = 0.029599\n",
      "Epoch: 42\tFidelity = 0.936723\tKL_Divergence = 0.024086\n",
      "Epoch: 43\tFidelity = 0.938707\tKL_Divergence = 0.021633\n",
      "Epoch: 44\tFidelity = 0.937981\tKL_Divergence = 0.021758\n",
      "Epoch: 45\tFidelity = 0.935807\tKL_Divergence = 0.022323\n",
      "Epoch: 46\tFidelity = 0.937176\tKL_Divergence = 0.022010\n",
      "Epoch: 47\tFidelity = 0.934951\tKL_Divergence = 0.024427\n",
      "Epoch: 48\tFidelity = 0.936138\tKL_Divergence = 0.022930\n",
      "Epoch: 49\tFidelity = 0.936767\tKL_Divergence = 0.022626\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:35:06,566] Trial 63 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.936941\tKL_Divergence = 0.024755\n",
      "Total time elapsed during training: 502.622 s\n",
      "Trial 63 pruned. \n",
      "Trial 63 pruned. \n",
      "Trial 63 pruned. \n",
      "Trial 63 pruned. \n",
      "Trial 63 pruned. \n",
      "Trial 63 pruned. \n",
      "Epoch: 1\tFidelity = 0.937531\tKL_Divergence = 0.021807\n",
      "Epoch: 2\tFidelity = 0.935890\tKL_Divergence = 0.023230\n",
      "Epoch: 3\tFidelity = 0.936254\tKL_Divergence = 0.023025\n",
      "Epoch: 4\tFidelity = 0.935165\tKL_Divergence = 0.024839\n",
      "Epoch: 5\tFidelity = 0.932621\tKL_Divergence = 0.027003\n",
      "Epoch: 6\tFidelity = 0.936302\tKL_Divergence = 0.022361\n",
      "Epoch: 7\tFidelity = 0.935431\tKL_Divergence = 0.023446\n",
      "Epoch: 8\tFidelity = 0.937451\tKL_Divergence = 0.021895\n",
      "Epoch: 9\tFidelity = 0.937430\tKL_Divergence = 0.021945\n",
      "Epoch: 10\tFidelity = 0.935454\tKL_Divergence = 0.024289\n",
      "Epoch: 11\tFidelity = 0.938390\tKL_Divergence = 0.021510\n",
      "Epoch: 12\tFidelity = 0.934885\tKL_Divergence = 0.023758\n",
      "Epoch: 13\tFidelity = 0.937145\tKL_Divergence = 0.022212\n",
      "Epoch: 14\tFidelity = 0.936758\tKL_Divergence = 0.022801\n",
      "Epoch: 15\tFidelity = 0.934939\tKL_Divergence = 0.024025\n",
      "Epoch: 16\tFidelity = 0.936925\tKL_Divergence = 0.022553\n",
      "Epoch: 17\tFidelity = 0.934957\tKL_Divergence = 0.025586\n",
      "Epoch: 18\tFidelity = 0.935432\tKL_Divergence = 0.023899\n",
      "Epoch: 19\tFidelity = 0.932858\tKL_Divergence = 0.025332\n",
      "Epoch: 20\tFidelity = 0.937907\tKL_Divergence = 0.021706\n",
      "Epoch: 21\tFidelity = 0.936666\tKL_Divergence = 0.022736\n",
      "Epoch: 22\tFidelity = 0.936882\tKL_Divergence = 0.022554\n",
      "Epoch: 23\tFidelity = 0.936378\tKL_Divergence = 0.022319\n",
      "Epoch: 24\tFidelity = 0.936488\tKL_Divergence = 0.022357\n",
      "Epoch: 25\tFidelity = 0.936913\tKL_Divergence = 0.023064\n",
      "Epoch: 26\tFidelity = 0.936725\tKL_Divergence = 0.022821\n",
      "Epoch: 27\tFidelity = 0.937249\tKL_Divergence = 0.022387\n",
      "Epoch: 28\tFidelity = 0.937893\tKL_Divergence = 0.021728\n",
      "Epoch: 29\tFidelity = 0.935682\tKL_Divergence = 0.023131\n",
      "Epoch: 30\tFidelity = 0.936456\tKL_Divergence = 0.022668\n",
      "Epoch: 31\tFidelity = 0.936513\tKL_Divergence = 0.022340\n",
      "Epoch: 32\tFidelity = 0.936138\tKL_Divergence = 0.022650\n",
      "Epoch: 33\tFidelity = 0.934702\tKL_Divergence = 0.023916\n",
      "Epoch: 34\tFidelity = 0.936407\tKL_Divergence = 0.022540\n",
      "Epoch: 35\tFidelity = 0.934631\tKL_Divergence = 0.023105\n",
      "Epoch: 36\tFidelity = 0.935289\tKL_Divergence = 0.025663\n",
      "Epoch: 37\tFidelity = 0.936101\tKL_Divergence = 0.022626\n",
      "Epoch: 38\tFidelity = 0.934714\tKL_Divergence = 0.023570\n",
      "Epoch: 39\tFidelity = 0.935231\tKL_Divergence = 0.023340\n",
      "Epoch: 40\tFidelity = 0.935887\tKL_Divergence = 0.022817\n",
      "Epoch: 41\tFidelity = 0.933770\tKL_Divergence = 0.024653\n",
      "Epoch: 42\tFidelity = 0.934418\tKL_Divergence = 0.023990\n",
      "Epoch: 43\tFidelity = 0.936808\tKL_Divergence = 0.022516\n",
      "Epoch: 44\tFidelity = 0.937130\tKL_Divergence = 0.022419\n",
      "Epoch: 45\tFidelity = 0.935653\tKL_Divergence = 0.023123\n",
      "Epoch: 46\tFidelity = 0.936048\tKL_Divergence = 0.023338\n",
      "Epoch: 47\tFidelity = 0.935469\tKL_Divergence = 0.023581\n",
      "Epoch: 48\tFidelity = 0.934792\tKL_Divergence = 0.023184\n",
      "Epoch: 49\tFidelity = 0.937076\tKL_Divergence = 0.022246\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:42:03,172] Trial 64 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.936772\tKL_Divergence = 0.022398\n",
      "Total time elapsed during training: 416.258 s\n",
      "Trial 64 pruned. \n",
      "Trial 64 pruned. \n",
      "Trial 64 pruned. \n",
      "Trial 64 pruned. \n",
      "Trial 64 pruned. \n",
      "Trial 64 pruned. \n",
      "Epoch: 1\tFidelity = 0.936369\tKL_Divergence = 0.022564\n",
      "Epoch: 2\tFidelity = 0.934314\tKL_Divergence = 0.023713\n",
      "Epoch: 3\tFidelity = 0.934993\tKL_Divergence = 0.023697\n",
      "Epoch: 4\tFidelity = 0.935110\tKL_Divergence = 0.023407\n",
      "Epoch: 5\tFidelity = 0.935828\tKL_Divergence = 0.023348\n",
      "Epoch: 6\tFidelity = 0.936900\tKL_Divergence = 0.022129\n",
      "Epoch: 7\tFidelity = 0.936762\tKL_Divergence = 0.022515\n",
      "Epoch: 8\tFidelity = 0.936406\tKL_Divergence = 0.022475\n",
      "Epoch: 9\tFidelity = 0.934204\tKL_Divergence = 0.025748\n",
      "Epoch: 10\tFidelity = 0.936316\tKL_Divergence = 0.022647\n",
      "Epoch: 11\tFidelity = 0.937592\tKL_Divergence = 0.021814\n",
      "Epoch: 12\tFidelity = 0.934715\tKL_Divergence = 0.023651\n",
      "Epoch: 13\tFidelity = 0.936662\tKL_Divergence = 0.022236\n",
      "Epoch: 14\tFidelity = 0.934934\tKL_Divergence = 0.022912\n",
      "Epoch: 15\tFidelity = 0.933625\tKL_Divergence = 0.026620\n",
      "Epoch: 16\tFidelity = 0.936863\tKL_Divergence = 0.022104\n",
      "Epoch: 17\tFidelity = 0.934693\tKL_Divergence = 0.023792\n",
      "Epoch: 18\tFidelity = 0.935969\tKL_Divergence = 0.023540\n",
      "Epoch: 19\tFidelity = 0.931894\tKL_Divergence = 0.027695\n",
      "Epoch: 20\tFidelity = 0.937008\tKL_Divergence = 0.022103\n",
      "Epoch: 21\tFidelity = 0.937310\tKL_Divergence = 0.022360\n",
      "Epoch: 22\tFidelity = 0.936826\tKL_Divergence = 0.023027\n",
      "Epoch: 23\tFidelity = 0.937946\tKL_Divergence = 0.021761\n",
      "Epoch: 24\tFidelity = 0.938500\tKL_Divergence = 0.021443\n",
      "Epoch: 25\tFidelity = 0.936755\tKL_Divergence = 0.022740\n",
      "Epoch: 26\tFidelity = 0.938514\tKL_Divergence = 0.021627\n",
      "Epoch: 27\tFidelity = 0.938738\tKL_Divergence = 0.021623\n",
      "Epoch: 28\tFidelity = 0.937159\tKL_Divergence = 0.022071\n",
      "Epoch: 29\tFidelity = 0.937487\tKL_Divergence = 0.022238\n",
      "Epoch: 30\tFidelity = 0.935860\tKL_Divergence = 0.022679\n",
      "Epoch: 31\tFidelity = 0.936498\tKL_Divergence = 0.022906\n",
      "Epoch: 32\tFidelity = 0.936974\tKL_Divergence = 0.022003\n",
      "Epoch: 33\tFidelity = 0.935777\tKL_Divergence = 0.025548\n",
      "Epoch: 34\tFidelity = 0.934782\tKL_Divergence = 0.025116\n",
      "Epoch: 35\tFidelity = 0.935235\tKL_Divergence = 0.024843\n",
      "Epoch: 36\tFidelity = 0.935444\tKL_Divergence = 0.024243\n",
      "Epoch: 37\tFidelity = 0.937582\tKL_Divergence = 0.022250\n",
      "Epoch: 38\tFidelity = 0.935985\tKL_Divergence = 0.023025\n",
      "Epoch: 39\tFidelity = 0.937123\tKL_Divergence = 0.023174\n",
      "Epoch: 40\tFidelity = 0.936329\tKL_Divergence = 0.022278\n",
      "Epoch: 41\tFidelity = 0.933129\tKL_Divergence = 0.025883\n",
      "Epoch: 42\tFidelity = 0.935771\tKL_Divergence = 0.022690\n",
      "Epoch: 43\tFidelity = 0.935756\tKL_Divergence = 0.023959\n",
      "Epoch: 44\tFidelity = 0.936688\tKL_Divergence = 0.022088\n",
      "Epoch: 45\tFidelity = 0.936591\tKL_Divergence = 0.022122\n",
      "Epoch: 46\tFidelity = 0.936312\tKL_Divergence = 0.022377\n",
      "Epoch: 47\tFidelity = 0.934661\tKL_Divergence = 0.024211\n",
      "Epoch: 48\tFidelity = 0.936285\tKL_Divergence = 0.025229\n",
      "Epoch: 49\tFidelity = 0.934763\tKL_Divergence = 0.025749\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:47:06,652] Trial 65 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.934576\tKL_Divergence = 0.022985\n",
      "Total time elapsed during training: 303.137 s\n",
      "Trial 65 pruned. \n",
      "Trial 65 pruned. \n",
      "Trial 65 pruned. \n",
      "Trial 65 pruned. \n",
      "Trial 65 pruned. \n",
      "Trial 65 pruned. \n",
      "Epoch: 1\tFidelity = 0.931156\tKL_Divergence = 0.025355\n",
      "Epoch: 2\tFidelity = 0.936586\tKL_Divergence = 0.025181\n",
      "Epoch: 3\tFidelity = 0.936279\tKL_Divergence = 0.024016\n",
      "Epoch: 4\tFidelity = 0.933572\tKL_Divergence = 0.030218\n",
      "Epoch: 5\tFidelity = 0.937163\tKL_Divergence = 0.022452\n",
      "Epoch: 6\tFidelity = 0.931002\tKL_Divergence = 0.025882\n",
      "Epoch: 7\tFidelity = 0.931060\tKL_Divergence = 0.030576\n",
      "Epoch: 8\tFidelity = 0.936926\tKL_Divergence = 0.022174\n",
      "Epoch: 9\tFidelity = 0.933219\tKL_Divergence = 0.027984\n",
      "Epoch: 10\tFidelity = 0.935363\tKL_Divergence = 0.023345\n",
      "Epoch: 11\tFidelity = 0.935249\tKL_Divergence = 0.025431\n",
      "Epoch: 12\tFidelity = 0.938241\tKL_Divergence = 0.021764\n",
      "Epoch: 13\tFidelity = 0.936553\tKL_Divergence = 0.025104\n",
      "Epoch: 14\tFidelity = 0.928808\tKL_Divergence = 0.033829\n",
      "Epoch: 15\tFidelity = 0.933105\tKL_Divergence = 0.027394\n",
      "Epoch: 16\tFidelity = 0.937868\tKL_Divergence = 0.023760\n",
      "Epoch: 17\tFidelity = 0.926697\tKL_Divergence = 0.032992\n",
      "Epoch: 18\tFidelity = 0.936371\tKL_Divergence = 0.022791\n",
      "Epoch: 19\tFidelity = 0.935454\tKL_Divergence = 0.023727\n",
      "Epoch: 20\tFidelity = 0.933436\tKL_Divergence = 0.027993\n",
      "Epoch: 21\tFidelity = 0.932120\tKL_Divergence = 0.024364\n",
      "Epoch: 22\tFidelity = 0.925996\tKL_Divergence = 0.027321\n",
      "Epoch: 23\tFidelity = 0.938384\tKL_Divergence = 0.021499\n",
      "Epoch: 24\tFidelity = 0.937821\tKL_Divergence = 0.022504\n",
      "Epoch: 25\tFidelity = 0.935560\tKL_Divergence = 0.025113\n",
      "Epoch: 26\tFidelity = 0.936092\tKL_Divergence = 0.022401\n",
      "Epoch: 27\tFidelity = 0.934347\tKL_Divergence = 0.023723\n",
      "Epoch: 28\tFidelity = 0.936171\tKL_Divergence = 0.022680\n",
      "Epoch: 29\tFidelity = 0.931582\tKL_Divergence = 0.030610\n",
      "Epoch: 30\tFidelity = 0.939331\tKL_Divergence = 0.021301\n",
      "Epoch: 31\tFidelity = 0.935447\tKL_Divergence = 0.024294\n",
      "Epoch: 32\tFidelity = 0.920861\tKL_Divergence = 0.040348\n",
      "Epoch: 33\tFidelity = 0.932428\tKL_Divergence = 0.024596\n",
      "Epoch: 34\tFidelity = 0.933902\tKL_Divergence = 0.025185\n",
      "Epoch: 35\tFidelity = 0.931434\tKL_Divergence = 0.026065\n",
      "Epoch: 36\tFidelity = 0.931743\tKL_Divergence = 0.027171\n",
      "Epoch: 37\tFidelity = 0.935913\tKL_Divergence = 0.022700\n",
      "Epoch: 38\tFidelity = 0.932344\tKL_Divergence = 0.026016\n",
      "Epoch: 39\tFidelity = 0.931083\tKL_Divergence = 0.028223\n",
      "Epoch: 40\tFidelity = 0.936515\tKL_Divergence = 0.022350\n",
      "Epoch: 41\tFidelity = 0.934997\tKL_Divergence = 0.023420\n",
      "Epoch: 42\tFidelity = 0.932940\tKL_Divergence = 0.024257\n",
      "Epoch: 43\tFidelity = 0.936322\tKL_Divergence = 0.022510\n",
      "Epoch: 44\tFidelity = 0.933318\tKL_Divergence = 0.024839\n",
      "Epoch: 45\tFidelity = 0.933324\tKL_Divergence = 0.030002\n",
      "Epoch: 46\tFidelity = 0.936579\tKL_Divergence = 0.022708\n",
      "Epoch: 47\tFidelity = 0.938219\tKL_Divergence = 0.022230\n",
      "Epoch: 48\tFidelity = 0.938617\tKL_Divergence = 0.023179\n",
      "Epoch: 49\tFidelity = 0.937646\tKL_Divergence = 0.023965\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:55:29,903] Trial 66 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.937434\tKL_Divergence = 0.022173\n",
      "Total time elapsed during training: 502.932 s\n",
      "Trial 66 pruned. \n",
      "Trial 66 pruned. \n",
      "Trial 66 pruned. \n",
      "Trial 66 pruned. \n",
      "Trial 66 pruned. \n",
      "Trial 66 pruned. \n",
      "Epoch: 1\tFidelity = 0.934362\tKL_Divergence = 0.023852\n",
      "Epoch: 2\tFidelity = 0.935918\tKL_Divergence = 0.024457\n",
      "Epoch: 3\tFidelity = 0.935311\tKL_Divergence = 0.025386\n",
      "Epoch: 4\tFidelity = 0.936968\tKL_Divergence = 0.022251\n",
      "Epoch: 5\tFidelity = 0.936806\tKL_Divergence = 0.022600\n",
      "Epoch: 6\tFidelity = 0.928546\tKL_Divergence = 0.040240\n",
      "Epoch: 7\tFidelity = 0.938582\tKL_Divergence = 0.021705\n",
      "Epoch: 8\tFidelity = 0.938259\tKL_Divergence = 0.023422\n",
      "Epoch: 9\tFidelity = 0.936501\tKL_Divergence = 0.022606\n",
      "Epoch: 10\tFidelity = 0.933062\tKL_Divergence = 0.029426\n",
      "Epoch: 11\tFidelity = 0.933872\tKL_Divergence = 0.027423\n",
      "Epoch: 12\tFidelity = 0.932863\tKL_Divergence = 0.024435\n",
      "Epoch: 13\tFidelity = 0.934466\tKL_Divergence = 0.024368\n",
      "Epoch: 14\tFidelity = 0.938859\tKL_Divergence = 0.021397\n",
      "Epoch: 15\tFidelity = 0.935438\tKL_Divergence = 0.022715\n",
      "Epoch: 16\tFidelity = 0.935105\tKL_Divergence = 0.023266\n",
      "Epoch: 17\tFidelity = 0.929878\tKL_Divergence = 0.025112\n",
      "Epoch: 18\tFidelity = 0.934006\tKL_Divergence = 0.023286\n",
      "Epoch: 19\tFidelity = 0.934393\tKL_Divergence = 0.024466\n",
      "Epoch: 20\tFidelity = 0.936259\tKL_Divergence = 0.023530\n",
      "Epoch: 21\tFidelity = 0.934878\tKL_Divergence = 0.023537\n",
      "Epoch: 22\tFidelity = 0.934450\tKL_Divergence = 0.026633\n",
      "Epoch: 23\tFidelity = 0.927996\tKL_Divergence = 0.028128\n",
      "Epoch: 24\tFidelity = 0.934954\tKL_Divergence = 0.023218\n",
      "Epoch: 25\tFidelity = 0.934321\tKL_Divergence = 0.023610\n",
      "Epoch: 26\tFidelity = 0.934628\tKL_Divergence = 0.024654\n",
      "Epoch: 27\tFidelity = 0.936501\tKL_Divergence = 0.022773\n",
      "Epoch: 28\tFidelity = 0.935256\tKL_Divergence = 0.027572\n",
      "Epoch: 29\tFidelity = 0.934001\tKL_Divergence = 0.026750\n",
      "Epoch: 30\tFidelity = 0.936157\tKL_Divergence = 0.022600\n",
      "Epoch: 31\tFidelity = 0.938309\tKL_Divergence = 0.021898\n",
      "Epoch: 32\tFidelity = 0.935564\tKL_Divergence = 0.023495\n",
      "Epoch: 33\tFidelity = 0.933822\tKL_Divergence = 0.026174\n",
      "Epoch: 34\tFidelity = 0.935634\tKL_Divergence = 0.024585\n",
      "Epoch: 35\tFidelity = 0.936812\tKL_Divergence = 0.024163\n",
      "Epoch: 36\tFidelity = 0.938087\tKL_Divergence = 0.022368\n",
      "Epoch: 37\tFidelity = 0.936624\tKL_Divergence = 0.023306\n",
      "Epoch: 38\tFidelity = 0.939030\tKL_Divergence = 0.021420\n",
      "Epoch: 39\tFidelity = 0.932523\tKL_Divergence = 0.026142\n",
      "Epoch: 40\tFidelity = 0.936600\tKL_Divergence = 0.024340\n",
      "Epoch: 41\tFidelity = 0.938412\tKL_Divergence = 0.021451\n",
      "Epoch: 42\tFidelity = 0.936879\tKL_Divergence = 0.022209\n",
      "Epoch: 43\tFidelity = 0.936839\tKL_Divergence = 0.022109\n",
      "Epoch: 44\tFidelity = 0.930805\tKL_Divergence = 0.025426\n",
      "Epoch: 45\tFidelity = 0.934824\tKL_Divergence = 0.023095\n",
      "Epoch: 46\tFidelity = 0.934273\tKL_Divergence = 0.023722\n",
      "Epoch: 47\tFidelity = 0.935946\tKL_Divergence = 0.022943\n",
      "Epoch: 48\tFidelity = 0.929668\tKL_Divergence = 0.027389\n",
      "Epoch: 49\tFidelity = 0.935358\tKL_Divergence = 0.023310\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:01:31,607] Trial 67 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.937083\tKL_Divergence = 0.022618\n",
      "Total time elapsed during training: 361.369 s\n",
      "Trial 67 pruned. \n",
      "Trial 67 pruned. \n",
      "Trial 67 pruned. \n",
      "Trial 67 pruned. \n",
      "Trial 67 pruned. \n",
      "Trial 67 pruned. \n",
      "Epoch: 1\tFidelity = 0.936447\tKL_Divergence = 0.022271\n",
      "Epoch: 2\tFidelity = 0.934156\tKL_Divergence = 0.024807\n",
      "Epoch: 3\tFidelity = 0.933843\tKL_Divergence = 0.024453\n",
      "Epoch: 4\tFidelity = 0.936169\tKL_Divergence = 0.022936\n",
      "Epoch: 5\tFidelity = 0.935937\tKL_Divergence = 0.022514\n",
      "Epoch: 6\tFidelity = 0.935482\tKL_Divergence = 0.022797\n",
      "Epoch: 7\tFidelity = 0.930731\tKL_Divergence = 0.027384\n",
      "Epoch: 8\tFidelity = 0.931874\tKL_Divergence = 0.026297\n",
      "Epoch: 9\tFidelity = 0.935017\tKL_Divergence = 0.023054\n",
      "Epoch: 10\tFidelity = 0.935035\tKL_Divergence = 0.022973\n",
      "Epoch: 11\tFidelity = 0.935369\tKL_Divergence = 0.022870\n",
      "Epoch: 12\tFidelity = 0.931503\tKL_Divergence = 0.028342\n",
      "Epoch: 13\tFidelity = 0.933534\tKL_Divergence = 0.026155\n",
      "Epoch: 14\tFidelity = 0.934692\tKL_Divergence = 0.023083\n",
      "Epoch: 15\tFidelity = 0.933718\tKL_Divergence = 0.023801\n",
      "Epoch: 16\tFidelity = 0.932593\tKL_Divergence = 0.025277\n",
      "Epoch: 17\tFidelity = 0.933726\tKL_Divergence = 0.024243\n",
      "Epoch: 18\tFidelity = 0.933469\tKL_Divergence = 0.024907\n",
      "Epoch: 19\tFidelity = 0.936881\tKL_Divergence = 0.022588\n",
      "Epoch: 20\tFidelity = 0.934903\tKL_Divergence = 0.024154\n",
      "Epoch: 21\tFidelity = 0.935529\tKL_Divergence = 0.022970\n",
      "Epoch: 22\tFidelity = 0.936052\tKL_Divergence = 0.023083\n",
      "Epoch: 23\tFidelity = 0.936468\tKL_Divergence = 0.022597\n",
      "Epoch: 24\tFidelity = 0.936616\tKL_Divergence = 0.022553\n",
      "Epoch: 25\tFidelity = 0.936236\tKL_Divergence = 0.023225\n",
      "Epoch: 26\tFidelity = 0.936421\tKL_Divergence = 0.022856\n",
      "Epoch: 27\tFidelity = 0.934377\tKL_Divergence = 0.025418\n",
      "Epoch: 28\tFidelity = 0.936476\tKL_Divergence = 0.022953\n",
      "Epoch: 29\tFidelity = 0.933395\tKL_Divergence = 0.027097\n",
      "Epoch: 30\tFidelity = 0.933410\tKL_Divergence = 0.025972\n",
      "Epoch: 31\tFidelity = 0.934587\tKL_Divergence = 0.023821\n",
      "Epoch: 32\tFidelity = 0.930165\tKL_Divergence = 0.030330\n",
      "Epoch: 33\tFidelity = 0.936042\tKL_Divergence = 0.022599\n",
      "Epoch: 34\tFidelity = 0.933568\tKL_Divergence = 0.024394\n",
      "Epoch: 35\tFidelity = 0.933026\tKL_Divergence = 0.024489\n",
      "Epoch: 36\tFidelity = 0.936088\tKL_Divergence = 0.022602\n",
      "Epoch: 37\tFidelity = 0.936306\tKL_Divergence = 0.022571\n",
      "Epoch: 38\tFidelity = 0.930788\tKL_Divergence = 0.025833\n",
      "Epoch: 39\tFidelity = 0.934293\tKL_Divergence = 0.025014\n",
      "Epoch: 40\tFidelity = 0.929145\tKL_Divergence = 0.028212\n",
      "Epoch: 41\tFidelity = 0.937607\tKL_Divergence = 0.022330\n",
      "Epoch: 42\tFidelity = 0.936295\tKL_Divergence = 0.023503\n",
      "Epoch: 43\tFidelity = 0.935678\tKL_Divergence = 0.023632\n",
      "Epoch: 44\tFidelity = 0.935244\tKL_Divergence = 0.023993\n",
      "Epoch: 45\tFidelity = 0.932773\tKL_Divergence = 0.024053\n",
      "Epoch: 46\tFidelity = 0.934663\tKL_Divergence = 0.023392\n",
      "Epoch: 47\tFidelity = 0.930868\tKL_Divergence = 0.025530\n",
      "Epoch: 48\tFidelity = 0.932709\tKL_Divergence = 0.026248\n",
      "Epoch: 49\tFidelity = 0.936718\tKL_Divergence = 0.022523\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:06:56,801] Trial 68 finished with value: 0.021695129794259492 and parameters: {'lr': 6.531429260684491, 'pbs': 7000, 'nbs': 5000}. Best is trial 57 with value: 0.02145553797915265.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.938525\tKL_Divergence = 0.021695\n",
      "Total time elapsed during training: 324.776 s\n",
      "Trial 68 finished with value: 0.021695129794259492 and parameters: {'lr': 6.531429260684491, 'pbs': 7000, 'nbs': 5000}. Best is trial 57 with value: 0.02145553797915265.\n",
      "Trial 68 finished with value: 0.021695129794259492 and parameters: {'lr': 6.531429260684491, 'pbs': 7000, 'nbs': 5000}. Best is trial 57 with value: 0.02145553797915265.\n",
      "Trial 68 finished with value: 0.021695129794259492 and parameters: {'lr': 6.531429260684491, 'pbs': 7000, 'nbs': 5000}. Best is trial 57 with value: 0.02145553797915265.\n",
      "Trial 68 finished with value: 0.021695129794259492 and parameters: {'lr': 6.531429260684491, 'pbs': 7000, 'nbs': 5000}. Best is trial 57 with value: 0.02145553797915265.\n",
      "Trial 68 finished with value: 0.021695129794259492 and parameters: {'lr': 6.531429260684491, 'pbs': 7000, 'nbs': 5000}. Best is trial 57 with value: 0.02145553797915265.\n",
      "Trial 68 finished with value: 0.021695129794259492 and parameters: {'lr': 6.531429260684491, 'pbs': 7000, 'nbs': 5000}. Best is trial 57 with value: 0.02145553797915265.\n",
      "Epoch: 1\tFidelity = 0.934639\tKL_Divergence = 0.023146\n",
      "Epoch: 2\tFidelity = 0.936000\tKL_Divergence = 0.022706\n",
      "Epoch: 3\tFidelity = 0.936942\tKL_Divergence = 0.022328\n",
      "Epoch: 4\tFidelity = 0.935223\tKL_Divergence = 0.023912\n",
      "Epoch: 5\tFidelity = 0.934855\tKL_Divergence = 0.023005\n",
      "Epoch: 6\tFidelity = 0.935270\tKL_Divergence = 0.023274\n",
      "Epoch: 7\tFidelity = 0.933189\tKL_Divergence = 0.027633\n",
      "Epoch: 8\tFidelity = 0.933127\tKL_Divergence = 0.025587\n",
      "Epoch: 9\tFidelity = 0.936134\tKL_Divergence = 0.022609\n",
      "Epoch: 10\tFidelity = 0.929418\tKL_Divergence = 0.026640\n",
      "Epoch: 11\tFidelity = 0.936692\tKL_Divergence = 0.022566\n",
      "Epoch: 12\tFidelity = 0.938223\tKL_Divergence = 0.022182\n",
      "Epoch: 13\tFidelity = 0.935798\tKL_Divergence = 0.022644\n",
      "Epoch: 14\tFidelity = 0.935922\tKL_Divergence = 0.023217\n",
      "Epoch: 15\tFidelity = 0.935535\tKL_Divergence = 0.024477\n",
      "Epoch: 16\tFidelity = 0.934468\tKL_Divergence = 0.026101\n",
      "Epoch: 17\tFidelity = 0.938231\tKL_Divergence = 0.021965\n",
      "Epoch: 18\tFidelity = 0.937725\tKL_Divergence = 0.022039\n",
      "Epoch: 19\tFidelity = 0.937354\tKL_Divergence = 0.022550\n",
      "Epoch: 20\tFidelity = 0.935004\tKL_Divergence = 0.025513\n",
      "Epoch: 21\tFidelity = 0.932459\tKL_Divergence = 0.026658\n",
      "Epoch: 22\tFidelity = 0.935366\tKL_Divergence = 0.022681\n",
      "Epoch: 23\tFidelity = 0.935112\tKL_Divergence = 0.024079\n",
      "Epoch: 24\tFidelity = 0.936737\tKL_Divergence = 0.022245\n",
      "Epoch: 25\tFidelity = 0.933519\tKL_Divergence = 0.024154\n",
      "Epoch: 26\tFidelity = 0.933832\tKL_Divergence = 0.024208\n",
      "Epoch: 27\tFidelity = 0.938900\tKL_Divergence = 0.022133\n",
      "Epoch: 28\tFidelity = 0.937942\tKL_Divergence = 0.022090\n",
      "Epoch: 29\tFidelity = 0.937476\tKL_Divergence = 0.022233\n",
      "Epoch: 30\tFidelity = 0.936011\tKL_Divergence = 0.023731\n",
      "Epoch: 31\tFidelity = 0.932295\tKL_Divergence = 0.028247\n",
      "Epoch: 32\tFidelity = 0.933038\tKL_Divergence = 0.024492\n",
      "Epoch: 33\tFidelity = 0.934225\tKL_Divergence = 0.023883\n",
      "Epoch: 34\tFidelity = 0.934846\tKL_Divergence = 0.022978\n",
      "Epoch: 35\tFidelity = 0.935575\tKL_Divergence = 0.022692\n",
      "Epoch: 36\tFidelity = 0.933765\tKL_Divergence = 0.027757\n",
      "Epoch: 37\tFidelity = 0.935441\tKL_Divergence = 0.023035\n",
      "Epoch: 38\tFidelity = 0.933503\tKL_Divergence = 0.026450\n",
      "Epoch: 39\tFidelity = 0.936578\tKL_Divergence = 0.022379\n",
      "Epoch: 40\tFidelity = 0.937548\tKL_Divergence = 0.022396\n",
      "Epoch: 41\tFidelity = 0.936659\tKL_Divergence = 0.022397\n",
      "Epoch: 42\tFidelity = 0.937229\tKL_Divergence = 0.022045\n",
      "Epoch: 43\tFidelity = 0.935651\tKL_Divergence = 0.024199\n",
      "Epoch: 44\tFidelity = 0.935845\tKL_Divergence = 0.022682\n",
      "Epoch: 45\tFidelity = 0.937703\tKL_Divergence = 0.021862\n",
      "Epoch: 46\tFidelity = 0.934539\tKL_Divergence = 0.023492\n",
      "Epoch: 47\tFidelity = 0.934742\tKL_Divergence = 0.023172\n",
      "Epoch: 48\tFidelity = 0.934825\tKL_Divergence = 0.023335\n",
      "Epoch: 49\tFidelity = 0.932829\tKL_Divergence = 0.023952\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:12:25,897] Trial 69 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.935886\tKL_Divergence = 0.023217\n",
      "Total time elapsed during training: 328.730 s\n",
      "Trial 69 pruned. \n",
      "Trial 69 pruned. \n",
      "Trial 69 pruned. \n",
      "Trial 69 pruned. \n",
      "Trial 69 pruned. \n",
      "Trial 69 pruned. \n",
      "Epoch: 1\tFidelity = 0.936899\tKL_Divergence = 0.022056\n",
      "Epoch: 2\tFidelity = 0.934987\tKL_Divergence = 0.023252\n",
      "Epoch: 3\tFidelity = 0.934481\tKL_Divergence = 0.025123\n",
      "Epoch: 4\tFidelity = 0.934059\tKL_Divergence = 0.025631\n",
      "Epoch: 5\tFidelity = 0.933061\tKL_Divergence = 0.023712\n",
      "Epoch: 6\tFidelity = 0.934952\tKL_Divergence = 0.023345\n",
      "Epoch: 7\tFidelity = 0.930276\tKL_Divergence = 0.029549\n",
      "Epoch: 8\tFidelity = 0.935303\tKL_Divergence = 0.022712\n",
      "Epoch: 9\tFidelity = 0.936108\tKL_Divergence = 0.022327\n",
      "Epoch: 10\tFidelity = 0.932952\tKL_Divergence = 0.024791\n",
      "Epoch: 11\tFidelity = 0.935300\tKL_Divergence = 0.022798\n",
      "Epoch: 12\tFidelity = 0.933709\tKL_Divergence = 0.023529\n",
      "Epoch: 13\tFidelity = 0.936566\tKL_Divergence = 0.022221\n",
      "Epoch: 14\tFidelity = 0.932761\tKL_Divergence = 0.025340\n",
      "Epoch: 15\tFidelity = 0.934148\tKL_Divergence = 0.023227\n",
      "Epoch: 16\tFidelity = 0.934319\tKL_Divergence = 0.023461\n",
      "Epoch: 17\tFidelity = 0.935211\tKL_Divergence = 0.022779\n",
      "Epoch: 18\tFidelity = 0.935865\tKL_Divergence = 0.022628\n",
      "Epoch: 19\tFidelity = 0.934462\tKL_Divergence = 0.023420\n",
      "Epoch: 20\tFidelity = 0.933735\tKL_Divergence = 0.023914\n",
      "Epoch: 21\tFidelity = 0.934887\tKL_Divergence = 0.023300\n",
      "Epoch: 22\tFidelity = 0.931865\tKL_Divergence = 0.025787\n",
      "Epoch: 23\tFidelity = 0.933595\tKL_Divergence = 0.024522\n",
      "Epoch: 24\tFidelity = 0.933578\tKL_Divergence = 0.023635\n",
      "Epoch: 25\tFidelity = 0.934596\tKL_Divergence = 0.024427\n",
      "Epoch: 26\tFidelity = 0.933805\tKL_Divergence = 0.024269\n",
      "Epoch: 27\tFidelity = 0.930764\tKL_Divergence = 0.028861\n",
      "Epoch: 28\tFidelity = 0.934935\tKL_Divergence = 0.023059\n",
      "Epoch: 29\tFidelity = 0.936222\tKL_Divergence = 0.022538\n",
      "Epoch: 30\tFidelity = 0.936841\tKL_Divergence = 0.022740\n",
      "Epoch: 31\tFidelity = 0.936111\tKL_Divergence = 0.023010\n",
      "Epoch: 32\tFidelity = 0.937683\tKL_Divergence = 0.021922\n",
      "Epoch: 33\tFidelity = 0.936592\tKL_Divergence = 0.022468\n",
      "Epoch: 34\tFidelity = 0.934969\tKL_Divergence = 0.023675\n",
      "Epoch: 35\tFidelity = 0.934586\tKL_Divergence = 0.023325\n",
      "Epoch: 36\tFidelity = 0.932932\tKL_Divergence = 0.024139\n",
      "Epoch: 37\tFidelity = 0.932237\tKL_Divergence = 0.025977\n",
      "Epoch: 38\tFidelity = 0.933910\tKL_Divergence = 0.023814\n",
      "Epoch: 39\tFidelity = 0.932530\tKL_Divergence = 0.024272\n",
      "Epoch: 40\tFidelity = 0.930209\tKL_Divergence = 0.031383\n",
      "Epoch: 41\tFidelity = 0.935869\tKL_Divergence = 0.022856\n",
      "Epoch: 42\tFidelity = 0.936101\tKL_Divergence = 0.022672\n",
      "Epoch: 43\tFidelity = 0.935684\tKL_Divergence = 0.022834\n",
      "Epoch: 44\tFidelity = 0.936439\tKL_Divergence = 0.022544\n",
      "Epoch: 45\tFidelity = 0.932663\tKL_Divergence = 0.026367\n",
      "Epoch: 46\tFidelity = 0.935500\tKL_Divergence = 0.022727\n",
      "Epoch: 47\tFidelity = 0.935691\tKL_Divergence = 0.022560\n",
      "Epoch: 48\tFidelity = 0.936439\tKL_Divergence = 0.022451\n",
      "Epoch: 49\tFidelity = 0.935261\tKL_Divergence = 0.022612\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:17:53,195] Trial 70 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.936364\tKL_Divergence = 0.022241\n",
      "Total time elapsed during training: 326.978 s\n",
      "Trial 70 pruned. \n",
      "Trial 70 pruned. \n",
      "Trial 70 pruned. \n",
      "Trial 70 pruned. \n",
      "Trial 70 pruned. \n",
      "Trial 70 pruned. \n",
      "Epoch: 1\tFidelity = 0.936374\tKL_Divergence = 0.023177\n",
      "Epoch: 2\tFidelity = 0.936717\tKL_Divergence = 0.022266\n",
      "Epoch: 3\tFidelity = 0.936627\tKL_Divergence = 0.022206\n",
      "Epoch: 4\tFidelity = 0.933311\tKL_Divergence = 0.026459\n",
      "Epoch: 5\tFidelity = 0.935534\tKL_Divergence = 0.023090\n",
      "Epoch: 6\tFidelity = 0.933735\tKL_Divergence = 0.024135\n",
      "Epoch: 7\tFidelity = 0.936378\tKL_Divergence = 0.022655\n",
      "Epoch: 8\tFidelity = 0.934153\tKL_Divergence = 0.023702\n",
      "Epoch: 9\tFidelity = 0.937110\tKL_Divergence = 0.022567\n",
      "Epoch: 10\tFidelity = 0.936073\tKL_Divergence = 0.023689\n",
      "Epoch: 11\tFidelity = 0.930900\tKL_Divergence = 0.029214\n",
      "Epoch: 12\tFidelity = 0.935061\tKL_Divergence = 0.023414\n",
      "Epoch: 13\tFidelity = 0.931955\tKL_Divergence = 0.030272\n",
      "Epoch: 14\tFidelity = 0.929644\tKL_Divergence = 0.030401\n",
      "Epoch: 15\tFidelity = 0.930967\tKL_Divergence = 0.026285\n",
      "Epoch: 16\tFidelity = 0.933916\tKL_Divergence = 0.023471\n",
      "Epoch: 17\tFidelity = 0.934023\tKL_Divergence = 0.025511\n",
      "Epoch: 18\tFidelity = 0.936987\tKL_Divergence = 0.022862\n",
      "Epoch: 19\tFidelity = 0.933991\tKL_Divergence = 0.024497\n",
      "Epoch: 20\tFidelity = 0.937397\tKL_Divergence = 0.022053\n",
      "Epoch: 21\tFidelity = 0.934527\tKL_Divergence = 0.024649\n",
      "Epoch: 22\tFidelity = 0.935446\tKL_Divergence = 0.023055\n",
      "Epoch: 23\tFidelity = 0.932790\tKL_Divergence = 0.024398\n",
      "Epoch: 24\tFidelity = 0.936151\tKL_Divergence = 0.023535\n",
      "Epoch: 25\tFidelity = 0.935748\tKL_Divergence = 0.022631\n",
      "Epoch: 26\tFidelity = 0.934673\tKL_Divergence = 0.023687\n",
      "Epoch: 27\tFidelity = 0.935636\tKL_Divergence = 0.022760\n",
      "Epoch: 28\tFidelity = 0.935240\tKL_Divergence = 0.022888\n",
      "Epoch: 29\tFidelity = 0.936012\tKL_Divergence = 0.022705\n",
      "Epoch: 30\tFidelity = 0.934053\tKL_Divergence = 0.023853\n",
      "Epoch: 31\tFidelity = 0.932799\tKL_Divergence = 0.025271\n",
      "Epoch: 32\tFidelity = 0.935135\tKL_Divergence = 0.023082\n",
      "Epoch: 33\tFidelity = 0.936123\tKL_Divergence = 0.023430\n",
      "Epoch: 34\tFidelity = 0.934315\tKL_Divergence = 0.024547\n",
      "Epoch: 35\tFidelity = 0.928836\tKL_Divergence = 0.029447\n",
      "Epoch: 36\tFidelity = 0.937166\tKL_Divergence = 0.022507\n",
      "Epoch: 37\tFidelity = 0.935424\tKL_Divergence = 0.023275\n",
      "Epoch: 38\tFidelity = 0.937616\tKL_Divergence = 0.022033\n",
      "Epoch: 39\tFidelity = 0.933352\tKL_Divergence = 0.024605\n",
      "Epoch: 40\tFidelity = 0.939059\tKL_Divergence = 0.021405\n",
      "Epoch: 41\tFidelity = 0.938765\tKL_Divergence = 0.021473\n",
      "Epoch: 42\tFidelity = 0.936507\tKL_Divergence = 0.022321\n",
      "Epoch: 43\tFidelity = 0.930771\tKL_Divergence = 0.028713\n",
      "Epoch: 44\tFidelity = 0.936228\tKL_Divergence = 0.022782\n",
      "Epoch: 45\tFidelity = 0.936496\tKL_Divergence = 0.022333\n",
      "Epoch: 46\tFidelity = 0.934392\tKL_Divergence = 0.027098\n",
      "Epoch: 47\tFidelity = 0.938183\tKL_Divergence = 0.022482\n",
      "Epoch: 48\tFidelity = 0.936588\tKL_Divergence = 0.024592\n",
      "Epoch: 49\tFidelity = 0.937116\tKL_Divergence = 0.022915\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:23:18,690] Trial 71 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.934951\tKL_Divergence = 0.025051\n",
      "Total time elapsed during training: 325.167 s\n",
      "Trial 71 pruned. \n",
      "Trial 71 pruned. \n",
      "Trial 71 pruned. \n",
      "Trial 71 pruned. \n",
      "Trial 71 pruned. \n",
      "Trial 71 pruned. \n",
      "Epoch: 1\tFidelity = 0.928346\tKL_Divergence = 0.027711\n",
      "Epoch: 2\tFidelity = 0.936915\tKL_Divergence = 0.022153\n",
      "Epoch: 3\tFidelity = 0.932276\tKL_Divergence = 0.027018\n",
      "Epoch: 4\tFidelity = 0.933755\tKL_Divergence = 0.025157\n",
      "Epoch: 5\tFidelity = 0.935460\tKL_Divergence = 0.026518\n",
      "Epoch: 6\tFidelity = 0.937183\tKL_Divergence = 0.022120\n",
      "Epoch: 7\tFidelity = 0.935933\tKL_Divergence = 0.023159\n",
      "Epoch: 8\tFidelity = 0.938302\tKL_Divergence = 0.022527\n",
      "Epoch: 9\tFidelity = 0.937801\tKL_Divergence = 0.022006\n",
      "Epoch: 10\tFidelity = 0.937318\tKL_Divergence = 0.022472\n",
      "Epoch: 11\tFidelity = 0.936851\tKL_Divergence = 0.022281\n",
      "Epoch: 12\tFidelity = 0.937098\tKL_Divergence = 0.023624\n",
      "Epoch: 13\tFidelity = 0.926736\tKL_Divergence = 0.029619\n",
      "Epoch: 14\tFidelity = 0.935512\tKL_Divergence = 0.027869\n",
      "Epoch: 15\tFidelity = 0.937482\tKL_Divergence = 0.022197\n",
      "Epoch: 16\tFidelity = 0.934471\tKL_Divergence = 0.026357\n",
      "Epoch: 17\tFidelity = 0.935193\tKL_Divergence = 0.025449\n",
      "Epoch: 18\tFidelity = 0.938281\tKL_Divergence = 0.022254\n",
      "Epoch: 19\tFidelity = 0.933625\tKL_Divergence = 0.025746\n",
      "Epoch: 20\tFidelity = 0.937907\tKL_Divergence = 0.021885\n",
      "Epoch: 21\tFidelity = 0.935937\tKL_Divergence = 0.025392\n",
      "Epoch: 22\tFidelity = 0.935449\tKL_Divergence = 0.024445\n",
      "Epoch: 23\tFidelity = 0.937914\tKL_Divergence = 0.022469\n",
      "Epoch: 24\tFidelity = 0.928968\tKL_Divergence = 0.033452\n",
      "Epoch: 25\tFidelity = 0.935689\tKL_Divergence = 0.023223\n",
      "Epoch: 26\tFidelity = 0.935534\tKL_Divergence = 0.023985\n",
      "Epoch: 27\tFidelity = 0.931432\tKL_Divergence = 0.027903\n",
      "Epoch: 28\tFidelity = 0.933046\tKL_Divergence = 0.027636\n",
      "Epoch: 29\tFidelity = 0.937213\tKL_Divergence = 0.022513\n",
      "Epoch: 30\tFidelity = 0.935216\tKL_Divergence = 0.025254\n",
      "Epoch: 31\tFidelity = 0.935057\tKL_Divergence = 0.026119\n",
      "Epoch: 32\tFidelity = 0.934323\tKL_Divergence = 0.025262\n",
      "Epoch: 33\tFidelity = 0.931680\tKL_Divergence = 0.025139\n",
      "Epoch: 34\tFidelity = 0.938104\tKL_Divergence = 0.021955\n",
      "Epoch: 35\tFidelity = 0.934797\tKL_Divergence = 0.026039\n",
      "Epoch: 36\tFidelity = 0.938356\tKL_Divergence = 0.023458\n",
      "Epoch: 37\tFidelity = 0.937264\tKL_Divergence = 0.021972\n",
      "Epoch: 38\tFidelity = 0.933308\tKL_Divergence = 0.027013\n",
      "Epoch: 39\tFidelity = 0.934964\tKL_Divergence = 0.022990\n",
      "Epoch: 40\tFidelity = 0.932736\tKL_Divergence = 0.025178\n",
      "Epoch: 41\tFidelity = 0.936480\tKL_Divergence = 0.024113\n",
      "Epoch: 42\tFidelity = 0.931727\tKL_Divergence = 0.024837\n",
      "Epoch: 43\tFidelity = 0.932151\tKL_Divergence = 0.027602\n",
      "Epoch: 44\tFidelity = 0.932918\tKL_Divergence = 0.025447\n",
      "Epoch: 45\tFidelity = 0.921825\tKL_Divergence = 0.042695\n",
      "Epoch: 46\tFidelity = 0.935362\tKL_Divergence = 0.022931\n",
      "Epoch: 47\tFidelity = 0.935310\tKL_Divergence = 0.024262\n",
      "Epoch: 48\tFidelity = 0.935771\tKL_Divergence = 0.024170\n",
      "Epoch: 49\tFidelity = 0.937015\tKL_Divergence = 0.022283\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:28:43,389] Trial 72 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.934725\tKL_Divergence = 0.026277\n",
      "Total time elapsed during training: 324.395 s\n",
      "Trial 72 pruned. \n",
      "Trial 72 pruned. \n",
      "Trial 72 pruned. \n",
      "Trial 72 pruned. \n",
      "Trial 72 pruned. \n",
      "Trial 72 pruned. \n",
      "Epoch: 1\tFidelity = 0.935971\tKL_Divergence = 0.022648\n",
      "Epoch: 2\tFidelity = 0.933201\tKL_Divergence = 0.026200\n",
      "Epoch: 3\tFidelity = 0.933895\tKL_Divergence = 0.024742\n",
      "Epoch: 4\tFidelity = 0.932991\tKL_Divergence = 0.026964\n",
      "Epoch: 5\tFidelity = 0.935449\tKL_Divergence = 0.023015\n",
      "Epoch: 6\tFidelity = 0.936068\tKL_Divergence = 0.022758\n",
      "Epoch: 7\tFidelity = 0.932803\tKL_Divergence = 0.027089\n",
      "Epoch: 8\tFidelity = 0.936859\tKL_Divergence = 0.022200\n",
      "Epoch: 9\tFidelity = 0.935635\tKL_Divergence = 0.022818\n",
      "Epoch: 10\tFidelity = 0.937442\tKL_Divergence = 0.021990\n",
      "Epoch: 11\tFidelity = 0.932129\tKL_Divergence = 0.028402\n",
      "Epoch: 12\tFidelity = 0.937078\tKL_Divergence = 0.023484\n",
      "Epoch: 13\tFidelity = 0.937231\tKL_Divergence = 0.022035\n",
      "Epoch: 14\tFidelity = 0.935793\tKL_Divergence = 0.024440\n",
      "Epoch: 15\tFidelity = 0.935494\tKL_Divergence = 0.022899\n",
      "Epoch: 16\tFidelity = 0.934292\tKL_Divergence = 0.025915\n",
      "Epoch: 17\tFidelity = 0.935668\tKL_Divergence = 0.024281\n",
      "Epoch: 18\tFidelity = 0.935004\tKL_Divergence = 0.024875\n",
      "Epoch: 19\tFidelity = 0.936499\tKL_Divergence = 0.023258\n",
      "Epoch: 20\tFidelity = 0.938072\tKL_Divergence = 0.021810\n",
      "Epoch: 21\tFidelity = 0.937971\tKL_Divergence = 0.021787\n",
      "Epoch: 22\tFidelity = 0.934716\tKL_Divergence = 0.024632\n",
      "Epoch: 23\tFidelity = 0.938260\tKL_Divergence = 0.021752\n",
      "Epoch: 24\tFidelity = 0.935305\tKL_Divergence = 0.024665\n",
      "Epoch: 25\tFidelity = 0.933292\tKL_Divergence = 0.027452\n",
      "Epoch: 26\tFidelity = 0.931764\tKL_Divergence = 0.027271\n",
      "Epoch: 27\tFidelity = 0.935998\tKL_Divergence = 0.023665\n",
      "Epoch: 28\tFidelity = 0.936817\tKL_Divergence = 0.022438\n",
      "Epoch: 29\tFidelity = 0.936252\tKL_Divergence = 0.022712\n",
      "Epoch: 30\tFidelity = 0.932611\tKL_Divergence = 0.026110\n",
      "Epoch: 31\tFidelity = 0.932408\tKL_Divergence = 0.025477\n",
      "Epoch: 32\tFidelity = 0.934735\tKL_Divergence = 0.023966\n",
      "Epoch: 33\tFidelity = 0.936261\tKL_Divergence = 0.022811\n",
      "Epoch: 34\tFidelity = 0.934565\tKL_Divergence = 0.025036\n",
      "Epoch: 35\tFidelity = 0.935336\tKL_Divergence = 0.023868\n",
      "Epoch: 36\tFidelity = 0.932357\tKL_Divergence = 0.024613\n",
      "Epoch: 37\tFidelity = 0.934852\tKL_Divergence = 0.024314\n",
      "Epoch: 38\tFidelity = 0.933973\tKL_Divergence = 0.025718\n",
      "Epoch: 39\tFidelity = 0.937688\tKL_Divergence = 0.022676\n",
      "Epoch: 40\tFidelity = 0.935809\tKL_Divergence = 0.022933\n",
      "Epoch: 41\tFidelity = 0.937934\tKL_Divergence = 0.022078\n",
      "Epoch: 42\tFidelity = 0.939394\tKL_Divergence = 0.021572\n",
      "Epoch: 43\tFidelity = 0.936554\tKL_Divergence = 0.023855\n",
      "Epoch: 44\tFidelity = 0.937152\tKL_Divergence = 0.025833\n",
      "Epoch: 45\tFidelity = 0.935859\tKL_Divergence = 0.025721\n",
      "Epoch: 46\tFidelity = 0.937055\tKL_Divergence = 0.026733\n",
      "Epoch: 47\tFidelity = 0.937209\tKL_Divergence = 0.022606\n",
      "Epoch: 48\tFidelity = 0.936938\tKL_Divergence = 0.022663\n",
      "Epoch: 49\tFidelity = 0.937868\tKL_Divergence = 0.023092\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:33:48,777] Trial 73 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.937549\tKL_Divergence = 0.022863\n",
      "Total time elapsed during training: 305.031 s\n",
      "Trial 73 pruned. \n",
      "Trial 73 pruned. \n",
      "Trial 73 pruned. \n",
      "Trial 73 pruned. \n",
      "Trial 73 pruned. \n",
      "Trial 73 pruned. \n",
      "Epoch: 1\tFidelity = 0.936636\tKL_Divergence = 0.023922\n",
      "Epoch: 2\tFidelity = 0.936184\tKL_Divergence = 0.022452\n",
      "Epoch: 3\tFidelity = 0.934839\tKL_Divergence = 0.023031\n",
      "Epoch: 4\tFidelity = 0.936456\tKL_Divergence = 0.022259\n",
      "Epoch: 5\tFidelity = 0.934859\tKL_Divergence = 0.024958\n",
      "Epoch: 6\tFidelity = 0.937002\tKL_Divergence = 0.021997\n",
      "Epoch: 7\tFidelity = 0.935255\tKL_Divergence = 0.023300\n",
      "Epoch: 8\tFidelity = 0.936111\tKL_Divergence = 0.022716\n",
      "Epoch: 9\tFidelity = 0.936230\tKL_Divergence = 0.022685\n",
      "Epoch: 10\tFidelity = 0.934917\tKL_Divergence = 0.024124\n",
      "Epoch: 11\tFidelity = 0.933722\tKL_Divergence = 0.024773\n",
      "Epoch: 12\tFidelity = 0.936244\tKL_Divergence = 0.022499\n",
      "Epoch: 13\tFidelity = 0.935443\tKL_Divergence = 0.023068\n",
      "Epoch: 14\tFidelity = 0.936146\tKL_Divergence = 0.022555\n",
      "Epoch: 15\tFidelity = 0.937398\tKL_Divergence = 0.021887\n",
      "Epoch: 16\tFidelity = 0.936116\tKL_Divergence = 0.022714\n",
      "Epoch: 17\tFidelity = 0.935729\tKL_Divergence = 0.024518\n",
      "Epoch: 18\tFidelity = 0.935593\tKL_Divergence = 0.023006\n",
      "Epoch: 19\tFidelity = 0.935359\tKL_Divergence = 0.022785\n",
      "Epoch: 20\tFidelity = 0.932528\tKL_Divergence = 0.026904\n",
      "Epoch: 21\tFidelity = 0.935475\tKL_Divergence = 0.024472\n",
      "Epoch: 22\tFidelity = 0.937241\tKL_Divergence = 0.022000\n",
      "Epoch: 23\tFidelity = 0.936209\tKL_Divergence = 0.024009\n",
      "Epoch: 24\tFidelity = 0.931799\tKL_Divergence = 0.027123\n",
      "Epoch: 25\tFidelity = 0.931942\tKL_Divergence = 0.024940\n",
      "Epoch: 26\tFidelity = 0.936216\tKL_Divergence = 0.022949\n",
      "Epoch: 27\tFidelity = 0.934836\tKL_Divergence = 0.024437\n",
      "Epoch: 28\tFidelity = 0.935416\tKL_Divergence = 0.022892\n",
      "Epoch: 29\tFidelity = 0.933624\tKL_Divergence = 0.023595\n",
      "Epoch: 30\tFidelity = 0.935189\tKL_Divergence = 0.023140\n",
      "Epoch: 31\tFidelity = 0.932458\tKL_Divergence = 0.025576\n",
      "Epoch: 32\tFidelity = 0.935191\tKL_Divergence = 0.023066\n",
      "Epoch: 33\tFidelity = 0.936405\tKL_Divergence = 0.022566\n",
      "Epoch: 34\tFidelity = 0.935509\tKL_Divergence = 0.023000\n",
      "Epoch: 35\tFidelity = 0.936732\tKL_Divergence = 0.022754\n",
      "Epoch: 36\tFidelity = 0.934806\tKL_Divergence = 0.024113\n",
      "Epoch: 37\tFidelity = 0.935475\tKL_Divergence = 0.023283\n",
      "Epoch: 38\tFidelity = 0.937879\tKL_Divergence = 0.022112\n",
      "Epoch: 39\tFidelity = 0.935170\tKL_Divergence = 0.023259\n",
      "Epoch: 40\tFidelity = 0.935179\tKL_Divergence = 0.026157\n",
      "Epoch: 41\tFidelity = 0.936926\tKL_Divergence = 0.022326\n",
      "Epoch: 42\tFidelity = 0.936548\tKL_Divergence = 0.022480\n",
      "Epoch: 43\tFidelity = 0.937078\tKL_Divergence = 0.022232\n",
      "Epoch: 44\tFidelity = 0.936554\tKL_Divergence = 0.022353\n",
      "Epoch: 45\tFidelity = 0.933679\tKL_Divergence = 0.026935\n",
      "Epoch: 46\tFidelity = 0.937174\tKL_Divergence = 0.022072\n",
      "Epoch: 47\tFidelity = 0.936834\tKL_Divergence = 0.023492\n",
      "Epoch: 48\tFidelity = 0.935361\tKL_Divergence = 0.023654\n",
      "Epoch: 49\tFidelity = 0.931174\tKL_Divergence = 0.029137\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:38:54,977] Trial 74 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.936244\tKL_Divergence = 0.023357\n",
      "Total time elapsed during training: 305.866 s\n",
      "Trial 74 pruned. \n",
      "Trial 74 pruned. \n",
      "Trial 74 pruned. \n",
      "Trial 74 pruned. \n",
      "Trial 74 pruned. \n",
      "Trial 74 pruned. \n",
      "Epoch: 1\tFidelity = 0.936580\tKL_Divergence = 0.024965\n",
      "Epoch: 2\tFidelity = 0.932900\tKL_Divergence = 0.026505\n",
      "Epoch: 3\tFidelity = 0.936753\tKL_Divergence = 0.024380\n",
      "Epoch: 4\tFidelity = 0.938500\tKL_Divergence = 0.021974\n",
      "Epoch: 5\tFidelity = 0.936362\tKL_Divergence = 0.023840\n",
      "Epoch: 6\tFidelity = 0.936730\tKL_Divergence = 0.022674\n",
      "Epoch: 7\tFidelity = 0.935579\tKL_Divergence = 0.022910\n",
      "Epoch: 8\tFidelity = 0.936351\tKL_Divergence = 0.023862\n",
      "Epoch: 9\tFidelity = 0.933722\tKL_Divergence = 0.027459\n",
      "Epoch: 10\tFidelity = 0.935223\tKL_Divergence = 0.024126\n",
      "Epoch: 11\tFidelity = 0.937088\tKL_Divergence = 0.023295\n",
      "Epoch: 12\tFidelity = 0.938261\tKL_Divergence = 0.023358\n",
      "Epoch: 13\tFidelity = 0.932570\tKL_Divergence = 0.025820\n",
      "Epoch: 14\tFidelity = 0.936027\tKL_Divergence = 0.023533\n",
      "Epoch: 15\tFidelity = 0.935193\tKL_Divergence = 0.023439\n",
      "Epoch: 16\tFidelity = 0.935502\tKL_Divergence = 0.023959\n",
      "Epoch: 17\tFidelity = 0.932527\tKL_Divergence = 0.028453\n",
      "Epoch: 18\tFidelity = 0.936332\tKL_Divergence = 0.023014\n",
      "Epoch: 19\tFidelity = 0.934357\tKL_Divergence = 0.024842\n",
      "Epoch: 20\tFidelity = 0.934245\tKL_Divergence = 0.023306\n",
      "Epoch: 21\tFidelity = 0.935045\tKL_Divergence = 0.024077\n",
      "Epoch: 22\tFidelity = 0.937179\tKL_Divergence = 0.022401\n",
      "Epoch: 23\tFidelity = 0.937157\tKL_Divergence = 0.022179\n",
      "Epoch: 24\tFidelity = 0.936112\tKL_Divergence = 0.024471\n",
      "Epoch: 25\tFidelity = 0.935012\tKL_Divergence = 0.024547\n",
      "Epoch: 26\tFidelity = 0.932626\tKL_Divergence = 0.024841\n",
      "Epoch: 27\tFidelity = 0.931480\tKL_Divergence = 0.028912\n",
      "Epoch: 28\tFidelity = 0.933050\tKL_Divergence = 0.026648\n",
      "Epoch: 29\tFidelity = 0.935201\tKL_Divergence = 0.023140\n",
      "Epoch: 30\tFidelity = 0.934172\tKL_Divergence = 0.026354\n",
      "Epoch: 31\tFidelity = 0.937705\tKL_Divergence = 0.022223\n",
      "Epoch: 32\tFidelity = 0.934918\tKL_Divergence = 0.023756\n",
      "Epoch: 33\tFidelity = 0.938360\tKL_Divergence = 0.021943\n",
      "Epoch: 34\tFidelity = 0.933908\tKL_Divergence = 0.027874\n",
      "Epoch: 35\tFidelity = 0.933396\tKL_Divergence = 0.024449\n",
      "Epoch: 36\tFidelity = 0.933713\tKL_Divergence = 0.024644\n",
      "Epoch: 37\tFidelity = 0.928300\tKL_Divergence = 0.035133\n",
      "Epoch: 38\tFidelity = 0.938420\tKL_Divergence = 0.021880\n",
      "Epoch: 39\tFidelity = 0.935519\tKL_Divergence = 0.024856\n",
      "Epoch: 40\tFidelity = 0.938067\tKL_Divergence = 0.023095\n",
      "Epoch: 41\tFidelity = 0.937009\tKL_Divergence = 0.022081\n",
      "Epoch: 42\tFidelity = 0.933920\tKL_Divergence = 0.027080\n",
      "Epoch: 43\tFidelity = 0.932738\tKL_Divergence = 0.027704\n",
      "Epoch: 44\tFidelity = 0.939289\tKL_Divergence = 0.021626\n",
      "Epoch: 45\tFidelity = 0.928049\tKL_Divergence = 0.031639\n",
      "Epoch: 46\tFidelity = 0.929513\tKL_Divergence = 0.030402\n",
      "Epoch: 47\tFidelity = 0.934067\tKL_Divergence = 0.026269\n",
      "Epoch: 48\tFidelity = 0.933429\tKL_Divergence = 0.026600\n",
      "Epoch: 49\tFidelity = 0.929984\tKL_Divergence = 0.028749\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:51:01,360] Trial 75 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.933700\tKL_Divergence = 0.029271\n",
      "Total time elapsed during training: 726.016 s\n",
      "Trial 75 pruned. \n",
      "Trial 75 pruned. \n",
      "Trial 75 pruned. \n",
      "Trial 75 pruned. \n",
      "Trial 75 pruned. \n",
      "Trial 75 pruned. \n",
      "Epoch: 1\tFidelity = 0.935673\tKL_Divergence = 0.023249\n",
      "Epoch: 2\tFidelity = 0.934330\tKL_Divergence = 0.024769\n",
      "Epoch: 3\tFidelity = 0.935747\tKL_Divergence = 0.022838\n",
      "Epoch: 4\tFidelity = 0.932491\tKL_Divergence = 0.027465\n",
      "Epoch: 5\tFidelity = 0.934083\tKL_Divergence = 0.023998\n",
      "Epoch: 6\tFidelity = 0.934703\tKL_Divergence = 0.023359\n",
      "Epoch: 7\tFidelity = 0.935481\tKL_Divergence = 0.023100\n",
      "Epoch: 8\tFidelity = 0.934676\tKL_Divergence = 0.025493\n",
      "Epoch: 9\tFidelity = 0.936699\tKL_Divergence = 0.022600\n",
      "Epoch: 10\tFidelity = 0.935583\tKL_Divergence = 0.023556\n",
      "Epoch: 11\tFidelity = 0.929477\tKL_Divergence = 0.031714\n",
      "Epoch: 12\tFidelity = 0.933948\tKL_Divergence = 0.024051\n",
      "Epoch: 13\tFidelity = 0.934177\tKL_Divergence = 0.026531\n",
      "Epoch: 14\tFidelity = 0.935237\tKL_Divergence = 0.025313\n",
      "Epoch: 15\tFidelity = 0.935145\tKL_Divergence = 0.025361\n",
      "Epoch: 16\tFidelity = 0.937910\tKL_Divergence = 0.022556\n",
      "Epoch: 17\tFidelity = 0.936393\tKL_Divergence = 0.022815\n",
      "Epoch: 18\tFidelity = 0.937303\tKL_Divergence = 0.023215\n",
      "Epoch: 19\tFidelity = 0.938335\tKL_Divergence = 0.021721\n",
      "Epoch: 20\tFidelity = 0.936087\tKL_Divergence = 0.024251\n",
      "Epoch: 21\tFidelity = 0.934829\tKL_Divergence = 0.024559\n",
      "Epoch: 22\tFidelity = 0.934286\tKL_Divergence = 0.024674\n",
      "Epoch: 23\tFidelity = 0.936360\tKL_Divergence = 0.022994\n",
      "Epoch: 24\tFidelity = 0.931140\tKL_Divergence = 0.025349\n",
      "Epoch: 25\tFidelity = 0.934993\tKL_Divergence = 0.023020\n",
      "Epoch: 26\tFidelity = 0.935019\tKL_Divergence = 0.023669\n",
      "Epoch: 27\tFidelity = 0.935203\tKL_Divergence = 0.023138\n",
      "Epoch: 28\tFidelity = 0.935185\tKL_Divergence = 0.024581\n",
      "Epoch: 29\tFidelity = 0.931834\tKL_Divergence = 0.025801\n",
      "Epoch: 30\tFidelity = 0.930944\tKL_Divergence = 0.029229\n",
      "Epoch: 31\tFidelity = 0.937225\tKL_Divergence = 0.022443\n",
      "Epoch: 32\tFidelity = 0.934711\tKL_Divergence = 0.023399\n",
      "Epoch: 33\tFidelity = 0.934762\tKL_Divergence = 0.023462\n",
      "Epoch: 34\tFidelity = 0.933903\tKL_Divergence = 0.026725\n",
      "Epoch: 35\tFidelity = 0.934116\tKL_Divergence = 0.023760\n",
      "Epoch: 36\tFidelity = 0.934280\tKL_Divergence = 0.023654\n",
      "Epoch: 37\tFidelity = 0.932548\tKL_Divergence = 0.027744\n",
      "Epoch: 38\tFidelity = 0.935601\tKL_Divergence = 0.024502\n",
      "Epoch: 39\tFidelity = 0.936642\tKL_Divergence = 0.023952\n",
      "Epoch: 40\tFidelity = 0.937985\tKL_Divergence = 0.022778\n",
      "Epoch: 41\tFidelity = 0.938886\tKL_Divergence = 0.021711\n",
      "Epoch: 42\tFidelity = 0.938796\tKL_Divergence = 0.023832\n",
      "Epoch: 43\tFidelity = 0.936608\tKL_Divergence = 0.024022\n",
      "Epoch: 44\tFidelity = 0.924849\tKL_Divergence = 0.043840\n",
      "Epoch: 45\tFidelity = 0.934084\tKL_Divergence = 0.025345\n",
      "Epoch: 46\tFidelity = 0.938020\tKL_Divergence = 0.023133\n",
      "Epoch: 47\tFidelity = 0.939118\tKL_Divergence = 0.021541\n",
      "Epoch: 48\tFidelity = 0.938648\tKL_Divergence = 0.022043\n",
      "Epoch: 49\tFidelity = 0.936958\tKL_Divergence = 0.022494\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:56:29,586] Trial 76 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.935361\tKL_Divergence = 0.025780\n",
      "Total time elapsed during training: 327.904 s\n",
      "Trial 76 pruned. \n",
      "Trial 76 pruned. \n",
      "Trial 76 pruned. \n",
      "Trial 76 pruned. \n",
      "Trial 76 pruned. \n",
      "Trial 76 pruned. \n",
      "Epoch: 1\tFidelity = 0.933985\tKL_Divergence = 0.024517\n",
      "Epoch: 2\tFidelity = 0.936341\tKL_Divergence = 0.022833\n",
      "Epoch: 3\tFidelity = 0.932996\tKL_Divergence = 0.024182\n",
      "Epoch: 4\tFidelity = 0.936905\tKL_Divergence = 0.022725\n",
      "Epoch: 5\tFidelity = 0.935533\tKL_Divergence = 0.023614\n",
      "Epoch: 6\tFidelity = 0.936456\tKL_Divergence = 0.024433\n",
      "Epoch: 7\tFidelity = 0.936622\tKL_Divergence = 0.022501\n",
      "Epoch: 8\tFidelity = 0.935231\tKL_Divergence = 0.023289\n",
      "Epoch: 9\tFidelity = 0.938312\tKL_Divergence = 0.021840\n",
      "Epoch: 10\tFidelity = 0.938695\tKL_Divergence = 0.021874\n",
      "Epoch: 11\tFidelity = 0.938360\tKL_Divergence = 0.022014\n",
      "Epoch: 12\tFidelity = 0.938739\tKL_Divergence = 0.021643\n",
      "Epoch: 13\tFidelity = 0.936045\tKL_Divergence = 0.024109\n",
      "Epoch: 14\tFidelity = 0.934614\tKL_Divergence = 0.025615\n",
      "Epoch: 15\tFidelity = 0.936637\tKL_Divergence = 0.023672\n",
      "Epoch: 16\tFidelity = 0.936852\tKL_Divergence = 0.022190\n",
      "Epoch: 17\tFidelity = 0.933198\tKL_Divergence = 0.024500\n",
      "Epoch: 18\tFidelity = 0.934334\tKL_Divergence = 0.023484\n",
      "Epoch: 19\tFidelity = 0.934081\tKL_Divergence = 0.023600\n",
      "Epoch: 20\tFidelity = 0.927979\tKL_Divergence = 0.027108\n",
      "Epoch: 21\tFidelity = 0.935685\tKL_Divergence = 0.022749\n",
      "Epoch: 22\tFidelity = 0.935326\tKL_Divergence = 0.023115\n",
      "Epoch: 23\tFidelity = 0.930525\tKL_Divergence = 0.030488\n",
      "Epoch: 24\tFidelity = 0.934573\tKL_Divergence = 0.023543\n",
      "Epoch: 25\tFidelity = 0.933882\tKL_Divergence = 0.025913\n",
      "Epoch: 26\tFidelity = 0.933320\tKL_Divergence = 0.025331\n",
      "Epoch: 27\tFidelity = 0.935514\tKL_Divergence = 0.023398\n",
      "Epoch: 28\tFidelity = 0.933530\tKL_Divergence = 0.026929\n",
      "Epoch: 29\tFidelity = 0.936340\tKL_Divergence = 0.024983\n",
      "Epoch: 30\tFidelity = 0.935516\tKL_Divergence = 0.026208\n",
      "Epoch: 31\tFidelity = 0.935253\tKL_Divergence = 0.024255\n",
      "Epoch: 32\tFidelity = 0.937303\tKL_Divergence = 0.022571\n",
      "Epoch: 33\tFidelity = 0.937555\tKL_Divergence = 0.022412\n",
      "Epoch: 34\tFidelity = 0.934273\tKL_Divergence = 0.025615\n",
      "Epoch: 35\tFidelity = 0.931320\tKL_Divergence = 0.031255\n",
      "Epoch: 36\tFidelity = 0.934670\tKL_Divergence = 0.023798\n",
      "Epoch: 37\tFidelity = 0.936912\tKL_Divergence = 0.022407\n",
      "Epoch: 38\tFidelity = 0.935574\tKL_Divergence = 0.023022\n",
      "Epoch: 39\tFidelity = 0.938155\tKL_Divergence = 0.022480\n",
      "Epoch: 40\tFidelity = 0.932908\tKL_Divergence = 0.024565\n",
      "Epoch: 41\tFidelity = 0.937271\tKL_Divergence = 0.022197\n",
      "Epoch: 42\tFidelity = 0.936767\tKL_Divergence = 0.025698\n",
      "Epoch: 43\tFidelity = 0.935473\tKL_Divergence = 0.023750\n",
      "Epoch: 44\tFidelity = 0.933953\tKL_Divergence = 0.028098\n",
      "Epoch: 45\tFidelity = 0.936361\tKL_Divergence = 0.022470\n",
      "Epoch: 46\tFidelity = 0.935588\tKL_Divergence = 0.023196\n",
      "Epoch: 47\tFidelity = 0.935563\tKL_Divergence = 0.022962\n",
      "Epoch: 48\tFidelity = 0.937210\tKL_Divergence = 0.022342\n",
      "Epoch: 49\tFidelity = 0.936971\tKL_Divergence = 0.022934\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 12:01:51,277] Trial 77 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.936419\tKL_Divergence = 0.022596\n",
      "Total time elapsed during training: 321.383 s\n",
      "Trial 77 pruned. \n",
      "Trial 77 pruned. \n",
      "Trial 77 pruned. \n",
      "Trial 77 pruned. \n",
      "Trial 77 pruned. \n",
      "Trial 77 pruned. \n",
      "Epoch: 1\tFidelity = 0.937147\tKL_Divergence = 0.023053\n",
      "Epoch: 2\tFidelity = 0.936492\tKL_Divergence = 0.022394\n",
      "Epoch: 3\tFidelity = 0.935643\tKL_Divergence = 0.022662\n",
      "Epoch: 4\tFidelity = 0.937038\tKL_Divergence = 0.022479\n",
      "Epoch: 5\tFidelity = 0.938362\tKL_Divergence = 0.022114\n",
      "Epoch: 6\tFidelity = 0.938121\tKL_Divergence = 0.022346\n",
      "Epoch: 7\tFidelity = 0.934290\tKL_Divergence = 0.029990\n",
      "Epoch: 8\tFidelity = 0.935190\tKL_Divergence = 0.025306\n",
      "Epoch: 9\tFidelity = 0.934309\tKL_Divergence = 0.025916\n",
      "Epoch: 10\tFidelity = 0.936263\tKL_Divergence = 0.022895\n",
      "Epoch: 11\tFidelity = 0.937307\tKL_Divergence = 0.022760\n",
      "Epoch: 12\tFidelity = 0.936887\tKL_Divergence = 0.022724\n",
      "Epoch: 13\tFidelity = 0.938233\tKL_Divergence = 0.022883\n",
      "Epoch: 14\tFidelity = 0.937841\tKL_Divergence = 0.021991\n",
      "Epoch: 15\tFidelity = 0.937925\tKL_Divergence = 0.021999\n",
      "Epoch: 16\tFidelity = 0.939046\tKL_Divergence = 0.021384\n",
      "Epoch: 17\tFidelity = 0.940081\tKL_Divergence = 0.021096\n",
      "Epoch: 18\tFidelity = 0.936747\tKL_Divergence = 0.022892\n",
      "Epoch: 19\tFidelity = 0.936015\tKL_Divergence = 0.023250\n",
      "Epoch: 20\tFidelity = 0.940118\tKL_Divergence = 0.021879\n",
      "Epoch: 21\tFidelity = 0.940778\tKL_Divergence = 0.020906\n",
      "Epoch: 22\tFidelity = 0.939088\tKL_Divergence = 0.022015\n",
      "Epoch: 23\tFidelity = 0.934888\tKL_Divergence = 0.028137\n",
      "Epoch: 24\tFidelity = 0.938055\tKL_Divergence = 0.022206\n",
      "Epoch: 25\tFidelity = 0.939635\tKL_Divergence = 0.021072\n",
      "Epoch: 26\tFidelity = 0.938772\tKL_Divergence = 0.022443\n",
      "Epoch: 27\tFidelity = 0.932611\tKL_Divergence = 0.030863\n",
      "Epoch: 28\tFidelity = 0.935462\tKL_Divergence = 0.024790\n",
      "Epoch: 29\tFidelity = 0.938393\tKL_Divergence = 0.021567\n",
      "Epoch: 30\tFidelity = 0.937013\tKL_Divergence = 0.022643\n",
      "Epoch: 31\tFidelity = 0.936526\tKL_Divergence = 0.022297\n",
      "Epoch: 32\tFidelity = 0.935622\tKL_Divergence = 0.022916\n",
      "Epoch: 33\tFidelity = 0.936684\tKL_Divergence = 0.021986\n",
      "Epoch: 34\tFidelity = 0.933945\tKL_Divergence = 0.026201\n",
      "Epoch: 35\tFidelity = 0.934131\tKL_Divergence = 0.026825\n",
      "Epoch: 36\tFidelity = 0.936480\tKL_Divergence = 0.022567\n",
      "Epoch: 37\tFidelity = 0.937497\tKL_Divergence = 0.021844\n",
      "Epoch: 38\tFidelity = 0.934996\tKL_Divergence = 0.024378\n",
      "Epoch: 39\tFidelity = 0.934021\tKL_Divergence = 0.025409\n",
      "Epoch: 40\tFidelity = 0.936385\tKL_Divergence = 0.023339\n",
      "Epoch: 41\tFidelity = 0.937951\tKL_Divergence = 0.021949\n",
      "Epoch: 42\tFidelity = 0.938864\tKL_Divergence = 0.021321\n",
      "Epoch: 43\tFidelity = 0.938910\tKL_Divergence = 0.021334\n",
      "Epoch: 44\tFidelity = 0.936945\tKL_Divergence = 0.022215\n",
      "Epoch: 45\tFidelity = 0.936488\tKL_Divergence = 0.022732\n",
      "Epoch: 46\tFidelity = 0.939598\tKL_Divergence = 0.021053\n",
      "Epoch: 47\tFidelity = 0.940050\tKL_Divergence = 0.021021\n",
      "Epoch: 48\tFidelity = 0.934373\tKL_Divergence = 0.025450\n",
      "Epoch: 49\tFidelity = 0.938890\tKL_Divergence = 0.021303\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 12:06:59,525] Trial 78 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.937753\tKL_Divergence = 0.022394\n",
      "Total time elapsed during training: 307.920 s\n",
      "Trial 78 pruned. \n",
      "Trial 78 pruned. \n",
      "Trial 78 pruned. \n",
      "Trial 78 pruned. \n",
      "Trial 78 pruned. \n",
      "Trial 78 pruned. \n",
      "Epoch: 1\tFidelity = 0.931659\tKL_Divergence = 0.029932\n",
      "Epoch: 2\tFidelity = 0.934631\tKL_Divergence = 0.025572\n",
      "Epoch: 3\tFidelity = 0.938440\tKL_Divergence = 0.021789\n",
      "Epoch: 4\tFidelity = 0.935832\tKL_Divergence = 0.023246\n",
      "Epoch: 5\tFidelity = 0.937254\tKL_Divergence = 0.021907\n",
      "Epoch: 6\tFidelity = 0.936669\tKL_Divergence = 0.022398\n",
      "Epoch: 7\tFidelity = 0.937207\tKL_Divergence = 0.024581\n",
      "Epoch: 8\tFidelity = 0.936048\tKL_Divergence = 0.022679\n",
      "Epoch: 9\tFidelity = 0.937705\tKL_Divergence = 0.021851\n",
      "Epoch: 10\tFidelity = 0.933627\tKL_Divergence = 0.023721\n",
      "Epoch: 11\tFidelity = 0.933852\tKL_Divergence = 0.024045\n",
      "Epoch: 12\tFidelity = 0.936918\tKL_Divergence = 0.022516\n",
      "Epoch: 13\tFidelity = 0.939306\tKL_Divergence = 0.022066\n",
      "Epoch: 14\tFidelity = 0.939232\tKL_Divergence = 0.021401\n",
      "Epoch: 15\tFidelity = 0.938624\tKL_Divergence = 0.021834\n",
      "Epoch: 16\tFidelity = 0.936643\tKL_Divergence = 0.022663\n",
      "Epoch: 17\tFidelity = 0.936037\tKL_Divergence = 0.022496\n",
      "Epoch: 18\tFidelity = 0.936489\tKL_Divergence = 0.022613\n",
      "Epoch: 19\tFidelity = 0.936727\tKL_Divergence = 0.022396\n",
      "Epoch: 20\tFidelity = 0.936249\tKL_Divergence = 0.022600\n",
      "Epoch: 21\tFidelity = 0.933613\tKL_Divergence = 0.024045\n",
      "Epoch: 22\tFidelity = 0.937030\tKL_Divergence = 0.022399\n",
      "Epoch: 23\tFidelity = 0.934194\tKL_Divergence = 0.023703\n",
      "Epoch: 24\tFidelity = 0.928680\tKL_Divergence = 0.032197\n",
      "Epoch: 25\tFidelity = 0.933909\tKL_Divergence = 0.024401\n",
      "Epoch: 26\tFidelity = 0.933495\tKL_Divergence = 0.026673\n",
      "Epoch: 27\tFidelity = 0.932888\tKL_Divergence = 0.026069\n",
      "Epoch: 28\tFidelity = 0.936209\tKL_Divergence = 0.025485\n",
      "Epoch: 29\tFidelity = 0.936225\tKL_Divergence = 0.022789\n",
      "Epoch: 30\tFidelity = 0.931307\tKL_Divergence = 0.034116\n",
      "Epoch: 31\tFidelity = 0.933664\tKL_Divergence = 0.024771\n",
      "Epoch: 32\tFidelity = 0.933389\tKL_Divergence = 0.027107\n",
      "Epoch: 33\tFidelity = 0.937285\tKL_Divergence = 0.022437\n",
      "Epoch: 34\tFidelity = 0.931945\tKL_Divergence = 0.030323\n",
      "Epoch: 35\tFidelity = 0.938373\tKL_Divergence = 0.022231\n",
      "Epoch: 36\tFidelity = 0.938531\tKL_Divergence = 0.021973\n",
      "Epoch: 37\tFidelity = 0.936818\tKL_Divergence = 0.022655\n",
      "Epoch: 38\tFidelity = 0.935545\tKL_Divergence = 0.024291\n",
      "Epoch: 39\tFidelity = 0.936288\tKL_Divergence = 0.023000\n",
      "Epoch: 40\tFidelity = 0.935926\tKL_Divergence = 0.022993\n",
      "Epoch: 41\tFidelity = 0.933748\tKL_Divergence = 0.026691\n",
      "Epoch: 42\tFidelity = 0.933616\tKL_Divergence = 0.028209\n",
      "Epoch: 43\tFidelity = 0.937042\tKL_Divergence = 0.027090\n",
      "Epoch: 44\tFidelity = 0.938488\tKL_Divergence = 0.022759\n",
      "Epoch: 45\tFidelity = 0.937285\tKL_Divergence = 0.026379\n",
      "Epoch: 46\tFidelity = 0.937093\tKL_Divergence = 0.025047\n",
      "Epoch: 47\tFidelity = 0.938268\tKL_Divergence = 0.022203\n",
      "Epoch: 48\tFidelity = 0.939932\tKL_Divergence = 0.023129\n",
      "Epoch: 49\tFidelity = 0.941625\tKL_Divergence = 0.021034\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 12:13:25,753] Trial 79 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.936143\tKL_Divergence = 0.022797\n",
      "Total time elapsed during training: 385.907 s\n",
      "Trial 79 pruned. \n",
      "Trial 79 pruned. \n",
      "Trial 79 pruned. \n",
      "Trial 79 pruned. \n",
      "Trial 79 pruned. \n",
      "Trial 79 pruned. \n",
      "Epoch: 1\tFidelity = 0.933949\tKL_Divergence = 0.023890\n",
      "Epoch: 2\tFidelity = 0.937778\tKL_Divergence = 0.025581\n",
      "Epoch: 3\tFidelity = 0.935655\tKL_Divergence = 0.026554\n",
      "Epoch: 4\tFidelity = 0.935545\tKL_Divergence = 0.031561\n",
      "Epoch: 5\tFidelity = 0.938890\tKL_Divergence = 0.022997\n",
      "Epoch: 6\tFidelity = 0.934207\tKL_Divergence = 0.027007\n",
      "Epoch: 7\tFidelity = 0.937885\tKL_Divergence = 0.023662\n",
      "Epoch: 8\tFidelity = 0.932781\tKL_Divergence = 0.036089\n",
      "Epoch: 9\tFidelity = 0.936203\tKL_Divergence = 0.022864\n",
      "Epoch: 10\tFidelity = 0.936427\tKL_Divergence = 0.024995\n",
      "Epoch: 11\tFidelity = 0.940955\tKL_Divergence = 0.022066\n",
      "Epoch: 12\tFidelity = 0.938440\tKL_Divergence = 0.021641\n",
      "Epoch: 13\tFidelity = 0.939674\tKL_Divergence = 0.021836\n",
      "Epoch: 14\tFidelity = 0.937330\tKL_Divergence = 0.022138\n",
      "Epoch: 15\tFidelity = 0.935820\tKL_Divergence = 0.024721\n",
      "Epoch: 16\tFidelity = 0.935581\tKL_Divergence = 0.023164\n",
      "Epoch: 17\tFidelity = 0.934920\tKL_Divergence = 0.026114\n",
      "Epoch: 18\tFidelity = 0.930440\tKL_Divergence = 0.033451\n",
      "Epoch: 19\tFidelity = 0.937540\tKL_Divergence = 0.022322\n",
      "Epoch: 20\tFidelity = 0.935540\tKL_Divergence = 0.024010\n",
      "Epoch: 21\tFidelity = 0.933706\tKL_Divergence = 0.023789\n",
      "Epoch: 22\tFidelity = 0.931786\tKL_Divergence = 0.035752\n",
      "Epoch: 23\tFidelity = 0.933275\tKL_Divergence = 0.023739\n",
      "Epoch: 24\tFidelity = 0.936056\tKL_Divergence = 0.023100\n",
      "Epoch: 25\tFidelity = 0.933613\tKL_Divergence = 0.028440\n",
      "Epoch: 26\tFidelity = 0.937098\tKL_Divergence = 0.022724\n",
      "Epoch: 27\tFidelity = 0.939405\tKL_Divergence = 0.023912\n",
      "Epoch: 28\tFidelity = 0.937171\tKL_Divergence = 0.023426\n",
      "Epoch: 29\tFidelity = 0.933835\tKL_Divergence = 0.026859\n",
      "Epoch: 30\tFidelity = 0.939352\tKL_Divergence = 0.021829\n",
      "Epoch: 31\tFidelity = 0.928663\tKL_Divergence = 0.041103\n",
      "Epoch: 32\tFidelity = 0.936595\tKL_Divergence = 0.022486\n",
      "Epoch: 33\tFidelity = 0.926356\tKL_Divergence = 0.038571\n",
      "Epoch: 34\tFidelity = 0.932612\tKL_Divergence = 0.028432\n",
      "Epoch: 35\tFidelity = 0.930365\tKL_Divergence = 0.027016\n",
      "Epoch: 36\tFidelity = 0.932165\tKL_Divergence = 0.028355\n",
      "Epoch: 37\tFidelity = 0.934505\tKL_Divergence = 0.025829\n",
      "Epoch: 38\tFidelity = 0.937277\tKL_Divergence = 0.024503\n",
      "Epoch: 39\tFidelity = 0.929593\tKL_Divergence = 0.033159\n",
      "Epoch: 40\tFidelity = 0.935040\tKL_Divergence = 0.024786\n",
      "Epoch: 41\tFidelity = 0.926242\tKL_Divergence = 0.035906\n",
      "Epoch: 42\tFidelity = 0.936875\tKL_Divergence = 0.022980\n",
      "Epoch: 43\tFidelity = 0.936499\tKL_Divergence = 0.023450\n",
      "Epoch: 44\tFidelity = 0.937583\tKL_Divergence = 0.025531\n",
      "Epoch: 45\tFidelity = 0.934577\tKL_Divergence = 0.023729\n",
      "Epoch: 46\tFidelity = 0.935421\tKL_Divergence = 0.024385\n",
      "Epoch: 47\tFidelity = 0.931768\tKL_Divergence = 0.028012\n",
      "Epoch: 48\tFidelity = 0.933949\tKL_Divergence = 0.025387\n",
      "Epoch: 49\tFidelity = 0.936671\tKL_Divergence = 0.023385\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 12:21:47,210] Trial 80 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.934600\tKL_Divergence = 0.027010\n",
      "Total time elapsed during training: 501.103 s\n",
      "Trial 80 pruned. \n",
      "Trial 80 pruned. \n",
      "Trial 80 pruned. \n",
      "Trial 80 pruned. \n",
      "Trial 80 pruned. \n",
      "Trial 80 pruned. \n",
      "Epoch: 1\tFidelity = 0.936337\tKL_Divergence = 0.025916\n",
      "Epoch: 2\tFidelity = 0.936930\tKL_Divergence = 0.023152\n",
      "Epoch: 3\tFidelity = 0.934494\tKL_Divergence = 0.024009\n",
      "Epoch: 4\tFidelity = 0.937097\tKL_Divergence = 0.022157\n",
      "Epoch: 5\tFidelity = 0.936744\tKL_Divergence = 0.022417\n",
      "Epoch: 6\tFidelity = 0.933153\tKL_Divergence = 0.024289\n",
      "Epoch: 7\tFidelity = 0.934585\tKL_Divergence = 0.023578\n",
      "Epoch: 8\tFidelity = 0.928161\tKL_Divergence = 0.029467\n",
      "Epoch: 9\tFidelity = 0.934098\tKL_Divergence = 0.023589\n",
      "Epoch: 10\tFidelity = 0.931371\tKL_Divergence = 0.030260\n",
      "Epoch: 11\tFidelity = 0.935417\tKL_Divergence = 0.025636\n",
      "Epoch: 12\tFidelity = 0.935510\tKL_Divergence = 0.023616\n",
      "Epoch: 13\tFidelity = 0.935129\tKL_Divergence = 0.023410\n",
      "Epoch: 14\tFidelity = 0.936255\tKL_Divergence = 0.022766\n",
      "Epoch: 15\tFidelity = 0.929213\tKL_Divergence = 0.033796\n",
      "Epoch: 16\tFidelity = 0.935839\tKL_Divergence = 0.024991\n",
      "Epoch: 17\tFidelity = 0.936610\tKL_Divergence = 0.023181\n",
      "Epoch: 18\tFidelity = 0.938012\tKL_Divergence = 0.022513\n",
      "Epoch: 19\tFidelity = 0.936813\tKL_Divergence = 0.022752\n",
      "Epoch: 20\tFidelity = 0.933313\tKL_Divergence = 0.026819\n",
      "Epoch: 21\tFidelity = 0.936508\tKL_Divergence = 0.022729\n",
      "Epoch: 22\tFidelity = 0.935500\tKL_Divergence = 0.023619\n",
      "Epoch: 23\tFidelity = 0.936417\tKL_Divergence = 0.023150\n",
      "Epoch: 24\tFidelity = 0.935921\tKL_Divergence = 0.023158\n",
      "Epoch: 25\tFidelity = 0.933535\tKL_Divergence = 0.026096\n",
      "Epoch: 26\tFidelity = 0.931569\tKL_Divergence = 0.025172\n",
      "Epoch: 27\tFidelity = 0.933254\tKL_Divergence = 0.026807\n",
      "Epoch: 28\tFidelity = 0.935335\tKL_Divergence = 0.022757\n",
      "Epoch: 29\tFidelity = 0.933861\tKL_Divergence = 0.025854\n",
      "Epoch: 30\tFidelity = 0.935773\tKL_Divergence = 0.022579\n",
      "Epoch: 31\tFidelity = 0.933209\tKL_Divergence = 0.023666\n",
      "Epoch: 32\tFidelity = 0.933649\tKL_Divergence = 0.025723\n",
      "Epoch: 33\tFidelity = 0.936060\tKL_Divergence = 0.022694\n",
      "Epoch: 34\tFidelity = 0.928691\tKL_Divergence = 0.028862\n",
      "Epoch: 35\tFidelity = 0.932504\tKL_Divergence = 0.026148\n",
      "Epoch: 36\tFidelity = 0.935620\tKL_Divergence = 0.023345\n",
      "Epoch: 37\tFidelity = 0.934458\tKL_Divergence = 0.023541\n",
      "Epoch: 38\tFidelity = 0.934488\tKL_Divergence = 0.025908\n",
      "Epoch: 39\tFidelity = 0.937826\tKL_Divergence = 0.022630\n",
      "Epoch: 40\tFidelity = 0.936548\tKL_Divergence = 0.023158\n",
      "Epoch: 41\tFidelity = 0.934481\tKL_Divergence = 0.025467\n",
      "Epoch: 42\tFidelity = 0.934139\tKL_Divergence = 0.025864\n",
      "Epoch: 43\tFidelity = 0.934225\tKL_Divergence = 0.023917\n",
      "Epoch: 44\tFidelity = 0.934125\tKL_Divergence = 0.023853\n",
      "Epoch: 45\tFidelity = 0.936319\tKL_Divergence = 0.023231\n",
      "Epoch: 46\tFidelity = 0.935847\tKL_Divergence = 0.023006\n",
      "Epoch: 47\tFidelity = 0.934983\tKL_Divergence = 0.026737\n",
      "Epoch: 48\tFidelity = 0.934692\tKL_Divergence = 0.023648\n",
      "Epoch: 49\tFidelity = 0.928798\tKL_Divergence = 0.033242\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 12:27:33,716] Trial 81 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.933520\tKL_Divergence = 0.026102\n",
      "Total time elapsed during training: 346.175 s\n",
      "Trial 81 pruned. \n",
      "Trial 81 pruned. \n",
      "Trial 81 pruned. \n",
      "Trial 81 pruned. \n",
      "Trial 81 pruned. \n",
      "Trial 81 pruned. \n",
      "Epoch: 1\tFidelity = 0.935054\tKL_Divergence = 0.025865\n",
      "Epoch: 2\tFidelity = 0.936249\tKL_Divergence = 0.022978\n",
      "Epoch: 3\tFidelity = 0.933526\tKL_Divergence = 0.023983\n",
      "Epoch: 4\tFidelity = 0.928357\tKL_Divergence = 0.037926\n",
      "Epoch: 5\tFidelity = 0.934783\tKL_Divergence = 0.023335\n",
      "Epoch: 6\tFidelity = 0.936682\tKL_Divergence = 0.023799\n",
      "Epoch: 7\tFidelity = 0.936439\tKL_Divergence = 0.023040\n",
      "Epoch: 8\tFidelity = 0.929843\tKL_Divergence = 0.025533\n",
      "Epoch: 9\tFidelity = 0.932580\tKL_Divergence = 0.024485\n",
      "Epoch: 10\tFidelity = 0.935261\tKL_Divergence = 0.023520\n",
      "Epoch: 11\tFidelity = 0.937216\tKL_Divergence = 0.022572\n",
      "Epoch: 12\tFidelity = 0.935566\tKL_Divergence = 0.023783\n",
      "Epoch: 13\tFidelity = 0.935796\tKL_Divergence = 0.024367\n",
      "Epoch: 14\tFidelity = 0.935466\tKL_Divergence = 0.023611\n",
      "Epoch: 15\tFidelity = 0.931474\tKL_Divergence = 0.025110\n",
      "Epoch: 16\tFidelity = 0.937260\tKL_Divergence = 0.023236\n",
      "Epoch: 17\tFidelity = 0.936056\tKL_Divergence = 0.022682\n",
      "Epoch: 18\tFidelity = 0.932035\tKL_Divergence = 0.027037\n",
      "Epoch: 19\tFidelity = 0.931746\tKL_Divergence = 0.025530\n",
      "Epoch: 20\tFidelity = 0.938104\tKL_Divergence = 0.022144\n",
      "Epoch: 21\tFidelity = 0.929058\tKL_Divergence = 0.033815\n",
      "Epoch: 22\tFidelity = 0.933492\tKL_Divergence = 0.028498\n",
      "Epoch: 23\tFidelity = 0.937185\tKL_Divergence = 0.023039\n",
      "Epoch: 24\tFidelity = 0.937029\tKL_Divergence = 0.024324\n",
      "Epoch: 25\tFidelity = 0.934879\tKL_Divergence = 0.027273\n",
      "Epoch: 26\tFidelity = 0.936517\tKL_Divergence = 0.024516\n",
      "Epoch: 27\tFidelity = 0.936877\tKL_Divergence = 0.023017\n",
      "Epoch: 28\tFidelity = 0.937835\tKL_Divergence = 0.022272\n",
      "Epoch: 29\tFidelity = 0.935800\tKL_Divergence = 0.022860\n",
      "Epoch: 30\tFidelity = 0.932415\tKL_Divergence = 0.027727\n",
      "Epoch: 31\tFidelity = 0.934407\tKL_Divergence = 0.023697\n",
      "Epoch: 32\tFidelity = 0.936942\tKL_Divergence = 0.022709\n",
      "Epoch: 33\tFidelity = 0.939067\tKL_Divergence = 0.021782\n",
      "Epoch: 34\tFidelity = 0.937647\tKL_Divergence = 0.022459\n",
      "Epoch: 35\tFidelity = 0.931123\tKL_Divergence = 0.025981\n",
      "Epoch: 36\tFidelity = 0.937645\tKL_Divergence = 0.022850\n",
      "Epoch: 37\tFidelity = 0.937529\tKL_Divergence = 0.024677\n",
      "Epoch: 38\tFidelity = 0.932920\tKL_Divergence = 0.026137\n",
      "Epoch: 39\tFidelity = 0.936243\tKL_Divergence = 0.022906\n",
      "Epoch: 40\tFidelity = 0.931844\tKL_Divergence = 0.028083\n",
      "Epoch: 41\tFidelity = 0.935119\tKL_Divergence = 0.026364\n",
      "Epoch: 42\tFidelity = 0.938158\tKL_Divergence = 0.021841\n",
      "Epoch: 43\tFidelity = 0.931848\tKL_Divergence = 0.026198\n",
      "Epoch: 44\tFidelity = 0.936540\tKL_Divergence = 0.023642\n",
      "Epoch: 45\tFidelity = 0.935420\tKL_Divergence = 0.024438\n",
      "Epoch: 46\tFidelity = 0.937818\tKL_Divergence = 0.021839\n",
      "Epoch: 47\tFidelity = 0.936734\tKL_Divergence = 0.022798\n",
      "Epoch: 48\tFidelity = 0.934801\tKL_Divergence = 0.023178\n",
      "Epoch: 49\tFidelity = 0.936288\tKL_Divergence = 0.022753\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 12:34:29,209] Trial 82 finished with value: 0.022097084468181014 and parameters: {'lr': 7.7347538771601165, 'pbs': 3000, 'nbs': 10000}. Best is trial 57 with value: 0.02145553797915265.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.937139\tKL_Divergence = 0.022097\n",
      "Total time elapsed during training: 415.156 s\n",
      "Trial 82 finished with value: 0.022097084468181014 and parameters: {'lr': 7.7347538771601165, 'pbs': 3000, 'nbs': 10000}. Best is trial 57 with value: 0.02145553797915265.\n",
      "Trial 82 finished with value: 0.022097084468181014 and parameters: {'lr': 7.7347538771601165, 'pbs': 3000, 'nbs': 10000}. Best is trial 57 with value: 0.02145553797915265.\n",
      "Trial 82 finished with value: 0.022097084468181014 and parameters: {'lr': 7.7347538771601165, 'pbs': 3000, 'nbs': 10000}. Best is trial 57 with value: 0.02145553797915265.\n",
      "Trial 82 finished with value: 0.022097084468181014 and parameters: {'lr': 7.7347538771601165, 'pbs': 3000, 'nbs': 10000}. Best is trial 57 with value: 0.02145553797915265.\n",
      "Trial 82 finished with value: 0.022097084468181014 and parameters: {'lr': 7.7347538771601165, 'pbs': 3000, 'nbs': 10000}. Best is trial 57 with value: 0.02145553797915265.\n",
      "Trial 82 finished with value: 0.022097084468181014 and parameters: {'lr': 7.7347538771601165, 'pbs': 3000, 'nbs': 10000}. Best is trial 57 with value: 0.02145553797915265.\n",
      "Epoch: 1\tFidelity = 0.937593\tKL_Divergence = 0.022202\n",
      "Epoch: 2\tFidelity = 0.935084\tKL_Divergence = 0.022940\n",
      "Epoch: 3\tFidelity = 0.934238\tKL_Divergence = 0.023635\n",
      "Epoch: 4\tFidelity = 0.935047\tKL_Divergence = 0.022881\n",
      "Epoch: 5\tFidelity = 0.931021\tKL_Divergence = 0.027713\n",
      "Epoch: 6\tFidelity = 0.934568\tKL_Divergence = 0.023978\n",
      "Epoch: 7\tFidelity = 0.933140\tKL_Divergence = 0.023988\n",
      "Epoch: 8\tFidelity = 0.938167\tKL_Divergence = 0.021999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-08-25 12:35:25,632] Trial 83 failed with parameters: {'lr': 6.7211417156523146, 'pbs': 7000, 'nbs': 3000} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_64/1699494747.py\", line 15, in objective\n",
      "    nn_state_dm.fit(data = meas_result,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/density_matrix.py\", line 354, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/neural_state.py\", line 614, in fit\n",
      "    all_grads = self.compute_batch_gradients(k, *batch)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/neural_state.py\", line 439, in compute_batch_gradients\n",
      "    grad = self.positive_phase_gradients(samples_batch, bases_batch=bases_batch)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/neural_state.py\", line 382, in positive_phase_gradients\n",
      "    grad = self.gradient(samples_batch, bases=bases_batch)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/neural_state.py\", line 359, in gradient\n",
      "    sample_grad = self.rotated_gradient(basis, samples[indices == i, :])\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/density_matrix.py\", line 298, in rotated_gradient\n",
      "    raw_grads = [self.am_grads(v), self.ph_grads(v)]\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/density_matrix.py\", line 330, in ph_grads\n",
      "    ) + self.pi_grad(v, v, phase=True, expand=True)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/density_matrix.py\", line 194, in pi_grad\n",
      "    sig = cplx.sigmoid(arg_real, arg_imag)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/utils/cplx.py\", line 331, in sigmoid\n",
      "    out = np.exp(z) / (1 + np.exp(z))\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 83 failed with parameters: {'lr': 6.7211417156523146, 'pbs': 7000, 'nbs': 3000} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_64/1699494747.py\", line 15, in objective\n",
      "    nn_state_dm.fit(data = meas_result,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/density_matrix.py\", line 354, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/neural_state.py\", line 614, in fit\n",
      "    all_grads = self.compute_batch_gradients(k, *batch)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/neural_state.py\", line 439, in compute_batch_gradients\n",
      "    grad = self.positive_phase_gradients(samples_batch, bases_batch=bases_batch)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/neural_state.py\", line 382, in positive_phase_gradients\n",
      "    grad = self.gradient(samples_batch, bases=bases_batch)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/neural_state.py\", line 359, in gradient\n",
      "    sample_grad = self.rotated_gradient(basis, samples[indices == i, :])\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/density_matrix.py\", line 298, in rotated_gradient\n",
      "    raw_grads = [self.am_grads(v), self.ph_grads(v)]\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/density_matrix.py\", line 330, in ph_grads\n",
      "    ) + self.pi_grad(v, v, phase=True, expand=True)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/density_matrix.py\", line 194, in pi_grad\n",
      "    sig = cplx.sigmoid(arg_real, arg_imag)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/utils/cplx.py\", line 331, in sigmoid\n",
      "    out = np.exp(z) / (1 + np.exp(z))\n",
      "KeyboardInterrupt\n",
      "Trial 83 failed with parameters: {'lr': 6.7211417156523146, 'pbs': 7000, 'nbs': 3000} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_64/1699494747.py\", line 15, in objective\n",
      "    nn_state_dm.fit(data = meas_result,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/density_matrix.py\", line 354, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/neural_state.py\", line 614, in fit\n",
      "    all_grads = self.compute_batch_gradients(k, *batch)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/neural_state.py\", line 439, in compute_batch_gradients\n",
      "    grad = self.positive_phase_gradients(samples_batch, bases_batch=bases_batch)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/neural_state.py\", line 382, in positive_phase_gradients\n",
      "    grad = self.gradient(samples_batch, bases=bases_batch)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/neural_state.py\", line 359, in gradient\n",
      "    sample_grad = self.rotated_gradient(basis, samples[indices == i, :])\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/density_matrix.py\", line 298, in rotated_gradient\n",
      "    raw_grads = [self.am_grads(v), self.ph_grads(v)]\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/density_matrix.py\", line 330, in ph_grads\n",
      "    ) + self.pi_grad(v, v, phase=True, expand=True)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/density_matrix.py\", line 194, in pi_grad\n",
      "    sig = cplx.sigmoid(arg_real, arg_imag)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/utils/cplx.py\", line 331, in sigmoid\n",
      "    out = np.exp(z) / (1 + np.exp(z))\n",
      "KeyboardInterrupt\n",
      "Trial 83 failed with parameters: {'lr': 6.7211417156523146, 'pbs': 7000, 'nbs': 3000} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_64/1699494747.py\", line 15, in objective\n",
      "    nn_state_dm.fit(data = meas_result,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/density_matrix.py\", line 354, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/neural_state.py\", line 614, in fit\n",
      "    all_grads = self.compute_batch_gradients(k, *batch)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/neural_state.py\", line 439, in compute_batch_gradients\n",
      "    grad = self.positive_phase_gradients(samples_batch, bases_batch=bases_batch)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/neural_state.py\", line 382, in positive_phase_gradients\n",
      "    grad = self.gradient(samples_batch, bases=bases_batch)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/neural_state.py\", line 359, in gradient\n",
      "    sample_grad = self.rotated_gradient(basis, samples[indices == i, :])\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/density_matrix.py\", line 298, in rotated_gradient\n",
      "    raw_grads = [self.am_grads(v), self.ph_grads(v)]\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/density_matrix.py\", line 330, in ph_grads\n",
      "    ) + self.pi_grad(v, v, phase=True, expand=True)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/density_matrix.py\", line 194, in pi_grad\n",
      "    sig = cplx.sigmoid(arg_real, arg_imag)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/utils/cplx.py\", line 331, in sigmoid\n",
      "    out = np.exp(z) / (1 + np.exp(z))\n",
      "KeyboardInterrupt\n",
      "Trial 83 failed with parameters: {'lr': 6.7211417156523146, 'pbs': 7000, 'nbs': 3000} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_64/1699494747.py\", line 15, in objective\n",
      "    nn_state_dm.fit(data = meas_result,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/density_matrix.py\", line 354, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/neural_state.py\", line 614, in fit\n",
      "    all_grads = self.compute_batch_gradients(k, *batch)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/neural_state.py\", line 439, in compute_batch_gradients\n",
      "    grad = self.positive_phase_gradients(samples_batch, bases_batch=bases_batch)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/neural_state.py\", line 382, in positive_phase_gradients\n",
      "    grad = self.gradient(samples_batch, bases=bases_batch)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/neural_state.py\", line 359, in gradient\n",
      "    sample_grad = self.rotated_gradient(basis, samples[indices == i, :])\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/density_matrix.py\", line 298, in rotated_gradient\n",
      "    raw_grads = [self.am_grads(v), self.ph_grads(v)]\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/density_matrix.py\", line 330, in ph_grads\n",
      "    ) + self.pi_grad(v, v, phase=True, expand=True)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/density_matrix.py\", line 194, in pi_grad\n",
      "    sig = cplx.sigmoid(arg_real, arg_imag)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/utils/cplx.py\", line 331, in sigmoid\n",
      "    out = np.exp(z) / (1 + np.exp(z))\n",
      "KeyboardInterrupt\n",
      "Trial 83 failed with parameters: {'lr': 6.7211417156523146, 'pbs': 7000, 'nbs': 3000} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_64/1699494747.py\", line 15, in objective\n",
      "    nn_state_dm.fit(data = meas_result,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/density_matrix.py\", line 354, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/neural_state.py\", line 614, in fit\n",
      "    all_grads = self.compute_batch_gradients(k, *batch)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/neural_state.py\", line 439, in compute_batch_gradients\n",
      "    grad = self.positive_phase_gradients(samples_batch, bases_batch=bases_batch)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/neural_state.py\", line 382, in positive_phase_gradients\n",
      "    grad = self.gradient(samples_batch, bases=bases_batch)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/neural_state.py\", line 359, in gradient\n",
      "    sample_grad = self.rotated_gradient(basis, samples[indices == i, :])\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/density_matrix.py\", line 298, in rotated_gradient\n",
      "    raw_grads = [self.am_grads(v), self.ph_grads(v)]\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/density_matrix.py\", line 330, in ph_grads\n",
      "    ) + self.pi_grad(v, v, phase=True, expand=True)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/density_matrix.py\", line 194, in pi_grad\n",
      "    sig = cplx.sigmoid(arg_real, arg_imag)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/utils/cplx.py\", line 331, in sigmoid\n",
      "    out = np.exp(z) / (1 + np.exp(z))\n",
      "KeyboardInterrupt\n",
      "Trial 83 failed with parameters: {'lr': 6.7211417156523146, 'pbs': 7000, 'nbs': 3000} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_64/1699494747.py\", line 15, in objective\n",
      "    nn_state_dm.fit(data = meas_result,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/density_matrix.py\", line 354, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/neural_state.py\", line 614, in fit\n",
      "    all_grads = self.compute_batch_gradients(k, *batch)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/neural_state.py\", line 439, in compute_batch_gradients\n",
      "    grad = self.positive_phase_gradients(samples_batch, bases_batch=bases_batch)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/neural_state.py\", line 382, in positive_phase_gradients\n",
      "    grad = self.gradient(samples_batch, bases=bases_batch)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/neural_state.py\", line 359, in gradient\n",
      "    sample_grad = self.rotated_gradient(basis, samples[indices == i, :])\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/density_matrix.py\", line 298, in rotated_gradient\n",
      "    raw_grads = [self.am_grads(v), self.ph_grads(v)]\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/density_matrix.py\", line 330, in ph_grads\n",
      "    ) + self.pi_grad(v, v, phase=True, expand=True)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/density_matrix.py\", line 194, in pi_grad\n",
      "    sig = cplx.sigmoid(arg_real, arg_imag)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/utils/cplx.py\", line 331, in sigmoid\n",
      "    out = np.exp(z) / (1 + np.exp(z))\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-08-25 12:35:25,637] Trial 83 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 83 failed with value None.\n",
      "Trial 83 failed with value None.\n",
      "Trial 83 failed with value None.\n",
      "Trial 83 failed with value None.\n",
      "Trial 83 failed with value None.\n",
      "Trial 83 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m optuna\u001b[38;5;241m.\u001b[39mlogging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptuna\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39maddHandler(logging\u001b[38;5;241m.\u001b[39mStreamHandler(sys\u001b[38;5;241m.\u001b[39mstdout))\n\u001b[1;32m      2\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(pruner\u001b[38;5;241m=\u001b[39moptuna\u001b[38;5;241m.\u001b[39mpruners\u001b[38;5;241m.\u001b[39mMedianPruner())\n\u001b[0;32m----> 3\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/optuna/study/study.py:442\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    341\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    349\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \n\u001b[1;32m    352\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 442\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     12\u001b[0m pbs \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39msuggest_categorical(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpbs\u001b[39m\u001b[38;5;124m\"\u001b[39m, [\u001b[38;5;241m1000\u001b[39m, \u001b[38;5;241m2000\u001b[39m, \u001b[38;5;241m3000\u001b[39m, \u001b[38;5;241m4000\u001b[39m, \u001b[38;5;241m5000\u001b[39m, \u001b[38;5;241m6000\u001b[39m, \u001b[38;5;241m7000\u001b[39m, \u001b[38;5;241m8000\u001b[39m, \u001b[38;5;241m9000\u001b[39m, \u001b[38;5;241m10000\u001b[39m])\n\u001b[1;32m     13\u001b[0m nbs \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39msuggest_categorical(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnbs\u001b[39m\u001b[38;5;124m\"\u001b[39m, [\u001b[38;5;241m1000\u001b[39m, \u001b[38;5;241m2000\u001b[39m, \u001b[38;5;241m3000\u001b[39m, \u001b[38;5;241m4000\u001b[39m, \u001b[38;5;241m5000\u001b[39m, \u001b[38;5;241m6000\u001b[39m, \u001b[38;5;241m7000\u001b[39m, \u001b[38;5;241m8000\u001b[39m, \u001b[38;5;241m9000\u001b[39m, \u001b[38;5;241m10000\u001b[39m])\n\u001b[0;32m---> 15\u001b[0m \u001b[43mnn_state_dm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmeas_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                        \u001b[49m\u001b[43minput_bases\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmeas_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpos_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpbs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mneg_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnbs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_gibbs_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mbases\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmeas_pattern\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m                        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdadelta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mschexduler\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_scheduler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStepLR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mscheduler_args\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstep_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_drop_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgamma\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_drop_factor\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m                        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m loss \u001b[38;5;241m=\u001b[39m callbacks[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKL_Divergence\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     31\u001b[0m trial\u001b[38;5;241m.\u001b[39mreport(loss, epoch)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/density_matrix.py:354\u001b[0m, in \u001b[0;36mDensityMatrix.fit\u001b[0;34m(self, data, epochs, pos_batch_size, neg_batch_size, k, lr, input_bases, progbar, starting_epoch, time, callbacks, optimizer, optimizer_args, scheduler, scheduler_args, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_bases must be provided to train a DensityMatrix!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 354\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneg_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneg_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_bases\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_bases\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstarting_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstarting_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtime\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscheduler_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/neural_state.py:614\u001b[0m, in \u001b[0;36mNeuralStateBase.fit\u001b[0;34m(self, data, epochs, pos_batch_size, neg_batch_size, k, lr, input_bases, progbar, starting_epoch, time, callbacks, optimizer, optimizer_args, scheduler, scheduler_args, **kwargs)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m b, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_iterator):\n\u001b[1;32m    612\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_batch_start(\u001b[38;5;28mself\u001b[39m, ep, b)\n\u001b[0;32m--> 614\u001b[0m     all_grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_batch_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    616\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()  \u001b[38;5;66;03m# clear any cached gradients\u001b[39;00m\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;66;03m# assign gradients to corresponding parameters\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/neural_state.py:439\u001b[0m, in \u001b[0;36mNeuralStateBase.compute_batch_gradients\u001b[0;34m(self, k, samples_batch, neg_batch, bases_batch)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;124;03m\"\"\"Compute the gradients of a batch of the training data (`samples_batch`).\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \n\u001b[1;32m    420\u001b[0m \u001b[38;5;124;03mIf measurements are taken in bases other than the reference basis,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;124;03m:rtype: list[torch.Tensor]\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;66;03m# Positive phase: learning signal driven by the data (and bases)\u001b[39;00m\n\u001b[0;32m--> 439\u001b[0m grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpositive_phase_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbases_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbases_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;66;03m# Negative phase: learning signal driven by the amplitude RBM of\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;66;03m# the NN state\u001b[39;00m\n\u001b[1;32m    443\u001b[0m vk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrbm_am\u001b[38;5;241m.\u001b[39mgibbs_steps(k, neg_batch)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/neural_state.py:382\u001b[0m, in \u001b[0;36mNeuralStateBase.positive_phase_gradients\u001b[0;34m(self, samples_batch, bases_batch)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpositive_phase_gradients\u001b[39m(\u001b[38;5;28mself\u001b[39m, samples_batch, bases_batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Computes the positive phase of the gradients of the parameters.\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \n\u001b[1;32m    374\u001b[0m \u001b[38;5;124;03m    :param samples_batch: The measurements\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;124;03m    :rtype: list[torch.Tensor]\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 382\u001b[0m     grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbases\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbases_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    383\u001b[0m     grad \u001b[38;5;241m=\u001b[39m [gr \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mfloat\u001b[39m(samples_batch\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m gr \u001b[38;5;129;01min\u001b[39;00m grad]\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m grad\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/neural_state.py:359\u001b[0m, in \u001b[0;36mNeuralStateBase.gradient\u001b[0;34m(self, samples, bases)\u001b[0m\n\u001b[1;32m    356\u001b[0m rot_sites \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(basis \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZ\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rot_sites\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 359\u001b[0m     sample_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrotated_gradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbasis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    361\u001b[0m     sample_grad \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    362\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrbm_am\u001b[38;5;241m.\u001b[39meffective_energy_gradient(samples[indices \u001b[38;5;241m==\u001b[39m i, :]),\n\u001b[1;32m    363\u001b[0m         \u001b[38;5;241m0.0\u001b[39m,\n\u001b[1;32m    364\u001b[0m     ]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/density_matrix.py:298\u001b[0m, in \u001b[0;36mDensityMatrix.rotated_gradient\u001b[0;34m(self, basis, sample)\u001b[0m\n\u001b[1;32m    293\u001b[0m UrhoU, UrhoU_v, v \u001b[38;5;241m=\u001b[39m unitaries\u001b[38;5;241m.\u001b[39mrotate_rho_probs(\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28mself\u001b[39m, basis, sample, include_extras\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    295\u001b[0m )\n\u001b[1;32m    296\u001b[0m inv_UrhoU \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m (UrhoU \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-8\u001b[39m)  \u001b[38;5;66;03m# avoid dividing by zero\u001b[39;00m\n\u001b[0;32m--> 298\u001b[0m raw_grads \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mam_grads(v), \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mph_grads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m    300\u001b[0m rotated_grad \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;241m-\u001b[39mcplx\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mijb,ijbg->bg\u001b[39m\u001b[38;5;124m\"\u001b[39m, UrhoU_v, g, imag_part\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m raw_grads\n\u001b[1;32m    302\u001b[0m ]\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [torch\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb,bg->g\u001b[39m\u001b[38;5;124m\"\u001b[39m, inv_UrhoU, g) \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m rotated_grad]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/density_matrix.py:330\u001b[0m, in \u001b[0;36mDensityMatrix.ph_grads\u001b[0;34m(self, v)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mph_grads\u001b[39m(\u001b[38;5;28mself\u001b[39m, v):\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Computes the gradients of the phase RBM for given input states\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \n\u001b[1;32m    322\u001b[0m \u001b[38;5;124;03m    :param v: The first input state, :math:`\\sigma`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;124;03m    :rtype: torch.Tensor\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cplx\u001b[38;5;241m.\u001b[39mscalar_mult(  \u001b[38;5;66;03m# need to multiply Gamma- by i\u001b[39;00m\n\u001b[1;32m    329\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrbm_ph\u001b[38;5;241m.\u001b[39mgamma_grad(v, v, eta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, expand\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), cplx\u001b[38;5;241m.\u001b[39mI\n\u001b[0;32m--> 330\u001b[0m     ) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpi_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/density_matrix.py:194\u001b[0m, in \u001b[0;36mDensityMatrix.pi_grad\u001b[0;34m(self, v, vp, phase, expand)\u001b[0m\n\u001b[1;32m    191\u001b[0m     arg_real \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrbm_am\u001b[38;5;241m.\u001b[39mmixing_term(v \u001b[38;5;241m+\u001b[39m vp)\n\u001b[1;32m    192\u001b[0m     arg_imag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrbm_ph\u001b[38;5;241m.\u001b[39mmixing_term(v \u001b[38;5;241m-\u001b[39m vp)\n\u001b[0;32m--> 194\u001b[0m sig \u001b[38;5;241m=\u001b[39m \u001b[43mcplx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_real\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg_imag\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    196\u001b[0m batch_sizes \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    197\u001b[0m     (v\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], vp\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39mv\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m expand \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;241m*\u001b[39mv\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],)\n\u001b[1;32m    198\u001b[0m )\n\u001b[1;32m    200\u001b[0m W_grad \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrbm_am\u001b[38;5;241m.\u001b[39mweights_W)\u001b[38;5;241m.\u001b[39mexpand(\u001b[38;5;241m*\u001b[39mbatch_sizes, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/qucumber/utils/cplx.py:331\u001b[0m, in \u001b[0;36msigmoid\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the sigmoid function of a complex number. Acts elementwise.\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \n\u001b[1;32m    322\u001b[0m \u001b[38;5;124;03m:param x: The real part of the complex number\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;124;03m:rtype: torch.Tensor\u001b[39;00m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    329\u001b[0m z \u001b[38;5;241m=\u001b[39m (x\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39mj \u001b[38;5;241m*\u001b[39m (y\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m--> 331\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([np\u001b[38;5;241m.\u001b[39mreal(out), np\u001b[38;5;241m.\u001b[39mimag(out)])\u001b[38;5;241m.\u001b[39mto(x)\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optuna.logging.get_logger(\"optuna\").addHandler(logging.StreamHandler(sys.stdout))\n",
    "study = optuna.create_study(pruner=optuna.pruners.MedianPruner())\n",
    "study.optimize(objective, n_trials=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692cbf2f-73bf-4083-a38d-c35e80122b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2f49de-d6fc-4d83-be19-0989fb55df12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best params\n",
    "params[\"train_info\"][\"lr\"] = study.best_params[\"lr\"]\n",
    "params[\"train_info\"][\"n_gibbs_step\"] = study.best_params[\"k\"]\n",
    "\n",
    "with open('./best_params_setting.yaml', 'w') as yml:\n",
    "    yaml.dump(params, yml, default_flow_style=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
