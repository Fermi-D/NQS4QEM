{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfd6da35-81e5-44b3-95c1-d30d0fc177c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import random\n",
    "import warnings\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "from tqdm.notebook import tqdm\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "from qucumber.nn_states import DensityMatrix\n",
    "from qucumber.nn_states import ComplexWaveFunction\n",
    "from qucumber.callbacks import MetricEvaluator\n",
    "import qucumber.utils.unitaries as unitaries\n",
    "import qucumber.utils.training_statistics as ts\n",
    "import qucumber.utils.cplx as cplx\n",
    "import qucumber.utils.data as data\n",
    "from qucumber.observables import ObservableBase, to_pm1\n",
    "from qucumber.observables.pauli import flip_spin\n",
    "import qucumber\n",
    "\n",
    "from qulacs.gate import Pauli\n",
    "\n",
    "import optuna\n",
    "\n",
    "with open('./params_setting.yaml', 'r') as yml:\n",
    "    params = yaml.safe_load(yml)\n",
    "    \n",
    "# quantum circuit parameter\n",
    "n_qubit = params[\"circuit_info\"][\"n_qubit\"]\n",
    "each_n_shot = params[\"circuit_info\"][\"each_n_shot\"]\n",
    "state_name = params[\"circuit_info\"][\"state_name\"]\n",
    "error_model = params[\"circuit_info\"][\"error_model\"]\n",
    "error_rate = params[\"circuit_info\"][\"error_rate\"]\n",
    "# RBM architecture parameter\n",
    "n_visible_unit = params[\"architecture_info\"][\"n_visible_unit\"]\n",
    "n_hidden_unit = params[\"architecture_info\"][\"n_hidden_unit\"] \n",
    "n_aux_unit = params[\"architecture_info\"][\"n_aux_unit\"]\n",
    "# train parameter\n",
    "lr = params[\"train_info\"][\"lr\"]\n",
    "pbs = params[\"train_info\"][\"positive_batch_size\"]\n",
    "nbs = params[\"train_info\"][\"negative_batch_size\"]\n",
    "n_gibbs_step = params[\"train_info\"][\"n_gibbs_step\"]\n",
    "period = 1\n",
    "epoch = params[\"train_info\"][\"n_epoch\"]\n",
    "lr_drop_epoch = params[\"train_info\"][\"lr_drop_epoch\"]\n",
    "lr_drop_factor = params[\"train_info\"][\"lr_drop_factor\"]\n",
    "seed = params[\"train_info\"][\"seed\"]\n",
    "# sampling parameter\n",
    "n_sampling = params[\"sampling_info\"][\"n_sample\"]\n",
    "n_copy = params[\"sampling_info\"][\"n_copy\"]\n",
    "# data path info\n",
    "train_data_path = f\"./data/{error_model}/error_prob_{100*error_rate}%/num_of_data_{each_n_shot}/\"\n",
    "ideal_state_path = f\"./target_state/\"\n",
    "\n",
    "# settings\n",
    "## warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "## seaborn layout\n",
    "sns.set()\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "## seed\n",
    "def seed_settings(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    qucumber.set_random_seed(seed, cpu=True, gpu=False)\n",
    "\n",
    "seed_settings(seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da0f212c-ba12-4c7c-ae2e-4795a0e50148",
   "metadata": {},
   "outputs": [],
   "source": [
    "meas_pattern_path = train_data_path + \"/measurement_pattern.txt\"\n",
    "meas_label_path = train_data_path + \"/measurement_label.txt\"\n",
    "meas_result_path = train_data_path + \"/measurement_result.txt\"\n",
    "ideal_rho_re_path = ideal_state_path + \"/rho_real.txt\"\n",
    "ideal_rho_im_path = ideal_state_path + \"/rho_imag.txt\"\n",
    "meas_result, ideal_rho, meas_label, meas_pattern = data.load_data_DM(meas_result_path,\n",
    "                                                                     ideal_rho_re_path,\n",
    "                                                                     ideal_rho_im_path,\n",
    "                                                                     meas_label_path,\n",
    "                                                                     meas_pattern_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b43214ba-75bd-4c68-84da-d896eb0d0868",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_state_dm = DensityMatrix(\n",
    "    num_visible = n_visible_unit, \n",
    "    num_hidden = n_hidden_unit, \n",
    "    num_aux = n_aux_unit, \n",
    "    unitary_dict = unitaries.create_dict(),\n",
    "    gpu = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8d8b377-3aa4-4227-9ca9-dfa48bcd98b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_callback_dm(nn_state):\n",
    "    metric_dict = {\n",
    "        \"Fidelity\": ts.fidelity,\n",
    "        \"KL_Divergence\": ts.KL,\n",
    "        #\"Observable_XXX_ev\": observable_XXX_ev,\n",
    "        #\"Observable_XZZ_ev\": observable_XZZ_ev,\n",
    "    }\n",
    "\n",
    "    space = nn_state.generate_hilbert_space()\n",
    "    callbacks = [\n",
    "        MetricEvaluator(\n",
    "            period,\n",
    "            metric_dict,\n",
    "            target = ideal_rho,\n",
    "            bases = meas_pattern,\n",
    "            verbose = True,\n",
    "            space = space,\n",
    "        )\n",
    "    ]\n",
    "    return callbacks\n",
    "\n",
    "callbacks = create_callback_dm(nn_state_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e40db9a-9fc8-40c3-a12c-4b79c308fd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # load dataset\n",
    "    meas_pattern_path = train_data_path + \"/measurement_pattern.txt\"\n",
    "    meas_label_path = train_data_path + \"/measurement_label.txt\"\n",
    "    meas_result_path = train_data_path + \"/measurement_result.txt\"\n",
    "    ideal_rho_re_path = ideal_state_path + \"/rho_real.txt\"\n",
    "    ideal_rho_im_path = ideal_state_path + \"/rho_imag.txt\"\n",
    "    meas_result, ideal_rho, meas_label, meas_pattern = data.load_data_DM(meas_result_path, ideal_rho_re_path, ideal_rho_im_path, meas_label_path, meas_pattern_path)\n",
    "    # search params\n",
    "    lr = trial.suggest_float(\"lr\", 5, 20, log=True)\n",
    "    #n_gibbs_step = trial.suggest_int(\"k\", 10, 5000, log=True)\n",
    "    pbs = trial.suggest_categorical(\"pbs\", [1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000])\n",
    "    nbs = trial.suggest_categorical(\"nbs\", [1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000])\n",
    "    \n",
    "    nn_state_dm.fit(data = meas_result,\n",
    "                            input_bases = meas_label,\n",
    "                            epochs = epoch,\n",
    "                            pos_batch_size = pbs,\n",
    "                            neg_batch_size = nbs,\n",
    "                            lr = lr,\n",
    "                            k = n_gibbs_step,\n",
    "                            bases = meas_pattern,\n",
    "                            callbacks = callbacks,\n",
    "                            time = True,\n",
    "                            optimizer = torch.optim.Adadelta,\n",
    "                            schexduler = torch.optim.lr_scheduler.StepLR,\n",
    "                            scheduler_args = {\"step_size\": lr_drop_epoch, \"gamma\": lr_drop_factor},\n",
    "                            )\n",
    "        \n",
    "    loss = callbacks[0][\"KL_Divergence\"][-1]\n",
    "    trial.report(loss, epoch)\n",
    "    if trial.should_prune():\n",
    "        raise optuna.TrialPruned()\n",
    "        \n",
    "    return callbacks[0][\"KL_Divergence\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d76d1e0-79f5-4f78-9cda-f24256a1ccce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 03:40:01,556] A new study created in memory with name: no-name-5940753c-5a61-4661-97c1-9a5f1e69ac4e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A new study created in memory with name: no-name-5940753c-5a61-4661-97c1-9a5f1e69ac4e\n",
      "Epoch: 1\tFidelity = 0.318301\tKL_Divergence = 0.541188\n",
      "Epoch: 2\tFidelity = 0.299754\tKL_Divergence = 0.519594\n",
      "Epoch: 3\tFidelity = 0.302634\tKL_Divergence = 0.497503\n",
      "Epoch: 4\tFidelity = 0.313960\tKL_Divergence = 0.473510\n",
      "Epoch: 5\tFidelity = 0.305669\tKL_Divergence = 0.451718\n",
      "Epoch: 6\tFidelity = 0.292351\tKL_Divergence = 0.434447\n",
      "Epoch: 7\tFidelity = 0.293377\tKL_Divergence = 0.416233\n",
      "Epoch: 8\tFidelity = 0.294965\tKL_Divergence = 0.399730\n",
      "Epoch: 9\tFidelity = 0.302871\tKL_Divergence = 0.384644\n",
      "Epoch: 10\tFidelity = 0.310355\tKL_Divergence = 0.366455\n",
      "Epoch: 11\tFidelity = 0.323802\tKL_Divergence = 0.348863\n",
      "Epoch: 12\tFidelity = 0.349900\tKL_Divergence = 0.326094\n",
      "Epoch: 13\tFidelity = 0.371227\tKL_Divergence = 0.304170\n",
      "Epoch: 14\tFidelity = 0.397929\tKL_Divergence = 0.279986\n",
      "Epoch: 15\tFidelity = 0.432628\tKL_Divergence = 0.251524\n",
      "Epoch: 16\tFidelity = 0.456764\tKL_Divergence = 0.233157\n",
      "Epoch: 17\tFidelity = 0.479364\tKL_Divergence = 0.224496\n",
      "Epoch: 18\tFidelity = 0.496530\tKL_Divergence = 0.196080\n",
      "Epoch: 19\tFidelity = 0.515274\tKL_Divergence = 0.181672\n",
      "Epoch: 20\tFidelity = 0.529567\tKL_Divergence = 0.177864\n",
      "Epoch: 21\tFidelity = 0.537745\tKL_Divergence = 0.186810\n",
      "Epoch: 22\tFidelity = 0.544458\tKL_Divergence = 0.197372\n",
      "Epoch: 23\tFidelity = 0.547825\tKL_Divergence = 0.201386\n",
      "Epoch: 24\tFidelity = 0.556665\tKL_Divergence = 0.203771\n",
      "Epoch: 25\tFidelity = 0.556899\tKL_Divergence = 0.207435\n",
      "Epoch: 26\tFidelity = 0.567327\tKL_Divergence = 0.190628\n",
      "Epoch: 27\tFidelity = 0.569068\tKL_Divergence = 0.182560\n",
      "Epoch: 28\tFidelity = 0.573348\tKL_Divergence = 0.213777\n",
      "Epoch: 29\tFidelity = 0.580289\tKL_Divergence = 0.160042\n",
      "Epoch: 30\tFidelity = 0.584089\tKL_Divergence = 0.199665\n",
      "Epoch: 31\tFidelity = 0.583384\tKL_Divergence = 0.185736\n",
      "Epoch: 32\tFidelity = 0.597152\tKL_Divergence = 0.167215\n",
      "Epoch: 33\tFidelity = 0.592845\tKL_Divergence = 0.181003\n",
      "Epoch: 34\tFidelity = 0.614406\tKL_Divergence = 0.130056\n",
      "Epoch: 35\tFidelity = 0.613824\tKL_Divergence = 0.142065\n",
      "Epoch: 36\tFidelity = 0.621828\tKL_Divergence = 0.158951\n",
      "Epoch: 37\tFidelity = 0.620453\tKL_Divergence = 0.152083\n",
      "Epoch: 38\tFidelity = 0.636316\tKL_Divergence = 0.136619\n",
      "Epoch: 39\tFidelity = 0.629630\tKL_Divergence = 0.149021\n",
      "Epoch: 40\tFidelity = 0.648368\tKL_Divergence = 0.127570\n",
      "Epoch: 41\tFidelity = 0.638109\tKL_Divergence = 0.157987\n",
      "Epoch: 42\tFidelity = 0.657614\tKL_Divergence = 0.130479\n",
      "Epoch: 43\tFidelity = 0.652186\tKL_Divergence = 0.138511\n",
      "Epoch: 44\tFidelity = 0.669777\tKL_Divergence = 0.115426\n",
      "Epoch: 45\tFidelity = 0.669290\tKL_Divergence = 0.115715\n",
      "Epoch: 46\tFidelity = 0.675500\tKL_Divergence = 0.140289\n",
      "Epoch: 47\tFidelity = 0.673533\tKL_Divergence = 0.125267\n",
      "Epoch: 48\tFidelity = 0.687550\tKL_Divergence = 0.117656\n",
      "Epoch: 49\tFidelity = 0.686576\tKL_Divergence = 0.107807\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 03:40:48,606] Trial 0 finished with value: 0.10645534226558982 and parameters: {'lr': 9.109756405618683, 'pbs': 3000, 'nbs': 6000}. Best is trial 0 with value: 0.10645534226558982.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.702269\tKL_Divergence = 0.106455\n",
      "Total time elapsed during training: 46.894 s\n",
      "Trial 0 finished with value: 0.10645534226558982 and parameters: {'lr': 9.109756405618683, 'pbs': 3000, 'nbs': 6000}. Best is trial 0 with value: 0.10645534226558982.\n",
      "Epoch: 1\tFidelity = 0.707015\tKL_Divergence = 0.082110\n",
      "Epoch: 2\tFidelity = 0.706724\tKL_Divergence = 0.084165\n",
      "Epoch: 3\tFidelity = 0.705035\tKL_Divergence = 0.085750\n",
      "Epoch: 4\tFidelity = 0.714354\tKL_Divergence = 0.085046\n",
      "Epoch: 5\tFidelity = 0.728563\tKL_Divergence = 0.073979\n",
      "Epoch: 6\tFidelity = 0.732551\tKL_Divergence = 0.076954\n",
      "Epoch: 7\tFidelity = 0.729026\tKL_Divergence = 0.076494\n",
      "Epoch: 8\tFidelity = 0.739942\tKL_Divergence = 0.070459\n",
      "Epoch: 9\tFidelity = 0.732223\tKL_Divergence = 0.086407\n",
      "Epoch: 10\tFidelity = 0.737509\tKL_Divergence = 0.072902\n",
      "Epoch: 11\tFidelity = 0.747676\tKL_Divergence = 0.068776\n",
      "Epoch: 12\tFidelity = 0.728746\tKL_Divergence = 0.085402\n",
      "Epoch: 13\tFidelity = 0.741638\tKL_Divergence = 0.084104\n",
      "Epoch: 14\tFidelity = 0.749864\tKL_Divergence = 0.069416\n",
      "Epoch: 15\tFidelity = 0.746171\tKL_Divergence = 0.072672\n",
      "Epoch: 16\tFidelity = 0.759201\tKL_Divergence = 0.066101\n",
      "Epoch: 17\tFidelity = 0.768123\tKL_Divergence = 0.062611\n",
      "Epoch: 18\tFidelity = 0.760736\tKL_Divergence = 0.070992\n",
      "Epoch: 19\tFidelity = 0.752999\tKL_Divergence = 0.072840\n",
      "Epoch: 20\tFidelity = 0.768938\tKL_Divergence = 0.066263\n",
      "Epoch: 21\tFidelity = 0.771959\tKL_Divergence = 0.063721\n",
      "Epoch: 22\tFidelity = 0.773180\tKL_Divergence = 0.063857\n",
      "Epoch: 23\tFidelity = 0.755509\tKL_Divergence = 0.074638\n",
      "Epoch: 24\tFidelity = 0.738516\tKL_Divergence = 0.085000\n",
      "Epoch: 25\tFidelity = 0.765006\tKL_Divergence = 0.072317\n",
      "Epoch: 26\tFidelity = 0.768558\tKL_Divergence = 0.071376\n",
      "Epoch: 27\tFidelity = 0.769654\tKL_Divergence = 0.071100\n",
      "Epoch: 28\tFidelity = 0.786486\tKL_Divergence = 0.063074\n",
      "Epoch: 29\tFidelity = 0.793770\tKL_Divergence = 0.062443\n",
      "Epoch: 30\tFidelity = 0.774578\tKL_Divergence = 0.076032\n",
      "Epoch: 31\tFidelity = 0.775230\tKL_Divergence = 0.069144\n",
      "Epoch: 32\tFidelity = 0.804164\tKL_Divergence = 0.056940\n",
      "Epoch: 33\tFidelity = 0.778811\tKL_Divergence = 0.087869\n",
      "Epoch: 34\tFidelity = 0.795320\tKL_Divergence = 0.075474\n",
      "Epoch: 35\tFidelity = 0.782213\tKL_Divergence = 0.069899\n",
      "Epoch: 36\tFidelity = 0.788374\tKL_Divergence = 0.088066\n",
      "Epoch: 37\tFidelity = 0.774788\tKL_Divergence = 0.079358\n",
      "Epoch: 38\tFidelity = 0.768931\tKL_Divergence = 0.082611\n",
      "Epoch: 39\tFidelity = 0.806382\tKL_Divergence = 0.055995\n",
      "Epoch: 40\tFidelity = 0.789591\tKL_Divergence = 0.068037\n",
      "Epoch: 41\tFidelity = 0.789990\tKL_Divergence = 0.079077\n",
      "Epoch: 42\tFidelity = 0.826871\tKL_Divergence = 0.047658\n",
      "Epoch: 43\tFidelity = 0.806855\tKL_Divergence = 0.058647\n",
      "Epoch: 44\tFidelity = 0.771883\tKL_Divergence = 0.084197\n",
      "Epoch: 45\tFidelity = 0.792168\tKL_Divergence = 0.069575\n",
      "Epoch: 46\tFidelity = 0.816469\tKL_Divergence = 0.059967\n",
      "Epoch: 47\tFidelity = 0.798075\tKL_Divergence = 0.078108\n",
      "Epoch: 48\tFidelity = 0.805974\tKL_Divergence = 0.065125\n",
      "Epoch: 49\tFidelity = 0.809495\tKL_Divergence = 0.077838\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 03:41:27,362] Trial 1 finished with value: 0.05588400346209574 and parameters: {'lr': 13.576484164193129, 'pbs': 8000, 'nbs': 1000}. Best is trial 1 with value: 0.05588400346209574.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.829786\tKL_Divergence = 0.055884\n",
      "Total time elapsed during training: 38.613 s\n",
      "Trial 1 finished with value: 0.05588400346209574 and parameters: {'lr': 13.576484164193129, 'pbs': 8000, 'nbs': 1000}. Best is trial 1 with value: 0.05588400346209574.\n",
      "Epoch: 1\tFidelity = 0.849141\tKL_Divergence = 0.038645\n",
      "Epoch: 2\tFidelity = 0.851165\tKL_Divergence = 0.038262\n",
      "Epoch: 3\tFidelity = 0.852527\tKL_Divergence = 0.037633\n",
      "Epoch: 4\tFidelity = 0.852647\tKL_Divergence = 0.038550\n",
      "Epoch: 5\tFidelity = 0.856281\tKL_Divergence = 0.036680\n",
      "Epoch: 6\tFidelity = 0.859100\tKL_Divergence = 0.035932\n",
      "Epoch: 7\tFidelity = 0.860723\tKL_Divergence = 0.038322\n",
      "Epoch: 8\tFidelity = 0.859622\tKL_Divergence = 0.037332\n",
      "Epoch: 9\tFidelity = 0.864622\tKL_Divergence = 0.035437\n",
      "Epoch: 10\tFidelity = 0.864822\tKL_Divergence = 0.034902\n",
      "Epoch: 11\tFidelity = 0.868249\tKL_Divergence = 0.033809\n",
      "Epoch: 12\tFidelity = 0.869833\tKL_Divergence = 0.034572\n",
      "Epoch: 13\tFidelity = 0.871350\tKL_Divergence = 0.032771\n",
      "Epoch: 14\tFidelity = 0.873600\tKL_Divergence = 0.032591\n",
      "Epoch: 15\tFidelity = 0.874606\tKL_Divergence = 0.033785\n",
      "Epoch: 16\tFidelity = 0.877250\tKL_Divergence = 0.031445\n",
      "Epoch: 17\tFidelity = 0.878128\tKL_Divergence = 0.030961\n",
      "Epoch: 18\tFidelity = 0.880489\tKL_Divergence = 0.030866\n",
      "Epoch: 19\tFidelity = 0.881466\tKL_Divergence = 0.032809\n",
      "Epoch: 20\tFidelity = 0.883467\tKL_Divergence = 0.031014\n",
      "Epoch: 21\tFidelity = 0.884295\tKL_Divergence = 0.029341\n",
      "Epoch: 22\tFidelity = 0.885518\tKL_Divergence = 0.029629\n",
      "Epoch: 23\tFidelity = 0.886359\tKL_Divergence = 0.029243\n",
      "Epoch: 24\tFidelity = 0.889161\tKL_Divergence = 0.029731\n",
      "Epoch: 25\tFidelity = 0.890413\tKL_Divergence = 0.027935\n",
      "Epoch: 26\tFidelity = 0.892056\tKL_Divergence = 0.027757\n",
      "Epoch: 27\tFidelity = 0.891972\tKL_Divergence = 0.027651\n",
      "Epoch: 28\tFidelity = 0.894078\tKL_Divergence = 0.026832\n",
      "Epoch: 29\tFidelity = 0.894287\tKL_Divergence = 0.027346\n",
      "Epoch: 30\tFidelity = 0.895407\tKL_Divergence = 0.026973\n",
      "Epoch: 31\tFidelity = 0.897568\tKL_Divergence = 0.028517\n",
      "Epoch: 32\tFidelity = 0.896775\tKL_Divergence = 0.027126\n",
      "Epoch: 33\tFidelity = 0.899717\tKL_Divergence = 0.025617\n",
      "Epoch: 34\tFidelity = 0.897350\tKL_Divergence = 0.027564\n",
      "Epoch: 35\tFidelity = 0.902008\tKL_Divergence = 0.024965\n",
      "Epoch: 36\tFidelity = 0.901858\tKL_Divergence = 0.025323\n",
      "Epoch: 37\tFidelity = 0.902921\tKL_Divergence = 0.025166\n",
      "Epoch: 38\tFidelity = 0.904753\tKL_Divergence = 0.024330\n",
      "Epoch: 39\tFidelity = 0.905551\tKL_Divergence = 0.024540\n",
      "Epoch: 40\tFidelity = 0.904777\tKL_Divergence = 0.025679\n",
      "Epoch: 41\tFidelity = 0.906508\tKL_Divergence = 0.025268\n",
      "Epoch: 42\tFidelity = 0.908989\tKL_Divergence = 0.023579\n",
      "Epoch: 43\tFidelity = 0.908542\tKL_Divergence = 0.023620\n",
      "Epoch: 44\tFidelity = 0.910883\tKL_Divergence = 0.024151\n",
      "Epoch: 45\tFidelity = 0.912221\tKL_Divergence = 0.022412\n",
      "Epoch: 46\tFidelity = 0.911904\tKL_Divergence = 0.023887\n",
      "Epoch: 47\tFidelity = 0.909743\tKL_Divergence = 0.025045\n",
      "Epoch: 48\tFidelity = 0.914655\tKL_Divergence = 0.022345\n",
      "Epoch: 49\tFidelity = 0.915235\tKL_Divergence = 0.021426\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 03:42:15,167] Trial 2 finished with value: 0.0220102079836446 and parameters: {'lr': 5.320245678391976, 'pbs': 3000, 'nbs': 10000}. Best is trial 2 with value: 0.0220102079836446.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.916247\tKL_Divergence = 0.022010\n",
      "Total time elapsed during training: 47.671 s\n",
      "Trial 2 finished with value: 0.0220102079836446 and parameters: {'lr': 5.320245678391976, 'pbs': 3000, 'nbs': 10000}. Best is trial 2 with value: 0.0220102079836446.\n",
      "Epoch: 1\tFidelity = 0.915921\tKL_Divergence = 0.022149\n",
      "Epoch: 2\tFidelity = 0.909412\tKL_Divergence = 0.038164\n",
      "Epoch: 3\tFidelity = 0.904242\tKL_Divergence = 0.030653\n",
      "Epoch: 4\tFidelity = 0.910694\tKL_Divergence = 0.039712\n",
      "Epoch: 5\tFidelity = 0.886953\tKL_Divergence = 0.056921\n",
      "Epoch: 6\tFidelity = 0.911159\tKL_Divergence = 0.039100\n",
      "Epoch: 7\tFidelity = 0.901218\tKL_Divergence = 0.037865\n",
      "Epoch: 8\tFidelity = 0.918697\tKL_Divergence = 0.024421\n",
      "Epoch: 9\tFidelity = 0.915056\tKL_Divergence = 0.033425\n",
      "Epoch: 10\tFidelity = 0.910538\tKL_Divergence = 0.046231\n",
      "Epoch: 11\tFidelity = 0.904623\tKL_Divergence = 0.048161\n",
      "Epoch: 12\tFidelity = 0.920249\tKL_Divergence = 0.034568\n",
      "Epoch: 13\tFidelity = 0.910694\tKL_Divergence = 0.038292\n",
      "Epoch: 14\tFidelity = 0.922708\tKL_Divergence = 0.033968\n",
      "Epoch: 15\tFidelity = 0.910015\tKL_Divergence = 0.036377\n",
      "Epoch: 16\tFidelity = 0.922340\tKL_Divergence = 0.035100\n",
      "Epoch: 17\tFidelity = 0.922261\tKL_Divergence = 0.029031\n",
      "Epoch: 18\tFidelity = 0.914775\tKL_Divergence = 0.036201\n",
      "Epoch: 19\tFidelity = 0.936157\tKL_Divergence = 0.017745\n",
      "Epoch: 20\tFidelity = 0.926089\tKL_Divergence = 0.029620\n",
      "Epoch: 21\tFidelity = 0.927569\tKL_Divergence = 0.026023\n",
      "Epoch: 22\tFidelity = 0.934040\tKL_Divergence = 0.020398\n",
      "Epoch: 23\tFidelity = 0.938429\tKL_Divergence = 0.017366\n",
      "Epoch: 24\tFidelity = 0.927538\tKL_Divergence = 0.026432\n",
      "Epoch: 25\tFidelity = 0.931904\tKL_Divergence = 0.025242\n",
      "Epoch: 26\tFidelity = 0.941072\tKL_Divergence = 0.019734\n",
      "Epoch: 27\tFidelity = 0.910226\tKL_Divergence = 0.059636\n",
      "Epoch: 28\tFidelity = 0.927502\tKL_Divergence = 0.030040\n",
      "Epoch: 29\tFidelity = 0.920362\tKL_Divergence = 0.045117\n",
      "Epoch: 30\tFidelity = 0.936419\tKL_Divergence = 0.021289\n",
      "Epoch: 31\tFidelity = 0.918145\tKL_Divergence = 0.037039\n",
      "Epoch: 32\tFidelity = 0.929436\tKL_Divergence = 0.030079\n",
      "Epoch: 33\tFidelity = 0.934783\tKL_Divergence = 0.027228\n",
      "Epoch: 34\tFidelity = 0.933327\tKL_Divergence = 0.027902\n",
      "Epoch: 35\tFidelity = 0.919283\tKL_Divergence = 0.046502\n",
      "Epoch: 36\tFidelity = 0.927555\tKL_Divergence = 0.028008\n",
      "Epoch: 37\tFidelity = 0.942597\tKL_Divergence = 0.019168\n",
      "Epoch: 38\tFidelity = 0.940853\tKL_Divergence = 0.020654\n",
      "Epoch: 39\tFidelity = 0.937058\tKL_Divergence = 0.027435\n",
      "Epoch: 40\tFidelity = 0.922884\tKL_Divergence = 0.045705\n",
      "Epoch: 41\tFidelity = 0.905430\tKL_Divergence = 0.045181\n",
      "Epoch: 42\tFidelity = 0.951444\tKL_Divergence = 0.014687\n",
      "Epoch: 43\tFidelity = 0.949729\tKL_Divergence = 0.015032\n",
      "Epoch: 44\tFidelity = 0.942726\tKL_Divergence = 0.029293\n",
      "Epoch: 45\tFidelity = 0.934563\tKL_Divergence = 0.034585\n",
      "Epoch: 46\tFidelity = 0.944921\tKL_Divergence = 0.022174\n",
      "Epoch: 47\tFidelity = 0.952694\tKL_Divergence = 0.013838\n",
      "Epoch: 48\tFidelity = 0.941253\tKL_Divergence = 0.025057\n",
      "Epoch: 49\tFidelity = 0.944151\tKL_Divergence = 0.023110\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 03:43:15,518] Trial 3 finished with value: 0.014932999638628435 and parameters: {'lr': 16.042848680152506, 'pbs': 2000, 'nbs': 8000}. Best is trial 3 with value: 0.014932999638628435.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.951370\tKL_Divergence = 0.014933\n",
      "Total time elapsed during training: 60.219 s\n",
      "Trial 3 finished with value: 0.014932999638628435 and parameters: {'lr': 16.042848680152506, 'pbs': 2000, 'nbs': 8000}. Best is trial 3 with value: 0.014932999638628435.\n",
      "Epoch: 1\tFidelity = 0.946956\tKL_Divergence = 0.020462\n",
      "Epoch: 2\tFidelity = 0.944425\tKL_Divergence = 0.021269\n",
      "Epoch: 3\tFidelity = 0.928566\tKL_Divergence = 0.032364\n",
      "Epoch: 4\tFidelity = 0.939553\tKL_Divergence = 0.030432\n",
      "Epoch: 5\tFidelity = 0.944487\tKL_Divergence = 0.024993\n",
      "Epoch: 6\tFidelity = 0.918804\tKL_Divergence = 0.060356\n",
      "Epoch: 7\tFidelity = 0.949415\tKL_Divergence = 0.019138\n",
      "Epoch: 8\tFidelity = 0.940286\tKL_Divergence = 0.022897\n",
      "Epoch: 9\tFidelity = 0.955180\tKL_Divergence = 0.013380\n",
      "Epoch: 10\tFidelity = 0.946350\tKL_Divergence = 0.028363\n",
      "Epoch: 11\tFidelity = 0.942787\tKL_Divergence = 0.033453\n",
      "Epoch: 12\tFidelity = 0.952891\tKL_Divergence = 0.017578\n",
      "Epoch: 13\tFidelity = 0.953718\tKL_Divergence = 0.014095\n",
      "Epoch: 14\tFidelity = 0.952574\tKL_Divergence = 0.015579\n",
      "Epoch: 15\tFidelity = 0.942402\tKL_Divergence = 0.026816\n",
      "Epoch: 16\tFidelity = 0.939149\tKL_Divergence = 0.032356\n",
      "Epoch: 17\tFidelity = 0.952749\tKL_Divergence = 0.014570\n",
      "Epoch: 18\tFidelity = 0.954065\tKL_Divergence = 0.016314\n",
      "Epoch: 19\tFidelity = 0.953712\tKL_Divergence = 0.017024\n",
      "Epoch: 20\tFidelity = 0.951029\tKL_Divergence = 0.016561\n",
      "Epoch: 21\tFidelity = 0.949244\tKL_Divergence = 0.017939\n",
      "Epoch: 22\tFidelity = 0.954045\tKL_Divergence = 0.014619\n",
      "Epoch: 23\tFidelity = 0.945058\tKL_Divergence = 0.023126\n",
      "Epoch: 24\tFidelity = 0.942233\tKL_Divergence = 0.033391\n",
      "Epoch: 25\tFidelity = 0.951804\tKL_Divergence = 0.019004\n",
      "Epoch: 26\tFidelity = 0.953727\tKL_Divergence = 0.014251\n",
      "Epoch: 27\tFidelity = 0.943177\tKL_Divergence = 0.021270\n",
      "Epoch: 28\tFidelity = 0.955446\tKL_Divergence = 0.014823\n",
      "Epoch: 29\tFidelity = 0.953579\tKL_Divergence = 0.016145\n",
      "Epoch: 30\tFidelity = 0.946194\tKL_Divergence = 0.029876\n",
      "Epoch: 31\tFidelity = 0.942660\tKL_Divergence = 0.024362\n",
      "Epoch: 32\tFidelity = 0.934455\tKL_Divergence = 0.033503\n",
      "Epoch: 33\tFidelity = 0.932034\tKL_Divergence = 0.038519\n",
      "Epoch: 34\tFidelity = 0.951704\tKL_Divergence = 0.017696\n",
      "Epoch: 35\tFidelity = 0.950606\tKL_Divergence = 0.018641\n",
      "Epoch: 36\tFidelity = 0.956151\tKL_Divergence = 0.012980\n",
      "Epoch: 37\tFidelity = 0.953763\tKL_Divergence = 0.014619\n",
      "Epoch: 38\tFidelity = 0.948731\tKL_Divergence = 0.021735\n",
      "Epoch: 39\tFidelity = 0.950440\tKL_Divergence = 0.017997\n",
      "Epoch: 40\tFidelity = 0.953835\tKL_Divergence = 0.015140\n",
      "Epoch: 41\tFidelity = 0.949196\tKL_Divergence = 0.020083\n",
      "Epoch: 42\tFidelity = 0.953309\tKL_Divergence = 0.014785\n",
      "Epoch: 43\tFidelity = 0.955041\tKL_Divergence = 0.013560\n",
      "Epoch: 44\tFidelity = 0.938654\tKL_Divergence = 0.034640\n",
      "Epoch: 45\tFidelity = 0.942264\tKL_Divergence = 0.028525\n",
      "Epoch: 46\tFidelity = 0.948010\tKL_Divergence = 0.021621\n",
      "Epoch: 47\tFidelity = 0.955459\tKL_Divergence = 0.013463\n",
      "Epoch: 48\tFidelity = 0.949851\tKL_Divergence = 0.017293\n",
      "Epoch: 49\tFidelity = 0.955469\tKL_Divergence = 0.013670\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 03:43:53,951] Trial 4 finished with value: 0.018562210329134778 and parameters: {'lr': 12.100420139019096, 'pbs': 8000, 'nbs': 10000}. Best is trial 3 with value: 0.014932999638628435.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.947984\tKL_Divergence = 0.018562\n",
      "Total time elapsed during training: 38.301 s\n",
      "Trial 4 finished with value: 0.018562210329134778 and parameters: {'lr': 12.100420139019096, 'pbs': 8000, 'nbs': 10000}. Best is trial 3 with value: 0.014932999638628435.\n",
      "Epoch: 1\tFidelity = 0.954451\tKL_Divergence = 0.015390\n",
      "Epoch: 2\tFidelity = 0.950463\tKL_Divergence = 0.025433\n",
      "Epoch: 3\tFidelity = 0.957401\tKL_Divergence = 0.012667\n",
      "Epoch: 4\tFidelity = 0.956127\tKL_Divergence = 0.016228\n",
      "Epoch: 5\tFidelity = 0.955618\tKL_Divergence = 0.013704\n",
      "Epoch: 6\tFidelity = 0.957890\tKL_Divergence = 0.012488\n",
      "Epoch: 7\tFidelity = 0.954220\tKL_Divergence = 0.016433\n",
      "Epoch: 8\tFidelity = 0.957117\tKL_Divergence = 0.013215\n",
      "Epoch: 9\tFidelity = 0.952043\tKL_Divergence = 0.018669\n",
      "Epoch: 10\tFidelity = 0.954090\tKL_Divergence = 0.019142\n",
      "Epoch: 11\tFidelity = 0.952502\tKL_Divergence = 0.018010\n",
      "Epoch: 12\tFidelity = 0.954088\tKL_Divergence = 0.019799\n",
      "Epoch: 13\tFidelity = 0.950518\tKL_Divergence = 0.021006\n",
      "Epoch: 14\tFidelity = 0.950830\tKL_Divergence = 0.024124\n",
      "Epoch: 15\tFidelity = 0.958045\tKL_Divergence = 0.012262\n",
      "Epoch: 16\tFidelity = 0.951606\tKL_Divergence = 0.019183\n",
      "Epoch: 17\tFidelity = 0.955067\tKL_Divergence = 0.018986\n",
      "Epoch: 18\tFidelity = 0.958980\tKL_Divergence = 0.012181\n",
      "Epoch: 19\tFidelity = 0.957844\tKL_Divergence = 0.013656\n",
      "Epoch: 20\tFidelity = 0.952878\tKL_Divergence = 0.018223\n",
      "Epoch: 21\tFidelity = 0.955220\tKL_Divergence = 0.018312\n",
      "Epoch: 22\tFidelity = 0.948228\tKL_Divergence = 0.024459\n",
      "Epoch: 23\tFidelity = 0.958426\tKL_Divergence = 0.012137\n",
      "Epoch: 24\tFidelity = 0.952724\tKL_Divergence = 0.017931\n",
      "Epoch: 25\tFidelity = 0.955290\tKL_Divergence = 0.018582\n",
      "Epoch: 26\tFidelity = 0.957572\tKL_Divergence = 0.013919\n",
      "Epoch: 27\tFidelity = 0.946903\tKL_Divergence = 0.033121\n",
      "Epoch: 28\tFidelity = 0.954860\tKL_Divergence = 0.017285\n",
      "Epoch: 29\tFidelity = 0.952572\tKL_Divergence = 0.024717\n",
      "Epoch: 30\tFidelity = 0.957820\tKL_Divergence = 0.014623\n",
      "Epoch: 31\tFidelity = 0.956222\tKL_Divergence = 0.019304\n",
      "Epoch: 32\tFidelity = 0.954285\tKL_Divergence = 0.018092\n",
      "Epoch: 33\tFidelity = 0.957445\tKL_Divergence = 0.017243\n",
      "Epoch: 34\tFidelity = 0.956120\tKL_Divergence = 0.014678\n",
      "Epoch: 35\tFidelity = 0.960564\tKL_Divergence = 0.011962\n",
      "Epoch: 36\tFidelity = 0.959160\tKL_Divergence = 0.014149\n",
      "Epoch: 37\tFidelity = 0.959246\tKL_Divergence = 0.013071\n",
      "Epoch: 38\tFidelity = 0.958883\tKL_Divergence = 0.013542\n",
      "Epoch: 39\tFidelity = 0.957968\tKL_Divergence = 0.014654\n",
      "Epoch: 40\tFidelity = 0.958996\tKL_Divergence = 0.013103\n",
      "Epoch: 41\tFidelity = 0.960707\tKL_Divergence = 0.011636\n",
      "Epoch: 42\tFidelity = 0.959028\tKL_Divergence = 0.012955\n",
      "Epoch: 43\tFidelity = 0.959860\tKL_Divergence = 0.014322\n",
      "Epoch: 44\tFidelity = 0.956931\tKL_Divergence = 0.015793\n",
      "Epoch: 45\tFidelity = 0.956065\tKL_Divergence = 0.016052\n",
      "Epoch: 46\tFidelity = 0.961417\tKL_Divergence = 0.011414\n",
      "Epoch: 47\tFidelity = 0.961335\tKL_Divergence = 0.011829\n",
      "Epoch: 48\tFidelity = 0.957022\tKL_Divergence = 0.016580\n",
      "Epoch: 49\tFidelity = 0.960244\tKL_Divergence = 0.012518\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 03:44:39,808] Trial 5 finished with value: 0.01268135823966654 and parameters: {'lr': 8.257942705693148, 'pbs': 3000, 'nbs': 6000}. Best is trial 5 with value: 0.01268135823966654.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.961129\tKL_Divergence = 0.012681\n",
      "Total time elapsed during training: 45.711 s\n",
      "Trial 5 finished with value: 0.01268135823966654 and parameters: {'lr': 8.257942705693148, 'pbs': 3000, 'nbs': 6000}. Best is trial 5 with value: 0.01268135823966654.\n",
      "Epoch: 1\tFidelity = 0.960953\tKL_Divergence = 0.011816\n",
      "Epoch: 2\tFidelity = 0.960125\tKL_Divergence = 0.014288\n",
      "Epoch: 3\tFidelity = 0.960143\tKL_Divergence = 0.012554\n",
      "Epoch: 4\tFidelity = 0.960477\tKL_Divergence = 0.012118\n",
      "Epoch: 5\tFidelity = 0.960975\tKL_Divergence = 0.012887\n",
      "Epoch: 6\tFidelity = 0.960117\tKL_Divergence = 0.014313\n",
      "Epoch: 7\tFidelity = 0.961154\tKL_Divergence = 0.012702\n",
      "Epoch: 8\tFidelity = 0.960415\tKL_Divergence = 0.012227\n",
      "Epoch: 9\tFidelity = 0.958671\tKL_Divergence = 0.017018\n",
      "Epoch: 10\tFidelity = 0.960063\tKL_Divergence = 0.012559\n",
      "Epoch: 11\tFidelity = 0.960568\tKL_Divergence = 0.013632\n",
      "Epoch: 12\tFidelity = 0.959467\tKL_Divergence = 0.012943\n",
      "Epoch: 13\tFidelity = 0.960004\tKL_Divergence = 0.014537\n",
      "Epoch: 14\tFidelity = 0.959824\tKL_Divergence = 0.012778\n",
      "Epoch: 15\tFidelity = 0.960228\tKL_Divergence = 0.014346\n",
      "Epoch: 16\tFidelity = 0.957336\tKL_Divergence = 0.015683\n",
      "Epoch: 17\tFidelity = 0.960992\tKL_Divergence = 0.013114\n",
      "Epoch: 18\tFidelity = 0.959980\tKL_Divergence = 0.012672\n",
      "Epoch: 19\tFidelity = 0.961437\tKL_Divergence = 0.011998\n",
      "Epoch: 20\tFidelity = 0.960659\tKL_Divergence = 0.012863\n",
      "Epoch: 21\tFidelity = 0.958177\tKL_Divergence = 0.014831\n",
      "Epoch: 22\tFidelity = 0.959365\tKL_Divergence = 0.014762\n",
      "Epoch: 23\tFidelity = 0.957937\tKL_Divergence = 0.014823\n",
      "Epoch: 24\tFidelity = 0.959873\tKL_Divergence = 0.013434\n",
      "Epoch: 25\tFidelity = 0.957763\tKL_Divergence = 0.015087\n",
      "Epoch: 26\tFidelity = 0.958012\tKL_Divergence = 0.016586\n",
      "Epoch: 27\tFidelity = 0.960549\tKL_Divergence = 0.012190\n",
      "Epoch: 28\tFidelity = 0.959941\tKL_Divergence = 0.012590\n",
      "Epoch: 29\tFidelity = 0.960799\tKL_Divergence = 0.012076\n",
      "Epoch: 30\tFidelity = 0.960114\tKL_Divergence = 0.012506\n",
      "Epoch: 31\tFidelity = 0.959440\tKL_Divergence = 0.013318\n",
      "Epoch: 32\tFidelity = 0.956007\tKL_Divergence = 0.020157\n",
      "Epoch: 33\tFidelity = 0.958238\tKL_Divergence = 0.014440\n",
      "Epoch: 34\tFidelity = 0.956938\tKL_Divergence = 0.018015\n",
      "Epoch: 35\tFidelity = 0.958746\tKL_Divergence = 0.013713\n",
      "Epoch: 36\tFidelity = 0.958831\tKL_Divergence = 0.014795\n",
      "Epoch: 37\tFidelity = 0.958515\tKL_Divergence = 0.014210\n",
      "Epoch: 38\tFidelity = 0.957775\tKL_Divergence = 0.016729\n",
      "Epoch: 39\tFidelity = 0.957629\tKL_Divergence = 0.015103\n",
      "Epoch: 40\tFidelity = 0.959419\tKL_Divergence = 0.013074\n",
      "Epoch: 41\tFidelity = 0.960423\tKL_Divergence = 0.012614\n",
      "Epoch: 42\tFidelity = 0.959731\tKL_Divergence = 0.013438\n",
      "Epoch: 43\tFidelity = 0.960767\tKL_Divergence = 0.012680\n",
      "Epoch: 44\tFidelity = 0.960067\tKL_Divergence = 0.012886\n",
      "Epoch: 45\tFidelity = 0.961223\tKL_Divergence = 0.012225\n",
      "Epoch: 46\tFidelity = 0.960289\tKL_Divergence = 0.012678\n",
      "Epoch: 47\tFidelity = 0.961260\tKL_Divergence = 0.012772\n",
      "Epoch: 48\tFidelity = 0.959717\tKL_Divergence = 0.013227\n",
      "Epoch: 49\tFidelity = 0.959409\tKL_Divergence = 0.016185\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 03:45:12,106] Trial 6 finished with value: 0.014742561277996336 and parameters: {'lr': 6.073651064320807, 'pbs': 10000, 'nbs': 8000}. Best is trial 5 with value: 0.01268135823966654.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.958140\tKL_Divergence = 0.014743\n",
      "Total time elapsed during training: 32.162 s\n",
      "Trial 6 finished with value: 0.014742561277996336 and parameters: {'lr': 6.073651064320807, 'pbs': 10000, 'nbs': 8000}. Best is trial 5 with value: 0.01268135823966654.\n",
      "Epoch: 1\tFidelity = 0.955449\tKL_Divergence = 0.021279\n",
      "Epoch: 2\tFidelity = 0.953173\tKL_Divergence = 0.019461\n",
      "Epoch: 3\tFidelity = 0.953066\tKL_Divergence = 0.024366\n",
      "Epoch: 4\tFidelity = 0.951839\tKL_Divergence = 0.020768\n",
      "Epoch: 5\tFidelity = 0.952819\tKL_Divergence = 0.024136\n",
      "Epoch: 6\tFidelity = 0.951740\tKL_Divergence = 0.020567\n",
      "Epoch: 7\tFidelity = 0.957398\tKL_Divergence = 0.015922\n",
      "Epoch: 8\tFidelity = 0.955185\tKL_Divergence = 0.016476\n",
      "Epoch: 9\tFidelity = 0.950127\tKL_Divergence = 0.027512\n",
      "Epoch: 10\tFidelity = 0.948942\tKL_Divergence = 0.023179\n",
      "Epoch: 11\tFidelity = 0.947527\tKL_Divergence = 0.030126\n",
      "Epoch: 12\tFidelity = 0.948201\tKL_Divergence = 0.022836\n",
      "Epoch: 13\tFidelity = 0.950584\tKL_Divergence = 0.023494\n",
      "Epoch: 14\tFidelity = 0.946159\tKL_Divergence = 0.024489\n",
      "Epoch: 15\tFidelity = 0.942300\tKL_Divergence = 0.034998\n",
      "Epoch: 16\tFidelity = 0.938358\tKL_Divergence = 0.032983\n",
      "Epoch: 17\tFidelity = 0.943626\tKL_Divergence = 0.030268\n",
      "Epoch: 18\tFidelity = 0.937425\tKL_Divergence = 0.032533\n",
      "Epoch: 19\tFidelity = 0.930440\tKL_Divergence = 0.048305\n",
      "Epoch: 20\tFidelity = 0.929973\tKL_Divergence = 0.040334\n",
      "Epoch: 21\tFidelity = 0.938518\tKL_Divergence = 0.032930\n",
      "Epoch: 22\tFidelity = 0.934476\tKL_Divergence = 0.032499\n",
      "Epoch: 23\tFidelity = 0.938886\tKL_Divergence = 0.029094\n",
      "Epoch: 24\tFidelity = 0.932524\tKL_Divergence = 0.032805\n",
      "Epoch: 25\tFidelity = 0.935213\tKL_Divergence = 0.030688\n",
      "Epoch: 26\tFidelity = 0.929988\tKL_Divergence = 0.033819\n",
      "Epoch: 27\tFidelity = 0.930071\tKL_Divergence = 0.034897\n",
      "Epoch: 28\tFidelity = 0.924342\tKL_Divergence = 0.037961\n",
      "Epoch: 29\tFidelity = 0.922748\tKL_Divergence = 0.042836\n",
      "Epoch: 30\tFidelity = 0.920176\tKL_Divergence = 0.041116\n",
      "Epoch: 31\tFidelity = 0.916419\tKL_Divergence = 0.050164\n",
      "Epoch: 32\tFidelity = 0.911712\tKL_Divergence = 0.051108\n",
      "Epoch: 33\tFidelity = 0.919574\tKL_Divergence = 0.046347\n",
      "Epoch: 34\tFidelity = 0.911036\tKL_Divergence = 0.053292\n",
      "Epoch: 35\tFidelity = 0.924301\tKL_Divergence = 0.041770\n",
      "Epoch: 36\tFidelity = 0.924954\tKL_Divergence = 0.038583\n",
      "Epoch: 37\tFidelity = 0.930118\tKL_Divergence = 0.034761\n",
      "Epoch: 38\tFidelity = 0.929706\tKL_Divergence = 0.035215\n",
      "Epoch: 39\tFidelity = 0.934700\tKL_Divergence = 0.032679\n",
      "Epoch: 40\tFidelity = 0.932407\tKL_Divergence = 0.034963\n",
      "Epoch: 41\tFidelity = 0.942643\tKL_Divergence = 0.026058\n",
      "Epoch: 42\tFidelity = 0.945819\tKL_Divergence = 0.024029\n",
      "Epoch: 43\tFidelity = 0.951572\tKL_Divergence = 0.020032\n",
      "Epoch: 44\tFidelity = 0.954446\tKL_Divergence = 0.021137\n",
      "Epoch: 45\tFidelity = 0.959219\tKL_Divergence = 0.015834\n",
      "Epoch: 46\tFidelity = 0.963452\tKL_Divergence = 0.012151\n",
      "Epoch: 47\tFidelity = 0.962423\tKL_Divergence = 0.013294\n",
      "Epoch: 48\tFidelity = 0.963324\tKL_Divergence = 0.014174\n",
      "Epoch: 49\tFidelity = 0.959218\tKL_Divergence = 0.017331\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 03:45:44,182] Trial 7 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.957215\tKL_Divergence = 0.023720\n",
      "Total time elapsed during training: 31.938 s\n",
      "Trial 7 pruned. \n",
      "Epoch: 1\tFidelity = 0.963934\tKL_Divergence = 0.012782\n",
      "Epoch: 2\tFidelity = 0.964076\tKL_Divergence = 0.012133\n",
      "Epoch: 3\tFidelity = 0.963140\tKL_Divergence = 0.012210\n",
      "Epoch: 4\tFidelity = 0.962189\tKL_Divergence = 0.012953\n",
      "Epoch: 5\tFidelity = 0.964253\tKL_Divergence = 0.011301\n",
      "Epoch: 6\tFidelity = 0.961122\tKL_Divergence = 0.014596\n",
      "Epoch: 7\tFidelity = 0.958644\tKL_Divergence = 0.017567\n",
      "Epoch: 8\tFidelity = 0.962476\tKL_Divergence = 0.012628\n",
      "Epoch: 9\tFidelity = 0.963789\tKL_Divergence = 0.011889\n",
      "Epoch: 10\tFidelity = 0.963421\tKL_Divergence = 0.012194\n",
      "Epoch: 11\tFidelity = 0.963907\tKL_Divergence = 0.011673\n",
      "Epoch: 12\tFidelity = 0.963403\tKL_Divergence = 0.011873\n",
      "Epoch: 13\tFidelity = 0.958343\tKL_Divergence = 0.020734\n",
      "Epoch: 14\tFidelity = 0.961709\tKL_Divergence = 0.014862\n",
      "Epoch: 15\tFidelity = 0.963302\tKL_Divergence = 0.011512\n",
      "Epoch: 16\tFidelity = 0.962281\tKL_Divergence = 0.012860\n",
      "Epoch: 17\tFidelity = 0.961100\tKL_Divergence = 0.013289\n",
      "Epoch: 18\tFidelity = 0.960517\tKL_Divergence = 0.013874\n",
      "Epoch: 19\tFidelity = 0.962584\tKL_Divergence = 0.012051\n",
      "Epoch: 20\tFidelity = 0.962104\tKL_Divergence = 0.013448\n",
      "Epoch: 21\tFidelity = 0.962786\tKL_Divergence = 0.013122\n",
      "Epoch: 22\tFidelity = 0.962140\tKL_Divergence = 0.013722\n",
      "Epoch: 23\tFidelity = 0.962754\tKL_Divergence = 0.013217\n",
      "Epoch: 24\tFidelity = 0.962689\tKL_Divergence = 0.012238\n",
      "Epoch: 25\tFidelity = 0.960788\tKL_Divergence = 0.014065\n",
      "Epoch: 26\tFidelity = 0.962207\tKL_Divergence = 0.012454\n",
      "Epoch: 27\tFidelity = 0.959948\tKL_Divergence = 0.015001\n",
      "Epoch: 28\tFidelity = 0.962121\tKL_Divergence = 0.012690\n",
      "Epoch: 29\tFidelity = 0.962098\tKL_Divergence = 0.013556\n",
      "Epoch: 30\tFidelity = 0.962079\tKL_Divergence = 0.012610\n",
      "Epoch: 31\tFidelity = 0.960881\tKL_Divergence = 0.013524\n",
      "Epoch: 32\tFidelity = 0.960181\tKL_Divergence = 0.014025\n",
      "Epoch: 33\tFidelity = 0.962178\tKL_Divergence = 0.012282\n",
      "Epoch: 34\tFidelity = 0.961412\tKL_Divergence = 0.012993\n",
      "Epoch: 35\tFidelity = 0.960430\tKL_Divergence = 0.015191\n",
      "Epoch: 36\tFidelity = 0.958216\tKL_Divergence = 0.018244\n",
      "Epoch: 37\tFidelity = 0.961117\tKL_Divergence = 0.012844\n",
      "Epoch: 38\tFidelity = 0.959330\tKL_Divergence = 0.015434\n",
      "Epoch: 39\tFidelity = 0.960454\tKL_Divergence = 0.013023\n",
      "Epoch: 40\tFidelity = 0.959593\tKL_Divergence = 0.013843\n",
      "Epoch: 41\tFidelity = 0.958547\tKL_Divergence = 0.014640\n",
      "Epoch: 42\tFidelity = 0.958927\tKL_Divergence = 0.014022\n",
      "Epoch: 43\tFidelity = 0.957854\tKL_Divergence = 0.015023\n",
      "Epoch: 44\tFidelity = 0.958132\tKL_Divergence = 0.014520\n",
      "Epoch: 45\tFidelity = 0.959381\tKL_Divergence = 0.014770\n",
      "Epoch: 46\tFidelity = 0.957654\tKL_Divergence = 0.016596\n",
      "Epoch: 47\tFidelity = 0.958829\tKL_Divergence = 0.015429\n",
      "Epoch: 48\tFidelity = 0.956860\tKL_Divergence = 0.017933\n",
      "Epoch: 49\tFidelity = 0.958789\tKL_Divergence = 0.014664\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 03:46:16,947] Trial 8 finished with value: 0.017096836848177123 and parameters: {'lr': 6.72761010262244, 'pbs': 10000, 'nbs': 1000}. Best is trial 5 with value: 0.01268135823966654.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.957106\tKL_Divergence = 0.017097\n",
      "Total time elapsed during training: 32.615 s\n",
      "Trial 8 finished with value: 0.017096836848177123 and parameters: {'lr': 6.72761010262244, 'pbs': 10000, 'nbs': 1000}. Best is trial 5 with value: 0.01268135823966654.\n",
      "Epoch: 1\tFidelity = 0.963585\tKL_Divergence = 0.011388\n",
      "Epoch: 2\tFidelity = 0.962414\tKL_Divergence = 0.012164\n",
      "Epoch: 3\tFidelity = 0.962060\tKL_Divergence = 0.012254\n",
      "Epoch: 4\tFidelity = 0.961269\tKL_Divergence = 0.012983\n",
      "Epoch: 5\tFidelity = 0.960893\tKL_Divergence = 0.013703\n",
      "Epoch: 6\tFidelity = 0.957350\tKL_Divergence = 0.017570\n",
      "Epoch: 7\tFidelity = 0.959516\tKL_Divergence = 0.014826\n",
      "Epoch: 8\tFidelity = 0.959754\tKL_Divergence = 0.015087\n",
      "Epoch: 9\tFidelity = 0.959888\tKL_Divergence = 0.014374\n",
      "Epoch: 10\tFidelity = 0.962868\tKL_Divergence = 0.012174\n",
      "Epoch: 11\tFidelity = 0.955413\tKL_Divergence = 0.019610\n",
      "Epoch: 12\tFidelity = 0.961030\tKL_Divergence = 0.013246\n",
      "Epoch: 13\tFidelity = 0.960975\tKL_Divergence = 0.014593\n",
      "Epoch: 14\tFidelity = 0.960984\tKL_Divergence = 0.013020\n",
      "Epoch: 15\tFidelity = 0.961788\tKL_Divergence = 0.012660\n",
      "Epoch: 16\tFidelity = 0.959085\tKL_Divergence = 0.014932\n",
      "Epoch: 17\tFidelity = 0.955798\tKL_Divergence = 0.022161\n",
      "Epoch: 18\tFidelity = 0.961817\tKL_Divergence = 0.013394\n",
      "Epoch: 19\tFidelity = 0.962478\tKL_Divergence = 0.011999\n",
      "Epoch: 20\tFidelity = 0.963120\tKL_Divergence = 0.013384\n",
      "Epoch: 21\tFidelity = 0.962523\tKL_Divergence = 0.012098\n",
      "Epoch: 22\tFidelity = 0.963391\tKL_Divergence = 0.011886\n",
      "Epoch: 23\tFidelity = 0.962208\tKL_Divergence = 0.012661\n",
      "Epoch: 24\tFidelity = 0.963586\tKL_Divergence = 0.011663\n",
      "Epoch: 25\tFidelity = 0.963297\tKL_Divergence = 0.011682\n",
      "Epoch: 26\tFidelity = 0.959316\tKL_Divergence = 0.014918\n",
      "Epoch: 27\tFidelity = 0.958123\tKL_Divergence = 0.020952\n",
      "Epoch: 28\tFidelity = 0.961810\tKL_Divergence = 0.014693\n",
      "Epoch: 29\tFidelity = 0.960063\tKL_Divergence = 0.017603\n",
      "Epoch: 30\tFidelity = 0.960927\tKL_Divergence = 0.014849\n",
      "Epoch: 31\tFidelity = 0.961618\tKL_Divergence = 0.015427\n",
      "Epoch: 32\tFidelity = 0.963631\tKL_Divergence = 0.011423\n",
      "Epoch: 33\tFidelity = 0.960238\tKL_Divergence = 0.017428\n",
      "Epoch: 34\tFidelity = 0.963274\tKL_Divergence = 0.012440\n",
      "Epoch: 35\tFidelity = 0.960789\tKL_Divergence = 0.013966\n",
      "Epoch: 36\tFidelity = 0.962171\tKL_Divergence = 0.012322\n",
      "Epoch: 37\tFidelity = 0.960954\tKL_Divergence = 0.014412\n",
      "Epoch: 38\tFidelity = 0.962393\tKL_Divergence = 0.012350\n",
      "Epoch: 39\tFidelity = 0.963908\tKL_Divergence = 0.011380\n",
      "Epoch: 40\tFidelity = 0.962766\tKL_Divergence = 0.013650\n",
      "Epoch: 41\tFidelity = 0.963292\tKL_Divergence = 0.013698\n",
      "Epoch: 42\tFidelity = 0.959840\tKL_Divergence = 0.014095\n",
      "Epoch: 43\tFidelity = 0.963849\tKL_Divergence = 0.011772\n",
      "Epoch: 44\tFidelity = 0.964800\tKL_Divergence = 0.011360\n",
      "Epoch: 45\tFidelity = 0.962550\tKL_Divergence = 0.014747\n",
      "Epoch: 46\tFidelity = 0.961420\tKL_Divergence = 0.014096\n",
      "Epoch: 47\tFidelity = 0.961809\tKL_Divergence = 0.013611\n",
      "Epoch: 48\tFidelity = 0.964743\tKL_Divergence = 0.011567\n",
      "Epoch: 49\tFidelity = 0.954693\tKL_Divergence = 0.023145\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 03:47:40,701] Trial 9 finished with value: 0.012536208046453043 and parameters: {'lr': 7.226803134315976, 'pbs': 1000, 'nbs': 3000}. Best is trial 9 with value: 0.012536208046453043.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.963559\tKL_Divergence = 0.012536\n",
      "Total time elapsed during training: 83.619 s\n",
      "Trial 9 finished with value: 0.012536208046453043 and parameters: {'lr': 7.226803134315976, 'pbs': 1000, 'nbs': 3000}. Best is trial 9 with value: 0.012536208046453043.\n",
      "Epoch: 1\tFidelity = 0.963753\tKL_Divergence = 0.012668\n",
      "Epoch: 2\tFidelity = 0.964364\tKL_Divergence = 0.011740\n",
      "Epoch: 3\tFidelity = 0.961929\tKL_Divergence = 0.013213\n",
      "Epoch: 4\tFidelity = 0.961114\tKL_Divergence = 0.014018\n",
      "Epoch: 5\tFidelity = 0.959069\tKL_Divergence = 0.015226\n",
      "Epoch: 6\tFidelity = 0.959265\tKL_Divergence = 0.015841\n",
      "Epoch: 7\tFidelity = 0.958903\tKL_Divergence = 0.015775\n",
      "Epoch: 8\tFidelity = 0.959837\tKL_Divergence = 0.015857\n",
      "Epoch: 9\tFidelity = 0.961905\tKL_Divergence = 0.014009\n",
      "Epoch: 10\tFidelity = 0.963905\tKL_Divergence = 0.012447\n",
      "Epoch: 11\tFidelity = 0.963656\tKL_Divergence = 0.014503\n",
      "Epoch: 12\tFidelity = 0.964276\tKL_Divergence = 0.012987\n",
      "Epoch: 13\tFidelity = 0.964323\tKL_Divergence = 0.013706\n",
      "Epoch: 14\tFidelity = 0.963244\tKL_Divergence = 0.013078\n",
      "Epoch: 15\tFidelity = 0.961308\tKL_Divergence = 0.015951\n",
      "Epoch: 16\tFidelity = 0.962360\tKL_Divergence = 0.014271\n",
      "Epoch: 17\tFidelity = 0.961570\tKL_Divergence = 0.017068\n",
      "Epoch: 18\tFidelity = 0.962830\tKL_Divergence = 0.013140\n",
      "Epoch: 19\tFidelity = 0.961720\tKL_Divergence = 0.015046\n",
      "Epoch: 20\tFidelity = 0.965214\tKL_Divergence = 0.011587\n",
      "Epoch: 21\tFidelity = 0.959488\tKL_Divergence = 0.017234\n",
      "Epoch: 22\tFidelity = 0.964785\tKL_Divergence = 0.011780\n",
      "Epoch: 23\tFidelity = 0.965605\tKL_Divergence = 0.011240\n",
      "Epoch: 24\tFidelity = 0.965388\tKL_Divergence = 0.011367\n",
      "Epoch: 25\tFidelity = 0.964224\tKL_Divergence = 0.014357\n",
      "Epoch: 26\tFidelity = 0.963173\tKL_Divergence = 0.012764\n",
      "Epoch: 27\tFidelity = 0.964168\tKL_Divergence = 0.012586\n",
      "Epoch: 28\tFidelity = 0.965336\tKL_Divergence = 0.011568\n",
      "Epoch: 29\tFidelity = 0.965605\tKL_Divergence = 0.011422\n",
      "Epoch: 30\tFidelity = 0.960246\tKL_Divergence = 0.020383\n",
      "Epoch: 31\tFidelity = 0.963979\tKL_Divergence = 0.012455\n",
      "Epoch: 32\tFidelity = 0.964578\tKL_Divergence = 0.012255\n",
      "Epoch: 33\tFidelity = 0.965215\tKL_Divergence = 0.011645\n",
      "Epoch: 34\tFidelity = 0.960488\tKL_Divergence = 0.021339\n",
      "Epoch: 35\tFidelity = 0.964346\tKL_Divergence = 0.014834\n",
      "Epoch: 36\tFidelity = 0.958564\tKL_Divergence = 0.023959\n",
      "Epoch: 37\tFidelity = 0.965970\tKL_Divergence = 0.011774\n",
      "Epoch: 38\tFidelity = 0.965876\tKL_Divergence = 0.011219\n",
      "Epoch: 39\tFidelity = 0.965961\tKL_Divergence = 0.011680\n",
      "Epoch: 40\tFidelity = 0.955285\tKL_Divergence = 0.029372\n",
      "Epoch: 41\tFidelity = 0.964089\tKL_Divergence = 0.014619\n",
      "Epoch: 42\tFidelity = 0.957526\tKL_Divergence = 0.024926\n",
      "Epoch: 43\tFidelity = 0.961585\tKL_Divergence = 0.014196\n",
      "Epoch: 44\tFidelity = 0.965012\tKL_Divergence = 0.013244\n",
      "Epoch: 45\tFidelity = 0.962744\tKL_Divergence = 0.014604\n",
      "Epoch: 46\tFidelity = 0.966802\tKL_Divergence = 0.011793\n",
      "Epoch: 47\tFidelity = 0.965218\tKL_Divergence = 0.012125\n",
      "Epoch: 48\tFidelity = 0.958467\tKL_Divergence = 0.019959\n",
      "Epoch: 49\tFidelity = 0.964529\tKL_Divergence = 0.013048\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 03:49:05,695] Trial 10 finished with value: 0.012344690390920182 and parameters: {'lr': 7.957191354148434, 'pbs': 1000, 'nbs': 3000}. Best is trial 10 with value: 0.012344690390920182.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.966000\tKL_Divergence = 0.012345\n",
      "Total time elapsed during training: 84.858 s\n",
      "Trial 10 finished with value: 0.012344690390920182 and parameters: {'lr': 7.957191354148434, 'pbs': 1000, 'nbs': 3000}. Best is trial 10 with value: 0.012344690390920182.\n",
      "Epoch: 1\tFidelity = 0.963508\tKL_Divergence = 0.013134\n",
      "Epoch: 2\tFidelity = 0.964958\tKL_Divergence = 0.012112\n",
      "Epoch: 3\tFidelity = 0.959287\tKL_Divergence = 0.021203\n",
      "Epoch: 4\tFidelity = 0.966071\tKL_Divergence = 0.011410\n",
      "Epoch: 5\tFidelity = 0.954868\tKL_Divergence = 0.022143\n",
      "Epoch: 6\tFidelity = 0.959346\tKL_Divergence = 0.018807\n",
      "Epoch: 7\tFidelity = 0.965903\tKL_Divergence = 0.011715\n",
      "Epoch: 8\tFidelity = 0.958747\tKL_Divergence = 0.016144\n",
      "Epoch: 9\tFidelity = 0.963941\tKL_Divergence = 0.012595\n",
      "Epoch: 10\tFidelity = 0.965735\tKL_Divergence = 0.011469\n",
      "Epoch: 11\tFidelity = 0.964929\tKL_Divergence = 0.011739\n",
      "Epoch: 12\tFidelity = 0.961699\tKL_Divergence = 0.016219\n",
      "Epoch: 13\tFidelity = 0.962543\tKL_Divergence = 0.014789\n",
      "Epoch: 14\tFidelity = 0.965765\tKL_Divergence = 0.012879\n",
      "Epoch: 15\tFidelity = 0.961339\tKL_Divergence = 0.020181\n",
      "Epoch: 16\tFidelity = 0.965597\tKL_Divergence = 0.013061\n",
      "Epoch: 17\tFidelity = 0.960535\tKL_Divergence = 0.018425\n",
      "Epoch: 18\tFidelity = 0.962090\tKL_Divergence = 0.015373\n",
      "Epoch: 19\tFidelity = 0.966067\tKL_Divergence = 0.012734\n",
      "Epoch: 20\tFidelity = 0.960870\tKL_Divergence = 0.014970\n",
      "Epoch: 21\tFidelity = 0.965207\tKL_Divergence = 0.012413\n",
      "Epoch: 22\tFidelity = 0.964349\tKL_Divergence = 0.012783\n",
      "Epoch: 23\tFidelity = 0.965900\tKL_Divergence = 0.011597\n",
      "Epoch: 24\tFidelity = 0.965624\tKL_Divergence = 0.012173\n",
      "Epoch: 25\tFidelity = 0.962920\tKL_Divergence = 0.017298\n",
      "Epoch: 26\tFidelity = 0.960900\tKL_Divergence = 0.018481\n",
      "Epoch: 27\tFidelity = 0.965877\tKL_Divergence = 0.011809\n",
      "Epoch: 28\tFidelity = 0.962658\tKL_Divergence = 0.014481\n",
      "Epoch: 29\tFidelity = 0.966427\tKL_Divergence = 0.011822\n",
      "Epoch: 30\tFidelity = 0.966358\tKL_Divergence = 0.011463\n",
      "Epoch: 31\tFidelity = 0.964872\tKL_Divergence = 0.014863\n",
      "Epoch: 32\tFidelity = 0.967027\tKL_Divergence = 0.012257\n",
      "Epoch: 33\tFidelity = 0.962130\tKL_Divergence = 0.020228\n",
      "Epoch: 34\tFidelity = 0.963970\tKL_Divergence = 0.017710\n",
      "Epoch: 35\tFidelity = 0.965488\tKL_Divergence = 0.015572\n",
      "Epoch: 36\tFidelity = 0.965389\tKL_Divergence = 0.015787\n",
      "Epoch: 37\tFidelity = 0.966766\tKL_Divergence = 0.011850\n",
      "Epoch: 38\tFidelity = 0.966447\tKL_Divergence = 0.012523\n",
      "Epoch: 39\tFidelity = 0.962495\tKL_Divergence = 0.018433\n",
      "Epoch: 40\tFidelity = 0.962489\tKL_Divergence = 0.014615\n",
      "Epoch: 41\tFidelity = 0.965284\tKL_Divergence = 0.016177\n",
      "Epoch: 42\tFidelity = 0.965879\tKL_Divergence = 0.013438\n",
      "Epoch: 43\tFidelity = 0.963975\tKL_Divergence = 0.016603\n",
      "Epoch: 44\tFidelity = 0.961640\tKL_Divergence = 0.014813\n",
      "Epoch: 45\tFidelity = 0.966499\tKL_Divergence = 0.012201\n",
      "Epoch: 46\tFidelity = 0.966398\tKL_Divergence = 0.011702\n",
      "Epoch: 47\tFidelity = 0.960599\tKL_Divergence = 0.021382\n",
      "Epoch: 48\tFidelity = 0.966297\tKL_Divergence = 0.011730\n",
      "Epoch: 49\tFidelity = 0.961146\tKL_Divergence = 0.016833\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 03:50:31,574] Trial 11 finished with value: 0.013822928519773365 and parameters: {'lr': 7.674700062141695, 'pbs': 1000, 'nbs': 3000}. Best is trial 10 with value: 0.012344690390920182.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.965291\tKL_Divergence = 0.013823\n",
      "Total time elapsed during training: 85.738 s\n",
      "Trial 11 finished with value: 0.013822928519773365 and parameters: {'lr': 7.674700062141695, 'pbs': 1000, 'nbs': 3000}. Best is trial 10 with value: 0.012344690390920182.\n",
      "Epoch: 1\tFidelity = 0.959306\tKL_Divergence = 0.025426\n",
      "Epoch: 2\tFidelity = 0.966267\tKL_Divergence = 0.015687\n",
      "Epoch: 3\tFidelity = 0.963082\tKL_Divergence = 0.015284\n",
      "Epoch: 4\tFidelity = 0.965135\tKL_Divergence = 0.013226\n",
      "Epoch: 5\tFidelity = 0.965590\tKL_Divergence = 0.015352\n",
      "Epoch: 6\tFidelity = 0.967394\tKL_Divergence = 0.012594\n",
      "Epoch: 7\tFidelity = 0.963592\tKL_Divergence = 0.015621\n",
      "Epoch: 8\tFidelity = 0.968022\tKL_Divergence = 0.011367\n",
      "Epoch: 9\tFidelity = 0.966080\tKL_Divergence = 0.015047\n",
      "Epoch: 10\tFidelity = 0.963944\tKL_Divergence = 0.017554\n",
      "Epoch: 11\tFidelity = 0.963120\tKL_Divergence = 0.014354\n",
      "Epoch: 12\tFidelity = 0.962094\tKL_Divergence = 0.018041\n",
      "Epoch: 13\tFidelity = 0.961255\tKL_Divergence = 0.019142\n",
      "Epoch: 14\tFidelity = 0.963579\tKL_Divergence = 0.013597\n",
      "Epoch: 15\tFidelity = 0.967352\tKL_Divergence = 0.011412\n",
      "Epoch: 16\tFidelity = 0.964024\tKL_Divergence = 0.015391\n",
      "Epoch: 17\tFidelity = 0.960994\tKL_Divergence = 0.016678\n",
      "Epoch: 18\tFidelity = 0.961612\tKL_Divergence = 0.016597\n",
      "Epoch: 19\tFidelity = 0.963773\tKL_Divergence = 0.015105\n",
      "Epoch: 20\tFidelity = 0.964191\tKL_Divergence = 0.014065\n",
      "Epoch: 21\tFidelity = 0.964240\tKL_Divergence = 0.015595\n",
      "Epoch: 22\tFidelity = 0.964684\tKL_Divergence = 0.014481\n",
      "Epoch: 23\tFidelity = 0.965429\tKL_Divergence = 0.014776\n",
      "Epoch: 24\tFidelity = 0.965672\tKL_Divergence = 0.015308\n",
      "Epoch: 25\tFidelity = 0.966287\tKL_Divergence = 0.015331\n",
      "Epoch: 26\tFidelity = 0.961519\tKL_Divergence = 0.023794\n",
      "Epoch: 27\tFidelity = 0.969400\tKL_Divergence = 0.011064\n",
      "Epoch: 28\tFidelity = 0.957909\tKL_Divergence = 0.022449\n",
      "Epoch: 29\tFidelity = 0.962869\tKL_Divergence = 0.019418\n",
      "Epoch: 30\tFidelity = 0.962195\tKL_Divergence = 0.016849\n",
      "Epoch: 31\tFidelity = 0.966923\tKL_Divergence = 0.012438\n",
      "Epoch: 32\tFidelity = 0.965463\tKL_Divergence = 0.017362\n",
      "Epoch: 33\tFidelity = 0.968104\tKL_Divergence = 0.011665\n",
      "Epoch: 34\tFidelity = 0.966424\tKL_Divergence = 0.012923\n",
      "Epoch: 35\tFidelity = 0.965780\tKL_Divergence = 0.016393\n",
      "Epoch: 36\tFidelity = 0.967356\tKL_Divergence = 0.013355\n",
      "Epoch: 37\tFidelity = 0.967062\tKL_Divergence = 0.012330\n",
      "Epoch: 38\tFidelity = 0.967159\tKL_Divergence = 0.012103\n",
      "Epoch: 39\tFidelity = 0.968249\tKL_Divergence = 0.012023\n",
      "Epoch: 40\tFidelity = 0.967357\tKL_Divergence = 0.012607\n",
      "Epoch: 41\tFidelity = 0.965959\tKL_Divergence = 0.015408\n",
      "Epoch: 42\tFidelity = 0.959374\tKL_Divergence = 0.024565\n",
      "Epoch: 43\tFidelity = 0.960905\tKL_Divergence = 0.023100\n",
      "Epoch: 44\tFidelity = 0.967253\tKL_Divergence = 0.012867\n",
      "Epoch: 45\tFidelity = 0.966677\tKL_Divergence = 0.012928\n",
      "Epoch: 46\tFidelity = 0.964934\tKL_Divergence = 0.017714\n",
      "Epoch: 47\tFidelity = 0.967486\tKL_Divergence = 0.012139\n",
      "Epoch: 48\tFidelity = 0.968800\tKL_Divergence = 0.011581\n",
      "Epoch: 49\tFidelity = 0.961190\tKL_Divergence = 0.016764\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 03:51:56,878] Trial 12 finished with value: 0.013628612793910685 and parameters: {'lr': 10.069943029443522, 'pbs': 1000, 'nbs': 3000}. Best is trial 10 with value: 0.012344690390920182.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.966811\tKL_Divergence = 0.013629\n",
      "Total time elapsed during training: 85.158 s\n",
      "Trial 12 finished with value: 0.013628612793910685 and parameters: {'lr': 10.069943029443522, 'pbs': 1000, 'nbs': 3000}. Best is trial 10 with value: 0.012344690390920182.\n",
      "Epoch: 1\tFidelity = 0.967388\tKL_Divergence = 0.012571\n",
      "Epoch: 2\tFidelity = 0.967908\tKL_Divergence = 0.012660\n",
      "Epoch: 3\tFidelity = 0.967757\tKL_Divergence = 0.012481\n",
      "Epoch: 4\tFidelity = 0.967084\tKL_Divergence = 0.012173\n",
      "Epoch: 5\tFidelity = 0.967135\tKL_Divergence = 0.012114\n",
      "Epoch: 6\tFidelity = 0.963934\tKL_Divergence = 0.017731\n",
      "Epoch: 7\tFidelity = 0.961334\tKL_Divergence = 0.020230\n",
      "Epoch: 8\tFidelity = 0.963382\tKL_Divergence = 0.015711\n",
      "Epoch: 9\tFidelity = 0.957681\tKL_Divergence = 0.027773\n",
      "Epoch: 10\tFidelity = 0.967829\tKL_Divergence = 0.011554\n",
      "Epoch: 11\tFidelity = 0.967295\tKL_Divergence = 0.011930\n",
      "Epoch: 12\tFidelity = 0.964940\tKL_Divergence = 0.013478\n",
      "Epoch: 13\tFidelity = 0.959447\tKL_Divergence = 0.024887\n",
      "Epoch: 14\tFidelity = 0.967374\tKL_Divergence = 0.012107\n",
      "Epoch: 15\tFidelity = 0.963692\tKL_Divergence = 0.016578\n",
      "Epoch: 16\tFidelity = 0.968498\tKL_Divergence = 0.011425\n",
      "Epoch: 17\tFidelity = 0.963899\tKL_Divergence = 0.018190\n",
      "Epoch: 18\tFidelity = 0.967225\tKL_Divergence = 0.014498\n",
      "Epoch: 19\tFidelity = 0.966926\tKL_Divergence = 0.014758\n",
      "Epoch: 20\tFidelity = 0.964420\tKL_Divergence = 0.015338\n",
      "Epoch: 21\tFidelity = 0.968545\tKL_Divergence = 0.011972\n",
      "Epoch: 22\tFidelity = 0.968296\tKL_Divergence = 0.011931\n",
      "Epoch: 23\tFidelity = 0.961596\tKL_Divergence = 0.021824\n",
      "Epoch: 24\tFidelity = 0.968035\tKL_Divergence = 0.012606\n",
      "Epoch: 25\tFidelity = 0.965468\tKL_Divergence = 0.015965\n",
      "Epoch: 26\tFidelity = 0.968706\tKL_Divergence = 0.011418\n",
      "Epoch: 27\tFidelity = 0.968024\tKL_Divergence = 0.011961\n",
      "Epoch: 28\tFidelity = 0.966911\tKL_Divergence = 0.014068\n",
      "Epoch: 29\tFidelity = 0.959471\tKL_Divergence = 0.020975\n",
      "Epoch: 30\tFidelity = 0.967875\tKL_Divergence = 0.013556\n",
      "Epoch: 31\tFidelity = 0.968935\tKL_Divergence = 0.011427\n",
      "Epoch: 32\tFidelity = 0.968374\tKL_Divergence = 0.013002\n",
      "Epoch: 33\tFidelity = 0.968736\tKL_Divergence = 0.011825\n",
      "Epoch: 34\tFidelity = 0.964789\tKL_Divergence = 0.017774\n",
      "Epoch: 35\tFidelity = 0.967062\tKL_Divergence = 0.013086\n",
      "Epoch: 36\tFidelity = 0.968608\tKL_Divergence = 0.011663\n",
      "Epoch: 37\tFidelity = 0.966898\tKL_Divergence = 0.013124\n",
      "Epoch: 38\tFidelity = 0.961830\tKL_Divergence = 0.019510\n",
      "Epoch: 39\tFidelity = 0.965991\tKL_Divergence = 0.014763\n",
      "Epoch: 40\tFidelity = 0.955383\tKL_Divergence = 0.031954\n",
      "Epoch: 41\tFidelity = 0.961692\tKL_Divergence = 0.021514\n",
      "Epoch: 42\tFidelity = 0.966143\tKL_Divergence = 0.013097\n",
      "Epoch: 43\tFidelity = 0.965783\tKL_Divergence = 0.012946\n",
      "Epoch: 44\tFidelity = 0.968036\tKL_Divergence = 0.011702\n",
      "Epoch: 45\tFidelity = 0.966717\tKL_Divergence = 0.013805\n",
      "Epoch: 46\tFidelity = 0.967044\tKL_Divergence = 0.012859\n",
      "Epoch: 47\tFidelity = 0.967468\tKL_Divergence = 0.013325\n",
      "Epoch: 48\tFidelity = 0.968032\tKL_Divergence = 0.011752\n",
      "Epoch: 49\tFidelity = 0.966277\tKL_Divergence = 0.012447\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 03:53:22,007] Trial 13 finished with value: 0.01462459826247585 and parameters: {'lr': 7.227113320670506, 'pbs': 1000, 'nbs': 3000}. Best is trial 10 with value: 0.012344690390920182.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.965034\tKL_Divergence = 0.014625\n",
      "Total time elapsed during training: 84.972 s\n",
      "Trial 13 finished with value: 0.01462459826247585 and parameters: {'lr': 7.227113320670506, 'pbs': 1000, 'nbs': 3000}. Best is trial 10 with value: 0.012344690390920182.\n",
      "Epoch: 1\tFidelity = 0.966543\tKL_Divergence = 0.014395\n",
      "Epoch: 2\tFidelity = 0.967818\tKL_Divergence = 0.011612\n",
      "Epoch: 3\tFidelity = 0.967663\tKL_Divergence = 0.012197\n",
      "Epoch: 4\tFidelity = 0.967222\tKL_Divergence = 0.013395\n",
      "Epoch: 5\tFidelity = 0.966840\tKL_Divergence = 0.013698\n",
      "Epoch: 6\tFidelity = 0.967130\tKL_Divergence = 0.013282\n",
      "Epoch: 7\tFidelity = 0.963939\tKL_Divergence = 0.018196\n",
      "Epoch: 8\tFidelity = 0.963616\tKL_Divergence = 0.018703\n",
      "Epoch: 9\tFidelity = 0.966638\tKL_Divergence = 0.014067\n",
      "Epoch: 10\tFidelity = 0.967108\tKL_Divergence = 0.012078\n",
      "Epoch: 11\tFidelity = 0.967950\tKL_Divergence = 0.011537\n",
      "Epoch: 12\tFidelity = 0.967627\tKL_Divergence = 0.012738\n",
      "Epoch: 13\tFidelity = 0.967233\tKL_Divergence = 0.012581\n",
      "Epoch: 14\tFidelity = 0.967363\tKL_Divergence = 0.012254\n",
      "Epoch: 15\tFidelity = 0.962798\tKL_Divergence = 0.019058\n",
      "Epoch: 16\tFidelity = 0.967908\tKL_Divergence = 0.011665\n",
      "Epoch: 17\tFidelity = 0.968166\tKL_Divergence = 0.011428\n",
      "Epoch: 18\tFidelity = 0.962641\tKL_Divergence = 0.016794\n",
      "Epoch: 19\tFidelity = 0.965524\tKL_Divergence = 0.015405\n",
      "Epoch: 20\tFidelity = 0.963368\tKL_Divergence = 0.017615\n",
      "Epoch: 21\tFidelity = 0.959158\tKL_Divergence = 0.025132\n",
      "Epoch: 22\tFidelity = 0.964230\tKL_Divergence = 0.017479\n",
      "Epoch: 23\tFidelity = 0.964346\tKL_Divergence = 0.017244\n",
      "Epoch: 24\tFidelity = 0.966835\tKL_Divergence = 0.013210\n",
      "Epoch: 25\tFidelity = 0.966982\tKL_Divergence = 0.012294\n",
      "Epoch: 26\tFidelity = 0.964261\tKL_Divergence = 0.016468\n",
      "Epoch: 27\tFidelity = 0.962942\tKL_Divergence = 0.019030\n",
      "Epoch: 28\tFidelity = 0.963682\tKL_Divergence = 0.016201\n",
      "Epoch: 29\tFidelity = 0.967321\tKL_Divergence = 0.011662\n",
      "Epoch: 30\tFidelity = 0.967077\tKL_Divergence = 0.012564\n",
      "Epoch: 31\tFidelity = 0.967187\tKL_Divergence = 0.012164\n",
      "Epoch: 32\tFidelity = 0.964245\tKL_Divergence = 0.016751\n",
      "Epoch: 33\tFidelity = 0.960577\tKL_Divergence = 0.022546\n",
      "Epoch: 34\tFidelity = 0.967989\tKL_Divergence = 0.011522\n",
      "Epoch: 35\tFidelity = 0.963448\tKL_Divergence = 0.017798\n",
      "Epoch: 36\tFidelity = 0.966667\tKL_Divergence = 0.012668\n",
      "Epoch: 37\tFidelity = 0.964114\tKL_Divergence = 0.018202\n",
      "Epoch: 38\tFidelity = 0.968233\tKL_Divergence = 0.011674\n",
      "Epoch: 39\tFidelity = 0.963849\tKL_Divergence = 0.019143\n",
      "Epoch: 40\tFidelity = 0.966682\tKL_Divergence = 0.014104\n",
      "Epoch: 41\tFidelity = 0.968254\tKL_Divergence = 0.011942\n",
      "Epoch: 42\tFidelity = 0.961589\tKL_Divergence = 0.022502\n",
      "Epoch: 43\tFidelity = 0.967465\tKL_Divergence = 0.012967\n",
      "Epoch: 44\tFidelity = 0.962795\tKL_Divergence = 0.020094\n",
      "Epoch: 45\tFidelity = 0.968526\tKL_Divergence = 0.012182\n",
      "Epoch: 46\tFidelity = 0.966705\tKL_Divergence = 0.015181\n",
      "Epoch: 47\tFidelity = 0.967089\tKL_Divergence = 0.013113\n",
      "Epoch: 48\tFidelity = 0.967423\tKL_Divergence = 0.012239\n",
      "Epoch: 49\tFidelity = 0.967586\tKL_Divergence = 0.013130\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 03:54:01,915] Trial 14 finished with value: 0.012475057015652052 and parameters: {'lr': 5.8671565526143645, 'pbs': 6000, 'nbs': 2000}. Best is trial 10 with value: 0.012344690390920182.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.967946\tKL_Divergence = 0.012475\n",
      "Total time elapsed during training: 39.755 s\n",
      "Trial 14 finished with value: 0.012475057015652052 and parameters: {'lr': 5.8671565526143645, 'pbs': 6000, 'nbs': 2000}. Best is trial 10 with value: 0.012344690390920182.\n",
      "Epoch: 1\tFidelity = 0.968226\tKL_Divergence = 0.011561\n",
      "Epoch: 2\tFidelity = 0.967517\tKL_Divergence = 0.012299\n",
      "Epoch: 3\tFidelity = 0.960097\tKL_Divergence = 0.023886\n",
      "Epoch: 4\tFidelity = 0.967231\tKL_Divergence = 0.011920\n",
      "Epoch: 5\tFidelity = 0.966881\tKL_Divergence = 0.013146\n",
      "Epoch: 6\tFidelity = 0.965309\tKL_Divergence = 0.015073\n",
      "Epoch: 7\tFidelity = 0.966082\tKL_Divergence = 0.014069\n",
      "Epoch: 8\tFidelity = 0.962677\tKL_Divergence = 0.018462\n",
      "Epoch: 9\tFidelity = 0.965960\tKL_Divergence = 0.013104\n",
      "Epoch: 10\tFidelity = 0.966185\tKL_Divergence = 0.014430\n",
      "Epoch: 11\tFidelity = 0.967565\tKL_Divergence = 0.011947\n",
      "Epoch: 12\tFidelity = 0.956407\tKL_Divergence = 0.026575\n",
      "Epoch: 13\tFidelity = 0.965441\tKL_Divergence = 0.015394\n",
      "Epoch: 14\tFidelity = 0.967176\tKL_Divergence = 0.012206\n",
      "Epoch: 15\tFidelity = 0.968071\tKL_Divergence = 0.011500\n",
      "Epoch: 16\tFidelity = 0.965953\tKL_Divergence = 0.014614\n",
      "Epoch: 17\tFidelity = 0.965088\tKL_Divergence = 0.014396\n",
      "Epoch: 18\tFidelity = 0.961890\tKL_Divergence = 0.020137\n",
      "Epoch: 19\tFidelity = 0.958864\tKL_Divergence = 0.025835\n",
      "Epoch: 20\tFidelity = 0.966959\tKL_Divergence = 0.014083\n",
      "Epoch: 21\tFidelity = 0.966892\tKL_Divergence = 0.013571\n",
      "Epoch: 22\tFidelity = 0.967171\tKL_Divergence = 0.012185\n",
      "Epoch: 23\tFidelity = 0.965558\tKL_Divergence = 0.016257\n",
      "Epoch: 24\tFidelity = 0.965492\tKL_Divergence = 0.016685\n",
      "Epoch: 25\tFidelity = 0.968784\tKL_Divergence = 0.011324\n",
      "Epoch: 26\tFidelity = 0.966623\tKL_Divergence = 0.013893\n",
      "Epoch: 27\tFidelity = 0.967852\tKL_Divergence = 0.012219\n",
      "Epoch: 28\tFidelity = 0.968156\tKL_Divergence = 0.011585\n",
      "Epoch: 29\tFidelity = 0.968084\tKL_Divergence = 0.011538\n",
      "Epoch: 30\tFidelity = 0.967906\tKL_Divergence = 0.011743\n",
      "Epoch: 31\tFidelity = 0.967252\tKL_Divergence = 0.013243\n",
      "Epoch: 32\tFidelity = 0.968376\tKL_Divergence = 0.012270\n",
      "Epoch: 33\tFidelity = 0.966167\tKL_Divergence = 0.014605\n",
      "Epoch: 34\tFidelity = 0.967402\tKL_Divergence = 0.012632\n",
      "Epoch: 35\tFidelity = 0.965416\tKL_Divergence = 0.016371\n",
      "Epoch: 36\tFidelity = 0.967855\tKL_Divergence = 0.011920\n",
      "Epoch: 37\tFidelity = 0.966229\tKL_Divergence = 0.012923\n",
      "Epoch: 38\tFidelity = 0.961665\tKL_Divergence = 0.020770\n",
      "Epoch: 39\tFidelity = 0.967555\tKL_Divergence = 0.012922\n",
      "Epoch: 40\tFidelity = 0.968194\tKL_Divergence = 0.012470\n",
      "Epoch: 41\tFidelity = 0.968352\tKL_Divergence = 0.012229\n",
      "Epoch: 42\tFidelity = 0.967491\tKL_Divergence = 0.013663\n",
      "Epoch: 43\tFidelity = 0.968890\tKL_Divergence = 0.011469\n",
      "Epoch: 44\tFidelity = 0.968912\tKL_Divergence = 0.011372\n",
      "Epoch: 45\tFidelity = 0.968186\tKL_Divergence = 0.011702\n",
      "Epoch: 46\tFidelity = 0.968474\tKL_Divergence = 0.011568\n",
      "Epoch: 47\tFidelity = 0.968264\tKL_Divergence = 0.011663\n",
      "Epoch: 48\tFidelity = 0.967738\tKL_Divergence = 0.011948\n",
      "Epoch: 49\tFidelity = 0.967134\tKL_Divergence = 0.012354\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 03:54:41,740] Trial 15 finished with value: 0.012458440191299798 and parameters: {'lr': 5.416840377733582, 'pbs': 6000, 'nbs': 2000}. Best is trial 10 with value: 0.012344690390920182.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.967538\tKL_Divergence = 0.012458\n",
      "Total time elapsed during training: 39.681 s\n",
      "Trial 15 finished with value: 0.012458440191299798 and parameters: {'lr': 5.416840377733582, 'pbs': 6000, 'nbs': 2000}. Best is trial 10 with value: 0.012344690390920182.\n",
      "Epoch: 1\tFidelity = 0.967002\tKL_Divergence = 0.013276\n",
      "Epoch: 2\tFidelity = 0.964284\tKL_Divergence = 0.017616\n",
      "Epoch: 3\tFidelity = 0.966083\tKL_Divergence = 0.014429\n",
      "Epoch: 4\tFidelity = 0.965490\tKL_Divergence = 0.015946\n",
      "Epoch: 5\tFidelity = 0.968070\tKL_Divergence = 0.011603\n",
      "Epoch: 6\tFidelity = 0.967530\tKL_Divergence = 0.012339\n",
      "Epoch: 7\tFidelity = 0.966653\tKL_Divergence = 0.013677\n",
      "Epoch: 8\tFidelity = 0.964383\tKL_Divergence = 0.017462\n",
      "Epoch: 9\tFidelity = 0.964636\tKL_Divergence = 0.016411\n",
      "Epoch: 10\tFidelity = 0.967571\tKL_Divergence = 0.012172\n",
      "Epoch: 11\tFidelity = 0.966163\tKL_Divergence = 0.014394\n",
      "Epoch: 12\tFidelity = 0.967943\tKL_Divergence = 0.011602\n",
      "Epoch: 13\tFidelity = 0.967812\tKL_Divergence = 0.012241\n",
      "Epoch: 14\tFidelity = 0.968405\tKL_Divergence = 0.011404\n",
      "Epoch: 15\tFidelity = 0.961875\tKL_Divergence = 0.021560\n",
      "Epoch: 16\tFidelity = 0.964441\tKL_Divergence = 0.018078\n",
      "Epoch: 17\tFidelity = 0.968116\tKL_Divergence = 0.012725\n",
      "Epoch: 18\tFidelity = 0.965670\tKL_Divergence = 0.014581\n",
      "Epoch: 19\tFidelity = 0.968275\tKL_Divergence = 0.012289\n",
      "Epoch: 20\tFidelity = 0.968772\tKL_Divergence = 0.011621\n",
      "Epoch: 21\tFidelity = 0.966491\tKL_Divergence = 0.014596\n",
      "Epoch: 22\tFidelity = 0.968445\tKL_Divergence = 0.011538\n",
      "Epoch: 23\tFidelity = 0.968677\tKL_Divergence = 0.011274\n",
      "Epoch: 24\tFidelity = 0.968675\tKL_Divergence = 0.011292\n",
      "Epoch: 25\tFidelity = 0.967178\tKL_Divergence = 0.014068\n",
      "Epoch: 26\tFidelity = 0.966080\tKL_Divergence = 0.015544\n",
      "Epoch: 27\tFidelity = 0.968492\tKL_Divergence = 0.011519\n",
      "Epoch: 28\tFidelity = 0.963613\tKL_Divergence = 0.019305\n",
      "Epoch: 29\tFidelity = 0.967009\tKL_Divergence = 0.014064\n",
      "Epoch: 30\tFidelity = 0.966183\tKL_Divergence = 0.015783\n",
      "Epoch: 31\tFidelity = 0.968295\tKL_Divergence = 0.012663\n",
      "Epoch: 32\tFidelity = 0.966953\tKL_Divergence = 0.014480\n",
      "Epoch: 33\tFidelity = 0.967080\tKL_Divergence = 0.014680\n",
      "Epoch: 34\tFidelity = 0.968489\tKL_Divergence = 0.012893\n",
      "Epoch: 35\tFidelity = 0.967288\tKL_Divergence = 0.014395\n",
      "Epoch: 36\tFidelity = 0.967760\tKL_Divergence = 0.013694\n",
      "Epoch: 37\tFidelity = 0.965535\tKL_Divergence = 0.016807\n",
      "Epoch: 38\tFidelity = 0.968164\tKL_Divergence = 0.013496\n",
      "Epoch: 39\tFidelity = 0.968893\tKL_Divergence = 0.012012\n",
      "Epoch: 40\tFidelity = 0.968969\tKL_Divergence = 0.012036\n",
      "Epoch: 41\tFidelity = 0.968713\tKL_Divergence = 0.011688\n",
      "Epoch: 42\tFidelity = 0.965642\tKL_Divergence = 0.016266\n",
      "Epoch: 43\tFidelity = 0.968313\tKL_Divergence = 0.012896\n",
      "Epoch: 44\tFidelity = 0.969405\tKL_Divergence = 0.011166\n",
      "Epoch: 45\tFidelity = 0.968810\tKL_Divergence = 0.011941\n",
      "Epoch: 46\tFidelity = 0.964524\tKL_Divergence = 0.018789\n",
      "Epoch: 47\tFidelity = 0.968838\tKL_Divergence = 0.012237\n",
      "Epoch: 48\tFidelity = 0.968405\tKL_Divergence = 0.012799\n",
      "Epoch: 49\tFidelity = 0.966995\tKL_Divergence = 0.014884\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 03:55:21,529] Trial 16 finished with value: 0.014235483454388334 and parameters: {'lr': 5.1133088488188125, 'pbs': 6000, 'nbs': 2000}. Best is trial 10 with value: 0.012344690390920182.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.967464\tKL_Divergence = 0.014235\n",
      "Total time elapsed during training: 39.644 s\n",
      "Trial 16 finished with value: 0.014235483454388334 and parameters: {'lr': 5.1133088488188125, 'pbs': 6000, 'nbs': 2000}. Best is trial 10 with value: 0.012344690390920182.\n",
      "Epoch: 1\tFidelity = 0.967681\tKL_Divergence = 0.013197\n",
      "Epoch: 2\tFidelity = 0.961969\tKL_Divergence = 0.021665\n",
      "Epoch: 3\tFidelity = 0.963953\tKL_Divergence = 0.019632\n",
      "Epoch: 4\tFidelity = 0.963990\tKL_Divergence = 0.018878\n",
      "Epoch: 5\tFidelity = 0.965405\tKL_Divergence = 0.017509\n",
      "Epoch: 6\tFidelity = 0.956959\tKL_Divergence = 0.028730\n",
      "Epoch: 7\tFidelity = 0.963565\tKL_Divergence = 0.019578\n",
      "Epoch: 8\tFidelity = 0.968621\tKL_Divergence = 0.014038\n",
      "Epoch: 9\tFidelity = 0.959120\tKL_Divergence = 0.023931\n",
      "Epoch: 10\tFidelity = 0.967774\tKL_Divergence = 0.014593\n",
      "Epoch: 11\tFidelity = 0.962759\tKL_Divergence = 0.018793\n",
      "Epoch: 12\tFidelity = 0.966207\tKL_Divergence = 0.014834\n",
      "Epoch: 13\tFidelity = 0.961508\tKL_Divergence = 0.023170\n",
      "Epoch: 14\tFidelity = 0.961551\tKL_Divergence = 0.023013\n",
      "Epoch: 15\tFidelity = 0.967432\tKL_Divergence = 0.013285\n",
      "Epoch: 16\tFidelity = 0.959698\tKL_Divergence = 0.024423\n",
      "Epoch: 17\tFidelity = 0.968881\tKL_Divergence = 0.013005\n",
      "Epoch: 18\tFidelity = 0.969510\tKL_Divergence = 0.011636\n",
      "Epoch: 19\tFidelity = 0.968362\tKL_Divergence = 0.013111\n",
      "Epoch: 20\tFidelity = 0.966651\tKL_Divergence = 0.014748\n",
      "Epoch: 21\tFidelity = 0.968898\tKL_Divergence = 0.011636\n",
      "Epoch: 22\tFidelity = 0.963193\tKL_Divergence = 0.021333\n",
      "Epoch: 23\tFidelity = 0.968114\tKL_Divergence = 0.011925\n",
      "Epoch: 24\tFidelity = 0.965527\tKL_Divergence = 0.014801\n",
      "Epoch: 25\tFidelity = 0.969935\tKL_Divergence = 0.011297\n",
      "Epoch: 26\tFidelity = 0.969021\tKL_Divergence = 0.012125\n",
      "Epoch: 27\tFidelity = 0.961467\tKL_Divergence = 0.024005\n",
      "Epoch: 28\tFidelity = 0.966975\tKL_Divergence = 0.013478\n",
      "Epoch: 29\tFidelity = 0.968256\tKL_Divergence = 0.012549\n",
      "Epoch: 30\tFidelity = 0.963777\tKL_Divergence = 0.020673\n",
      "Epoch: 31\tFidelity = 0.969022\tKL_Divergence = 0.012170\n",
      "Epoch: 32\tFidelity = 0.966817\tKL_Divergence = 0.015309\n",
      "Epoch: 33\tFidelity = 0.967712\tKL_Divergence = 0.013592\n",
      "Epoch: 34\tFidelity = 0.968068\tKL_Divergence = 0.013266\n",
      "Epoch: 35\tFidelity = 0.969072\tKL_Divergence = 0.011915\n",
      "Epoch: 36\tFidelity = 0.967684\tKL_Divergence = 0.013895\n",
      "Epoch: 37\tFidelity = 0.967747\tKL_Divergence = 0.013258\n",
      "Epoch: 38\tFidelity = 0.969758\tKL_Divergence = 0.011426\n",
      "Epoch: 39\tFidelity = 0.960623\tKL_Divergence = 0.025316\n",
      "Epoch: 40\tFidelity = 0.967709\tKL_Divergence = 0.014961\n",
      "Epoch: 41\tFidelity = 0.967508\tKL_Divergence = 0.014929\n",
      "Epoch: 42\tFidelity = 0.967960\tKL_Divergence = 0.012590\n",
      "Epoch: 43\tFidelity = 0.967364\tKL_Divergence = 0.014554\n",
      "Epoch: 44\tFidelity = 0.969465\tKL_Divergence = 0.011932\n",
      "Epoch: 45\tFidelity = 0.966484\tKL_Divergence = 0.015359\n",
      "Epoch: 46\tFidelity = 0.970244\tKL_Divergence = 0.010979\n",
      "Epoch: 47\tFidelity = 0.964517\tKL_Divergence = 0.018402\n",
      "Epoch: 48\tFidelity = 0.968568\tKL_Divergence = 0.012829\n",
      "Epoch: 49\tFidelity = 0.966569\tKL_Divergence = 0.016507\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 03:56:07,618] Trial 17 finished with value: 0.012625748161580833 and parameters: {'lr': 6.231531171404441, 'pbs': 4000, 'nbs': 4000}. Best is trial 10 with value: 0.012344690390920182.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.969022\tKL_Divergence = 0.012626\n",
      "Total time elapsed during training: 45.945 s\n",
      "Trial 17 finished with value: 0.012625748161580833 and parameters: {'lr': 6.231531171404441, 'pbs': 4000, 'nbs': 4000}. Best is trial 10 with value: 0.012344690390920182.\n",
      "Epoch: 1\tFidelity = 0.966453\tKL_Divergence = 0.016899\n",
      "Epoch: 2\tFidelity = 0.969698\tKL_Divergence = 0.011721\n",
      "Epoch: 3\tFidelity = 0.967252\tKL_Divergence = 0.015470\n",
      "Epoch: 4\tFidelity = 0.969982\tKL_Divergence = 0.010898\n",
      "Epoch: 5\tFidelity = 0.968760\tKL_Divergence = 0.013050\n",
      "Epoch: 6\tFidelity = 0.969098\tKL_Divergence = 0.012367\n",
      "Epoch: 7\tFidelity = 0.969681\tKL_Divergence = 0.011060\n",
      "Epoch: 8\tFidelity = 0.969222\tKL_Divergence = 0.011807\n",
      "Epoch: 9\tFidelity = 0.967868\tKL_Divergence = 0.013935\n",
      "Epoch: 10\tFidelity = 0.967285\tKL_Divergence = 0.014881\n",
      "Epoch: 11\tFidelity = 0.969143\tKL_Divergence = 0.012026\n",
      "Epoch: 12\tFidelity = 0.969233\tKL_Divergence = 0.011756\n",
      "Epoch: 13\tFidelity = 0.968670\tKL_Divergence = 0.012586\n",
      "Epoch: 14\tFidelity = 0.961600\tKL_Divergence = 0.023252\n",
      "Epoch: 15\tFidelity = 0.967510\tKL_Divergence = 0.014624\n",
      "Epoch: 16\tFidelity = 0.965312\tKL_Divergence = 0.017862\n",
      "Epoch: 17\tFidelity = 0.969447\tKL_Divergence = 0.011576\n",
      "Epoch: 18\tFidelity = 0.969169\tKL_Divergence = 0.011789\n",
      "Epoch: 19\tFidelity = 0.968517\tKL_Divergence = 0.012913\n",
      "Epoch: 20\tFidelity = 0.967898\tKL_Divergence = 0.013785\n",
      "Epoch: 21\tFidelity = 0.969493\tKL_Divergence = 0.011118\n",
      "Epoch: 22\tFidelity = 0.966872\tKL_Divergence = 0.015214\n",
      "Epoch: 23\tFidelity = 0.967242\tKL_Divergence = 0.014642\n",
      "Epoch: 24\tFidelity = 0.966616\tKL_Divergence = 0.015513\n",
      "Epoch: 25\tFidelity = 0.966272\tKL_Divergence = 0.016168\n",
      "Epoch: 26\tFidelity = 0.964987\tKL_Divergence = 0.018036\n",
      "Epoch: 27\tFidelity = 0.967732\tKL_Divergence = 0.014100\n",
      "Epoch: 28\tFidelity = 0.969045\tKL_Divergence = 0.011703\n",
      "Epoch: 29\tFidelity = 0.969419\tKL_Divergence = 0.011014\n",
      "Epoch: 30\tFidelity = 0.967905\tKL_Divergence = 0.013353\n",
      "Epoch: 31\tFidelity = 0.968190\tKL_Divergence = 0.013035\n",
      "Epoch: 32\tFidelity = 0.967359\tKL_Divergence = 0.014265\n",
      "Epoch: 33\tFidelity = 0.967698\tKL_Divergence = 0.013910\n",
      "Epoch: 34\tFidelity = 0.969183\tKL_Divergence = 0.011435\n",
      "Epoch: 35\tFidelity = 0.966240\tKL_Divergence = 0.016169\n",
      "Epoch: 36\tFidelity = 0.967756\tKL_Divergence = 0.013841\n",
      "Epoch: 37\tFidelity = 0.965703\tKL_Divergence = 0.017084\n",
      "Epoch: 38\tFidelity = 0.968395\tKL_Divergence = 0.012967\n",
      "Epoch: 39\tFidelity = 0.968726\tKL_Divergence = 0.012504\n",
      "Epoch: 40\tFidelity = 0.969071\tKL_Divergence = 0.011705\n",
      "Epoch: 41\tFidelity = 0.968874\tKL_Divergence = 0.012045\n",
      "Epoch: 42\tFidelity = 0.968375\tKL_Divergence = 0.012740\n",
      "Epoch: 43\tFidelity = 0.967261\tKL_Divergence = 0.014682\n",
      "Epoch: 44\tFidelity = 0.969124\tKL_Divergence = 0.011606\n",
      "Epoch: 45\tFidelity = 0.966468\tKL_Divergence = 0.015746\n",
      "Epoch: 46\tFidelity = 0.967518\tKL_Divergence = 0.014145\n",
      "Epoch: 47\tFidelity = 0.966404\tKL_Divergence = 0.015938\n",
      "Epoch: 48\tFidelity = 0.964790\tKL_Divergence = 0.018367\n",
      "Epoch: 49\tFidelity = 0.969479\tKL_Divergence = 0.011203\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 03:56:40,521] Trial 18 finished with value: 0.011098253765905588 and parameters: {'lr': 5.09715659922742, 'pbs': 9000, 'nbs': 9000}. Best is trial 18 with value: 0.011098253765905588.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.969281\tKL_Divergence = 0.011098\n",
      "Total time elapsed during training: 32.770 s\n",
      "Trial 18 finished with value: 0.011098253765905588 and parameters: {'lr': 5.09715659922742, 'pbs': 9000, 'nbs': 9000}. Best is trial 18 with value: 0.011098253765905588.\n",
      "Epoch: 1\tFidelity = 0.966520\tKL_Divergence = 0.015692\n",
      "Epoch: 2\tFidelity = 0.968853\tKL_Divergence = 0.011343\n",
      "Epoch: 3\tFidelity = 0.968218\tKL_Divergence = 0.012788\n",
      "Epoch: 4\tFidelity = 0.963804\tKL_Divergence = 0.018408\n",
      "Epoch: 5\tFidelity = 0.968048\tKL_Divergence = 0.012125\n",
      "Epoch: 6\tFidelity = 0.962197\tKL_Divergence = 0.020694\n",
      "Epoch: 7\tFidelity = 0.962547\tKL_Divergence = 0.021113\n",
      "Epoch: 8\tFidelity = 0.966738\tKL_Divergence = 0.013924\n",
      "Epoch: 9\tFidelity = 0.966993\tKL_Divergence = 0.014885\n",
      "Epoch: 10\tFidelity = 0.958191\tKL_Divergence = 0.027200\n",
      "Epoch: 11\tFidelity = 0.967694\tKL_Divergence = 0.013844\n",
      "Epoch: 12\tFidelity = 0.956602\tKL_Divergence = 0.029495\n",
      "Epoch: 13\tFidelity = 0.966601\tKL_Divergence = 0.015469\n",
      "Epoch: 14\tFidelity = 0.964728\tKL_Divergence = 0.017377\n",
      "Epoch: 15\tFidelity = 0.966967\tKL_Divergence = 0.015143\n",
      "Epoch: 16\tFidelity = 0.967220\tKL_Divergence = 0.013934\n",
      "Epoch: 17\tFidelity = 0.959320\tKL_Divergence = 0.027076\n",
      "Epoch: 18\tFidelity = 0.961745\tKL_Divergence = 0.022299\n",
      "Epoch: 19\tFidelity = 0.962257\tKL_Divergence = 0.022513\n",
      "Epoch: 20\tFidelity = 0.961644\tKL_Divergence = 0.022091\n",
      "Epoch: 21\tFidelity = 0.968575\tKL_Divergence = 0.012663\n",
      "Epoch: 22\tFidelity = 0.962316\tKL_Divergence = 0.021454\n",
      "Epoch: 23\tFidelity = 0.968869\tKL_Divergence = 0.012334\n",
      "Epoch: 24\tFidelity = 0.967079\tKL_Divergence = 0.014435\n",
      "Epoch: 25\tFidelity = 0.967776\tKL_Divergence = 0.014622\n",
      "Epoch: 26\tFidelity = 0.964906\tKL_Divergence = 0.017943\n",
      "Epoch: 27\tFidelity = 0.961586\tKL_Divergence = 0.023853\n",
      "Epoch: 28\tFidelity = 0.963528\tKL_Divergence = 0.019747\n",
      "Epoch: 29\tFidelity = 0.968364\tKL_Divergence = 0.013481\n",
      "Epoch: 30\tFidelity = 0.965670\tKL_Divergence = 0.016452\n",
      "Epoch: 31\tFidelity = 0.963608\tKL_Divergence = 0.020851\n",
      "Epoch: 32\tFidelity = 0.967689\tKL_Divergence = 0.013197\n",
      "Epoch: 33\tFidelity = 0.968201\tKL_Divergence = 0.014365\n",
      "Epoch: 34\tFidelity = 0.967445\tKL_Divergence = 0.013653\n",
      "Epoch: 35\tFidelity = 0.969174\tKL_Divergence = 0.013270\n",
      "Epoch: 36\tFidelity = 0.965557\tKL_Divergence = 0.017647\n",
      "Epoch: 37\tFidelity = 0.966410\tKL_Divergence = 0.017394\n",
      "Epoch: 38\tFidelity = 0.967542\tKL_Divergence = 0.014393\n",
      "Epoch: 39\tFidelity = 0.969901\tKL_Divergence = 0.011834\n",
      "Epoch: 40\tFidelity = 0.962527\tKL_Divergence = 0.022066\n",
      "Epoch: 41\tFidelity = 0.969558\tKL_Divergence = 0.012009\n",
      "Epoch: 42\tFidelity = 0.955716\tKL_Divergence = 0.031897\n",
      "Epoch: 43\tFidelity = 0.969079\tKL_Divergence = 0.012331\n",
      "Epoch: 44\tFidelity = 0.957035\tKL_Divergence = 0.029727\n",
      "Epoch: 45\tFidelity = 0.965702\tKL_Divergence = 0.016250\n",
      "Epoch: 46\tFidelity = 0.966780\tKL_Divergence = 0.014971\n",
      "Epoch: 47\tFidelity = 0.956006\tKL_Divergence = 0.032194\n",
      "Epoch: 48\tFidelity = 0.967166\tKL_Divergence = 0.013414\n",
      "Epoch: 49\tFidelity = 0.965335\tKL_Divergence = 0.018160\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 03:57:13,539] Trial 19 finished with value: 0.013785190119510132 and parameters: {'lr': 8.819571194800861, 'pbs': 9000, 'nbs': 9000}. Best is trial 18 with value: 0.011098253765905588.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.967049\tKL_Divergence = 0.013785\n",
      "Total time elapsed during training: 32.877 s\n",
      "Trial 19 finished with value: 0.013785190119510132 and parameters: {'lr': 8.819571194800861, 'pbs': 9000, 'nbs': 9000}. Best is trial 18 with value: 0.011098253765905588.\n",
      "Epoch: 1\tFidelity = 0.967804\tKL_Divergence = 0.016622\n",
      "Epoch: 2\tFidelity = 0.970467\tKL_Divergence = 0.013009\n",
      "Epoch: 3\tFidelity = 0.968362\tKL_Divergence = 0.015895\n",
      "Epoch: 4\tFidelity = 0.969178\tKL_Divergence = 0.014521\n",
      "Epoch: 5\tFidelity = 0.971368\tKL_Divergence = 0.010896\n",
      "Epoch: 6\tFidelity = 0.966241\tKL_Divergence = 0.018546\n",
      "Epoch: 7\tFidelity = 0.971357\tKL_Divergence = 0.010635\n",
      "Epoch: 8\tFidelity = 0.964794\tKL_Divergence = 0.020481\n",
      "Epoch: 9\tFidelity = 0.969212\tKL_Divergence = 0.014048\n",
      "Epoch: 10\tFidelity = 0.971035\tKL_Divergence = 0.011049\n",
      "Epoch: 11\tFidelity = 0.970374\tKL_Divergence = 0.011798\n",
      "Epoch: 12\tFidelity = 0.963719\tKL_Divergence = 0.021697\n",
      "Epoch: 13\tFidelity = 0.969723\tKL_Divergence = 0.012824\n",
      "Epoch: 14\tFidelity = 0.970722\tKL_Divergence = 0.010764\n",
      "Epoch: 15\tFidelity = 0.970130\tKL_Divergence = 0.011676\n",
      "Epoch: 16\tFidelity = 0.968894\tKL_Divergence = 0.013522\n",
      "Epoch: 17\tFidelity = 0.968387\tKL_Divergence = 0.014112\n",
      "Epoch: 18\tFidelity = 0.970372\tKL_Divergence = 0.010834\n",
      "Epoch: 19\tFidelity = 0.970184\tKL_Divergence = 0.010875\n",
      "Epoch: 20\tFidelity = 0.966881\tKL_Divergence = 0.016112\n",
      "Epoch: 21\tFidelity = 0.970162\tKL_Divergence = 0.010885\n",
      "Epoch: 22\tFidelity = 0.969995\tKL_Divergence = 0.011131\n",
      "Epoch: 23\tFidelity = 0.969908\tKL_Divergence = 0.011112\n",
      "Epoch: 24\tFidelity = 0.966488\tKL_Divergence = 0.016394\n",
      "Epoch: 25\tFidelity = 0.967674\tKL_Divergence = 0.014609\n",
      "Epoch: 26\tFidelity = 0.968684\tKL_Divergence = 0.013093\n",
      "Epoch: 27\tFidelity = 0.965206\tKL_Divergence = 0.018432\n",
      "Epoch: 28\tFidelity = 0.969793\tKL_Divergence = 0.011391\n",
      "Epoch: 29\tFidelity = 0.969914\tKL_Divergence = 0.010946\n",
      "Epoch: 30\tFidelity = 0.967687\tKL_Divergence = 0.014635\n",
      "Epoch: 31\tFidelity = 0.967065\tKL_Divergence = 0.015599\n",
      "Epoch: 32\tFidelity = 0.968317\tKL_Divergence = 0.013605\n",
      "Epoch: 33\tFidelity = 0.968413\tKL_Divergence = 0.013544\n",
      "Epoch: 34\tFidelity = 0.968802\tKL_Divergence = 0.012967\n",
      "Epoch: 35\tFidelity = 0.967996\tKL_Divergence = 0.014285\n",
      "Epoch: 36\tFidelity = 0.965364\tKL_Divergence = 0.018190\n",
      "Epoch: 37\tFidelity = 0.970089\tKL_Divergence = 0.010991\n",
      "Epoch: 38\tFidelity = 0.965583\tKL_Divergence = 0.017796\n",
      "Epoch: 39\tFidelity = 0.969243\tKL_Divergence = 0.012428\n",
      "Epoch: 40\tFidelity = 0.960167\tKL_Divergence = 0.025803\n",
      "Epoch: 41\tFidelity = 0.969229\tKL_Divergence = 0.012625\n",
      "Epoch: 42\tFidelity = 0.969776\tKL_Divergence = 0.011315\n",
      "Epoch: 43\tFidelity = 0.968936\tKL_Divergence = 0.013062\n",
      "Epoch: 44\tFidelity = 0.968198\tKL_Divergence = 0.013726\n",
      "Epoch: 45\tFidelity = 0.969395\tKL_Divergence = 0.012175\n",
      "Epoch: 46\tFidelity = 0.965711\tKL_Divergence = 0.017272\n",
      "Epoch: 47\tFidelity = 0.966938\tKL_Divergence = 0.015835\n",
      "Epoch: 48\tFidelity = 0.966541\tKL_Divergence = 0.016050\n",
      "Epoch: 49\tFidelity = 0.969055\tKL_Divergence = 0.012639\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 03:57:47,264] Trial 20 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.966868\tKL_Divergence = 0.015345\n",
      "Total time elapsed during training: 33.583 s\n",
      "Trial 20 pruned. \n",
      "Epoch: 1\tFidelity = 0.965070\tKL_Divergence = 0.018340\n",
      "Epoch: 2\tFidelity = 0.969101\tKL_Divergence = 0.012818\n",
      "Epoch: 3\tFidelity = 0.964878\tKL_Divergence = 0.018590\n",
      "Epoch: 4\tFidelity = 0.968139\tKL_Divergence = 0.013979\n",
      "Epoch: 5\tFidelity = 0.965229\tKL_Divergence = 0.017995\n",
      "Epoch: 6\tFidelity = 0.966974\tKL_Divergence = 0.015461\n",
      "Epoch: 7\tFidelity = 0.968130\tKL_Divergence = 0.014066\n",
      "Epoch: 8\tFidelity = 0.967461\tKL_Divergence = 0.014968\n",
      "Epoch: 9\tFidelity = 0.969447\tKL_Divergence = 0.011349\n",
      "Epoch: 10\tFidelity = 0.968390\tKL_Divergence = 0.011994\n",
      "Epoch: 11\tFidelity = 0.968736\tKL_Divergence = 0.011997\n",
      "Epoch: 12\tFidelity = 0.966855\tKL_Divergence = 0.014548\n",
      "Epoch: 13\tFidelity = 0.963187\tKL_Divergence = 0.020385\n",
      "Epoch: 14\tFidelity = 0.969028\tKL_Divergence = 0.011947\n",
      "Epoch: 15\tFidelity = 0.966761\tKL_Divergence = 0.014553\n",
      "Epoch: 16\tFidelity = 0.969599\tKL_Divergence = 0.010980\n",
      "Epoch: 17\tFidelity = 0.968332\tKL_Divergence = 0.011934\n",
      "Epoch: 18\tFidelity = 0.968014\tKL_Divergence = 0.013420\n",
      "Epoch: 19\tFidelity = 0.965177\tKL_Divergence = 0.015487\n",
      "Epoch: 20\tFidelity = 0.966465\tKL_Divergence = 0.016617\n",
      "Epoch: 21\tFidelity = 0.966768\tKL_Divergence = 0.015625\n",
      "Epoch: 22\tFidelity = 0.969232\tKL_Divergence = 0.012313\n",
      "Epoch: 23\tFidelity = 0.967706\tKL_Divergence = 0.014004\n",
      "Epoch: 24\tFidelity = 0.968224\tKL_Divergence = 0.012604\n",
      "Epoch: 25\tFidelity = 0.961173\tKL_Divergence = 0.024274\n",
      "Epoch: 26\tFidelity = 0.968371\tKL_Divergence = 0.013750\n",
      "Epoch: 27\tFidelity = 0.969603\tKL_Divergence = 0.012063\n",
      "Epoch: 28\tFidelity = 0.970321\tKL_Divergence = 0.011002\n",
      "Epoch: 29\tFidelity = 0.966092\tKL_Divergence = 0.016777\n",
      "Epoch: 30\tFidelity = 0.963674\tKL_Divergence = 0.019048\n",
      "Epoch: 31\tFidelity = 0.966149\tKL_Divergence = 0.016764\n",
      "Epoch: 32\tFidelity = 0.965990\tKL_Divergence = 0.016668\n",
      "Epoch: 33\tFidelity = 0.967336\tKL_Divergence = 0.014688\n",
      "Epoch: 34\tFidelity = 0.958652\tKL_Divergence = 0.027588\n",
      "Epoch: 35\tFidelity = 0.968654\tKL_Divergence = 0.012869\n",
      "Epoch: 36\tFidelity = 0.968693\tKL_Divergence = 0.012217\n",
      "Epoch: 37\tFidelity = 0.965746\tKL_Divergence = 0.016099\n",
      "Epoch: 38\tFidelity = 0.968606\tKL_Divergence = 0.011985\n",
      "Epoch: 39\tFidelity = 0.969474\tKL_Divergence = 0.011635\n",
      "Epoch: 40\tFidelity = 0.969676\tKL_Divergence = 0.010997\n",
      "Epoch: 41\tFidelity = 0.966722\tKL_Divergence = 0.014490\n",
      "Epoch: 42\tFidelity = 0.966795\tKL_Divergence = 0.015172\n",
      "Epoch: 43\tFidelity = 0.965717\tKL_Divergence = 0.016472\n",
      "Epoch: 44\tFidelity = 0.965515\tKL_Divergence = 0.017028\n",
      "Epoch: 45\tFidelity = 0.969129\tKL_Divergence = 0.012223\n",
      "Epoch: 46\tFidelity = 0.965596\tKL_Divergence = 0.017893\n",
      "Epoch: 47\tFidelity = 0.969495\tKL_Divergence = 0.012245\n",
      "Epoch: 48\tFidelity = 0.965282\tKL_Divergence = 0.018280\n",
      "Epoch: 49\tFidelity = 0.963192\tKL_Divergence = 0.020312\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 03:58:27,466] Trial 21 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.967333\tKL_Divergence = 0.015124\n",
      "Total time elapsed during training: 40.061 s\n",
      "Trial 21 pruned. \n",
      "Epoch: 1\tFidelity = 0.969662\tKL_Divergence = 0.011846\n",
      "Epoch: 2\tFidelity = 0.966515\tKL_Divergence = 0.016128\n",
      "Epoch: 3\tFidelity = 0.968100\tKL_Divergence = 0.013844\n",
      "Epoch: 4\tFidelity = 0.966834\tKL_Divergence = 0.015774\n",
      "Epoch: 5\tFidelity = 0.966354\tKL_Divergence = 0.016248\n",
      "Epoch: 6\tFidelity = 0.964078\tKL_Divergence = 0.019829\n",
      "Epoch: 7\tFidelity = 0.961976\tKL_Divergence = 0.023139\n",
      "Epoch: 8\tFidelity = 0.961739\tKL_Divergence = 0.023612\n",
      "Epoch: 9\tFidelity = 0.969815\tKL_Divergence = 0.011497\n",
      "Epoch: 10\tFidelity = 0.965616\tKL_Divergence = 0.017926\n",
      "Epoch: 11\tFidelity = 0.968637\tKL_Divergence = 0.013753\n",
      "Epoch: 12\tFidelity = 0.966266\tKL_Divergence = 0.016198\n",
      "Epoch: 13\tFidelity = 0.967781\tKL_Divergence = 0.015087\n",
      "Epoch: 14\tFidelity = 0.969249\tKL_Divergence = 0.012369\n",
      "Epoch: 15\tFidelity = 0.968323\tKL_Divergence = 0.014164\n",
      "Epoch: 16\tFidelity = 0.967278\tKL_Divergence = 0.015329\n",
      "Epoch: 17\tFidelity = 0.968345\tKL_Divergence = 0.013978\n",
      "Epoch: 18\tFidelity = 0.967400\tKL_Divergence = 0.015092\n",
      "Epoch: 19\tFidelity = 0.969849\tKL_Divergence = 0.010955\n",
      "Epoch: 20\tFidelity = 0.969557\tKL_Divergence = 0.011426\n",
      "Epoch: 21\tFidelity = 0.965505\tKL_Divergence = 0.017816\n",
      "Epoch: 22\tFidelity = 0.959088\tKL_Divergence = 0.027422\n",
      "Epoch: 23\tFidelity = 0.967182\tKL_Divergence = 0.015650\n",
      "Epoch: 24\tFidelity = 0.964314\tKL_Divergence = 0.019616\n",
      "Epoch: 25\tFidelity = 0.966136\tKL_Divergence = 0.017353\n",
      "Epoch: 26\tFidelity = 0.967711\tKL_Divergence = 0.014798\n",
      "Epoch: 27\tFidelity = 0.968866\tKL_Divergence = 0.013426\n",
      "Epoch: 28\tFidelity = 0.969840\tKL_Divergence = 0.011652\n",
      "Epoch: 29\tFidelity = 0.965486\tKL_Divergence = 0.018016\n",
      "Epoch: 30\tFidelity = 0.969952\tKL_Divergence = 0.011194\n",
      "Epoch: 31\tFidelity = 0.968277\tKL_Divergence = 0.013756\n",
      "Epoch: 32\tFidelity = 0.968895\tKL_Divergence = 0.012941\n",
      "Epoch: 33\tFidelity = 0.969667\tKL_Divergence = 0.011465\n",
      "Epoch: 34\tFidelity = 0.962505\tKL_Divergence = 0.022298\n",
      "Epoch: 35\tFidelity = 0.969998\tKL_Divergence = 0.011103\n",
      "Epoch: 36\tFidelity = 0.969021\tKL_Divergence = 0.012758\n",
      "Epoch: 37\tFidelity = 0.968691\tKL_Divergence = 0.013388\n",
      "Epoch: 38\tFidelity = 0.965951\tKL_Divergence = 0.017157\n",
      "Epoch: 39\tFidelity = 0.966675\tKL_Divergence = 0.016303\n",
      "Epoch: 40\tFidelity = 0.969454\tKL_Divergence = 0.011663\n",
      "Epoch: 41\tFidelity = 0.968263\tKL_Divergence = 0.013886\n",
      "Epoch: 42\tFidelity = 0.969805\tKL_Divergence = 0.011129\n",
      "Epoch: 43\tFidelity = 0.964417\tKL_Divergence = 0.019312\n",
      "Epoch: 44\tFidelity = 0.963532\tKL_Divergence = 0.020993\n",
      "Epoch: 45\tFidelity = 0.965743\tKL_Divergence = 0.017411\n",
      "Epoch: 46\tFidelity = 0.964790\tKL_Divergence = 0.018817\n",
      "Epoch: 47\tFidelity = 0.969750\tKL_Divergence = 0.011676\n",
      "Epoch: 48\tFidelity = 0.968544\tKL_Divergence = 0.012674\n",
      "Epoch: 49\tFidelity = 0.969055\tKL_Divergence = 0.011878\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 03:59:07,525] Trial 22 finished with value: 0.011076022933445413 and parameters: {'lr': 5.0710733359635976, 'pbs': 5000, 'nbs': 2000}. Best is trial 22 with value: 0.011076022933445413.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.969691\tKL_Divergence = 0.011076\n",
      "Total time elapsed during training: 39.917 s\n",
      "Trial 22 finished with value: 0.011076022933445413 and parameters: {'lr': 5.0710733359635976, 'pbs': 5000, 'nbs': 2000}. Best is trial 22 with value: 0.011076022933445413.\n",
      "Epoch: 1\tFidelity = 0.969156\tKL_Divergence = 0.011850\n",
      "Epoch: 2\tFidelity = 0.965875\tKL_Divergence = 0.016885\n",
      "Epoch: 3\tFidelity = 0.968941\tKL_Divergence = 0.012089\n",
      "Epoch: 4\tFidelity = 0.965300\tKL_Divergence = 0.017628\n",
      "Epoch: 5\tFidelity = 0.966528\tKL_Divergence = 0.016052\n",
      "Epoch: 6\tFidelity = 0.969269\tKL_Divergence = 0.011873\n",
      "Epoch: 7\tFidelity = 0.967226\tKL_Divergence = 0.015120\n",
      "Epoch: 8\tFidelity = 0.969947\tKL_Divergence = 0.011005\n",
      "Epoch: 9\tFidelity = 0.962241\tKL_Divergence = 0.021982\n",
      "Epoch: 10\tFidelity = 0.967211\tKL_Divergence = 0.015087\n",
      "Epoch: 11\tFidelity = 0.967318\tKL_Divergence = 0.014947\n",
      "Epoch: 12\tFidelity = 0.966587\tKL_Divergence = 0.016341\n",
      "Epoch: 13\tFidelity = 0.966608\tKL_Divergence = 0.016071\n",
      "Epoch: 14\tFidelity = 0.969051\tKL_Divergence = 0.012677\n",
      "Epoch: 15\tFidelity = 0.967724\tKL_Divergence = 0.014813\n",
      "Epoch: 16\tFidelity = 0.969167\tKL_Divergence = 0.012374\n",
      "Epoch: 17\tFidelity = 0.968449\tKL_Divergence = 0.013380\n",
      "Epoch: 18\tFidelity = 0.970070\tKL_Divergence = 0.010886\n",
      "Epoch: 19\tFidelity = 0.968382\tKL_Divergence = 0.013551\n",
      "Epoch: 20\tFidelity = 0.969623\tKL_Divergence = 0.011540\n",
      "Epoch: 21\tFidelity = 0.964767\tKL_Divergence = 0.018202\n",
      "Epoch: 22\tFidelity = 0.969294\tKL_Divergence = 0.011494\n",
      "Epoch: 23\tFidelity = 0.969285\tKL_Divergence = 0.011807\n",
      "Epoch: 24\tFidelity = 0.965635\tKL_Divergence = 0.017537\n",
      "Epoch: 25\tFidelity = 0.966482\tKL_Divergence = 0.016684\n",
      "Epoch: 26\tFidelity = 0.969901\tKL_Divergence = 0.011003\n",
      "Epoch: 27\tFidelity = 0.966415\tKL_Divergence = 0.015634\n",
      "Epoch: 28\tFidelity = 0.970137\tKL_Divergence = 0.011223\n",
      "Epoch: 29\tFidelity = 0.964313\tKL_Divergence = 0.019677\n",
      "Epoch: 30\tFidelity = 0.969088\tKL_Divergence = 0.012795\n",
      "Epoch: 31\tFidelity = 0.966822\tKL_Divergence = 0.016024\n",
      "Epoch: 32\tFidelity = 0.969385\tKL_Divergence = 0.011939\n",
      "Epoch: 33\tFidelity = 0.968861\tKL_Divergence = 0.013126\n",
      "Epoch: 34\tFidelity = 0.965223\tKL_Divergence = 0.018468\n",
      "Epoch: 35\tFidelity = 0.964475\tKL_Divergence = 0.019317\n",
      "Epoch: 36\tFidelity = 0.969706\tKL_Divergence = 0.011879\n",
      "Epoch: 37\tFidelity = 0.964570\tKL_Divergence = 0.019596\n",
      "Epoch: 38\tFidelity = 0.968761\tKL_Divergence = 0.013523\n",
      "Epoch: 39\tFidelity = 0.969456\tKL_Divergence = 0.012694\n",
      "Epoch: 40\tFidelity = 0.968896\tKL_Divergence = 0.013355\n",
      "Epoch: 41\tFidelity = 0.968067\tKL_Divergence = 0.014725\n",
      "Epoch: 42\tFidelity = 0.970169\tKL_Divergence = 0.011287\n",
      "Epoch: 43\tFidelity = 0.969170\tKL_Divergence = 0.012028\n",
      "Epoch: 44\tFidelity = 0.969604\tKL_Divergence = 0.012366\n",
      "Epoch: 45\tFidelity = 0.970514\tKL_Divergence = 0.010786\n",
      "Epoch: 46\tFidelity = 0.961234\tKL_Divergence = 0.024483\n",
      "Epoch: 47\tFidelity = 0.968757\tKL_Divergence = 0.013663\n",
      "Epoch: 48\tFidelity = 0.970556\tKL_Divergence = 0.011010\n",
      "Epoch: 49\tFidelity = 0.963942\tKL_Divergence = 0.020950\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 03:59:47,310] Trial 23 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.968650\tKL_Divergence = 0.014035\n",
      "Total time elapsed during training: 39.640 s\n",
      "Trial 23 pruned. \n",
      "Epoch: 1\tFidelity = 0.968048\tKL_Divergence = 0.015050\n",
      "Epoch: 2\tFidelity = 0.970613\tKL_Divergence = 0.011164\n",
      "Epoch: 3\tFidelity = 0.969648\tKL_Divergence = 0.012662\n",
      "Epoch: 4\tFidelity = 0.968480\tKL_Divergence = 0.014031\n",
      "Epoch: 5\tFidelity = 0.969236\tKL_Divergence = 0.011795\n",
      "Epoch: 6\tFidelity = 0.968837\tKL_Divergence = 0.013371\n",
      "Epoch: 7\tFidelity = 0.967927\tKL_Divergence = 0.014576\n",
      "Epoch: 8\tFidelity = 0.966123\tKL_Divergence = 0.017613\n",
      "Epoch: 9\tFidelity = 0.965447\tKL_Divergence = 0.018561\n",
      "Epoch: 10\tFidelity = 0.968286\tKL_Divergence = 0.013792\n",
      "Epoch: 11\tFidelity = 0.970801\tKL_Divergence = 0.010891\n",
      "Epoch: 12\tFidelity = 0.967604\tKL_Divergence = 0.015033\n",
      "Epoch: 13\tFidelity = 0.968333\tKL_Divergence = 0.014534\n",
      "Epoch: 14\tFidelity = 0.970610\tKL_Divergence = 0.011028\n",
      "Epoch: 15\tFidelity = 0.968813\tKL_Divergence = 0.011837\n",
      "Epoch: 16\tFidelity = 0.969428\tKL_Divergence = 0.011844\n",
      "Epoch: 17\tFidelity = 0.969324\tKL_Divergence = 0.012482\n",
      "Epoch: 18\tFidelity = 0.969580\tKL_Divergence = 0.012188\n",
      "Epoch: 19\tFidelity = 0.969358\tKL_Divergence = 0.012675\n",
      "Epoch: 20\tFidelity = 0.964705\tKL_Divergence = 0.019487\n",
      "Epoch: 21\tFidelity = 0.962032\tKL_Divergence = 0.023494\n",
      "Epoch: 22\tFidelity = 0.968526\tKL_Divergence = 0.013712\n",
      "Epoch: 23\tFidelity = 0.968556\tKL_Divergence = 0.012833\n",
      "Epoch: 24\tFidelity = 0.964562\tKL_Divergence = 0.019776\n",
      "Epoch: 25\tFidelity = 0.970043\tKL_Divergence = 0.011786\n",
      "Epoch: 26\tFidelity = 0.964816\tKL_Divergence = 0.018999\n",
      "Epoch: 27\tFidelity = 0.967981\tKL_Divergence = 0.013913\n",
      "Epoch: 28\tFidelity = 0.967840\tKL_Divergence = 0.015174\n",
      "Epoch: 29\tFidelity = 0.966526\tKL_Divergence = 0.015580\n",
      "Epoch: 30\tFidelity = 0.968867\tKL_Divergence = 0.013700\n",
      "Epoch: 31\tFidelity = 0.970154\tKL_Divergence = 0.011876\n",
      "Epoch: 32\tFidelity = 0.969528\tKL_Divergence = 0.012660\n",
      "Epoch: 33\tFidelity = 0.969418\tKL_Divergence = 0.012323\n",
      "Epoch: 34\tFidelity = 0.970450\tKL_Divergence = 0.011107\n",
      "Epoch: 35\tFidelity = 0.968997\tKL_Divergence = 0.013174\n",
      "Epoch: 36\tFidelity = 0.966972\tKL_Divergence = 0.015674\n",
      "Epoch: 37\tFidelity = 0.966208\tKL_Divergence = 0.016955\n",
      "Epoch: 38\tFidelity = 0.969976\tKL_Divergence = 0.011933\n",
      "Epoch: 39\tFidelity = 0.969132\tKL_Divergence = 0.013203\n",
      "Epoch: 40\tFidelity = 0.965719\tKL_Divergence = 0.017561\n",
      "Epoch: 41\tFidelity = 0.964970\tKL_Divergence = 0.019764\n",
      "Epoch: 42\tFidelity = 0.966485\tKL_Divergence = 0.017647\n",
      "Epoch: 43\tFidelity = 0.966576\tKL_Divergence = 0.017115\n",
      "Epoch: 44\tFidelity = 0.964086\tKL_Divergence = 0.020815\n",
      "Epoch: 45\tFidelity = 0.968709\tKL_Divergence = 0.014155\n",
      "Epoch: 46\tFidelity = 0.967932\tKL_Divergence = 0.015411\n",
      "Epoch: 47\tFidelity = 0.967510\tKL_Divergence = 0.015727\n",
      "Epoch: 48\tFidelity = 0.968659\tKL_Divergence = 0.013538\n",
      "Epoch: 49\tFidelity = 0.966849\tKL_Divergence = 0.016284\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:00:25,546] Trial 24 finished with value: 0.010929923347822168 and parameters: {'lr': 5.784267805887543, 'pbs': 5000, 'nbs': 7000}. Best is trial 24 with value: 0.010929923347822168.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.971104\tKL_Divergence = 0.010930\n",
      "Total time elapsed during training: 38.091 s\n",
      "Trial 24 finished with value: 0.010929923347822168 and parameters: {'lr': 5.784267805887543, 'pbs': 5000, 'nbs': 7000}. Best is trial 24 with value: 0.010929923347822168.\n",
      "Epoch: 1\tFidelity = 0.969052\tKL_Divergence = 0.014063\n",
      "Epoch: 2\tFidelity = 0.970874\tKL_Divergence = 0.011206\n",
      "Epoch: 3\tFidelity = 0.967407\tKL_Divergence = 0.015823\n",
      "Epoch: 4\tFidelity = 0.968440\tKL_Divergence = 0.014472\n",
      "Epoch: 5\tFidelity = 0.968441\tKL_Divergence = 0.014450\n",
      "Epoch: 6\tFidelity = 0.961276\tKL_Divergence = 0.025480\n",
      "Epoch: 7\tFidelity = 0.965344\tKL_Divergence = 0.019327\n",
      "Epoch: 8\tFidelity = 0.969044\tKL_Divergence = 0.013754\n",
      "Epoch: 9\tFidelity = 0.963468\tKL_Divergence = 0.022797\n",
      "Epoch: 10\tFidelity = 0.962716\tKL_Divergence = 0.023021\n",
      "Epoch: 11\tFidelity = 0.971661\tKL_Divergence = 0.010722\n",
      "Epoch: 12\tFidelity = 0.968518\tKL_Divergence = 0.013495\n",
      "Epoch: 13\tFidelity = 0.968783\tKL_Divergence = 0.014385\n",
      "Epoch: 14\tFidelity = 0.971474\tKL_Divergence = 0.010863\n",
      "Epoch: 15\tFidelity = 0.968680\tKL_Divergence = 0.014433\n",
      "Epoch: 16\tFidelity = 0.968740\tKL_Divergence = 0.014306\n",
      "Epoch: 17\tFidelity = 0.967963\tKL_Divergence = 0.015922\n",
      "Epoch: 18\tFidelity = 0.965689\tKL_Divergence = 0.018426\n",
      "Epoch: 19\tFidelity = 0.968610\tKL_Divergence = 0.013894\n",
      "Epoch: 20\tFidelity = 0.963343\tKL_Divergence = 0.022667\n",
      "Epoch: 21\tFidelity = 0.969375\tKL_Divergence = 0.013820\n",
      "Epoch: 22\tFidelity = 0.971025\tKL_Divergence = 0.011282\n",
      "Epoch: 23\tFidelity = 0.970766\tKL_Divergence = 0.011672\n",
      "Epoch: 24\tFidelity = 0.967065\tKL_Divergence = 0.016462\n",
      "Epoch: 25\tFidelity = 0.968920\tKL_Divergence = 0.014514\n",
      "Epoch: 26\tFidelity = 0.966960\tKL_Divergence = 0.017339\n",
      "Epoch: 27\tFidelity = 0.970683\tKL_Divergence = 0.010959\n",
      "Epoch: 28\tFidelity = 0.967547\tKL_Divergence = 0.015308\n",
      "Epoch: 29\tFidelity = 0.969549\tKL_Divergence = 0.011826\n",
      "Epoch: 30\tFidelity = 0.969284\tKL_Divergence = 0.012012\n",
      "Epoch: 31\tFidelity = 0.959112\tKL_Divergence = 0.028309\n",
      "Epoch: 32\tFidelity = 0.967149\tKL_Divergence = 0.016257\n",
      "Epoch: 33\tFidelity = 0.962019\tKL_Divergence = 0.023791\n",
      "Epoch: 34\tFidelity = 0.970420\tKL_Divergence = 0.011325\n",
      "Epoch: 35\tFidelity = 0.969750\tKL_Divergence = 0.012498\n",
      "Epoch: 36\tFidelity = 0.968871\tKL_Divergence = 0.013659\n",
      "Epoch: 37\tFidelity = 0.967705\tKL_Divergence = 0.014683\n",
      "Epoch: 38\tFidelity = 0.968840\tKL_Divergence = 0.012396\n",
      "Epoch: 39\tFidelity = 0.970206\tKL_Divergence = 0.011424\n",
      "Epoch: 40\tFidelity = 0.969893\tKL_Divergence = 0.011196\n",
      "Epoch: 41\tFidelity = 0.966670\tKL_Divergence = 0.016076\n",
      "Epoch: 42\tFidelity = 0.967216\tKL_Divergence = 0.015759\n",
      "Epoch: 43\tFidelity = 0.961126\tKL_Divergence = 0.023933\n",
      "Epoch: 44\tFidelity = 0.969768\tKL_Divergence = 0.012042\n",
      "Epoch: 45\tFidelity = 0.968788\tKL_Divergence = 0.013628\n",
      "Epoch: 46\tFidelity = 0.968591\tKL_Divergence = 0.013717\n",
      "Epoch: 47\tFidelity = 0.967367\tKL_Divergence = 0.015343\n",
      "Epoch: 48\tFidelity = 0.967494\tKL_Divergence = 0.015319\n",
      "Epoch: 49\tFidelity = 0.963917\tKL_Divergence = 0.020772\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:01:03,906] Trial 25 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.966651\tKL_Divergence = 0.016865\n",
      "Total time elapsed during training: 38.224 s\n",
      "Trial 25 pruned. \n",
      "Epoch: 1\tFidelity = 0.966598\tKL_Divergence = 0.016957\n",
      "Epoch: 2\tFidelity = 0.969379\tKL_Divergence = 0.012002\n",
      "Epoch: 3\tFidelity = 0.966329\tKL_Divergence = 0.016747\n",
      "Epoch: 4\tFidelity = 0.969329\tKL_Divergence = 0.012095\n",
      "Epoch: 5\tFidelity = 0.969424\tKL_Divergence = 0.011633\n",
      "Epoch: 6\tFidelity = 0.964339\tKL_Divergence = 0.020805\n",
      "Epoch: 7\tFidelity = 0.967239\tKL_Divergence = 0.016485\n",
      "Epoch: 8\tFidelity = 0.971103\tKL_Divergence = 0.010749\n",
      "Epoch: 9\tFidelity = 0.966950\tKL_Divergence = 0.016833\n",
      "Epoch: 10\tFidelity = 0.969886\tKL_Divergence = 0.011557\n",
      "Epoch: 11\tFidelity = 0.963319\tKL_Divergence = 0.021744\n",
      "Epoch: 12\tFidelity = 0.968899\tKL_Divergence = 0.013936\n",
      "Epoch: 13\tFidelity = 0.970452\tKL_Divergence = 0.011644\n",
      "Epoch: 14\tFidelity = 0.964521\tKL_Divergence = 0.019241\n",
      "Epoch: 15\tFidelity = 0.970367\tKL_Divergence = 0.010950\n",
      "Epoch: 16\tFidelity = 0.968854\tKL_Divergence = 0.013717\n",
      "Epoch: 17\tFidelity = 0.970043\tKL_Divergence = 0.011406\n",
      "Epoch: 18\tFidelity = 0.969737\tKL_Divergence = 0.012467\n",
      "Epoch: 19\tFidelity = 0.968230\tKL_Divergence = 0.014637\n",
      "Epoch: 20\tFidelity = 0.965418\tKL_Divergence = 0.018465\n",
      "Epoch: 21\tFidelity = 0.967952\tKL_Divergence = 0.014695\n",
      "Epoch: 22\tFidelity = 0.969092\tKL_Divergence = 0.012388\n",
      "Epoch: 23\tFidelity = 0.967176\tKL_Divergence = 0.016119\n",
      "Epoch: 24\tFidelity = 0.970431\tKL_Divergence = 0.011480\n",
      "Epoch: 25\tFidelity = 0.969458\tKL_Divergence = 0.013063\n",
      "Epoch: 26\tFidelity = 0.965312\tKL_Divergence = 0.019174\n",
      "Epoch: 27\tFidelity = 0.969564\tKL_Divergence = 0.012417\n",
      "Epoch: 28\tFidelity = 0.970326\tKL_Divergence = 0.011586\n",
      "Epoch: 29\tFidelity = 0.968924\tKL_Divergence = 0.013645\n",
      "Epoch: 30\tFidelity = 0.969474\tKL_Divergence = 0.012961\n",
      "Epoch: 31\tFidelity = 0.964925\tKL_Divergence = 0.019567\n",
      "Epoch: 32\tFidelity = 0.958888\tKL_Divergence = 0.028708\n",
      "Epoch: 33\tFidelity = 0.965918\tKL_Divergence = 0.018121\n",
      "Epoch: 34\tFidelity = 0.970711\tKL_Divergence = 0.011377\n",
      "Epoch: 35\tFidelity = 0.970485\tKL_Divergence = 0.011528\n",
      "Epoch: 36\tFidelity = 0.967785\tKL_Divergence = 0.014051\n",
      "Epoch: 37\tFidelity = 0.970103\tKL_Divergence = 0.011940\n",
      "Epoch: 38\tFidelity = 0.958431\tKL_Divergence = 0.029552\n",
      "Epoch: 39\tFidelity = 0.967100\tKL_Divergence = 0.017207\n",
      "Epoch: 40\tFidelity = 0.967284\tKL_Divergence = 0.017084\n",
      "Epoch: 41\tFidelity = 0.969206\tKL_Divergence = 0.013276\n",
      "Epoch: 42\tFidelity = 0.965457\tKL_Divergence = 0.019486\n",
      "Epoch: 43\tFidelity = 0.964616\tKL_Divergence = 0.020868\n",
      "Epoch: 44\tFidelity = 0.970475\tKL_Divergence = 0.012122\n",
      "Epoch: 45\tFidelity = 0.966263\tKL_Divergence = 0.018089\n",
      "Epoch: 46\tFidelity = 0.969826\tKL_Divergence = 0.012354\n",
      "Epoch: 47\tFidelity = 0.966595\tKL_Divergence = 0.017139\n",
      "Epoch: 48\tFidelity = 0.967161\tKL_Divergence = 0.017051\n",
      "Epoch: 49\tFidelity = 0.969447\tKL_Divergence = 0.013773\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:01:42,611] Trial 26 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.963603\tKL_Divergence = 0.022320\n",
      "Total time elapsed during training: 38.566 s\n",
      "Trial 26 pruned. \n",
      "Epoch: 1\tFidelity = 0.969998\tKL_Divergence = 0.012022\n",
      "Epoch: 2\tFidelity = 0.963038\tKL_Divergence = 0.023195\n",
      "Epoch: 3\tFidelity = 0.962830\tKL_Divergence = 0.023535\n",
      "Epoch: 4\tFidelity = 0.971653\tKL_Divergence = 0.010463\n",
      "Epoch: 5\tFidelity = 0.968389\tKL_Divergence = 0.014731\n",
      "Epoch: 6\tFidelity = 0.968305\tKL_Divergence = 0.015597\n",
      "Epoch: 7\tFidelity = 0.971717\tKL_Divergence = 0.010380\n",
      "Epoch: 8\tFidelity = 0.960857\tKL_Divergence = 0.026424\n",
      "Epoch: 9\tFidelity = 0.970738\tKL_Divergence = 0.011162\n",
      "Epoch: 10\tFidelity = 0.963288\tKL_Divergence = 0.022458\n",
      "Epoch: 11\tFidelity = 0.952707\tKL_Divergence = 0.037868\n",
      "Epoch: 12\tFidelity = 0.963352\tKL_Divergence = 0.022419\n",
      "Epoch: 13\tFidelity = 0.970971\tKL_Divergence = 0.010723\n",
      "Epoch: 14\tFidelity = 0.966812\tKL_Divergence = 0.015944\n",
      "Epoch: 15\tFidelity = 0.968041\tKL_Divergence = 0.015553\n",
      "Epoch: 16\tFidelity = 0.971101\tKL_Divergence = 0.010811\n",
      "Epoch: 17\tFidelity = 0.963157\tKL_Divergence = 0.022584\n",
      "Epoch: 18\tFidelity = 0.970735\tKL_Divergence = 0.011445\n",
      "Epoch: 19\tFidelity = 0.969263\tKL_Divergence = 0.011937\n",
      "Epoch: 20\tFidelity = 0.967082\tKL_Divergence = 0.015712\n",
      "Epoch: 21\tFidelity = 0.966350\tKL_Divergence = 0.017786\n",
      "Epoch: 22\tFidelity = 0.961436\tKL_Divergence = 0.024784\n",
      "Epoch: 23\tFidelity = 0.969457\tKL_Divergence = 0.013033\n",
      "Epoch: 24\tFidelity = 0.969272\tKL_Divergence = 0.013092\n",
      "Epoch: 25\tFidelity = 0.970965\tKL_Divergence = 0.010721\n",
      "Epoch: 26\tFidelity = 0.967706\tKL_Divergence = 0.015384\n",
      "Epoch: 27\tFidelity = 0.968648\tKL_Divergence = 0.014616\n",
      "Epoch: 28\tFidelity = 0.968825\tKL_Divergence = 0.013877\n",
      "Epoch: 29\tFidelity = 0.968935\tKL_Divergence = 0.013710\n",
      "Epoch: 30\tFidelity = 0.962338\tKL_Divergence = 0.022467\n",
      "Epoch: 31\tFidelity = 0.963559\tKL_Divergence = 0.021752\n",
      "Epoch: 32\tFidelity = 0.969046\tKL_Divergence = 0.012449\n",
      "Epoch: 33\tFidelity = 0.964620\tKL_Divergence = 0.019542\n",
      "Epoch: 34\tFidelity = 0.969485\tKL_Divergence = 0.012122\n",
      "Epoch: 35\tFidelity = 0.965076\tKL_Divergence = 0.019107\n",
      "Epoch: 36\tFidelity = 0.969567\tKL_Divergence = 0.012359\n",
      "Epoch: 37\tFidelity = 0.962760\tKL_Divergence = 0.022719\n",
      "Epoch: 38\tFidelity = 0.956189\tKL_Divergence = 0.032480\n",
      "Epoch: 39\tFidelity = 0.969774\tKL_Divergence = 0.012782\n",
      "Epoch: 40\tFidelity = 0.970309\tKL_Divergence = 0.011802\n",
      "Epoch: 41\tFidelity = 0.970293\tKL_Divergence = 0.011438\n",
      "Epoch: 42\tFidelity = 0.970946\tKL_Divergence = 0.010929\n",
      "Epoch: 43\tFidelity = 0.970256\tKL_Divergence = 0.011996\n",
      "Epoch: 44\tFidelity = 0.966229\tKL_Divergence = 0.017667\n",
      "Epoch: 45\tFidelity = 0.969639\tKL_Divergence = 0.012479\n",
      "Epoch: 46\tFidelity = 0.962611\tKL_Divergence = 0.022663\n",
      "Epoch: 47\tFidelity = 0.969576\tKL_Divergence = 0.011886\n",
      "Epoch: 48\tFidelity = 0.969960\tKL_Divergence = 0.011628\n",
      "Epoch: 49\tFidelity = 0.968001\tKL_Divergence = 0.015740\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:02:20,766] Trial 27 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.968404\tKL_Divergence = 0.015383\n",
      "Total time elapsed during training: 38.024 s\n",
      "Trial 27 pruned. \n",
      "Epoch: 1\tFidelity = 0.970984\tKL_Divergence = 0.011387\n",
      "Epoch: 2\tFidelity = 0.966803\tKL_Divergence = 0.017751\n",
      "Epoch: 3\tFidelity = 0.959561\tKL_Divergence = 0.028350\n",
      "Epoch: 4\tFidelity = 0.967577\tKL_Divergence = 0.016761\n",
      "Epoch: 5\tFidelity = 0.956461\tKL_Divergence = 0.033018\n",
      "Epoch: 6\tFidelity = 0.961688\tKL_Divergence = 0.025454\n",
      "Epoch: 7\tFidelity = 0.968733\tKL_Divergence = 0.015067\n",
      "Epoch: 8\tFidelity = 0.971649\tKL_Divergence = 0.010738\n",
      "Epoch: 9\tFidelity = 0.971046\tKL_Divergence = 0.011580\n",
      "Epoch: 10\tFidelity = 0.968238\tKL_Divergence = 0.015711\n",
      "Epoch: 11\tFidelity = 0.963496\tKL_Divergence = 0.022688\n",
      "Epoch: 12\tFidelity = 0.968662\tKL_Divergence = 0.015323\n",
      "Epoch: 13\tFidelity = 0.967169\tKL_Divergence = 0.017587\n",
      "Epoch: 14\tFidelity = 0.968966\tKL_Divergence = 0.014907\n",
      "Epoch: 15\tFidelity = 0.968946\tKL_Divergence = 0.014911\n",
      "Epoch: 16\tFidelity = 0.967655\tKL_Divergence = 0.016851\n",
      "Epoch: 17\tFidelity = 0.971714\tKL_Divergence = 0.010522\n",
      "Epoch: 18\tFidelity = 0.969360\tKL_Divergence = 0.013923\n",
      "Epoch: 19\tFidelity = 0.966976\tKL_Divergence = 0.017480\n",
      "Epoch: 20\tFidelity = 0.969817\tKL_Divergence = 0.013159\n",
      "Epoch: 21\tFidelity = 0.966231\tKL_Divergence = 0.018589\n",
      "Epoch: 22\tFidelity = 0.971208\tKL_Divergence = 0.011153\n",
      "Epoch: 23\tFidelity = 0.970422\tKL_Divergence = 0.012405\n",
      "Epoch: 24\tFidelity = 0.971453\tKL_Divergence = 0.010559\n",
      "Epoch: 25\tFidelity = 0.967837\tKL_Divergence = 0.015948\n",
      "Epoch: 26\tFidelity = 0.970596\tKL_Divergence = 0.011875\n",
      "Epoch: 27\tFidelity = 0.969925\tKL_Divergence = 0.012646\n",
      "Epoch: 28\tFidelity = 0.969937\tKL_Divergence = 0.012565\n",
      "Epoch: 29\tFidelity = 0.970899\tKL_Divergence = 0.010862\n",
      "Epoch: 30\tFidelity = 0.969224\tKL_Divergence = 0.013518\n",
      "Epoch: 31\tFidelity = 0.970723\tKL_Divergence = 0.011280\n",
      "Epoch: 32\tFidelity = 0.965951\tKL_Divergence = 0.018404\n",
      "Epoch: 33\tFidelity = 0.963347\tKL_Divergence = 0.022255\n",
      "Epoch: 34\tFidelity = 0.965625\tKL_Divergence = 0.018945\n",
      "Epoch: 35\tFidelity = 0.964776\tKL_Divergence = 0.020255\n",
      "Epoch: 36\tFidelity = 0.962831\tKL_Divergence = 0.023240\n",
      "Epoch: 37\tFidelity = 0.967233\tKL_Divergence = 0.016993\n",
      "Epoch: 38\tFidelity = 0.966144\tKL_Divergence = 0.018554\n",
      "Epoch: 39\tFidelity = 0.968109\tKL_Divergence = 0.015632\n",
      "Epoch: 40\tFidelity = 0.960343\tKL_Divergence = 0.027132\n",
      "Epoch: 41\tFidelity = 0.964998\tKL_Divergence = 0.020582\n",
      "Epoch: 42\tFidelity = 0.970476\tKL_Divergence = 0.012498\n",
      "Epoch: 43\tFidelity = 0.971653\tKL_Divergence = 0.010633\n",
      "Epoch: 44\tFidelity = 0.971307\tKL_Divergence = 0.011006\n",
      "Epoch: 45\tFidelity = 0.968383\tKL_Divergence = 0.015369\n",
      "Epoch: 46\tFidelity = 0.970172\tKL_Divergence = 0.012630\n",
      "Epoch: 47\tFidelity = 0.971351\tKL_Divergence = 0.010561\n",
      "Epoch: 48\tFidelity = 0.967870\tKL_Divergence = 0.015812\n",
      "Epoch: 49\tFidelity = 0.967589\tKL_Divergence = 0.016280\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:02:52,499] Trial 28 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.966743\tKL_Divergence = 0.017602\n",
      "Total time elapsed during training: 31.588 s\n",
      "Trial 28 pruned. \n",
      "Epoch: 1\tFidelity = 0.969463\tKL_Divergence = 0.013412\n",
      "Epoch: 2\tFidelity = 0.967326\tKL_Divergence = 0.016497\n",
      "Epoch: 3\tFidelity = 0.964071\tKL_Divergence = 0.021379\n",
      "Epoch: 4\tFidelity = 0.963820\tKL_Divergence = 0.021444\n",
      "Epoch: 5\tFidelity = 0.966846\tKL_Divergence = 0.017425\n",
      "Epoch: 6\tFidelity = 0.967035\tKL_Divergence = 0.016489\n",
      "Epoch: 7\tFidelity = 0.969824\tKL_Divergence = 0.011367\n",
      "Epoch: 8\tFidelity = 0.970283\tKL_Divergence = 0.011336\n",
      "Epoch: 9\tFidelity = 0.968938\tKL_Divergence = 0.013571\n",
      "Epoch: 10\tFidelity = 0.968031\tKL_Divergence = 0.015037\n",
      "Epoch: 11\tFidelity = 0.969111\tKL_Divergence = 0.013583\n",
      "Epoch: 12\tFidelity = 0.965516\tKL_Divergence = 0.018864\n",
      "Epoch: 13\tFidelity = 0.962162\tKL_Divergence = 0.023700\n",
      "Epoch: 14\tFidelity = 0.963087\tKL_Divergence = 0.021851\n",
      "Epoch: 15\tFidelity = 0.965899\tKL_Divergence = 0.017596\n",
      "Epoch: 16\tFidelity = 0.969525\tKL_Divergence = 0.012846\n",
      "Epoch: 17\tFidelity = 0.969138\tKL_Divergence = 0.013726\n",
      "Epoch: 18\tFidelity = 0.970682\tKL_Divergence = 0.011687\n",
      "Epoch: 19\tFidelity = 0.969345\tKL_Divergence = 0.012745\n",
      "Epoch: 20\tFidelity = 0.969538\tKL_Divergence = 0.013384\n",
      "Epoch: 21\tFidelity = 0.970411\tKL_Divergence = 0.011560\n",
      "Epoch: 22\tFidelity = 0.970317\tKL_Divergence = 0.011725\n",
      "Epoch: 23\tFidelity = 0.962555\tKL_Divergence = 0.023458\n",
      "Epoch: 24\tFidelity = 0.967821\tKL_Divergence = 0.014791\n",
      "Epoch: 25\tFidelity = 0.969529\tKL_Divergence = 0.012887\n",
      "Epoch: 26\tFidelity = 0.969589\tKL_Divergence = 0.012988\n",
      "Epoch: 27\tFidelity = 0.968893\tKL_Divergence = 0.014106\n",
      "Epoch: 28\tFidelity = 0.968095\tKL_Divergence = 0.015343\n",
      "Epoch: 29\tFidelity = 0.967377\tKL_Divergence = 0.016759\n",
      "Epoch: 30\tFidelity = 0.957370\tKL_Divergence = 0.030449\n",
      "Epoch: 31\tFidelity = 0.967504\tKL_Divergence = 0.016191\n",
      "Epoch: 32\tFidelity = 0.971448\tKL_Divergence = 0.010596\n",
      "Epoch: 33\tFidelity = 0.969565\tKL_Divergence = 0.013284\n",
      "Epoch: 34\tFidelity = 0.964769\tKL_Divergence = 0.020337\n",
      "Epoch: 35\tFidelity = 0.960173\tKL_Divergence = 0.027267\n",
      "Epoch: 36\tFidelity = 0.959682\tKL_Divergence = 0.028029\n",
      "Epoch: 37\tFidelity = 0.967188\tKL_Divergence = 0.017022\n",
      "Epoch: 38\tFidelity = 0.965042\tKL_Divergence = 0.020486\n",
      "Epoch: 39\tFidelity = 0.966948\tKL_Divergence = 0.017760\n",
      "Epoch: 40\tFidelity = 0.969594\tKL_Divergence = 0.013320\n",
      "Epoch: 41\tFidelity = 0.971466\tKL_Divergence = 0.010751\n",
      "Epoch: 42\tFidelity = 0.966709\tKL_Divergence = 0.017861\n",
      "Epoch: 43\tFidelity = 0.970853\tKL_Divergence = 0.011142\n",
      "Epoch: 44\tFidelity = 0.969708\tKL_Divergence = 0.013843\n",
      "Epoch: 45\tFidelity = 0.965183\tKL_Divergence = 0.018785\n",
      "Epoch: 46\tFidelity = 0.971029\tKL_Divergence = 0.011569\n",
      "Epoch: 47\tFidelity = 0.970027\tKL_Divergence = 0.012986\n",
      "Epoch: 48\tFidelity = 0.970989\tKL_Divergence = 0.011772\n",
      "Epoch: 49\tFidelity = 0.971296\tKL_Divergence = 0.010725\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:03:30,773] Trial 29 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.967793\tKL_Divergence = 0.015869\n",
      "Total time elapsed during training: 38.131 s\n",
      "Trial 29 pruned. \n",
      "Epoch: 1\tFidelity = 0.960432\tKL_Divergence = 0.024859\n",
      "Epoch: 2\tFidelity = 0.971828\tKL_Divergence = 0.010903\n",
      "Epoch: 3\tFidelity = 0.960397\tKL_Divergence = 0.027610\n",
      "Epoch: 4\tFidelity = 0.970317\tKL_Divergence = 0.013191\n",
      "Epoch: 5\tFidelity = 0.971544\tKL_Divergence = 0.010811\n",
      "Epoch: 6\tFidelity = 0.969490\tKL_Divergence = 0.012031\n",
      "Epoch: 7\tFidelity = 0.959198\tKL_Divergence = 0.028859\n",
      "Epoch: 8\tFidelity = 0.956269\tKL_Divergence = 0.033591\n",
      "Epoch: 9\tFidelity = 0.964294\tKL_Divergence = 0.020481\n",
      "Epoch: 10\tFidelity = 0.966768\tKL_Divergence = 0.016395\n",
      "Epoch: 11\tFidelity = 0.963926\tKL_Divergence = 0.021221\n",
      "Epoch: 12\tFidelity = 0.971467\tKL_Divergence = 0.010811\n",
      "Epoch: 13\tFidelity = 0.965893\tKL_Divergence = 0.018912\n",
      "Epoch: 14\tFidelity = 0.967929\tKL_Divergence = 0.016608\n",
      "Epoch: 15\tFidelity = 0.968478\tKL_Divergence = 0.015367\n",
      "Epoch: 16\tFidelity = 0.966108\tKL_Divergence = 0.018707\n",
      "Epoch: 17\tFidelity = 0.968601\tKL_Divergence = 0.016608\n",
      "Epoch: 18\tFidelity = 0.971852\tKL_Divergence = 0.010997\n",
      "Epoch: 19\tFidelity = 0.971720\tKL_Divergence = 0.010667\n",
      "Epoch: 20\tFidelity = 0.970568\tKL_Divergence = 0.011943\n",
      "Epoch: 21\tFidelity = 0.963535\tKL_Divergence = 0.021000\n",
      "Epoch: 22\tFidelity = 0.971901\tKL_Divergence = 0.010467\n",
      "Epoch: 23\tFidelity = 0.968301\tKL_Divergence = 0.014036\n",
      "Epoch: 24\tFidelity = 0.962491\tKL_Divergence = 0.022602\n",
      "Epoch: 25\tFidelity = 0.971667\tKL_Divergence = 0.010446\n",
      "Epoch: 26\tFidelity = 0.967868\tKL_Divergence = 0.016393\n",
      "Epoch: 27\tFidelity = 0.964019\tKL_Divergence = 0.022196\n",
      "Epoch: 28\tFidelity = 0.966938\tKL_Divergence = 0.017720\n",
      "Epoch: 29\tFidelity = 0.971489\tKL_Divergence = 0.011058\n",
      "Epoch: 30\tFidelity = 0.970461\tKL_Divergence = 0.012961\n",
      "Epoch: 31\tFidelity = 0.969195\tKL_Divergence = 0.014767\n",
      "Epoch: 32\tFidelity = 0.971039\tKL_Divergence = 0.011771\n",
      "Epoch: 33\tFidelity = 0.969740\tKL_Divergence = 0.011809\n",
      "Epoch: 34\tFidelity = 0.969650\tKL_Divergence = 0.013984\n",
      "Epoch: 35\tFidelity = 0.969288\tKL_Divergence = 0.014719\n",
      "Epoch: 36\tFidelity = 0.971172\tKL_Divergence = 0.011107\n",
      "Epoch: 37\tFidelity = 0.969317\tKL_Divergence = 0.013346\n",
      "Epoch: 38\tFidelity = 0.970883\tKL_Divergence = 0.011741\n",
      "Epoch: 39\tFidelity = 0.967463\tKL_Divergence = 0.017223\n",
      "Epoch: 40\tFidelity = 0.965368\tKL_Divergence = 0.020339\n",
      "Epoch: 41\tFidelity = 0.961078\tKL_Divergence = 0.026477\n",
      "Epoch: 42\tFidelity = 0.963844\tKL_Divergence = 0.022184\n",
      "Epoch: 43\tFidelity = 0.972154\tKL_Divergence = 0.010511\n",
      "Epoch: 44\tFidelity = 0.970019\tKL_Divergence = 0.013659\n",
      "Epoch: 45\tFidelity = 0.970218\tKL_Divergence = 0.012847\n",
      "Epoch: 46\tFidelity = 0.964079\tKL_Divergence = 0.019155\n",
      "Epoch: 47\tFidelity = 0.957592\tKL_Divergence = 0.030121\n",
      "Epoch: 48\tFidelity = 0.963212\tKL_Divergence = 0.024020\n",
      "Epoch: 49\tFidelity = 0.972460\tKL_Divergence = 0.010720\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:04:28,935] Trial 30 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.963987\tKL_Divergence = 0.023596\n",
      "Total time elapsed during training: 57.689 s\n",
      "Trial 30 pruned. \n",
      "Epoch: 1\tFidelity = 0.971540\tKL_Divergence = 0.011944\n",
      "Epoch: 2\tFidelity = 0.960101\tKL_Divergence = 0.024046\n",
      "Epoch: 3\tFidelity = 0.967252\tKL_Divergence = 0.017075\n",
      "Epoch: 4\tFidelity = 0.971568\tKL_Divergence = 0.011424\n",
      "Epoch: 5\tFidelity = 0.961722\tKL_Divergence = 0.025642\n",
      "Epoch: 6\tFidelity = 0.970109\tKL_Divergence = 0.014722\n",
      "Epoch: 7\tFidelity = 0.968890\tKL_Divergence = 0.016243\n",
      "Epoch: 8\tFidelity = 0.969501\tKL_Divergence = 0.015395\n",
      "Epoch: 9\tFidelity = 0.969748\tKL_Divergence = 0.014457\n",
      "Epoch: 10\tFidelity = 0.972113\tKL_Divergence = 0.010923\n",
      "Epoch: 11\tFidelity = 0.970185\tKL_Divergence = 0.013282\n",
      "Epoch: 12\tFidelity = 0.961788\tKL_Divergence = 0.024581\n",
      "Epoch: 13\tFidelity = 0.957744\tKL_Divergence = 0.031241\n",
      "Epoch: 14\tFidelity = 0.961178\tKL_Divergence = 0.026179\n",
      "Epoch: 15\tFidelity = 0.972071\tKL_Divergence = 0.011379\n",
      "Epoch: 16\tFidelity = 0.966222\tKL_Divergence = 0.019142\n",
      "Epoch: 17\tFidelity = 0.966937\tKL_Divergence = 0.018910\n",
      "Epoch: 18\tFidelity = 0.969404\tKL_Divergence = 0.014801\n",
      "Epoch: 19\tFidelity = 0.971202\tKL_Divergence = 0.012330\n",
      "Epoch: 20\tFidelity = 0.964699\tKL_Divergence = 0.021785\n",
      "Epoch: 21\tFidelity = 0.958875\tKL_Divergence = 0.029807\n",
      "Epoch: 22\tFidelity = 0.966437\tKL_Divergence = 0.017763\n",
      "Epoch: 23\tFidelity = 0.955312\tKL_Divergence = 0.035011\n",
      "Epoch: 24\tFidelity = 0.971509\tKL_Divergence = 0.011179\n",
      "Epoch: 25\tFidelity = 0.966752\tKL_Divergence = 0.018064\n",
      "Epoch: 26\tFidelity = 0.971952\tKL_Divergence = 0.010953\n",
      "Epoch: 27\tFidelity = 0.967298\tKL_Divergence = 0.017120\n",
      "Epoch: 28\tFidelity = 0.971410\tKL_Divergence = 0.011619\n",
      "Epoch: 29\tFidelity = 0.972058\tKL_Divergence = 0.010893\n",
      "Epoch: 30\tFidelity = 0.971088\tKL_Divergence = 0.011713\n",
      "Epoch: 31\tFidelity = 0.968768\tKL_Divergence = 0.013564\n",
      "Epoch: 32\tFidelity = 0.962993\tKL_Divergence = 0.022954\n",
      "Epoch: 33\tFidelity = 0.963624\tKL_Divergence = 0.021840\n",
      "Epoch: 34\tFidelity = 0.969991\tKL_Divergence = 0.013464\n",
      "Epoch: 35\tFidelity = 0.960037\tKL_Divergence = 0.026832\n",
      "Epoch: 36\tFidelity = 0.969171\tKL_Divergence = 0.015150\n",
      "Epoch: 37\tFidelity = 0.969855\tKL_Divergence = 0.012907\n",
      "Epoch: 38\tFidelity = 0.967065\tKL_Divergence = 0.018454\n",
      "Epoch: 39\tFidelity = 0.969703\tKL_Divergence = 0.014860\n",
      "Epoch: 40\tFidelity = 0.959406\tKL_Divergence = 0.030132\n",
      "Epoch: 41\tFidelity = 0.970898\tKL_Divergence = 0.013485\n",
      "Epoch: 42\tFidelity = 0.971206\tKL_Divergence = 0.012937\n",
      "Epoch: 43\tFidelity = 0.964592\tKL_Divergence = 0.022959\n",
      "Epoch: 44\tFidelity = 0.966354\tKL_Divergence = 0.020350\n",
      "Epoch: 45\tFidelity = 0.964884\tKL_Divergence = 0.021970\n",
      "Epoch: 46\tFidelity = 0.962860\tKL_Divergence = 0.025583\n",
      "Epoch: 47\tFidelity = 0.969010\tKL_Divergence = 0.016941\n",
      "Epoch: 48\tFidelity = 0.969455\tKL_Divergence = 0.015600\n",
      "Epoch: 49\tFidelity = 0.966057\tKL_Divergence = 0.018655\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:05:12,907] Trial 31 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.970255\tKL_Divergence = 0.014039\n",
      "Total time elapsed during training: 43.837 s\n",
      "Trial 31 pruned. \n",
      "Epoch: 1\tFidelity = 0.963705\tKL_Divergence = 0.022928\n",
      "Epoch: 2\tFidelity = 0.971138\tKL_Divergence = 0.012225\n",
      "Epoch: 3\tFidelity = 0.972676\tKL_Divergence = 0.010240\n",
      "Epoch: 4\tFidelity = 0.970703\tKL_Divergence = 0.012698\n",
      "Epoch: 5\tFidelity = 0.971635\tKL_Divergence = 0.010732\n",
      "Epoch: 6\tFidelity = 0.968013\tKL_Divergence = 0.017039\n",
      "Epoch: 7\tFidelity = 0.970189\tKL_Divergence = 0.013922\n",
      "Epoch: 8\tFidelity = 0.967736\tKL_Divergence = 0.016244\n",
      "Epoch: 9\tFidelity = 0.964878\tKL_Divergence = 0.021097\n",
      "Epoch: 10\tFidelity = 0.968812\tKL_Divergence = 0.015486\n",
      "Epoch: 11\tFidelity = 0.971563\tKL_Divergence = 0.010992\n",
      "Epoch: 12\tFidelity = 0.971096\tKL_Divergence = 0.010718\n",
      "Epoch: 13\tFidelity = 0.970921\tKL_Divergence = 0.011445\n",
      "Epoch: 14\tFidelity = 0.968251\tKL_Divergence = 0.015314\n",
      "Epoch: 15\tFidelity = 0.970204\tKL_Divergence = 0.011383\n",
      "Epoch: 16\tFidelity = 0.968899\tKL_Divergence = 0.014434\n",
      "Epoch: 17\tFidelity = 0.964756\tKL_Divergence = 0.020437\n",
      "Epoch: 18\tFidelity = 0.971007\tKL_Divergence = 0.011472\n",
      "Epoch: 19\tFidelity = 0.967122\tKL_Divergence = 0.016989\n",
      "Epoch: 20\tFidelity = 0.965863\tKL_Divergence = 0.018898\n",
      "Epoch: 21\tFidelity = 0.971152\tKL_Divergence = 0.011466\n",
      "Epoch: 22\tFidelity = 0.969886\tKL_Divergence = 0.011794\n",
      "Epoch: 23\tFidelity = 0.966045\tKL_Divergence = 0.018256\n",
      "Epoch: 24\tFidelity = 0.966282\tKL_Divergence = 0.017340\n",
      "Epoch: 25\tFidelity = 0.965593\tKL_Divergence = 0.018290\n",
      "Epoch: 26\tFidelity = 0.968766\tKL_Divergence = 0.014437\n",
      "Epoch: 27\tFidelity = 0.964270\tKL_Divergence = 0.020160\n",
      "Epoch: 28\tFidelity = 0.969331\tKL_Divergence = 0.013223\n",
      "Epoch: 29\tFidelity = 0.969502\tKL_Divergence = 0.013647\n",
      "Epoch: 30\tFidelity = 0.967009\tKL_Divergence = 0.016716\n",
      "Epoch: 31\tFidelity = 0.965096\tKL_Divergence = 0.018285\n",
      "Epoch: 32\tFidelity = 0.970462\tKL_Divergence = 0.011370\n",
      "Epoch: 33\tFidelity = 0.967254\tKL_Divergence = 0.016100\n",
      "Epoch: 34\tFidelity = 0.958655\tKL_Divergence = 0.028859\n",
      "Epoch: 35\tFidelity = 0.960064\tKL_Divergence = 0.026846\n",
      "Epoch: 36\tFidelity = 0.955767\tKL_Divergence = 0.032104\n",
      "Epoch: 37\tFidelity = 0.968498\tKL_Divergence = 0.015030\n",
      "Epoch: 38\tFidelity = 0.966994\tKL_Divergence = 0.017134\n",
      "Epoch: 39\tFidelity = 0.967541\tKL_Divergence = 0.016314\n",
      "Epoch: 40\tFidelity = 0.967923\tKL_Divergence = 0.013149\n",
      "Epoch: 41\tFidelity = 0.969325\tKL_Divergence = 0.013110\n",
      "Epoch: 42\tFidelity = 0.971467\tKL_Divergence = 0.010695\n",
      "Epoch: 43\tFidelity = 0.964337\tKL_Divergence = 0.018549\n",
      "Epoch: 44\tFidelity = 0.965050\tKL_Divergence = 0.020496\n",
      "Epoch: 45\tFidelity = 0.960780\tKL_Divergence = 0.025259\n",
      "Epoch: 46\tFidelity = 0.967396\tKL_Divergence = 0.017252\n",
      "Epoch: 47\tFidelity = 0.966998\tKL_Divergence = 0.016825\n",
      "Epoch: 48\tFidelity = 0.971761\tKL_Divergence = 0.010672\n",
      "Epoch: 49\tFidelity = 0.968782\tKL_Divergence = 0.012747\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:05:51,519] Trial 32 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.964855\tKL_Divergence = 0.018240\n",
      "Total time elapsed during training: 38.480 s\n",
      "Trial 32 pruned. \n",
      "Epoch: 1\tFidelity = 0.963824\tKL_Divergence = 0.022635\n",
      "Epoch: 2\tFidelity = 0.950291\tKL_Divergence = 0.042747\n",
      "Epoch: 3\tFidelity = 0.964734\tKL_Divergence = 0.021800\n",
      "Epoch: 4\tFidelity = 0.972305\tKL_Divergence = 0.010885\n",
      "Epoch: 5\tFidelity = 0.964737\tKL_Divergence = 0.021707\n",
      "Epoch: 6\tFidelity = 0.972324\tKL_Divergence = 0.010557\n",
      "Epoch: 7\tFidelity = 0.967035\tKL_Divergence = 0.018149\n",
      "Epoch: 8\tFidelity = 0.959432\tKL_Divergence = 0.029123\n",
      "Epoch: 9\tFidelity = 0.947892\tKL_Divergence = 0.046354\n",
      "Epoch: 10\tFidelity = 0.970383\tKL_Divergence = 0.013843\n",
      "Epoch: 11\tFidelity = 0.964692\tKL_Divergence = 0.021776\n",
      "Epoch: 12\tFidelity = 0.970988\tKL_Divergence = 0.012808\n",
      "Epoch: 13\tFidelity = 0.966716\tKL_Divergence = 0.018947\n",
      "Epoch: 14\tFidelity = 0.953713\tKL_Divergence = 0.037918\n",
      "Epoch: 15\tFidelity = 0.962601\tKL_Divergence = 0.025299\n",
      "Epoch: 16\tFidelity = 0.969111\tKL_Divergence = 0.016199\n",
      "Epoch: 17\tFidelity = 0.957169\tKL_Divergence = 0.033659\n",
      "Epoch: 18\tFidelity = 0.950160\tKL_Divergence = 0.044091\n",
      "Epoch: 19\tFidelity = 0.970457\tKL_Divergence = 0.014742\n",
      "Epoch: 20\tFidelity = 0.963362\tKL_Divergence = 0.024973\n",
      "Epoch: 21\tFidelity = 0.957345\tKL_Divergence = 0.033687\n",
      "Epoch: 22\tFidelity = 0.952692\tKL_Divergence = 0.040783\n",
      "Epoch: 23\tFidelity = 0.963406\tKL_Divergence = 0.025381\n",
      "Epoch: 24\tFidelity = 0.972512\tKL_Divergence = 0.012262\n",
      "Epoch: 25\tFidelity = 0.960341\tKL_Divergence = 0.029869\n",
      "Epoch: 26\tFidelity = 0.973873\tKL_Divergence = 0.010469\n",
      "Epoch: 27\tFidelity = 0.973268\tKL_Divergence = 0.010682\n",
      "Epoch: 28\tFidelity = 0.973152\tKL_Divergence = 0.010942\n",
      "Epoch: 29\tFidelity = 0.971412\tKL_Divergence = 0.012868\n",
      "Epoch: 30\tFidelity = 0.970938\tKL_Divergence = 0.013635\n",
      "Epoch: 31\tFidelity = 0.968997\tKL_Divergence = 0.016607\n",
      "Epoch: 32\tFidelity = 0.972957\tKL_Divergence = 0.010285\n",
      "Epoch: 33\tFidelity = 0.959515\tKL_Divergence = 0.030005\n",
      "Epoch: 34\tFidelity = 0.956290\tKL_Divergence = 0.034761\n",
      "Epoch: 35\tFidelity = 0.956925\tKL_Divergence = 0.034123\n",
      "Epoch: 36\tFidelity = 0.969320\tKL_Divergence = 0.015959\n",
      "Epoch: 37\tFidelity = 0.973168\tKL_Divergence = 0.010489\n",
      "Epoch: 38\tFidelity = 0.971911\tKL_Divergence = 0.011851\n",
      "Epoch: 39\tFidelity = 0.973039\tKL_Divergence = 0.010265\n",
      "Epoch: 40\tFidelity = 0.972560\tKL_Divergence = 0.010465\n",
      "Epoch: 41\tFidelity = 0.958954\tKL_Divergence = 0.030621\n",
      "Epoch: 42\tFidelity = 0.957156\tKL_Divergence = 0.032991\n",
      "Epoch: 43\tFidelity = 0.956533\tKL_Divergence = 0.034082\n",
      "Epoch: 44\tFidelity = 0.945250\tKL_Divergence = 0.050328\n",
      "Epoch: 45\tFidelity = 0.964733\tKL_Divergence = 0.022276\n",
      "Epoch: 46\tFidelity = 0.956646\tKL_Divergence = 0.033512\n",
      "Epoch: 47\tFidelity = 0.964585\tKL_Divergence = 0.022651\n",
      "Epoch: 48\tFidelity = 0.958531\tKL_Divergence = 0.031062\n",
      "Epoch: 49\tFidelity = 0.966518\tKL_Divergence = 0.019926\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:06:24,796] Trial 33 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.961131\tKL_Divergence = 0.027250\n",
      "Total time elapsed during training: 33.135 s\n",
      "Trial 33 pruned. \n",
      "Epoch: 1\tFidelity = 0.970729\tKL_Divergence = 0.014344\n",
      "Epoch: 2\tFidelity = 0.973173\tKL_Divergence = 0.010210\n",
      "Epoch: 3\tFidelity = 0.972185\tKL_Divergence = 0.011489\n",
      "Epoch: 4\tFidelity = 0.970465\tKL_Divergence = 0.013268\n",
      "Epoch: 5\tFidelity = 0.971783\tKL_Divergence = 0.011028\n",
      "Epoch: 6\tFidelity = 0.969682\tKL_Divergence = 0.014260\n",
      "Epoch: 7\tFidelity = 0.969804\tKL_Divergence = 0.013930\n",
      "Epoch: 8\tFidelity = 0.969110\tKL_Divergence = 0.015078\n",
      "Epoch: 9\tFidelity = 0.969148\tKL_Divergence = 0.014957\n",
      "Epoch: 10\tFidelity = 0.966657\tKL_Divergence = 0.018227\n",
      "Epoch: 11\tFidelity = 0.963014\tKL_Divergence = 0.024019\n",
      "Epoch: 12\tFidelity = 0.963251\tKL_Divergence = 0.023741\n",
      "Epoch: 13\tFidelity = 0.970894\tKL_Divergence = 0.012471\n",
      "Epoch: 14\tFidelity = 0.970462\tKL_Divergence = 0.013248\n",
      "Epoch: 15\tFidelity = 0.964290\tKL_Divergence = 0.022409\n",
      "Epoch: 16\tFidelity = 0.967237\tKL_Divergence = 0.017866\n",
      "Epoch: 17\tFidelity = 0.959329\tKL_Divergence = 0.029629\n",
      "Epoch: 18\tFidelity = 0.965565\tKL_Divergence = 0.020278\n",
      "Epoch: 19\tFidelity = 0.969834\tKL_Divergence = 0.014209\n",
      "Epoch: 20\tFidelity = 0.962467\tKL_Divergence = 0.025115\n",
      "Epoch: 21\tFidelity = 0.967597\tKL_Divergence = 0.017171\n",
      "Epoch: 22\tFidelity = 0.971269\tKL_Divergence = 0.012316\n",
      "Epoch: 23\tFidelity = 0.971354\tKL_Divergence = 0.012220\n",
      "Epoch: 24\tFidelity = 0.971713\tKL_Divergence = 0.011090\n",
      "Epoch: 25\tFidelity = 0.969870\tKL_Divergence = 0.012899\n",
      "Epoch: 26\tFidelity = 0.968065\tKL_Divergence = 0.015791\n",
      "Epoch: 27\tFidelity = 0.971797\tKL_Divergence = 0.011136\n",
      "Epoch: 28\tFidelity = 0.969797\tKL_Divergence = 0.013838\n",
      "Epoch: 29\tFidelity = 0.970965\tKL_Divergence = 0.012099\n",
      "Epoch: 30\tFidelity = 0.966663\tKL_Divergence = 0.018360\n",
      "Epoch: 31\tFidelity = 0.971571\tKL_Divergence = 0.010730\n",
      "Epoch: 32\tFidelity = 0.970031\tKL_Divergence = 0.011533\n",
      "Epoch: 33\tFidelity = 0.970943\tKL_Divergence = 0.011502\n",
      "Epoch: 34\tFidelity = 0.970982\tKL_Divergence = 0.011469\n",
      "Epoch: 35\tFidelity = 0.970261\tKL_Divergence = 0.012252\n",
      "Epoch: 36\tFidelity = 0.970785\tKL_Divergence = 0.011582\n",
      "Epoch: 37\tFidelity = 0.965770\tKL_Divergence = 0.018971\n",
      "Epoch: 38\tFidelity = 0.965193\tKL_Divergence = 0.019507\n",
      "Epoch: 39\tFidelity = 0.962834\tKL_Divergence = 0.021923\n",
      "Epoch: 40\tFidelity = 0.968670\tKL_Divergence = 0.014564\n",
      "Epoch: 41\tFidelity = 0.968568\tKL_Divergence = 0.014898\n",
      "Epoch: 42\tFidelity = 0.969376\tKL_Divergence = 0.014128\n",
      "Epoch: 43\tFidelity = 0.962504\tKL_Divergence = 0.024076\n",
      "Epoch: 44\tFidelity = 0.966160\tKL_Divergence = 0.018677\n",
      "Epoch: 45\tFidelity = 0.970455\tKL_Divergence = 0.012361\n",
      "Epoch: 46\tFidelity = 0.970761\tKL_Divergence = 0.011815\n",
      "Epoch: 47\tFidelity = 0.970125\tKL_Divergence = 0.012634\n",
      "Epoch: 48\tFidelity = 0.969500\tKL_Divergence = 0.013692\n",
      "Epoch: 49\tFidelity = 0.970944\tKL_Divergence = 0.011433\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:07:05,457] Trial 34 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.967795\tKL_Divergence = 0.016055\n",
      "Total time elapsed during training: 40.507 s\n",
      "Trial 34 pruned. \n",
      "Epoch: 1\tFidelity = 0.967345\tKL_Divergence = 0.014782\n",
      "Epoch: 2\tFidelity = 0.970213\tKL_Divergence = 0.013015\n",
      "Epoch: 3\tFidelity = 0.967884\tKL_Divergence = 0.014497\n",
      "Epoch: 4\tFidelity = 0.967281\tKL_Divergence = 0.015831\n",
      "Epoch: 5\tFidelity = 0.967908\tKL_Divergence = 0.017465\n",
      "Epoch: 6\tFidelity = 0.972582\tKL_Divergence = 0.010858\n",
      "Epoch: 7\tFidelity = 0.959354\tKL_Divergence = 0.030466\n",
      "Epoch: 8\tFidelity = 0.965381\tKL_Divergence = 0.020439\n",
      "Epoch: 9\tFidelity = 0.960240\tKL_Divergence = 0.025523\n",
      "Epoch: 10\tFidelity = 0.968839\tKL_Divergence = 0.016488\n",
      "Epoch: 11\tFidelity = 0.972530\tKL_Divergence = 0.010521\n",
      "Epoch: 12\tFidelity = 0.960696\tKL_Divergence = 0.026176\n",
      "Epoch: 13\tFidelity = 0.968366\tKL_Divergence = 0.013417\n",
      "Epoch: 14\tFidelity = 0.955455\tKL_Divergence = 0.035154\n",
      "Epoch: 15\tFidelity = 0.963512\tKL_Divergence = 0.021027\n",
      "Epoch: 16\tFidelity = 0.972410\tKL_Divergence = 0.012036\n",
      "Epoch: 17\tFidelity = 0.972809\tKL_Divergence = 0.010510\n",
      "Epoch: 18\tFidelity = 0.961051\tKL_Divergence = 0.028635\n",
      "Epoch: 19\tFidelity = 0.959613\tKL_Divergence = 0.030146\n",
      "Epoch: 20\tFidelity = 0.968716\tKL_Divergence = 0.015477\n",
      "Epoch: 21\tFidelity = 0.959186\tKL_Divergence = 0.028270\n",
      "Epoch: 22\tFidelity = 0.972875\tKL_Divergence = 0.010803\n",
      "Epoch: 23\tFidelity = 0.966141\tKL_Divergence = 0.018774\n",
      "Epoch: 24\tFidelity = 0.968310\tKL_Divergence = 0.017271\n",
      "Epoch: 25\tFidelity = 0.965620\tKL_Divergence = 0.021854\n",
      "Epoch: 26\tFidelity = 0.966232\tKL_Divergence = 0.014860\n",
      "Epoch: 27\tFidelity = 0.959051\tKL_Divergence = 0.028623\n",
      "Epoch: 28\tFidelity = 0.968347\tKL_Divergence = 0.017760\n",
      "Epoch: 29\tFidelity = 0.959775\tKL_Divergence = 0.030164\n",
      "Epoch: 30\tFidelity = 0.963301\tKL_Divergence = 0.018713\n",
      "Epoch: 31\tFidelity = 0.954970\tKL_Divergence = 0.036059\n",
      "Epoch: 32\tFidelity = 0.946974\tKL_Divergence = 0.045155\n",
      "Epoch: 33\tFidelity = 0.957064\tKL_Divergence = 0.034044\n",
      "Epoch: 34\tFidelity = 0.973566\tKL_Divergence = 0.010405\n",
      "Epoch: 35\tFidelity = 0.969427\tKL_Divergence = 0.016269\n",
      "Epoch: 36\tFidelity = 0.972912\tKL_Divergence = 0.010678\n",
      "Epoch: 37\tFidelity = 0.946977\tKL_Divergence = 0.042353\n",
      "Epoch: 38\tFidelity = 0.964456\tKL_Divergence = 0.019164\n",
      "Epoch: 39\tFidelity = 0.969010\tKL_Divergence = 0.014744\n",
      "Epoch: 40\tFidelity = 0.968200\tKL_Divergence = 0.017398\n",
      "Epoch: 41\tFidelity = 0.965485\tKL_Divergence = 0.017463\n",
      "Epoch: 42\tFidelity = 0.963609\tKL_Divergence = 0.020008\n",
      "Epoch: 43\tFidelity = 0.965899\tKL_Divergence = 0.020461\n",
      "Epoch: 44\tFidelity = 0.965104\tKL_Divergence = 0.018561\n",
      "Epoch: 45\tFidelity = 0.972689\tKL_Divergence = 0.010714\n",
      "Epoch: 46\tFidelity = 0.959525\tKL_Divergence = 0.023261\n",
      "Epoch: 47\tFidelity = 0.961934\tKL_Divergence = 0.023841\n",
      "Epoch: 48\tFidelity = 0.968530\tKL_Divergence = 0.014825\n",
      "Epoch: 49\tFidelity = 0.970937\tKL_Divergence = 0.011614\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:07:45,796] Trial 35 finished with value: 0.011109409178955802 and parameters: {'lr': 7.807746253884792, 'pbs': 8000, 'nbs': 8000}. Best is trial 24 with value: 0.010929923347822168.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.971175\tKL_Divergence = 0.011109\n",
      "Total time elapsed during training: 40.188 s\n",
      "Trial 35 finished with value: 0.011109409178955802 and parameters: {'lr': 7.807746253884792, 'pbs': 8000, 'nbs': 8000}. Best is trial 24 with value: 0.010929923347822168.\n",
      "Epoch: 1\tFidelity = 0.970251\tKL_Divergence = 0.012407\n",
      "Epoch: 2\tFidelity = 0.963001\tKL_Divergence = 0.022901\n",
      "Epoch: 3\tFidelity = 0.968316\tKL_Divergence = 0.015414\n",
      "Epoch: 4\tFidelity = 0.969635\tKL_Divergence = 0.014102\n",
      "Epoch: 5\tFidelity = 0.963017\tKL_Divergence = 0.023519\n",
      "Epoch: 6\tFidelity = 0.969514\tKL_Divergence = 0.014592\n",
      "Epoch: 7\tFidelity = 0.971882\tKL_Divergence = 0.010983\n",
      "Epoch: 8\tFidelity = 0.971023\tKL_Divergence = 0.011720\n",
      "Epoch: 9\tFidelity = 0.968254\tKL_Divergence = 0.013053\n",
      "Epoch: 10\tFidelity = 0.966551\tKL_Divergence = 0.015934\n",
      "Epoch: 11\tFidelity = 0.969114\tKL_Divergence = 0.015275\n",
      "Epoch: 12\tFidelity = 0.966984\tKL_Divergence = 0.017410\n",
      "Epoch: 13\tFidelity = 0.966603\tKL_Divergence = 0.019387\n",
      "Epoch: 14\tFidelity = 0.969428\tKL_Divergence = 0.014131\n",
      "Epoch: 15\tFidelity = 0.968241\tKL_Divergence = 0.016072\n",
      "Epoch: 16\tFidelity = 0.969758\tKL_Divergence = 0.014562\n",
      "Epoch: 17\tFidelity = 0.969983\tKL_Divergence = 0.013275\n",
      "Epoch: 18\tFidelity = 0.966944\tKL_Divergence = 0.018795\n",
      "Epoch: 19\tFidelity = 0.969992\tKL_Divergence = 0.012198\n",
      "Epoch: 20\tFidelity = 0.964289\tKL_Divergence = 0.019460\n",
      "Epoch: 21\tFidelity = 0.965422\tKL_Divergence = 0.020750\n",
      "Epoch: 22\tFidelity = 0.968123\tKL_Divergence = 0.017251\n",
      "Epoch: 23\tFidelity = 0.967673\tKL_Divergence = 0.017937\n",
      "Epoch: 24\tFidelity = 0.967532\tKL_Divergence = 0.018153\n",
      "Epoch: 25\tFidelity = 0.966904\tKL_Divergence = 0.016788\n",
      "Epoch: 26\tFidelity = 0.967174\tKL_Divergence = 0.018519\n",
      "Epoch: 27\tFidelity = 0.967983\tKL_Divergence = 0.017585\n",
      "Epoch: 28\tFidelity = 0.969148\tKL_Divergence = 0.014627\n",
      "Epoch: 29\tFidelity = 0.967132\tKL_Divergence = 0.018590\n",
      "Epoch: 30\tFidelity = 0.970359\tKL_Divergence = 0.012151\n",
      "Epoch: 31\tFidelity = 0.969065\tKL_Divergence = 0.015717\n",
      "Epoch: 32\tFidelity = 0.967633\tKL_Divergence = 0.017030\n",
      "Epoch: 33\tFidelity = 0.967644\tKL_Divergence = 0.015693\n",
      "Epoch: 34\tFidelity = 0.971214\tKL_Divergence = 0.013126\n",
      "Epoch: 35\tFidelity = 0.966103\tKL_Divergence = 0.019013\n",
      "Epoch: 36\tFidelity = 0.967091\tKL_Divergence = 0.017433\n",
      "Epoch: 37\tFidelity = 0.970378\tKL_Divergence = 0.012501\n",
      "Epoch: 38\tFidelity = 0.968713\tKL_Divergence = 0.015946\n",
      "Epoch: 39\tFidelity = 0.971518\tKL_Divergence = 0.011830\n",
      "Epoch: 40\tFidelity = 0.957706\tKL_Divergence = 0.031314\n",
      "Epoch: 41\tFidelity = 0.971114\tKL_Divergence = 0.011967\n",
      "Epoch: 42\tFidelity = 0.969467\tKL_Divergence = 0.014580\n",
      "Epoch: 43\tFidelity = 0.969324\tKL_Divergence = 0.014616\n",
      "Epoch: 44\tFidelity = 0.971574\tKL_Divergence = 0.011718\n",
      "Epoch: 45\tFidelity = 0.970700\tKL_Divergence = 0.011596\n",
      "Epoch: 46\tFidelity = 0.959524\tKL_Divergence = 0.029601\n",
      "Epoch: 47\tFidelity = 0.957477\tKL_Divergence = 0.033260\n",
      "Epoch: 48\tFidelity = 0.969816\tKL_Divergence = 0.012899\n",
      "Epoch: 49\tFidelity = 0.969200\tKL_Divergence = 0.015545\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:08:24,695] Trial 36 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.963619\tKL_Divergence = 0.021055\n",
      "Total time elapsed during training: 38.749 s\n",
      "Trial 36 pruned. \n",
      "Epoch: 1\tFidelity = 0.962514\tKL_Divergence = 0.025406\n",
      "Epoch: 2\tFidelity = 0.971153\tKL_Divergence = 0.013027\n",
      "Epoch: 3\tFidelity = 0.969086\tKL_Divergence = 0.015794\n",
      "Epoch: 4\tFidelity = 0.967316\tKL_Divergence = 0.018231\n",
      "Epoch: 5\tFidelity = 0.961987\tKL_Divergence = 0.024797\n",
      "Epoch: 6\tFidelity = 0.970906\tKL_Divergence = 0.011374\n",
      "Epoch: 7\tFidelity = 0.966482\tKL_Divergence = 0.019322\n",
      "Epoch: 8\tFidelity = 0.962983\tKL_Divergence = 0.024183\n",
      "Epoch: 9\tFidelity = 0.965543\tKL_Divergence = 0.019896\n",
      "Epoch: 10\tFidelity = 0.960664\tKL_Divergence = 0.027976\n",
      "Epoch: 11\tFidelity = 0.966660\tKL_Divergence = 0.019810\n",
      "Epoch: 12\tFidelity = 0.971374\tKL_Divergence = 0.012951\n",
      "Epoch: 13\tFidelity = 0.963662\tKL_Divergence = 0.023757\n",
      "Epoch: 14\tFidelity = 0.961979\tKL_Divergence = 0.025306\n",
      "Epoch: 15\tFidelity = 0.972805\tKL_Divergence = 0.011106\n",
      "Epoch: 16\tFidelity = 0.967239\tKL_Divergence = 0.017219\n",
      "Epoch: 17\tFidelity = 0.965840\tKL_Divergence = 0.021243\n",
      "Epoch: 18\tFidelity = 0.968741\tKL_Divergence = 0.016358\n",
      "Epoch: 19\tFidelity = 0.970209\tKL_Divergence = 0.015438\n",
      "Epoch: 20\tFidelity = 0.971904\tKL_Divergence = 0.012982\n",
      "Epoch: 21\tFidelity = 0.970553\tKL_Divergence = 0.014978\n",
      "Epoch: 22\tFidelity = 0.972963\tKL_Divergence = 0.011238\n",
      "Epoch: 23\tFidelity = 0.965379\tKL_Divergence = 0.022578\n",
      "Epoch: 24\tFidelity = 0.972341\tKL_Divergence = 0.012383\n",
      "Epoch: 25\tFidelity = 0.966649\tKL_Divergence = 0.019273\n",
      "Epoch: 26\tFidelity = 0.971189\tKL_Divergence = 0.012390\n",
      "Epoch: 27\tFidelity = 0.974179\tKL_Divergence = 0.010087\n",
      "Epoch: 28\tFidelity = 0.973397\tKL_Divergence = 0.010239\n",
      "Epoch: 29\tFidelity = 0.972500\tKL_Divergence = 0.010941\n",
      "Epoch: 30\tFidelity = 0.963315\tKL_Divergence = 0.023846\n",
      "Epoch: 31\tFidelity = 0.970300\tKL_Divergence = 0.014031\n",
      "Epoch: 32\tFidelity = 0.965894\tKL_Divergence = 0.018738\n",
      "Epoch: 33\tFidelity = 0.962755\tKL_Divergence = 0.025243\n",
      "Epoch: 34\tFidelity = 0.972809\tKL_Divergence = 0.010479\n",
      "Epoch: 35\tFidelity = 0.970107\tKL_Divergence = 0.013590\n",
      "Epoch: 36\tFidelity = 0.967613\tKL_Divergence = 0.014461\n",
      "Epoch: 37\tFidelity = 0.965742\tKL_Divergence = 0.019312\n",
      "Epoch: 38\tFidelity = 0.964662\tKL_Divergence = 0.019760\n",
      "Epoch: 39\tFidelity = 0.951454\tKL_Divergence = 0.037239\n",
      "Epoch: 40\tFidelity = 0.968374\tKL_Divergence = 0.015607\n",
      "Epoch: 41\tFidelity = 0.968010\tKL_Divergence = 0.013537\n",
      "Epoch: 42\tFidelity = 0.966852\tKL_Divergence = 0.018008\n",
      "Epoch: 43\tFidelity = 0.964725\tKL_Divergence = 0.021006\n",
      "Epoch: 44\tFidelity = 0.969977\tKL_Divergence = 0.013002\n",
      "Epoch: 45\tFidelity = 0.968891\tKL_Divergence = 0.015069\n",
      "Epoch: 46\tFidelity = 0.972168\tKL_Divergence = 0.010367\n",
      "Epoch: 47\tFidelity = 0.968345\tKL_Divergence = 0.015568\n",
      "Epoch: 48\tFidelity = 0.956116\tKL_Divergence = 0.032757\n",
      "Epoch: 49\tFidelity = 0.967912\tKL_Divergence = 0.016569\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:09:03,736] Trial 37 finished with value: 0.01221675745509422 and parameters: {'lr': 5.458947208711856, 'pbs': 8000, 'nbs': 8000}. Best is trial 24 with value: 0.010929923347822168.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.970857\tKL_Divergence = 0.012217\n",
      "Total time elapsed during training: 38.903 s\n",
      "Trial 37 finished with value: 0.01221675745509422 and parameters: {'lr': 5.458947208711856, 'pbs': 8000, 'nbs': 8000}. Best is trial 24 with value: 0.010929923347822168.\n",
      "Epoch: 1\tFidelity = 0.958173\tKL_Divergence = 0.031236\n",
      "Epoch: 2\tFidelity = 0.972205\tKL_Divergence = 0.010724\n",
      "Epoch: 3\tFidelity = 0.972554\tKL_Divergence = 0.010301\n",
      "Epoch: 4\tFidelity = 0.972915\tKL_Divergence = 0.010371\n",
      "Epoch: 5\tFidelity = 0.970091\tKL_Divergence = 0.014626\n",
      "Epoch: 6\tFidelity = 0.968986\tKL_Divergence = 0.016342\n",
      "Epoch: 7\tFidelity = 0.950781\tKL_Divergence = 0.041738\n",
      "Epoch: 8\tFidelity = 0.972596\tKL_Divergence = 0.011060\n",
      "Epoch: 9\tFidelity = 0.972868\tKL_Divergence = 0.010514\n",
      "Epoch: 10\tFidelity = 0.957979\tKL_Divergence = 0.031116\n",
      "Epoch: 11\tFidelity = 0.964986\tKL_Divergence = 0.022858\n",
      "Epoch: 12\tFidelity = 0.963444\tKL_Divergence = 0.024333\n",
      "Epoch: 13\tFidelity = 0.966464\tKL_Divergence = 0.020763\n",
      "Epoch: 14\tFidelity = 0.959045\tKL_Divergence = 0.031861\n",
      "Epoch: 15\tFidelity = 0.972847\tKL_Divergence = 0.011856\n",
      "Epoch: 16\tFidelity = 0.964385\tKL_Divergence = 0.024085\n",
      "Epoch: 17\tFidelity = 0.965146\tKL_Divergence = 0.021883\n",
      "Epoch: 18\tFidelity = 0.964472\tKL_Divergence = 0.023992\n",
      "Epoch: 19\tFidelity = 0.972976\tKL_Divergence = 0.010764\n",
      "Epoch: 20\tFidelity = 0.961870\tKL_Divergence = 0.026387\n",
      "Epoch: 21\tFidelity = 0.960875\tKL_Divergence = 0.027976\n",
      "Epoch: 22\tFidelity = 0.959708\tKL_Divergence = 0.028138\n",
      "Epoch: 23\tFidelity = 0.972717\tKL_Divergence = 0.011540\n",
      "Epoch: 24\tFidelity = 0.968318\tKL_Divergence = 0.017666\n",
      "Epoch: 25\tFidelity = 0.957055\tKL_Divergence = 0.034254\n",
      "Epoch: 26\tFidelity = 0.959454\tKL_Divergence = 0.028429\n",
      "Epoch: 27\tFidelity = 0.957203\tKL_Divergence = 0.033859\n",
      "Epoch: 28\tFidelity = 0.969643\tKL_Divergence = 0.014435\n",
      "Epoch: 29\tFidelity = 0.965932\tKL_Divergence = 0.021171\n",
      "Epoch: 30\tFidelity = 0.969537\tKL_Divergence = 0.015583\n",
      "Epoch: 31\tFidelity = 0.972210\tKL_Divergence = 0.011473\n",
      "Epoch: 32\tFidelity = 0.971631\tKL_Divergence = 0.011871\n",
      "Epoch: 33\tFidelity = 0.961705\tKL_Divergence = 0.026662\n",
      "Epoch: 34\tFidelity = 0.973120\tKL_Divergence = 0.010351\n",
      "Epoch: 35\tFidelity = 0.963974\tKL_Divergence = 0.021854\n",
      "Epoch: 36\tFidelity = 0.972092\tKL_Divergence = 0.011039\n",
      "Epoch: 37\tFidelity = 0.972999\tKL_Divergence = 0.010457\n",
      "Epoch: 38\tFidelity = 0.963216\tKL_Divergence = 0.024264\n",
      "Epoch: 39\tFidelity = 0.967766\tKL_Divergence = 0.017533\n",
      "Epoch: 40\tFidelity = 0.970901\tKL_Divergence = 0.013679\n",
      "Epoch: 41\tFidelity = 0.969340\tKL_Divergence = 0.014562\n",
      "Epoch: 42\tFidelity = 0.968745\tKL_Divergence = 0.016291\n",
      "Epoch: 43\tFidelity = 0.959951\tKL_Divergence = 0.029240\n",
      "Epoch: 44\tFidelity = 0.971477\tKL_Divergence = 0.011530\n",
      "Epoch: 45\tFidelity = 0.971539\tKL_Divergence = 0.011212\n",
      "Epoch: 46\tFidelity = 0.962523\tKL_Divergence = 0.022887\n",
      "Epoch: 47\tFidelity = 0.962178\tKL_Divergence = 0.021470\n",
      "Epoch: 48\tFidelity = 0.965882\tKL_Divergence = 0.021370\n",
      "Epoch: 49\tFidelity = 0.969898\tKL_Divergence = 0.015820\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:09:42,859] Trial 38 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.966480\tKL_Divergence = 0.020706\n",
      "Total time elapsed during training: 38.976 s\n",
      "Trial 38 pruned. \n",
      "Epoch: 1\tFidelity = 0.960292\tKL_Divergence = 0.029853\n",
      "Epoch: 2\tFidelity = 0.964318\tKL_Divergence = 0.022815\n",
      "Epoch: 3\tFidelity = 0.972686\tKL_Divergence = 0.011614\n",
      "Epoch: 4\tFidelity = 0.963073\tKL_Divergence = 0.024632\n",
      "Epoch: 5\tFidelity = 0.972236\tKL_Divergence = 0.012321\n",
      "Epoch: 6\tFidelity = 0.956469\tKL_Divergence = 0.034262\n",
      "Epoch: 7\tFidelity = 0.971949\tKL_Divergence = 0.012349\n",
      "Epoch: 8\tFidelity = 0.960627\tKL_Divergence = 0.028887\n",
      "Epoch: 9\tFidelity = 0.970773\tKL_Divergence = 0.014515\n",
      "Epoch: 10\tFidelity = 0.967164\tKL_Divergence = 0.019279\n",
      "Epoch: 11\tFidelity = 0.972299\tKL_Divergence = 0.011775\n",
      "Epoch: 12\tFidelity = 0.965890\tKL_Divergence = 0.020929\n",
      "Epoch: 13\tFidelity = 0.973422\tKL_Divergence = 0.010029\n",
      "Epoch: 14\tFidelity = 0.970253\tKL_Divergence = 0.014359\n",
      "Epoch: 15\tFidelity = 0.969648\tKL_Divergence = 0.015381\n",
      "Epoch: 16\tFidelity = 0.959132\tKL_Divergence = 0.030248\n",
      "Epoch: 17\tFidelity = 0.967956\tKL_Divergence = 0.017340\n",
      "Epoch: 18\tFidelity = 0.968525\tKL_Divergence = 0.016724\n",
      "Epoch: 19\tFidelity = 0.964938\tKL_Divergence = 0.021046\n",
      "Epoch: 20\tFidelity = 0.972349\tKL_Divergence = 0.011046\n",
      "Epoch: 21\tFidelity = 0.970577\tKL_Divergence = 0.012932\n",
      "Epoch: 22\tFidelity = 0.968719\tKL_Divergence = 0.016101\n",
      "Epoch: 23\tFidelity = 0.967159\tKL_Divergence = 0.017444\n",
      "Epoch: 24\tFidelity = 0.969851\tKL_Divergence = 0.015181\n",
      "Epoch: 25\tFidelity = 0.970452\tKL_Divergence = 0.013859\n",
      "Epoch: 26\tFidelity = 0.972535\tKL_Divergence = 0.010644\n",
      "Epoch: 27\tFidelity = 0.971191\tKL_Divergence = 0.012509\n",
      "Epoch: 28\tFidelity = 0.972827\tKL_Divergence = 0.010233\n",
      "Epoch: 29\tFidelity = 0.970507\tKL_Divergence = 0.013273\n",
      "Epoch: 30\tFidelity = 0.965760\tKL_Divergence = 0.019484\n",
      "Epoch: 31\tFidelity = 0.966122\tKL_Divergence = 0.019683\n",
      "Epoch: 32\tFidelity = 0.970053\tKL_Divergence = 0.013104\n",
      "Epoch: 33\tFidelity = 0.970036\tKL_Divergence = 0.012884\n",
      "Epoch: 34\tFidelity = 0.971812\tKL_Divergence = 0.011725\n",
      "Epoch: 35\tFidelity = 0.964657\tKL_Divergence = 0.021806\n",
      "Epoch: 36\tFidelity = 0.958559\tKL_Divergence = 0.030918\n",
      "Epoch: 37\tFidelity = 0.972188\tKL_Divergence = 0.010759\n",
      "Epoch: 38\tFidelity = 0.964765\tKL_Divergence = 0.022129\n",
      "Epoch: 39\tFidelity = 0.954295\tKL_Divergence = 0.037236\n",
      "Epoch: 40\tFidelity = 0.954809\tKL_Divergence = 0.034966\n",
      "Epoch: 41\tFidelity = 0.966224\tKL_Divergence = 0.020045\n",
      "Epoch: 42\tFidelity = 0.960589\tKL_Divergence = 0.027654\n",
      "Epoch: 43\tFidelity = 0.961950\tKL_Divergence = 0.026703\n",
      "Epoch: 44\tFidelity = 0.973277\tKL_Divergence = 0.010046\n",
      "Epoch: 45\tFidelity = 0.971941\tKL_Divergence = 0.012005\n",
      "Epoch: 46\tFidelity = 0.962954\tKL_Divergence = 0.025353\n",
      "Epoch: 47\tFidelity = 0.971493\tKL_Divergence = 0.012798\n",
      "Epoch: 48\tFidelity = 0.966765\tKL_Divergence = 0.019868\n",
      "Epoch: 49\tFidelity = 0.961420\tKL_Divergence = 0.027066\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:10:29,861] Trial 39 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.965809\tKL_Divergence = 0.021047\n",
      "Total time elapsed during training: 46.838 s\n",
      "Trial 39 pruned. \n",
      "Epoch: 1\tFidelity = 0.966253\tKL_Divergence = 0.015438\n",
      "Epoch: 2\tFidelity = 0.971078\tKL_Divergence = 0.012953\n",
      "Epoch: 3\tFidelity = 0.969024\tKL_Divergence = 0.013146\n",
      "Epoch: 4\tFidelity = 0.955879\tKL_Divergence = 0.032245\n",
      "Epoch: 5\tFidelity = 0.964645\tKL_Divergence = 0.022303\n",
      "Epoch: 6\tFidelity = 0.966856\tKL_Divergence = 0.014639\n",
      "Epoch: 7\tFidelity = 0.971401\tKL_Divergence = 0.012673\n",
      "Epoch: 8\tFidelity = 0.955311\tKL_Divergence = 0.034942\n",
      "Epoch: 9\tFidelity = 0.970909\tKL_Divergence = 0.012504\n",
      "Epoch: 10\tFidelity = 0.953263\tKL_Divergence = 0.037313\n",
      "Epoch: 11\tFidelity = 0.967319\tKL_Divergence = 0.018980\n",
      "Epoch: 12\tFidelity = 0.968960\tKL_Divergence = 0.014847\n",
      "Epoch: 13\tFidelity = 0.963623\tKL_Divergence = 0.021183\n",
      "Epoch: 14\tFidelity = 0.967763\tKL_Divergence = 0.015938\n",
      "Epoch: 15\tFidelity = 0.973712\tKL_Divergence = 0.009940\n",
      "Epoch: 16\tFidelity = 0.959563\tKL_Divergence = 0.029807\n",
      "Epoch: 17\tFidelity = 0.972718\tKL_Divergence = 0.010629\n",
      "Epoch: 18\tFidelity = 0.967403\tKL_Divergence = 0.014056\n",
      "Epoch: 19\tFidelity = 0.961789\tKL_Divergence = 0.027330\n",
      "Epoch: 20\tFidelity = 0.969448\tKL_Divergence = 0.013223\n",
      "Epoch: 21\tFidelity = 0.968726\tKL_Divergence = 0.015935\n",
      "Epoch: 22\tFidelity = 0.954186\tKL_Divergence = 0.039228\n",
      "Epoch: 23\tFidelity = 0.966875\tKL_Divergence = 0.017423\n",
      "Epoch: 24\tFidelity = 0.973491\tKL_Divergence = 0.011683\n",
      "Epoch: 25\tFidelity = 0.967790\tKL_Divergence = 0.019392\n",
      "Epoch: 26\tFidelity = 0.973633\tKL_Divergence = 0.010436\n",
      "Epoch: 27\tFidelity = 0.962552\tKL_Divergence = 0.026102\n",
      "Epoch: 28\tFidelity = 0.958455\tKL_Divergence = 0.027956\n",
      "Epoch: 29\tFidelity = 0.967789\tKL_Divergence = 0.017799\n",
      "Epoch: 30\tFidelity = 0.965681\tKL_Divergence = 0.021332\n",
      "Epoch: 31\tFidelity = 0.972651\tKL_Divergence = 0.011771\n",
      "Epoch: 32\tFidelity = 0.966223\tKL_Divergence = 0.021336\n",
      "Epoch: 33\tFidelity = 0.962932\tKL_Divergence = 0.025596\n",
      "Epoch: 34\tFidelity = 0.970799\tKL_Divergence = 0.014908\n",
      "Epoch: 35\tFidelity = 0.973371\tKL_Divergence = 0.010162\n",
      "Epoch: 36\tFidelity = 0.972094\tKL_Divergence = 0.011605\n",
      "Epoch: 37\tFidelity = 0.955646\tKL_Divergence = 0.034124\n",
      "Epoch: 38\tFidelity = 0.969194\tKL_Divergence = 0.014426\n",
      "Epoch: 39\tFidelity = 0.965462\tKL_Divergence = 0.018523\n",
      "Epoch: 40\tFidelity = 0.969506\tKL_Divergence = 0.014327\n",
      "Epoch: 41\tFidelity = 0.963838\tKL_Divergence = 0.020385\n",
      "Epoch: 42\tFidelity = 0.961910\tKL_Divergence = 0.026548\n",
      "Epoch: 43\tFidelity = 0.967533\tKL_Divergence = 0.019691\n",
      "Epoch: 44\tFidelity = 0.972665\tKL_Divergence = 0.011749\n",
      "Epoch: 45\tFidelity = 0.967046\tKL_Divergence = 0.016977\n",
      "Epoch: 46\tFidelity = 0.972628\tKL_Divergence = 0.010374\n",
      "Epoch: 47\tFidelity = 0.952726\tKL_Divergence = 0.038155\n",
      "Epoch: 48\tFidelity = 0.966911\tKL_Divergence = 0.015784\n",
      "Epoch: 49\tFidelity = 0.971073\tKL_Divergence = 0.013333\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:11:30,647] Trial 40 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.968290\tKL_Divergence = 0.018018\n",
      "Total time elapsed during training: 60.633 s\n",
      "Trial 40 pruned. \n",
      "Epoch: 1\tFidelity = 0.968745\tKL_Divergence = 0.015794\n",
      "Epoch: 2\tFidelity = 0.964070\tKL_Divergence = 0.023982\n",
      "Epoch: 3\tFidelity = 0.961913\tKL_Divergence = 0.027413\n",
      "Epoch: 4\tFidelity = 0.967556\tKL_Divergence = 0.017737\n",
      "Epoch: 5\tFidelity = 0.964116\tKL_Divergence = 0.023181\n",
      "Epoch: 6\tFidelity = 0.968419\tKL_Divergence = 0.016173\n",
      "Epoch: 7\tFidelity = 0.960562\tKL_Divergence = 0.028374\n",
      "Epoch: 8\tFidelity = 0.954101\tKL_Divergence = 0.037258\n",
      "Epoch: 9\tFidelity = 0.964235\tKL_Divergence = 0.023643\n",
      "Epoch: 10\tFidelity = 0.973576\tKL_Divergence = 0.010446\n",
      "Epoch: 11\tFidelity = 0.974093\tKL_Divergence = 0.009859\n",
      "Epoch: 12\tFidelity = 0.951725\tKL_Divergence = 0.041755\n",
      "Epoch: 13\tFidelity = 0.960815\tKL_Divergence = 0.029654\n",
      "Epoch: 14\tFidelity = 0.942237\tKL_Divergence = 0.054151\n",
      "Epoch: 15\tFidelity = 0.960900\tKL_Divergence = 0.030116\n",
      "Epoch: 16\tFidelity = 0.974154\tKL_Divergence = 0.010215\n",
      "Epoch: 17\tFidelity = 0.972518\tKL_Divergence = 0.012020\n",
      "Epoch: 18\tFidelity = 0.960260\tKL_Divergence = 0.029461\n",
      "Epoch: 19\tFidelity = 0.965212\tKL_Divergence = 0.022896\n",
      "Epoch: 20\tFidelity = 0.973322\tKL_Divergence = 0.011046\n",
      "Epoch: 21\tFidelity = 0.965228\tKL_Divergence = 0.022856\n",
      "Epoch: 22\tFidelity = 0.952561\tKL_Divergence = 0.041476\n",
      "Epoch: 23\tFidelity = 0.969727\tKL_Divergence = 0.015778\n",
      "Epoch: 24\tFidelity = 0.962950\tKL_Divergence = 0.026359\n",
      "Epoch: 25\tFidelity = 0.962188\tKL_Divergence = 0.027689\n",
      "Epoch: 26\tFidelity = 0.969097\tKL_Divergence = 0.017850\n",
      "Epoch: 27\tFidelity = 0.968222\tKL_Divergence = 0.018842\n",
      "Epoch: 28\tFidelity = 0.971587\tKL_Divergence = 0.013817\n",
      "Epoch: 29\tFidelity = 0.969563\tKL_Divergence = 0.016168\n",
      "Epoch: 30\tFidelity = 0.970417\tKL_Divergence = 0.014931\n",
      "Epoch: 31\tFidelity = 0.967494\tKL_Divergence = 0.017972\n",
      "Epoch: 32\tFidelity = 0.972998\tKL_Divergence = 0.011474\n",
      "Epoch: 33\tFidelity = 0.966252\tKL_Divergence = 0.020502\n",
      "Epoch: 34\tFidelity = 0.961492\tKL_Divergence = 0.028252\n",
      "Epoch: 35\tFidelity = 0.969200\tKL_Divergence = 0.017174\n",
      "Epoch: 36\tFidelity = 0.965849\tKL_Divergence = 0.022095\n",
      "Epoch: 37\tFidelity = 0.970487\tKL_Divergence = 0.015919\n",
      "Epoch: 38\tFidelity = 0.959191\tKL_Divergence = 0.031958\n",
      "Epoch: 39\tFidelity = 0.954147\tKL_Divergence = 0.039359\n",
      "Epoch: 40\tFidelity = 0.968086\tKL_Divergence = 0.019668\n",
      "Epoch: 41\tFidelity = 0.962133\tKL_Divergence = 0.028258\n",
      "Epoch: 42\tFidelity = 0.970331\tKL_Divergence = 0.016815\n",
      "Epoch: 43\tFidelity = 0.974806\tKL_Divergence = 0.009980\n",
      "Epoch: 44\tFidelity = 0.973607\tKL_Divergence = 0.011889\n",
      "Epoch: 45\tFidelity = 0.969250\tKL_Divergence = 0.017914\n",
      "Epoch: 46\tFidelity = 0.972806\tKL_Divergence = 0.013063\n",
      "Epoch: 47\tFidelity = 0.966849\tKL_Divergence = 0.020866\n",
      "Epoch: 48\tFidelity = 0.973086\tKL_Divergence = 0.012490\n",
      "Epoch: 49\tFidelity = 0.972292\tKL_Divergence = 0.013001\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:12:09,824] Trial 41 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.965951\tKL_Divergence = 0.021270\n",
      "Total time elapsed during training: 39.031 s\n",
      "Trial 41 pruned. \n",
      "Epoch: 1\tFidelity = 0.957785\tKL_Divergence = 0.034692\n",
      "Epoch: 2\tFidelity = 0.970393\tKL_Divergence = 0.016531\n",
      "Epoch: 3\tFidelity = 0.972083\tKL_Divergence = 0.014127\n",
      "Epoch: 4\tFidelity = 0.963430\tKL_Divergence = 0.025962\n",
      "Epoch: 5\tFidelity = 0.956045\tKL_Divergence = 0.037009\n",
      "Epoch: 6\tFidelity = 0.946226\tKL_Divergence = 0.051830\n",
      "Epoch: 7\tFidelity = 0.968708\tKL_Divergence = 0.018100\n",
      "Epoch: 8\tFidelity = 0.951447\tKL_Divergence = 0.043415\n",
      "Epoch: 9\tFidelity = 0.967785\tKL_Divergence = 0.019826\n",
      "Epoch: 10\tFidelity = 0.973870\tKL_Divergence = 0.011196\n",
      "Epoch: 11\tFidelity = 0.968620\tKL_Divergence = 0.018080\n",
      "Epoch: 12\tFidelity = 0.969202\tKL_Divergence = 0.017030\n",
      "Epoch: 13\tFidelity = 0.972645\tKL_Divergence = 0.012240\n",
      "Epoch: 14\tFidelity = 0.967025\tKL_Divergence = 0.019297\n",
      "Epoch: 15\tFidelity = 0.961463\tKL_Divergence = 0.027611\n",
      "Epoch: 16\tFidelity = 0.961436\tKL_Divergence = 0.026762\n",
      "Epoch: 17\tFidelity = 0.966776\tKL_Divergence = 0.021015\n",
      "Epoch: 18\tFidelity = 0.970636\tKL_Divergence = 0.014630\n",
      "Epoch: 19\tFidelity = 0.970173\tKL_Divergence = 0.016324\n",
      "Epoch: 20\tFidelity = 0.972954\tKL_Divergence = 0.010773\n",
      "Epoch: 21\tFidelity = 0.972467\tKL_Divergence = 0.011515\n",
      "Epoch: 22\tFidelity = 0.961228\tKL_Divergence = 0.026991\n",
      "Epoch: 23\tFidelity = 0.965486\tKL_Divergence = 0.020127\n",
      "Epoch: 24\tFidelity = 0.960002\tKL_Divergence = 0.029305\n",
      "Epoch: 25\tFidelity = 0.965260\tKL_Divergence = 0.021666\n",
      "Epoch: 26\tFidelity = 0.955743\tKL_Divergence = 0.035872\n",
      "Epoch: 27\tFidelity = 0.961499\tKL_Divergence = 0.025673\n",
      "Epoch: 28\tFidelity = 0.972860\tKL_Divergence = 0.011644\n",
      "Epoch: 29\tFidelity = 0.971283\tKL_Divergence = 0.013699\n",
      "Epoch: 30\tFidelity = 0.972875\tKL_Divergence = 0.011308\n",
      "Epoch: 31\tFidelity = 0.973622\tKL_Divergence = 0.009955\n",
      "Epoch: 32\tFidelity = 0.966466\tKL_Divergence = 0.019307\n",
      "Epoch: 33\tFidelity = 0.967998\tKL_Divergence = 0.017934\n",
      "Epoch: 34\tFidelity = 0.971940\tKL_Divergence = 0.012852\n",
      "Epoch: 35\tFidelity = 0.963098\tKL_Divergence = 0.025281\n",
      "Epoch: 36\tFidelity = 0.963042\tKL_Divergence = 0.026035\n",
      "Epoch: 37\tFidelity = 0.968022\tKL_Divergence = 0.017480\n",
      "Epoch: 38\tFidelity = 0.970848\tKL_Divergence = 0.012742\n",
      "Epoch: 39\tFidelity = 0.973448\tKL_Divergence = 0.010528\n",
      "Epoch: 40\tFidelity = 0.965912\tKL_Divergence = 0.021800\n",
      "Epoch: 41\tFidelity = 0.967906\tKL_Divergence = 0.019042\n",
      "Epoch: 42\tFidelity = 0.959784\tKL_Divergence = 0.030605\n",
      "Epoch: 43\tFidelity = 0.968268\tKL_Divergence = 0.017966\n",
      "Epoch: 44\tFidelity = 0.967212\tKL_Divergence = 0.020799\n",
      "Epoch: 45\tFidelity = 0.966982\tKL_Divergence = 0.021401\n",
      "Epoch: 46\tFidelity = 0.960087\tKL_Divergence = 0.029124\n",
      "Epoch: 47\tFidelity = 0.967090\tKL_Divergence = 0.021249\n",
      "Epoch: 48\tFidelity = 0.970784\tKL_Divergence = 0.015215\n",
      "Epoch: 49\tFidelity = 0.970415\tKL_Divergence = 0.015645\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:12:49,067] Trial 42 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.969030\tKL_Divergence = 0.018139\n",
      "Total time elapsed during training: 39.098 s\n",
      "Trial 42 pruned. \n",
      "Epoch: 1\tFidelity = 0.968924\tKL_Divergence = 0.016860\n",
      "Epoch: 2\tFidelity = 0.967827\tKL_Divergence = 0.018145\n",
      "Epoch: 3\tFidelity = 0.973148\tKL_Divergence = 0.010668\n",
      "Epoch: 4\tFidelity = 0.950835\tKL_Divergence = 0.043799\n",
      "Epoch: 5\tFidelity = 0.963868\tKL_Divergence = 0.018475\n",
      "Epoch: 6\tFidelity = 0.970253\tKL_Divergence = 0.015937\n",
      "Epoch: 7\tFidelity = 0.970426\tKL_Divergence = 0.015493\n",
      "Epoch: 8\tFidelity = 0.966453\tKL_Divergence = 0.020801\n",
      "Epoch: 9\tFidelity = 0.972946\tKL_Divergence = 0.011475\n",
      "Epoch: 10\tFidelity = 0.965813\tKL_Divergence = 0.021305\n",
      "Epoch: 11\tFidelity = 0.955642\tKL_Divergence = 0.035119\n",
      "Epoch: 12\tFidelity = 0.952947\tKL_Divergence = 0.041098\n",
      "Epoch: 13\tFidelity = 0.966720\tKL_Divergence = 0.020938\n",
      "Epoch: 14\tFidelity = 0.961862\tKL_Divergence = 0.026627\n",
      "Epoch: 15\tFidelity = 0.958582\tKL_Divergence = 0.029143\n",
      "Epoch: 16\tFidelity = 0.973635\tKL_Divergence = 0.010742\n",
      "Epoch: 17\tFidelity = 0.963722\tKL_Divergence = 0.024819\n",
      "Epoch: 18\tFidelity = 0.967318\tKL_Divergence = 0.019857\n",
      "Epoch: 19\tFidelity = 0.974177\tKL_Divergence = 0.010261\n",
      "Epoch: 20\tFidelity = 0.970521\tKL_Divergence = 0.015008\n",
      "Epoch: 21\tFidelity = 0.972998\tKL_Divergence = 0.011424\n",
      "Epoch: 22\tFidelity = 0.958444\tKL_Divergence = 0.030274\n",
      "Epoch: 23\tFidelity = 0.966117\tKL_Divergence = 0.021472\n",
      "Epoch: 24\tFidelity = 0.967110\tKL_Divergence = 0.019093\n",
      "Epoch: 25\tFidelity = 0.972446\tKL_Divergence = 0.012856\n",
      "Epoch: 26\tFidelity = 0.970183\tKL_Divergence = 0.015741\n",
      "Epoch: 27\tFidelity = 0.965024\tKL_Divergence = 0.022872\n",
      "Epoch: 28\tFidelity = 0.955242\tKL_Divergence = 0.036932\n",
      "Epoch: 29\tFidelity = 0.972607\tKL_Divergence = 0.010811\n",
      "Epoch: 30\tFidelity = 0.973600\tKL_Divergence = 0.010119\n",
      "Epoch: 31\tFidelity = 0.962585\tKL_Divergence = 0.024303\n",
      "Epoch: 32\tFidelity = 0.969654\tKL_Divergence = 0.014242\n",
      "Epoch: 33\tFidelity = 0.970809\tKL_Divergence = 0.013930\n",
      "Epoch: 34\tFidelity = 0.970157\tKL_Divergence = 0.014963\n",
      "Epoch: 35\tFidelity = 0.965443\tKL_Divergence = 0.016250\n",
      "Epoch: 36\tFidelity = 0.966111\tKL_Divergence = 0.017727\n",
      "Epoch: 37\tFidelity = 0.969659\tKL_Divergence = 0.015755\n",
      "Epoch: 38\tFidelity = 0.970334\tKL_Divergence = 0.013933\n",
      "Epoch: 39\tFidelity = 0.972604\tKL_Divergence = 0.011237\n",
      "Epoch: 40\tFidelity = 0.958354\tKL_Divergence = 0.032084\n",
      "Epoch: 41\tFidelity = 0.962317\tKL_Divergence = 0.026614\n",
      "Epoch: 42\tFidelity = 0.972390\tKL_Divergence = 0.011988\n",
      "Epoch: 43\tFidelity = 0.970763\tKL_Divergence = 0.014085\n",
      "Epoch: 44\tFidelity = 0.968445\tKL_Divergence = 0.016515\n",
      "Epoch: 45\tFidelity = 0.969433\tKL_Divergence = 0.014288\n",
      "Epoch: 46\tFidelity = 0.967259\tKL_Divergence = 0.018803\n",
      "Epoch: 47\tFidelity = 0.968949\tKL_Divergence = 0.016617\n",
      "Epoch: 48\tFidelity = 0.956235\tKL_Divergence = 0.033797\n",
      "Epoch: 49\tFidelity = 0.962676\tKL_Divergence = 0.023900\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:13:28,191] Trial 43 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.960462\tKL_Divergence = 0.029844\n",
      "Total time elapsed during training: 38.974 s\n",
      "Trial 43 pruned. \n",
      "Epoch: 1\tFidelity = 0.965894\tKL_Divergence = 0.021936\n",
      "Epoch: 2\tFidelity = 0.963846\tKL_Divergence = 0.024140\n",
      "Epoch: 3\tFidelity = 0.973263\tKL_Divergence = 0.011938\n",
      "Epoch: 4\tFidelity = 0.974026\tKL_Divergence = 0.011194\n",
      "Epoch: 5\tFidelity = 0.971507\tKL_Divergence = 0.014586\n",
      "Epoch: 6\tFidelity = 0.973580\tKL_Divergence = 0.010183\n",
      "Epoch: 7\tFidelity = 0.957542\tKL_Divergence = 0.032856\n",
      "Epoch: 8\tFidelity = 0.957513\tKL_Divergence = 0.033789\n",
      "Epoch: 9\tFidelity = 0.964704\tKL_Divergence = 0.021410\n",
      "Epoch: 10\tFidelity = 0.964749\tKL_Divergence = 0.024105\n",
      "Epoch: 11\tFidelity = 0.973615\tKL_Divergence = 0.011277\n",
      "Epoch: 12\tFidelity = 0.954879\tKL_Divergence = 0.038000\n",
      "Epoch: 13\tFidelity = 0.967131\tKL_Divergence = 0.019851\n",
      "Epoch: 14\tFidelity = 0.957873\tKL_Divergence = 0.033469\n",
      "Epoch: 15\tFidelity = 0.962960\tKL_Divergence = 0.025239\n",
      "Epoch: 16\tFidelity = 0.974186\tKL_Divergence = 0.009680\n",
      "Epoch: 17\tFidelity = 0.947842\tKL_Divergence = 0.047137\n",
      "Epoch: 18\tFidelity = 0.972125\tKL_Divergence = 0.012974\n",
      "Epoch: 19\tFidelity = 0.974315\tKL_Divergence = 0.009539\n",
      "Epoch: 20\tFidelity = 0.966744\tKL_Divergence = 0.017942\n",
      "Epoch: 21\tFidelity = 0.970734\tKL_Divergence = 0.014308\n",
      "Epoch: 22\tFidelity = 0.969052\tKL_Divergence = 0.017146\n",
      "Epoch: 23\tFidelity = 0.955427\tKL_Divergence = 0.036366\n",
      "Epoch: 24\tFidelity = 0.968452\tKL_Divergence = 0.018487\n",
      "Epoch: 25\tFidelity = 0.966892\tKL_Divergence = 0.020430\n",
      "Epoch: 26\tFidelity = 0.968335\tKL_Divergence = 0.018685\n",
      "Epoch: 27\tFidelity = 0.973195\tKL_Divergence = 0.011219\n",
      "Epoch: 28\tFidelity = 0.971746\tKL_Divergence = 0.013356\n",
      "Epoch: 29\tFidelity = 0.974794\tKL_Divergence = 0.010003\n",
      "Epoch: 30\tFidelity = 0.961716\tKL_Divergence = 0.028769\n",
      "Epoch: 31\tFidelity = 0.974372\tKL_Divergence = 0.009972\n",
      "Epoch: 32\tFidelity = 0.974336\tKL_Divergence = 0.010031\n",
      "Epoch: 33\tFidelity = 0.973553\tKL_Divergence = 0.011021\n",
      "Epoch: 34\tFidelity = 0.958068\tKL_Divergence = 0.033553\n",
      "Epoch: 35\tFidelity = 0.963386\tKL_Divergence = 0.024195\n",
      "Epoch: 36\tFidelity = 0.975250\tKL_Divergence = 0.009283\n",
      "Epoch: 37\tFidelity = 0.964627\tKL_Divergence = 0.024262\n",
      "Epoch: 38\tFidelity = 0.956730\tKL_Divergence = 0.034930\n",
      "Epoch: 39\tFidelity = 0.961675\tKL_Divergence = 0.028247\n",
      "Epoch: 40\tFidelity = 0.974930\tKL_Divergence = 0.009702\n",
      "Epoch: 41\tFidelity = 0.974508\tKL_Divergence = 0.009414\n",
      "Epoch: 42\tFidelity = 0.968923\tKL_Divergence = 0.017816\n",
      "Epoch: 43\tFidelity = 0.964291\tKL_Divergence = 0.024397\n",
      "Epoch: 44\tFidelity = 0.970883\tKL_Divergence = 0.014809\n",
      "Epoch: 45\tFidelity = 0.973725\tKL_Divergence = 0.010669\n",
      "Epoch: 46\tFidelity = 0.973101\tKL_Divergence = 0.010405\n",
      "Epoch: 47\tFidelity = 0.965348\tKL_Divergence = 0.021906\n",
      "Epoch: 48\tFidelity = 0.945050\tKL_Divergence = 0.051250\n",
      "Epoch: 49\tFidelity = 0.972202\tKL_Divergence = 0.012359\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:14:07,269] Trial 44 finished with value: 0.012260645598363644 and parameters: {'lr': 5.877965068831728, 'pbs': 8000, 'nbs': 8000}. Best is trial 24 with value: 0.010929923347822168.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.972035\tKL_Divergence = 0.012261\n",
      "Total time elapsed during training: 38.920 s\n",
      "Trial 44 finished with value: 0.012260645598363644 and parameters: {'lr': 5.877965068831728, 'pbs': 8000, 'nbs': 8000}. Best is trial 24 with value: 0.010929923347822168.\n",
      "Epoch: 1\tFidelity = 0.963574\tKL_Divergence = 0.024876\n",
      "Epoch: 2\tFidelity = 0.971469\tKL_Divergence = 0.013770\n",
      "Epoch: 3\tFidelity = 0.965784\tKL_Divergence = 0.022035\n",
      "Epoch: 4\tFidelity = 0.964068\tKL_Divergence = 0.024446\n",
      "Epoch: 5\tFidelity = 0.960121\tKL_Divergence = 0.030178\n",
      "Epoch: 6\tFidelity = 0.967229\tKL_Divergence = 0.019388\n",
      "Epoch: 7\tFidelity = 0.964655\tKL_Divergence = 0.024353\n",
      "Epoch: 8\tFidelity = 0.960759\tKL_Divergence = 0.029530\n",
      "Epoch: 9\tFidelity = 0.956842\tKL_Divergence = 0.034842\n",
      "Epoch: 10\tFidelity = 0.964668\tKL_Divergence = 0.024923\n",
      "Epoch: 11\tFidelity = 0.970213\tKL_Divergence = 0.016403\n",
      "Epoch: 12\tFidelity = 0.963014\tKL_Divergence = 0.027192\n",
      "Epoch: 13\tFidelity = 0.968791\tKL_Divergence = 0.017774\n",
      "Epoch: 14\tFidelity = 0.971840\tKL_Divergence = 0.014948\n",
      "Epoch: 15\tFidelity = 0.970380\tKL_Divergence = 0.017081\n",
      "Epoch: 16\tFidelity = 0.968934\tKL_Divergence = 0.019127\n",
      "Epoch: 17\tFidelity = 0.966758\tKL_Divergence = 0.022542\n",
      "Epoch: 18\tFidelity = 0.965692\tKL_Divergence = 0.023971\n",
      "Epoch: 19\tFidelity = 0.967863\tKL_Divergence = 0.021362\n",
      "Epoch: 20\tFidelity = 0.955595\tKL_Divergence = 0.039177\n",
      "Epoch: 21\tFidelity = 0.971450\tKL_Divergence = 0.015107\n",
      "Epoch: 22\tFidelity = 0.970314\tKL_Divergence = 0.017387\n",
      "Epoch: 23\tFidelity = 0.952188\tKL_Divergence = 0.043832\n",
      "Epoch: 24\tFidelity = 0.965436\tKL_Divergence = 0.025056\n",
      "Epoch: 25\tFidelity = 0.968885\tKL_Divergence = 0.019557\n",
      "Epoch: 26\tFidelity = 0.950460\tKL_Divergence = 0.046557\n",
      "Epoch: 27\tFidelity = 0.972135\tKL_Divergence = 0.015346\n",
      "Epoch: 28\tFidelity = 0.959991\tKL_Divergence = 0.032732\n",
      "Epoch: 29\tFidelity = 0.950688\tKL_Divergence = 0.046226\n",
      "Epoch: 30\tFidelity = 0.968209\tKL_Divergence = 0.020639\n",
      "Epoch: 31\tFidelity = 0.965258\tKL_Divergence = 0.024651\n",
      "Epoch: 32\tFidelity = 0.960670\tKL_Divergence = 0.031400\n",
      "Epoch: 33\tFidelity = 0.949743\tKL_Divergence = 0.046671\n",
      "Epoch: 34\tFidelity = 0.953810\tKL_Divergence = 0.041350\n",
      "Epoch: 35\tFidelity = 0.966467\tKL_Divergence = 0.023976\n",
      "Epoch: 36\tFidelity = 0.960506\tKL_Divergence = 0.031910\n",
      "Epoch: 37\tFidelity = 0.966015\tKL_Divergence = 0.023048\n",
      "Epoch: 38\tFidelity = 0.976280\tKL_Divergence = 0.010032\n",
      "Epoch: 39\tFidelity = 0.963747\tKL_Divergence = 0.027303\n",
      "Epoch: 40\tFidelity = 0.972873\tKL_Divergence = 0.014750\n",
      "Epoch: 41\tFidelity = 0.958915\tKL_Divergence = 0.034442\n",
      "Epoch: 42\tFidelity = 0.965560\tKL_Divergence = 0.024395\n",
      "Epoch: 43\tFidelity = 0.969736\tKL_Divergence = 0.017954\n",
      "Epoch: 44\tFidelity = 0.954570\tKL_Divergence = 0.041269\n",
      "Epoch: 45\tFidelity = 0.953660\tKL_Divergence = 0.040721\n",
      "Epoch: 46\tFidelity = 0.956426\tKL_Divergence = 0.039090\n",
      "Epoch: 47\tFidelity = 0.967081\tKL_Divergence = 0.023407\n",
      "Epoch: 48\tFidelity = 0.951701\tKL_Divergence = 0.046079\n",
      "Epoch: 49\tFidelity = 0.969865\tKL_Divergence = 0.019379\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:14:47,361] Trial 45 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.961262\tKL_Divergence = 0.032393\n",
      "Total time elapsed during training: 39.930 s\n",
      "Trial 45 pruned. \n",
      "Epoch: 1\tFidelity = 0.952830\tKL_Divergence = 0.044805\n",
      "Epoch: 2\tFidelity = 0.965727\tKL_Divergence = 0.026264\n",
      "Epoch: 3\tFidelity = 0.973739\tKL_Divergence = 0.014657\n",
      "Epoch: 4\tFidelity = 0.975758\tKL_Divergence = 0.011782\n",
      "Epoch: 5\tFidelity = 0.970642\tKL_Divergence = 0.018985\n",
      "Epoch: 6\tFidelity = 0.954793\tKL_Divergence = 0.041927\n",
      "Epoch: 7\tFidelity = 0.955638\tKL_Divergence = 0.040738\n",
      "Epoch: 8\tFidelity = 0.963398\tKL_Divergence = 0.029579\n",
      "Epoch: 9\tFidelity = 0.964358\tKL_Divergence = 0.028174\n",
      "Epoch: 10\tFidelity = 0.950859\tKL_Divergence = 0.048056\n",
      "Epoch: 11\tFidelity = 0.958409\tKL_Divergence = 0.037032\n",
      "Epoch: 12\tFidelity = 0.954841\tKL_Divergence = 0.042395\n",
      "Epoch: 13\tFidelity = 0.968374\tKL_Divergence = 0.022743\n",
      "Epoch: 14\tFidelity = 0.971576\tKL_Divergence = 0.018192\n",
      "Epoch: 15\tFidelity = 0.967241\tKL_Divergence = 0.024245\n",
      "Epoch: 16\tFidelity = 0.976236\tKL_Divergence = 0.011413\n",
      "Epoch: 17\tFidelity = 0.974982\tKL_Divergence = 0.012894\n",
      "Epoch: 18\tFidelity = 0.970393\tKL_Divergence = 0.019450\n",
      "Epoch: 19\tFidelity = 0.969076\tKL_Divergence = 0.021222\n",
      "Epoch: 20\tFidelity = 0.969056\tKL_Divergence = 0.021264\n",
      "Epoch: 21\tFidelity = 0.973005\tKL_Divergence = 0.015433\n",
      "Epoch: 22\tFidelity = 0.961152\tKL_Divergence = 0.032521\n",
      "Epoch: 23\tFidelity = 0.966175\tKL_Divergence = 0.025324\n",
      "Epoch: 24\tFidelity = 0.961550\tKL_Divergence = 0.032189\n",
      "Epoch: 25\tFidelity = 0.963838\tKL_Divergence = 0.028856\n",
      "Epoch: 26\tFidelity = 0.971404\tKL_Divergence = 0.018081\n",
      "Epoch: 27\tFidelity = 0.970162\tKL_Divergence = 0.019746\n",
      "Epoch: 28\tFidelity = 0.971459\tKL_Divergence = 0.017874\n",
      "Epoch: 29\tFidelity = 0.968185\tKL_Divergence = 0.022431\n",
      "Epoch: 30\tFidelity = 0.973769\tKL_Divergence = 0.014385\n",
      "Epoch: 31\tFidelity = 0.975418\tKL_Divergence = 0.011812\n",
      "Epoch: 32\tFidelity = 0.972710\tKL_Divergence = 0.015632\n",
      "Epoch: 33\tFidelity = 0.969525\tKL_Divergence = 0.020001\n",
      "Epoch: 34\tFidelity = 0.973882\tKL_Divergence = 0.013734\n",
      "Epoch: 35\tFidelity = 0.968362\tKL_Divergence = 0.021496\n",
      "Epoch: 36\tFidelity = 0.970074\tKL_Divergence = 0.019106\n",
      "Epoch: 37\tFidelity = 0.961963\tKL_Divergence = 0.030606\n",
      "Epoch: 38\tFidelity = 0.952109\tKL_Divergence = 0.045110\n",
      "Epoch: 39\tFidelity = 0.957622\tKL_Divergence = 0.036942\n",
      "Epoch: 40\tFidelity = 0.954544\tKL_Divergence = 0.041687\n",
      "Epoch: 41\tFidelity = 0.968240\tKL_Divergence = 0.021754\n",
      "Epoch: 42\tFidelity = 0.971258\tKL_Divergence = 0.017547\n",
      "Epoch: 43\tFidelity = 0.957031\tKL_Divergence = 0.037879\n",
      "Epoch: 44\tFidelity = 0.959919\tKL_Divergence = 0.033927\n",
      "Epoch: 45\tFidelity = 0.963710\tKL_Divergence = 0.028379\n",
      "Epoch: 46\tFidelity = 0.971751\tKL_Divergence = 0.017002\n",
      "Epoch: 47\tFidelity = 0.971949\tKL_Divergence = 0.016475\n",
      "Epoch: 48\tFidelity = 0.967222\tKL_Divergence = 0.023422\n",
      "Epoch: 49\tFidelity = 0.962963\tKL_Divergence = 0.029371\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:15:20,523] Trial 46 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.970040\tKL_Divergence = 0.019348\n",
      "Total time elapsed during training: 33.020 s\n",
      "Trial 46 pruned. \n",
      "Epoch: 1\tFidelity = 0.951227\tKL_Divergence = 0.045777\n",
      "Epoch: 2\tFidelity = 0.965868\tKL_Divergence = 0.024687\n",
      "Epoch: 3\tFidelity = 0.974052\tKL_Divergence = 0.012258\n",
      "Epoch: 4\tFidelity = 0.971369\tKL_Divergence = 0.016806\n",
      "Epoch: 5\tFidelity = 0.959593\tKL_Divergence = 0.033096\n",
      "Epoch: 6\tFidelity = 0.965926\tKL_Divergence = 0.024280\n",
      "Epoch: 7\tFidelity = 0.944632\tKL_Divergence = 0.054586\n",
      "Epoch: 8\tFidelity = 0.970941\tKL_Divergence = 0.016888\n",
      "Epoch: 9\tFidelity = 0.975144\tKL_Divergence = 0.010186\n",
      "Epoch: 10\tFidelity = 0.976864\tKL_Divergence = 0.009196\n",
      "Epoch: 11\tFidelity = 0.963778\tKL_Divergence = 0.027389\n",
      "Epoch: 12\tFidelity = 0.947373\tKL_Divergence = 0.051697\n",
      "Epoch: 13\tFidelity = 0.974013\tKL_Divergence = 0.012433\n",
      "Epoch: 14\tFidelity = 0.972429\tKL_Divergence = 0.015435\n",
      "Epoch: 15\tFidelity = 0.959718\tKL_Divergence = 0.033050\n",
      "Epoch: 16\tFidelity = 0.962606\tKL_Divergence = 0.029244\n",
      "Epoch: 17\tFidelity = 0.974896\tKL_Divergence = 0.010688\n",
      "Epoch: 18\tFidelity = 0.966100\tKL_Divergence = 0.024595\n",
      "Epoch: 19\tFidelity = 0.975186\tKL_Divergence = 0.010647\n",
      "Epoch: 20\tFidelity = 0.976589\tKL_Divergence = 0.009424\n",
      "Epoch: 21\tFidelity = 0.974693\tKL_Divergence = 0.011544\n",
      "Epoch: 22\tFidelity = 0.975464\tKL_Divergence = 0.010991\n",
      "Epoch: 23\tFidelity = 0.959750\tKL_Divergence = 0.032939\n",
      "Epoch: 24\tFidelity = 0.961123\tKL_Divergence = 0.031112\n",
      "Epoch: 25\tFidelity = 0.975227\tKL_Divergence = 0.009951\n",
      "Epoch: 26\tFidelity = 0.971806\tKL_Divergence = 0.015933\n",
      "Epoch: 27\tFidelity = 0.955564\tKL_Divergence = 0.038644\n",
      "Epoch: 28\tFidelity = 0.969698\tKL_Divergence = 0.018330\n",
      "Epoch: 29\tFidelity = 0.966478\tKL_Divergence = 0.021976\n",
      "Epoch: 30\tFidelity = 0.967763\tKL_Divergence = 0.020659\n",
      "Epoch: 31\tFidelity = 0.955143\tKL_Divergence = 0.037654\n",
      "Epoch: 32\tFidelity = 0.961897\tKL_Divergence = 0.028235\n",
      "Epoch: 33\tFidelity = 0.961930\tKL_Divergence = 0.026580\n",
      "Epoch: 34\tFidelity = 0.956198\tKL_Divergence = 0.035919\n",
      "Epoch: 35\tFidelity = 0.956933\tKL_Divergence = 0.033274\n",
      "Epoch: 36\tFidelity = 0.970389\tKL_Divergence = 0.015018\n",
      "Epoch: 37\tFidelity = 0.958018\tKL_Divergence = 0.032483\n",
      "Epoch: 38\tFidelity = 0.972579\tKL_Divergence = 0.012417\n",
      "Epoch: 39\tFidelity = 0.971868\tKL_Divergence = 0.013452\n",
      "Epoch: 40\tFidelity = 0.976556\tKL_Divergence = 0.009512\n",
      "Epoch: 41\tFidelity = 0.976448\tKL_Divergence = 0.009534\n",
      "Epoch: 42\tFidelity = 0.974136\tKL_Divergence = 0.013410\n",
      "Epoch: 43\tFidelity = 0.971239\tKL_Divergence = 0.017238\n",
      "Epoch: 44\tFidelity = 0.975010\tKL_Divergence = 0.011992\n",
      "Epoch: 45\tFidelity = 0.975430\tKL_Divergence = 0.011094\n",
      "Epoch: 46\tFidelity = 0.969598\tKL_Divergence = 0.019370\n",
      "Epoch: 47\tFidelity = 0.971306\tKL_Divergence = 0.016633\n",
      "Epoch: 48\tFidelity = 0.947024\tKL_Divergence = 0.051749\n",
      "Epoch: 49\tFidelity = 0.963037\tKL_Divergence = 0.028633\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:15:53,549] Trial 47 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.965052\tKL_Divergence = 0.025778\n",
      "Total time elapsed during training: 32.873 s\n",
      "Trial 47 pruned. \n",
      "Epoch: 1\tFidelity = 0.971278\tKL_Divergence = 0.016765\n",
      "Epoch: 2\tFidelity = 0.965444\tKL_Divergence = 0.025206\n",
      "Epoch: 3\tFidelity = 0.965131\tKL_Divergence = 0.025755\n",
      "Epoch: 4\tFidelity = 0.960855\tKL_Divergence = 0.031972\n",
      "Epoch: 5\tFidelity = 0.967874\tKL_Divergence = 0.022195\n",
      "Epoch: 6\tFidelity = 0.959570\tKL_Divergence = 0.034413\n",
      "Epoch: 7\tFidelity = 0.971923\tKL_Divergence = 0.016882\n",
      "Epoch: 8\tFidelity = 0.960511\tKL_Divergence = 0.033017\n",
      "Epoch: 9\tFidelity = 0.967319\tKL_Divergence = 0.023531\n",
      "Epoch: 10\tFidelity = 0.971932\tKL_Divergence = 0.016653\n",
      "Epoch: 11\tFidelity = 0.973478\tKL_Divergence = 0.014704\n",
      "Epoch: 12\tFidelity = 0.973090\tKL_Divergence = 0.015302\n",
      "Epoch: 13\tFidelity = 0.966459\tKL_Divergence = 0.024535\n",
      "Epoch: 14\tFidelity = 0.968055\tKL_Divergence = 0.022606\n",
      "Epoch: 15\tFidelity = 0.970243\tKL_Divergence = 0.019597\n",
      "Epoch: 16\tFidelity = 0.960477\tKL_Divergence = 0.033739\n",
      "Epoch: 17\tFidelity = 0.968003\tKL_Divergence = 0.022725\n",
      "Epoch: 18\tFidelity = 0.965468\tKL_Divergence = 0.026457\n",
      "Epoch: 19\tFidelity = 0.972318\tKL_Divergence = 0.016919\n",
      "Epoch: 20\tFidelity = 0.972583\tKL_Divergence = 0.016442\n",
      "Epoch: 21\tFidelity = 0.969194\tKL_Divergence = 0.021203\n",
      "Epoch: 22\tFidelity = 0.960234\tKL_Divergence = 0.034388\n",
      "Epoch: 23\tFidelity = 0.957019\tKL_Divergence = 0.039226\n",
      "Epoch: 24\tFidelity = 0.960353\tKL_Divergence = 0.034339\n",
      "Epoch: 25\tFidelity = 0.946805\tKL_Divergence = 0.054600\n",
      "Epoch: 26\tFidelity = 0.961556\tKL_Divergence = 0.032865\n",
      "Epoch: 27\tFidelity = 0.963595\tKL_Divergence = 0.029879\n",
      "Epoch: 28\tFidelity = 0.973465\tKL_Divergence = 0.015749\n",
      "Epoch: 29\tFidelity = 0.962107\tKL_Divergence = 0.032161\n",
      "Epoch: 30\tFidelity = 0.965711\tKL_Divergence = 0.027311\n",
      "Epoch: 31\tFidelity = 0.967235\tKL_Divergence = 0.024984\n",
      "Epoch: 32\tFidelity = 0.961606\tKL_Divergence = 0.033092\n",
      "Epoch: 33\tFidelity = 0.958820\tKL_Divergence = 0.036860\n",
      "Epoch: 34\tFidelity = 0.959744\tKL_Divergence = 0.035722\n",
      "Epoch: 35\tFidelity = 0.964480\tKL_Divergence = 0.028962\n",
      "Epoch: 36\tFidelity = 0.964651\tKL_Divergence = 0.028288\n",
      "Epoch: 37\tFidelity = 0.967204\tKL_Divergence = 0.025040\n",
      "Epoch: 38\tFidelity = 0.962331\tKL_Divergence = 0.031939\n",
      "Epoch: 39\tFidelity = 0.973156\tKL_Divergence = 0.016444\n",
      "Epoch: 40\tFidelity = 0.967207\tKL_Divergence = 0.024707\n",
      "Epoch: 41\tFidelity = 0.959608\tKL_Divergence = 0.035685\n",
      "Epoch: 42\tFidelity = 0.956199\tKL_Divergence = 0.040174\n",
      "Epoch: 43\tFidelity = 0.970365\tKL_Divergence = 0.020013\n",
      "Epoch: 44\tFidelity = 0.960988\tKL_Divergence = 0.033706\n",
      "Epoch: 45\tFidelity = 0.959598\tKL_Divergence = 0.036298\n",
      "Epoch: 46\tFidelity = 0.962642\tKL_Divergence = 0.031952\n",
      "Epoch: 47\tFidelity = 0.970567\tKL_Divergence = 0.020362\n",
      "Epoch: 48\tFidelity = 0.968698\tKL_Divergence = 0.023554\n",
      "Epoch: 49\tFidelity = 0.971884\tKL_Divergence = 0.018877\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:16:40,497] Trial 48 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.972416\tKL_Divergence = 0.018181\n",
      "Total time elapsed during training: 46.807 s\n",
      "Trial 48 pruned. \n",
      "Epoch: 1\tFidelity = 0.954169\tKL_Divergence = 0.044083\n",
      "Epoch: 2\tFidelity = 0.952839\tKL_Divergence = 0.046456\n",
      "Epoch: 3\tFidelity = 0.955318\tKL_Divergence = 0.040638\n",
      "Epoch: 4\tFidelity = 0.973135\tKL_Divergence = 0.017575\n",
      "Epoch: 5\tFidelity = 0.951198\tKL_Divergence = 0.047657\n",
      "Epoch: 6\tFidelity = 0.971854\tKL_Divergence = 0.020031\n",
      "Epoch: 7\tFidelity = 0.973532\tKL_Divergence = 0.016872\n",
      "Epoch: 8\tFidelity = 0.973583\tKL_Divergence = 0.016646\n",
      "Epoch: 9\tFidelity = 0.961555\tKL_Divergence = 0.030606\n",
      "Epoch: 10\tFidelity = 0.958112\tKL_Divergence = 0.038695\n",
      "Epoch: 11\tFidelity = 0.977023\tKL_Divergence = 0.011072\n",
      "Epoch: 12\tFidelity = 0.969817\tKL_Divergence = 0.021634\n",
      "Epoch: 13\tFidelity = 0.973680\tKL_Divergence = 0.015460\n",
      "Epoch: 14\tFidelity = 0.973792\tKL_Divergence = 0.014471\n",
      "Epoch: 15\tFidelity = 0.960483\tKL_Divergence = 0.034414\n",
      "Epoch: 16\tFidelity = 0.969408\tKL_Divergence = 0.021236\n",
      "Epoch: 17\tFidelity = 0.950396\tKL_Divergence = 0.048579\n",
      "Epoch: 18\tFidelity = 0.940225\tKL_Divergence = 0.063975\n",
      "Epoch: 19\tFidelity = 0.955030\tKL_Divergence = 0.042997\n",
      "Epoch: 20\tFidelity = 0.953292\tKL_Divergence = 0.042706\n",
      "Epoch: 21\tFidelity = 0.965778\tKL_Divergence = 0.026783\n",
      "Epoch: 22\tFidelity = 0.950008\tKL_Divergence = 0.048577\n",
      "Epoch: 23\tFidelity = 0.950757\tKL_Divergence = 0.047429\n",
      "Epoch: 24\tFidelity = 0.971101\tKL_Divergence = 0.020243\n",
      "Epoch: 25\tFidelity = 0.967066\tKL_Divergence = 0.025803\n",
      "Epoch: 26\tFidelity = 0.961080\tKL_Divergence = 0.033306\n",
      "Epoch: 27\tFidelity = 0.969087\tKL_Divergence = 0.022649\n",
      "Epoch: 28\tFidelity = 0.977587\tKL_Divergence = 0.011419\n",
      "Epoch: 29\tFidelity = 0.976402\tKL_Divergence = 0.011885\n",
      "Epoch: 30\tFidelity = 0.968890\tKL_Divergence = 0.020925\n",
      "Epoch: 31\tFidelity = 0.942547\tKL_Divergence = 0.058810\n",
      "Epoch: 32\tFidelity = 0.945954\tKL_Divergence = 0.053155\n",
      "Epoch: 33\tFidelity = 0.957866\tKL_Divergence = 0.038837\n",
      "Epoch: 34\tFidelity = 0.957883\tKL_Divergence = 0.038958\n",
      "Epoch: 35\tFidelity = 0.949152\tKL_Divergence = 0.051143\n",
      "Epoch: 36\tFidelity = 0.969690\tKL_Divergence = 0.022706\n",
      "Epoch: 37\tFidelity = 0.949830\tKL_Divergence = 0.050786\n",
      "Epoch: 38\tFidelity = 0.945750\tKL_Divergence = 0.057722\n",
      "Epoch: 39\tFidelity = 0.945914\tKL_Divergence = 0.057301\n",
      "Epoch: 40\tFidelity = 0.962571\tKL_Divergence = 0.031236\n",
      "Epoch: 41\tFidelity = 0.962799\tKL_Divergence = 0.032776\n",
      "Epoch: 42\tFidelity = 0.949339\tKL_Divergence = 0.051472\n",
      "Epoch: 43\tFidelity = 0.968248\tKL_Divergence = 0.024032\n",
      "Epoch: 44\tFidelity = 0.973449\tKL_Divergence = 0.017928\n",
      "Epoch: 45\tFidelity = 0.972434\tKL_Divergence = 0.018866\n",
      "Epoch: 46\tFidelity = 0.975339\tKL_Divergence = 0.014921\n",
      "Epoch: 47\tFidelity = 0.965468\tKL_Divergence = 0.028452\n",
      "Epoch: 48\tFidelity = 0.971703\tKL_Divergence = 0.016952\n",
      "Epoch: 49\tFidelity = 0.965426\tKL_Divergence = 0.026014\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:17:19,865] Trial 49 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.969110\tKL_Divergence = 0.023501\n",
      "Total time elapsed during training: 39.223 s\n",
      "Trial 49 pruned. \n",
      "Epoch: 1\tFidelity = 0.961030\tKL_Divergence = 0.034338\n",
      "Epoch: 2\tFidelity = 0.958449\tKL_Divergence = 0.039438\n",
      "Epoch: 3\tFidelity = 0.956260\tKL_Divergence = 0.041045\n",
      "Epoch: 4\tFidelity = 0.953331\tKL_Divergence = 0.045675\n",
      "Epoch: 5\tFidelity = 0.964532\tKL_Divergence = 0.030330\n",
      "Epoch: 6\tFidelity = 0.959831\tKL_Divergence = 0.036761\n",
      "Epoch: 7\tFidelity = 0.968874\tKL_Divergence = 0.022887\n",
      "Epoch: 8\tFidelity = 0.977234\tKL_Divergence = 0.011549\n",
      "Epoch: 9\tFidelity = 0.958772\tKL_Divergence = 0.035757\n",
      "Epoch: 10\tFidelity = 0.979266\tKL_Divergence = 0.008372\n",
      "Epoch: 11\tFidelity = 0.972605\tKL_Divergence = 0.017263\n",
      "Epoch: 12\tFidelity = 0.962874\tKL_Divergence = 0.031399\n",
      "Epoch: 13\tFidelity = 0.954267\tKL_Divergence = 0.044285\n",
      "Epoch: 14\tFidelity = 0.975764\tKL_Divergence = 0.013116\n",
      "Epoch: 15\tFidelity = 0.969694\tKL_Divergence = 0.021937\n",
      "Epoch: 16\tFidelity = 0.957729\tKL_Divergence = 0.035467\n",
      "Epoch: 17\tFidelity = 0.942001\tKL_Divergence = 0.061612\n",
      "Epoch: 18\tFidelity = 0.933674\tKL_Divergence = 0.074305\n",
      "Epoch: 19\tFidelity = 0.948707\tKL_Divergence = 0.051366\n",
      "Epoch: 20\tFidelity = 0.968310\tKL_Divergence = 0.024281\n",
      "Epoch: 21\tFidelity = 0.962455\tKL_Divergence = 0.030732\n",
      "Epoch: 22\tFidelity = 0.958917\tKL_Divergence = 0.034579\n",
      "Epoch: 23\tFidelity = 0.968326\tKL_Divergence = 0.021244\n",
      "Epoch: 24\tFidelity = 0.972982\tKL_Divergence = 0.015372\n",
      "Epoch: 25\tFidelity = 0.969148\tKL_Divergence = 0.022504\n",
      "Epoch: 26\tFidelity = 0.976511\tKL_Divergence = 0.012647\n",
      "Epoch: 27\tFidelity = 0.957128\tKL_Divergence = 0.037040\n",
      "Epoch: 28\tFidelity = 0.968756\tKL_Divergence = 0.022055\n",
      "Epoch: 29\tFidelity = 0.951724\tKL_Divergence = 0.048162\n",
      "Epoch: 30\tFidelity = 0.961380\tKL_Divergence = 0.034187\n",
      "Epoch: 31\tFidelity = 0.971837\tKL_Divergence = 0.018455\n",
      "Epoch: 32\tFidelity = 0.944405\tKL_Divergence = 0.059512\n",
      "Epoch: 33\tFidelity = 0.943498\tKL_Divergence = 0.061124\n",
      "Epoch: 34\tFidelity = 0.936211\tKL_Divergence = 0.072520\n",
      "Epoch: 35\tFidelity = 0.964214\tKL_Divergence = 0.031034\n",
      "Epoch: 36\tFidelity = 0.948982\tKL_Divergence = 0.053517\n",
      "Epoch: 37\tFidelity = 0.961410\tKL_Divergence = 0.033309\n",
      "Epoch: 38\tFidelity = 0.958152\tKL_Divergence = 0.039736\n",
      "Epoch: 39\tFidelity = 0.959466\tKL_Divergence = 0.038299\n",
      "Epoch: 40\tFidelity = 0.967461\tKL_Divergence = 0.026434\n",
      "Epoch: 41\tFidelity = 0.976980\tKL_Divergence = 0.013457\n",
      "Epoch: 42\tFidelity = 0.968643\tKL_Divergence = 0.023447\n",
      "Epoch: 43\tFidelity = 0.956989\tKL_Divergence = 0.040304\n",
      "Epoch: 44\tFidelity = 0.937009\tKL_Divergence = 0.068543\n",
      "Epoch: 45\tFidelity = 0.969106\tKL_Divergence = 0.023812\n",
      "Epoch: 46\tFidelity = 0.964415\tKL_Divergence = 0.030501\n",
      "Epoch: 47\tFidelity = 0.944420\tKL_Divergence = 0.060007\n",
      "Epoch: 48\tFidelity = 0.942861\tKL_Divergence = 0.059543\n",
      "Epoch: 49\tFidelity = 0.954541\tKL_Divergence = 0.045713\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:18:04,304] Trial 50 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.962782\tKL_Divergence = 0.033152\n",
      "Total time elapsed during training: 44.296 s\n",
      "Trial 50 pruned. \n",
      "Epoch: 1\tFidelity = 0.963201\tKL_Divergence = 0.032465\n",
      "Epoch: 2\tFidelity = 0.973893\tKL_Divergence = 0.017797\n",
      "Epoch: 3\tFidelity = 0.946658\tKL_Divergence = 0.057201\n",
      "Epoch: 4\tFidelity = 0.962025\tKL_Divergence = 0.033216\n",
      "Epoch: 5\tFidelity = 0.968738\tKL_Divergence = 0.023105\n",
      "Epoch: 6\tFidelity = 0.958835\tKL_Divergence = 0.038970\n",
      "Epoch: 7\tFidelity = 0.932169\tKL_Divergence = 0.077660\n",
      "Epoch: 8\tFidelity = 0.974981\tKL_Divergence = 0.015392\n",
      "Epoch: 9\tFidelity = 0.954082\tKL_Divergence = 0.043175\n",
      "Epoch: 10\tFidelity = 0.951948\tKL_Divergence = 0.049328\n",
      "Epoch: 11\tFidelity = 0.968355\tKL_Divergence = 0.025924\n",
      "Epoch: 12\tFidelity = 0.971840\tKL_Divergence = 0.018343\n",
      "Epoch: 13\tFidelity = 0.972302\tKL_Divergence = 0.019814\n",
      "Epoch: 14\tFidelity = 0.971586\tKL_Divergence = 0.021010\n",
      "Epoch: 15\tFidelity = 0.965407\tKL_Divergence = 0.028623\n",
      "Epoch: 16\tFidelity = 0.971403\tKL_Divergence = 0.018064\n",
      "Epoch: 17\tFidelity = 0.979559\tKL_Divergence = 0.009847\n",
      "Epoch: 18\tFidelity = 0.965045\tKL_Divergence = 0.029944\n",
      "Epoch: 19\tFidelity = 0.963474\tKL_Divergence = 0.032055\n",
      "Epoch: 20\tFidelity = 0.971535\tKL_Divergence = 0.020285\n",
      "Epoch: 21\tFidelity = 0.955674\tKL_Divergence = 0.042552\n",
      "Epoch: 22\tFidelity = 0.946623\tKL_Divergence = 0.057216\n",
      "Epoch: 23\tFidelity = 0.968644\tKL_Divergence = 0.025102\n",
      "Epoch: 24\tFidelity = 0.962084\tKL_Divergence = 0.034809\n",
      "Epoch: 25\tFidelity = 0.967285\tKL_Divergence = 0.027455\n",
      "Epoch: 26\tFidelity = 0.950290\tKL_Divergence = 0.051017\n",
      "Epoch: 27\tFidelity = 0.961635\tKL_Divergence = 0.035799\n",
      "Epoch: 28\tFidelity = 0.963870\tKL_Divergence = 0.032521\n",
      "Epoch: 29\tFidelity = 0.960803\tKL_Divergence = 0.036854\n",
      "Epoch: 30\tFidelity = 0.970310\tKL_Divergence = 0.022983\n",
      "Epoch: 31\tFidelity = 0.963779\tKL_Divergence = 0.030410\n",
      "Epoch: 32\tFidelity = 0.949413\tKL_Divergence = 0.053286\n",
      "Epoch: 33\tFidelity = 0.948911\tKL_Divergence = 0.053721\n",
      "Epoch: 34\tFidelity = 0.963820\tKL_Divergence = 0.031827\n",
      "Epoch: 35\tFidelity = 0.958874\tKL_Divergence = 0.039893\n",
      "Epoch: 36\tFidelity = 0.948476\tKL_Divergence = 0.052612\n",
      "Epoch: 37\tFidelity = 0.957376\tKL_Divergence = 0.041498\n",
      "Epoch: 38\tFidelity = 0.958210\tKL_Divergence = 0.040435\n",
      "Epoch: 39\tFidelity = 0.969253\tKL_Divergence = 0.025654\n",
      "Epoch: 40\tFidelity = 0.965352\tKL_Divergence = 0.031154\n",
      "Epoch: 41\tFidelity = 0.942643\tKL_Divergence = 0.064465\n",
      "Epoch: 42\tFidelity = 0.926837\tKL_Divergence = 0.088627\n",
      "Epoch: 43\tFidelity = 0.967628\tKL_Divergence = 0.026738\n",
      "Epoch: 44\tFidelity = 0.977986\tKL_Divergence = 0.013396\n",
      "Epoch: 45\tFidelity = 0.970116\tKL_Divergence = 0.023956\n",
      "Epoch: 46\tFidelity = 0.965911\tKL_Divergence = 0.030643\n",
      "Epoch: 47\tFidelity = 0.937510\tKL_Divergence = 0.070891\n",
      "Epoch: 48\tFidelity = 0.958202\tKL_Divergence = 0.042065\n",
      "Epoch: 49\tFidelity = 0.957232\tKL_Divergence = 0.041262\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:18:41,562] Trial 51 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.951227\tKL_Divergence = 0.052110\n",
      "Total time elapsed during training: 37.118 s\n",
      "Trial 51 pruned. \n",
      "Epoch: 1\tFidelity = 0.950545\tKL_Divergence = 0.052819\n",
      "Epoch: 2\tFidelity = 0.963619\tKL_Divergence = 0.034366\n",
      "Epoch: 3\tFidelity = 0.953376\tKL_Divergence = 0.048882\n",
      "Epoch: 4\tFidelity = 0.964038\tKL_Divergence = 0.031889\n",
      "Epoch: 5\tFidelity = 0.935333\tKL_Divergence = 0.076093\n",
      "Epoch: 6\tFidelity = 0.940145\tKL_Divergence = 0.069143\n",
      "Epoch: 7\tFidelity = 0.926400\tKL_Divergence = 0.090236\n",
      "Epoch: 8\tFidelity = 0.969130\tKL_Divergence = 0.026792\n",
      "Epoch: 9\tFidelity = 0.969444\tKL_Divergence = 0.026761\n",
      "Epoch: 10\tFidelity = 0.957005\tKL_Divergence = 0.043996\n",
      "Epoch: 11\tFidelity = 0.961160\tKL_Divergence = 0.038304\n",
      "Epoch: 12\tFidelity = 0.960829\tKL_Divergence = 0.038727\n",
      "Epoch: 13\tFidelity = 0.952125\tKL_Divergence = 0.051638\n",
      "Epoch: 14\tFidelity = 0.949695\tKL_Divergence = 0.055509\n",
      "Epoch: 15\tFidelity = 0.967530\tKL_Divergence = 0.029493\n",
      "Epoch: 16\tFidelity = 0.966587\tKL_Divergence = 0.031105\n",
      "Epoch: 17\tFidelity = 0.946575\tKL_Divergence = 0.059341\n",
      "Epoch: 18\tFidelity = 0.955624\tKL_Divergence = 0.047075\n",
      "Epoch: 19\tFidelity = 0.943449\tKL_Divergence = 0.064518\n",
      "Epoch: 20\tFidelity = 0.917237\tKL_Divergence = 0.104714\n",
      "Epoch: 21\tFidelity = 0.938983\tKL_Divergence = 0.071862\n",
      "Epoch: 22\tFidelity = 0.963990\tKL_Divergence = 0.035336\n",
      "Epoch: 23\tFidelity = 0.948652\tKL_Divergence = 0.056440\n",
      "Epoch: 24\tFidelity = 0.957047\tKL_Divergence = 0.045230\n",
      "Epoch: 25\tFidelity = 0.950367\tKL_Divergence = 0.055079\n",
      "Epoch: 26\tFidelity = 0.937171\tKL_Divergence = 0.074459\n",
      "Epoch: 27\tFidelity = 0.947935\tKL_Divergence = 0.058760\n",
      "Epoch: 28\tFidelity = 0.937367\tKL_Divergence = 0.074147\n",
      "Epoch: 29\tFidelity = 0.956466\tKL_Divergence = 0.046187\n",
      "Epoch: 30\tFidelity = 0.944938\tKL_Divergence = 0.063662\n",
      "Epoch: 31\tFidelity = 0.948518\tKL_Divergence = 0.058148\n",
      "Epoch: 32\tFidelity = 0.941747\tKL_Divergence = 0.068544\n",
      "Epoch: 33\tFidelity = 0.934057\tKL_Divergence = 0.079988\n",
      "Epoch: 34\tFidelity = 0.960197\tKL_Divergence = 0.040884\n",
      "Epoch: 35\tFidelity = 0.950874\tKL_Divergence = 0.055222\n",
      "Epoch: 36\tFidelity = 0.961385\tKL_Divergence = 0.039925\n",
      "Epoch: 37\tFidelity = 0.967030\tKL_Divergence = 0.031607\n",
      "Epoch: 38\tFidelity = 0.960496\tKL_Divergence = 0.040850\n",
      "Epoch: 39\tFidelity = 0.969058\tKL_Divergence = 0.028890\n",
      "Epoch: 40\tFidelity = 0.957951\tKL_Divergence = 0.043885\n",
      "Epoch: 41\tFidelity = 0.939729\tKL_Divergence = 0.071421\n",
      "Epoch: 42\tFidelity = 0.946849\tKL_Divergence = 0.060334\n",
      "Epoch: 43\tFidelity = 0.954550\tKL_Divergence = 0.049442\n",
      "Epoch: 44\tFidelity = 0.969337\tKL_Divergence = 0.028546\n",
      "Epoch: 45\tFidelity = 0.967561\tKL_Divergence = 0.030794\n",
      "Epoch: 46\tFidelity = 0.960380\tKL_Divergence = 0.041595\n",
      "Epoch: 47\tFidelity = 0.935631\tKL_Divergence = 0.077931\n",
      "Epoch: 48\tFidelity = 0.948719\tKL_Divergence = 0.056388\n",
      "Epoch: 49\tFidelity = 0.952103\tKL_Divergence = 0.052973\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:19:18,273] Trial 52 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.970268\tKL_Divergence = 0.025223\n",
      "Total time elapsed during training: 36.572 s\n",
      "Trial 52 pruned. \n",
      "Epoch: 1\tFidelity = 0.959983\tKL_Divergence = 0.041500\n",
      "Epoch: 2\tFidelity = 0.966794\tKL_Divergence = 0.031927\n",
      "Epoch: 3\tFidelity = 0.953369\tKL_Divergence = 0.051184\n",
      "Epoch: 4\tFidelity = 0.942990\tKL_Divergence = 0.066420\n",
      "Epoch: 5\tFidelity = 0.940672\tKL_Divergence = 0.069796\n",
      "Epoch: 6\tFidelity = 0.935833\tKL_Divergence = 0.077407\n",
      "Epoch: 7\tFidelity = 0.950243\tKL_Divergence = 0.055680\n",
      "Epoch: 8\tFidelity = 0.961280\tKL_Divergence = 0.039714\n",
      "Epoch: 9\tFidelity = 0.950081\tKL_Divergence = 0.056492\n",
      "Epoch: 10\tFidelity = 0.954873\tKL_Divergence = 0.049296\n",
      "Epoch: 11\tFidelity = 0.951288\tKL_Divergence = 0.052682\n",
      "Epoch: 12\tFidelity = 0.961056\tKL_Divergence = 0.040470\n",
      "Epoch: 13\tFidelity = 0.959148\tKL_Divergence = 0.041587\n",
      "Epoch: 14\tFidelity = 0.957108\tKL_Divergence = 0.044882\n",
      "Epoch: 15\tFidelity = 0.964431\tKL_Divergence = 0.036185\n",
      "Epoch: 16\tFidelity = 0.965809\tKL_Divergence = 0.034243\n",
      "Epoch: 17\tFidelity = 0.961034\tKL_Divergence = 0.039458\n",
      "Epoch: 18\tFidelity = 0.956598\tKL_Divergence = 0.044773\n",
      "Epoch: 19\tFidelity = 0.939874\tKL_Divergence = 0.071383\n",
      "Epoch: 20\tFidelity = 0.948845\tKL_Divergence = 0.057689\n",
      "Epoch: 21\tFidelity = 0.963956\tKL_Divergence = 0.036927\n",
      "Epoch: 22\tFidelity = 0.954875\tKL_Divergence = 0.048713\n",
      "Epoch: 23\tFidelity = 0.933658\tKL_Divergence = 0.080964\n",
      "Epoch: 24\tFidelity = 0.958218\tKL_Divergence = 0.044374\n",
      "Epoch: 25\tFidelity = 0.945369\tKL_Divergence = 0.064271\n",
      "Epoch: 26\tFidelity = 0.926419\tKL_Divergence = 0.093128\n",
      "Epoch: 27\tFidelity = 0.951891\tKL_Divergence = 0.054827\n",
      "Epoch: 28\tFidelity = 0.948712\tKL_Divergence = 0.059193\n",
      "Epoch: 29\tFidelity = 0.961703\tKL_Divergence = 0.040708\n",
      "Epoch: 30\tFidelity = 0.944046\tKL_Divergence = 0.066530\n",
      "Epoch: 31\tFidelity = 0.956290\tKL_Divergence = 0.047356\n",
      "Epoch: 32\tFidelity = 0.930367\tKL_Divergence = 0.086369\n",
      "Epoch: 33\tFidelity = 0.936266\tKL_Divergence = 0.077421\n",
      "Epoch: 34\tFidelity = 0.961107\tKL_Divergence = 0.040741\n",
      "Epoch: 35\tFidelity = 0.942997\tKL_Divergence = 0.068084\n",
      "Epoch: 36\tFidelity = 0.958060\tKL_Divergence = 0.045827\n",
      "Epoch: 37\tFidelity = 0.963322\tKL_Divergence = 0.038056\n",
      "Epoch: 38\tFidelity = 0.968714\tKL_Divergence = 0.030862\n",
      "Epoch: 39\tFidelity = 0.962949\tKL_Divergence = 0.037823\n",
      "Epoch: 40\tFidelity = 0.962418\tKL_Divergence = 0.040046\n",
      "Epoch: 41\tFidelity = 0.957476\tKL_Divergence = 0.046483\n",
      "Epoch: 42\tFidelity = 0.956351\tKL_Divergence = 0.048812\n",
      "Epoch: 43\tFidelity = 0.946764\tKL_Divergence = 0.062929\n",
      "Epoch: 44\tFidelity = 0.944776\tKL_Divergence = 0.065337\n",
      "Epoch: 45\tFidelity = 0.922811\tKL_Divergence = 0.099612\n",
      "Epoch: 46\tFidelity = 0.964240\tKL_Divergence = 0.037784\n",
      "Epoch: 47\tFidelity = 0.944538\tKL_Divergence = 0.064826\n",
      "Epoch: 48\tFidelity = 0.950768\tKL_Divergence = 0.057117\n",
      "Epoch: 49\tFidelity = 0.936963\tKL_Divergence = 0.077266\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:19:55,097] Trial 53 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.956384\tKL_Divergence = 0.049081\n",
      "Total time elapsed during training: 36.685 s\n",
      "Trial 53 pruned. \n",
      "Epoch: 1\tFidelity = 0.937835\tKL_Divergence = 0.075471\n",
      "Epoch: 2\tFidelity = 0.944826\tKL_Divergence = 0.066194\n",
      "Epoch: 3\tFidelity = 0.950687\tKL_Divergence = 0.056923\n",
      "Epoch: 4\tFidelity = 0.913520\tKL_Divergence = 0.113968\n",
      "Epoch: 5\tFidelity = 0.946560\tKL_Divergence = 0.063803\n",
      "Epoch: 6\tFidelity = 0.969243\tKL_Divergence = 0.029045\n",
      "Epoch: 7\tFidelity = 0.962027\tKL_Divergence = 0.038954\n",
      "Epoch: 8\tFidelity = 0.927817\tKL_Divergence = 0.092205\n",
      "Epoch: 9\tFidelity = 0.961178\tKL_Divergence = 0.042151\n",
      "Epoch: 10\tFidelity = 0.968116\tKL_Divergence = 0.032242\n",
      "Epoch: 11\tFidelity = 0.940617\tKL_Divergence = 0.072579\n",
      "Epoch: 12\tFidelity = 0.916496\tKL_Divergence = 0.108088\n",
      "Epoch: 13\tFidelity = 0.975263\tKL_Divergence = 0.021534\n",
      "Epoch: 14\tFidelity = 0.934599\tKL_Divergence = 0.081764\n",
      "Epoch: 15\tFidelity = 0.924901\tKL_Divergence = 0.096796\n",
      "Epoch: 16\tFidelity = 0.946067\tKL_Divergence = 0.064646\n",
      "Epoch: 17\tFidelity = 0.931464\tKL_Divergence = 0.085929\n",
      "Epoch: 18\tFidelity = 0.961132\tKL_Divergence = 0.041980\n",
      "Epoch: 19\tFidelity = 0.980893\tKL_Divergence = 0.014400\n",
      "Epoch: 20\tFidelity = 0.958075\tKL_Divergence = 0.045358\n",
      "Epoch: 21\tFidelity = 0.969637\tKL_Divergence = 0.029572\n",
      "Epoch: 22\tFidelity = 0.948653\tKL_Divergence = 0.060713\n",
      "Epoch: 23\tFidelity = 0.940732\tKL_Divergence = 0.070741\n",
      "Epoch: 24\tFidelity = 0.973727\tKL_Divergence = 0.024320\n",
      "Epoch: 25\tFidelity = 0.948950\tKL_Divergence = 0.060011\n",
      "Epoch: 26\tFidelity = 0.935425\tKL_Divergence = 0.079191\n",
      "Epoch: 27\tFidelity = 0.960767\tKL_Divergence = 0.041699\n",
      "Epoch: 28\tFidelity = 0.972672\tKL_Divergence = 0.025879\n",
      "Epoch: 29\tFidelity = 0.950350\tKL_Divergence = 0.057415\n",
      "Epoch: 30\tFidelity = 0.907895\tKL_Divergence = 0.122317\n",
      "Epoch: 31\tFidelity = 0.954593\tKL_Divergence = 0.051563\n",
      "Epoch: 32\tFidelity = 0.962296\tKL_Divergence = 0.040630\n",
      "Epoch: 33\tFidelity = 0.955442\tKL_Divergence = 0.050595\n",
      "Epoch: 34\tFidelity = 0.965837\tKL_Divergence = 0.035625\n",
      "Epoch: 35\tFidelity = 0.949184\tKL_Divergence = 0.059936\n",
      "Epoch: 36\tFidelity = 0.925264\tKL_Divergence = 0.095753\n",
      "Epoch: 37\tFidelity = 0.931676\tKL_Divergence = 0.085914\n",
      "Epoch: 38\tFidelity = 0.937248\tKL_Divergence = 0.078003\n",
      "Epoch: 39\tFidelity = 0.947406\tKL_Divergence = 0.061643\n",
      "Epoch: 40\tFidelity = 0.920713\tKL_Divergence = 0.102994\n",
      "Epoch: 41\tFidelity = 0.933515\tKL_Divergence = 0.083841\n",
      "Epoch: 42\tFidelity = 0.951435\tKL_Divergence = 0.057078\n",
      "Epoch: 43\tFidelity = 0.959024\tKL_Divergence = 0.045471\n",
      "Epoch: 44\tFidelity = 0.921236\tKL_Divergence = 0.101880\n",
      "Epoch: 45\tFidelity = 0.923846\tKL_Divergence = 0.096539\n",
      "Epoch: 46\tFidelity = 0.899916\tKL_Divergence = 0.135643\n",
      "Epoch: 47\tFidelity = 0.910708\tKL_Divergence = 0.119571\n",
      "Epoch: 48\tFidelity = 0.916162\tKL_Divergence = 0.110960\n",
      "Epoch: 49\tFidelity = 0.957124\tKL_Divergence = 0.049256\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:20:31,782] Trial 54 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.915214\tKL_Divergence = 0.112845\n",
      "Total time elapsed during training: 36.551 s\n",
      "Trial 54 pruned. \n",
      "Epoch: 1\tFidelity = 0.923253\tKL_Divergence = 0.100366\n",
      "Epoch: 2\tFidelity = 0.919017\tKL_Divergence = 0.106868\n",
      "Epoch: 3\tFidelity = 0.921432\tKL_Divergence = 0.103019\n",
      "Epoch: 4\tFidelity = 0.946822\tKL_Divergence = 0.064724\n",
      "Epoch: 5\tFidelity = 0.942367\tKL_Divergence = 0.071336\n",
      "Epoch: 6\tFidelity = 0.936696\tKL_Divergence = 0.078529\n",
      "Epoch: 7\tFidelity = 0.946185\tKL_Divergence = 0.065733\n",
      "Epoch: 8\tFidelity = 0.933280\tKL_Divergence = 0.085292\n",
      "Epoch: 9\tFidelity = 0.915015\tKL_Divergence = 0.113665\n",
      "Epoch: 10\tFidelity = 0.928480\tKL_Divergence = 0.092780\n",
      "Epoch: 11\tFidelity = 0.945182\tKL_Divergence = 0.067555\n",
      "Epoch: 12\tFidelity = 0.933990\tKL_Divergence = 0.084445\n",
      "Epoch: 13\tFidelity = 0.924878\tKL_Divergence = 0.098102\n",
      "Epoch: 14\tFidelity = 0.936985\tKL_Divergence = 0.079563\n",
      "Epoch: 15\tFidelity = 0.935952\tKL_Divergence = 0.081600\n",
      "Epoch: 16\tFidelity = 0.938673\tKL_Divergence = 0.077289\n",
      "Epoch: 17\tFidelity = 0.922141\tKL_Divergence = 0.102784\n",
      "Epoch: 18\tFidelity = 0.919274\tKL_Divergence = 0.107094\n",
      "Epoch: 19\tFidelity = 0.933175\tKL_Divergence = 0.084742\n",
      "Epoch: 20\tFidelity = 0.946209\tKL_Divergence = 0.066059\n",
      "Epoch: 21\tFidelity = 0.944489\tKL_Divergence = 0.068575\n",
      "Epoch: 22\tFidelity = 0.943998\tKL_Divergence = 0.068705\n",
      "Epoch: 23\tFidelity = 0.953155\tKL_Divergence = 0.055997\n",
      "Epoch: 24\tFidelity = 0.930090\tKL_Divergence = 0.090123\n",
      "Epoch: 25\tFidelity = 0.935788\tKL_Divergence = 0.081906\n",
      "Epoch: 26\tFidelity = 0.926067\tKL_Divergence = 0.096684\n",
      "Epoch: 27\tFidelity = 0.942228\tKL_Divergence = 0.072040\n",
      "Epoch: 28\tFidelity = 0.941268\tKL_Divergence = 0.073570\n",
      "Epoch: 29\tFidelity = 0.940080\tKL_Divergence = 0.074871\n",
      "Epoch: 30\tFidelity = 0.896547\tKL_Divergence = 0.144205\n",
      "Epoch: 31\tFidelity = 0.917471\tKL_Divergence = 0.110638\n",
      "Epoch: 32\tFidelity = 0.920781\tKL_Divergence = 0.104614\n",
      "Epoch: 33\tFidelity = 0.945891\tKL_Divergence = 0.066816\n",
      "Epoch: 34\tFidelity = 0.920095\tKL_Divergence = 0.106388\n",
      "Epoch: 35\tFidelity = 0.920067\tKL_Divergence = 0.106445\n",
      "Epoch: 36\tFidelity = 0.911655\tKL_Divergence = 0.118838\n",
      "Epoch: 37\tFidelity = 0.921844\tKL_Divergence = 0.103952\n",
      "Epoch: 38\tFidelity = 0.905091\tKL_Divergence = 0.130659\n",
      "Epoch: 39\tFidelity = 0.897177\tKL_Divergence = 0.142061\n",
      "Epoch: 40\tFidelity = 0.895457\tKL_Divergence = 0.146291\n",
      "Epoch: 41\tFidelity = 0.924382\tKL_Divergence = 0.099905\n",
      "Epoch: 42\tFidelity = 0.935840\tKL_Divergence = 0.082474\n",
      "Epoch: 43\tFidelity = 0.921035\tKL_Divergence = 0.105352\n",
      "Epoch: 44\tFidelity = 0.943759\tKL_Divergence = 0.070665\n",
      "Epoch: 45\tFidelity = 0.903606\tKL_Divergence = 0.132367\n",
      "Epoch: 46\tFidelity = 0.915936\tKL_Divergence = 0.111508\n",
      "Epoch: 47\tFidelity = 0.901800\tKL_Divergence = 0.136238\n",
      "Epoch: 48\tFidelity = 0.937113\tKL_Divergence = 0.080284\n",
      "Epoch: 49\tFidelity = 0.911229\tKL_Divergence = 0.120914\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:21:09,821] Trial 55 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.933509\tKL_Divergence = 0.085874\n",
      "Total time elapsed during training: 37.907 s\n",
      "Trial 55 pruned. \n",
      "Epoch: 1\tFidelity = 0.920718\tKL_Divergence = 0.105686\n",
      "Epoch: 2\tFidelity = 0.932442\tKL_Divergence = 0.087763\n",
      "Epoch: 3\tFidelity = 0.910931\tKL_Divergence = 0.121251\n",
      "Epoch: 4\tFidelity = 0.925972\tKL_Divergence = 0.097329\n",
      "Epoch: 5\tFidelity = 0.940888\tKL_Divergence = 0.075232\n",
      "Epoch: 6\tFidelity = 0.916084\tKL_Divergence = 0.112899\n",
      "Epoch: 7\tFidelity = 0.913492\tKL_Divergence = 0.116844\n",
      "Epoch: 8\tFidelity = 0.922011\tKL_Divergence = 0.104244\n",
      "Epoch: 9\tFidelity = 0.912876\tKL_Divergence = 0.118694\n",
      "Epoch: 10\tFidelity = 0.925430\tKL_Divergence = 0.098834\n",
      "Epoch: 11\tFidelity = 0.898740\tKL_Divergence = 0.140719\n",
      "Epoch: 12\tFidelity = 0.932289\tKL_Divergence = 0.088390\n",
      "Epoch: 13\tFidelity = 0.900346\tKL_Divergence = 0.139109\n",
      "Epoch: 14\tFidelity = 0.923216\tKL_Divergence = 0.102516\n",
      "Epoch: 15\tFidelity = 0.911678\tKL_Divergence = 0.120007\n",
      "Epoch: 16\tFidelity = 0.920891\tKL_Divergence = 0.106224\n",
      "Epoch: 17\tFidelity = 0.897846\tKL_Divergence = 0.143338\n",
      "Epoch: 18\tFidelity = 0.908876\tKL_Divergence = 0.125358\n",
      "Epoch: 19\tFidelity = 0.898622\tKL_Divergence = 0.141455\n",
      "Epoch: 20\tFidelity = 0.904768\tKL_Divergence = 0.131927\n",
      "Epoch: 21\tFidelity = 0.896403\tKL_Divergence = 0.145533\n",
      "Epoch: 22\tFidelity = 0.917915\tKL_Divergence = 0.111129\n",
      "Epoch: 23\tFidelity = 0.930378\tKL_Divergence = 0.091474\n",
      "Epoch: 24\tFidelity = 0.919850\tKL_Divergence = 0.107964\n",
      "Epoch: 25\tFidelity = 0.925532\tKL_Divergence = 0.098746\n",
      "Epoch: 26\tFidelity = 0.895588\tKL_Divergence = 0.146585\n",
      "Epoch: 27\tFidelity = 0.903579\tKL_Divergence = 0.133474\n",
      "Epoch: 28\tFidelity = 0.889468\tKL_Divergence = 0.157551\n",
      "Epoch: 29\tFidelity = 0.902821\tKL_Divergence = 0.135495\n",
      "Epoch: 30\tFidelity = 0.918495\tKL_Divergence = 0.110209\n",
      "Epoch: 31\tFidelity = 0.915319\tKL_Divergence = 0.114973\n",
      "Epoch: 32\tFidelity = 0.896504\tKL_Divergence = 0.145530\n",
      "Epoch: 33\tFidelity = 0.897331\tKL_Divergence = 0.144597\n",
      "Epoch: 34\tFidelity = 0.887360\tKL_Divergence = 0.160333\n",
      "Epoch: 35\tFidelity = 0.898845\tKL_Divergence = 0.142067\n",
      "Epoch: 36\tFidelity = 0.891770\tKL_Divergence = 0.153802\n",
      "Epoch: 37\tFidelity = 0.914283\tKL_Divergence = 0.116949\n",
      "Epoch: 38\tFidelity = 0.917685\tKL_Divergence = 0.111008\n",
      "Epoch: 39\tFidelity = 0.898691\tKL_Divergence = 0.142264\n",
      "Epoch: 40\tFidelity = 0.905261\tKL_Divergence = 0.131316\n",
      "Epoch: 41\tFidelity = 0.914685\tKL_Divergence = 0.114707\n",
      "Epoch: 42\tFidelity = 0.895755\tKL_Divergence = 0.146877\n",
      "Epoch: 43\tFidelity = 0.903810\tKL_Divergence = 0.132836\n",
      "Epoch: 44\tFidelity = 0.879563\tKL_Divergence = 0.174031\n",
      "Epoch: 45\tFidelity = 0.886694\tKL_Divergence = 0.162554\n",
      "Epoch: 46\tFidelity = 0.878951\tKL_Divergence = 0.175807\n",
      "Epoch: 47\tFidelity = 0.901012\tKL_Divergence = 0.138601\n",
      "Epoch: 48\tFidelity = 0.905765\tKL_Divergence = 0.131065\n",
      "Epoch: 49\tFidelity = 0.886901\tKL_Divergence = 0.162324\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:21:47,084] Trial 56 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.892387\tKL_Divergence = 0.152061\n",
      "Total time elapsed during training: 37.114 s\n",
      "Trial 56 pruned. \n",
      "Epoch: 1\tFidelity = 0.899648\tKL_Divergence = 0.140740\n",
      "Epoch: 2\tFidelity = 0.869822\tKL_Divergence = 0.191904\n",
      "Epoch: 3\tFidelity = 0.895574\tKL_Divergence = 0.147929\n",
      "Epoch: 4\tFidelity = 0.895100\tKL_Divergence = 0.148537\n",
      "Epoch: 5\tFidelity = 0.905662\tKL_Divergence = 0.131287\n",
      "Epoch: 6\tFidelity = 0.899019\tKL_Divergence = 0.142248\n",
      "Epoch: 7\tFidelity = 0.884366\tKL_Divergence = 0.166837\n",
      "Epoch: 8\tFidelity = 0.888816\tKL_Divergence = 0.158943\n",
      "Epoch: 9\tFidelity = 0.890752\tKL_Divergence = 0.155867\n",
      "Epoch: 10\tFidelity = 0.875988\tKL_Divergence = 0.181042\n",
      "Epoch: 11\tFidelity = 0.893828\tKL_Divergence = 0.150898\n",
      "Epoch: 12\tFidelity = 0.882314\tKL_Divergence = 0.170409\n",
      "Epoch: 13\tFidelity = 0.865819\tKL_Divergence = 0.198290\n",
      "Epoch: 14\tFidelity = 0.903566\tKL_Divergence = 0.134988\n",
      "Epoch: 15\tFidelity = 0.897303\tKL_Divergence = 0.145177\n",
      "Epoch: 16\tFidelity = 0.883314\tKL_Divergence = 0.168716\n",
      "Epoch: 17\tFidelity = 0.889937\tKL_Divergence = 0.157053\n",
      "Epoch: 18\tFidelity = 0.896136\tKL_Divergence = 0.146836\n",
      "Epoch: 19\tFidelity = 0.892374\tKL_Divergence = 0.153432\n",
      "Epoch: 20\tFidelity = 0.871854\tKL_Divergence = 0.188256\n",
      "Epoch: 21\tFidelity = 0.883242\tKL_Divergence = 0.168687\n",
      "Epoch: 22\tFidelity = 0.879034\tKL_Divergence = 0.175779\n",
      "Epoch: 23\tFidelity = 0.882567\tKL_Divergence = 0.169876\n",
      "Epoch: 24\tFidelity = 0.903781\tKL_Divergence = 0.134706\n",
      "Epoch: 25\tFidelity = 0.871094\tKL_Divergence = 0.189906\n",
      "Epoch: 26\tFidelity = 0.884301\tKL_Divergence = 0.166614\n",
      "Epoch: 27\tFidelity = 0.858803\tKL_Divergence = 0.211943\n",
      "Epoch: 28\tFidelity = 0.842479\tKL_Divergence = 0.240713\n",
      "Epoch: 29\tFidelity = 0.886664\tKL_Divergence = 0.163096\n",
      "Epoch: 30\tFidelity = 0.878105\tKL_Divergence = 0.177514\n",
      "Epoch: 31\tFidelity = 0.857264\tKL_Divergence = 0.214385\n",
      "Epoch: 32\tFidelity = 0.889543\tKL_Divergence = 0.158146\n",
      "Epoch: 33\tFidelity = 0.871713\tKL_Divergence = 0.189056\n",
      "Epoch: 34\tFidelity = 0.857319\tKL_Divergence = 0.214666\n",
      "Epoch: 35\tFidelity = 0.862311\tKL_Divergence = 0.204721\n",
      "Epoch: 36\tFidelity = 0.869524\tKL_Divergence = 0.192702\n",
      "Epoch: 37\tFidelity = 0.877418\tKL_Divergence = 0.178621\n",
      "Epoch: 38\tFidelity = 0.898140\tKL_Divergence = 0.144018\n",
      "Epoch: 39\tFidelity = 0.873415\tKL_Divergence = 0.185739\n",
      "Epoch: 40\tFidelity = 0.839460\tKL_Divergence = 0.248087\n",
      "Epoch: 41\tFidelity = 0.869482\tKL_Divergence = 0.192388\n",
      "Epoch: 42\tFidelity = 0.858249\tKL_Divergence = 0.213154\n",
      "Epoch: 43\tFidelity = 0.876844\tKL_Divergence = 0.180092\n",
      "Epoch: 44\tFidelity = 0.859166\tKL_Divergence = 0.211583\n",
      "Epoch: 45\tFidelity = 0.838140\tKL_Divergence = 0.249908\n",
      "Epoch: 46\tFidelity = 0.853906\tKL_Divergence = 0.221138\n",
      "Epoch: 47\tFidelity = 0.872128\tKL_Divergence = 0.188098\n",
      "Epoch: 48\tFidelity = 0.872830\tKL_Divergence = 0.186810\n",
      "Epoch: 49\tFidelity = 0.875902\tKL_Divergence = 0.181850\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:22:24,657] Trial 57 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.869086\tKL_Divergence = 0.193649\n",
      "Total time elapsed during training: 37.432 s\n",
      "Trial 57 pruned. \n",
      "Epoch: 1\tFidelity = 0.871816\tKL_Divergence = 0.189132\n",
      "Epoch: 2\tFidelity = 0.852667\tKL_Divergence = 0.223565\n",
      "Epoch: 3\tFidelity = 0.857957\tKL_Divergence = 0.213919\n",
      "Epoch: 4\tFidelity = 0.869353\tKL_Divergence = 0.193552\n",
      "Epoch: 5\tFidelity = 0.891197\tKL_Divergence = 0.156027\n",
      "Epoch: 6\tFidelity = 0.858967\tKL_Divergence = 0.212098\n",
      "Epoch: 7\tFidelity = 0.849589\tKL_Divergence = 0.229269\n",
      "Epoch: 8\tFidelity = 0.841884\tKL_Divergence = 0.243711\n",
      "Epoch: 9\tFidelity = 0.861549\tKL_Divergence = 0.207471\n",
      "Epoch: 10\tFidelity = 0.839179\tKL_Divergence = 0.248848\n",
      "Epoch: 11\tFidelity = 0.846240\tKL_Divergence = 0.235548\n",
      "Epoch: 12\tFidelity = 0.844321\tKL_Divergence = 0.239159\n",
      "Epoch: 13\tFidelity = 0.849254\tKL_Divergence = 0.229949\n",
      "Epoch: 14\tFidelity = 0.838469\tKL_Divergence = 0.250245\n",
      "Epoch: 15\tFidelity = 0.823180\tKL_Divergence = 0.280049\n",
      "Epoch: 16\tFidelity = 0.854580\tKL_Divergence = 0.220169\n",
      "Epoch: 17\tFidelity = 0.846491\tKL_Divergence = 0.235148\n",
      "Epoch: 18\tFidelity = 0.860862\tKL_Divergence = 0.208802\n",
      "Epoch: 19\tFidelity = 0.839040\tKL_Divergence = 0.249221\n",
      "Epoch: 20\tFidelity = 0.855049\tKL_Divergence = 0.219352\n",
      "Epoch: 21\tFidelity = 0.859645\tKL_Divergence = 0.211002\n",
      "Epoch: 22\tFidelity = 0.833628\tKL_Divergence = 0.259625\n",
      "Epoch: 23\tFidelity = 0.827560\tKL_Divergence = 0.271466\n",
      "Epoch: 24\tFidelity = 0.841937\tKL_Divergence = 0.243738\n",
      "Epoch: 25\tFidelity = 0.849152\tKL_Divergence = 0.230242\n",
      "Epoch: 26\tFidelity = 0.847269\tKL_Divergence = 0.233744\n",
      "Epoch: 27\tFidelity = 0.848440\tKL_Divergence = 0.231586\n",
      "Epoch: 28\tFidelity = 0.843091\tKL_Divergence = 0.241590\n",
      "Epoch: 29\tFidelity = 0.861489\tKL_Divergence = 0.207734\n",
      "Epoch: 30\tFidelity = 0.863968\tKL_Divergence = 0.203291\n",
      "Epoch: 31\tFidelity = 0.850164\tKL_Divergence = 0.228404\n",
      "Epoch: 32\tFidelity = 0.839036\tKL_Divergence = 0.249308\n",
      "Epoch: 33\tFidelity = 0.851545\tKL_Divergence = 0.225858\n",
      "Epoch: 34\tFidelity = 0.835372\tKL_Divergence = 0.256328\n",
      "Epoch: 35\tFidelity = 0.862542\tKL_Divergence = 0.205865\n",
      "Epoch: 36\tFidelity = 0.840899\tKL_Divergence = 0.245780\n",
      "Epoch: 37\tFidelity = 0.835549\tKL_Divergence = 0.255999\n",
      "Epoch: 38\tFidelity = 0.870571\tKL_Divergence = 0.191622\n",
      "Epoch: 39\tFidelity = 0.837219\tKL_Divergence = 0.252809\n",
      "Epoch: 40\tFidelity = 0.827438\tKL_Divergence = 0.271803\n",
      "Epoch: 41\tFidelity = 0.835068\tKL_Divergence = 0.256957\n",
      "Epoch: 42\tFidelity = 0.861214\tKL_Divergence = 0.208294\n",
      "Epoch: 43\tFidelity = 0.850326\tKL_Divergence = 0.228151\n",
      "Epoch: 44\tFidelity = 0.847961\tKL_Divergence = 0.232540\n",
      "Epoch: 45\tFidelity = 0.857021\tKL_Divergence = 0.215879\n",
      "Epoch: 46\tFidelity = 0.875817\tKL_Divergence = 0.182497\n",
      "Epoch: 47\tFidelity = 0.867083\tKL_Divergence = 0.197825\n",
      "Epoch: 48\tFidelity = 0.853430\tKL_Divergence = 0.222461\n",
      "Epoch: 49\tFidelity = 0.878177\tKL_Divergence = 0.178419\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:22:55,825] Trial 58 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.871199\tKL_Divergence = 0.190559\n",
      "Total time elapsed during training: 31.033 s\n",
      "Trial 58 pruned. \n",
      "Epoch: 1\tFidelity = 0.847462\tKL_Divergence = 0.233481\n",
      "Epoch: 2\tFidelity = 0.823146\tKL_Divergence = 0.280309\n",
      "Epoch: 3\tFidelity = 0.847452\tKL_Divergence = 0.233513\n",
      "Epoch: 4\tFidelity = 0.879603\tKL_Divergence = 0.175960\n",
      "Epoch: 5\tFidelity = 0.857919\tKL_Divergence = 0.214271\n",
      "Epoch: 6\tFidelity = 0.843850\tKL_Divergence = 0.240274\n",
      "Epoch: 7\tFidelity = 0.821289\tKL_Divergence = 0.284048\n",
      "Epoch: 8\tFidelity = 0.846968\tKL_Divergence = 0.234456\n",
      "Epoch: 9\tFidelity = 0.825085\tKL_Divergence = 0.276515\n",
      "Epoch: 10\tFidelity = 0.850598\tKL_Divergence = 0.227729\n",
      "Epoch: 11\tFidelity = 0.810479\tKL_Divergence = 0.306053\n",
      "Epoch: 12\tFidelity = 0.799230\tKL_Divergence = 0.329687\n",
      "Epoch: 13\tFidelity = 0.848633\tKL_Divergence = 0.231394\n",
      "Epoch: 14\tFidelity = 0.850076\tKL_Divergence = 0.228730\n",
      "Epoch: 15\tFidelity = 0.825112\tKL_Divergence = 0.276510\n",
      "Epoch: 16\tFidelity = 0.869512\tKL_Divergence = 0.193643\n",
      "Epoch: 17\tFidelity = 0.876557\tKL_Divergence = 0.181352\n",
      "Epoch: 18\tFidelity = 0.873187\tKL_Divergence = 0.187243\n",
      "Epoch: 19\tFidelity = 0.859256\tKL_Divergence = 0.212002\n",
      "Epoch: 20\tFidelity = 0.856602\tKL_Divergence = 0.216827\n",
      "Epoch: 21\tFidelity = 0.877055\tKL_Divergence = 0.180513\n",
      "Epoch: 22\tFidelity = 0.850510\tKL_Divergence = 0.228006\n",
      "Epoch: 23\tFidelity = 0.867768\tKL_Divergence = 0.196787\n",
      "Epoch: 24\tFidelity = 0.825239\tKL_Divergence = 0.276357\n",
      "Epoch: 25\tFidelity = 0.847098\tKL_Divergence = 0.234361\n",
      "Epoch: 26\tFidelity = 0.808249\tKL_Divergence = 0.310836\n",
      "Epoch: 27\tFidelity = 0.850755\tKL_Divergence = 0.227600\n",
      "Epoch: 28\tFidelity = 0.871818\tKL_Divergence = 0.189723\n",
      "Epoch: 29\tFidelity = 0.845466\tKL_Divergence = 0.237450\n",
      "Epoch: 30\tFidelity = 0.872825\tKL_Divergence = 0.187977\n",
      "Epoch: 31\tFidelity = 0.831128\tKL_Divergence = 0.264825\n",
      "Epoch: 32\tFidelity = 0.855212\tKL_Divergence = 0.219475\n",
      "Epoch: 33\tFidelity = 0.821002\tKL_Divergence = 0.284841\n",
      "Epoch: 34\tFidelity = 0.838797\tKL_Divergence = 0.250136\n",
      "Epoch: 35\tFidelity = 0.834449\tKL_Divergence = 0.258406\n",
      "Epoch: 36\tFidelity = 0.825089\tKL_Divergence = 0.276742\n",
      "Epoch: 37\tFidelity = 0.811005\tKL_Divergence = 0.305152\n",
      "Epoch: 38\tFidelity = 0.802823\tKL_Divergence = 0.322271\n",
      "Epoch: 39\tFidelity = 0.813440\tKL_Divergence = 0.300182\n",
      "Epoch: 40\tFidelity = 0.817918\tKL_Divergence = 0.291092\n",
      "Epoch: 41\tFidelity = 0.823510\tKL_Divergence = 0.279871\n",
      "Epoch: 42\tFidelity = 0.789380\tKL_Divergence = 0.351281\n",
      "Epoch: 43\tFidelity = 0.802661\tKL_Divergence = 0.322632\n",
      "Epoch: 44\tFidelity = 0.792832\tKL_Divergence = 0.343749\n",
      "Epoch: 45\tFidelity = 0.826132\tKL_Divergence = 0.274735\n",
      "Epoch: 46\tFidelity = 0.862324\tKL_Divergence = 0.206654\n",
      "Epoch: 47\tFidelity = 0.836329\tKL_Divergence = 0.254889\n",
      "Epoch: 48\tFidelity = 0.848859\tKL_Divergence = 0.231243\n",
      "Epoch: 49\tFidelity = 0.875690\tKL_Divergence = 0.183047\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:23:27,524] Trial 59 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.866803\tKL_Divergence = 0.198670\n",
      "Total time elapsed during training: 31.562 s\n",
      "Trial 59 pruned. \n",
      "Epoch: 1\tFidelity = 0.832882\tKL_Divergence = 0.261101\n",
      "Epoch: 2\tFidelity = 0.828888\tKL_Divergence = 0.268888\n",
      "Epoch: 3\tFidelity = 0.852015\tKL_Divergence = 0.224219\n",
      "Epoch: 4\tFidelity = 0.812696\tKL_Divergence = 0.300412\n",
      "Epoch: 5\tFidelity = 0.834102\tKL_Divergence = 0.258132\n",
      "Epoch: 6\tFidelity = 0.811493\tKL_Divergence = 0.303384\n",
      "Epoch: 7\tFidelity = 0.804931\tKL_Divergence = 0.317956\n",
      "Epoch: 8\tFidelity = 0.825456\tKL_Divergence = 0.275812\n",
      "Epoch: 9\tFidelity = 0.825175\tKL_Divergence = 0.276089\n",
      "Epoch: 10\tFidelity = 0.813183\tKL_Divergence = 0.300683\n",
      "Epoch: 11\tFidelity = 0.798970\tKL_Divergence = 0.330614\n",
      "Epoch: 12\tFidelity = 0.821166\tKL_Divergence = 0.283165\n",
      "Epoch: 13\tFidelity = 0.807864\tKL_Divergence = 0.311642\n",
      "Epoch: 14\tFidelity = 0.822426\tKL_Divergence = 0.282281\n",
      "Epoch: 15\tFidelity = 0.801686\tKL_Divergence = 0.323861\n",
      "Epoch: 16\tFidelity = 0.791373\tKL_Divergence = 0.345942\n",
      "Epoch: 17\tFidelity = 0.837238\tKL_Divergence = 0.252186\n",
      "Epoch: 18\tFidelity = 0.819497\tKL_Divergence = 0.288014\n",
      "Epoch: 19\tFidelity = 0.820679\tKL_Divergence = 0.285757\n",
      "Epoch: 20\tFidelity = 0.821130\tKL_Divergence = 0.284940\n",
      "Epoch: 21\tFidelity = 0.812687\tKL_Divergence = 0.301859\n",
      "Epoch: 22\tFidelity = 0.822473\tKL_Divergence = 0.281343\n",
      "Epoch: 23\tFidelity = 0.790002\tKL_Divergence = 0.350095\n",
      "Epoch: 24\tFidelity = 0.797952\tKL_Divergence = 0.331759\n",
      "Epoch: 25\tFidelity = 0.821684\tKL_Divergence = 0.283890\n",
      "Epoch: 26\tFidelity = 0.823209\tKL_Divergence = 0.280461\n",
      "Epoch: 27\tFidelity = 0.813623\tKL_Divergence = 0.300153\n",
      "Epoch: 28\tFidelity = 0.767046\tKL_Divergence = 0.402686\n",
      "Epoch: 29\tFidelity = 0.824323\tKL_Divergence = 0.277920\n",
      "Epoch: 30\tFidelity = 0.814317\tKL_Divergence = 0.298505\n",
      "Epoch: 31\tFidelity = 0.812338\tKL_Divergence = 0.302414\n",
      "Epoch: 32\tFidelity = 0.792322\tKL_Divergence = 0.343887\n",
      "Epoch: 33\tFidelity = 0.794698\tKL_Divergence = 0.339598\n",
      "Epoch: 34\tFidelity = 0.784103\tKL_Divergence = 0.363065\n",
      "Epoch: 35\tFidelity = 0.802680\tKL_Divergence = 0.322391\n",
      "Epoch: 36\tFidelity = 0.789546\tKL_Divergence = 0.350981\n",
      "Epoch: 37\tFidelity = 0.783734\tKL_Divergence = 0.364206\n",
      "Epoch: 38\tFidelity = 0.804379\tKL_Divergence = 0.319203\n",
      "Epoch: 39\tFidelity = 0.794359\tKL_Divergence = 0.339831\n",
      "Epoch: 40\tFidelity = 0.796670\tKL_Divergence = 0.334734\n",
      "Epoch: 41\tFidelity = 0.788085\tKL_Divergence = 0.354725\n",
      "Epoch: 42\tFidelity = 0.807257\tKL_Divergence = 0.312759\n",
      "Epoch: 43\tFidelity = 0.799923\tKL_Divergence = 0.329000\n",
      "Epoch: 44\tFidelity = 0.804974\tKL_Divergence = 0.317054\n",
      "Epoch: 45\tFidelity = 0.767290\tKL_Divergence = 0.402341\n",
      "Epoch: 46\tFidelity = 0.798061\tKL_Divergence = 0.331819\n",
      "Epoch: 47\tFidelity = 0.790858\tKL_Divergence = 0.347933\n",
      "Epoch: 48\tFidelity = 0.798578\tKL_Divergence = 0.331325\n",
      "Epoch: 49\tFidelity = 0.788465\tKL_Divergence = 0.353110\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:24:06,002] Trial 60 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.777592\tKL_Divergence = 0.377010\n",
      "Total time elapsed during training: 38.327 s\n",
      "Trial 60 pruned. \n",
      "Epoch: 1\tFidelity = 0.780067\tKL_Divergence = 0.372843\n",
      "Epoch: 2\tFidelity = 0.848070\tKL_Divergence = 0.233174\n",
      "Epoch: 3\tFidelity = 0.769293\tKL_Divergence = 0.394483\n",
      "Epoch: 4\tFidelity = 0.769286\tKL_Divergence = 0.397783\n",
      "Epoch: 5\tFidelity = 0.784232\tKL_Divergence = 0.363380\n",
      "Epoch: 6\tFidelity = 0.799863\tKL_Divergence = 0.329330\n",
      "Epoch: 7\tFidelity = 0.768526\tKL_Divergence = 0.399448\n",
      "Epoch: 8\tFidelity = 0.768159\tKL_Divergence = 0.398867\n",
      "Epoch: 9\tFidelity = 0.756238\tKL_Divergence = 0.429056\n",
      "Epoch: 10\tFidelity = 0.716809\tKL_Divergence = 0.532763\n",
      "Epoch: 11\tFidelity = 0.704093\tKL_Divergence = 0.571744\n",
      "Epoch: 12\tFidelity = 0.749999\tKL_Divergence = 0.442847\n",
      "Epoch: 13\tFidelity = 0.711741\tKL_Divergence = 0.548672\n",
      "Epoch: 14\tFidelity = 0.778436\tKL_Divergence = 0.377133\n",
      "Epoch: 15\tFidelity = 0.714817\tKL_Divergence = 0.540300\n",
      "Epoch: 16\tFidelity = 0.747414\tKL_Divergence = 0.445366\n",
      "Epoch: 17\tFidelity = 0.750432\tKL_Divergence = 0.444107\n",
      "Epoch: 18\tFidelity = 0.733732\tKL_Divergence = 0.483816\n",
      "Epoch: 19\tFidelity = 0.715024\tKL_Divergence = 0.539671\n",
      "Epoch: 20\tFidelity = 0.727181\tKL_Divergence = 0.504708\n",
      "Epoch: 21\tFidelity = 0.732024\tKL_Divergence = 0.492287\n",
      "Epoch: 22\tFidelity = 0.729763\tKL_Divergence = 0.498329\n",
      "Epoch: 23\tFidelity = 0.717343\tKL_Divergence = 0.532750\n",
      "Epoch: 24\tFidelity = 0.723191\tKL_Divergence = 0.516722\n",
      "Epoch: 25\tFidelity = 0.698843\tKL_Divergence = 0.584994\n",
      "Epoch: 26\tFidelity = 0.737247\tKL_Divergence = 0.478644\n",
      "Epoch: 27\tFidelity = 0.686072\tKL_Divergence = 0.625065\n",
      "Epoch: 28\tFidelity = 0.671059\tKL_Divergence = 0.676041\n",
      "Epoch: 29\tFidelity = 0.711831\tKL_Divergence = 0.547311\n",
      "Epoch: 30\tFidelity = 0.697299\tKL_Divergence = 0.593507\n",
      "Epoch: 31\tFidelity = 0.716032\tKL_Divergence = 0.535631\n",
      "Epoch: 32\tFidelity = 0.689250\tKL_Divergence = 0.617953\n",
      "Epoch: 33\tFidelity = 0.692057\tKL_Divergence = 0.610318\n",
      "Epoch: 34\tFidelity = 0.662700\tKL_Divergence = 0.712017\n",
      "Epoch: 35\tFidelity = 0.660948\tKL_Divergence = 0.718590\n",
      "Epoch: 36\tFidelity = 0.668555\tKL_Divergence = 0.690482\n",
      "Epoch: 37\tFidelity = 0.697733\tKL_Divergence = 0.592386\n",
      "Epoch: 38\tFidelity = 0.707919\tKL_Divergence = 0.561329\n",
      "Epoch: 39\tFidelity = 0.662587\tKL_Divergence = 0.712045\n",
      "Epoch: 40\tFidelity = 0.686716\tKL_Divergence = 0.626925\n",
      "Epoch: 41\tFidelity = 0.681636\tKL_Divergence = 0.644063\n",
      "Epoch: 42\tFidelity = 0.673864\tKL_Divergence = 0.670719\n",
      "Epoch: 43\tFidelity = 0.684840\tKL_Divergence = 0.633571\n",
      "Epoch: 44\tFidelity = 0.674853\tKL_Divergence = 0.668360\n",
      "Epoch: 45\tFidelity = 0.720269\tKL_Divergence = 0.525571\n",
      "Epoch: 46\tFidelity = 0.692510\tKL_Divergence = 0.606279\n",
      "Epoch: 47\tFidelity = 0.637756\tKL_Divergence = 0.813372\n",
      "Epoch: 48\tFidelity = 0.661644\tKL_Divergence = 0.716398\n",
      "Epoch: 49\tFidelity = 0.632960\tKL_Divergence = 0.832736\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:25:26,124] Trial 61 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.648691\tKL_Divergence = 0.766659\n",
      "Total time elapsed during training: 79.986 s\n",
      "Trial 61 pruned. \n",
      "Epoch: 1\tFidelity = 0.646553\tKL_Divergence = 0.776019\n",
      "Epoch: 2\tFidelity = 0.662520\tKL_Divergence = 0.713053\n",
      "Epoch: 3\tFidelity = 0.647843\tKL_Divergence = 0.770432\n",
      "Epoch: 4\tFidelity = 0.651514\tKL_Divergence = 0.755848\n",
      "Epoch: 5\tFidelity = 0.653602\tKL_Divergence = 0.747447\n",
      "Epoch: 6\tFidelity = 0.652381\tKL_Divergence = 0.752497\n",
      "Epoch: 7\tFidelity = 0.653102\tKL_Divergence = 0.749203\n",
      "Epoch: 8\tFidelity = 0.645120\tKL_Divergence = 0.782105\n",
      "Epoch: 9\tFidelity = 0.656680\tKL_Divergence = 0.735400\n",
      "Epoch: 10\tFidelity = 0.641395\tKL_Divergence = 0.797446\n",
      "Epoch: 11\tFidelity = 0.652705\tKL_Divergence = 0.751241\n",
      "Epoch: 12\tFidelity = 0.634639\tKL_Divergence = 0.826842\n",
      "Epoch: 13\tFidelity = 0.641585\tKL_Divergence = 0.796852\n",
      "Epoch: 14\tFidelity = 0.648592\tKL_Divergence = 0.767856\n",
      "Epoch: 15\tFidelity = 0.639304\tKL_Divergence = 0.806840\n",
      "Epoch: 16\tFidelity = 0.647495\tKL_Divergence = 0.772272\n",
      "Epoch: 17\tFidelity = 0.622815\tKL_Divergence = 0.882691\n",
      "Epoch: 18\tFidelity = 0.633362\tKL_Divergence = 0.832579\n",
      "Epoch: 19\tFidelity = 0.641517\tKL_Divergence = 0.797452\n",
      "Epoch: 20\tFidelity = 0.644570\tKL_Divergence = 0.784564\n",
      "Epoch: 21\tFidelity = 0.623955\tKL_Divergence = 0.876740\n",
      "Epoch: 22\tFidelity = 0.653821\tKL_Divergence = 0.746864\n",
      "Epoch: 23\tFidelity = 0.639558\tKL_Divergence = 0.805626\n",
      "Epoch: 24\tFidelity = 0.624552\tKL_Divergence = 0.874141\n",
      "Epoch: 25\tFidelity = 0.628845\tKL_Divergence = 0.853625\n",
      "Epoch: 26\tFidelity = 0.633033\tKL_Divergence = 0.834364\n",
      "Epoch: 27\tFidelity = 0.629690\tKL_Divergence = 0.849720\n",
      "Epoch: 28\tFidelity = 0.627739\tKL_Divergence = 0.858963\n",
      "Epoch: 29\tFidelity = 0.618344\tKL_Divergence = 0.905012\n",
      "Epoch: 30\tFidelity = 0.639425\tKL_Divergence = 0.806291\n",
      "Epoch: 31\tFidelity = 0.615692\tKL_Divergence = 0.918296\n",
      "Epoch: 32\tFidelity = 0.623253\tKL_Divergence = 0.880487\n",
      "Epoch: 33\tFidelity = 0.622005\tKL_Divergence = 0.886870\n",
      "Epoch: 34\tFidelity = 0.623283\tKL_Divergence = 0.880636\n",
      "Epoch: 35\tFidelity = 0.618088\tKL_Divergence = 0.906352\n",
      "Epoch: 36\tFidelity = 0.616472\tKL_Divergence = 0.914574\n",
      "Epoch: 37\tFidelity = 0.620838\tKL_Divergence = 0.892564\n",
      "Epoch: 38\tFidelity = 0.608874\tKL_Divergence = 0.954861\n",
      "Epoch: 39\tFidelity = 0.604172\tKL_Divergence = 0.981056\n",
      "Epoch: 40\tFidelity = 0.622674\tKL_Divergence = 0.883466\n",
      "Epoch: 41\tFidelity = 0.624278\tKL_Divergence = 0.875608\n",
      "Epoch: 42\tFidelity = 0.624413\tKL_Divergence = 0.875148\n",
      "Epoch: 43\tFidelity = 0.612106\tKL_Divergence = 0.936877\n",
      "Epoch: 44\tFidelity = 0.617384\tKL_Divergence = 0.909586\n",
      "Epoch: 45\tFidelity = 0.602390\tKL_Divergence = 0.991267\n",
      "Epoch: 46\tFidelity = 0.618105\tKL_Divergence = 0.906332\n",
      "Epoch: 47\tFidelity = 0.621209\tKL_Divergence = 0.890088\n",
      "Epoch: 48\tFidelity = 0.612586\tKL_Divergence = 0.934923\n",
      "Epoch: 49\tFidelity = 0.611223\tKL_Divergence = 0.942105\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:26:46,849] Trial 62 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.607991\tKL_Divergence = 0.959745\n",
      "Total time elapsed during training: 80.581 s\n",
      "Trial 62 pruned. \n",
      "Epoch: 1\tFidelity = 0.616475\tKL_Divergence = 0.914296\n",
      "Epoch: 2\tFidelity = 0.600431\tKL_Divergence = 1.002855\n",
      "Epoch: 3\tFidelity = 0.629802\tKL_Divergence = 0.849820\n",
      "Epoch: 4\tFidelity = 0.617721\tKL_Divergence = 0.908396\n",
      "Epoch: 5\tFidelity = 0.604187\tKL_Divergence = 0.981152\n",
      "Epoch: 6\tFidelity = 0.607181\tKL_Divergence = 0.963818\n",
      "Epoch: 7\tFidelity = 0.609453\tKL_Divergence = 0.951779\n",
      "Epoch: 8\tFidelity = 0.600420\tKL_Divergence = 1.002862\n",
      "Epoch: 9\tFidelity = 0.601774\tKL_Divergence = 0.995044\n",
      "Epoch: 10\tFidelity = 0.605734\tKL_Divergence = 0.972447\n",
      "Epoch: 11\tFidelity = 0.611295\tKL_Divergence = 0.941837\n",
      "Epoch: 12\tFidelity = 0.595589\tKL_Divergence = 1.031432\n",
      "Epoch: 13\tFidelity = 0.595363\tKL_Divergence = 1.033550\n",
      "Epoch: 14\tFidelity = 0.596341\tKL_Divergence = 1.027612\n",
      "Epoch: 15\tFidelity = 0.598708\tKL_Divergence = 1.012494\n",
      "Epoch: 16\tFidelity = 0.597618\tKL_Divergence = 1.019864\n",
      "Epoch: 17\tFidelity = 0.611264\tKL_Divergence = 0.941060\n",
      "Epoch: 18\tFidelity = 0.590856\tKL_Divergence = 1.062264\n",
      "Epoch: 19\tFidelity = 0.603123\tKL_Divergence = 0.987405\n",
      "Epoch: 20\tFidelity = 0.591962\tKL_Divergence = 1.055174\n",
      "Epoch: 21\tFidelity = 0.596112\tKL_Divergence = 1.029118\n",
      "Epoch: 22\tFidelity = 0.602445\tKL_Divergence = 0.991311\n",
      "Epoch: 23\tFidelity = 0.584511\tKL_Divergence = 1.104867\n",
      "Epoch: 24\tFidelity = 0.593128\tKL_Divergence = 1.047759\n",
      "Epoch: 25\tFidelity = 0.592796\tKL_Divergence = 1.049068\n",
      "Epoch: 26\tFidelity = 0.595975\tKL_Divergence = 1.029990\n",
      "Epoch: 27\tFidelity = 0.582957\tKL_Divergence = 1.115734\n",
      "Epoch: 28\tFidelity = 0.588421\tKL_Divergence = 1.078350\n",
      "Epoch: 29\tFidelity = 0.597475\tKL_Divergence = 1.020841\n",
      "Epoch: 30\tFidelity = 0.587173\tKL_Divergence = 1.086438\n",
      "Epoch: 31\tFidelity = 0.598815\tKL_Divergence = 1.012419\n",
      "Epoch: 32\tFidelity = 0.591667\tKL_Divergence = 1.056906\n",
      "Epoch: 33\tFidelity = 0.588177\tKL_Divergence = 1.079973\n",
      "Epoch: 34\tFidelity = 0.583046\tKL_Divergence = 1.115216\n",
      "Epoch: 35\tFidelity = 0.591824\tKL_Divergence = 1.056128\n",
      "Epoch: 36\tFidelity = 0.588747\tKL_Divergence = 1.075551\n",
      "Epoch: 37\tFidelity = 0.589919\tKL_Divergence = 1.068452\n",
      "Epoch: 38\tFidelity = 0.582223\tKL_Divergence = 1.120806\n",
      "Epoch: 39\tFidelity = 0.592206\tKL_Divergence = 1.053676\n",
      "Epoch: 40\tFidelity = 0.585536\tKL_Divergence = 1.097934\n",
      "Epoch: 41\tFidelity = 0.582728\tKL_Divergence = 1.116862\n",
      "Epoch: 42\tFidelity = 0.577186\tKL_Divergence = 1.158095\n",
      "Epoch: 43\tFidelity = 0.581544\tKL_Divergence = 1.125583\n",
      "Epoch: 44\tFidelity = 0.594720\tKL_Divergence = 1.037820\n",
      "Epoch: 45\tFidelity = 0.581030\tKL_Divergence = 1.129679\n",
      "Epoch: 46\tFidelity = 0.592002\tKL_Divergence = 1.054757\n",
      "Epoch: 47\tFidelity = 0.585113\tKL_Divergence = 1.100888\n",
      "Epoch: 48\tFidelity = 0.587020\tKL_Divergence = 1.087890\n",
      "Epoch: 49\tFidelity = 0.579817\tKL_Divergence = 1.138506\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:28:07,127] Trial 63 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.576954\tKL_Divergence = 1.159872\n",
      "Total time elapsed during training: 80.140 s\n",
      "Trial 63 pruned. \n",
      "Epoch: 1\tFidelity = 0.574716\tKL_Divergence = 1.177074\n",
      "Epoch: 2\tFidelity = 0.588949\tKL_Divergence = 1.075016\n",
      "Epoch: 3\tFidelity = 0.582298\tKL_Divergence = 1.119619\n",
      "Epoch: 4\tFidelity = 0.579671\tKL_Divergence = 1.139686\n",
      "Epoch: 5\tFidelity = 0.573585\tKL_Divergence = 1.186076\n",
      "Epoch: 6\tFidelity = 0.571122\tKL_Divergence = 1.205955\n",
      "Epoch: 7\tFidelity = 0.583545\tKL_Divergence = 1.111836\n",
      "Epoch: 8\tFidelity = 0.578475\tKL_Divergence = 1.148348\n",
      "Epoch: 9\tFidelity = 0.565420\tKL_Divergence = 1.254166\n",
      "Epoch: 10\tFidelity = 0.566237\tKL_Divergence = 1.247426\n",
      "Epoch: 11\tFidelity = 0.577359\tKL_Divergence = 1.156971\n",
      "Epoch: 12\tFidelity = 0.586872\tKL_Divergence = 1.088961\n",
      "Epoch: 13\tFidelity = 0.586934\tKL_Divergence = 1.088248\n",
      "Epoch: 14\tFidelity = 0.574724\tKL_Divergence = 1.177048\n",
      "Epoch: 15\tFidelity = 0.578914\tKL_Divergence = 1.145316\n",
      "Epoch: 16\tFidelity = 0.577611\tKL_Divergence = 1.155058\n",
      "Epoch: 17\tFidelity = 0.577545\tKL_Divergence = 1.155573\n",
      "Epoch: 18\tFidelity = 0.577128\tKL_Divergence = 1.158432\n",
      "Epoch: 19\tFidelity = 0.577747\tKL_Divergence = 1.154062\n",
      "Epoch: 20\tFidelity = 0.572975\tKL_Divergence = 1.191073\n",
      "Epoch: 21\tFidelity = 0.574028\tKL_Divergence = 1.182599\n",
      "Epoch: 22\tFidelity = 0.574700\tKL_Divergence = 1.177397\n",
      "Epoch: 23\tFidelity = 0.564658\tKL_Divergence = 1.261281\n",
      "Epoch: 24\tFidelity = 0.580622\tKL_Divergence = 1.132819\n",
      "Epoch: 25\tFidelity = 0.580746\tKL_Divergence = 1.131902\n",
      "Epoch: 26\tFidelity = 0.577252\tKL_Divergence = 1.157680\n",
      "Epoch: 27\tFidelity = 0.581841\tKL_Divergence = 1.123848\n",
      "Epoch: 28\tFidelity = 0.578890\tKL_Divergence = 1.145568\n",
      "Epoch: 29\tFidelity = 0.566653\tKL_Divergence = 1.243259\n",
      "Epoch: 30\tFidelity = 0.576796\tKL_Divergence = 1.161275\n",
      "Epoch: 31\tFidelity = 0.575633\tKL_Divergence = 1.170213\n",
      "Epoch: 32\tFidelity = 0.572776\tKL_Divergence = 1.192680\n",
      "Epoch: 33\tFidelity = 0.577384\tKL_Divergence = 1.156829\n",
      "Epoch: 34\tFidelity = 0.579084\tKL_Divergence = 1.144157\n",
      "Epoch: 35\tFidelity = 0.575254\tKL_Divergence = 1.173177\n",
      "Epoch: 36\tFidelity = 0.585936\tKL_Divergence = 1.095411\n",
      "Epoch: 37\tFidelity = 0.569180\tKL_Divergence = 1.222222\n",
      "Epoch: 38\tFidelity = 0.578247\tKL_Divergence = 1.150294\n",
      "Epoch: 39\tFidelity = 0.570966\tKL_Divergence = 1.207116\n",
      "Epoch: 40\tFidelity = 0.573084\tKL_Divergence = 1.190041\n",
      "Epoch: 41\tFidelity = 0.576394\tKL_Divergence = 1.164208\n",
      "Epoch: 42\tFidelity = 0.570693\tKL_Divergence = 1.209456\n",
      "Epoch: 43\tFidelity = 0.566263\tKL_Divergence = 1.247184\n",
      "Epoch: 44\tFidelity = 0.579497\tKL_Divergence = 1.141146\n",
      "Epoch: 45\tFidelity = 0.571785\tKL_Divergence = 1.200692\n",
      "Epoch: 46\tFidelity = 0.570100\tKL_Divergence = 1.214562\n",
      "Epoch: 47\tFidelity = 0.574584\tKL_Divergence = 1.178425\n",
      "Epoch: 48\tFidelity = 0.571038\tKL_Divergence = 1.206797\n",
      "Epoch: 49\tFidelity = 0.567758\tKL_Divergence = 1.234148\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:29:27,135] Trial 64 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.567978\tKL_Divergence = 1.232498\n",
      "Total time elapsed during training: 79.859 s\n",
      "Trial 64 pruned. \n",
      "Epoch: 1\tFidelity = 0.569750\tKL_Divergence = 1.217562\n",
      "Epoch: 2\tFidelity = 0.560133\tKL_Divergence = 1.303652\n",
      "Epoch: 3\tFidelity = 0.555933\tKL_Divergence = 1.345422\n",
      "Epoch: 4\tFidelity = 0.566939\tKL_Divergence = 1.241487\n",
      "Epoch: 5\tFidelity = 0.568543\tKL_Divergence = 1.227603\n",
      "Epoch: 6\tFidelity = 0.567624\tKL_Divergence = 1.235564\n",
      "Epoch: 7\tFidelity = 0.572643\tKL_Divergence = 1.193886\n",
      "Epoch: 8\tFidelity = 0.574649\tKL_Divergence = 1.177881\n",
      "Epoch: 9\tFidelity = 0.565986\tKL_Divergence = 1.249815\n",
      "Epoch: 10\tFidelity = 0.565698\tKL_Divergence = 1.252271\n",
      "Epoch: 11\tFidelity = 0.567419\tKL_Divergence = 1.237341\n",
      "Epoch: 12\tFidelity = 0.567145\tKL_Divergence = 1.239726\n",
      "Epoch: 13\tFidelity = 0.574043\tKL_Divergence = 1.182675\n",
      "Epoch: 14\tFidelity = 0.564000\tKL_Divergence = 1.267362\n",
      "Epoch: 15\tFidelity = 0.564789\tKL_Divergence = 1.260481\n",
      "Epoch: 16\tFidelity = 0.572481\tKL_Divergence = 1.195191\n",
      "Epoch: 17\tFidelity = 0.566693\tKL_Divergence = 1.243641\n",
      "Epoch: 18\tFidelity = 0.564410\tKL_Divergence = 1.263887\n",
      "Epoch: 19\tFidelity = 0.560301\tKL_Divergence = 1.302004\n",
      "Epoch: 20\tFidelity = 0.558573\tKL_Divergence = 1.318898\n",
      "Epoch: 21\tFidelity = 0.561707\tKL_Divergence = 1.288756\n",
      "Epoch: 22\tFidelity = 0.574116\tKL_Divergence = 1.182125\n",
      "Epoch: 23\tFidelity = 0.570663\tKL_Divergence = 1.209802\n",
      "Epoch: 24\tFidelity = 0.562645\tKL_Divergence = 1.280029\n",
      "Epoch: 25\tFidelity = 0.568634\tKL_Divergence = 1.227013\n",
      "Epoch: 26\tFidelity = 0.563085\tKL_Divergence = 1.275810\n",
      "Epoch: 27\tFidelity = 0.562661\tKL_Divergence = 1.279843\n",
      "Epoch: 28\tFidelity = 0.561201\tKL_Divergence = 1.293439\n",
      "Epoch: 29\tFidelity = 0.557559\tKL_Divergence = 1.329027\n",
      "Epoch: 30\tFidelity = 0.557434\tKL_Divergence = 1.330021\n",
      "Epoch: 31\tFidelity = 0.563232\tKL_Divergence = 1.274584\n",
      "Epoch: 32\tFidelity = 0.558460\tKL_Divergence = 1.319884\n",
      "Epoch: 33\tFidelity = 0.563869\tKL_Divergence = 1.268802\n",
      "Epoch: 34\tFidelity = 0.564863\tKL_Divergence = 1.259519\n",
      "Epoch: 35\tFidelity = 0.562177\tKL_Divergence = 1.284329\n",
      "Epoch: 36\tFidelity = 0.576401\tKL_Divergence = 1.164265\n",
      "Epoch: 37\tFidelity = 0.565121\tKL_Divergence = 1.257574\n",
      "Epoch: 38\tFidelity = 0.560612\tKL_Divergence = 1.299209\n",
      "Epoch: 39\tFidelity = 0.561094\tKL_Divergence = 1.294508\n",
      "Epoch: 40\tFidelity = 0.570979\tKL_Divergence = 1.207424\n",
      "Epoch: 41\tFidelity = 0.558860\tKL_Divergence = 1.316096\n",
      "Epoch: 42\tFidelity = 0.567454\tKL_Divergence = 1.237171\n",
      "Epoch: 43\tFidelity = 0.564753\tKL_Divergence = 1.260857\n",
      "Epoch: 44\tFidelity = 0.556547\tKL_Divergence = 1.339360\n",
      "Epoch: 45\tFidelity = 0.560917\tKL_Divergence = 1.296281\n",
      "Epoch: 46\tFidelity = 0.562865\tKL_Divergence = 1.277850\n",
      "Epoch: 47\tFidelity = 0.557182\tKL_Divergence = 1.332859\n",
      "Epoch: 48\tFidelity = 0.561250\tKL_Divergence = 1.293086\n",
      "Epoch: 49\tFidelity = 0.559393\tKL_Divergence = 1.310991\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:30:25,598] Trial 65 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.568749\tKL_Divergence = 1.226120\n",
      "Total time elapsed during training: 58.330 s\n",
      "Trial 65 pruned. \n",
      "Epoch: 1\tFidelity = 0.558956\tKL_Divergence = 1.315257\n",
      "Epoch: 2\tFidelity = 0.562513\tKL_Divergence = 1.281337\n",
      "Epoch: 3\tFidelity = 0.559144\tKL_Divergence = 1.313433\n",
      "Epoch: 4\tFidelity = 0.561029\tKL_Divergence = 1.295281\n",
      "Epoch: 5\tFidelity = 0.556935\tKL_Divergence = 1.335447\n",
      "Epoch: 6\tFidelity = 0.554029\tKL_Divergence = 1.365676\n",
      "Epoch: 7\tFidelity = 0.557662\tKL_Divergence = 1.328107\n",
      "Epoch: 8\tFidelity = 0.563834\tKL_Divergence = 1.269228\n",
      "Epoch: 9\tFidelity = 0.564871\tKL_Divergence = 1.259862\n",
      "Epoch: 10\tFidelity = 0.557642\tKL_Divergence = 1.328319\n",
      "Epoch: 11\tFidelity = 0.560738\tKL_Divergence = 1.298060\n",
      "Epoch: 12\tFidelity = 0.558071\tKL_Divergence = 1.324032\n",
      "Epoch: 13\tFidelity = 0.561204\tKL_Divergence = 1.293637\n",
      "Epoch: 14\tFidelity = 0.553909\tKL_Divergence = 1.366962\n",
      "Epoch: 15\tFidelity = 0.558753\tKL_Divergence = 1.317295\n",
      "Epoch: 16\tFidelity = 0.560913\tKL_Divergence = 1.296406\n",
      "Epoch: 17\tFidelity = 0.551635\tKL_Divergence = 1.391805\n",
      "Epoch: 18\tFidelity = 0.560913\tKL_Divergence = 1.296419\n",
      "Epoch: 19\tFidelity = 0.553769\tKL_Divergence = 1.368489\n",
      "Epoch: 20\tFidelity = 0.560628\tKL_Divergence = 1.299138\n",
      "Epoch: 21\tFidelity = 0.565443\tKL_Divergence = 1.254824\n",
      "Epoch: 22\tFidelity = 0.566788\tKL_Divergence = 1.243003\n",
      "Epoch: 23\tFidelity = 0.555402\tKL_Divergence = 1.351232\n",
      "Epoch: 24\tFidelity = 0.561132\tKL_Divergence = 1.294335\n",
      "Epoch: 25\tFidelity = 0.552162\tKL_Divergence = 1.385967\n",
      "Epoch: 26\tFidelity = 0.564754\tKL_Divergence = 1.260909\n",
      "Epoch: 27\tFidelity = 0.550616\tKL_Divergence = 1.403294\n",
      "Epoch: 28\tFidelity = 0.559492\tKL_Divergence = 1.310095\n",
      "Epoch: 29\tFidelity = 0.559132\tKL_Divergence = 1.313592\n",
      "Epoch: 30\tFidelity = 0.562779\tKL_Divergence = 1.278945\n",
      "Epoch: 31\tFidelity = 0.555540\tKL_Divergence = 1.349807\n",
      "Epoch: 32\tFidelity = 0.558138\tKL_Divergence = 1.323400\n",
      "Epoch: 33\tFidelity = 0.560266\tKL_Divergence = 1.302623\n",
      "Epoch: 34\tFidelity = 0.558302\tKL_Divergence = 1.321781\n",
      "Epoch: 35\tFidelity = 0.549244\tKL_Divergence = 1.419100\n",
      "Epoch: 36\tFidelity = 0.553077\tKL_Divergence = 1.375983\n",
      "Epoch: 37\tFidelity = 0.557727\tKL_Divergence = 1.327518\n",
      "Epoch: 38\tFidelity = 0.552186\tKL_Divergence = 1.385699\n",
      "Epoch: 39\tFidelity = 0.558404\tKL_Divergence = 1.320771\n",
      "Epoch: 40\tFidelity = 0.556668\tKL_Divergence = 1.338207\n",
      "Epoch: 41\tFidelity = 0.549110\tKL_Divergence = 1.420690\n",
      "Epoch: 42\tFidelity = 0.561417\tKL_Divergence = 1.291675\n",
      "Epoch: 43\tFidelity = 0.558604\tKL_Divergence = 1.318808\n",
      "Epoch: 44\tFidelity = 0.559512\tKL_Divergence = 1.309915\n",
      "Epoch: 45\tFidelity = 0.558641\tKL_Divergence = 1.318445\n",
      "Epoch: 46\tFidelity = 0.559487\tKL_Divergence = 1.310159\n",
      "Epoch: 47\tFidelity = 0.560443\tKL_Divergence = 1.300938\n",
      "Epoch: 48\tFidelity = 0.555322\tKL_Divergence = 1.352111\n",
      "Epoch: 49\tFidelity = 0.556639\tKL_Divergence = 1.338527\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:31:03,985] Trial 66 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.552903\tKL_Divergence = 1.377871\n",
      "Total time elapsed during training: 38.247 s\n",
      "Trial 66 pruned. \n",
      "Epoch: 1\tFidelity = 0.558675\tKL_Divergence = 1.318111\n",
      "Epoch: 2\tFidelity = 0.553643\tKL_Divergence = 1.369877\n",
      "Epoch: 3\tFidelity = 0.558363\tKL_Divergence = 1.321194\n",
      "Epoch: 4\tFidelity = 0.553928\tKL_Divergence = 1.366825\n",
      "Epoch: 5\tFidelity = 0.556415\tKL_Divergence = 1.340815\n",
      "Epoch: 6\tFidelity = 0.558764\tKL_Divergence = 1.317239\n",
      "Epoch: 7\tFidelity = 0.555337\tKL_Divergence = 1.351951\n",
      "Epoch: 8\tFidelity = 0.556790\tKL_Divergence = 1.336993\n",
      "Epoch: 9\tFidelity = 0.553024\tKL_Divergence = 1.376578\n",
      "Epoch: 10\tFidelity = 0.558058\tKL_Divergence = 1.324230\n",
      "Epoch: 11\tFidelity = 0.554541\tKL_Divergence = 1.360320\n",
      "Epoch: 12\tFidelity = 0.558429\tKL_Divergence = 1.320558\n",
      "Epoch: 13\tFidelity = 0.554835\tKL_Divergence = 1.357223\n",
      "Epoch: 14\tFidelity = 0.555306\tKL_Divergence = 1.352284\n",
      "Epoch: 15\tFidelity = 0.554648\tKL_Divergence = 1.359199\n",
      "Epoch: 16\tFidelity = 0.558022\tKL_Divergence = 1.324601\n",
      "Epoch: 17\tFidelity = 0.552153\tKL_Divergence = 1.386127\n",
      "Epoch: 18\tFidelity = 0.557208\tKL_Divergence = 1.332766\n",
      "Epoch: 19\tFidelity = 0.554220\tKL_Divergence = 1.363731\n",
      "Epoch: 20\tFidelity = 0.561985\tKL_Divergence = 1.286366\n",
      "Epoch: 21\tFidelity = 0.552228\tKL_Divergence = 1.385311\n",
      "Epoch: 22\tFidelity = 0.551805\tKL_Divergence = 1.389993\n",
      "Epoch: 23\tFidelity = 0.556940\tKL_Divergence = 1.335487\n",
      "Epoch: 24\tFidelity = 0.551181\tKL_Divergence = 1.396967\n",
      "Epoch: 25\tFidelity = 0.559538\tKL_Divergence = 1.309695\n",
      "Epoch: 26\tFidelity = 0.554035\tKL_Divergence = 1.365710\n",
      "Epoch: 27\tFidelity = 0.557062\tKL_Divergence = 1.334250\n",
      "Epoch: 28\tFidelity = 0.555466\tKL_Divergence = 1.350636\n",
      "Epoch: 29\tFidelity = 0.557085\tKL_Divergence = 1.334020\n",
      "Epoch: 30\tFidelity = 0.553576\tKL_Divergence = 1.370628\n",
      "Epoch: 31\tFidelity = 0.557635\tKL_Divergence = 1.328486\n",
      "Epoch: 32\tFidelity = 0.555645\tKL_Divergence = 1.348781\n",
      "Epoch: 33\tFidelity = 0.554901\tKL_Divergence = 1.356551\n",
      "Epoch: 34\tFidelity = 0.557315\tKL_Divergence = 1.331709\n",
      "Epoch: 35\tFidelity = 0.551453\tKL_Divergence = 1.393930\n",
      "Epoch: 36\tFidelity = 0.556724\tKL_Divergence = 1.337697\n",
      "Epoch: 37\tFidelity = 0.550535\tKL_Divergence = 1.404289\n",
      "Epoch: 38\tFidelity = 0.558258\tKL_Divergence = 1.322277\n",
      "Epoch: 39\tFidelity = 0.553663\tKL_Divergence = 1.369703\n",
      "Epoch: 40\tFidelity = 0.552562\tKL_Divergence = 1.381646\n",
      "Epoch: 41\tFidelity = 0.557850\tKL_Divergence = 1.326340\n",
      "Epoch: 42\tFidelity = 0.550248\tKL_Divergence = 1.407561\n",
      "Epoch: 43\tFidelity = 0.557388\tKL_Divergence = 1.330969\n",
      "Epoch: 44\tFidelity = 0.551162\tKL_Divergence = 1.397197\n",
      "Epoch: 45\tFidelity = 0.558170\tKL_Divergence = 1.323147\n",
      "Epoch: 46\tFidelity = 0.550792\tKL_Divergence = 1.401373\n",
      "Epoch: 47\tFidelity = 0.557593\tKL_Divergence = 1.328913\n",
      "Epoch: 48\tFidelity = 0.551132\tKL_Divergence = 1.397529\n",
      "Epoch: 49\tFidelity = 0.557943\tKL_Divergence = 1.325409\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:31:35,421] Trial 67 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.553473\tKL_Divergence = 1.371755\n",
      "Total time elapsed during training: 31.282 s\n",
      "Trial 67 pruned. \n",
      "Epoch: 1\tFidelity = 0.565780\tKL_Divergence = 1.251876\n",
      "Epoch: 2\tFidelity = 0.549768\tKL_Divergence = 1.412984\n",
      "Epoch: 3\tFidelity = 0.549952\tKL_Divergence = 1.410910\n",
      "Epoch: 4\tFidelity = 0.557766\tKL_Divergence = 1.327113\n",
      "Epoch: 5\tFidelity = 0.563745\tKL_Divergence = 1.270152\n",
      "Epoch: 6\tFidelity = 0.557938\tKL_Divergence = 1.325343\n",
      "Epoch: 7\tFidelity = 0.553998\tKL_Divergence = 1.366124\n",
      "Epoch: 8\tFidelity = 0.558145\tKL_Divergence = 1.322941\n",
      "Epoch: 9\tFidelity = 0.563574\tKL_Divergence = 1.271711\n",
      "Epoch: 10\tFidelity = 0.557406\tKL_Divergence = 1.330777\n",
      "Epoch: 11\tFidelity = 0.552682\tKL_Divergence = 1.380312\n",
      "Epoch: 12\tFidelity = 0.545484\tKL_Divergence = 1.464485\n",
      "Epoch: 13\tFidelity = 0.544877\tKL_Divergence = 1.472278\n",
      "Epoch: 14\tFidelity = 0.559227\tKL_Divergence = 1.312736\n",
      "Epoch: 15\tFidelity = 0.550010\tKL_Divergence = 1.410160\n",
      "Epoch: 16\tFidelity = 0.546165\tKL_Divergence = 1.456273\n",
      "Epoch: 17\tFidelity = 0.551084\tKL_Divergence = 1.397902\n",
      "Epoch: 18\tFidelity = 0.553369\tKL_Divergence = 1.372903\n",
      "Epoch: 19\tFidelity = 0.546727\tKL_Divergence = 1.449317\n",
      "Epoch: 20\tFidelity = 0.561967\tKL_Divergence = 1.286295\n",
      "Epoch: 21\tFidelity = 0.556522\tKL_Divergence = 1.339803\n",
      "Epoch: 22\tFidelity = 0.555751\tKL_Divergence = 1.347716\n",
      "Epoch: 23\tFidelity = 0.549012\tKL_Divergence = 1.421865\n",
      "Epoch: 24\tFidelity = 0.544445\tKL_Divergence = 1.477939\n",
      "Epoch: 25\tFidelity = 0.543312\tKL_Divergence = 1.492391\n",
      "Epoch: 26\tFidelity = 0.548620\tKL_Divergence = 1.426538\n",
      "Epoch: 27\tFidelity = 0.554069\tKL_Divergence = 1.365398\n",
      "Epoch: 28\tFidelity = 0.546312\tKL_Divergence = 1.454288\n",
      "Epoch: 29\tFidelity = 0.549598\tKL_Divergence = 1.414975\n",
      "Epoch: 30\tFidelity = 0.554306\tKL_Divergence = 1.362750\n",
      "Epoch: 31\tFidelity = 0.563662\tKL_Divergence = 1.270737\n",
      "Epoch: 32\tFidelity = 0.559836\tKL_Divergence = 1.306859\n",
      "Epoch: 33\tFidelity = 0.556629\tKL_Divergence = 1.338710\n",
      "Epoch: 34\tFidelity = 0.543357\tKL_Divergence = 1.492096\n",
      "Epoch: 35\tFidelity = 0.549545\tKL_Divergence = 1.415499\n",
      "Epoch: 36\tFidelity = 0.547025\tKL_Divergence = 1.445682\n",
      "Epoch: 37\tFidelity = 0.549851\tKL_Divergence = 1.411868\n",
      "Epoch: 38\tFidelity = 0.553448\tKL_Divergence = 1.372064\n",
      "Epoch: 39\tFidelity = 0.559714\tKL_Divergence = 1.307896\n",
      "Epoch: 40\tFidelity = 0.548020\tKL_Divergence = 1.433589\n",
      "Epoch: 41\tFidelity = 0.554375\tKL_Divergence = 1.361938\n",
      "Epoch: 42\tFidelity = 0.552826\tKL_Divergence = 1.378717\n",
      "Epoch: 43\tFidelity = 0.553304\tKL_Divergence = 1.373118\n",
      "Epoch: 44\tFidelity = 0.556672\tKL_Divergence = 1.338047\n",
      "Epoch: 45\tFidelity = 0.554149\tKL_Divergence = 1.364547\n",
      "Epoch: 46\tFidelity = 0.561098\tKL_Divergence = 1.294308\n",
      "Epoch: 47\tFidelity = 0.541242\tKL_Divergence = 1.520842\n",
      "Epoch: 48\tFidelity = 0.560579\tKL_Divergence = 1.299528\n",
      "Epoch: 49\tFidelity = 0.551571\tKL_Divergence = 1.392655\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:32:12,304] Trial 68 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.552332\tKL_Divergence = 1.384138\n",
      "Total time elapsed during training: 36.740 s\n",
      "Trial 68 pruned. \n",
      "Epoch: 1\tFidelity = 0.559918\tKL_Divergence = 1.306020\n",
      "Epoch: 2\tFidelity = 0.548970\tKL_Divergence = 1.422438\n",
      "Epoch: 3\tFidelity = 0.555484\tKL_Divergence = 1.350525\n",
      "Epoch: 4\tFidelity = 0.549494\tKL_Divergence = 1.416310\n",
      "Epoch: 5\tFidelity = 0.553315\tKL_Divergence = 1.373515\n",
      "Epoch: 6\tFidelity = 0.563212\tKL_Divergence = 1.275065\n",
      "Epoch: 7\tFidelity = 0.551142\tKL_Divergence = 1.397496\n",
      "Epoch: 8\tFidelity = 0.555241\tKL_Divergence = 1.353067\n",
      "Epoch: 9\tFidelity = 0.558067\tKL_Divergence = 1.324248\n",
      "Epoch: 10\tFidelity = 0.556762\tKL_Divergence = 1.337396\n",
      "Epoch: 11\tFidelity = 0.546408\tKL_Divergence = 1.453309\n",
      "Epoch: 12\tFidelity = 0.557755\tKL_Divergence = 1.327381\n",
      "Epoch: 13\tFidelity = 0.551455\tKL_Divergence = 1.394008\n",
      "Epoch: 14\tFidelity = 0.549637\tKL_Divergence = 1.414717\n",
      "Epoch: 15\tFidelity = 0.557163\tKL_Divergence = 1.333348\n",
      "Epoch: 16\tFidelity = 0.540461\tKL_Divergence = 1.531842\n",
      "Epoch: 17\tFidelity = 0.547113\tKL_Divergence = 1.444678\n",
      "Epoch: 18\tFidelity = 0.546503\tKL_Divergence = 1.452142\n",
      "Epoch: 19\tFidelity = 0.550763\tKL_Divergence = 1.401796\n",
      "Epoch: 20\tFidelity = 0.545838\tKL_Divergence = 1.460410\n",
      "Epoch: 21\tFidelity = 0.546554\tKL_Divergence = 1.451512\n",
      "Epoch: 22\tFidelity = 0.551959\tKL_Divergence = 1.388387\n",
      "Epoch: 23\tFidelity = 0.549747\tKL_Divergence = 1.413425\n",
      "Epoch: 24\tFidelity = 0.548347\tKL_Divergence = 1.429812\n",
      "Epoch: 25\tFidelity = 0.547378\tKL_Divergence = 1.441456\n",
      "Epoch: 26\tFidelity = 0.553675\tKL_Divergence = 1.369683\n",
      "Epoch: 27\tFidelity = 0.555986\tKL_Divergence = 1.345353\n",
      "Epoch: 28\tFidelity = 0.555387\tKL_Divergence = 1.351557\n",
      "Epoch: 29\tFidelity = 0.548130\tKL_Divergence = 1.432426\n",
      "Epoch: 30\tFidelity = 0.548451\tKL_Divergence = 1.428606\n",
      "Epoch: 31\tFidelity = 0.546640\tKL_Divergence = 1.450452\n",
      "Epoch: 32\tFidelity = 0.546365\tKL_Divergence = 1.453836\n",
      "Epoch: 33\tFidelity = 0.552506\tKL_Divergence = 1.382346\n",
      "Epoch: 34\tFidelity = 0.549944\tKL_Divergence = 1.411152\n",
      "Epoch: 35\tFidelity = 0.549979\tKL_Divergence = 1.410748\n",
      "Epoch: 36\tFidelity = 0.543894\tKL_Divergence = 1.485239\n",
      "Epoch: 37\tFidelity = 0.552548\tKL_Divergence = 1.381889\n",
      "Epoch: 38\tFidelity = 0.551160\tKL_Divergence = 1.397304\n",
      "Epoch: 39\tFidelity = 0.549255\tKL_Divergence = 1.419119\n",
      "Epoch: 40\tFidelity = 0.556957\tKL_Divergence = 1.335410\n",
      "Epoch: 41\tFidelity = 0.543723\tKL_Divergence = 1.487486\n",
      "Epoch: 42\tFidelity = 0.546541\tKL_Divergence = 1.451698\n",
      "Epoch: 43\tFidelity = 0.553447\tKL_Divergence = 1.372160\n",
      "Epoch: 44\tFidelity = 0.545859\tKL_Divergence = 1.460192\n",
      "Epoch: 45\tFidelity = 0.553146\tKL_Divergence = 1.375411\n",
      "Epoch: 46\tFidelity = 0.555622\tKL_Divergence = 1.349165\n",
      "Epoch: 47\tFidelity = 0.554521\tKL_Divergence = 1.360708\n",
      "Epoch: 48\tFidelity = 0.542426\tKL_Divergence = 1.504780\n",
      "Epoch: 49\tFidelity = 0.546607\tKL_Divergence = 1.450904\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:32:57,586] Trial 69 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.554116\tKL_Divergence = 1.365016\n",
      "Total time elapsed during training: 45.135 s\n",
      "Trial 69 pruned. \n",
      "Epoch: 1\tFidelity = 0.545236\tKL_Divergence = 1.468062\n",
      "Epoch: 2\tFidelity = 0.548373\tKL_Divergence = 1.429569\n",
      "Epoch: 3\tFidelity = 0.545532\tKL_Divergence = 1.464314\n",
      "Epoch: 4\tFidelity = 0.546716\tKL_Divergence = 1.449546\n",
      "Epoch: 5\tFidelity = 0.548579\tKL_Divergence = 1.427139\n",
      "Epoch: 6\tFidelity = 0.551397\tKL_Divergence = 1.394685\n",
      "Epoch: 7\tFidelity = 0.548764\tKL_Divergence = 1.424937\n",
      "Epoch: 8\tFidelity = 0.546143\tKL_Divergence = 1.456671\n",
      "Epoch: 9\tFidelity = 0.544146\tKL_Divergence = 1.482021\n",
      "Epoch: 10\tFidelity = 0.551343\tKL_Divergence = 1.395316\n",
      "Epoch: 11\tFidelity = 0.549079\tKL_Divergence = 1.421267\n",
      "Epoch: 12\tFidelity = 0.555614\tKL_Divergence = 1.349252\n",
      "Epoch: 13\tFidelity = 0.552201\tKL_Divergence = 1.385720\n",
      "Epoch: 14\tFidelity = 0.546588\tKL_Divergence = 1.451146\n",
      "Epoch: 15\tFidelity = 0.549003\tKL_Divergence = 1.422090\n",
      "Epoch: 16\tFidelity = 0.547343\tKL_Divergence = 1.441953\n",
      "Epoch: 17\tFidelity = 0.541400\tKL_Divergence = 1.518812\n",
      "Epoch: 18\tFidelity = 0.546609\tKL_Divergence = 1.450932\n",
      "Epoch: 19\tFidelity = 0.544714\tKL_Divergence = 1.474704\n",
      "Epoch: 20\tFidelity = 0.543089\tKL_Divergence = 1.495928\n",
      "Epoch: 21\tFidelity = 0.546694\tKL_Divergence = 1.449883\n",
      "Epoch: 22\tFidelity = 0.553090\tKL_Divergence = 1.376064\n",
      "Epoch: 23\tFidelity = 0.543728\tKL_Divergence = 1.487492\n",
      "Epoch: 24\tFidelity = 0.547022\tKL_Divergence = 1.445874\n",
      "Epoch: 25\tFidelity = 0.546327\tKL_Divergence = 1.454414\n",
      "Epoch: 26\tFidelity = 0.548203\tKL_Divergence = 1.431622\n",
      "Epoch: 27\tFidelity = 0.546012\tKL_Divergence = 1.458281\n",
      "Epoch: 28\tFidelity = 0.546499\tKL_Divergence = 1.452191\n",
      "Epoch: 29\tFidelity = 0.543741\tKL_Divergence = 1.487300\n",
      "Epoch: 30\tFidelity = 0.546849\tKL_Divergence = 1.447921\n",
      "Epoch: 31\tFidelity = 0.546677\tKL_Divergence = 1.450092\n",
      "Epoch: 32\tFidelity = 0.548743\tKL_Divergence = 1.425212\n",
      "Epoch: 33\tFidelity = 0.550182\tKL_Divergence = 1.408476\n",
      "Epoch: 34\tFidelity = 0.550378\tKL_Divergence = 1.406221\n",
      "Epoch: 35\tFidelity = 0.549679\tKL_Divergence = 1.414278\n",
      "Epoch: 36\tFidelity = 0.549861\tKL_Divergence = 1.412097\n",
      "Epoch: 37\tFidelity = 0.545963\tKL_Divergence = 1.458889\n",
      "Epoch: 38\tFidelity = 0.547483\tKL_Divergence = 1.440243\n",
      "Epoch: 39\tFidelity = 0.549365\tKL_Divergence = 1.417932\n",
      "Epoch: 40\tFidelity = 0.548804\tKL_Divergence = 1.424496\n",
      "Epoch: 41\tFidelity = 0.544879\tKL_Divergence = 1.472574\n",
      "Epoch: 42\tFidelity = 0.546648\tKL_Divergence = 1.450431\n",
      "Epoch: 43\tFidelity = 0.544528\tKL_Divergence = 1.477108\n",
      "Epoch: 44\tFidelity = 0.549013\tKL_Divergence = 1.422012\n",
      "Epoch: 45\tFidelity = 0.550433\tKL_Divergence = 1.405629\n",
      "Epoch: 46\tFidelity = 0.544094\tKL_Divergence = 1.482686\n",
      "Epoch: 47\tFidelity = 0.547591\tKL_Divergence = 1.438949\n",
      "Epoch: 48\tFidelity = 0.551600\tKL_Divergence = 1.392459\n",
      "Epoch: 49\tFidelity = 0.551565\tKL_Divergence = 1.392857\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:33:35,576] Trial 70 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.548232\tKL_Divergence = 1.431295\n",
      "Total time elapsed during training: 37.842 s\n",
      "Trial 70 pruned. \n",
      "Epoch: 1\tFidelity = 0.546710\tKL_Divergence = 1.449707\n",
      "Epoch: 2\tFidelity = 0.542094\tKL_Divergence = 1.509311\n",
      "Epoch: 3\tFidelity = 0.545014\tKL_Divergence = 1.470912\n",
      "Epoch: 4\tFidelity = 0.546416\tKL_Divergence = 1.453326\n",
      "Epoch: 5\tFidelity = 0.546275\tKL_Divergence = 1.455071\n",
      "Epoch: 6\tFidelity = 0.544729\tKL_Divergence = 1.474553\n",
      "Epoch: 7\tFidelity = 0.547602\tKL_Divergence = 1.438803\n",
      "Epoch: 8\tFidelity = 0.544948\tKL_Divergence = 1.471741\n",
      "Epoch: 9\tFidelity = 0.548472\tKL_Divergence = 1.428432\n",
      "Epoch: 10\tFidelity = 0.543583\tKL_Divergence = 1.489416\n",
      "Epoch: 11\tFidelity = 0.543419\tKL_Divergence = 1.491561\n",
      "Epoch: 12\tFidelity = 0.546652\tKL_Divergence = 1.450405\n",
      "Epoch: 13\tFidelity = 0.544093\tKL_Divergence = 1.482740\n",
      "Epoch: 14\tFidelity = 0.553270\tKL_Divergence = 1.374100\n",
      "Epoch: 15\tFidelity = 0.544190\tKL_Divergence = 1.481494\n",
      "Epoch: 16\tFidelity = 0.549490\tKL_Divergence = 1.416489\n",
      "Epoch: 17\tFidelity = 0.548945\tKL_Divergence = 1.422821\n",
      "Epoch: 18\tFidelity = 0.543059\tKL_Divergence = 1.496357\n",
      "Epoch: 19\tFidelity = 0.549748\tKL_Divergence = 1.413500\n",
      "Epoch: 20\tFidelity = 0.543372\tKL_Divergence = 1.492192\n",
      "Epoch: 21\tFidelity = 0.543534\tKL_Divergence = 1.490046\n",
      "Epoch: 22\tFidelity = 0.548548\tKL_Divergence = 1.427477\n",
      "Epoch: 23\tFidelity = 0.543858\tKL_Divergence = 1.485721\n",
      "Epoch: 24\tFidelity = 0.545461\tKL_Divergence = 1.465207\n",
      "Epoch: 25\tFidelity = 0.550476\tKL_Divergence = 1.405115\n",
      "Epoch: 26\tFidelity = 0.545922\tKL_Divergence = 1.459452\n",
      "Epoch: 27\tFidelity = 0.544320\tKL_Divergence = 1.479801\n",
      "Epoch: 28\tFidelity = 0.546289\tKL_Divergence = 1.454875\n",
      "Epoch: 29\tFidelity = 0.546810\tKL_Divergence = 1.448471\n",
      "Epoch: 30\tFidelity = 0.549209\tKL_Divergence = 1.419754\n",
      "Epoch: 31\tFidelity = 0.546386\tKL_Divergence = 1.453669\n",
      "Epoch: 32\tFidelity = 0.547464\tKL_Divergence = 1.440423\n",
      "Epoch: 33\tFidelity = 0.543106\tKL_Divergence = 1.495734\n",
      "Epoch: 34\tFidelity = 0.544445\tKL_Divergence = 1.478212\n",
      "Epoch: 35\tFidelity = 0.542617\tKL_Divergence = 1.502257\n",
      "Epoch: 36\tFidelity = 0.547705\tKL_Divergence = 1.437608\n",
      "Epoch: 37\tFidelity = 0.549233\tKL_Divergence = 1.419490\n",
      "Epoch: 38\tFidelity = 0.548643\tKL_Divergence = 1.426414\n",
      "Epoch: 39\tFidelity = 0.541359\tKL_Divergence = 1.519347\n",
      "Epoch: 40\tFidelity = 0.542963\tKL_Divergence = 1.497604\n",
      "Epoch: 41\tFidelity = 0.544242\tKL_Divergence = 1.480774\n",
      "Epoch: 42\tFidelity = 0.551703\tKL_Divergence = 1.391244\n",
      "Epoch: 43\tFidelity = 0.546574\tKL_Divergence = 1.451311\n",
      "Epoch: 44\tFidelity = 0.541973\tKL_Divergence = 1.510967\n",
      "Epoch: 45\tFidelity = 0.546137\tKL_Divergence = 1.456782\n",
      "Epoch: 46\tFidelity = 0.549570\tKL_Divergence = 1.415557\n",
      "Epoch: 47\tFidelity = 0.545389\tKL_Divergence = 1.466115\n",
      "Epoch: 48\tFidelity = 0.546880\tKL_Divergence = 1.447616\n",
      "Epoch: 49\tFidelity = 0.544922\tKL_Divergence = 1.472040\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:34:15,145] Trial 71 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.550441\tKL_Divergence = 1.405509\n",
      "Total time elapsed during training: 39.424 s\n",
      "Trial 71 pruned. \n",
      "Epoch: 1\tFidelity = 0.548566\tKL_Divergence = 1.427331\n",
      "Epoch: 2\tFidelity = 0.546500\tKL_Divergence = 1.452296\n",
      "Epoch: 3\tFidelity = 0.540299\tKL_Divergence = 1.534105\n",
      "Epoch: 4\tFidelity = 0.555807\tKL_Divergence = 1.347027\n",
      "Epoch: 5\tFidelity = 0.550444\tKL_Divergence = 1.405434\n",
      "Epoch: 6\tFidelity = 0.542978\tKL_Divergence = 1.497432\n",
      "Epoch: 7\tFidelity = 0.549427\tKL_Divergence = 1.417230\n",
      "Epoch: 8\tFidelity = 0.542851\tKL_Divergence = 1.499083\n",
      "Epoch: 9\tFidelity = 0.549954\tKL_Divergence = 1.411121\n",
      "Epoch: 10\tFidelity = 0.547762\tKL_Divergence = 1.436884\n",
      "Epoch: 11\tFidelity = 0.545628\tKL_Divergence = 1.463157\n",
      "Epoch: 12\tFidelity = 0.539544\tKL_Divergence = 1.545067\n",
      "Epoch: 13\tFidelity = 0.537598\tKL_Divergence = 1.573815\n",
      "Epoch: 14\tFidelity = 0.547657\tKL_Divergence = 1.437985\n",
      "Epoch: 15\tFidelity = 0.542732\tKL_Divergence = 1.500637\n",
      "Epoch: 16\tFidelity = 0.547452\tKL_Divergence = 1.440461\n",
      "Epoch: 17\tFidelity = 0.548822\tKL_Divergence = 1.423993\n",
      "Epoch: 18\tFidelity = 0.542944\tKL_Divergence = 1.497611\n",
      "Epoch: 19\tFidelity = 0.550765\tKL_Divergence = 1.401766\n",
      "Epoch: 20\tFidelity = 0.542607\tKL_Divergence = 1.502246\n",
      "Epoch: 21\tFidelity = 0.545681\tKL_Divergence = 1.462439\n",
      "Epoch: 22\tFidelity = 0.545486\tKL_Divergence = 1.464909\n",
      "Epoch: 23\tFidelity = 0.540062\tKL_Divergence = 1.537607\n",
      "Epoch: 24\tFidelity = 0.543805\tKL_Divergence = 1.486450\n",
      "Epoch: 25\tFidelity = 0.543938\tKL_Divergence = 1.484673\n",
      "Epoch: 26\tFidelity = 0.542865\tKL_Divergence = 1.498771\n",
      "Epoch: 27\tFidelity = 0.546171\tKL_Divergence = 1.456077\n",
      "Epoch: 28\tFidelity = 0.545938\tKL_Divergence = 1.459199\n",
      "Epoch: 29\tFidelity = 0.542039\tKL_Divergence = 1.510014\n",
      "Epoch: 30\tFidelity = 0.544152\tKL_Divergence = 1.481786\n",
      "Epoch: 31\tFidelity = 0.543601\tKL_Divergence = 1.489064\n",
      "Epoch: 32\tFidelity = 0.548082\tKL_Divergence = 1.432974\n",
      "Epoch: 33\tFidelity = 0.546851\tKL_Divergence = 1.447947\n",
      "Epoch: 34\tFidelity = 0.545299\tKL_Divergence = 1.467338\n",
      "Epoch: 35\tFidelity = 0.549614\tKL_Divergence = 1.415068\n",
      "Epoch: 36\tFidelity = 0.547476\tKL_Divergence = 1.440329\n",
      "Epoch: 37\tFidelity = 0.542525\tKL_Divergence = 1.503514\n",
      "Epoch: 38\tFidelity = 0.545849\tKL_Divergence = 1.460392\n",
      "Epoch: 39\tFidelity = 0.543743\tKL_Divergence = 1.487154\n",
      "Epoch: 40\tFidelity = 0.538859\tKL_Divergence = 1.555025\n",
      "Epoch: 41\tFidelity = 0.543148\tKL_Divergence = 1.495202\n",
      "Epoch: 42\tFidelity = 0.544305\tKL_Divergence = 1.480001\n",
      "Epoch: 43\tFidelity = 0.541604\tKL_Divergence = 1.515908\n",
      "Epoch: 44\tFidelity = 0.544171\tKL_Divergence = 1.481653\n",
      "Epoch: 45\tFidelity = 0.541142\tKL_Divergence = 1.522447\n",
      "Epoch: 46\tFidelity = 0.545938\tKL_Divergence = 1.459220\n",
      "Epoch: 47\tFidelity = 0.551292\tKL_Divergence = 1.395888\n",
      "Epoch: 48\tFidelity = 0.545031\tKL_Divergence = 1.470744\n",
      "Epoch: 49\tFidelity = 0.542788\tKL_Divergence = 1.499977\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:34:58,620] Trial 72 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.544394\tKL_Divergence = 1.478910\n",
      "Total time elapsed during training: 43.245 s\n",
      "Trial 72 pruned. \n",
      "Epoch: 1\tFidelity = 0.543659\tKL_Divergence = 1.488472\n",
      "Epoch: 2\tFidelity = 0.547089\tKL_Divergence = 1.445102\n",
      "Epoch: 3\tFidelity = 0.543914\tKL_Divergence = 1.485107\n",
      "Epoch: 4\tFidelity = 0.545877\tKL_Divergence = 1.460067\n",
      "Epoch: 5\tFidelity = 0.548721\tKL_Divergence = 1.425511\n",
      "Epoch: 6\tFidelity = 0.546309\tKL_Divergence = 1.454674\n",
      "Epoch: 7\tFidelity = 0.543449\tKL_Divergence = 1.491223\n",
      "Epoch: 8\tFidelity = 0.543576\tKL_Divergence = 1.489561\n",
      "Epoch: 9\tFidelity = 0.542705\tKL_Divergence = 1.501121\n",
      "Epoch: 10\tFidelity = 0.548477\tKL_Divergence = 1.428405\n",
      "Epoch: 11\tFidelity = 0.547477\tKL_Divergence = 1.440399\n",
      "Epoch: 12\tFidelity = 0.543917\tKL_Divergence = 1.485050\n",
      "Epoch: 13\tFidelity = 0.546398\tKL_Divergence = 1.453585\n",
      "Epoch: 14\tFidelity = 0.546102\tKL_Divergence = 1.457264\n",
      "Epoch: 15\tFidelity = 0.543102\tKL_Divergence = 1.495838\n",
      "Epoch: 16\tFidelity = 0.547131\tKL_Divergence = 1.444614\n",
      "Epoch: 17\tFidelity = 0.544828\tKL_Divergence = 1.473343\n",
      "Epoch: 18\tFidelity = 0.544002\tKL_Divergence = 1.484003\n",
      "Epoch: 19\tFidelity = 0.545728\tKL_Divergence = 1.461916\n",
      "Epoch: 20\tFidelity = 0.546390\tKL_Divergence = 1.453696\n",
      "Epoch: 21\tFidelity = 0.542550\tKL_Divergence = 1.503204\n",
      "Epoch: 22\tFidelity = 0.544096\tKL_Divergence = 1.482749\n",
      "Epoch: 23\tFidelity = 0.541124\tKL_Divergence = 1.522721\n",
      "Epoch: 24\tFidelity = 0.545558\tKL_Divergence = 1.464080\n",
      "Epoch: 25\tFidelity = 0.540307\tKL_Divergence = 1.534202\n",
      "Epoch: 26\tFidelity = 0.543565\tKL_Divergence = 1.489711\n",
      "Epoch: 27\tFidelity = 0.541215\tKL_Divergence = 1.521467\n",
      "Epoch: 28\tFidelity = 0.541009\tKL_Divergence = 1.524344\n",
      "Epoch: 29\tFidelity = 0.543026\tKL_Divergence = 1.496869\n",
      "Epoch: 30\tFidelity = 0.541167\tKL_Divergence = 1.522133\n",
      "Epoch: 31\tFidelity = 0.545032\tKL_Divergence = 1.470758\n",
      "Epoch: 32\tFidelity = 0.546578\tKL_Divergence = 1.451396\n",
      "Epoch: 33\tFidelity = 0.538267\tKL_Divergence = 1.563868\n",
      "Epoch: 34\tFidelity = 0.542418\tKL_Divergence = 1.505016\n",
      "Epoch: 35\tFidelity = 0.541099\tKL_Divergence = 1.523086\n",
      "Epoch: 36\tFidelity = 0.540676\tKL_Divergence = 1.529009\n",
      "Epoch: 37\tFidelity = 0.542527\tKL_Divergence = 1.503544\n",
      "Epoch: 38\tFidelity = 0.547513\tKL_Divergence = 1.439953\n",
      "Epoch: 39\tFidelity = 0.543511\tKL_Divergence = 1.490439\n",
      "Epoch: 40\tFidelity = 0.549430\tKL_Divergence = 1.417264\n",
      "Epoch: 41\tFidelity = 0.544874\tKL_Divergence = 1.472792\n",
      "Epoch: 42\tFidelity = 0.546605\tKL_Divergence = 1.451072\n",
      "Epoch: 43\tFidelity = 0.542982\tKL_Divergence = 1.497476\n",
      "Epoch: 44\tFidelity = 0.543060\tKL_Divergence = 1.496432\n",
      "Epoch: 45\tFidelity = 0.541757\tKL_Divergence = 1.514009\n",
      "Epoch: 46\tFidelity = 0.542284\tKL_Divergence = 1.506842\n",
      "Epoch: 47\tFidelity = 0.544487\tKL_Divergence = 1.477741\n",
      "Epoch: 48\tFidelity = 0.540778\tKL_Divergence = 1.527581\n",
      "Epoch: 49\tFidelity = 0.546224\tKL_Divergence = 1.455777\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:35:35,644] Trial 73 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.546960\tKL_Divergence = 1.446713\n",
      "Total time elapsed during training: 36.876 s\n",
      "Trial 73 pruned. \n",
      "Epoch: 1\tFidelity = 0.539788\tKL_Divergence = 1.541580\n",
      "Epoch: 2\tFidelity = 0.544657\tKL_Divergence = 1.475509\n",
      "Epoch: 3\tFidelity = 0.540975\tKL_Divergence = 1.524781\n",
      "Epoch: 4\tFidelity = 0.545572\tKL_Divergence = 1.463918\n",
      "Epoch: 5\tFidelity = 0.544813\tKL_Divergence = 1.473562\n",
      "Epoch: 6\tFidelity = 0.542479\tKL_Divergence = 1.504193\n",
      "Epoch: 7\tFidelity = 0.544245\tKL_Divergence = 1.480872\n",
      "Epoch: 8\tFidelity = 0.539785\tKL_Divergence = 1.541666\n",
      "Epoch: 9\tFidelity = 0.539881\tKL_Divergence = 1.540297\n",
      "Epoch: 10\tFidelity = 0.543603\tKL_Divergence = 1.489249\n",
      "Epoch: 11\tFidelity = 0.541139\tKL_Divergence = 1.522548\n",
      "Epoch: 12\tFidelity = 0.538850\tKL_Divergence = 1.555261\n",
      "Epoch: 13\tFidelity = 0.539507\tKL_Divergence = 1.545678\n",
      "Epoch: 14\tFidelity = 0.545707\tKL_Divergence = 1.462240\n",
      "Epoch: 15\tFidelity = 0.544219\tKL_Divergence = 1.481218\n",
      "Epoch: 16\tFidelity = 0.543230\tKL_Divergence = 1.494195\n",
      "Epoch: 17\tFidelity = 0.542774\tKL_Divergence = 1.500250\n",
      "Epoch: 18\tFidelity = 0.540382\tKL_Divergence = 1.533178\n",
      "Epoch: 19\tFidelity = 0.538766\tKL_Divergence = 1.556515\n",
      "Epoch: 20\tFidelity = 0.540390\tKL_Divergence = 1.533058\n",
      "Epoch: 21\tFidelity = 0.539834\tKL_Divergence = 1.540983\n",
      "Epoch: 22\tFidelity = 0.539063\tKL_Divergence = 1.552128\n",
      "Epoch: 23\tFidelity = 0.543538\tKL_Divergence = 1.490061\n",
      "Epoch: 24\tFidelity = 0.544297\tKL_Divergence = 1.480208\n",
      "Epoch: 25\tFidelity = 0.539222\tKL_Divergence = 1.549823\n",
      "Epoch: 26\tFidelity = 0.542111\tKL_Divergence = 1.509200\n",
      "Epoch: 27\tFidelity = 0.545383\tKL_Divergence = 1.466330\n",
      "Epoch: 28\tFidelity = 0.542424\tKL_Divergence = 1.504967\n",
      "Epoch: 29\tFidelity = 0.538042\tKL_Divergence = 1.567261\n",
      "Epoch: 30\tFidelity = 0.540062\tKL_Divergence = 1.537647\n",
      "Epoch: 31\tFidelity = 0.540609\tKL_Divergence = 1.529933\n",
      "Epoch: 32\tFidelity = 0.543574\tKL_Divergence = 1.489598\n",
      "Epoch: 33\tFidelity = 0.537927\tKL_Divergence = 1.568948\n",
      "Epoch: 34\tFidelity = 0.540107\tKL_Divergence = 1.537034\n",
      "Epoch: 35\tFidelity = 0.540919\tKL_Divergence = 1.525603\n",
      "Epoch: 36\tFidelity = 0.539971\tKL_Divergence = 1.538999\n",
      "Epoch: 37\tFidelity = 0.538202\tKL_Divergence = 1.564843\n",
      "Epoch: 38\tFidelity = 0.541325\tKL_Divergence = 1.519975\n",
      "Epoch: 39\tFidelity = 0.539475\tKL_Divergence = 1.546147\n",
      "Epoch: 40\tFidelity = 0.539043\tKL_Divergence = 1.552423\n",
      "Epoch: 41\tFidelity = 0.539995\tKL_Divergence = 1.538672\n",
      "Epoch: 42\tFidelity = 0.541076\tKL_Divergence = 1.523404\n",
      "Epoch: 43\tFidelity = 0.542958\tKL_Divergence = 1.497798\n",
      "Epoch: 44\tFidelity = 0.537794\tKL_Divergence = 1.571002\n",
      "Epoch: 45\tFidelity = 0.540708\tKL_Divergence = 1.528572\n",
      "Epoch: 46\tFidelity = 0.542631\tKL_Divergence = 1.502178\n",
      "Epoch: 47\tFidelity = 0.542640\tKL_Divergence = 1.502063\n",
      "Epoch: 48\tFidelity = 0.540615\tKL_Divergence = 1.529879\n",
      "Epoch: 49\tFidelity = 0.540008\tKL_Divergence = 1.538465\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:36:12,305] Trial 74 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.544207\tKL_Divergence = 1.481360\n",
      "Total time elapsed during training: 36.524 s\n",
      "Trial 74 pruned. \n",
      "Epoch: 1\tFidelity = 0.542394\tKL_Divergence = 1.505345\n",
      "Epoch: 2\tFidelity = 0.542029\tKL_Divergence = 1.510313\n",
      "Epoch: 3\tFidelity = 0.541575\tKL_Divergence = 1.516533\n",
      "Epoch: 4\tFidelity = 0.539372\tKL_Divergence = 1.547651\n",
      "Epoch: 5\tFidelity = 0.543490\tKL_Divergence = 1.490756\n",
      "Epoch: 6\tFidelity = 0.543418\tKL_Divergence = 1.491702\n",
      "Epoch: 7\tFidelity = 0.536006\tKL_Divergence = 1.598637\n",
      "Epoch: 8\tFidelity = 0.538832\tKL_Divergence = 1.555528\n",
      "Epoch: 9\tFidelity = 0.540589\tKL_Divergence = 1.530266\n",
      "Epoch: 10\tFidelity = 0.541267\tKL_Divergence = 1.520787\n",
      "Epoch: 11\tFidelity = 0.544639\tKL_Divergence = 1.475811\n",
      "Epoch: 12\tFidelity = 0.541586\tKL_Divergence = 1.516375\n",
      "Epoch: 13\tFidelity = 0.541180\tKL_Divergence = 1.521994\n",
      "Epoch: 14\tFidelity = 0.543240\tKL_Divergence = 1.494058\n",
      "Epoch: 15\tFidelity = 0.539968\tKL_Divergence = 1.539067\n",
      "Epoch: 16\tFidelity = 0.538848\tKL_Divergence = 1.555298\n",
      "Epoch: 17\tFidelity = 0.539943\tKL_Divergence = 1.539424\n",
      "Epoch: 18\tFidelity = 0.538292\tKL_Divergence = 1.563538\n",
      "Epoch: 19\tFidelity = 0.540583\tKL_Divergence = 1.530334\n",
      "Epoch: 20\tFidelity = 0.538669\tKL_Divergence = 1.557941\n",
      "Epoch: 21\tFidelity = 0.541514\tKL_Divergence = 1.517378\n",
      "Epoch: 22\tFidelity = 0.540638\tKL_Divergence = 1.529568\n",
      "Epoch: 23\tFidelity = 0.542753\tKL_Divergence = 1.500553\n",
      "Epoch: 24\tFidelity = 0.542547\tKL_Divergence = 1.503314\n",
      "Epoch: 25\tFidelity = 0.539468\tKL_Divergence = 1.546268\n",
      "Epoch: 26\tFidelity = 0.540954\tKL_Divergence = 1.525146\n",
      "Epoch: 27\tFidelity = 0.545480\tKL_Divergence = 1.465126\n",
      "Epoch: 28\tFidelity = 0.542871\tKL_Divergence = 1.498972\n",
      "Epoch: 29\tFidelity = 0.540174\tKL_Divergence = 1.536139\n",
      "Epoch: 30\tFidelity = 0.541903\tKL_Divergence = 1.512031\n",
      "Epoch: 31\tFidelity = 0.542823\tKL_Divergence = 1.499602\n",
      "Epoch: 32\tFidelity = 0.542208\tKL_Divergence = 1.507895\n",
      "Epoch: 33\tFidelity = 0.540447\tKL_Divergence = 1.532258\n",
      "Epoch: 34\tFidelity = 0.539190\tKL_Divergence = 1.550312\n",
      "Epoch: 35\tFidelity = 0.539533\tKL_Divergence = 1.545334\n",
      "Epoch: 36\tFidelity = 0.538795\tKL_Divergence = 1.556096\n",
      "Epoch: 37\tFidelity = 0.542020\tKL_Divergence = 1.510464\n",
      "Epoch: 38\tFidelity = 0.538893\tKL_Divergence = 1.554645\n",
      "Epoch: 39\tFidelity = 0.542630\tKL_Divergence = 1.502198\n",
      "Epoch: 40\tFidelity = 0.544857\tKL_Divergence = 1.473020\n",
      "Epoch: 41\tFidelity = 0.542434\tKL_Divergence = 1.504828\n",
      "Epoch: 42\tFidelity = 0.544994\tKL_Divergence = 1.471274\n",
      "Epoch: 43\tFidelity = 0.542491\tKL_Divergence = 1.504055\n",
      "Epoch: 44\tFidelity = 0.536770\tKL_Divergence = 1.586659\n",
      "Epoch: 45\tFidelity = 0.535956\tKL_Divergence = 1.599404\n",
      "Epoch: 46\tFidelity = 0.539579\tKL_Divergence = 1.544649\n",
      "Epoch: 47\tFidelity = 0.541181\tKL_Divergence = 1.521957\n",
      "Epoch: 48\tFidelity = 0.540521\tKL_Divergence = 1.531211\n",
      "Epoch: 49\tFidelity = 0.540052\tKL_Divergence = 1.537884\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:36:49,282] Trial 75 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.542039\tKL_Divergence = 1.510184\n",
      "Total time elapsed during training: 36.835 s\n",
      "Trial 75 pruned. \n",
      "Epoch: 1\tFidelity = 0.541836\tKL_Divergence = 1.512939\n",
      "Epoch: 2\tFidelity = 0.539968\tKL_Divergence = 1.539045\n",
      "Epoch: 3\tFidelity = 0.539769\tKL_Divergence = 1.541963\n",
      "Epoch: 4\tFidelity = 0.540559\tKL_Divergence = 1.530701\n",
      "Epoch: 5\tFidelity = 0.539245\tKL_Divergence = 1.549522\n",
      "Epoch: 6\tFidelity = 0.543474\tKL_Divergence = 1.490953\n",
      "Epoch: 7\tFidelity = 0.543309\tKL_Divergence = 1.493169\n",
      "Epoch: 8\tFidelity = 0.538469\tKL_Divergence = 1.560934\n",
      "Epoch: 9\tFidelity = 0.536539\tKL_Divergence = 1.590220\n",
      "Epoch: 10\tFidelity = 0.534028\tKL_Divergence = 1.630817\n",
      "Epoch: 11\tFidelity = 0.534585\tKL_Divergence = 1.621296\n",
      "Epoch: 12\tFidelity = 0.544454\tKL_Divergence = 1.477967\n",
      "Epoch: 13\tFidelity = 0.534143\tKL_Divergence = 1.628744\n",
      "Epoch: 14\tFidelity = 0.540508\tKL_Divergence = 1.531249\n",
      "Epoch: 15\tFidelity = 0.538831\tKL_Divergence = 1.555316\n",
      "Epoch: 16\tFidelity = 0.536993\tKL_Divergence = 1.583265\n",
      "Epoch: 17\tFidelity = 0.540614\tKL_Divergence = 1.529950\n",
      "Epoch: 18\tFidelity = 0.537019\tKL_Divergence = 1.582796\n",
      "Epoch: 19\tFidelity = 0.538377\tKL_Divergence = 1.562306\n",
      "Epoch: 20\tFidelity = 0.540038\tKL_Divergence = 1.538124\n",
      "Epoch: 21\tFidelity = 0.537847\tKL_Divergence = 1.570216\n",
      "Epoch: 22\tFidelity = 0.536072\tKL_Divergence = 1.597533\n",
      "Epoch: 23\tFidelity = 0.544759\tKL_Divergence = 1.474306\n",
      "Epoch: 24\tFidelity = 0.542344\tKL_Divergence = 1.505950\n",
      "Epoch: 25\tFidelity = 0.538091\tKL_Divergence = 1.566509\n",
      "Epoch: 26\tFidelity = 0.539402\tKL_Divergence = 1.547090\n",
      "Epoch: 27\tFidelity = 0.539857\tKL_Divergence = 1.540733\n",
      "Epoch: 28\tFidelity = 0.533934\tKL_Divergence = 1.632450\n",
      "Epoch: 29\tFidelity = 0.540572\tKL_Divergence = 1.530567\n",
      "Epoch: 30\tFidelity = 0.540469\tKL_Divergence = 1.531988\n",
      "Epoch: 31\tFidelity = 0.538968\tKL_Divergence = 1.553468\n",
      "Epoch: 32\tFidelity = 0.542903\tKL_Divergence = 1.498292\n",
      "Epoch: 33\tFidelity = 0.534195\tKL_Divergence = 1.627839\n",
      "Epoch: 34\tFidelity = 0.540631\tKL_Divergence = 1.529664\n",
      "Epoch: 35\tFidelity = 0.538321\tKL_Divergence = 1.562922\n",
      "Epoch: 36\tFidelity = 0.537179\tKL_Divergence = 1.580218\n",
      "Epoch: 37\tFidelity = 0.539343\tKL_Divergence = 1.548120\n",
      "Epoch: 38\tFidelity = 0.539585\tKL_Divergence = 1.544638\n",
      "Epoch: 39\tFidelity = 0.537286\tKL_Divergence = 1.578539\n",
      "Epoch: 40\tFidelity = 0.543046\tKL_Divergence = 1.496351\n",
      "Epoch: 41\tFidelity = 0.535788\tKL_Divergence = 1.601863\n",
      "Epoch: 42\tFidelity = 0.537513\tKL_Divergence = 1.575274\n",
      "Epoch: 43\tFidelity = 0.539338\tKL_Divergence = 1.548088\n",
      "Epoch: 44\tFidelity = 0.545012\tKL_Divergence = 1.471011\n",
      "Epoch: 45\tFidelity = 0.536289\tKL_Divergence = 1.594243\n",
      "Epoch: 46\tFidelity = 0.539561\tKL_Divergence = 1.544931\n",
      "Epoch: 47\tFidelity = 0.536849\tKL_Divergence = 1.585449\n",
      "Epoch: 48\tFidelity = 0.538695\tKL_Divergence = 1.557553\n",
      "Epoch: 49\tFidelity = 0.538508\tKL_Divergence = 1.560377\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:37:26,271] Trial 76 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.540854\tKL_Divergence = 1.526602\n",
      "Total time elapsed during training: 36.849 s\n",
      "Trial 76 pruned. \n",
      "Epoch: 1\tFidelity = 0.539001\tKL_Divergence = 1.553144\n",
      "Epoch: 2\tFidelity = 0.538148\tKL_Divergence = 1.565757\n",
      "Epoch: 3\tFidelity = 0.539858\tKL_Divergence = 1.540722\n",
      "Epoch: 4\tFidelity = 0.539050\tKL_Divergence = 1.552425\n",
      "Epoch: 5\tFidelity = 0.537264\tKL_Divergence = 1.579127\n",
      "Epoch: 6\tFidelity = 0.536661\tKL_Divergence = 1.588426\n",
      "Epoch: 7\tFidelity = 0.536781\tKL_Divergence = 1.586566\n",
      "Epoch: 8\tFidelity = 0.535265\tKL_Divergence = 1.610554\n",
      "Epoch: 9\tFidelity = 0.539770\tKL_Divergence = 1.541958\n",
      "Epoch: 10\tFidelity = 0.537271\tKL_Divergence = 1.579020\n",
      "Epoch: 11\tFidelity = 0.539711\tKL_Divergence = 1.542755\n",
      "Epoch: 12\tFidelity = 0.539150\tKL_Divergence = 1.550851\n",
      "Epoch: 13\tFidelity = 0.537493\tKL_Divergence = 1.575637\n",
      "Epoch: 14\tFidelity = 0.539815\tKL_Divergence = 1.541333\n",
      "Epoch: 15\tFidelity = 0.539265\tKL_Divergence = 1.549279\n",
      "Epoch: 16\tFidelity = 0.533874\tKL_Divergence = 1.633454\n",
      "Epoch: 17\tFidelity = 0.540450\tKL_Divergence = 1.532285\n",
      "Epoch: 18\tFidelity = 0.539395\tKL_Divergence = 1.547336\n",
      "Epoch: 19\tFidelity = 0.541841\tKL_Divergence = 1.512946\n",
      "Epoch: 20\tFidelity = 0.535775\tKL_Divergence = 1.602309\n",
      "Epoch: 21\tFidelity = 0.541806\tKL_Divergence = 1.513328\n",
      "Epoch: 22\tFidelity = 0.540980\tKL_Divergence = 1.524768\n",
      "Epoch: 23\tFidelity = 0.532768\tKL_Divergence = 1.652334\n",
      "Epoch: 24\tFidelity = 0.539071\tKL_Divergence = 1.552089\n",
      "Epoch: 25\tFidelity = 0.539159\tKL_Divergence = 1.550822\n",
      "Epoch: 26\tFidelity = 0.539205\tKL_Divergence = 1.550100\n",
      "Epoch: 27\tFidelity = 0.539970\tKL_Divergence = 1.539071\n",
      "Epoch: 28\tFidelity = 0.538066\tKL_Divergence = 1.566807\n",
      "Epoch: 29\tFidelity = 0.538663\tKL_Divergence = 1.557986\n",
      "Epoch: 30\tFidelity = 0.538672\tKL_Divergence = 1.557895\n",
      "Epoch: 31\tFidelity = 0.535378\tKL_Divergence = 1.608719\n",
      "Epoch: 32\tFidelity = 0.541259\tKL_Divergence = 1.520960\n",
      "Epoch: 33\tFidelity = 0.539110\tKL_Divergence = 1.551542\n",
      "Epoch: 34\tFidelity = 0.540781\tKL_Divergence = 1.527619\n",
      "Epoch: 35\tFidelity = 0.537441\tKL_Divergence = 1.576445\n",
      "Epoch: 36\tFidelity = 0.535999\tKL_Divergence = 1.598789\n",
      "Epoch: 37\tFidelity = 0.535697\tKL_Divergence = 1.603526\n",
      "Epoch: 38\tFidelity = 0.533656\tKL_Divergence = 1.637101\n",
      "Epoch: 39\tFidelity = 0.538646\tKL_Divergence = 1.558244\n",
      "Epoch: 40\tFidelity = 0.539112\tKL_Divergence = 1.551391\n",
      "Epoch: 41\tFidelity = 0.536843\tKL_Divergence = 1.585599\n",
      "Epoch: 42\tFidelity = 0.536521\tKL_Divergence = 1.590550\n",
      "Epoch: 43\tFidelity = 0.535673\tKL_Divergence = 1.604009\n",
      "Epoch: 44\tFidelity = 0.537286\tKL_Divergence = 1.578765\n",
      "Epoch: 45\tFidelity = 0.534611\tKL_Divergence = 1.621180\n",
      "Epoch: 46\tFidelity = 0.538073\tKL_Divergence = 1.566837\n",
      "Epoch: 47\tFidelity = 0.537361\tKL_Divergence = 1.577656\n",
      "Epoch: 48\tFidelity = 0.535665\tKL_Divergence = 1.604104\n",
      "Epoch: 49\tFidelity = 0.535671\tKL_Divergence = 1.603896\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:38:03,641] Trial 77 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.534509\tKL_Divergence = 1.622862\n",
      "Total time elapsed during training: 37.230 s\n",
      "Trial 77 pruned. \n",
      "Epoch: 1\tFidelity = 0.539185\tKL_Divergence = 1.550431\n",
      "Epoch: 2\tFidelity = 0.536557\tKL_Divergence = 1.590045\n",
      "Epoch: 3\tFidelity = 0.537442\tKL_Divergence = 1.576414\n",
      "Epoch: 4\tFidelity = 0.535239\tKL_Divergence = 1.610986\n",
      "Epoch: 5\tFidelity = 0.540152\tKL_Divergence = 1.536522\n",
      "Epoch: 6\tFidelity = 0.534557\tKL_Divergence = 1.622119\n",
      "Epoch: 7\tFidelity = 0.540739\tKL_Divergence = 1.528230\n",
      "Epoch: 8\tFidelity = 0.536995\tKL_Divergence = 1.583275\n",
      "Epoch: 9\tFidelity = 0.532354\tKL_Divergence = 1.659573\n",
      "Epoch: 10\tFidelity = 0.538307\tKL_Divergence = 1.563394\n",
      "Epoch: 11\tFidelity = 0.534271\tKL_Divergence = 1.626839\n",
      "Epoch: 12\tFidelity = 0.536667\tKL_Divergence = 1.588341\n",
      "Epoch: 13\tFidelity = 0.537237\tKL_Divergence = 1.579555\n",
      "Epoch: 14\tFidelity = 0.536692\tKL_Divergence = 1.587959\n",
      "Epoch: 15\tFidelity = 0.542547\tKL_Divergence = 1.503393\n",
      "Epoch: 16\tFidelity = 0.536231\tKL_Divergence = 1.595175\n",
      "Epoch: 17\tFidelity = 0.539270\tKL_Divergence = 1.549219\n",
      "Epoch: 18\tFidelity = 0.534681\tKL_Divergence = 1.620072\n",
      "Epoch: 19\tFidelity = 0.538240\tKL_Divergence = 1.564391\n",
      "Epoch: 20\tFidelity = 0.533839\tKL_Divergence = 1.634058\n",
      "Epoch: 21\tFidelity = 0.540214\tKL_Divergence = 1.535646\n",
      "Epoch: 22\tFidelity = 0.535028\tKL_Divergence = 1.614404\n",
      "Epoch: 23\tFidelity = 0.539242\tKL_Divergence = 1.549626\n",
      "Epoch: 24\tFidelity = 0.535790\tKL_Divergence = 1.602147\n",
      "Epoch: 25\tFidelity = 0.534533\tKL_Divergence = 1.622510\n",
      "Epoch: 26\tFidelity = 0.540648\tKL_Divergence = 1.529510\n",
      "Epoch: 27\tFidelity = 0.532903\tKL_Divergence = 1.650003\n",
      "Epoch: 28\tFidelity = 0.542513\tKL_Divergence = 1.503837\n",
      "Epoch: 29\tFidelity = 0.535906\tKL_Divergence = 1.600301\n",
      "Epoch: 30\tFidelity = 0.538177\tKL_Divergence = 1.565335\n",
      "Epoch: 31\tFidelity = 0.534632\tKL_Divergence = 1.620879\n",
      "Epoch: 32\tFidelity = 0.540263\tKL_Divergence = 1.534959\n",
      "Epoch: 33\tFidelity = 0.532060\tKL_Divergence = 1.664772\n",
      "Epoch: 34\tFidelity = 0.543438\tKL_Divergence = 1.491527\n",
      "Epoch: 35\tFidelity = 0.534100\tKL_Divergence = 1.629703\n",
      "Epoch: 36\tFidelity = 0.538821\tKL_Divergence = 1.555788\n",
      "Epoch: 37\tFidelity = 0.537973\tKL_Divergence = 1.568400\n",
      "Epoch: 38\tFidelity = 0.536494\tKL_Divergence = 1.591056\n",
      "Epoch: 39\tFidelity = 0.533686\tKL_Divergence = 1.636647\n",
      "Epoch: 40\tFidelity = 0.536528\tKL_Divergence = 1.590531\n",
      "Epoch: 41\tFidelity = 0.535802\tKL_Divergence = 1.601966\n",
      "Epoch: 42\tFidelity = 0.537566\tKL_Divergence = 1.574537\n",
      "Epoch: 43\tFidelity = 0.536986\tKL_Divergence = 1.583414\n",
      "Epoch: 44\tFidelity = 0.534996\tKL_Divergence = 1.614923\n",
      "Epoch: 45\tFidelity = 0.539123\tKL_Divergence = 1.551368\n",
      "Epoch: 46\tFidelity = 0.535304\tKL_Divergence = 1.609940\n",
      "Epoch: 47\tFidelity = 0.535337\tKL_Divergence = 1.609414\n",
      "Epoch: 48\tFidelity = 0.538190\tKL_Divergence = 1.565139\n",
      "Epoch: 49\tFidelity = 0.536231\tKL_Divergence = 1.595172\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:38:34,507] Trial 78 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.535289\tKL_Divergence = 1.610188\n",
      "Total time elapsed during training: 30.717 s\n",
      "Trial 78 pruned. \n",
      "Epoch: 1\tFidelity = 0.538735\tKL_Divergence = 1.556987\n",
      "Epoch: 2\tFidelity = 0.535169\tKL_Divergence = 1.612131\n",
      "Epoch: 3\tFidelity = 0.535337\tKL_Divergence = 1.609360\n",
      "Epoch: 4\tFidelity = 0.538274\tKL_Divergence = 1.563885\n",
      "Epoch: 5\tFidelity = 0.537545\tKL_Divergence = 1.574839\n",
      "Epoch: 6\tFidelity = 0.530973\tKL_Divergence = 1.684368\n",
      "Epoch: 7\tFidelity = 0.540492\tKL_Divergence = 1.531740\n",
      "Epoch: 8\tFidelity = 0.536639\tKL_Divergence = 1.588626\n",
      "Epoch: 9\tFidelity = 0.534667\tKL_Divergence = 1.620163\n",
      "Epoch: 10\tFidelity = 0.532458\tKL_Divergence = 1.657820\n",
      "Epoch: 11\tFidelity = 0.537758\tKL_Divergence = 1.571515\n",
      "Epoch: 12\tFidelity = 0.535938\tKL_Divergence = 1.599854\n",
      "Epoch: 13\tFidelity = 0.540217\tKL_Divergence = 1.535414\n",
      "Epoch: 14\tFidelity = 0.535243\tKL_Divergence = 1.610914\n",
      "Epoch: 15\tFidelity = 0.535570\tKL_Divergence = 1.605698\n",
      "Epoch: 16\tFidelity = 0.536222\tKL_Divergence = 1.595391\n",
      "Epoch: 17\tFidelity = 0.537186\tKL_Divergence = 1.580347\n",
      "Epoch: 18\tFidelity = 0.536976\tKL_Divergence = 1.583635\n",
      "Epoch: 19\tFidelity = 0.539072\tKL_Divergence = 1.552157\n",
      "Epoch: 20\tFidelity = 0.534813\tKL_Divergence = 1.617982\n",
      "Epoch: 21\tFidelity = 0.532427\tKL_Divergence = 1.658399\n",
      "Epoch: 22\tFidelity = 0.538129\tKL_Divergence = 1.566133\n",
      "Epoch: 23\tFidelity = 0.539950\tKL_Divergence = 1.539493\n",
      "Epoch: 24\tFidelity = 0.536632\tKL_Divergence = 1.588973\n",
      "Epoch: 25\tFidelity = 0.533337\tKL_Divergence = 1.642637\n",
      "Epoch: 26\tFidelity = 0.536161\tKL_Divergence = 1.596364\n",
      "Epoch: 27\tFidelity = 0.532032\tKL_Divergence = 1.665248\n",
      "Epoch: 28\tFidelity = 0.534491\tKL_Divergence = 1.623196\n",
      "Epoch: 29\tFidelity = 0.539230\tKL_Divergence = 1.549873\n",
      "Epoch: 30\tFidelity = 0.534939\tKL_Divergence = 1.615948\n",
      "Epoch: 31\tFidelity = 0.532507\tKL_Divergence = 1.656897\n",
      "Epoch: 32\tFidelity = 0.536139\tKL_Divergence = 1.596683\n",
      "Epoch: 33\tFidelity = 0.533072\tKL_Divergence = 1.647194\n",
      "Epoch: 34\tFidelity = 0.531532\tKL_Divergence = 1.674215\n",
      "Epoch: 35\tFidelity = 0.535675\tKL_Divergence = 1.604002\n",
      "Epoch: 36\tFidelity = 0.537503\tKL_Divergence = 1.575542\n",
      "Epoch: 37\tFidelity = 0.533863\tKL_Divergence = 1.633702\n",
      "Epoch: 38\tFidelity = 0.539161\tKL_Divergence = 1.550704\n",
      "Epoch: 39\tFidelity = 0.535302\tKL_Divergence = 1.609922\n",
      "Epoch: 40\tFidelity = 0.534730\tKL_Divergence = 1.619357\n",
      "Epoch: 41\tFidelity = 0.537148\tKL_Divergence = 1.580996\n",
      "Epoch: 42\tFidelity = 0.532902\tKL_Divergence = 1.650042\n",
      "Epoch: 43\tFidelity = 0.533535\tKL_Divergence = 1.639246\n",
      "Epoch: 44\tFidelity = 0.534440\tKL_Divergence = 1.623873\n",
      "Epoch: 45\tFidelity = 0.535670\tKL_Divergence = 1.604141\n",
      "Epoch: 46\tFidelity = 0.534398\tKL_Divergence = 1.624793\n",
      "Epoch: 47\tFidelity = 0.531737\tKL_Divergence = 1.670608\n",
      "Epoch: 48\tFidelity = 0.533616\tKL_Divergence = 1.637913\n",
      "Epoch: 49\tFidelity = 0.534703\tKL_Divergence = 1.619516\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:39:52,819] Trial 79 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.535011\tKL_Divergence = 1.614683\n",
      "Total time elapsed during training: 78.166 s\n",
      "Trial 79 pruned. \n",
      "Epoch: 1\tFidelity = 0.529648\tKL_Divergence = 1.709206\n",
      "Epoch: 2\tFidelity = 0.537488\tKL_Divergence = 1.575666\n",
      "Epoch: 3\tFidelity = 0.531459\tKL_Divergence = 1.675603\n",
      "Epoch: 4\tFidelity = 0.530046\tKL_Divergence = 1.701675\n",
      "Epoch: 5\tFidelity = 0.533463\tKL_Divergence = 1.640356\n",
      "Epoch: 6\tFidelity = 0.531574\tKL_Divergence = 1.673219\n",
      "Epoch: 7\tFidelity = 0.529964\tKL_Divergence = 1.703179\n",
      "Epoch: 8\tFidelity = 0.538133\tKL_Divergence = 1.565998\n",
      "Epoch: 9\tFidelity = 0.539220\tKL_Divergence = 1.549948\n",
      "Epoch: 10\tFidelity = 0.538996\tKL_Divergence = 1.553306\n",
      "Epoch: 11\tFidelity = 0.533272\tKL_Divergence = 1.643745\n",
      "Epoch: 12\tFidelity = 0.530504\tKL_Divergence = 1.693056\n",
      "Epoch: 13\tFidelity = 0.534691\tKL_Divergence = 1.619855\n",
      "Epoch: 14\tFidelity = 0.532766\tKL_Divergence = 1.652381\n",
      "Epoch: 15\tFidelity = 0.537564\tKL_Divergence = 1.574580\n",
      "Epoch: 16\tFidelity = 0.531948\tKL_Divergence = 1.666772\n",
      "Epoch: 17\tFidelity = 0.533650\tKL_Divergence = 1.637301\n",
      "Epoch: 18\tFidelity = 0.529866\tKL_Divergence = 1.705106\n",
      "Epoch: 19\tFidelity = 0.536608\tKL_Divergence = 1.589375\n",
      "Epoch: 20\tFidelity = 0.539746\tKL_Divergence = 1.542322\n",
      "Epoch: 21\tFidelity = 0.533705\tKL_Divergence = 1.636390\n",
      "Epoch: 22\tFidelity = 0.529843\tKL_Divergence = 1.705526\n",
      "Epoch: 23\tFidelity = 0.529666\tKL_Divergence = 1.708900\n",
      "Epoch: 24\tFidelity = 0.532239\tKL_Divergence = 1.661660\n",
      "Epoch: 25\tFidelity = 0.529280\tKL_Divergence = 1.716118\n",
      "Epoch: 26\tFidelity = 0.536546\tKL_Divergence = 1.590077\n",
      "Epoch: 27\tFidelity = 0.535043\tKL_Divergence = 1.614006\n",
      "Epoch: 28\tFidelity = 0.531858\tKL_Divergence = 1.668456\n",
      "Epoch: 29\tFidelity = 0.534169\tKL_Divergence = 1.628633\n",
      "Epoch: 30\tFidelity = 0.529601\tKL_Divergence = 1.710042\n",
      "Epoch: 31\tFidelity = 0.533892\tKL_Divergence = 1.633284\n",
      "Epoch: 32\tFidelity = 0.535662\tKL_Divergence = 1.604302\n",
      "Epoch: 33\tFidelity = 0.532965\tKL_Divergence = 1.649020\n",
      "Epoch: 34\tFidelity = 0.531349\tKL_Divergence = 1.677612\n",
      "Epoch: 35\tFidelity = 0.532962\tKL_Divergence = 1.649118\n",
      "Epoch: 36\tFidelity = 0.538556\tKL_Divergence = 1.559797\n",
      "Epoch: 37\tFidelity = 0.535589\tKL_Divergence = 1.605486\n",
      "Epoch: 38\tFidelity = 0.535700\tKL_Divergence = 1.603709\n",
      "Epoch: 39\tFidelity = 0.534746\tKL_Divergence = 1.619106\n",
      "Epoch: 40\tFidelity = 0.533606\tKL_Divergence = 1.638105\n",
      "Epoch: 41\tFidelity = 0.535921\tKL_Divergence = 1.600184\n",
      "Epoch: 42\tFidelity = 0.533953\tKL_Divergence = 1.632254\n",
      "Epoch: 43\tFidelity = 0.533034\tKL_Divergence = 1.647684\n",
      "Epoch: 44\tFidelity = 0.530475\tKL_Divergence = 1.693669\n",
      "Epoch: 45\tFidelity = 0.536333\tKL_Divergence = 1.593676\n",
      "Epoch: 46\tFidelity = 0.535490\tKL_Divergence = 1.607044\n",
      "Epoch: 47\tFidelity = 0.530440\tKL_Divergence = 1.694258\n",
      "Epoch: 48\tFidelity = 0.529385\tKL_Divergence = 1.714308\n",
      "Epoch: 49\tFidelity = 0.536088\tKL_Divergence = 1.597525\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:40:31,172] Trial 80 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.533346\tKL_Divergence = 1.642498\n",
      "Total time elapsed during training: 38.202 s\n",
      "Trial 80 pruned. \n",
      "Epoch: 1\tFidelity = 0.533942\tKL_Divergence = 1.632418\n",
      "Epoch: 2\tFidelity = 0.532852\tKL_Divergence = 1.650989\n",
      "Epoch: 3\tFidelity = 0.533862\tKL_Divergence = 1.633765\n",
      "Epoch: 4\tFidelity = 0.536659\tKL_Divergence = 1.588582\n",
      "Epoch: 5\tFidelity = 0.530167\tKL_Divergence = 1.699430\n",
      "Epoch: 6\tFidelity = 0.531371\tKL_Divergence = 1.677226\n",
      "Epoch: 7\tFidelity = 0.534202\tKL_Divergence = 1.628099\n",
      "Epoch: 8\tFidelity = 0.529126\tKL_Divergence = 1.719358\n",
      "Epoch: 9\tFidelity = 0.533498\tKL_Divergence = 1.639931\n",
      "Epoch: 10\tFidelity = 0.532078\tKL_Divergence = 1.664565\n",
      "Epoch: 11\tFidelity = 0.530732\tKL_Divergence = 1.688907\n",
      "Epoch: 12\tFidelity = 0.529605\tKL_Divergence = 1.710092\n",
      "Epoch: 13\tFidelity = 0.533148\tKL_Divergence = 1.645900\n",
      "Epoch: 14\tFidelity = 0.534410\tKL_Divergence = 1.624622\n",
      "Epoch: 15\tFidelity = 0.532818\tKL_Divergence = 1.651588\n",
      "Epoch: 16\tFidelity = 0.534528\tKL_Divergence = 1.622695\n",
      "Epoch: 17\tFidelity = 0.535875\tKL_Divergence = 1.600906\n",
      "Epoch: 18\tFidelity = 0.534132\tKL_Divergence = 1.629274\n",
      "Epoch: 19\tFidelity = 0.535163\tKL_Divergence = 1.612338\n",
      "Epoch: 20\tFidelity = 0.533479\tKL_Divergence = 1.640248\n",
      "Epoch: 21\tFidelity = 0.534805\tKL_Divergence = 1.618157\n",
      "Epoch: 22\tFidelity = 0.535478\tKL_Divergence = 1.607251\n",
      "Epoch: 23\tFidelity = 0.532899\tKL_Divergence = 1.650204\n",
      "Epoch: 24\tFidelity = 0.533688\tKL_Divergence = 1.636722\n",
      "Epoch: 25\tFidelity = 0.532231\tKL_Divergence = 1.661860\n",
      "Epoch: 26\tFidelity = 0.537407\tKL_Divergence = 1.577070\n",
      "Epoch: 27\tFidelity = 0.534003\tKL_Divergence = 1.631423\n",
      "Epoch: 28\tFidelity = 0.532174\tKL_Divergence = 1.662871\n",
      "Epoch: 29\tFidelity = 0.530321\tKL_Divergence = 1.696567\n",
      "Epoch: 30\tFidelity = 0.532576\tKL_Divergence = 1.655825\n",
      "Epoch: 31\tFidelity = 0.531533\tKL_Divergence = 1.674308\n",
      "Epoch: 32\tFidelity = 0.532382\tKL_Divergence = 1.659210\n",
      "Epoch: 33\tFidelity = 0.532347\tKL_Divergence = 1.659826\n",
      "Epoch: 34\tFidelity = 0.530482\tKL_Divergence = 1.693559\n",
      "Epoch: 35\tFidelity = 0.531314\tKL_Divergence = 1.678267\n",
      "Epoch: 36\tFidelity = 0.530174\tKL_Divergence = 1.699317\n",
      "Epoch: 37\tFidelity = 0.534093\tKL_Divergence = 1.629927\n",
      "Epoch: 38\tFidelity = 0.532137\tKL_Divergence = 1.663512\n",
      "Epoch: 39\tFidelity = 0.536335\tKL_Divergence = 1.593644\n",
      "Epoch: 40\tFidelity = 0.532053\tKL_Divergence = 1.665004\n",
      "Epoch: 41\tFidelity = 0.534529\tKL_Divergence = 1.622702\n",
      "Epoch: 42\tFidelity = 0.528334\tKL_Divergence = 1.734987\n",
      "Epoch: 43\tFidelity = 0.532066\tKL_Divergence = 1.664779\n",
      "Epoch: 44\tFidelity = 0.532552\tKL_Divergence = 1.656224\n",
      "Epoch: 45\tFidelity = 0.533132\tKL_Divergence = 1.646201\n",
      "Epoch: 46\tFidelity = 0.537606\tKL_Divergence = 1.574015\n",
      "Epoch: 47\tFidelity = 0.532412\tKL_Divergence = 1.658689\n",
      "Epoch: 48\tFidelity = 0.535817\tKL_Divergence = 1.601825\n",
      "Epoch: 49\tFidelity = 0.532868\tKL_Divergence = 1.650755\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:41:10,449] Trial 81 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.530978\tKL_Divergence = 1.684384\n",
      "Total time elapsed during training: 39.130 s\n",
      "Trial 81 pruned. \n",
      "Epoch: 1\tFidelity = 0.532548\tKL_Divergence = 1.656298\n",
      "Epoch: 2\tFidelity = 0.533339\tKL_Divergence = 1.642630\n",
      "Epoch: 3\tFidelity = 0.534576\tKL_Divergence = 1.621913\n",
      "Epoch: 4\tFidelity = 0.531899\tKL_Divergence = 1.667743\n",
      "Epoch: 5\tFidelity = 0.531250\tKL_Divergence = 1.679421\n",
      "Epoch: 6\tFidelity = 0.529710\tKL_Divergence = 1.708112\n",
      "Epoch: 7\tFidelity = 0.529879\tKL_Divergence = 1.704870\n",
      "Epoch: 8\tFidelity = 0.530692\tKL_Divergence = 1.689665\n",
      "Epoch: 9\tFidelity = 0.534443\tKL_Divergence = 1.624112\n",
      "Epoch: 10\tFidelity = 0.532596\tKL_Divergence = 1.655473\n",
      "Epoch: 11\tFidelity = 0.532187\tKL_Divergence = 1.662663\n",
      "Epoch: 12\tFidelity = 0.528263\tKL_Divergence = 1.736441\n",
      "Epoch: 13\tFidelity = 0.535492\tKL_Divergence = 1.607049\n",
      "Epoch: 14\tFidelity = 0.533552\tKL_Divergence = 1.639053\n",
      "Epoch: 15\tFidelity = 0.534978\tKL_Divergence = 1.615351\n",
      "Epoch: 16\tFidelity = 0.538338\tKL_Divergence = 1.563045\n",
      "Epoch: 17\tFidelity = 0.531260\tKL_Divergence = 1.679265\n",
      "Epoch: 18\tFidelity = 0.527519\tKL_Divergence = 1.751541\n",
      "Epoch: 19\tFidelity = 0.535384\tKL_Divergence = 1.608773\n",
      "Epoch: 20\tFidelity = 0.530712\tKL_Divergence = 1.689307\n",
      "Epoch: 21\tFidelity = 0.532045\tKL_Divergence = 1.665167\n",
      "Epoch: 22\tFidelity = 0.530465\tKL_Divergence = 1.693842\n",
      "Epoch: 23\tFidelity = 0.533228\tKL_Divergence = 1.644453\n",
      "Epoch: 24\tFidelity = 0.532554\tKL_Divergence = 1.656067\n",
      "Epoch: 25\tFidelity = 0.533706\tKL_Divergence = 1.636404\n",
      "Epoch: 26\tFidelity = 0.532038\tKL_Divergence = 1.665283\n",
      "Epoch: 27\tFidelity = 0.530366\tKL_Divergence = 1.695655\n",
      "Epoch: 28\tFidelity = 0.533514\tKL_Divergence = 1.639632\n",
      "Epoch: 29\tFidelity = 0.529040\tKL_Divergence = 1.721024\n",
      "Epoch: 30\tFidelity = 0.535115\tKL_Divergence = 1.613058\n",
      "Epoch: 31\tFidelity = 0.531267\tKL_Divergence = 1.679088\n",
      "Epoch: 32\tFidelity = 0.527846\tKL_Divergence = 1.744808\n",
      "Epoch: 33\tFidelity = 0.530758\tKL_Divergence = 1.688370\n",
      "Epoch: 34\tFidelity = 0.532933\tKL_Divergence = 1.649475\n",
      "Epoch: 35\tFidelity = 0.532884\tKL_Divergence = 1.650409\n",
      "Epoch: 36\tFidelity = 0.533655\tKL_Divergence = 1.637279\n",
      "Epoch: 37\tFidelity = 0.535436\tKL_Divergence = 1.607913\n",
      "Epoch: 38\tFidelity = 0.531322\tKL_Divergence = 1.678131\n",
      "Epoch: 39\tFidelity = 0.529019\tKL_Divergence = 1.721488\n",
      "Epoch: 40\tFidelity = 0.531794\tKL_Divergence = 1.669638\n",
      "Epoch: 41\tFidelity = 0.532019\tKL_Divergence = 1.665630\n",
      "Epoch: 42\tFidelity = 0.530929\tKL_Divergence = 1.685308\n",
      "Epoch: 43\tFidelity = 0.529455\tKL_Divergence = 1.713012\n",
      "Epoch: 44\tFidelity = 0.532473\tKL_Divergence = 1.657637\n",
      "Epoch: 45\tFidelity = 0.534536\tKL_Divergence = 1.622597\n",
      "Epoch: 46\tFidelity = 0.532538\tKL_Divergence = 1.656505\n",
      "Epoch: 47\tFidelity = 0.528740\tKL_Divergence = 1.726974\n",
      "Epoch: 48\tFidelity = 0.528368\tKL_Divergence = 1.734312\n",
      "Epoch: 49\tFidelity = 0.532753\tKL_Divergence = 1.652754\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:41:49,728] Trial 82 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.531524\tKL_Divergence = 1.674489\n",
      "Total time elapsed during training: 39.130 s\n",
      "Trial 82 pruned. \n",
      "Epoch: 1\tFidelity = 0.531037\tKL_Divergence = 1.683356\n",
      "Epoch: 2\tFidelity = 0.528477\tKL_Divergence = 1.732182\n",
      "Epoch: 3\tFidelity = 0.529823\tKL_Divergence = 1.706014\n",
      "Epoch: 4\tFidelity = 0.534169\tKL_Divergence = 1.628701\n",
      "Epoch: 5\tFidelity = 0.532483\tKL_Divergence = 1.657483\n",
      "Epoch: 6\tFidelity = 0.530630\tKL_Divergence = 1.690848\n",
      "Epoch: 7\tFidelity = 0.531431\tKL_Divergence = 1.676185\n",
      "Epoch: 8\tFidelity = 0.528542\tKL_Divergence = 1.730859\n",
      "Epoch: 9\tFidelity = 0.530195\tKL_Divergence = 1.698945\n",
      "Epoch: 10\tFidelity = 0.531717\tKL_Divergence = 1.671024\n",
      "Epoch: 11\tFidelity = 0.533358\tKL_Divergence = 1.642332\n",
      "Epoch: 12\tFidelity = 0.530997\tKL_Divergence = 1.684041\n",
      "Epoch: 13\tFidelity = 0.533179\tKL_Divergence = 1.645393\n",
      "Epoch: 14\tFidelity = 0.531975\tKL_Divergence = 1.666414\n",
      "Epoch: 15\tFidelity = 0.533517\tKL_Divergence = 1.639646\n",
      "Epoch: 16\tFidelity = 0.533997\tKL_Divergence = 1.631551\n",
      "Epoch: 17\tFidelity = 0.532403\tKL_Divergence = 1.658830\n",
      "Epoch: 18\tFidelity = 0.536434\tKL_Divergence = 1.592118\n",
      "Epoch: 19\tFidelity = 0.532729\tKL_Divergence = 1.653198\n",
      "Epoch: 20\tFidelity = 0.528563\tKL_Divergence = 1.730485\n",
      "Epoch: 21\tFidelity = 0.529969\tKL_Divergence = 1.703239\n",
      "Epoch: 22\tFidelity = 0.534009\tKL_Divergence = 1.631383\n",
      "Epoch: 23\tFidelity = 0.531119\tKL_Divergence = 1.681890\n",
      "Epoch: 24\tFidelity = 0.531056\tKL_Divergence = 1.683020\n",
      "Epoch: 25\tFidelity = 0.528912\tKL_Divergence = 1.723631\n",
      "Epoch: 26\tFidelity = 0.527608\tKL_Divergence = 1.749779\n",
      "Epoch: 27\tFidelity = 0.530994\tKL_Divergence = 1.684158\n",
      "Epoch: 28\tFidelity = 0.527125\tKL_Divergence = 1.759738\n",
      "Epoch: 29\tFidelity = 0.531881\tKL_Divergence = 1.668129\n",
      "Epoch: 30\tFidelity = 0.533485\tKL_Divergence = 1.640224\n",
      "Epoch: 31\tFidelity = 0.533710\tKL_Divergence = 1.636400\n",
      "Epoch: 32\tFidelity = 0.531024\tKL_Divergence = 1.683609\n",
      "Epoch: 33\tFidelity = 0.531120\tKL_Divergence = 1.681855\n",
      "Epoch: 34\tFidelity = 0.531327\tKL_Divergence = 1.678078\n",
      "Epoch: 35\tFidelity = 0.533155\tKL_Divergence = 1.645839\n",
      "Epoch: 36\tFidelity = 0.530287\tKL_Divergence = 1.697242\n",
      "Epoch: 37\tFidelity = 0.528083\tKL_Divergence = 1.740032\n",
      "Epoch: 38\tFidelity = 0.528303\tKL_Divergence = 1.735675\n",
      "Epoch: 39\tFidelity = 0.533105\tKL_Divergence = 1.646644\n",
      "Epoch: 40\tFidelity = 0.530898\tKL_Divergence = 1.685850\n",
      "Epoch: 41\tFidelity = 0.527398\tKL_Divergence = 1.754048\n",
      "Epoch: 42\tFidelity = 0.532751\tKL_Divergence = 1.652799\n",
      "Epoch: 43\tFidelity = 0.532452\tKL_Divergence = 1.658021\n",
      "Epoch: 44\tFidelity = 0.528302\tKL_Divergence = 1.735677\n",
      "Epoch: 45\tFidelity = 0.528959\tKL_Divergence = 1.722647\n",
      "Epoch: 46\tFidelity = 0.530821\tKL_Divergence = 1.687318\n",
      "Epoch: 47\tFidelity = 0.530560\tKL_Divergence = 1.692132\n",
      "Epoch: 48\tFidelity = 0.529062\tKL_Divergence = 1.720659\n",
      "Epoch: 49\tFidelity = 0.531547\tKL_Divergence = 1.674100\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:42:29,001] Trial 83 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.533342\tKL_Divergence = 1.642637\n",
      "Total time elapsed during training: 39.128 s\n",
      "Trial 83 pruned. \n",
      "Epoch: 1\tFidelity = 0.530674\tKL_Divergence = 1.690013\n",
      "Epoch: 2\tFidelity = 0.534994\tKL_Divergence = 1.615117\n",
      "Epoch: 3\tFidelity = 0.532710\tKL_Divergence = 1.653517\n",
      "Epoch: 4\tFidelity = 0.532871\tKL_Divergence = 1.650724\n",
      "Epoch: 5\tFidelity = 0.528700\tKL_Divergence = 1.727768\n",
      "Epoch: 6\tFidelity = 0.533010\tKL_Divergence = 1.648345\n",
      "Epoch: 7\tFidelity = 0.528758\tKL_Divergence = 1.726624\n",
      "Epoch: 8\tFidelity = 0.534920\tKL_Divergence = 1.616322\n",
      "Epoch: 9\tFidelity = 0.530276\tKL_Divergence = 1.697457\n",
      "Epoch: 10\tFidelity = 0.530684\tKL_Divergence = 1.689860\n",
      "Epoch: 11\tFidelity = 0.531356\tKL_Divergence = 1.677554\n",
      "Epoch: 12\tFidelity = 0.533367\tKL_Divergence = 1.642225\n",
      "Epoch: 13\tFidelity = 0.529833\tKL_Divergence = 1.705814\n",
      "Epoch: 14\tFidelity = 0.528375\tKL_Divergence = 1.734232\n",
      "Epoch: 15\tFidelity = 0.528809\tKL_Divergence = 1.725621\n",
      "Epoch: 16\tFidelity = 0.528504\tKL_Divergence = 1.731654\n",
      "Epoch: 17\tFidelity = 0.533261\tKL_Divergence = 1.644034\n",
      "Epoch: 18\tFidelity = 0.530327\tKL_Divergence = 1.696508\n",
      "Epoch: 19\tFidelity = 0.533727\tKL_Divergence = 1.636134\n",
      "Epoch: 20\tFidelity = 0.530394\tKL_Divergence = 1.695256\n",
      "Epoch: 21\tFidelity = 0.529563\tKL_Divergence = 1.710984\n",
      "Epoch: 22\tFidelity = 0.530171\tKL_Divergence = 1.699435\n",
      "Epoch: 23\tFidelity = 0.530072\tKL_Divergence = 1.701309\n",
      "Epoch: 24\tFidelity = 0.529189\tKL_Divergence = 1.718209\n",
      "Epoch: 25\tFidelity = 0.526750\tKL_Divergence = 1.767662\n",
      "Epoch: 26\tFidelity = 0.527969\tKL_Divergence = 1.742416\n",
      "Epoch: 27\tFidelity = 0.530981\tKL_Divergence = 1.684418\n",
      "Epoch: 28\tFidelity = 0.529002\tKL_Divergence = 1.721863\n",
      "Epoch: 29\tFidelity = 0.531064\tKL_Divergence = 1.682878\n",
      "Epoch: 30\tFidelity = 0.530239\tKL_Divergence = 1.698154\n",
      "Epoch: 31\tFidelity = 0.531148\tKL_Divergence = 1.681348\n",
      "Epoch: 32\tFidelity = 0.530610\tKL_Divergence = 1.691236\n",
      "Epoch: 33\tFidelity = 0.531986\tKL_Divergence = 1.666259\n",
      "Epoch: 34\tFidelity = 0.529207\tKL_Divergence = 1.717861\n",
      "Epoch: 35\tFidelity = 0.528992\tKL_Divergence = 1.722041\n",
      "Epoch: 36\tFidelity = 0.529628\tKL_Divergence = 1.709751\n",
      "Epoch: 37\tFidelity = 0.528708\tKL_Divergence = 1.727640\n",
      "Epoch: 38\tFidelity = 0.530928\tKL_Divergence = 1.685364\n",
      "Epoch: 39\tFidelity = 0.528282\tKL_Divergence = 1.736104\n",
      "Epoch: 40\tFidelity = 0.531942\tKL_Divergence = 1.667039\n",
      "Epoch: 41\tFidelity = 0.528157\tKL_Divergence = 1.738610\n",
      "Epoch: 42\tFidelity = 0.532525\tKL_Divergence = 1.656758\n",
      "Epoch: 43\tFidelity = 0.531395\tKL_Divergence = 1.676846\n",
      "Epoch: 44\tFidelity = 0.530864\tKL_Divergence = 1.686533\n",
      "Epoch: 45\tFidelity = 0.532204\tKL_Divergence = 1.662402\n",
      "Epoch: 46\tFidelity = 0.529905\tKL_Divergence = 1.704455\n",
      "Epoch: 47\tFidelity = 0.530874\tKL_Divergence = 1.686351\n",
      "Epoch: 48\tFidelity = 0.529146\tKL_Divergence = 1.719037\n",
      "Epoch: 49\tFidelity = 0.531053\tKL_Divergence = 1.683080\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:43:08,445] Trial 84 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.532219\tKL_Divergence = 1.662143\n",
      "Total time elapsed during training: 39.284 s\n",
      "Trial 84 pruned. \n",
      "Epoch: 1\tFidelity = 0.529525\tKL_Divergence = 1.711724\n",
      "Epoch: 2\tFidelity = 0.533010\tKL_Divergence = 1.648356\n",
      "Epoch: 3\tFidelity = 0.530556\tKL_Divergence = 1.692238\n",
      "Epoch: 4\tFidelity = 0.530927\tKL_Divergence = 1.685385\n",
      "Epoch: 5\tFidelity = 0.530935\tKL_Divergence = 1.685234\n",
      "Epoch: 6\tFidelity = 0.532044\tKL_Divergence = 1.665226\n",
      "Epoch: 7\tFidelity = 0.528642\tKL_Divergence = 1.728920\n",
      "Epoch: 8\tFidelity = 0.532827\tKL_Divergence = 1.651501\n",
      "Epoch: 9\tFidelity = 0.531103\tKL_Divergence = 1.682158\n",
      "Epoch: 10\tFidelity = 0.529457\tKL_Divergence = 1.713023\n",
      "Epoch: 11\tFidelity = 0.527839\tKL_Divergence = 1.745044\n",
      "Epoch: 12\tFidelity = 0.529971\tKL_Divergence = 1.703204\n",
      "Epoch: 13\tFidelity = 0.534915\tKL_Divergence = 1.616404\n",
      "Epoch: 14\tFidelity = 0.530426\tKL_Divergence = 1.694652\n",
      "Epoch: 15\tFidelity = 0.529918\tKL_Divergence = 1.704188\n",
      "Epoch: 16\tFidelity = 0.530389\tKL_Divergence = 1.695320\n",
      "Epoch: 17\tFidelity = 0.530249\tKL_Divergence = 1.697948\n",
      "Epoch: 18\tFidelity = 0.532148\tKL_Divergence = 1.663374\n",
      "Epoch: 19\tFidelity = 0.531030\tKL_Divergence = 1.683476\n",
      "Epoch: 20\tFidelity = 0.529744\tKL_Divergence = 1.707500\n",
      "Epoch: 21\tFidelity = 0.532385\tKL_Divergence = 1.659192\n",
      "Epoch: 22\tFidelity = 0.527976\tKL_Divergence = 1.742242\n",
      "Epoch: 23\tFidelity = 0.528399\tKL_Divergence = 1.733744\n",
      "Epoch: 24\tFidelity = 0.528857\tKL_Divergence = 1.724676\n",
      "Epoch: 25\tFidelity = 0.530130\tKL_Divergence = 1.700187\n",
      "Epoch: 26\tFidelity = 0.528924\tKL_Divergence = 1.723355\n",
      "Epoch: 27\tFidelity = 0.528474\tKL_Divergence = 1.732254\n",
      "Epoch: 28\tFidelity = 0.532746\tKL_Divergence = 1.652899\n",
      "Epoch: 29\tFidelity = 0.532223\tKL_Divergence = 1.662057\n",
      "Epoch: 30\tFidelity = 0.529481\tKL_Divergence = 1.712543\n",
      "Epoch: 31\tFidelity = 0.529940\tKL_Divergence = 1.703778\n",
      "Epoch: 32\tFidelity = 0.528255\tKL_Divergence = 1.736627\n",
      "Epoch: 33\tFidelity = 0.527736\tKL_Divergence = 1.747136\n",
      "Epoch: 34\tFidelity = 0.530161\tKL_Divergence = 1.699619\n",
      "Epoch: 35\tFidelity = 0.527987\tKL_Divergence = 1.742034\n",
      "Epoch: 36\tFidelity = 0.531935\tKL_Divergence = 1.667151\n",
      "Epoch: 37\tFidelity = 0.533686\tKL_Divergence = 1.636809\n",
      "Epoch: 38\tFidelity = 0.528745\tKL_Divergence = 1.726875\n",
      "Epoch: 39\tFidelity = 0.531497\tKL_Divergence = 1.675007\n",
      "Epoch: 40\tFidelity = 0.531398\tKL_Divergence = 1.676795\n",
      "Epoch: 41\tFidelity = 0.530795\tKL_Divergence = 1.687815\n",
      "Epoch: 42\tFidelity = 0.534004\tKL_Divergence = 1.631465\n",
      "Epoch: 43\tFidelity = 0.530492\tKL_Divergence = 1.693432\n",
      "Epoch: 44\tFidelity = 0.532860\tKL_Divergence = 1.650931\n",
      "Epoch: 45\tFidelity = 0.530726\tKL_Divergence = 1.689081\n",
      "Epoch: 46\tFidelity = 0.529148\tKL_Divergence = 1.719000\n",
      "Epoch: 47\tFidelity = 0.532696\tKL_Divergence = 1.653784\n",
      "Epoch: 48\tFidelity = 0.527266\tKL_Divergence = 1.756818\n",
      "Epoch: 49\tFidelity = 0.531138\tKL_Divergence = 1.681514\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:43:40,728] Trial 85 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.530270\tKL_Divergence = 1.697578\n",
      "Total time elapsed during training: 32.137 s\n",
      "Trial 85 pruned. \n",
      "Epoch: 1\tFidelity = 0.534304\tKL_Divergence = 1.626360\n",
      "Epoch: 2\tFidelity = 0.529267\tKL_Divergence = 1.716610\n",
      "Epoch: 3\tFidelity = 0.530464\tKL_Divergence = 1.693816\n",
      "Epoch: 4\tFidelity = 0.527056\tKL_Divergence = 1.761202\n",
      "Epoch: 5\tFidelity = 0.529093\tKL_Divergence = 1.719877\n",
      "Epoch: 6\tFidelity = 0.529039\tKL_Divergence = 1.721019\n",
      "Epoch: 7\tFidelity = 0.528974\tKL_Divergence = 1.722396\n",
      "Epoch: 8\tFidelity = 0.527717\tKL_Divergence = 1.747536\n",
      "Epoch: 9\tFidelity = 0.527741\tKL_Divergence = 1.746978\n",
      "Epoch: 10\tFidelity = 0.531846\tKL_Divergence = 1.668694\n",
      "Epoch: 11\tFidelity = 0.528823\tKL_Divergence = 1.725016\n",
      "Epoch: 12\tFidelity = 0.529308\tKL_Divergence = 1.715897\n",
      "Epoch: 13\tFidelity = 0.531672\tKL_Divergence = 1.671774\n",
      "Epoch: 14\tFidelity = 0.528145\tKL_Divergence = 1.738848\n",
      "Epoch: 15\tFidelity = 0.529831\tKL_Divergence = 1.705659\n",
      "Epoch: 16\tFidelity = 0.535808\tKL_Divergence = 1.601603\n",
      "Epoch: 17\tFidelity = 0.530018\tKL_Divergence = 1.702315\n",
      "Epoch: 18\tFidelity = 0.528255\tKL_Divergence = 1.736640\n",
      "Epoch: 19\tFidelity = 0.530605\tKL_Divergence = 1.691326\n",
      "Epoch: 20\tFidelity = 0.535631\tKL_Divergence = 1.604869\n",
      "Epoch: 21\tFidelity = 0.529755\tKL_Divergence = 1.707304\n",
      "Epoch: 22\tFidelity = 0.534143\tKL_Divergence = 1.629173\n",
      "Epoch: 23\tFidelity = 0.530542\tKL_Divergence = 1.692518\n",
      "Epoch: 24\tFidelity = 0.527712\tKL_Divergence = 1.747674\n",
      "Epoch: 25\tFidelity = 0.528883\tKL_Divergence = 1.724199\n",
      "Epoch: 26\tFidelity = 0.529331\tKL_Divergence = 1.715278\n",
      "Epoch: 27\tFidelity = 0.535262\tKL_Divergence = 1.610749\n",
      "Epoch: 28\tFidelity = 0.529066\tKL_Divergence = 1.720553\n",
      "Epoch: 29\tFidelity = 0.532584\tKL_Divergence = 1.655768\n",
      "Epoch: 30\tFidelity = 0.530492\tKL_Divergence = 1.693385\n",
      "Epoch: 31\tFidelity = 0.528832\tKL_Divergence = 1.725055\n",
      "Epoch: 32\tFidelity = 0.531606\tKL_Divergence = 1.672712\n",
      "Epoch: 33\tFidelity = 0.529442\tKL_Divergence = 1.713095\n",
      "Epoch: 34\tFidelity = 0.530232\tKL_Divergence = 1.698284\n",
      "Epoch: 35\tFidelity = 0.528340\tKL_Divergence = 1.734987\n",
      "Epoch: 36\tFidelity = 0.528905\tKL_Divergence = 1.723755\n",
      "Epoch: 37\tFidelity = 0.530158\tKL_Divergence = 1.699416\n",
      "Epoch: 38\tFidelity = 0.533645\tKL_Divergence = 1.637283\n",
      "Epoch: 39\tFidelity = 0.532890\tKL_Divergence = 1.650182\n",
      "Epoch: 40\tFidelity = 0.533221\tKL_Divergence = 1.644651\n",
      "Epoch: 41\tFidelity = 0.531562\tKL_Divergence = 1.673866\n",
      "Epoch: 42\tFidelity = 0.529342\tKL_Divergence = 1.715296\n",
      "Epoch: 43\tFidelity = 0.534754\tKL_Divergence = 1.619114\n",
      "Epoch: 44\tFidelity = 0.528057\tKL_Divergence = 1.740696\n",
      "Epoch: 45\tFidelity = 0.529017\tKL_Divergence = 1.721570\n",
      "Epoch: 46\tFidelity = 0.530452\tKL_Divergence = 1.694249\n",
      "Epoch: 47\tFidelity = 0.530036\tKL_Divergence = 1.701878\n",
      "Epoch: 48\tFidelity = 0.533820\tKL_Divergence = 1.634574\n",
      "Epoch: 49\tFidelity = 0.529348\tKL_Divergence = 1.715162\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:44:19,496] Trial 86 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.530239\tKL_Divergence = 1.698152\n",
      "Total time elapsed during training: 38.616 s\n",
      "Trial 86 pruned. \n",
      "Epoch: 1\tFidelity = 0.531525\tKL_Divergence = 1.674568\n",
      "Epoch: 2\tFidelity = 0.534918\tKL_Divergence = 1.616407\n",
      "Epoch: 3\tFidelity = 0.530433\tKL_Divergence = 1.694573\n",
      "Epoch: 4\tFidelity = 0.532023\tKL_Divergence = 1.665625\n",
      "Epoch: 5\tFidelity = 0.527349\tKL_Divergence = 1.755161\n",
      "Epoch: 6\tFidelity = 0.530653\tKL_Divergence = 1.690469\n",
      "Epoch: 7\tFidelity = 0.528556\tKL_Divergence = 1.730698\n",
      "Epoch: 8\tFidelity = 0.527307\tKL_Divergence = 1.756020\n",
      "Epoch: 9\tFidelity = 0.528598\tKL_Divergence = 1.729869\n",
      "Epoch: 10\tFidelity = 0.530607\tKL_Divergence = 1.691344\n",
      "Epoch: 11\tFidelity = 0.531023\tKL_Divergence = 1.683686\n",
      "Epoch: 12\tFidelity = 0.528959\tKL_Divergence = 1.722723\n",
      "Epoch: 13\tFidelity = 0.530074\tKL_Divergence = 1.701263\n",
      "Epoch: 14\tFidelity = 0.528105\tKL_Divergence = 1.739535\n",
      "Epoch: 15\tFidelity = 0.531219\tKL_Divergence = 1.680042\n",
      "Epoch: 16\tFidelity = 0.531712\tKL_Divergence = 1.671205\n",
      "Epoch: 17\tFidelity = 0.534269\tKL_Divergence = 1.627067\n",
      "Epoch: 18\tFidelity = 0.529903\tKL_Divergence = 1.704407\n",
      "Epoch: 19\tFidelity = 0.525487\tKL_Divergence = 1.795014\n",
      "Epoch: 20\tFidelity = 0.529584\tKL_Divergence = 1.710516\n",
      "Epoch: 21\tFidelity = 0.531949\tKL_Divergence = 1.666964\n",
      "Epoch: 22\tFidelity = 0.528578\tKL_Divergence = 1.730258\n",
      "Epoch: 23\tFidelity = 0.529095\tKL_Divergence = 1.720087\n",
      "Epoch: 24\tFidelity = 0.531900\tKL_Divergence = 1.667833\n",
      "Epoch: 25\tFidelity = 0.531788\tKL_Divergence = 1.669819\n",
      "Epoch: 26\tFidelity = 0.530598\tKL_Divergence = 1.691494\n",
      "Epoch: 27\tFidelity = 0.531079\tKL_Divergence = 1.682590\n",
      "Epoch: 28\tFidelity = 0.532193\tKL_Divergence = 1.662498\n",
      "Epoch: 29\tFidelity = 0.527529\tKL_Divergence = 1.751359\n",
      "Epoch: 30\tFidelity = 0.529749\tKL_Divergence = 1.707460\n",
      "Epoch: 31\tFidelity = 0.530322\tKL_Divergence = 1.696632\n",
      "Epoch: 32\tFidelity = 0.533788\tKL_Divergence = 1.635073\n",
      "Epoch: 33\tFidelity = 0.527704\tKL_Divergence = 1.747848\n",
      "Epoch: 34\tFidelity = 0.531889\tKL_Divergence = 1.668029\n",
      "Epoch: 35\tFidelity = 0.527455\tKL_Divergence = 1.752952\n",
      "Epoch: 36\tFidelity = 0.530450\tKL_Divergence = 1.694214\n",
      "Epoch: 37\tFidelity = 0.530116\tKL_Divergence = 1.700382\n",
      "Epoch: 38\tFidelity = 0.527936\tKL_Divergence = 1.743002\n",
      "Epoch: 39\tFidelity = 0.527814\tKL_Divergence = 1.745482\n",
      "Epoch: 40\tFidelity = 0.528134\tKL_Divergence = 1.739046\n",
      "Epoch: 41\tFidelity = 0.530586\tKL_Divergence = 1.691680\n",
      "Epoch: 42\tFidelity = 0.531886\tKL_Divergence = 1.667916\n",
      "Epoch: 43\tFidelity = 0.527338\tKL_Divergence = 1.755370\n",
      "Epoch: 44\tFidelity = 0.528200\tKL_Divergence = 1.737686\n",
      "Epoch: 45\tFidelity = 0.529351\tKL_Divergence = 1.715094\n",
      "Epoch: 46\tFidelity = 0.528937\tKL_Divergence = 1.723166\n",
      "Epoch: 47\tFidelity = 0.527769\tKL_Divergence = 1.746476\n",
      "Epoch: 48\tFidelity = 0.530038\tKL_Divergence = 1.701987\n",
      "Epoch: 49\tFidelity = 0.528078\tKL_Divergence = 1.740248\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:45:19,183] Trial 87 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.531473\tKL_Divergence = 1.675453\n",
      "Total time elapsed during training: 59.534 s\n",
      "Trial 87 pruned. \n",
      "Epoch: 1\tFidelity = 0.531917\tKL_Divergence = 1.667520\n",
      "Epoch: 2\tFidelity = 0.526770\tKL_Divergence = 1.767263\n",
      "Epoch: 3\tFidelity = 0.530952\tKL_Divergence = 1.684966\n",
      "Epoch: 4\tFidelity = 0.529993\tKL_Divergence = 1.702828\n",
      "Epoch: 5\tFidelity = 0.528631\tKL_Divergence = 1.729192\n",
      "Epoch: 6\tFidelity = 0.529397\tKL_Divergence = 1.714201\n",
      "Epoch: 7\tFidelity = 0.530226\tKL_Divergence = 1.698435\n",
      "Epoch: 8\tFidelity = 0.529751\tKL_Divergence = 1.707414\n",
      "Epoch: 9\tFidelity = 0.529159\tKL_Divergence = 1.718800\n",
      "Epoch: 10\tFidelity = 0.530571\tKL_Divergence = 1.691990\n",
      "Epoch: 11\tFidelity = 0.527628\tKL_Divergence = 1.749395\n",
      "Epoch: 12\tFidelity = 0.529076\tKL_Divergence = 1.720438\n",
      "Epoch: 13\tFidelity = 0.529481\tKL_Divergence = 1.712588\n",
      "Epoch: 14\tFidelity = 0.525866\tKL_Divergence = 1.786690\n",
      "Epoch: 15\tFidelity = 0.530063\tKL_Divergence = 1.701492\n",
      "Epoch: 16\tFidelity = 0.530029\tKL_Divergence = 1.702134\n",
      "Epoch: 17\tFidelity = 0.529751\tKL_Divergence = 1.707415\n",
      "Epoch: 18\tFidelity = 0.531703\tKL_Divergence = 1.671338\n",
      "Epoch: 19\tFidelity = 0.530821\tKL_Divergence = 1.687360\n",
      "Epoch: 20\tFidelity = 0.529065\tKL_Divergence = 1.720659\n",
      "Epoch: 21\tFidelity = 0.532084\tKL_Divergence = 1.664552\n",
      "Epoch: 22\tFidelity = 0.531791\tKL_Divergence = 1.669775\n",
      "Epoch: 23\tFidelity = 0.530820\tKL_Divergence = 1.687380\n",
      "Epoch: 24\tFidelity = 0.530907\tKL_Divergence = 1.685780\n",
      "Epoch: 25\tFidelity = 0.529687\tKL_Divergence = 1.708655\n",
      "Epoch: 26\tFidelity = 0.531749\tKL_Divergence = 1.670524\n",
      "Epoch: 27\tFidelity = 0.529219\tKL_Divergence = 1.717673\n",
      "Epoch: 28\tFidelity = 0.528440\tKL_Divergence = 1.732993\n",
      "Epoch: 29\tFidelity = 0.531680\tKL_Divergence = 1.671759\n",
      "Epoch: 30\tFidelity = 0.529961\tKL_Divergence = 1.703437\n",
      "Epoch: 31\tFidelity = 0.527607\tKL_Divergence = 1.749833\n",
      "Epoch: 32\tFidelity = 0.530869\tKL_Divergence = 1.686499\n",
      "Epoch: 33\tFidelity = 0.527584\tKL_Divergence = 1.750282\n",
      "Epoch: 34\tFidelity = 0.527213\tKL_Divergence = 1.757971\n",
      "Epoch: 35\tFidelity = 0.526702\tKL_Divergence = 1.768678\n",
      "Epoch: 36\tFidelity = 0.529797\tKL_Divergence = 1.706548\n",
      "Epoch: 37\tFidelity = 0.528353\tKL_Divergence = 1.734707\n",
      "Epoch: 38\tFidelity = 0.529083\tKL_Divergence = 1.720293\n",
      "Epoch: 39\tFidelity = 0.531384\tKL_Divergence = 1.677089\n",
      "Epoch: 40\tFidelity = 0.531286\tKL_Divergence = 1.678870\n",
      "Epoch: 41\tFidelity = 0.527394\tKL_Divergence = 1.754215\n",
      "Epoch: 42\tFidelity = 0.527301\tKL_Divergence = 1.756145\n",
      "Epoch: 43\tFidelity = 0.528530\tKL_Divergence = 1.731182\n",
      "Epoch: 44\tFidelity = 0.527383\tKL_Divergence = 1.754440\n",
      "Epoch: 45\tFidelity = 0.529870\tKL_Divergence = 1.705158\n",
      "Epoch: 46\tFidelity = 0.525681\tKL_Divergence = 1.790767\n",
      "Epoch: 47\tFidelity = 0.529431\tKL_Divergence = 1.713563\n",
      "Epoch: 48\tFidelity = 0.526545\tKL_Divergence = 1.772055\n",
      "Epoch: 49\tFidelity = 0.528722\tKL_Divergence = 1.727397\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:45:58,360] Trial 88 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.528657\tKL_Divergence = 1.728676\n",
      "Total time elapsed during training: 39.019 s\n",
      "Trial 88 pruned. \n",
      "Epoch: 1\tFidelity = 0.525922\tKL_Divergence = 1.785491\n",
      "Epoch: 2\tFidelity = 0.529685\tKL_Divergence = 1.708679\n",
      "Epoch: 3\tFidelity = 0.527905\tKL_Divergence = 1.743747\n",
      "Epoch: 4\tFidelity = 0.530248\tKL_Divergence = 1.698028\n",
      "Epoch: 5\tFidelity = 0.530665\tKL_Divergence = 1.690238\n",
      "Epoch: 6\tFidelity = 0.527613\tKL_Divergence = 1.749702\n",
      "Epoch: 7\tFidelity = 0.528731\tKL_Divergence = 1.727214\n",
      "Epoch: 8\tFidelity = 0.528782\tKL_Divergence = 1.726190\n",
      "Epoch: 9\tFidelity = 0.530232\tKL_Divergence = 1.698313\n",
      "Epoch: 10\tFidelity = 0.529484\tKL_Divergence = 1.712531\n",
      "Epoch: 11\tFidelity = 0.529642\tKL_Divergence = 1.709505\n",
      "Epoch: 12\tFidelity = 0.530055\tKL_Divergence = 1.701651\n",
      "Epoch: 13\tFidelity = 0.527968\tKL_Divergence = 1.742450\n",
      "Epoch: 14\tFidelity = 0.530117\tKL_Divergence = 1.700474\n",
      "Epoch: 15\tFidelity = 0.529821\tKL_Divergence = 1.706076\n",
      "Epoch: 16\tFidelity = 0.528791\tKL_Divergence = 1.726024\n",
      "Epoch: 17\tFidelity = 0.529213\tKL_Divergence = 1.717775\n",
      "Epoch: 18\tFidelity = 0.530428\tKL_Divergence = 1.694649\n",
      "Epoch: 19\tFidelity = 0.527614\tKL_Divergence = 1.749663\n",
      "Epoch: 20\tFidelity = 0.528867\tKL_Divergence = 1.724518\n",
      "Epoch: 21\tFidelity = 0.528372\tKL_Divergence = 1.734335\n",
      "Epoch: 22\tFidelity = 0.528981\tKL_Divergence = 1.722283\n",
      "Epoch: 23\tFidelity = 0.528851\tKL_Divergence = 1.724829\n",
      "Epoch: 24\tFidelity = 0.529091\tKL_Divergence = 1.720133\n",
      "Epoch: 25\tFidelity = 0.529337\tKL_Divergence = 1.715371\n",
      "Epoch: 26\tFidelity = 0.528994\tKL_Divergence = 1.722040\n",
      "Epoch: 27\tFidelity = 0.528899\tKL_Divergence = 1.723882\n",
      "Epoch: 28\tFidelity = 0.529246\tKL_Divergence = 1.717133\n",
      "Epoch: 29\tFidelity = 0.527057\tKL_Divergence = 1.761209\n",
      "Epoch: 30\tFidelity = 0.530237\tKL_Divergence = 1.698223\n",
      "Epoch: 31\tFidelity = 0.526707\tKL_Divergence = 1.768587\n",
      "Epoch: 32\tFidelity = 0.530454\tKL_Divergence = 1.694159\n",
      "Epoch: 33\tFidelity = 0.527367\tKL_Divergence = 1.754754\n",
      "Epoch: 34\tFidelity = 0.529094\tKL_Divergence = 1.720070\n",
      "Epoch: 35\tFidelity = 0.529876\tKL_Divergence = 1.705029\n",
      "Epoch: 36\tFidelity = 0.529154\tKL_Divergence = 1.718905\n",
      "Epoch: 37\tFidelity = 0.529048\tKL_Divergence = 1.720979\n",
      "Epoch: 38\tFidelity = 0.527451\tKL_Divergence = 1.753017\n",
      "Epoch: 39\tFidelity = 0.528918\tKL_Divergence = 1.723510\n",
      "Epoch: 40\tFidelity = 0.529502\tKL_Divergence = 1.712182\n",
      "Epoch: 41\tFidelity = 0.527472\tKL_Divergence = 1.752577\n",
      "Epoch: 42\tFidelity = 0.531799\tKL_Divergence = 1.669609\n",
      "Epoch: 43\tFidelity = 0.528562\tKL_Divergence = 1.730527\n",
      "Epoch: 44\tFidelity = 0.527155\tKL_Divergence = 1.759164\n",
      "Epoch: 45\tFidelity = 0.530105\tKL_Divergence = 1.700702\n",
      "Epoch: 46\tFidelity = 0.528617\tKL_Divergence = 1.729453\n",
      "Epoch: 47\tFidelity = 0.530338\tKL_Divergence = 1.696323\n",
      "Epoch: 48\tFidelity = 0.529621\tKL_Divergence = 1.709881\n",
      "Epoch: 49\tFidelity = 0.529106\tKL_Divergence = 1.719835\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:46:30,772] Trial 89 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.529363\tKL_Divergence = 1.714856\n",
      "Total time elapsed during training: 32.263 s\n",
      "Trial 89 pruned. \n",
      "Epoch: 1\tFidelity = 0.528810\tKL_Divergence = 1.725532\n",
      "Epoch: 2\tFidelity = 0.530146\tKL_Divergence = 1.699848\n",
      "Epoch: 3\tFidelity = 0.528465\tKL_Divergence = 1.732343\n",
      "Epoch: 4\tFidelity = 0.532171\tKL_Divergence = 1.662674\n",
      "Epoch: 5\tFidelity = 0.526740\tKL_Divergence = 1.767057\n",
      "Epoch: 6\tFidelity = 0.526593\tKL_Divergence = 1.770465\n",
      "Epoch: 7\tFidelity = 0.529934\tKL_Divergence = 1.703776\n",
      "Epoch: 8\tFidelity = 0.532835\tKL_Divergence = 1.651282\n",
      "Epoch: 9\tFidelity = 0.530921\tKL_Divergence = 1.685490\n",
      "Epoch: 10\tFidelity = 0.528728\tKL_Divergence = 1.727217\n",
      "Epoch: 11\tFidelity = 0.532510\tKL_Divergence = 1.657012\n",
      "Epoch: 12\tFidelity = 0.529330\tKL_Divergence = 1.715481\n",
      "Epoch: 13\tFidelity = 0.528287\tKL_Divergence = 1.736009\n",
      "Epoch: 14\tFidelity = 0.532118\tKL_Divergence = 1.663880\n",
      "Epoch: 15\tFidelity = 0.535637\tKL_Divergence = 1.604707\n",
      "Epoch: 16\tFidelity = 0.533222\tKL_Divergence = 1.644551\n",
      "Epoch: 17\tFidelity = 0.529907\tKL_Divergence = 1.704349\n",
      "Epoch: 18\tFidelity = 0.528557\tKL_Divergence = 1.730301\n",
      "Epoch: 19\tFidelity = 0.531753\tKL_Divergence = 1.670117\n",
      "Epoch: 20\tFidelity = 0.529424\tKL_Divergence = 1.713642\n",
      "Epoch: 21\tFidelity = 0.530631\tKL_Divergence = 1.690832\n",
      "Epoch: 22\tFidelity = 0.526903\tKL_Divergence = 1.764416\n",
      "Epoch: 23\tFidelity = 0.527909\tKL_Divergence = 1.743631\n",
      "Epoch: 24\tFidelity = 0.530556\tKL_Divergence = 1.692195\n",
      "Epoch: 25\tFidelity = 0.529704\tKL_Divergence = 1.708234\n",
      "Epoch: 26\tFidelity = 0.535257\tKL_Divergence = 1.610758\n",
      "Epoch: 27\tFidelity = 0.533903\tKL_Divergence = 1.633060\n",
      "Epoch: 28\tFidelity = 0.527552\tKL_Divergence = 1.750789\n",
      "Epoch: 29\tFidelity = 0.525846\tKL_Divergence = 1.786998\n",
      "Epoch: 30\tFidelity = 0.528061\tKL_Divergence = 1.740524\n",
      "Epoch: 31\tFidelity = 0.527128\tKL_Divergence = 1.759672\n",
      "Epoch: 32\tFidelity = 0.530137\tKL_Divergence = 1.700049\n",
      "Epoch: 33\tFidelity = 0.530605\tKL_Divergence = 1.691237\n",
      "Epoch: 34\tFidelity = 0.533371\tKL_Divergence = 1.641769\n",
      "Epoch: 35\tFidelity = 0.528563\tKL_Divergence = 1.730186\n",
      "Epoch: 36\tFidelity = 0.527133\tKL_Divergence = 1.759516\n",
      "Epoch: 37\tFidelity = 0.531962\tKL_Divergence = 1.666642\n",
      "Epoch: 38\tFidelity = 0.529748\tKL_Divergence = 1.707427\n",
      "Epoch: 39\tFidelity = 0.531584\tKL_Divergence = 1.673363\n",
      "Epoch: 40\tFidelity = 0.527602\tKL_Divergence = 1.749866\n",
      "Epoch: 41\tFidelity = 0.527843\tKL_Divergence = 1.744786\n",
      "Epoch: 42\tFidelity = 0.531822\tKL_Divergence = 1.669155\n",
      "Epoch: 43\tFidelity = 0.526774\tKL_Divergence = 1.767133\n",
      "Epoch: 44\tFidelity = 0.532158\tKL_Divergence = 1.663188\n",
      "Epoch: 45\tFidelity = 0.527968\tKL_Divergence = 1.742409\n",
      "Epoch: 46\tFidelity = 0.527828\tKL_Divergence = 1.745007\n",
      "Epoch: 47\tFidelity = 0.528200\tKL_Divergence = 1.737701\n",
      "Epoch: 48\tFidelity = 0.527466\tKL_Divergence = 1.752675\n",
      "Epoch: 49\tFidelity = 0.529989\tKL_Divergence = 1.702814\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:47:10,386] Trial 90 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.530146\tKL_Divergence = 1.699853\n",
      "Total time elapsed during training: 39.467 s\n",
      "Trial 90 pruned. \n",
      "Epoch: 1\tFidelity = 0.525964\tKL_Divergence = 1.784315\n",
      "Epoch: 2\tFidelity = 0.532400\tKL_Divergence = 1.658907\n",
      "Epoch: 3\tFidelity = 0.527801\tKL_Divergence = 1.745798\n",
      "Epoch: 4\tFidelity = 0.531410\tKL_Divergence = 1.676546\n",
      "Epoch: 5\tFidelity = 0.527527\tKL_Divergence = 1.751338\n",
      "Epoch: 6\tFidelity = 0.528533\tKL_Divergence = 1.731132\n",
      "Epoch: 7\tFidelity = 0.532242\tKL_Divergence = 1.661754\n",
      "Epoch: 8\tFidelity = 0.527729\tKL_Divergence = 1.747337\n",
      "Epoch: 9\tFidelity = 0.526998\tKL_Divergence = 1.762448\n",
      "Epoch: 10\tFidelity = 0.528217\tKL_Divergence = 1.737471\n",
      "Epoch: 11\tFidelity = 0.529671\tKL_Divergence = 1.708974\n",
      "Epoch: 12\tFidelity = 0.530360\tKL_Divergence = 1.695859\n",
      "Epoch: 13\tFidelity = 0.529528\tKL_Divergence = 1.711720\n",
      "Epoch: 14\tFidelity = 0.529934\tKL_Divergence = 1.703989\n",
      "Epoch: 15\tFidelity = 0.533562\tKL_Divergence = 1.638966\n",
      "Epoch: 16\tFidelity = 0.526642\tKL_Divergence = 1.769521\n",
      "Epoch: 17\tFidelity = 0.527017\tKL_Divergence = 1.762088\n",
      "Epoch: 18\tFidelity = 0.527736\tKL_Divergence = 1.747245\n",
      "Epoch: 19\tFidelity = 0.527539\tKL_Divergence = 1.751285\n",
      "Epoch: 20\tFidelity = 0.526363\tKL_Divergence = 1.775959\n",
      "Epoch: 21\tFidelity = 0.527960\tKL_Divergence = 1.742661\n",
      "Epoch: 22\tFidelity = 0.525614\tKL_Divergence = 1.792247\n",
      "Epoch: 23\tFidelity = 0.526250\tKL_Divergence = 1.778257\n",
      "Epoch: 24\tFidelity = 0.525670\tKL_Divergence = 1.791046\n",
      "Epoch: 25\tFidelity = 0.530143\tKL_Divergence = 1.700019\n",
      "Epoch: 26\tFidelity = 0.525266\tKL_Divergence = 1.800000\n",
      "Epoch: 27\tFidelity = 0.527172\tKL_Divergence = 1.758854\n",
      "Epoch: 28\tFidelity = 0.526968\tKL_Divergence = 1.763082\n",
      "Epoch: 29\tFidelity = 0.531992\tKL_Divergence = 1.666206\n",
      "Epoch: 30\tFidelity = 0.527854\tKL_Divergence = 1.744803\n",
      "Epoch: 31\tFidelity = 0.528370\tKL_Divergence = 1.734423\n",
      "Epoch: 32\tFidelity = 0.532427\tKL_Divergence = 1.658465\n",
      "Epoch: 33\tFidelity = 0.532028\tKL_Divergence = 1.665273\n",
      "Epoch: 34\tFidelity = 0.530662\tKL_Divergence = 1.690298\n",
      "Epoch: 35\tFidelity = 0.530071\tKL_Divergence = 1.701380\n",
      "Epoch: 36\tFidelity = 0.527361\tKL_Divergence = 1.754845\n",
      "Epoch: 37\tFidelity = 0.526023\tKL_Divergence = 1.783314\n",
      "Epoch: 38\tFidelity = 0.529296\tKL_Divergence = 1.715893\n",
      "Epoch: 39\tFidelity = 0.526766\tKL_Divergence = 1.767287\n",
      "Epoch: 40\tFidelity = 0.528145\tKL_Divergence = 1.738944\n",
      "Epoch: 41\tFidelity = 0.528885\tKL_Divergence = 1.724217\n",
      "Epoch: 42\tFidelity = 0.532944\tKL_Divergence = 1.649561\n",
      "Epoch: 43\tFidelity = 0.526278\tKL_Divergence = 1.777787\n",
      "Epoch: 44\tFidelity = 0.525372\tKL_Divergence = 1.797686\n",
      "Epoch: 45\tFidelity = 0.526162\tKL_Divergence = 1.780248\n",
      "Epoch: 46\tFidelity = 0.521663\tKL_Divergence = 1.886837\n",
      "Epoch: 47\tFidelity = 0.527536\tKL_Divergence = 1.751358\n",
      "Epoch: 48\tFidelity = 0.523772\tKL_Divergence = 1.834465\n",
      "Epoch: 49\tFidelity = 0.529672\tKL_Divergence = 1.709000\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:48:31,434] Trial 91 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.521137\tKL_Divergence = 1.900694\n",
      "Total time elapsed during training: 80.901 s\n",
      "Trial 91 pruned. \n",
      "Epoch: 1\tFidelity = 0.526929\tKL_Divergence = 1.763970\n",
      "Epoch: 2\tFidelity = 0.525607\tKL_Divergence = 1.792420\n",
      "Epoch: 3\tFidelity = 0.524897\tKL_Divergence = 1.808104\n",
      "Epoch: 4\tFidelity = 0.523881\tKL_Divergence = 1.831913\n",
      "Epoch: 5\tFidelity = 0.529484\tKL_Divergence = 1.712572\n",
      "Epoch: 6\tFidelity = 0.528045\tKL_Divergence = 1.740990\n",
      "Epoch: 7\tFidelity = 0.527753\tKL_Divergence = 1.746929\n",
      "Epoch: 8\tFidelity = 0.527367\tKL_Divergence = 1.754887\n",
      "Epoch: 9\tFidelity = 0.523000\tKL_Divergence = 1.852921\n",
      "Epoch: 10\tFidelity = 0.523491\tKL_Divergence = 1.841229\n",
      "Epoch: 11\tFidelity = 0.527738\tKL_Divergence = 1.747261\n",
      "Epoch: 12\tFidelity = 0.526690\tKL_Divergence = 1.769085\n",
      "Epoch: 13\tFidelity = 0.523620\tKL_Divergence = 1.838156\n",
      "Epoch: 14\tFidelity = 0.527511\tKL_Divergence = 1.751897\n",
      "Epoch: 15\tFidelity = 0.523569\tKL_Divergence = 1.839394\n",
      "Epoch: 16\tFidelity = 0.527464\tKL_Divergence = 1.752908\n",
      "Epoch: 17\tFidelity = 0.523378\tKL_Divergence = 1.843686\n",
      "Epoch: 18\tFidelity = 0.525727\tKL_Divergence = 1.789842\n",
      "Epoch: 19\tFidelity = 0.526215\tKL_Divergence = 1.779256\n",
      "Epoch: 20\tFidelity = 0.525496\tKL_Divergence = 1.794950\n",
      "Epoch: 21\tFidelity = 0.528217\tKL_Divergence = 1.737374\n",
      "Epoch: 22\tFidelity = 0.529061\tKL_Divergence = 1.720827\n",
      "Epoch: 23\tFidelity = 0.528589\tKL_Divergence = 1.729934\n",
      "Epoch: 24\tFidelity = 0.527320\tKL_Divergence = 1.755855\n",
      "Epoch: 25\tFidelity = 0.522518\tKL_Divergence = 1.865104\n",
      "Epoch: 26\tFidelity = 0.527231\tKL_Divergence = 1.757617\n",
      "Epoch: 27\tFidelity = 0.526059\tKL_Divergence = 1.782610\n",
      "Epoch: 28\tFidelity = 0.526827\tKL_Divergence = 1.766135\n",
      "Epoch: 29\tFidelity = 0.525068\tKL_Divergence = 1.804510\n",
      "Epoch: 30\tFidelity = 0.525408\tKL_Divergence = 1.796803\n",
      "Epoch: 31\tFidelity = 0.524519\tKL_Divergence = 1.817048\n",
      "Epoch: 32\tFidelity = 0.524299\tKL_Divergence = 1.822142\n",
      "Epoch: 33\tFidelity = 0.529385\tKL_Divergence = 1.714540\n",
      "Epoch: 34\tFidelity = 0.533180\tKL_Divergence = 1.645533\n",
      "Epoch: 35\tFidelity = 0.528071\tKL_Divergence = 1.740227\n",
      "Epoch: 36\tFidelity = 0.523611\tKL_Divergence = 1.838318\n",
      "Epoch: 37\tFidelity = 0.525433\tKL_Divergence = 1.796272\n",
      "Epoch: 38\tFidelity = 0.524632\tKL_Divergence = 1.814399\n",
      "Epoch: 39\tFidelity = 0.524980\tKL_Divergence = 1.806496\n",
      "Epoch: 40\tFidelity = 0.525786\tKL_Divergence = 1.788478\n",
      "Epoch: 41\tFidelity = 0.526285\tKL_Divergence = 1.777468\n",
      "Epoch: 42\tFidelity = 0.525684\tKL_Divergence = 1.790771\n",
      "Epoch: 43\tFidelity = 0.527685\tKL_Divergence = 1.748297\n",
      "Epoch: 44\tFidelity = 0.523602\tKL_Divergence = 1.838542\n",
      "Epoch: 45\tFidelity = 0.524604\tKL_Divergence = 1.814998\n",
      "Epoch: 46\tFidelity = 0.524040\tKL_Divergence = 1.828125\n",
      "Epoch: 47\tFidelity = 0.526247\tKL_Divergence = 1.778445\n",
      "Epoch: 48\tFidelity = 0.528532\tKL_Divergence = 1.731203\n",
      "Epoch: 49\tFidelity = 0.525102\tKL_Divergence = 1.803665\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:49:51,936] Trial 92 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.527954\tKL_Divergence = 1.742678\n",
      "Total time elapsed during training: 80.343 s\n",
      "Trial 92 pruned. \n",
      "Epoch: 1\tFidelity = 0.529467\tKL_Divergence = 1.712904\n",
      "Epoch: 2\tFidelity = 0.524271\tKL_Divergence = 1.822729\n",
      "Epoch: 3\tFidelity = 0.526723\tKL_Divergence = 1.768076\n",
      "Epoch: 4\tFidelity = 0.529243\tKL_Divergence = 1.717075\n",
      "Epoch: 5\tFidelity = 0.528261\tKL_Divergence = 1.736615\n",
      "Epoch: 6\tFidelity = 0.529981\tKL_Divergence = 1.703031\n",
      "Epoch: 7\tFidelity = 0.523429\tKL_Divergence = 1.842605\n",
      "Epoch: 8\tFidelity = 0.529573\tKL_Divergence = 1.710877\n",
      "Epoch: 9\tFidelity = 0.525869\tKL_Divergence = 1.786588\n",
      "Epoch: 10\tFidelity = 0.525656\tKL_Divergence = 1.791327\n",
      "Epoch: 11\tFidelity = 0.524942\tKL_Divergence = 1.807275\n",
      "Epoch: 12\tFidelity = 0.527717\tKL_Divergence = 1.747584\n",
      "Epoch: 13\tFidelity = 0.529455\tKL_Divergence = 1.713105\n",
      "Epoch: 14\tFidelity = 0.526362\tKL_Divergence = 1.775946\n",
      "Epoch: 15\tFidelity = 0.529582\tKL_Divergence = 1.710698\n",
      "Epoch: 16\tFidelity = 0.525136\tKL_Divergence = 1.802923\n",
      "Epoch: 17\tFidelity = 0.524857\tKL_Divergence = 1.809189\n",
      "Epoch: 18\tFidelity = 0.527796\tKL_Divergence = 1.745976\n",
      "Epoch: 19\tFidelity = 0.530429\tKL_Divergence = 1.694649\n",
      "Epoch: 20\tFidelity = 0.528506\tKL_Divergence = 1.731637\n",
      "Epoch: 21\tFidelity = 0.526637\tKL_Divergence = 1.770054\n",
      "Epoch: 22\tFidelity = 0.525734\tKL_Divergence = 1.789639\n",
      "Epoch: 23\tFidelity = 0.525719\tKL_Divergence = 1.789957\n",
      "Epoch: 24\tFidelity = 0.527869\tKL_Divergence = 1.744526\n",
      "Epoch: 25\tFidelity = 0.524184\tKL_Divergence = 1.824729\n",
      "Epoch: 26\tFidelity = 0.522518\tKL_Divergence = 1.865006\n",
      "Epoch: 27\tFidelity = 0.524801\tKL_Divergence = 1.810490\n",
      "Epoch: 28\tFidelity = 0.525126\tKL_Divergence = 1.803007\n",
      "Epoch: 29\tFidelity = 0.525822\tKL_Divergence = 1.787703\n",
      "Epoch: 30\tFidelity = 0.524634\tKL_Divergence = 1.814348\n",
      "Epoch: 31\tFidelity = 0.525662\tKL_Divergence = 1.791243\n",
      "Epoch: 32\tFidelity = 0.528958\tKL_Divergence = 1.722737\n",
      "Epoch: 33\tFidelity = 0.527729\tKL_Divergence = 1.747352\n",
      "Epoch: 34\tFidelity = 0.524429\tKL_Divergence = 1.818997\n",
      "Epoch: 35\tFidelity = 0.521671\tKL_Divergence = 1.886221\n",
      "Epoch: 36\tFidelity = 0.525070\tKL_Divergence = 1.804275\n",
      "Epoch: 37\tFidelity = 0.524175\tKL_Divergence = 1.824958\n",
      "Epoch: 38\tFidelity = 0.523325\tKL_Divergence = 1.845137\n",
      "Epoch: 39\tFidelity = 0.530249\tKL_Divergence = 1.698061\n",
      "Epoch: 40\tFidelity = 0.526072\tKL_Divergence = 1.782146\n",
      "Epoch: 41\tFidelity = 0.526637\tKL_Divergence = 1.770162\n",
      "Epoch: 42\tFidelity = 0.526595\tKL_Divergence = 1.771055\n",
      "Epoch: 43\tFidelity = 0.529351\tKL_Divergence = 1.715189\n",
      "Epoch: 44\tFidelity = 0.525051\tKL_Divergence = 1.804880\n",
      "Epoch: 45\tFidelity = 0.526053\tKL_Divergence = 1.782651\n",
      "Epoch: 46\tFidelity = 0.523942\tKL_Divergence = 1.830496\n",
      "Epoch: 47\tFidelity = 0.525232\tKL_Divergence = 1.800842\n",
      "Epoch: 48\tFidelity = 0.527863\tKL_Divergence = 1.744726\n",
      "Epoch: 49\tFidelity = 0.520438\tKL_Divergence = 1.919617\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:51:12,269] Trial 93 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.528583\tKL_Divergence = 1.730252\n",
      "Total time elapsed during training: 80.185 s\n",
      "Trial 93 pruned. \n",
      "Epoch: 1\tFidelity = 0.526610\tKL_Divergence = 1.770769\n",
      "Epoch: 2\tFidelity = 0.528907\tKL_Divergence = 1.723845\n",
      "Epoch: 3\tFidelity = 0.529360\tKL_Divergence = 1.715050\n",
      "Epoch: 4\tFidelity = 0.524041\tKL_Divergence = 1.828209\n",
      "Epoch: 5\tFidelity = 0.526937\tKL_Divergence = 1.763869\n",
      "Epoch: 6\tFidelity = 0.523308\tKL_Divergence = 1.845634\n",
      "Epoch: 7\tFidelity = 0.527644\tKL_Divergence = 1.749183\n",
      "Epoch: 8\tFidelity = 0.525133\tKL_Divergence = 1.803083\n",
      "Epoch: 9\tFidelity = 0.523223\tKL_Divergence = 1.847699\n",
      "Epoch: 10\tFidelity = 0.524645\tKL_Divergence = 1.814169\n",
      "Epoch: 11\tFidelity = 0.524517\tKL_Divergence = 1.817048\n",
      "Epoch: 12\tFidelity = 0.528516\tKL_Divergence = 1.731491\n",
      "Epoch: 13\tFidelity = 0.524209\tKL_Divergence = 1.824244\n",
      "Epoch: 14\tFidelity = 0.527532\tKL_Divergence = 1.751488\n",
      "Epoch: 15\tFidelity = 0.525172\tKL_Divergence = 1.802234\n",
      "Epoch: 16\tFidelity = 0.526299\tKL_Divergence = 1.777375\n",
      "Epoch: 17\tFidelity = 0.522802\tKL_Divergence = 1.858075\n",
      "Epoch: 18\tFidelity = 0.526706\tKL_Divergence = 1.768764\n",
      "Epoch: 19\tFidelity = 0.526213\tKL_Divergence = 1.779183\n",
      "Epoch: 20\tFidelity = 0.526017\tKL_Divergence = 1.783457\n",
      "Epoch: 21\tFidelity = 0.522891\tKL_Divergence = 1.855846\n",
      "Epoch: 22\tFidelity = 0.524806\tKL_Divergence = 1.810516\n",
      "Epoch: 23\tFidelity = 0.522071\tKL_Divergence = 1.876482\n",
      "Epoch: 24\tFidelity = 0.524684\tKL_Divergence = 1.813210\n",
      "Epoch: 25\tFidelity = 0.525844\tKL_Divergence = 1.787304\n",
      "Epoch: 26\tFidelity = 0.528203\tKL_Divergence = 1.737853\n",
      "Epoch: 27\tFidelity = 0.525649\tKL_Divergence = 1.791609\n",
      "Epoch: 28\tFidelity = 0.526387\tKL_Divergence = 1.775524\n",
      "Epoch: 29\tFidelity = 0.522618\tKL_Divergence = 1.862620\n",
      "Epoch: 30\tFidelity = 0.523138\tKL_Divergence = 1.849810\n",
      "Epoch: 31\tFidelity = 0.524457\tKL_Divergence = 1.818499\n",
      "Epoch: 32\tFidelity = 0.524267\tKL_Divergence = 1.822951\n",
      "Epoch: 33\tFidelity = 0.524048\tKL_Divergence = 1.828054\n",
      "Epoch: 34\tFidelity = 0.524434\tKL_Divergence = 1.819055\n",
      "Epoch: 35\tFidelity = 0.524650\tKL_Divergence = 1.814082\n",
      "Epoch: 36\tFidelity = 0.523692\tKL_Divergence = 1.836475\n",
      "Epoch: 37\tFidelity = 0.528074\tKL_Divergence = 1.740467\n",
      "Epoch: 38\tFidelity = 0.527166\tKL_Divergence = 1.759049\n",
      "Epoch: 39\tFidelity = 0.525977\tKL_Divergence = 1.784442\n",
      "Epoch: 40\tFidelity = 0.521037\tKL_Divergence = 1.903457\n",
      "Epoch: 41\tFidelity = 0.522903\tKL_Divergence = 1.855561\n",
      "Epoch: 42\tFidelity = 0.525238\tKL_Divergence = 1.800560\n",
      "Epoch: 43\tFidelity = 0.525896\tKL_Divergence = 1.786194\n",
      "Epoch: 44\tFidelity = 0.523005\tKL_Divergence = 1.853073\n",
      "Epoch: 45\tFidelity = 0.525894\tKL_Divergence = 1.786242\n",
      "Epoch: 46\tFidelity = 0.528011\tKL_Divergence = 1.741720\n",
      "Epoch: 47\tFidelity = 0.528705\tKL_Divergence = 1.727854\n",
      "Epoch: 48\tFidelity = 0.525513\tKL_Divergence = 1.794653\n",
      "Epoch: 49\tFidelity = 0.524569\tKL_Divergence = 1.815803\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:51:56,720] Trial 94 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.524625\tKL_Divergence = 1.814588\n",
      "Total time elapsed during training: 44.297 s\n",
      "Trial 94 pruned. \n",
      "Epoch: 1\tFidelity = 0.520784\tKL_Divergence = 1.910316\n",
      "Epoch: 2\tFidelity = 0.530575\tKL_Divergence = 1.692045\n",
      "Epoch: 3\tFidelity = 0.528494\tKL_Divergence = 1.732051\n",
      "Epoch: 4\tFidelity = 0.521647\tKL_Divergence = 1.887423\n",
      "Epoch: 5\tFidelity = 0.526241\tKL_Divergence = 1.778713\n",
      "Epoch: 6\tFidelity = 0.524773\tKL_Divergence = 1.811276\n",
      "Epoch: 7\tFidelity = 0.523310\tKL_Divergence = 1.845658\n",
      "Epoch: 8\tFidelity = 0.522501\tKL_Divergence = 1.865588\n",
      "Epoch: 9\tFidelity = 0.523064\tKL_Divergence = 1.851666\n",
      "Epoch: 10\tFidelity = 0.525892\tKL_Divergence = 1.786300\n",
      "Epoch: 11\tFidelity = 0.524342\tKL_Divergence = 1.821210\n",
      "Epoch: 12\tFidelity = 0.523611\tKL_Divergence = 1.838450\n",
      "Epoch: 13\tFidelity = 0.526399\tKL_Divergence = 1.775332\n",
      "Epoch: 14\tFidelity = 0.526286\tKL_Divergence = 1.777770\n",
      "Epoch: 15\tFidelity = 0.520841\tKL_Divergence = 1.908844\n",
      "Epoch: 16\tFidelity = 0.524124\tKL_Divergence = 1.826296\n",
      "Epoch: 17\tFidelity = 0.524960\tKL_Divergence = 1.807036\n",
      "Epoch: 18\tFidelity = 0.523690\tKL_Divergence = 1.836545\n",
      "Epoch: 19\tFidelity = 0.524782\tKL_Divergence = 1.811090\n",
      "Epoch: 20\tFidelity = 0.523936\tKL_Divergence = 1.830728\n",
      "Epoch: 21\tFidelity = 0.527298\tKL_Divergence = 1.756374\n",
      "Epoch: 22\tFidelity = 0.525078\tKL_Divergence = 1.804372\n",
      "Epoch: 23\tFidelity = 0.525122\tKL_Divergence = 1.803401\n",
      "Epoch: 24\tFidelity = 0.525221\tKL_Divergence = 1.801161\n",
      "Epoch: 25\tFidelity = 0.524799\tKL_Divergence = 1.810707\n",
      "Epoch: 26\tFidelity = 0.525026\tKL_Divergence = 1.805564\n",
      "Epoch: 27\tFidelity = 0.522420\tKL_Divergence = 1.867663\n",
      "Epoch: 28\tFidelity = 0.523875\tKL_Divergence = 1.832166\n",
      "Epoch: 29\tFidelity = 0.525007\tKL_Divergence = 1.805987\n",
      "Epoch: 30\tFidelity = 0.525716\tKL_Divergence = 1.790172\n",
      "Epoch: 31\tFidelity = 0.522566\tKL_Divergence = 1.863998\n",
      "Epoch: 32\tFidelity = 0.525653\tKL_Divergence = 1.791541\n",
      "Epoch: 33\tFidelity = 0.525409\tKL_Divergence = 1.796947\n",
      "Epoch: 34\tFidelity = 0.526428\tKL_Divergence = 1.774699\n",
      "Epoch: 35\tFidelity = 0.526282\tKL_Divergence = 1.777838\n",
      "Epoch: 36\tFidelity = 0.522321\tKL_Divergence = 1.870152\n",
      "Epoch: 37\tFidelity = 0.526673\tKL_Divergence = 1.769466\n",
      "Epoch: 38\tFidelity = 0.526862\tKL_Divergence = 1.765462\n",
      "Epoch: 39\tFidelity = 0.526671\tKL_Divergence = 1.769495\n",
      "Epoch: 40\tFidelity = 0.526067\tKL_Divergence = 1.782466\n",
      "Epoch: 41\tFidelity = 0.522960\tKL_Divergence = 1.854218\n",
      "Epoch: 42\tFidelity = 0.524511\tKL_Divergence = 1.817295\n",
      "Epoch: 43\tFidelity = 0.524489\tKL_Divergence = 1.817794\n",
      "Epoch: 44\tFidelity = 0.528134\tKL_Divergence = 1.739274\n",
      "Epoch: 45\tFidelity = 0.522233\tKL_Divergence = 1.872382\n",
      "Epoch: 46\tFidelity = 0.522697\tKL_Divergence = 1.860710\n",
      "Epoch: 47\tFidelity = 0.527669\tKL_Divergence = 1.748720\n",
      "Epoch: 48\tFidelity = 0.525716\tKL_Divergence = 1.790163\n",
      "Epoch: 49\tFidelity = 0.526280\tKL_Divergence = 1.777867\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:52:40,826] Trial 95 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.523046\tKL_Divergence = 1.852108\n",
      "Total time elapsed during training: 43.969 s\n",
      "Trial 95 pruned. \n",
      "Epoch: 1\tFidelity = 0.527120\tKL_Divergence = 1.760066\n",
      "Epoch: 2\tFidelity = 0.527393\tKL_Divergence = 1.754401\n",
      "Epoch: 3\tFidelity = 0.527566\tKL_Divergence = 1.750834\n",
      "Epoch: 4\tFidelity = 0.523252\tKL_Divergence = 1.847072\n",
      "Epoch: 5\tFidelity = 0.523119\tKL_Divergence = 1.850330\n",
      "Epoch: 6\tFidelity = 0.522357\tKL_Divergence = 1.869232\n",
      "Epoch: 7\tFidelity = 0.521808\tKL_Divergence = 1.883259\n",
      "Epoch: 8\tFidelity = 0.522884\tKL_Divergence = 1.856103\n",
      "Epoch: 9\tFidelity = 0.527404\tKL_Divergence = 1.754190\n",
      "Epoch: 10\tFidelity = 0.527259\tKL_Divergence = 1.757191\n",
      "Epoch: 11\tFidelity = 0.523488\tKL_Divergence = 1.841370\n",
      "Epoch: 12\tFidelity = 0.521507\tKL_Divergence = 1.891106\n",
      "Epoch: 13\tFidelity = 0.522817\tKL_Divergence = 1.857753\n",
      "Epoch: 14\tFidelity = 0.519383\tKL_Divergence = 1.949706\n",
      "Epoch: 15\tFidelity = 0.523484\tKL_Divergence = 1.841462\n",
      "Epoch: 16\tFidelity = 0.522992\tKL_Divergence = 1.853452\n",
      "Epoch: 17\tFidelity = 0.525265\tKL_Divergence = 1.800175\n",
      "Epoch: 18\tFidelity = 0.522767\tKL_Divergence = 1.859009\n",
      "Epoch: 19\tFidelity = 0.519945\tKL_Divergence = 1.933602\n",
      "Epoch: 20\tFidelity = 0.524863\tKL_Divergence = 1.809251\n",
      "Epoch: 21\tFidelity = 0.526608\tKL_Divergence = 1.770873\n",
      "Epoch: 22\tFidelity = 0.526057\tKL_Divergence = 1.782710\n",
      "Epoch: 23\tFidelity = 0.527007\tKL_Divergence = 1.762453\n",
      "Epoch: 24\tFidelity = 0.525083\tKL_Divergence = 1.804264\n",
      "Epoch: 25\tFidelity = 0.523000\tKL_Divergence = 1.853254\n",
      "Epoch: 26\tFidelity = 0.525575\tKL_Divergence = 1.793301\n",
      "Epoch: 27\tFidelity = 0.522705\tKL_Divergence = 1.860547\n",
      "Epoch: 28\tFidelity = 0.522856\tKL_Divergence = 1.856718\n",
      "Epoch: 29\tFidelity = 0.523580\tKL_Divergence = 1.839117\n",
      "Epoch: 30\tFidelity = 0.527362\tKL_Divergence = 1.755047\n",
      "Epoch: 31\tFidelity = 0.524326\tKL_Divergence = 1.821603\n",
      "Epoch: 32\tFidelity = 0.524524\tKL_Divergence = 1.817029\n",
      "Epoch: 33\tFidelity = 0.525914\tKL_Divergence = 1.785834\n",
      "Epoch: 34\tFidelity = 0.524255\tKL_Divergence = 1.823265\n",
      "Epoch: 35\tFidelity = 0.522793\tKL_Divergence = 1.858356\n",
      "Epoch: 36\tFidelity = 0.525135\tKL_Divergence = 1.803126\n",
      "Epoch: 37\tFidelity = 0.526194\tKL_Divergence = 1.779777\n",
      "Epoch: 38\tFidelity = 0.524582\tKL_Divergence = 1.815678\n",
      "Epoch: 39\tFidelity = 0.518902\tKL_Divergence = 1.963817\n",
      "Epoch: 40\tFidelity = 0.521669\tKL_Divergence = 1.886904\n",
      "Epoch: 41\tFidelity = 0.521103\tKL_Divergence = 1.901796\n",
      "Epoch: 42\tFidelity = 0.525553\tKL_Divergence = 1.793792\n",
      "Epoch: 43\tFidelity = 0.518685\tKL_Divergence = 1.970328\n",
      "Epoch: 44\tFidelity = 0.522168\tKL_Divergence = 1.874068\n",
      "Epoch: 45\tFidelity = 0.520033\tKL_Divergence = 1.931145\n",
      "Epoch: 46\tFidelity = 0.525650\tKL_Divergence = 1.791664\n",
      "Epoch: 47\tFidelity = 0.523277\tKL_Divergence = 1.846512\n",
      "Epoch: 48\tFidelity = 0.528026\tKL_Divergence = 1.741485\n",
      "Epoch: 49\tFidelity = 0.525596\tKL_Divergence = 1.792799\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:53:18,778] Trial 96 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.522116\tKL_Divergence = 1.875355\n",
      "Total time elapsed during training: 37.811 s\n",
      "Trial 96 pruned. \n",
      "Epoch: 1\tFidelity = 0.521453\tKL_Divergence = 1.892441\n",
      "Epoch: 2\tFidelity = 0.523426\tKL_Divergence = 1.842913\n",
      "Epoch: 3\tFidelity = 0.524200\tKL_Divergence = 1.824531\n",
      "Epoch: 4\tFidelity = 0.523538\tKL_Divergence = 1.840191\n",
      "Epoch: 5\tFidelity = 0.524051\tKL_Divergence = 1.828042\n",
      "Epoch: 6\tFidelity = 0.522527\tKL_Divergence = 1.864975\n",
      "Epoch: 7\tFidelity = 0.524801\tKL_Divergence = 1.810676\n",
      "Epoch: 8\tFidelity = 0.523346\tKL_Divergence = 1.844799\n",
      "Epoch: 9\tFidelity = 0.519567\tKL_Divergence = 1.944404\n",
      "Epoch: 10\tFidelity = 0.522912\tKL_Divergence = 1.855427\n",
      "Epoch: 11\tFidelity = 0.520706\tKL_Divergence = 1.912515\n",
      "Epoch: 12\tFidelity = 0.521671\tKL_Divergence = 1.886834\n",
      "Epoch: 13\tFidelity = 0.521333\tKL_Divergence = 1.895648\n",
      "Epoch: 14\tFidelity = 0.522877\tKL_Divergence = 1.856294\n",
      "Epoch: 15\tFidelity = 0.525993\tKL_Divergence = 1.784129\n",
      "Epoch: 16\tFidelity = 0.524764\tKL_Divergence = 1.811433\n",
      "Epoch: 17\tFidelity = 0.521958\tKL_Divergence = 1.879437\n",
      "Epoch: 18\tFidelity = 0.522439\tKL_Divergence = 1.867179\n",
      "Epoch: 19\tFidelity = 0.524050\tKL_Divergence = 1.828060\n",
      "Epoch: 20\tFidelity = 0.523756\tKL_Divergence = 1.835039\n",
      "Epoch: 21\tFidelity = 0.523880\tKL_Divergence = 1.832095\n",
      "Epoch: 22\tFidelity = 0.523903\tKL_Divergence = 1.831555\n",
      "Epoch: 23\tFidelity = 0.521194\tKL_Divergence = 1.899432\n",
      "Epoch: 24\tFidelity = 0.522962\tKL_Divergence = 1.854221\n",
      "Epoch: 25\tFidelity = 0.523108\tKL_Divergence = 1.850583\n",
      "Epoch: 26\tFidelity = 0.521308\tKL_Divergence = 1.896386\n",
      "Epoch: 27\tFidelity = 0.522062\tKL_Divergence = 1.876756\n",
      "Epoch: 28\tFidelity = 0.521459\tKL_Divergence = 1.892359\n",
      "Epoch: 29\tFidelity = 0.523674\tKL_Divergence = 1.836954\n",
      "Epoch: 30\tFidelity = 0.522976\tKL_Divergence = 1.853887\n",
      "Epoch: 31\tFidelity = 0.524261\tKL_Divergence = 1.823130\n",
      "Epoch: 32\tFidelity = 0.524497\tKL_Divergence = 1.817678\n",
      "Epoch: 33\tFidelity = 0.523243\tKL_Divergence = 1.847364\n",
      "Epoch: 34\tFidelity = 0.524253\tKL_Divergence = 1.823330\n",
      "Epoch: 35\tFidelity = 0.524581\tKL_Divergence = 1.815732\n",
      "Epoch: 36\tFidelity = 0.522383\tKL_Divergence = 1.868625\n",
      "Epoch: 37\tFidelity = 0.522149\tKL_Divergence = 1.874554\n",
      "Epoch: 38\tFidelity = 0.521953\tKL_Divergence = 1.879538\n",
      "Epoch: 39\tFidelity = 0.522592\tKL_Divergence = 1.863300\n",
      "Epoch: 40\tFidelity = 0.521476\tKL_Divergence = 1.891964\n",
      "Epoch: 41\tFidelity = 0.522930\tKL_Divergence = 1.854960\n",
      "Epoch: 42\tFidelity = 0.524723\tKL_Divergence = 1.812448\n",
      "Epoch: 43\tFidelity = 0.521669\tKL_Divergence = 1.886882\n",
      "Epoch: 44\tFidelity = 0.522626\tKL_Divergence = 1.862474\n",
      "Epoch: 45\tFidelity = 0.527174\tKL_Divergence = 1.758915\n",
      "Epoch: 46\tFidelity = 0.522811\tKL_Divergence = 1.857941\n",
      "Epoch: 47\tFidelity = 0.524152\tKL_Divergence = 1.825695\n",
      "Epoch: 48\tFidelity = 0.520989\tKL_Divergence = 1.904930\n",
      "Epoch: 49\tFidelity = 0.522588\tKL_Divergence = 1.863444\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:54:36,533] Trial 97 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.519983\tKL_Divergence = 1.932431\n",
      "Total time elapsed during training: 77.620 s\n",
      "Trial 97 pruned. \n",
      "Epoch: 1\tFidelity = 0.522906\tKL_Divergence = 1.855476\n",
      "Epoch: 2\tFidelity = 0.522981\tKL_Divergence = 1.853692\n",
      "Epoch: 3\tFidelity = 0.521743\tKL_Divergence = 1.884988\n",
      "Epoch: 4\tFidelity = 0.523218\tKL_Divergence = 1.847973\n",
      "Epoch: 5\tFidelity = 0.521725\tKL_Divergence = 1.885483\n",
      "Epoch: 6\tFidelity = 0.521736\tKL_Divergence = 1.885201\n",
      "Epoch: 7\tFidelity = 0.523317\tKL_Divergence = 1.845586\n",
      "Epoch: 8\tFidelity = 0.522590\tKL_Divergence = 1.863478\n",
      "Epoch: 9\tFidelity = 0.521845\tKL_Divergence = 1.882399\n",
      "Epoch: 10\tFidelity = 0.523716\tKL_Divergence = 1.835998\n",
      "Epoch: 11\tFidelity = 0.523075\tKL_Divergence = 1.851470\n",
      "Epoch: 12\tFidelity = 0.521490\tKL_Divergence = 1.891625\n",
      "Epoch: 13\tFidelity = 0.522010\tKL_Divergence = 1.878141\n",
      "Epoch: 14\tFidelity = 0.521199\tKL_Divergence = 1.899332\n",
      "Epoch: 15\tFidelity = 0.523091\tKL_Divergence = 1.851082\n",
      "Epoch: 16\tFidelity = 0.521974\tKL_Divergence = 1.879065\n",
      "Epoch: 17\tFidelity = 0.521158\tKL_Divergence = 1.900397\n",
      "Epoch: 18\tFidelity = 0.523289\tKL_Divergence = 1.846260\n",
      "Epoch: 19\tFidelity = 0.524165\tKL_Divergence = 1.825386\n",
      "Epoch: 20\tFidelity = 0.523064\tKL_Divergence = 1.851733\n",
      "Epoch: 21\tFidelity = 0.522897\tKL_Divergence = 1.855850\n",
      "Epoch: 22\tFidelity = 0.520957\tKL_Divergence = 1.905767\n",
      "Epoch: 23\tFidelity = 0.522844\tKL_Divergence = 1.857149\n",
      "Epoch: 24\tFidelity = 0.520448\tKL_Divergence = 1.919634\n",
      "Epoch: 25\tFidelity = 0.523718\tKL_Divergence = 1.835951\n",
      "Epoch: 26\tFidelity = 0.524095\tKL_Divergence = 1.827054\n",
      "Epoch: 27\tFidelity = 0.521700\tKL_Divergence = 1.886137\n",
      "Epoch: 28\tFidelity = 0.524246\tKL_Divergence = 1.823503\n",
      "Epoch: 29\tFidelity = 0.519995\tKL_Divergence = 1.932283\n",
      "Epoch: 30\tFidelity = 0.524477\tKL_Divergence = 1.818164\n",
      "Epoch: 31\tFidelity = 0.523244\tKL_Divergence = 1.847362\n",
      "Epoch: 32\tFidelity = 0.522319\tKL_Divergence = 1.870262\n",
      "Epoch: 33\tFidelity = 0.524391\tKL_Divergence = 1.820141\n",
      "Epoch: 34\tFidelity = 0.520626\tKL_Divergence = 1.914761\n",
      "Epoch: 35\tFidelity = 0.523337\tKL_Divergence = 1.845103\n",
      "Epoch: 36\tFidelity = 0.520105\tKL_Divergence = 1.929187\n",
      "Epoch: 37\tFidelity = 0.522820\tKL_Divergence = 1.857757\n",
      "Epoch: 38\tFidelity = 0.523527\tKL_Divergence = 1.840525\n",
      "Epoch: 39\tFidelity = 0.523707\tKL_Divergence = 1.836206\n",
      "Epoch: 40\tFidelity = 0.523938\tKL_Divergence = 1.830733\n",
      "Epoch: 41\tFidelity = 0.523352\tKL_Divergence = 1.844729\n",
      "Epoch: 42\tFidelity = 0.525028\tKL_Divergence = 1.805549\n",
      "Epoch: 43\tFidelity = 0.519588\tKL_Divergence = 1.943838\n",
      "Epoch: 44\tFidelity = 0.522475\tKL_Divergence = 1.866311\n",
      "Epoch: 45\tFidelity = 0.521684\tKL_Divergence = 1.886542\n",
      "Epoch: 46\tFidelity = 0.522133\tKL_Divergence = 1.874996\n",
      "Epoch: 47\tFidelity = 0.520259\tKL_Divergence = 1.924868\n",
      "Epoch: 48\tFidelity = 0.521481\tKL_Divergence = 1.891869\n",
      "Epoch: 49\tFidelity = 0.521228\tKL_Divergence = 1.898556\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:55:14,185] Trial 98 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.520723\tKL_Divergence = 1.912111\n",
      "Total time elapsed during training: 37.512 s\n",
      "Trial 98 pruned. \n",
      "Epoch: 1\tFidelity = 0.526139\tKL_Divergence = 1.781002\n",
      "Epoch: 2\tFidelity = 0.526833\tKL_Divergence = 1.766066\n",
      "Epoch: 3\tFidelity = 0.524661\tKL_Divergence = 1.813936\n",
      "Epoch: 4\tFidelity = 0.525225\tKL_Divergence = 1.801160\n",
      "Epoch: 5\tFidelity = 0.520559\tKL_Divergence = 1.916553\n",
      "Epoch: 6\tFidelity = 0.523234\tKL_Divergence = 1.847605\n",
      "Epoch: 7\tFidelity = 0.524501\tKL_Divergence = 1.817623\n",
      "Epoch: 8\tFidelity = 0.523636\tKL_Divergence = 1.837886\n",
      "Epoch: 9\tFidelity = 0.523015\tKL_Divergence = 1.852865\n",
      "Epoch: 10\tFidelity = 0.524456\tKL_Divergence = 1.818630\n",
      "Epoch: 11\tFidelity = 0.528735\tKL_Divergence = 1.727379\n",
      "Epoch: 12\tFidelity = 0.522803\tKL_Divergence = 1.858172\n",
      "Epoch: 13\tFidelity = 0.522307\tKL_Divergence = 1.870586\n",
      "Epoch: 14\tFidelity = 0.521308\tKL_Divergence = 1.896396\n",
      "Epoch: 15\tFidelity = 0.525702\tKL_Divergence = 1.790508\n",
      "Epoch: 16\tFidelity = 0.521676\tKL_Divergence = 1.886765\n",
      "Epoch: 17\tFidelity = 0.520788\tKL_Divergence = 1.910361\n",
      "Epoch: 18\tFidelity = 0.518004\tKL_Divergence = 1.991251\n",
      "Epoch: 19\tFidelity = 0.524676\tKL_Divergence = 1.813586\n",
      "Epoch: 20\tFidelity = 0.521152\tKL_Divergence = 1.900566\n",
      "Epoch: 21\tFidelity = 0.526583\tKL_Divergence = 1.771449\n",
      "Epoch: 22\tFidelity = 0.524171\tKL_Divergence = 1.824980\n",
      "Epoch: 23\tFidelity = 0.520246\tKL_Divergence = 1.925177\n",
      "Epoch: 24\tFidelity = 0.522957\tKL_Divergence = 1.854401\n",
      "Epoch: 25\tFidelity = 0.524413\tKL_Divergence = 1.819609\n",
      "Epoch: 26\tFidelity = 0.521745\tKL_Divergence = 1.884993\n",
      "Epoch: 27\tFidelity = 0.519155\tKL_Divergence = 1.956470\n",
      "Epoch: 28\tFidelity = 0.522828\tKL_Divergence = 1.857561\n",
      "Epoch: 29\tFidelity = 0.523956\tKL_Divergence = 1.830327\n",
      "Epoch: 30\tFidelity = 0.519564\tKL_Divergence = 1.944500\n",
      "Epoch: 31\tFidelity = 0.523170\tKL_Divergence = 1.849100\n",
      "Epoch: 32\tFidelity = 0.524987\tKL_Divergence = 1.806519\n",
      "Epoch: 33\tFidelity = 0.519891\tKL_Divergence = 1.935089\n",
      "Epoch: 34\tFidelity = 0.523990\tKL_Divergence = 1.829468\n",
      "Epoch: 35\tFidelity = 0.525660\tKL_Divergence = 1.791371\n",
      "Epoch: 36\tFidelity = 0.522998\tKL_Divergence = 1.853389\n",
      "Epoch: 37\tFidelity = 0.523294\tKL_Divergence = 1.846159\n",
      "Epoch: 38\tFidelity = 0.522107\tKL_Divergence = 1.875678\n",
      "Epoch: 39\tFidelity = 0.520495\tKL_Divergence = 1.918369\n",
      "Epoch: 40\tFidelity = 0.520973\tKL_Divergence = 1.905381\n",
      "Epoch: 41\tFidelity = 0.525462\tKL_Divergence = 1.795764\n",
      "Epoch: 42\tFidelity = 0.520549\tKL_Divergence = 1.916898\n",
      "Epoch: 43\tFidelity = 0.522588\tKL_Divergence = 1.863530\n",
      "Epoch: 44\tFidelity = 0.523362\tKL_Divergence = 1.844521\n",
      "Epoch: 45\tFidelity = 0.522908\tKL_Divergence = 1.855421\n",
      "Epoch: 46\tFidelity = 0.527462\tKL_Divergence = 1.753033\n",
      "Epoch: 47\tFidelity = 0.521484\tKL_Divergence = 1.891771\n",
      "Epoch: 48\tFidelity = 0.522054\tKL_Divergence = 1.877040\n",
      "Epoch: 49\tFidelity = 0.518318\tKL_Divergence = 1.981561\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:55:51,742] Trial 99 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.521451\tKL_Divergence = 1.892640\n",
      "Total time elapsed during training: 37.413 s\n",
      "Trial 99 pruned. \n",
      "Epoch: 1\tFidelity = 0.520894\tKL_Divergence = 1.907505\n",
      "Epoch: 2\tFidelity = 0.521774\tKL_Divergence = 1.884254\n",
      "Epoch: 3\tFidelity = 0.521485\tKL_Divergence = 1.891790\n",
      "Epoch: 4\tFidelity = 0.521685\tKL_Divergence = 1.886517\n",
      "Epoch: 5\tFidelity = 0.524087\tKL_Divergence = 1.827173\n",
      "Epoch: 6\tFidelity = 0.521506\tKL_Divergence = 1.891224\n",
      "Epoch: 7\tFidelity = 0.520408\tKL_Divergence = 1.920771\n",
      "Epoch: 8\tFidelity = 0.520698\tKL_Divergence = 1.912810\n",
      "Epoch: 9\tFidelity = 0.523840\tKL_Divergence = 1.833079\n",
      "Epoch: 10\tFidelity = 0.522020\tKL_Divergence = 1.877896\n",
      "Epoch: 11\tFidelity = 0.522104\tKL_Divergence = 1.875769\n",
      "Epoch: 12\tFidelity = 0.520926\tKL_Divergence = 1.906642\n",
      "Epoch: 13\tFidelity = 0.521195\tKL_Divergence = 1.899413\n",
      "Epoch: 14\tFidelity = 0.522645\tKL_Divergence = 1.862080\n",
      "Epoch: 15\tFidelity = 0.522370\tKL_Divergence = 1.869012\n",
      "Epoch: 16\tFidelity = 0.520094\tKL_Divergence = 1.929478\n",
      "Epoch: 17\tFidelity = 0.522862\tKL_Divergence = 1.856683\n",
      "Epoch: 18\tFidelity = 0.520514\tKL_Divergence = 1.917802\n",
      "Epoch: 19\tFidelity = 0.523089\tKL_Divergence = 1.851137\n",
      "Epoch: 20\tFidelity = 0.522436\tKL_Divergence = 1.867348\n",
      "Epoch: 21\tFidelity = 0.523099\tKL_Divergence = 1.850911\n",
      "Epoch: 22\tFidelity = 0.524096\tKL_Divergence = 1.827033\n",
      "Epoch: 23\tFidelity = 0.523644\tKL_Divergence = 1.837749\n",
      "Epoch: 24\tFidelity = 0.522219\tKL_Divergence = 1.872798\n",
      "Epoch: 25\tFidelity = 0.522435\tKL_Divergence = 1.867360\n",
      "Epoch: 26\tFidelity = 0.520775\tKL_Divergence = 1.910711\n",
      "Epoch: 27\tFidelity = 0.522423\tKL_Divergence = 1.867670\n",
      "Epoch: 28\tFidelity = 0.521628\tKL_Divergence = 1.888019\n",
      "Epoch: 29\tFidelity = 0.522772\tKL_Divergence = 1.858920\n",
      "Epoch: 30\tFidelity = 0.521641\tKL_Divergence = 1.887703\n",
      "Epoch: 31\tFidelity = 0.523176\tKL_Divergence = 1.849024\n",
      "Epoch: 32\tFidelity = 0.522905\tKL_Divergence = 1.855669\n",
      "Epoch: 33\tFidelity = 0.521833\tKL_Divergence = 1.882719\n",
      "Epoch: 34\tFidelity = 0.521921\tKL_Divergence = 1.880435\n",
      "Epoch: 35\tFidelity = 0.523279\tKL_Divergence = 1.846490\n",
      "Epoch: 36\tFidelity = 0.521135\tKL_Divergence = 1.900980\n",
      "Epoch: 37\tFidelity = 0.524485\tKL_Divergence = 1.817982\n",
      "Epoch: 38\tFidelity = 0.524093\tKL_Divergence = 1.827073\n",
      "Epoch: 39\tFidelity = 0.521809\tKL_Divergence = 1.883178\n",
      "Epoch: 40\tFidelity = 0.523407\tKL_Divergence = 1.843118\n",
      "Epoch: 41\tFidelity = 0.521683\tKL_Divergence = 1.886424\n",
      "Epoch: 42\tFidelity = 0.521060\tKL_Divergence = 1.902840\n",
      "Epoch: 43\tFidelity = 0.522544\tKL_Divergence = 1.864395\n",
      "Epoch: 44\tFidelity = 0.523052\tKL_Divergence = 1.851844\n",
      "Epoch: 45\tFidelity = 0.524107\tKL_Divergence = 1.826645\n",
      "Epoch: 46\tFidelity = 0.520776\tKL_Divergence = 1.910629\n",
      "Epoch: 47\tFidelity = 0.523657\tKL_Divergence = 1.837390\n",
      "Epoch: 48\tFidelity = 0.522288\tKL_Divergence = 1.871049\n",
      "Epoch: 49\tFidelity = 0.523325\tKL_Divergence = 1.845388\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:56:30,111] Trial 100 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.522352\tKL_Divergence = 1.869428\n",
      "Total time elapsed during training: 38.227 s\n",
      "Trial 100 pruned. \n",
      "Epoch: 1\tFidelity = 0.523930\tKL_Divergence = 1.830925\n",
      "Epoch: 2\tFidelity = 0.521727\tKL_Divergence = 1.885438\n",
      "Epoch: 3\tFidelity = 0.526862\tKL_Divergence = 1.765540\n",
      "Epoch: 4\tFidelity = 0.521660\tKL_Divergence = 1.887197\n",
      "Epoch: 5\tFidelity = 0.518396\tKL_Divergence = 1.979202\n",
      "Epoch: 6\tFidelity = 0.521123\tKL_Divergence = 1.901290\n",
      "Epoch: 7\tFidelity = 0.519743\tKL_Divergence = 1.939442\n",
      "Epoch: 8\tFidelity = 0.523127\tKL_Divergence = 1.850235\n",
      "Epoch: 9\tFidelity = 0.521526\tKL_Divergence = 1.890694\n",
      "Epoch: 10\tFidelity = 0.522069\tKL_Divergence = 1.876568\n",
      "Epoch: 11\tFidelity = 0.521313\tKL_Divergence = 1.896307\n",
      "Epoch: 12\tFidelity = 0.521041\tKL_Divergence = 1.903552\n",
      "Epoch: 13\tFidelity = 0.524173\tKL_Divergence = 1.825213\n",
      "Epoch: 14\tFidelity = 0.518984\tKL_Divergence = 1.961489\n",
      "Epoch: 15\tFidelity = 0.524253\tKL_Divergence = 1.823378\n",
      "Epoch: 16\tFidelity = 0.520061\tKL_Divergence = 1.930436\n",
      "Epoch: 17\tFidelity = 0.519291\tKL_Divergence = 1.952450\n",
      "Epoch: 18\tFidelity = 0.525770\tKL_Divergence = 1.789046\n",
      "Epoch: 19\tFidelity = 0.520845\tKL_Divergence = 1.908796\n",
      "Epoch: 20\tFidelity = 0.519454\tKL_Divergence = 1.947706\n",
      "Epoch: 21\tFidelity = 0.518771\tKL_Divergence = 1.967837\n",
      "Epoch: 22\tFidelity = 0.517963\tKL_Divergence = 1.992592\n",
      "Epoch: 23\tFidelity = 0.520008\tKL_Divergence = 1.931883\n",
      "Epoch: 24\tFidelity = 0.522249\tKL_Divergence = 1.872082\n",
      "Epoch: 25\tFidelity = 0.520409\tKL_Divergence = 1.920732\n",
      "Epoch: 26\tFidelity = 0.522701\tKL_Divergence = 1.860719\n",
      "Epoch: 27\tFidelity = 0.519024\tKL_Divergence = 1.960326\n",
      "Epoch: 28\tFidelity = 0.521130\tKL_Divergence = 1.901148\n",
      "Epoch: 29\tFidelity = 0.524374\tKL_Divergence = 1.820375\n",
      "Epoch: 30\tFidelity = 0.520500\tKL_Divergence = 1.918215\n",
      "Epoch: 31\tFidelity = 0.523514\tKL_Divergence = 1.840762\n",
      "Epoch: 32\tFidelity = 0.523396\tKL_Divergence = 1.843705\n",
      "Epoch: 33\tFidelity = 0.524719\tKL_Divergence = 1.812593\n",
      "Epoch: 34\tFidelity = 0.527049\tKL_Divergence = 1.761537\n",
      "Epoch: 35\tFidelity = 0.519973\tKL_Divergence = 1.932691\n",
      "Epoch: 36\tFidelity = 0.521561\tKL_Divergence = 1.889775\n",
      "Epoch: 37\tFidelity = 0.519741\tKL_Divergence = 1.939477\n",
      "Epoch: 38\tFidelity = 0.523685\tKL_Divergence = 1.836657\n",
      "Epoch: 39\tFidelity = 0.522852\tKL_Divergence = 1.856849\n",
      "Epoch: 40\tFidelity = 0.521815\tKL_Divergence = 1.883103\n",
      "Epoch: 41\tFidelity = 0.524436\tKL_Divergence = 1.819145\n",
      "Epoch: 42\tFidelity = 0.520838\tKL_Divergence = 1.908987\n",
      "Epoch: 43\tFidelity = 0.521213\tKL_Divergence = 1.898964\n",
      "Epoch: 44\tFidelity = 0.522634\tKL_Divergence = 1.862380\n",
      "Epoch: 45\tFidelity = 0.518613\tKL_Divergence = 1.972463\n",
      "Epoch: 46\tFidelity = 0.525690\tKL_Divergence = 1.790762\n",
      "Epoch: 47\tFidelity = 0.519528\tKL_Divergence = 1.945577\n",
      "Epoch: 48\tFidelity = 0.521190\tKL_Divergence = 1.899584\n",
      "Epoch: 49\tFidelity = 0.524304\tKL_Divergence = 1.822199\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:57:13,662] Trial 101 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.523949\tKL_Divergence = 1.830509\n",
      "Total time elapsed during training: 43.410 s\n",
      "Trial 101 pruned. \n",
      "Epoch: 1\tFidelity = 0.521756\tKL_Divergence = 1.884722\n",
      "Epoch: 2\tFidelity = 0.521624\tKL_Divergence = 1.888146\n",
      "Epoch: 3\tFidelity = 0.520479\tKL_Divergence = 1.918804\n",
      "Epoch: 4\tFidelity = 0.519918\tKL_Divergence = 1.934444\n",
      "Epoch: 5\tFidelity = 0.521054\tKL_Divergence = 1.903198\n",
      "Epoch: 6\tFidelity = 0.524155\tKL_Divergence = 1.825641\n",
      "Epoch: 7\tFidelity = 0.520218\tKL_Divergence = 1.925838\n",
      "Epoch: 8\tFidelity = 0.522979\tKL_Divergence = 1.853607\n",
      "Epoch: 9\tFidelity = 0.519353\tKL_Divergence = 1.950535\n",
      "Epoch: 10\tFidelity = 0.518893\tKL_Divergence = 1.963946\n",
      "Epoch: 11\tFidelity = 0.522496\tKL_Divergence = 1.865457\n",
      "Epoch: 12\tFidelity = 0.520825\tKL_Divergence = 1.909087\n",
      "Epoch: 13\tFidelity = 0.523603\tKL_Divergence = 1.838546\n",
      "Epoch: 14\tFidelity = 0.520620\tKL_Divergence = 1.914787\n",
      "Epoch: 15\tFidelity = 0.522167\tKL_Divergence = 1.873937\n",
      "Epoch: 16\tFidelity = 0.520292\tKL_Divergence = 1.923750\n",
      "Epoch: 17\tFidelity = 0.523435\tKL_Divergence = 1.842578\n",
      "Epoch: 18\tFidelity = 0.522865\tKL_Divergence = 1.856642\n",
      "Epoch: 19\tFidelity = 0.521630\tKL_Divergence = 1.887989\n",
      "Epoch: 20\tFidelity = 0.521398\tKL_Divergence = 1.894057\n",
      "Epoch: 21\tFidelity = 0.520540\tKL_Divergence = 1.917100\n",
      "Epoch: 22\tFidelity = 0.520758\tKL_Divergence = 1.911178\n",
      "Epoch: 23\tFidelity = 0.523045\tKL_Divergence = 1.852208\n",
      "Epoch: 24\tFidelity = 0.520001\tKL_Divergence = 1.932083\n",
      "Epoch: 25\tFidelity = 0.520087\tKL_Divergence = 1.929629\n",
      "Epoch: 26\tFidelity = 0.520714\tKL_Divergence = 1.912317\n",
      "Epoch: 27\tFidelity = 0.523362\tKL_Divergence = 1.844488\n",
      "Epoch: 28\tFidelity = 0.518795\tKL_Divergence = 1.967108\n",
      "Epoch: 29\tFidelity = 0.521483\tKL_Divergence = 1.891806\n",
      "Epoch: 30\tFidelity = 0.519577\tKL_Divergence = 1.944095\n",
      "Epoch: 31\tFidelity = 0.523157\tKL_Divergence = 1.849462\n",
      "Epoch: 32\tFidelity = 0.521481\tKL_Divergence = 1.891865\n",
      "Epoch: 33\tFidelity = 0.520499\tKL_Divergence = 1.918196\n",
      "Epoch: 34\tFidelity = 0.520655\tKL_Divergence = 1.913947\n",
      "Epoch: 35\tFidelity = 0.522383\tKL_Divergence = 1.868637\n",
      "Epoch: 36\tFidelity = 0.522308\tKL_Divergence = 1.870426\n",
      "Epoch: 37\tFidelity = 0.521790\tKL_Divergence = 1.883757\n",
      "Epoch: 38\tFidelity = 0.520599\tKL_Divergence = 1.915504\n",
      "Epoch: 39\tFidelity = 0.523882\tKL_Divergence = 1.832071\n",
      "Epoch: 40\tFidelity = 0.520534\tKL_Divergence = 1.917275\n",
      "Epoch: 41\tFidelity = 0.525370\tKL_Divergence = 1.797906\n",
      "Epoch: 42\tFidelity = 0.520645\tKL_Divergence = 1.914273\n",
      "Epoch: 43\tFidelity = 0.523092\tKL_Divergence = 1.851063\n",
      "Epoch: 44\tFidelity = 0.517727\tKL_Divergence = 2.000019\n",
      "Epoch: 45\tFidelity = 0.521505\tKL_Divergence = 1.891240\n",
      "Epoch: 46\tFidelity = 0.522564\tKL_Divergence = 1.864138\n",
      "Epoch: 47\tFidelity = 0.523648\tKL_Divergence = 1.837657\n",
      "Epoch: 48\tFidelity = 0.521021\tKL_Divergence = 1.904049\n",
      "Epoch: 49\tFidelity = 0.519926\tKL_Divergence = 1.934210\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:57:56,933] Trial 102 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.523070\tKL_Divergence = 1.851621\n",
      "Total time elapsed during training: 43.131 s\n",
      "Trial 102 pruned. \n",
      "Epoch: 1\tFidelity = 0.525247\tKL_Divergence = 1.800602\n",
      "Epoch: 2\tFidelity = 0.517506\tKL_Divergence = 2.006869\n",
      "Epoch: 3\tFidelity = 0.518967\tKL_Divergence = 1.961861\n",
      "Epoch: 4\tFidelity = 0.519462\tKL_Divergence = 1.947322\n",
      "Epoch: 5\tFidelity = 0.519829\tKL_Divergence = 1.936935\n",
      "Epoch: 6\tFidelity = 0.523169\tKL_Divergence = 1.848983\n",
      "Epoch: 7\tFidelity = 0.520194\tKL_Divergence = 1.926668\n",
      "Epoch: 8\tFidelity = 0.520510\tKL_Divergence = 1.917982\n",
      "Epoch: 9\tFidelity = 0.519150\tKL_Divergence = 1.956605\n",
      "Epoch: 10\tFidelity = 0.520853\tKL_Divergence = 1.908541\n",
      "Epoch: 11\tFidelity = 0.521033\tKL_Divergence = 1.903791\n",
      "Epoch: 12\tFidelity = 0.520660\tKL_Divergence = 1.913777\n",
      "Epoch: 13\tFidelity = 0.525430\tKL_Divergence = 1.796388\n",
      "Epoch: 14\tFidelity = 0.527121\tKL_Divergence = 1.760044\n",
      "Epoch: 15\tFidelity = 0.526368\tKL_Divergence = 1.775925\n",
      "Epoch: 16\tFidelity = 0.523485\tKL_Divergence = 1.841383\n",
      "Epoch: 17\tFidelity = 0.518959\tKL_Divergence = 1.962100\n",
      "Epoch: 18\tFidelity = 0.518546\tKL_Divergence = 1.974427\n",
      "Epoch: 19\tFidelity = 0.525738\tKL_Divergence = 1.789689\n",
      "Epoch: 20\tFidelity = 0.521664\tKL_Divergence = 1.887080\n",
      "Epoch: 21\tFidelity = 0.523662\tKL_Divergence = 1.837321\n",
      "Epoch: 22\tFidelity = 0.523163\tKL_Divergence = 1.849351\n",
      "Epoch: 23\tFidelity = 0.519797\tKL_Divergence = 1.937912\n",
      "Epoch: 24\tFidelity = 0.519367\tKL_Divergence = 1.950246\n",
      "Epoch: 25\tFidelity = 0.523874\tKL_Divergence = 1.832175\n",
      "Epoch: 26\tFidelity = 0.520799\tKL_Divergence = 1.910052\n",
      "Epoch: 27\tFidelity = 0.519134\tKL_Divergence = 1.957125\n",
      "Epoch: 28\tFidelity = 0.521012\tKL_Divergence = 1.904339\n",
      "Epoch: 29\tFidelity = 0.523349\tKL_Divergence = 1.844873\n",
      "Epoch: 30\tFidelity = 0.520915\tKL_Divergence = 1.906978\n",
      "Epoch: 31\tFidelity = 0.521181\tKL_Divergence = 1.899834\n",
      "Epoch: 32\tFidelity = 0.518772\tKL_Divergence = 1.967846\n",
      "Epoch: 33\tFidelity = 0.523026\tKL_Divergence = 1.852729\n",
      "Epoch: 34\tFidelity = 0.524023\tKL_Divergence = 1.828794\n",
      "Epoch: 35\tFidelity = 0.523954\tKL_Divergence = 1.830390\n",
      "Epoch: 36\tFidelity = 0.521040\tKL_Divergence = 1.903611\n",
      "Epoch: 37\tFidelity = 0.524787\tKL_Divergence = 1.811022\n",
      "Epoch: 38\tFidelity = 0.520179\tKL_Divergence = 1.927166\n",
      "Epoch: 39\tFidelity = 0.518696\tKL_Divergence = 1.970080\n",
      "Epoch: 40\tFidelity = 0.520379\tKL_Divergence = 1.921561\n",
      "Epoch: 41\tFidelity = 0.522102\tKL_Divergence = 1.875718\n",
      "Epoch: 42\tFidelity = 0.521410\tKL_Divergence = 1.893487\n",
      "Epoch: 43\tFidelity = 0.520226\tKL_Divergence = 1.925428\n",
      "Epoch: 44\tFidelity = 0.519828\tKL_Divergence = 1.936364\n",
      "Epoch: 45\tFidelity = 0.519891\tKL_Divergence = 1.935041\n",
      "Epoch: 46\tFidelity = 0.520555\tKL_Divergence = 1.916586\n",
      "Epoch: 47\tFidelity = 0.519929\tKL_Divergence = 1.934206\n",
      "Epoch: 48\tFidelity = 0.521833\tKL_Divergence = 1.882754\n",
      "Epoch: 49\tFidelity = 0.521018\tKL_Divergence = 1.904212\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:58:40,041] Trial 103 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.521245\tKL_Divergence = 1.898163\n",
      "Total time elapsed during training: 42.959 s\n",
      "Trial 103 pruned. \n",
      "Epoch: 1\tFidelity = 0.521243\tKL_Divergence = 1.898230\n",
      "Epoch: 2\tFidelity = 0.520315\tKL_Divergence = 1.923396\n",
      "Epoch: 3\tFidelity = 0.520283\tKL_Divergence = 1.924290\n",
      "Epoch: 4\tFidelity = 0.521254\tKL_Divergence = 1.897923\n",
      "Epoch: 5\tFidelity = 0.520352\tKL_Divergence = 1.922279\n",
      "Epoch: 6\tFidelity = 0.523938\tKL_Divergence = 1.830681\n",
      "Epoch: 7\tFidelity = 0.521690\tKL_Divergence = 1.886288\n",
      "Epoch: 8\tFidelity = 0.520038\tKL_Divergence = 1.930954\n",
      "Epoch: 9\tFidelity = 0.519247\tKL_Divergence = 1.953669\n",
      "Epoch: 10\tFidelity = 0.521794\tKL_Divergence = 1.883668\n",
      "Epoch: 11\tFidelity = 0.519863\tKL_Divergence = 1.936015\n",
      "Epoch: 12\tFidelity = 0.520381\tKL_Divergence = 1.921469\n",
      "Epoch: 13\tFidelity = 0.520045\tKL_Divergence = 1.930879\n",
      "Epoch: 14\tFidelity = 0.521151\tKL_Divergence = 1.900394\n",
      "Epoch: 15\tFidelity = 0.523062\tKL_Divergence = 1.851638\n",
      "Epoch: 16\tFidelity = 0.518679\tKL_Divergence = 1.970495\n",
      "Epoch: 17\tFidelity = 0.521557\tKL_Divergence = 1.889646\n",
      "Epoch: 18\tFidelity = 0.522715\tKL_Divergence = 1.860259\n",
      "Epoch: 19\tFidelity = 0.522492\tKL_Divergence = 1.865931\n",
      "Epoch: 20\tFidelity = 0.520111\tKL_Divergence = 1.928926\n",
      "Epoch: 21\tFidelity = 0.520108\tKL_Divergence = 1.929080\n",
      "Epoch: 22\tFidelity = 0.523098\tKL_Divergence = 1.850987\n",
      "Epoch: 23\tFidelity = 0.521126\tKL_Divergence = 1.901338\n",
      "Epoch: 24\tFidelity = 0.521461\tKL_Divergence = 1.892441\n",
      "Epoch: 25\tFidelity = 0.518693\tKL_Divergence = 1.970223\n",
      "Epoch: 26\tFidelity = 0.519821\tKL_Divergence = 1.937259\n",
      "Epoch: 27\tFidelity = 0.521218\tKL_Divergence = 1.898837\n",
      "Epoch: 28\tFidelity = 0.523107\tKL_Divergence = 1.850567\n",
      "Epoch: 29\tFidelity = 0.522034\tKL_Divergence = 1.877377\n",
      "Epoch: 30\tFidelity = 0.519354\tKL_Divergence = 1.950504\n",
      "Epoch: 31\tFidelity = 0.521456\tKL_Divergence = 1.892521\n",
      "Epoch: 32\tFidelity = 0.521263\tKL_Divergence = 1.897625\n",
      "Epoch: 33\tFidelity = 0.521933\tKL_Divergence = 1.880010\n",
      "Epoch: 34\tFidelity = 0.520484\tKL_Divergence = 1.918571\n",
      "Epoch: 35\tFidelity = 0.522858\tKL_Divergence = 1.856821\n",
      "Epoch: 36\tFidelity = 0.519683\tKL_Divergence = 1.941111\n",
      "Epoch: 37\tFidelity = 0.520153\tKL_Divergence = 1.927863\n",
      "Epoch: 38\tFidelity = 0.521602\tKL_Divergence = 1.888701\n",
      "Epoch: 39\tFidelity = 0.522009\tKL_Divergence = 1.878207\n",
      "Epoch: 40\tFidelity = 0.520284\tKL_Divergence = 1.924236\n",
      "Epoch: 41\tFidelity = 0.520883\tKL_Divergence = 1.907823\n",
      "Epoch: 42\tFidelity = 0.518779\tKL_Divergence = 1.967631\n",
      "Epoch: 43\tFidelity = 0.518886\tKL_Divergence = 1.964366\n",
      "Epoch: 44\tFidelity = 0.520834\tKL_Divergence = 1.909158\n",
      "Epoch: 45\tFidelity = 0.518875\tKL_Divergence = 1.964726\n",
      "Epoch: 46\tFidelity = 0.523220\tKL_Divergence = 1.847928\n",
      "Epoch: 47\tFidelity = 0.519448\tKL_Divergence = 1.947862\n",
      "Epoch: 48\tFidelity = 0.519706\tKL_Divergence = 1.940505\n",
      "Epoch: 49\tFidelity = 0.522619\tKL_Divergence = 1.862782\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:59:16,831] Trial 104 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.521335\tKL_Divergence = 1.895663\n",
      "Total time elapsed during training: 36.655 s\n",
      "Trial 104 pruned. \n",
      "Epoch: 1\tFidelity = 0.519373\tKL_Divergence = 1.950049\n",
      "Epoch: 2\tFidelity = 0.521803\tKL_Divergence = 1.883488\n",
      "Epoch: 3\tFidelity = 0.523934\tKL_Divergence = 1.830840\n",
      "Epoch: 4\tFidelity = 0.522745\tKL_Divergence = 1.859646\n",
      "Epoch: 5\tFidelity = 0.520523\tKL_Divergence = 1.917611\n",
      "Epoch: 6\tFidelity = 0.522301\tKL_Divergence = 1.870779\n",
      "Epoch: 7\tFidelity = 0.520027\tKL_Divergence = 1.931402\n",
      "Epoch: 8\tFidelity = 0.521942\tKL_Divergence = 1.879939\n",
      "Epoch: 9\tFidelity = 0.518661\tKL_Divergence = 1.971170\n",
      "Epoch: 10\tFidelity = 0.522639\tKL_Divergence = 1.862301\n",
      "Epoch: 11\tFidelity = 0.521202\tKL_Divergence = 1.899271\n",
      "Epoch: 12\tFidelity = 0.522692\tKL_Divergence = 1.860974\n",
      "Epoch: 13\tFidelity = 0.519325\tKL_Divergence = 1.951503\n",
      "Epoch: 14\tFidelity = 0.518256\tKL_Divergence = 1.983514\n",
      "Epoch: 15\tFidelity = 0.521301\tKL_Divergence = 1.896644\n",
      "Epoch: 16\tFidelity = 0.521784\tKL_Divergence = 1.884013\n",
      "Epoch: 17\tFidelity = 0.519525\tKL_Divergence = 1.945686\n",
      "Epoch: 18\tFidelity = 0.521674\tKL_Divergence = 1.886855\n",
      "Epoch: 19\tFidelity = 0.520529\tKL_Divergence = 1.917462\n",
      "Epoch: 20\tFidelity = 0.523812\tKL_Divergence = 1.833738\n",
      "Epoch: 21\tFidelity = 0.519422\tKL_Divergence = 1.948646\n",
      "Epoch: 22\tFidelity = 0.521515\tKL_Divergence = 1.890986\n",
      "Epoch: 23\tFidelity = 0.523324\tKL_Divergence = 1.845424\n",
      "Epoch: 24\tFidelity = 0.520380\tKL_Divergence = 1.921548\n",
      "Epoch: 25\tFidelity = 0.524752\tKL_Divergence = 1.811863\n",
      "Epoch: 26\tFidelity = 0.522074\tKL_Divergence = 1.876510\n",
      "Epoch: 27\tFidelity = 0.522190\tKL_Divergence = 1.873560\n",
      "Epoch: 28\tFidelity = 0.521230\tKL_Divergence = 1.898502\n",
      "Epoch: 29\tFidelity = 0.521187\tKL_Divergence = 1.899636\n",
      "Epoch: 30\tFidelity = 0.520934\tKL_Divergence = 1.906430\n",
      "Epoch: 31\tFidelity = 0.522208\tKL_Divergence = 1.873102\n",
      "Epoch: 32\tFidelity = 0.522712\tKL_Divergence = 1.860442\n",
      "Epoch: 33\tFidelity = 0.521480\tKL_Divergence = 1.891902\n",
      "Epoch: 34\tFidelity = 0.521796\tKL_Divergence = 1.883662\n",
      "Epoch: 35\tFidelity = 0.522150\tKL_Divergence = 1.874564\n",
      "Epoch: 36\tFidelity = 0.522906\tKL_Divergence = 1.855637\n",
      "Epoch: 37\tFidelity = 0.521994\tKL_Divergence = 1.878550\n",
      "Epoch: 38\tFidelity = 0.519340\tKL_Divergence = 1.951018\n",
      "Epoch: 39\tFidelity = 0.522201\tKL_Divergence = 1.873261\n",
      "Epoch: 40\tFidelity = 0.521181\tKL_Divergence = 1.899786\n",
      "Epoch: 41\tFidelity = 0.521836\tKL_Divergence = 1.882613\n",
      "Epoch: 42\tFidelity = 0.520428\tKL_Divergence = 1.920185\n",
      "Epoch: 43\tFidelity = 0.524456\tKL_Divergence = 1.818624\n",
      "Epoch: 44\tFidelity = 0.522094\tKL_Divergence = 1.875980\n",
      "Epoch: 45\tFidelity = 0.519915\tKL_Divergence = 1.934521\n",
      "Epoch: 46\tFidelity = 0.521491\tKL_Divergence = 1.891597\n",
      "Epoch: 47\tFidelity = 0.522405\tKL_Divergence = 1.868094\n",
      "Epoch: 48\tFidelity = 0.523955\tKL_Divergence = 1.830334\n",
      "Epoch: 49\tFidelity = 0.521289\tKL_Divergence = 1.896903\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 04:59:47,643] Trial 105 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.520916\tKL_Divergence = 1.906863\n",
      "Total time elapsed during training: 30.658 s\n",
      "Trial 105 pruned. \n",
      "Epoch: 1\tFidelity = 0.520620\tKL_Divergence = 1.914904\n",
      "Epoch: 2\tFidelity = 0.520592\tKL_Divergence = 1.915660\n",
      "Epoch: 3\tFidelity = 0.520459\tKL_Divergence = 1.919314\n",
      "Epoch: 4\tFidelity = 0.521480\tKL_Divergence = 1.891869\n",
      "Epoch: 5\tFidelity = 0.520025\tKL_Divergence = 1.931401\n",
      "Epoch: 6\tFidelity = 0.522209\tKL_Divergence = 1.873038\n",
      "Epoch: 7\tFidelity = 0.519646\tKL_Divergence = 1.942166\n",
      "Epoch: 8\tFidelity = 0.519795\tKL_Divergence = 1.937902\n",
      "Epoch: 9\tFidelity = 0.523720\tKL_Divergence = 1.835880\n",
      "Epoch: 10\tFidelity = 0.522086\tKL_Divergence = 1.876181\n",
      "Epoch: 11\tFidelity = 0.522632\tKL_Divergence = 1.862395\n",
      "Epoch: 12\tFidelity = 0.521054\tKL_Divergence = 1.903179\n",
      "Epoch: 13\tFidelity = 0.521340\tKL_Divergence = 1.895552\n",
      "Epoch: 14\tFidelity = 0.521287\tKL_Divergence = 1.896943\n",
      "Epoch: 15\tFidelity = 0.521757\tKL_Divergence = 1.884629\n",
      "Epoch: 16\tFidelity = 0.520215\tKL_Divergence = 1.926060\n",
      "Epoch: 17\tFidelity = 0.521003\tKL_Divergence = 1.904513\n",
      "Epoch: 18\tFidelity = 0.521291\tKL_Divergence = 1.896855\n",
      "Epoch: 19\tFidelity = 0.520850\tKL_Divergence = 1.908646\n",
      "Epoch: 20\tFidelity = 0.521636\tKL_Divergence = 1.887796\n",
      "Epoch: 21\tFidelity = 0.521691\tKL_Divergence = 1.886362\n",
      "Epoch: 22\tFidelity = 0.522522\tKL_Divergence = 1.865150\n",
      "Epoch: 23\tFidelity = 0.520643\tKL_Divergence = 1.914271\n",
      "Epoch: 24\tFidelity = 0.523743\tKL_Divergence = 1.835325\n",
      "Epoch: 25\tFidelity = 0.523144\tKL_Divergence = 1.849743\n",
      "Epoch: 26\tFidelity = 0.523101\tKL_Divergence = 1.850805\n",
      "Epoch: 27\tFidelity = 0.520735\tKL_Divergence = 1.911736\n",
      "Epoch: 28\tFidelity = 0.521207\tKL_Divergence = 1.899061\n",
      "Epoch: 29\tFidelity = 0.521481\tKL_Divergence = 1.891811\n",
      "Epoch: 30\tFidelity = 0.521889\tKL_Divergence = 1.881198\n",
      "Epoch: 31\tFidelity = 0.524100\tKL_Divergence = 1.826872\n",
      "Epoch: 32\tFidelity = 0.521265\tKL_Divergence = 1.897522\n",
      "Epoch: 33\tFidelity = 0.521638\tKL_Divergence = 1.887721\n",
      "Epoch: 34\tFidelity = 0.523381\tKL_Divergence = 1.843990\n",
      "Epoch: 35\tFidelity = 0.523096\tKL_Divergence = 1.850923\n",
      "Epoch: 36\tFidelity = 0.521465\tKL_Divergence = 1.892225\n",
      "Epoch: 37\tFidelity = 0.522256\tKL_Divergence = 1.871822\n",
      "Epoch: 38\tFidelity = 0.522267\tKL_Divergence = 1.871516\n",
      "Epoch: 39\tFidelity = 0.522708\tKL_Divergence = 1.860477\n",
      "Epoch: 40\tFidelity = 0.520949\tKL_Divergence = 1.905958\n",
      "Epoch: 41\tFidelity = 0.520362\tKL_Divergence = 1.921971\n",
      "Epoch: 42\tFidelity = 0.522269\tKL_Divergence = 1.871495\n",
      "Epoch: 43\tFidelity = 0.521288\tKL_Divergence = 1.896916\n",
      "Epoch: 44\tFidelity = 0.521155\tKL_Divergence = 1.900450\n",
      "Epoch: 45\tFidelity = 0.521587\tKL_Divergence = 1.889050\n",
      "Epoch: 46\tFidelity = 0.520835\tKL_Divergence = 1.909033\n",
      "Epoch: 47\tFidelity = 0.522544\tKL_Divergence = 1.864571\n",
      "Epoch: 48\tFidelity = 0.522881\tKL_Divergence = 1.856203\n",
      "Epoch: 49\tFidelity = 0.519755\tKL_Divergence = 1.939019\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:00:25,431] Trial 106 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.522451\tKL_Divergence = 1.866916\n",
      "Total time elapsed during training: 37.652 s\n",
      "Trial 106 pruned. \n",
      "Epoch: 1\tFidelity = 0.523151\tKL_Divergence = 1.849577\n",
      "Epoch: 2\tFidelity = 0.523883\tKL_Divergence = 1.831998\n",
      "Epoch: 3\tFidelity = 0.522129\tKL_Divergence = 1.875073\n",
      "Epoch: 4\tFidelity = 0.520642\tKL_Divergence = 1.914270\n",
      "Epoch: 5\tFidelity = 0.519156\tKL_Divergence = 1.956335\n",
      "Epoch: 6\tFidelity = 0.521489\tKL_Divergence = 1.891607\n",
      "Epoch: 7\tFidelity = 0.521724\tKL_Divergence = 1.885484\n",
      "Epoch: 8\tFidelity = 0.522313\tKL_Divergence = 1.870349\n",
      "Epoch: 9\tFidelity = 0.520967\tKL_Divergence = 1.905450\n",
      "Epoch: 10\tFidelity = 0.524168\tKL_Divergence = 1.825263\n",
      "Epoch: 11\tFidelity = 0.519812\tKL_Divergence = 1.937400\n",
      "Epoch: 12\tFidelity = 0.521981\tKL_Divergence = 1.878838\n",
      "Epoch: 13\tFidelity = 0.520547\tKL_Divergence = 1.916856\n",
      "Epoch: 14\tFidelity = 0.522965\tKL_Divergence = 1.854113\n",
      "Epoch: 15\tFidelity = 0.524021\tKL_Divergence = 1.828726\n",
      "Epoch: 16\tFidelity = 0.523736\tKL_Divergence = 1.835475\n",
      "Epoch: 17\tFidelity = 0.525312\tKL_Divergence = 1.799082\n",
      "Epoch: 18\tFidelity = 0.520627\tKL_Divergence = 1.914609\n",
      "Epoch: 19\tFidelity = 0.520019\tKL_Divergence = 1.931520\n",
      "Epoch: 20\tFidelity = 0.524250\tKL_Divergence = 1.823349\n",
      "Epoch: 21\tFidelity = 0.522363\tKL_Divergence = 1.869090\n",
      "Epoch: 22\tFidelity = 0.524736\tKL_Divergence = 1.812135\n",
      "Epoch: 23\tFidelity = 0.522179\tKL_Divergence = 1.873777\n",
      "Epoch: 24\tFidelity = 0.525078\tKL_Divergence = 1.804386\n",
      "Epoch: 25\tFidelity = 0.520845\tKL_Divergence = 1.908737\n",
      "Epoch: 26\tFidelity = 0.520635\tKL_Divergence = 1.914446\n",
      "Epoch: 27\tFidelity = 0.525990\tKL_Divergence = 1.784155\n",
      "Epoch: 28\tFidelity = 0.524016\tKL_Divergence = 1.828826\n",
      "Epoch: 29\tFidelity = 0.526051\tKL_Divergence = 1.782818\n",
      "Epoch: 30\tFidelity = 0.522005\tKL_Divergence = 1.878205\n",
      "Epoch: 31\tFidelity = 0.521660\tKL_Divergence = 1.887130\n",
      "Epoch: 32\tFidelity = 0.522254\tKL_Divergence = 1.871856\n",
      "Epoch: 33\tFidelity = 0.523027\tKL_Divergence = 1.852586\n",
      "Epoch: 34\tFidelity = 0.519786\tKL_Divergence = 1.938113\n",
      "Epoch: 35\tFidelity = 0.523353\tKL_Divergence = 1.844652\n",
      "Epoch: 36\tFidelity = 0.521361\tKL_Divergence = 1.894975\n",
      "Epoch: 37\tFidelity = 0.519682\tKL_Divergence = 1.941087\n",
      "Epoch: 38\tFidelity = 0.522604\tKL_Divergence = 1.863048\n",
      "Epoch: 39\tFidelity = 0.520630\tKL_Divergence = 1.914574\n",
      "Epoch: 40\tFidelity = 0.521008\tKL_Divergence = 1.904323\n",
      "Epoch: 41\tFidelity = 0.521557\tKL_Divergence = 1.889774\n",
      "Epoch: 42\tFidelity = 0.520956\tKL_Divergence = 1.905756\n",
      "Epoch: 43\tFidelity = 0.519878\tKL_Divergence = 1.935511\n",
      "Epoch: 44\tFidelity = 0.524288\tKL_Divergence = 1.822457\n",
      "Epoch: 45\tFidelity = 0.520159\tKL_Divergence = 1.927599\n",
      "Epoch: 46\tFidelity = 0.521290\tKL_Divergence = 1.896824\n",
      "Epoch: 47\tFidelity = 0.521434\tKL_Divergence = 1.893015\n",
      "Epoch: 48\tFidelity = 0.522627\tKL_Divergence = 1.862452\n",
      "Epoch: 49\tFidelity = 0.521122\tKL_Divergence = 1.901268\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:01:03,576] Trial 107 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.521983\tKL_Divergence = 1.878786\n",
      "Total time elapsed during training: 38.010 s\n",
      "Trial 107 pruned. \n",
      "Epoch: 1\tFidelity = 0.523926\tKL_Divergence = 1.830931\n",
      "Epoch: 2\tFidelity = 0.523786\tKL_Divergence = 1.834277\n",
      "Epoch: 3\tFidelity = 0.523197\tKL_Divergence = 1.848395\n",
      "Epoch: 4\tFidelity = 0.523626\tKL_Divergence = 1.838090\n",
      "Epoch: 5\tFidelity = 0.522386\tKL_Divergence = 1.868530\n",
      "Epoch: 6\tFidelity = 0.523235\tKL_Divergence = 1.847506\n",
      "Epoch: 7\tFidelity = 0.520311\tKL_Divergence = 1.923371\n",
      "Epoch: 8\tFidelity = 0.522301\tKL_Divergence = 1.870669\n",
      "Epoch: 9\tFidelity = 0.522895\tKL_Divergence = 1.855790\n",
      "Epoch: 10\tFidelity = 0.520593\tKL_Divergence = 1.915570\n",
      "Epoch: 11\tFidelity = 0.521844\tKL_Divergence = 1.882293\n",
      "Epoch: 12\tFidelity = 0.519645\tKL_Divergence = 1.942094\n",
      "Epoch: 13\tFidelity = 0.522668\tKL_Divergence = 1.861346\n",
      "Epoch: 14\tFidelity = 0.521707\tKL_Divergence = 1.885898\n",
      "Epoch: 15\tFidelity = 0.523060\tKL_Divergence = 1.851799\n",
      "Epoch: 16\tFidelity = 0.520877\tKL_Divergence = 1.907863\n",
      "Epoch: 17\tFidelity = 0.520302\tKL_Divergence = 1.923638\n",
      "Epoch: 18\tFidelity = 0.521213\tKL_Divergence = 1.898863\n",
      "Epoch: 19\tFidelity = 0.522153\tKL_Divergence = 1.874284\n",
      "Epoch: 20\tFidelity = 0.524560\tKL_Divergence = 1.816172\n",
      "Epoch: 21\tFidelity = 0.522136\tKL_Divergence = 1.874859\n",
      "Epoch: 22\tFidelity = 0.523454\tKL_Divergence = 1.842191\n",
      "Epoch: 23\tFidelity = 0.520723\tKL_Divergence = 1.911912\n",
      "Epoch: 24\tFidelity = 0.522925\tKL_Divergence = 1.855085\n",
      "Epoch: 25\tFidelity = 0.522480\tKL_Divergence = 1.866106\n",
      "Epoch: 26\tFidelity = 0.524862\tKL_Divergence = 1.809251\n",
      "Epoch: 27\tFidelity = 0.520525\tKL_Divergence = 1.917440\n",
      "Epoch: 28\tFidelity = 0.523777\tKL_Divergence = 1.834468\n",
      "Epoch: 29\tFidelity = 0.521241\tKL_Divergence = 1.898074\n",
      "Epoch: 30\tFidelity = 0.523756\tKL_Divergence = 1.834973\n",
      "Epoch: 31\tFidelity = 0.523482\tKL_Divergence = 1.841468\n",
      "Epoch: 32\tFidelity = 0.525083\tKL_Divergence = 1.804220\n",
      "Epoch: 33\tFidelity = 0.523660\tKL_Divergence = 1.837245\n",
      "Epoch: 34\tFidelity = 0.522956\tKL_Divergence = 1.854208\n",
      "Epoch: 35\tFidelity = 0.522270\tKL_Divergence = 1.871423\n",
      "Epoch: 36\tFidelity = 0.520644\tKL_Divergence = 1.914182\n",
      "Epoch: 37\tFidelity = 0.522980\tKL_Divergence = 1.853721\n",
      "Epoch: 38\tFidelity = 0.523379\tKL_Divergence = 1.843974\n",
      "Epoch: 39\tFidelity = 0.521948\tKL_Divergence = 1.879593\n",
      "Epoch: 40\tFidelity = 0.523687\tKL_Divergence = 1.836533\n",
      "Epoch: 41\tFidelity = 0.523183\tKL_Divergence = 1.848741\n",
      "Epoch: 42\tFidelity = 0.521146\tKL_Divergence = 1.900581\n",
      "Epoch: 43\tFidelity = 0.521425\tKL_Divergence = 1.893204\n",
      "Epoch: 44\tFidelity = 0.522448\tKL_Divergence = 1.866940\n",
      "Epoch: 45\tFidelity = 0.523824\tKL_Divergence = 1.833360\n",
      "Epoch: 46\tFidelity = 0.522447\tKL_Divergence = 1.866977\n",
      "Epoch: 47\tFidelity = 0.521513\tKL_Divergence = 1.890928\n",
      "Epoch: 48\tFidelity = 0.521139\tKL_Divergence = 1.900844\n",
      "Epoch: 49\tFidelity = 0.521048\tKL_Divergence = 1.903276\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:02:22,891] Trial 108 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.523134\tKL_Divergence = 1.849952\n",
      "Total time elapsed during training: 79.174 s\n",
      "Trial 108 pruned. \n",
      "Epoch: 1\tFidelity = 0.521133\tKL_Divergence = 1.900975\n",
      "Epoch: 2\tFidelity = 0.523354\tKL_Divergence = 1.844597\n",
      "Epoch: 3\tFidelity = 0.520293\tKL_Divergence = 1.923834\n",
      "Epoch: 4\tFidelity = 0.524166\tKL_Divergence = 1.825290\n",
      "Epoch: 5\tFidelity = 0.519798\tKL_Divergence = 1.937742\n",
      "Epoch: 6\tFidelity = 0.523008\tKL_Divergence = 1.853036\n",
      "Epoch: 7\tFidelity = 0.521626\tKL_Divergence = 1.887982\n",
      "Epoch: 8\tFidelity = 0.525192\tKL_Divergence = 1.801803\n",
      "Epoch: 9\tFidelity = 0.520642\tKL_Divergence = 1.914255\n",
      "Epoch: 10\tFidelity = 0.523559\tKL_Divergence = 1.839677\n",
      "Epoch: 11\tFidelity = 0.519739\tKL_Divergence = 1.939434\n",
      "Epoch: 12\tFidelity = 0.522620\tKL_Divergence = 1.862657\n",
      "Epoch: 13\tFidelity = 0.520340\tKL_Divergence = 1.922566\n",
      "Epoch: 14\tFidelity = 0.523568\tKL_Divergence = 1.839456\n",
      "Epoch: 15\tFidelity = 0.520095\tKL_Divergence = 1.929397\n",
      "Epoch: 16\tFidelity = 0.521148\tKL_Divergence = 1.900601\n",
      "Epoch: 17\tFidelity = 0.524891\tKL_Divergence = 1.808589\n",
      "Epoch: 18\tFidelity = 0.522718\tKL_Divergence = 1.860193\n",
      "Epoch: 19\tFidelity = 0.520933\tKL_Divergence = 1.906354\n",
      "Epoch: 20\tFidelity = 0.522261\tKL_Divergence = 1.871681\n",
      "Epoch: 21\tFidelity = 0.524285\tKL_Divergence = 1.822533\n",
      "Epoch: 22\tFidelity = 0.519588\tKL_Divergence = 1.943769\n",
      "Epoch: 23\tFidelity = 0.523974\tKL_Divergence = 1.829832\n",
      "Epoch: 24\tFidelity = 0.520211\tKL_Divergence = 1.926153\n",
      "Epoch: 25\tFidelity = 0.522782\tKL_Divergence = 1.858617\n",
      "Epoch: 26\tFidelity = 0.522550\tKL_Divergence = 1.864395\n",
      "Epoch: 27\tFidelity = 0.522350\tKL_Divergence = 1.869442\n",
      "Epoch: 28\tFidelity = 0.524078\tKL_Divergence = 1.827371\n",
      "Epoch: 29\tFidelity = 0.519651\tKL_Divergence = 1.941996\n",
      "Epoch: 30\tFidelity = 0.523649\tKL_Divergence = 1.837541\n",
      "Epoch: 31\tFidelity = 0.519964\tKL_Divergence = 1.933074\n",
      "Epoch: 32\tFidelity = 0.523130\tKL_Divergence = 1.850059\n",
      "Epoch: 33\tFidelity = 0.520919\tKL_Divergence = 1.906745\n",
      "Epoch: 34\tFidelity = 0.524349\tKL_Divergence = 1.821053\n",
      "Epoch: 35\tFidelity = 0.522010\tKL_Divergence = 1.878077\n",
      "Epoch: 36\tFidelity = 0.520923\tKL_Divergence = 1.906642\n",
      "Epoch: 37\tFidelity = 0.522282\tKL_Divergence = 1.871152\n",
      "Epoch: 38\tFidelity = 0.520654\tKL_Divergence = 1.913944\n",
      "Epoch: 39\tFidelity = 0.522366\tKL_Divergence = 1.869032\n",
      "Epoch: 40\tFidelity = 0.523665\tKL_Divergence = 1.837145\n",
      "Epoch: 41\tFidelity = 0.522724\tKL_Divergence = 1.860062\n",
      "Epoch: 42\tFidelity = 0.521398\tKL_Divergence = 1.893989\n",
      "Epoch: 43\tFidelity = 0.519253\tKL_Divergence = 1.953478\n",
      "Epoch: 44\tFidelity = 0.522573\tKL_Divergence = 1.863807\n",
      "Epoch: 45\tFidelity = 0.522557\tKL_Divergence = 1.864211\n",
      "Epoch: 46\tFidelity = 0.521649\tKL_Divergence = 1.887413\n",
      "Epoch: 47\tFidelity = 0.520860\tKL_Divergence = 1.908324\n",
      "Epoch: 48\tFidelity = 0.524283\tKL_Divergence = 1.822575\n",
      "Epoch: 49\tFidelity = 0.522735\tKL_Divergence = 1.859796\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:02:54,611] Trial 109 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.519710\tKL_Divergence = 1.940279\n",
      "Total time elapsed during training: 31.572 s\n",
      "Trial 109 pruned. \n",
      "Epoch: 1\tFidelity = 0.522975\tKL_Divergence = 1.853865\n",
      "Epoch: 2\tFidelity = 0.528045\tKL_Divergence = 1.741028\n",
      "Epoch: 3\tFidelity = 0.521351\tKL_Divergence = 1.895215\n",
      "Epoch: 4\tFidelity = 0.520154\tKL_Divergence = 1.927764\n",
      "Epoch: 5\tFidelity = 0.522328\tKL_Divergence = 1.869965\n",
      "Epoch: 6\tFidelity = 0.525095\tKL_Divergence = 1.804006\n",
      "Epoch: 7\tFidelity = 0.521595\tKL_Divergence = 1.888827\n",
      "Epoch: 8\tFidelity = 0.521061\tKL_Divergence = 1.902888\n",
      "Epoch: 9\tFidelity = 0.522129\tKL_Divergence = 1.875020\n",
      "Epoch: 10\tFidelity = 0.522366\tKL_Divergence = 1.869017\n",
      "Epoch: 11\tFidelity = 0.521170\tKL_Divergence = 1.899915\n",
      "Epoch: 12\tFidelity = 0.522250\tKL_Divergence = 1.871780\n",
      "Epoch: 13\tFidelity = 0.522852\tKL_Divergence = 1.856860\n",
      "Epoch: 14\tFidelity = 0.519871\tKL_Divergence = 1.935665\n",
      "Epoch: 15\tFidelity = 0.523378\tKL_Divergence = 1.843969\n",
      "Epoch: 16\tFidelity = 0.523756\tKL_Divergence = 1.834921\n",
      "Epoch: 17\tFidelity = 0.520256\tKL_Divergence = 1.924906\n",
      "Epoch: 18\tFidelity = 0.525733\tKL_Divergence = 1.789818\n",
      "Epoch: 19\tFidelity = 0.521584\tKL_Divergence = 1.889145\n",
      "Epoch: 20\tFidelity = 0.523251\tKL_Divergence = 1.847146\n",
      "Epoch: 21\tFidelity = 0.525115\tKL_Divergence = 1.803585\n",
      "Epoch: 22\tFidelity = 0.521164\tKL_Divergence = 1.900212\n",
      "Epoch: 23\tFidelity = 0.520298\tKL_Divergence = 1.923724\n",
      "Epoch: 24\tFidelity = 0.527659\tKL_Divergence = 1.748921\n",
      "Epoch: 25\tFidelity = 0.521468\tKL_Divergence = 1.892165\n",
      "Epoch: 26\tFidelity = 0.521678\tKL_Divergence = 1.886647\n",
      "Epoch: 27\tFidelity = 0.525056\tKL_Divergence = 1.804860\n",
      "Epoch: 28\tFidelity = 0.520696\tKL_Divergence = 1.912742\n",
      "Epoch: 29\tFidelity = 0.522561\tKL_Divergence = 1.864099\n",
      "Epoch: 30\tFidelity = 0.525535\tKL_Divergence = 1.794094\n",
      "Epoch: 31\tFidelity = 0.521582\tKL_Divergence = 1.889122\n",
      "Epoch: 32\tFidelity = 0.524116\tKL_Divergence = 1.826479\n",
      "Epoch: 33\tFidelity = 0.524028\tKL_Divergence = 1.828490\n",
      "Epoch: 34\tFidelity = 0.523495\tKL_Divergence = 1.841011\n",
      "Epoch: 35\tFidelity = 0.519853\tKL_Divergence = 1.936078\n",
      "Epoch: 36\tFidelity = 0.517774\tKL_Divergence = 1.998265\n",
      "Epoch: 37\tFidelity = 0.521134\tKL_Divergence = 1.900777\n",
      "Epoch: 38\tFidelity = 0.526622\tKL_Divergence = 1.770514\n",
      "Epoch: 39\tFidelity = 0.527357\tKL_Divergence = 1.755030\n",
      "Epoch: 40\tFidelity = 0.524572\tKL_Divergence = 1.815817\n",
      "Epoch: 41\tFidelity = 0.521190\tKL_Divergence = 1.899422\n",
      "Epoch: 42\tFidelity = 0.527292\tKL_Divergence = 1.756433\n",
      "Epoch: 43\tFidelity = 0.527641\tKL_Divergence = 1.749185\n",
      "Epoch: 44\tFidelity = 0.523032\tKL_Divergence = 1.852392\n",
      "Epoch: 45\tFidelity = 0.522206\tKL_Divergence = 1.873047\n",
      "Epoch: 46\tFidelity = 0.521913\tKL_Divergence = 1.880553\n",
      "Epoch: 47\tFidelity = 0.518892\tKL_Divergence = 1.964045\n",
      "Epoch: 48\tFidelity = 0.521737\tKL_Divergence = 1.885094\n",
      "Epoch: 49\tFidelity = 0.520840\tKL_Divergence = 1.908879\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:03:51,821] Trial 110 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.524167\tKL_Divergence = 1.825287\n",
      "Total time elapsed during training: 57.072 s\n",
      "Trial 110 pruned. \n",
      "Epoch: 1\tFidelity = 0.521274\tKL_Divergence = 1.897265\n",
      "Epoch: 2\tFidelity = 0.521556\tKL_Divergence = 1.889817\n",
      "Epoch: 3\tFidelity = 0.524373\tKL_Divergence = 1.820484\n",
      "Epoch: 4\tFidelity = 0.525594\tKL_Divergence = 1.792860\n",
      "Epoch: 5\tFidelity = 0.519598\tKL_Divergence = 1.943492\n",
      "Epoch: 6\tFidelity = 0.526468\tKL_Divergence = 1.773883\n",
      "Epoch: 7\tFidelity = 0.522537\tKL_Divergence = 1.864759\n",
      "Epoch: 8\tFidelity = 0.522387\tKL_Divergence = 1.868518\n",
      "Epoch: 9\tFidelity = 0.520928\tKL_Divergence = 1.906491\n",
      "Epoch: 10\tFidelity = 0.521009\tKL_Divergence = 1.904332\n",
      "Epoch: 11\tFidelity = 0.524422\tKL_Divergence = 1.819379\n",
      "Epoch: 12\tFidelity = 0.523982\tKL_Divergence = 1.829653\n",
      "Epoch: 13\tFidelity = 0.520398\tKL_Divergence = 1.920954\n",
      "Epoch: 14\tFidelity = 0.523787\tKL_Divergence = 1.834260\n",
      "Epoch: 15\tFidelity = 0.524922\tKL_Divergence = 1.807910\n",
      "Epoch: 16\tFidelity = 0.520921\tKL_Divergence = 1.906709\n",
      "Epoch: 17\tFidelity = 0.521621\tKL_Divergence = 1.888146\n",
      "Epoch: 18\tFidelity = 0.522293\tKL_Divergence = 1.870877\n",
      "Epoch: 19\tFidelity = 0.520450\tKL_Divergence = 1.919494\n",
      "Epoch: 20\tFidelity = 0.522699\tKL_Divergence = 1.860675\n",
      "Epoch: 21\tFidelity = 0.524741\tKL_Divergence = 1.812023\n",
      "Epoch: 22\tFidelity = 0.525232\tKL_Divergence = 1.800935\n",
      "Epoch: 23\tFidelity = 0.520883\tKL_Divergence = 1.907711\n",
      "Epoch: 24\tFidelity = 0.523323\tKL_Divergence = 1.845394\n",
      "Epoch: 25\tFidelity = 0.522476\tKL_Divergence = 1.866233\n",
      "Epoch: 26\tFidelity = 0.522908\tKL_Divergence = 1.855508\n",
      "Epoch: 27\tFidelity = 0.524003\tKL_Divergence = 1.829127\n",
      "Epoch: 28\tFidelity = 0.520764\tKL_Divergence = 1.910920\n",
      "Epoch: 29\tFidelity = 0.521826\tKL_Divergence = 1.882788\n",
      "Epoch: 30\tFidelity = 0.522122\tKL_Divergence = 1.875190\n",
      "Epoch: 31\tFidelity = 0.521854\tKL_Divergence = 1.882098\n",
      "Epoch: 32\tFidelity = 0.522045\tKL_Divergence = 1.877168\n",
      "Epoch: 33\tFidelity = 0.521258\tKL_Divergence = 1.897696\n",
      "Epoch: 34\tFidelity = 0.519957\tKL_Divergence = 1.933266\n",
      "Epoch: 35\tFidelity = 0.523678\tKL_Divergence = 1.836837\n",
      "Epoch: 36\tFidelity = 0.525674\tKL_Divergence = 1.791103\n",
      "Epoch: 37\tFidelity = 0.523115\tKL_Divergence = 1.850445\n",
      "Epoch: 38\tFidelity = 0.521972\tKL_Divergence = 1.879030\n",
      "Epoch: 39\tFidelity = 0.523989\tKL_Divergence = 1.829469\n",
      "Epoch: 40\tFidelity = 0.519582\tKL_Divergence = 1.943949\n",
      "Epoch: 41\tFidelity = 0.523055\tKL_Divergence = 1.851862\n",
      "Epoch: 42\tFidelity = 0.521119\tKL_Divergence = 1.901356\n",
      "Epoch: 43\tFidelity = 0.520518\tKL_Divergence = 1.917647\n",
      "Epoch: 44\tFidelity = 0.524306\tKL_Divergence = 1.822061\n",
      "Epoch: 45\tFidelity = 0.522600\tKL_Divergence = 1.863159\n",
      "Epoch: 46\tFidelity = 0.524252\tKL_Divergence = 1.823304\n",
      "Epoch: 47\tFidelity = 0.519384\tKL_Divergence = 1.949659\n",
      "Epoch: 48\tFidelity = 0.521217\tKL_Divergence = 1.898797\n",
      "Epoch: 49\tFidelity = 0.520733\tKL_Divergence = 1.911772\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:04:36,089] Trial 111 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.523710\tKL_Divergence = 1.836091\n",
      "Total time elapsed during training: 44.126 s\n",
      "Trial 111 pruned. \n",
      "Epoch: 1\tFidelity = 0.520574\tKL_Divergence = 1.916125\n",
      "Epoch: 2\tFidelity = 0.522230\tKL_Divergence = 1.872472\n",
      "Epoch: 3\tFidelity = 0.523640\tKL_Divergence = 1.837762\n",
      "Epoch: 4\tFidelity = 0.521532\tKL_Divergence = 1.890477\n",
      "Epoch: 5\tFidelity = 0.521102\tKL_Divergence = 1.901844\n",
      "Epoch: 6\tFidelity = 0.520996\tKL_Divergence = 1.904699\n",
      "Epoch: 7\tFidelity = 0.521221\tKL_Divergence = 1.898695\n",
      "Epoch: 8\tFidelity = 0.521300\tKL_Divergence = 1.896590\n",
      "Epoch: 9\tFidelity = 0.521939\tKL_Divergence = 1.879923\n",
      "Epoch: 10\tFidelity = 0.521312\tKL_Divergence = 1.896260\n",
      "Epoch: 11\tFidelity = 0.520635\tKL_Divergence = 1.914470\n",
      "Epoch: 12\tFidelity = 0.523667\tKL_Divergence = 1.837115\n",
      "Epoch: 13\tFidelity = 0.522191\tKL_Divergence = 1.873478\n",
      "Epoch: 14\tFidelity = 0.521397\tKL_Divergence = 1.894017\n",
      "Epoch: 15\tFidelity = 0.523353\tKL_Divergence = 1.844651\n",
      "Epoch: 16\tFidelity = 0.520171\tKL_Divergence = 1.927280\n",
      "Epoch: 17\tFidelity = 0.521745\tKL_Divergence = 1.884918\n",
      "Epoch: 18\tFidelity = 0.523255\tKL_Divergence = 1.847021\n",
      "Epoch: 19\tFidelity = 0.520821\tKL_Divergence = 1.909400\n",
      "Epoch: 20\tFidelity = 0.522183\tKL_Divergence = 1.873662\n",
      "Epoch: 21\tFidelity = 0.520077\tKL_Divergence = 1.929880\n",
      "Epoch: 22\tFidelity = 0.522767\tKL_Divergence = 1.858998\n",
      "Epoch: 23\tFidelity = 0.520562\tKL_Divergence = 1.916441\n",
      "Epoch: 24\tFidelity = 0.518936\tKL_Divergence = 1.962838\n",
      "Epoch: 25\tFidelity = 0.522222\tKL_Divergence = 1.872661\n",
      "Epoch: 26\tFidelity = 0.521152\tKL_Divergence = 1.900486\n",
      "Epoch: 27\tFidelity = 0.521999\tKL_Divergence = 1.878355\n",
      "Epoch: 28\tFidelity = 0.520427\tKL_Divergence = 1.920174\n",
      "Epoch: 29\tFidelity = 0.519181\tKL_Divergence = 1.955600\n",
      "Epoch: 30\tFidelity = 0.522002\tKL_Divergence = 1.878280\n",
      "Epoch: 31\tFidelity = 0.520164\tKL_Divergence = 1.927463\n",
      "Epoch: 32\tFidelity = 0.520282\tKL_Divergence = 1.924179\n",
      "Epoch: 33\tFidelity = 0.520621\tKL_Divergence = 1.914836\n",
      "Epoch: 34\tFidelity = 0.521440\tKL_Divergence = 1.892877\n",
      "Epoch: 35\tFidelity = 0.523220\tKL_Divergence = 1.847865\n",
      "Epoch: 36\tFidelity = 0.521300\tKL_Divergence = 1.896562\n",
      "Epoch: 37\tFidelity = 0.521576\tKL_Divergence = 1.889308\n",
      "Epoch: 38\tFidelity = 0.521687\tKL_Divergence = 1.886433\n",
      "Epoch: 39\tFidelity = 0.522727\tKL_Divergence = 1.859993\n",
      "Epoch: 40\tFidelity = 0.520318\tKL_Divergence = 1.923179\n",
      "Epoch: 41\tFidelity = 0.519746\tKL_Divergence = 1.939283\n",
      "Epoch: 42\tFidelity = 0.521477\tKL_Divergence = 1.891903\n",
      "Epoch: 43\tFidelity = 0.522284\tKL_Divergence = 1.871107\n",
      "Epoch: 44\tFidelity = 0.521958\tKL_Divergence = 1.879427\n",
      "Epoch: 45\tFidelity = 0.519982\tKL_Divergence = 1.932596\n",
      "Epoch: 46\tFidelity = 0.522957\tKL_Divergence = 1.854315\n",
      "Epoch: 47\tFidelity = 0.520825\tKL_Divergence = 1.909305\n",
      "Epoch: 48\tFidelity = 0.521672\tKL_Divergence = 1.886830\n",
      "Epoch: 49\tFidelity = 0.520265\tKL_Divergence = 1.924648\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:05:20,854] Trial 112 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.520396\tKL_Divergence = 1.921035\n",
      "Total time elapsed during training: 44.604 s\n",
      "Trial 112 pruned. \n",
      "Epoch: 1\tFidelity = 0.522875\tKL_Divergence = 1.856319\n",
      "Epoch: 2\tFidelity = 0.519735\tKL_Divergence = 1.939572\n",
      "Epoch: 3\tFidelity = 0.519998\tKL_Divergence = 1.932125\n",
      "Epoch: 4\tFidelity = 0.521748\tKL_Divergence = 1.884859\n",
      "Epoch: 5\tFidelity = 0.523385\tKL_Divergence = 1.843869\n",
      "Epoch: 6\tFidelity = 0.519456\tKL_Divergence = 1.947599\n",
      "Epoch: 7\tFidelity = 0.520236\tKL_Divergence = 1.925459\n",
      "Epoch: 8\tFidelity = 0.520817\tKL_Divergence = 1.909504\n",
      "Epoch: 9\tFidelity = 0.521902\tKL_Divergence = 1.880871\n",
      "Epoch: 10\tFidelity = 0.523744\tKL_Divergence = 1.835269\n",
      "Epoch: 11\tFidelity = 0.521435\tKL_Divergence = 1.893033\n",
      "Epoch: 12\tFidelity = 0.521940\tKL_Divergence = 1.879890\n",
      "Epoch: 13\tFidelity = 0.519919\tKL_Divergence = 1.934339\n",
      "Epoch: 14\tFidelity = 0.522544\tKL_Divergence = 1.864576\n",
      "Epoch: 15\tFidelity = 0.522181\tKL_Divergence = 1.873713\n",
      "Epoch: 16\tFidelity = 0.519769\tKL_Divergence = 1.938596\n",
      "Epoch: 17\tFidelity = 0.521660\tKL_Divergence = 1.887120\n",
      "Epoch: 18\tFidelity = 0.522106\tKL_Divergence = 1.875614\n",
      "Epoch: 19\tFidelity = 0.519485\tKL_Divergence = 1.946758\n",
      "Epoch: 20\tFidelity = 0.519721\tKL_Divergence = 1.939968\n",
      "Epoch: 21\tFidelity = 0.520751\tKL_Divergence = 1.911290\n",
      "Epoch: 22\tFidelity = 0.522060\tKL_Divergence = 1.876759\n",
      "Epoch: 23\tFidelity = 0.519191\tKL_Divergence = 1.955272\n",
      "Epoch: 24\tFidelity = 0.521990\tKL_Divergence = 1.878536\n",
      "Epoch: 25\tFidelity = 0.522854\tKL_Divergence = 1.856796\n",
      "Epoch: 26\tFidelity = 0.523053\tKL_Divergence = 1.851908\n",
      "Epoch: 27\tFidelity = 0.520605\tKL_Divergence = 1.915214\n",
      "Epoch: 28\tFidelity = 0.524514\tKL_Divergence = 1.817183\n",
      "Epoch: 29\tFidelity = 0.520507\tKL_Divergence = 1.917899\n",
      "Epoch: 30\tFidelity = 0.520346\tKL_Divergence = 1.922342\n",
      "Epoch: 31\tFidelity = 0.521458\tKL_Divergence = 1.892370\n",
      "Epoch: 32\tFidelity = 0.521664\tKL_Divergence = 1.886985\n",
      "Epoch: 33\tFidelity = 0.520821\tKL_Divergence = 1.909380\n",
      "Epoch: 34\tFidelity = 0.519176\tKL_Divergence = 1.955709\n",
      "Epoch: 35\tFidelity = 0.520595\tKL_Divergence = 1.915536\n",
      "Epoch: 36\tFidelity = 0.522839\tKL_Divergence = 1.857208\n",
      "Epoch: 37\tFidelity = 0.523116\tKL_Divergence = 1.850413\n",
      "Epoch: 38\tFidelity = 0.522319\tKL_Divergence = 1.870218\n",
      "Epoch: 39\tFidelity = 0.526070\tKL_Divergence = 1.782428\n",
      "Epoch: 40\tFidelity = 0.523083\tKL_Divergence = 1.851217\n",
      "Epoch: 41\tFidelity = 0.523167\tKL_Divergence = 1.849167\n",
      "Epoch: 42\tFidelity = 0.520486\tKL_Divergence = 1.918567\n",
      "Epoch: 43\tFidelity = 0.521330\tKL_Divergence = 1.895800\n",
      "Epoch: 44\tFidelity = 0.522342\tKL_Divergence = 1.869649\n",
      "Epoch: 45\tFidelity = 0.519256\tKL_Divergence = 1.953400\n",
      "Epoch: 46\tFidelity = 0.519694\tKL_Divergence = 1.940741\n",
      "Epoch: 47\tFidelity = 0.523008\tKL_Divergence = 1.853070\n",
      "Epoch: 48\tFidelity = 0.521101\tKL_Divergence = 1.901882\n",
      "Epoch: 49\tFidelity = 0.519491\tKL_Divergence = 1.946613\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:06:04,294] Trial 113 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.522691\tKL_Divergence = 1.860907\n",
      "Total time elapsed during training: 43.298 s\n",
      "Trial 113 pruned. \n",
      "Epoch: 1\tFidelity = 0.520239\tKL_Divergence = 1.925414\n",
      "Epoch: 2\tFidelity = 0.520957\tKL_Divergence = 1.905765\n",
      "Epoch: 3\tFidelity = 0.519954\tKL_Divergence = 1.933349\n",
      "Epoch: 4\tFidelity = 0.518747\tKL_Divergence = 1.968346\n",
      "Epoch: 5\tFidelity = 0.525705\tKL_Divergence = 1.790027\n",
      "Epoch: 6\tFidelity = 0.519431\tKL_Divergence = 1.948279\n",
      "Epoch: 7\tFidelity = 0.520003\tKL_Divergence = 1.931923\n",
      "Epoch: 8\tFidelity = 0.520030\tKL_Divergence = 1.931133\n",
      "Epoch: 9\tFidelity = 0.525633\tKL_Divergence = 1.791683\n",
      "Epoch: 10\tFidelity = 0.522255\tKL_Divergence = 1.871248\n",
      "Epoch: 11\tFidelity = 0.519537\tKL_Divergence = 1.944512\n",
      "Epoch: 12\tFidelity = 0.519753\tKL_Divergence = 1.938521\n",
      "Epoch: 13\tFidelity = 0.523476\tKL_Divergence = 1.841445\n",
      "Epoch: 14\tFidelity = 0.525825\tKL_Divergence = 1.787063\n",
      "Epoch: 15\tFidelity = 0.518726\tKL_Divergence = 1.968592\n",
      "Epoch: 16\tFidelity = 0.522566\tKL_Divergence = 1.863353\n",
      "Epoch: 17\tFidelity = 0.522398\tKL_Divergence = 1.867999\n",
      "Epoch: 18\tFidelity = 0.521478\tKL_Divergence = 1.891879\n",
      "Epoch: 19\tFidelity = 0.519801\tKL_Divergence = 1.937715\n",
      "Epoch: 20\tFidelity = 0.522239\tKL_Divergence = 1.872241\n",
      "Epoch: 21\tFidelity = 0.518715\tKL_Divergence = 1.969339\n",
      "Epoch: 22\tFidelity = 0.522537\tKL_Divergence = 1.864627\n",
      "Epoch: 23\tFidelity = 0.520480\tKL_Divergence = 1.918605\n",
      "Epoch: 24\tFidelity = 0.520413\tKL_Divergence = 1.920573\n",
      "Epoch: 25\tFidelity = 0.519786\tKL_Divergence = 1.938026\n",
      "Epoch: 26\tFidelity = 0.522592\tKL_Divergence = 1.863274\n",
      "Epoch: 27\tFidelity = 0.519405\tKL_Divergence = 1.949085\n",
      "Epoch: 28\tFidelity = 0.520552\tKL_Divergence = 1.916750\n",
      "Epoch: 29\tFidelity = 0.519303\tKL_Divergence = 1.952083\n",
      "Epoch: 30\tFidelity = 0.523423\tKL_Divergence = 1.842996\n",
      "Epoch: 31\tFidelity = 0.522841\tKL_Divergence = 1.857187\n",
      "Epoch: 32\tFidelity = 0.521667\tKL_Divergence = 1.886972\n",
      "Epoch: 33\tFidelity = 0.523742\tKL_Divergence = 1.835337\n",
      "Epoch: 34\tFidelity = 0.519758\tKL_Divergence = 1.938917\n",
      "Epoch: 35\tFidelity = 0.517797\tKL_Divergence = 1.997782\n",
      "Epoch: 36\tFidelity = 0.520612\tKL_Divergence = 1.915059\n",
      "Epoch: 37\tFidelity = 0.520304\tKL_Divergence = 1.923536\n",
      "Epoch: 38\tFidelity = 0.520533\tKL_Divergence = 1.917269\n",
      "Epoch: 39\tFidelity = 0.519608\tKL_Divergence = 1.943215\n",
      "Epoch: 40\tFidelity = 0.520827\tKL_Divergence = 1.909050\n",
      "Epoch: 41\tFidelity = 0.522363\tKL_Divergence = 1.869029\n",
      "Epoch: 42\tFidelity = 0.523289\tKL_Divergence = 1.846121\n",
      "Epoch: 43\tFidelity = 0.520623\tKL_Divergence = 1.914656\n",
      "Epoch: 44\tFidelity = 0.520097\tKL_Divergence = 1.928942\n",
      "Epoch: 45\tFidelity = 0.520027\tKL_Divergence = 1.931245\n",
      "Epoch: 46\tFidelity = 0.518831\tKL_Divergence = 1.965905\n",
      "Epoch: 47\tFidelity = 0.520928\tKL_Divergence = 1.906444\n",
      "Epoch: 48\tFidelity = 0.519205\tKL_Divergence = 1.954923\n",
      "Epoch: 49\tFidelity = 0.520973\tKL_Divergence = 1.905214\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:06:40,816] Trial 114 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.519430\tKL_Divergence = 1.948162\n",
      "Total time elapsed during training: 36.381 s\n",
      "Trial 114 pruned. \n",
      "Epoch: 1\tFidelity = 0.522005\tKL_Divergence = 1.878078\n",
      "Epoch: 2\tFidelity = 0.520104\tKL_Divergence = 1.929038\n",
      "Epoch: 3\tFidelity = 0.522216\tKL_Divergence = 1.872741\n",
      "Epoch: 4\tFidelity = 0.521815\tKL_Divergence = 1.883037\n",
      "Epoch: 5\tFidelity = 0.523179\tKL_Divergence = 1.848832\n",
      "Epoch: 6\tFidelity = 0.520455\tKL_Divergence = 1.919353\n",
      "Epoch: 7\tFidelity = 0.520150\tKL_Divergence = 1.927840\n",
      "Epoch: 8\tFidelity = 0.523146\tKL_Divergence = 1.849663\n",
      "Epoch: 9\tFidelity = 0.520161\tKL_Divergence = 1.927521\n",
      "Epoch: 10\tFidelity = 0.521652\tKL_Divergence = 1.887307\n",
      "Epoch: 11\tFidelity = 0.521419\tKL_Divergence = 1.893422\n",
      "Epoch: 12\tFidelity = 0.522067\tKL_Divergence = 1.876631\n",
      "Epoch: 13\tFidelity = 0.520637\tKL_Divergence = 1.914406\n",
      "Epoch: 14\tFidelity = 0.521606\tKL_Divergence = 1.888520\n",
      "Epoch: 15\tFidelity = 0.522016\tKL_Divergence = 1.877936\n",
      "Epoch: 16\tFidelity = 0.520821\tKL_Divergence = 1.909399\n",
      "Epoch: 17\tFidelity = 0.520784\tKL_Divergence = 1.910399\n",
      "Epoch: 18\tFidelity = 0.522532\tKL_Divergence = 1.864875\n",
      "Epoch: 19\tFidelity = 0.519649\tKL_Divergence = 1.942060\n",
      "Epoch: 20\tFidelity = 0.522682\tKL_Divergence = 1.861128\n",
      "Epoch: 21\tFidelity = 0.519783\tKL_Divergence = 1.938217\n",
      "Epoch: 22\tFidelity = 0.523649\tKL_Divergence = 1.837539\n",
      "Epoch: 23\tFidelity = 0.519385\tKL_Divergence = 1.949675\n",
      "Epoch: 24\tFidelity = 0.521506\tKL_Divergence = 1.891160\n",
      "Epoch: 25\tFidelity = 0.521360\tKL_Divergence = 1.895012\n",
      "Epoch: 26\tFidelity = 0.522766\tKL_Divergence = 1.859054\n",
      "Epoch: 27\tFidelity = 0.519209\tKL_Divergence = 1.954811\n",
      "Epoch: 28\tFidelity = 0.521009\tKL_Divergence = 1.904359\n",
      "Epoch: 29\tFidelity = 0.520409\tKL_Divergence = 1.920678\n",
      "Epoch: 30\tFidelity = 0.521407\tKL_Divergence = 1.893786\n",
      "Epoch: 31\tFidelity = 0.521012\tKL_Divergence = 1.904264\n",
      "Epoch: 32\tFidelity = 0.519889\tKL_Divergence = 1.935211\n",
      "Epoch: 33\tFidelity = 0.521842\tKL_Divergence = 1.882423\n",
      "Epoch: 34\tFidelity = 0.519714\tKL_Divergence = 1.940198\n",
      "Epoch: 35\tFidelity = 0.521997\tKL_Divergence = 1.878438\n",
      "Epoch: 36\tFidelity = 0.520303\tKL_Divergence = 1.923628\n",
      "Epoch: 37\tFidelity = 0.521217\tKL_Divergence = 1.898814\n",
      "Epoch: 38\tFidelity = 0.520743\tKL_Divergence = 1.911550\n",
      "Epoch: 39\tFidelity = 0.522747\tKL_Divergence = 1.859517\n",
      "Epoch: 40\tFidelity = 0.519582\tKL_Divergence = 1.943981\n",
      "Epoch: 41\tFidelity = 0.520993\tKL_Divergence = 1.904791\n",
      "Epoch: 42\tFidelity = 0.521559\tKL_Divergence = 1.889797\n",
      "Epoch: 43\tFidelity = 0.520509\tKL_Divergence = 1.917918\n",
      "Epoch: 44\tFidelity = 0.521336\tKL_Divergence = 1.895655\n",
      "Epoch: 45\tFidelity = 0.519688\tKL_Divergence = 1.940931\n",
      "Epoch: 46\tFidelity = 0.522074\tKL_Divergence = 1.876457\n",
      "Epoch: 47\tFidelity = 0.521133\tKL_Divergence = 1.901029\n",
      "Epoch: 48\tFidelity = 0.521241\tKL_Divergence = 1.898156\n",
      "Epoch: 49\tFidelity = 0.521289\tKL_Divergence = 1.896893\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:07:11,958] Trial 115 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.522976\tKL_Divergence = 1.853859\n",
      "Total time elapsed during training: 30.891 s\n",
      "Trial 115 pruned. \n",
      "Epoch: 1\tFidelity = 0.519701\tKL_Divergence = 1.940562\n",
      "Epoch: 2\tFidelity = 0.523390\tKL_Divergence = 1.843766\n",
      "Epoch: 3\tFidelity = 0.521645\tKL_Divergence = 1.887556\n",
      "Epoch: 4\tFidelity = 0.520213\tKL_Divergence = 1.926138\n",
      "Epoch: 5\tFidelity = 0.519927\tKL_Divergence = 1.934143\n",
      "Epoch: 6\tFidelity = 0.520034\tKL_Divergence = 1.931148\n",
      "Epoch: 7\tFidelity = 0.521627\tKL_Divergence = 1.888020\n",
      "Epoch: 8\tFidelity = 0.522758\tKL_Divergence = 1.859251\n",
      "Epoch: 9\tFidelity = 0.519989\tKL_Divergence = 1.932394\n",
      "Epoch: 10\tFidelity = 0.521679\tKL_Divergence = 1.886653\n",
      "Epoch: 11\tFidelity = 0.521987\tKL_Divergence = 1.878712\n",
      "Epoch: 12\tFidelity = 0.522121\tKL_Divergence = 1.875282\n",
      "Epoch: 13\tFidelity = 0.520465\tKL_Divergence = 1.919145\n",
      "Epoch: 14\tFidelity = 0.520700\tKL_Divergence = 1.912716\n",
      "Epoch: 15\tFidelity = 0.520259\tKL_Divergence = 1.924850\n",
      "Epoch: 16\tFidelity = 0.523289\tKL_Divergence = 1.846214\n",
      "Epoch: 17\tFidelity = 0.521694\tKL_Divergence = 1.886268\n",
      "Epoch: 18\tFidelity = 0.520054\tKL_Divergence = 1.930588\n",
      "Epoch: 19\tFidelity = 0.522047\tKL_Divergence = 1.877178\n",
      "Epoch: 20\tFidelity = 0.520518\tKL_Divergence = 1.917699\n",
      "Epoch: 21\tFidelity = 0.521183\tKL_Divergence = 1.899705\n",
      "Epoch: 22\tFidelity = 0.522828\tKL_Divergence = 1.857522\n",
      "Epoch: 23\tFidelity = 0.522217\tKL_Divergence = 1.872820\n",
      "Epoch: 24\tFidelity = 0.520381\tKL_Divergence = 1.921472\n",
      "Epoch: 25\tFidelity = 0.523403\tKL_Divergence = 1.843456\n",
      "Epoch: 26\tFidelity = 0.522465\tKL_Divergence = 1.866556\n",
      "Epoch: 27\tFidelity = 0.518836\tKL_Divergence = 1.965843\n",
      "Epoch: 28\tFidelity = 0.521528\tKL_Divergence = 1.890582\n",
      "Epoch: 29\tFidelity = 0.519382\tKL_Divergence = 1.949768\n",
      "Epoch: 30\tFidelity = 0.521729\tKL_Divergence = 1.885357\n",
      "Epoch: 31\tFidelity = 0.522067\tKL_Divergence = 1.876650\n",
      "Epoch: 32\tFidelity = 0.521685\tKL_Divergence = 1.886487\n",
      "Epoch: 33\tFidelity = 0.521290\tKL_Divergence = 1.896866\n",
      "Epoch: 34\tFidelity = 0.519617\tKL_Divergence = 1.942974\n",
      "Epoch: 35\tFidelity = 0.522477\tKL_Divergence = 1.866258\n",
      "Epoch: 36\tFidelity = 0.521103\tKL_Divergence = 1.901842\n",
      "Epoch: 37\tFidelity = 0.519159\tKL_Divergence = 1.956268\n",
      "Epoch: 38\tFidelity = 0.520596\tKL_Divergence = 1.915540\n",
      "Epoch: 39\tFidelity = 0.522045\tKL_Divergence = 1.877226\n",
      "Epoch: 40\tFidelity = 0.523275\tKL_Divergence = 1.846558\n",
      "Epoch: 41\tFidelity = 0.520698\tKL_Divergence = 1.912756\n",
      "Epoch: 42\tFidelity = 0.521875\tKL_Divergence = 1.881596\n",
      "Epoch: 43\tFidelity = 0.521998\tKL_Divergence = 1.878427\n",
      "Epoch: 44\tFidelity = 0.519799\tKL_Divergence = 1.937774\n",
      "Epoch: 45\tFidelity = 0.522924\tKL_Divergence = 1.855163\n",
      "Epoch: 46\tFidelity = 0.521101\tKL_Divergence = 1.901904\n",
      "Epoch: 47\tFidelity = 0.521778\tKL_Divergence = 1.884080\n",
      "Epoch: 48\tFidelity = 0.519964\tKL_Divergence = 1.933089\n",
      "Epoch: 49\tFidelity = 0.522676\tKL_Divergence = 1.861268\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:07:50,126] Trial 116 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.521011\tKL_Divergence = 1.904296\n",
      "Total time elapsed during training: 38.025 s\n",
      "Trial 116 pruned. \n",
      "Epoch: 1\tFidelity = 0.519292\tKL_Divergence = 1.952377\n",
      "Epoch: 2\tFidelity = 0.520509\tKL_Divergence = 1.917926\n",
      "Epoch: 3\tFidelity = 0.524317\tKL_Divergence = 1.821831\n",
      "Epoch: 4\tFidelity = 0.521354\tKL_Divergence = 1.895182\n",
      "Epoch: 5\tFidelity = 0.519946\tKL_Divergence = 1.933605\n",
      "Epoch: 6\tFidelity = 0.520478\tKL_Divergence = 1.918779\n",
      "Epoch: 7\tFidelity = 0.520985\tKL_Divergence = 1.904992\n",
      "Epoch: 8\tFidelity = 0.519400\tKL_Divergence = 1.949242\n",
      "Epoch: 9\tFidelity = 0.519756\tKL_Divergence = 1.938998\n",
      "Epoch: 10\tFidelity = 0.522519\tKL_Divergence = 1.865209\n",
      "Epoch: 11\tFidelity = 0.522368\tKL_Divergence = 1.868983\n",
      "Epoch: 12\tFidelity = 0.520725\tKL_Divergence = 1.912011\n",
      "Epoch: 13\tFidelity = 0.523294\tKL_Divergence = 1.846087\n",
      "Epoch: 14\tFidelity = 0.523812\tKL_Divergence = 1.833670\n",
      "Epoch: 15\tFidelity = 0.519910\tKL_Divergence = 1.934630\n",
      "Epoch: 16\tFidelity = 0.523952\tKL_Divergence = 1.830357\n",
      "Epoch: 17\tFidelity = 0.522979\tKL_Divergence = 1.853777\n",
      "Epoch: 18\tFidelity = 0.522954\tKL_Divergence = 1.854405\n",
      "Epoch: 19\tFidelity = 0.521085\tKL_Divergence = 1.902311\n",
      "Epoch: 20\tFidelity = 0.521111\tKL_Divergence = 1.901625\n",
      "Epoch: 21\tFidelity = 0.522566\tKL_Divergence = 1.864002\n",
      "Epoch: 22\tFidelity = 0.523002\tKL_Divergence = 1.853222\n",
      "Epoch: 23\tFidelity = 0.523895\tKL_Divergence = 1.831700\n",
      "Epoch: 24\tFidelity = 0.521493\tKL_Divergence = 1.891505\n",
      "Epoch: 25\tFidelity = 0.520488\tKL_Divergence = 1.918491\n",
      "Epoch: 26\tFidelity = 0.520758\tKL_Divergence = 1.911107\n",
      "Epoch: 27\tFidelity = 0.522111\tKL_Divergence = 1.875458\n",
      "Epoch: 28\tFidelity = 0.520050\tKL_Divergence = 1.930647\n",
      "Epoch: 29\tFidelity = 0.520233\tKL_Divergence = 1.925537\n",
      "Epoch: 30\tFidelity = 0.521105\tKL_Divergence = 1.901750\n",
      "Epoch: 31\tFidelity = 0.522248\tKL_Divergence = 1.872027\n",
      "Epoch: 32\tFidelity = 0.521014\tKL_Divergence = 1.904191\n",
      "Epoch: 33\tFidelity = 0.520271\tKL_Divergence = 1.924497\n",
      "Epoch: 34\tFidelity = 0.522879\tKL_Divergence = 1.856261\n",
      "Epoch: 35\tFidelity = 0.521834\tKL_Divergence = 1.882629\n",
      "Epoch: 36\tFidelity = 0.519176\tKL_Divergence = 1.955770\n",
      "Epoch: 37\tFidelity = 0.522582\tKL_Divergence = 1.863645\n",
      "Epoch: 38\tFidelity = 0.520456\tKL_Divergence = 1.919414\n",
      "Epoch: 39\tFidelity = 0.522042\tKL_Divergence = 1.877301\n",
      "Epoch: 40\tFidelity = 0.520942\tKL_Divergence = 1.906183\n",
      "Epoch: 41\tFidelity = 0.520528\tKL_Divergence = 1.917425\n",
      "Epoch: 42\tFidelity = 0.521995\tKL_Divergence = 1.878515\n",
      "Epoch: 43\tFidelity = 0.521196\tKL_Divergence = 1.899377\n",
      "Epoch: 44\tFidelity = 0.522144\tKL_Divergence = 1.874682\n",
      "Epoch: 45\tFidelity = 0.522180\tKL_Divergence = 1.873778\n",
      "Epoch: 46\tFidelity = 0.519455\tKL_Divergence = 1.947682\n",
      "Epoch: 47\tFidelity = 0.521112\tKL_Divergence = 1.901617\n",
      "Epoch: 48\tFidelity = 0.520801\tKL_Divergence = 1.909975\n",
      "Epoch: 49\tFidelity = 0.520957\tKL_Divergence = 1.905759\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:08:28,811] Trial 117 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.521046\tKL_Divergence = 1.903378\n",
      "Total time elapsed during training: 38.534 s\n",
      "Trial 117 pruned. \n",
      "Epoch: 1\tFidelity = 0.520974\tKL_Divergence = 1.905268\n",
      "Epoch: 2\tFidelity = 0.520818\tKL_Divergence = 1.909509\n",
      "Epoch: 3\tFidelity = 0.519936\tKL_Divergence = 1.933887\n",
      "Epoch: 4\tFidelity = 0.522481\tKL_Divergence = 1.866089\n",
      "Epoch: 5\tFidelity = 0.522653\tKL_Divergence = 1.861851\n",
      "Epoch: 6\tFidelity = 0.522300\tKL_Divergence = 1.870703\n",
      "Epoch: 7\tFidelity = 0.521201\tKL_Divergence = 1.899232\n",
      "Epoch: 8\tFidelity = 0.523124\tKL_Divergence = 1.850234\n",
      "Epoch: 9\tFidelity = 0.521185\tKL_Divergence = 1.899673\n",
      "Epoch: 10\tFidelity = 0.516687\tKL_Divergence = 2.033987\n",
      "Epoch: 11\tFidelity = 0.517360\tKL_Divergence = 2.011749\n",
      "Epoch: 12\tFidelity = 0.524462\tKL_Divergence = 1.818449\n",
      "Epoch: 13\tFidelity = 0.521181\tKL_Divergence = 1.899740\n",
      "Epoch: 14\tFidelity = 0.519525\tKL_Divergence = 1.945661\n",
      "Epoch: 15\tFidelity = 0.521459\tKL_Divergence = 1.892455\n",
      "Epoch: 16\tFidelity = 0.523359\tKL_Divergence = 1.844546\n",
      "Epoch: 17\tFidelity = 0.522999\tKL_Divergence = 1.853334\n",
      "Epoch: 18\tFidelity = 0.521020\tKL_Divergence = 1.904079\n",
      "Epoch: 19\tFidelity = 0.520810\tKL_Divergence = 1.909747\n",
      "Epoch: 20\tFidelity = 0.523644\tKL_Divergence = 1.837643\n",
      "Epoch: 21\tFidelity = 0.520335\tKL_Divergence = 1.922664\n",
      "Epoch: 22\tFidelity = 0.519900\tKL_Divergence = 1.934933\n",
      "Epoch: 23\tFidelity = 0.520016\tKL_Divergence = 1.931669\n",
      "Epoch: 24\tFidelity = 0.523291\tKL_Divergence = 1.846141\n",
      "Epoch: 25\tFidelity = 0.520492\tKL_Divergence = 1.918345\n",
      "Epoch: 26\tFidelity = 0.519995\tKL_Divergence = 1.932216\n",
      "Epoch: 27\tFidelity = 0.518380\tKL_Divergence = 1.979641\n",
      "Epoch: 28\tFidelity = 0.521323\tKL_Divergence = 1.895972\n",
      "Epoch: 29\tFidelity = 0.519589\tKL_Divergence = 1.943734\n",
      "Epoch: 30\tFidelity = 0.520960\tKL_Divergence = 1.905605\n",
      "Epoch: 31\tFidelity = 0.519803\tKL_Divergence = 1.937640\n",
      "Epoch: 32\tFidelity = 0.521272\tKL_Divergence = 1.897309\n",
      "Epoch: 33\tFidelity = 0.520345\tKL_Divergence = 1.922456\n",
      "Epoch: 34\tFidelity = 0.524712\tKL_Divergence = 1.812691\n",
      "Epoch: 35\tFidelity = 0.524278\tKL_Divergence = 1.822641\n",
      "Epoch: 36\tFidelity = 0.518609\tKL_Divergence = 1.972605\n",
      "Epoch: 37\tFidelity = 0.520656\tKL_Divergence = 1.913732\n",
      "Epoch: 38\tFidelity = 0.520295\tKL_Divergence = 1.923801\n",
      "Epoch: 39\tFidelity = 0.522459\tKL_Divergence = 1.866643\n",
      "Epoch: 40\tFidelity = 0.522465\tKL_Divergence = 1.866569\n",
      "Epoch: 41\tFidelity = 0.520085\tKL_Divergence = 1.929711\n",
      "Epoch: 42\tFidelity = 0.520676\tKL_Divergence = 1.913369\n",
      "Epoch: 43\tFidelity = 0.525007\tKL_Divergence = 1.806007\n",
      "Epoch: 44\tFidelity = 0.518820\tKL_Divergence = 1.966361\n",
      "Epoch: 45\tFidelity = 0.522614\tKL_Divergence = 1.862812\n",
      "Epoch: 46\tFidelity = 0.522753\tKL_Divergence = 1.859396\n",
      "Epoch: 47\tFidelity = 0.520480\tKL_Divergence = 1.918715\n",
      "Epoch: 48\tFidelity = 0.522572\tKL_Divergence = 1.863859\n",
      "Epoch: 49\tFidelity = 0.521165\tKL_Divergence = 1.900200\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:09:12,405] Trial 118 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.521107\tKL_Divergence = 1.901775\n",
      "Total time elapsed during training: 43.446 s\n",
      "Trial 118 pruned. \n",
      "Epoch: 1\tFidelity = 0.519504\tKL_Divergence = 1.946260\n",
      "Epoch: 2\tFidelity = 0.519457\tKL_Divergence = 1.947614\n",
      "Epoch: 3\tFidelity = 0.525912\tKL_Divergence = 1.785909\n",
      "Epoch: 4\tFidelity = 0.518462\tKL_Divergence = 1.977137\n",
      "Epoch: 5\tFidelity = 0.521126\tKL_Divergence = 1.901217\n",
      "Epoch: 6\tFidelity = 0.519969\tKL_Divergence = 1.932954\n",
      "Epoch: 7\tFidelity = 0.519925\tKL_Divergence = 1.934227\n",
      "Epoch: 8\tFidelity = 0.523125\tKL_Divergence = 1.850235\n",
      "Epoch: 9\tFidelity = 0.520905\tKL_Divergence = 1.907160\n",
      "Epoch: 10\tFidelity = 0.522258\tKL_Divergence = 1.871790\n",
      "Epoch: 11\tFidelity = 0.520042\tKL_Divergence = 1.930917\n",
      "Epoch: 12\tFidelity = 0.520299\tKL_Divergence = 1.923737\n",
      "Epoch: 13\tFidelity = 0.523148\tKL_Divergence = 1.849642\n",
      "Epoch: 14\tFidelity = 0.521971\tKL_Divergence = 1.879092\n",
      "Epoch: 15\tFidelity = 0.518546\tKL_Divergence = 1.974577\n",
      "Epoch: 16\tFidelity = 0.521561\tKL_Divergence = 1.889701\n",
      "Epoch: 17\tFidelity = 0.522498\tKL_Divergence = 1.865711\n",
      "Epoch: 18\tFidelity = 0.523654\tKL_Divergence = 1.837399\n",
      "Epoch: 19\tFidelity = 0.522700\tKL_Divergence = 1.860651\n",
      "Epoch: 20\tFidelity = 0.520608\tKL_Divergence = 1.915162\n",
      "Epoch: 21\tFidelity = 0.522401\tKL_Divergence = 1.868107\n",
      "Epoch: 22\tFidelity = 0.525391\tKL_Divergence = 1.797334\n",
      "Epoch: 23\tFidelity = 0.521144\tKL_Divergence = 1.900703\n",
      "Epoch: 24\tFidelity = 0.521321\tKL_Divergence = 1.895984\n",
      "Epoch: 25\tFidelity = 0.519387\tKL_Divergence = 1.949542\n",
      "Epoch: 26\tFidelity = 0.520699\tKL_Divergence = 1.912670\n",
      "Epoch: 27\tFidelity = 0.524347\tKL_Divergence = 1.821050\n",
      "Epoch: 28\tFidelity = 0.520937\tKL_Divergence = 1.906209\n",
      "Epoch: 29\tFidelity = 0.522336\tKL_Divergence = 1.869716\n",
      "Epoch: 30\tFidelity = 0.521597\tKL_Divergence = 1.888705\n",
      "Epoch: 31\tFidelity = 0.522166\tKL_Divergence = 1.874035\n",
      "Epoch: 32\tFidelity = 0.522583\tKL_Divergence = 1.863499\n",
      "Epoch: 33\tFidelity = 0.521276\tKL_Divergence = 1.897143\n",
      "Epoch: 34\tFidelity = 0.522381\tKL_Divergence = 1.868602\n",
      "Epoch: 35\tFidelity = 0.523220\tKL_Divergence = 1.847838\n",
      "Epoch: 36\tFidelity = 0.522360\tKL_Divergence = 1.869127\n",
      "Epoch: 37\tFidelity = 0.521326\tKL_Divergence = 1.895835\n",
      "Epoch: 38\tFidelity = 0.524874\tKL_Divergence = 1.808919\n",
      "Epoch: 39\tFidelity = 0.524322\tKL_Divergence = 1.821582\n",
      "Epoch: 40\tFidelity = 0.524550\tKL_Divergence = 1.816325\n",
      "Epoch: 41\tFidelity = 0.524775\tKL_Divergence = 1.811171\n",
      "Epoch: 42\tFidelity = 0.521300\tKL_Divergence = 1.896516\n",
      "Epoch: 43\tFidelity = 0.524892\tKL_Divergence = 1.808529\n",
      "Epoch: 44\tFidelity = 0.522725\tKL_Divergence = 1.859965\n",
      "Epoch: 45\tFidelity = 0.525070\tKL_Divergence = 1.804490\n",
      "Epoch: 46\tFidelity = 0.519525\tKL_Divergence = 1.945530\n",
      "Epoch: 47\tFidelity = 0.523431\tKL_Divergence = 1.842699\n",
      "Epoch: 48\tFidelity = 0.522806\tKL_Divergence = 1.857957\n",
      "Epoch: 49\tFidelity = 0.521067\tKL_Divergence = 1.902729\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:09:56,261] Trial 119 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.520938\tKL_Divergence = 1.906192\n",
      "Total time elapsed during training: 43.713 s\n",
      "Trial 119 pruned. \n",
      "Epoch: 1\tFidelity = 0.520336\tKL_Divergence = 1.922638\n",
      "Epoch: 2\tFidelity = 0.523257\tKL_Divergence = 1.846792\n",
      "Epoch: 3\tFidelity = 0.523798\tKL_Divergence = 1.833350\n",
      "Epoch: 4\tFidelity = 0.524690\tKL_Divergence = 1.812683\n",
      "Epoch: 5\tFidelity = 0.522653\tKL_Divergence = 1.861695\n",
      "Epoch: 6\tFidelity = 0.524187\tKL_Divergence = 1.824786\n",
      "Epoch: 7\tFidelity = 0.517942\tKL_Divergence = 1.993156\n",
      "Epoch: 8\tFidelity = 0.519466\tKL_Divergence = 1.947289\n",
      "Epoch: 9\tFidelity = 0.521916\tKL_Divergence = 1.880492\n",
      "Epoch: 10\tFidelity = 0.524928\tKL_Divergence = 1.807737\n",
      "Epoch: 11\tFidelity = 0.519428\tKL_Divergence = 1.948364\n",
      "Epoch: 12\tFidelity = 0.521643\tKL_Divergence = 1.887404\n",
      "Epoch: 13\tFidelity = 0.518277\tKL_Divergence = 1.982670\n",
      "Epoch: 14\tFidelity = 0.522290\tKL_Divergence = 1.870921\n",
      "Epoch: 15\tFidelity = 0.521980\tKL_Divergence = 1.878761\n",
      "Epoch: 16\tFidelity = 0.521728\tKL_Divergence = 1.885115\n",
      "Epoch: 17\tFidelity = 0.520664\tKL_Divergence = 1.913485\n",
      "Epoch: 18\tFidelity = 0.518680\tKL_Divergence = 1.970458\n",
      "Epoch: 19\tFidelity = 0.525305\tKL_Divergence = 1.799214\n",
      "Epoch: 20\tFidelity = 0.519189\tKL_Divergence = 1.955032\n",
      "Epoch: 21\tFidelity = 0.521282\tKL_Divergence = 1.896990\n",
      "Epoch: 22\tFidelity = 0.522571\tKL_Divergence = 1.863768\n",
      "Epoch: 23\tFidelity = 0.523054\tKL_Divergence = 1.851735\n",
      "Epoch: 24\tFidelity = 0.520932\tKL_Divergence = 1.906383\n",
      "Epoch: 25\tFidelity = 0.522567\tKL_Divergence = 1.863841\n",
      "Epoch: 26\tFidelity = 0.520084\tKL_Divergence = 1.929223\n",
      "Epoch: 27\tFidelity = 0.522580\tKL_Divergence = 1.863469\n",
      "Epoch: 28\tFidelity = 0.521980\tKL_Divergence = 1.878658\n",
      "Epoch: 29\tFidelity = 0.521436\tKL_Divergence = 1.892742\n",
      "Epoch: 30\tFidelity = 0.523043\tKL_Divergence = 1.851829\n",
      "Epoch: 31\tFidelity = 0.524138\tKL_Divergence = 1.825877\n",
      "Epoch: 32\tFidelity = 0.520560\tKL_Divergence = 1.916440\n",
      "Epoch: 33\tFidelity = 0.519920\tKL_Divergence = 1.934214\n",
      "Epoch: 34\tFidelity = 0.518124\tKL_Divergence = 1.987348\n",
      "Epoch: 35\tFidelity = 0.521761\tKL_Divergence = 1.884431\n",
      "Epoch: 36\tFidelity = 0.527021\tKL_Divergence = 1.762066\n",
      "Epoch: 37\tFidelity = 0.525806\tKL_Divergence = 1.788078\n",
      "Epoch: 38\tFidelity = 0.522603\tKL_Divergence = 1.863059\n",
      "Epoch: 39\tFidelity = 0.520045\tKL_Divergence = 1.930788\n",
      "Epoch: 40\tFidelity = 0.524003\tKL_Divergence = 1.829015\n",
      "Epoch: 41\tFidelity = 0.520065\tKL_Divergence = 1.930124\n",
      "Epoch: 42\tFidelity = 0.522906\tKL_Divergence = 1.855538\n",
      "Epoch: 43\tFidelity = 0.521500\tKL_Divergence = 1.891313\n",
      "Epoch: 44\tFidelity = 0.521174\tKL_Divergence = 1.899920\n",
      "Epoch: 45\tFidelity = 0.522701\tKL_Divergence = 1.860637\n",
      "Epoch: 46\tFidelity = 0.521121\tKL_Divergence = 1.901228\n",
      "Epoch: 47\tFidelity = 0.521448\tKL_Divergence = 1.892498\n",
      "Epoch: 48\tFidelity = 0.520728\tKL_Divergence = 1.911678\n",
      "Epoch: 49\tFidelity = 0.524623\tKL_Divergence = 1.814694\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:10:33,006] Trial 120 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.522236\tKL_Divergence = 1.872278\n",
      "Total time elapsed during training: 36.606 s\n",
      "Trial 120 pruned. \n",
      "Epoch: 1\tFidelity = 0.519755\tKL_Divergence = 1.938898\n",
      "Epoch: 2\tFidelity = 0.523009\tKL_Divergence = 1.852889\n",
      "Epoch: 3\tFidelity = 0.518489\tKL_Divergence = 1.975495\n",
      "Epoch: 4\tFidelity = 0.518202\tKL_Divergence = 1.985071\n",
      "Epoch: 5\tFidelity = 0.518995\tKL_Divergence = 1.961082\n",
      "Epoch: 6\tFidelity = 0.524233\tKL_Divergence = 1.823650\n",
      "Epoch: 7\tFidelity = 0.520236\tKL_Divergence = 1.925439\n",
      "Epoch: 8\tFidelity = 0.521219\tKL_Divergence = 1.898660\n",
      "Epoch: 9\tFidelity = 0.525834\tKL_Divergence = 1.787426\n",
      "Epoch: 10\tFidelity = 0.520307\tKL_Divergence = 1.923440\n",
      "Epoch: 11\tFidelity = 0.521987\tKL_Divergence = 1.878573\n",
      "Epoch: 12\tFidelity = 0.523755\tKL_Divergence = 1.834892\n",
      "Epoch: 13\tFidelity = 0.522687\tKL_Divergence = 1.860837\n",
      "Epoch: 14\tFidelity = 0.518523\tKL_Divergence = 1.975220\n",
      "Epoch: 15\tFidelity = 0.520836\tKL_Divergence = 1.908942\n",
      "Epoch: 16\tFidelity = 0.520095\tKL_Divergence = 1.929241\n",
      "Epoch: 17\tFidelity = 0.521614\tKL_Divergence = 1.888286\n",
      "Epoch: 18\tFidelity = 0.525246\tKL_Divergence = 1.800327\n",
      "Epoch: 19\tFidelity = 0.519834\tKL_Divergence = 1.936748\n",
      "Epoch: 20\tFidelity = 0.522723\tKL_Divergence = 1.859758\n",
      "Epoch: 21\tFidelity = 0.523376\tKL_Divergence = 1.844116\n",
      "Epoch: 22\tFidelity = 0.522718\tKL_Divergence = 1.859865\n",
      "Epoch: 23\tFidelity = 0.521791\tKL_Divergence = 1.883743\n",
      "Epoch: 24\tFidelity = 0.520482\tKL_Divergence = 1.918682\n",
      "Epoch: 25\tFidelity = 0.523547\tKL_Divergence = 1.840012\n",
      "Epoch: 26\tFidelity = 0.527094\tKL_Divergence = 1.760580\n",
      "Epoch: 27\tFidelity = 0.527770\tKL_Divergence = 1.746665\n",
      "Epoch: 28\tFidelity = 0.523271\tKL_Divergence = 1.846657\n",
      "Epoch: 29\tFidelity = 0.520792\tKL_Divergence = 1.910141\n",
      "Epoch: 30\tFidelity = 0.518162\tKL_Divergence = 1.986362\n",
      "Epoch: 31\tFidelity = 0.525741\tKL_Divergence = 1.789652\n",
      "Epoch: 32\tFidelity = 0.520912\tKL_Divergence = 1.906933\n",
      "Epoch: 33\tFidelity = 0.522832\tKL_Divergence = 1.857264\n",
      "Epoch: 34\tFidelity = 0.523773\tKL_Divergence = 1.834300\n",
      "Epoch: 35\tFidelity = 0.520239\tKL_Divergence = 1.925298\n",
      "Epoch: 36\tFidelity = 0.524840\tKL_Divergence = 1.809612\n",
      "Epoch: 37\tFidelity = 0.521209\tKL_Divergence = 1.898926\n",
      "Epoch: 38\tFidelity = 0.524968\tKL_Divergence = 1.806857\n",
      "Epoch: 39\tFidelity = 0.521887\tKL_Divergence = 1.881215\n",
      "Epoch: 40\tFidelity = 0.519497\tKL_Divergence = 1.946436\n",
      "Epoch: 41\tFidelity = 0.523547\tKL_Divergence = 1.840028\n",
      "Epoch: 42\tFidelity = 0.521896\tKL_Divergence = 1.880911\n",
      "Epoch: 43\tFidelity = 0.522308\tKL_Divergence = 1.870497\n",
      "Epoch: 44\tFidelity = 0.521424\tKL_Divergence = 1.893287\n",
      "Epoch: 45\tFidelity = 0.521123\tKL_Divergence = 1.901325\n",
      "Epoch: 46\tFidelity = 0.519819\tKL_Divergence = 1.937207\n",
      "Epoch: 47\tFidelity = 0.519708\tKL_Divergence = 1.940388\n",
      "Epoch: 48\tFidelity = 0.522933\tKL_Divergence = 1.854812\n",
      "Epoch: 49\tFidelity = 0.521244\tKL_Divergence = 1.898113\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:11:50,102] Trial 121 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.516975\tKL_Divergence = 2.024231\n",
      "Total time elapsed during training: 76.922 s\n",
      "Trial 121 pruned. \n",
      "Epoch: 1\tFidelity = 0.521115\tKL_Divergence = 1.901443\n",
      "Epoch: 2\tFidelity = 0.520009\tKL_Divergence = 1.931866\n",
      "Epoch: 3\tFidelity = 0.521553\tKL_Divergence = 1.889962\n",
      "Epoch: 4\tFidelity = 0.520709\tKL_Divergence = 1.912377\n",
      "Epoch: 5\tFidelity = 0.520658\tKL_Divergence = 1.913774\n",
      "Epoch: 6\tFidelity = 0.518205\tKL_Divergence = 1.985011\n",
      "Epoch: 7\tFidelity = 0.521096\tKL_Divergence = 1.902062\n",
      "Epoch: 8\tFidelity = 0.520328\tKL_Divergence = 1.922973\n",
      "Epoch: 9\tFidelity = 0.521089\tKL_Divergence = 1.902235\n",
      "Epoch: 10\tFidelity = 0.521596\tKL_Divergence = 1.888755\n",
      "Epoch: 11\tFidelity = 0.522135\tKL_Divergence = 1.874877\n",
      "Epoch: 12\tFidelity = 0.522345\tKL_Divergence = 1.869489\n",
      "Epoch: 13\tFidelity = 0.521931\tKL_Divergence = 1.879960\n",
      "Epoch: 14\tFidelity = 0.522718\tKL_Divergence = 1.860246\n",
      "Epoch: 15\tFidelity = 0.523652\tKL_Divergence = 1.837515\n",
      "Epoch: 16\tFidelity = 0.520741\tKL_Divergence = 1.911605\n",
      "Epoch: 17\tFidelity = 0.519452\tKL_Divergence = 1.947774\n",
      "Epoch: 18\tFidelity = 0.519821\tKL_Divergence = 1.937162\n",
      "Epoch: 19\tFidelity = 0.522601\tKL_Divergence = 1.863126\n",
      "Epoch: 20\tFidelity = 0.521360\tKL_Divergence = 1.895048\n",
      "Epoch: 21\tFidelity = 0.519350\tKL_Divergence = 1.950750\n",
      "Epoch: 22\tFidelity = 0.520719\tKL_Divergence = 1.912243\n",
      "Epoch: 23\tFidelity = 0.521561\tKL_Divergence = 1.889792\n",
      "Epoch: 24\tFidelity = 0.521101\tKL_Divergence = 1.901928\n",
      "Epoch: 25\tFidelity = 0.521591\tKL_Divergence = 1.888988\n",
      "Epoch: 26\tFidelity = 0.521610\tKL_Divergence = 1.888498\n",
      "Epoch: 27\tFidelity = 0.520834\tKL_Divergence = 1.909094\n",
      "Epoch: 28\tFidelity = 0.521778\tKL_Divergence = 1.884143\n",
      "Epoch: 29\tFidelity = 0.523274\tKL_Divergence = 1.846596\n",
      "Epoch: 30\tFidelity = 0.522951\tKL_Divergence = 1.854540\n",
      "Epoch: 31\tFidelity = 0.523344\tKL_Divergence = 1.844886\n",
      "Epoch: 32\tFidelity = 0.521760\tKL_Divergence = 1.884608\n",
      "Epoch: 33\tFidelity = 0.519590\tKL_Divergence = 1.943796\n",
      "Epoch: 34\tFidelity = 0.522519\tKL_Divergence = 1.865258\n",
      "Epoch: 35\tFidelity = 0.520008\tKL_Divergence = 1.931857\n",
      "Epoch: 36\tFidelity = 0.524141\tKL_Divergence = 1.825943\n",
      "Epoch: 37\tFidelity = 0.521453\tKL_Divergence = 1.892633\n",
      "Epoch: 38\tFidelity = 0.520669\tKL_Divergence = 1.913601\n",
      "Epoch: 39\tFidelity = 0.520095\tKL_Divergence = 1.929354\n",
      "Epoch: 40\tFidelity = 0.523266\tKL_Divergence = 1.846816\n",
      "Epoch: 41\tFidelity = 0.520520\tKL_Divergence = 1.917533\n",
      "Epoch: 42\tFidelity = 0.521763\tKL_Divergence = 1.884497\n",
      "Epoch: 43\tFidelity = 0.520944\tKL_Divergence = 1.906133\n",
      "Epoch: 44\tFidelity = 0.520642\tKL_Divergence = 1.914310\n",
      "Epoch: 45\tFidelity = 0.519326\tKL_Divergence = 1.951413\n",
      "Epoch: 46\tFidelity = 0.520845\tKL_Divergence = 1.908831\n",
      "Epoch: 47\tFidelity = 0.519415\tKL_Divergence = 1.948806\n",
      "Epoch: 48\tFidelity = 0.518809\tKL_Divergence = 1.966700\n",
      "Epoch: 49\tFidelity = 0.520790\tKL_Divergence = 1.910313\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:13:08,332] Trial 122 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.521103\tKL_Divergence = 1.901829\n",
      "Total time elapsed during training: 78.086 s\n",
      "Trial 122 pruned. \n",
      "Epoch: 1\tFidelity = 0.520468\tKL_Divergence = 1.919000\n",
      "Epoch: 2\tFidelity = 0.523772\tKL_Divergence = 1.834666\n",
      "Epoch: 3\tFidelity = 0.520188\tKL_Divergence = 1.926880\n",
      "Epoch: 4\tFidelity = 0.520901\tKL_Divergence = 1.907218\n",
      "Epoch: 5\tFidelity = 0.521467\tKL_Divergence = 1.892209\n",
      "Epoch: 6\tFidelity = 0.518613\tKL_Divergence = 1.972569\n",
      "Epoch: 7\tFidelity = 0.519638\tKL_Divergence = 1.942388\n",
      "Epoch: 8\tFidelity = 0.523044\tKL_Divergence = 1.852176\n",
      "Epoch: 9\tFidelity = 0.522102\tKL_Divergence = 1.875722\n",
      "Epoch: 10\tFidelity = 0.521299\tKL_Divergence = 1.896595\n",
      "Epoch: 11\tFidelity = 0.522352\tKL_Divergence = 1.869451\n",
      "Epoch: 12\tFidelity = 0.521631\tKL_Divergence = 1.887906\n",
      "Epoch: 13\tFidelity = 0.518619\tKL_Divergence = 1.972357\n",
      "Epoch: 14\tFidelity = 0.520869\tKL_Divergence = 1.908198\n",
      "Epoch: 15\tFidelity = 0.524258\tKL_Divergence = 1.823258\n",
      "Epoch: 16\tFidelity = 0.522828\tKL_Divergence = 1.857364\n",
      "Epoch: 17\tFidelity = 0.523068\tKL_Divergence = 1.851670\n",
      "Epoch: 18\tFidelity = 0.518750\tKL_Divergence = 1.968539\n",
      "Epoch: 19\tFidelity = 0.521942\tKL_Divergence = 1.879961\n",
      "Epoch: 20\tFidelity = 0.518551\tKL_Divergence = 1.974475\n",
      "Epoch: 21\tFidelity = 0.517878\tKL_Divergence = 1.995313\n",
      "Epoch: 22\tFidelity = 0.520691\tKL_Divergence = 1.913060\n",
      "Epoch: 23\tFidelity = 0.521349\tKL_Divergence = 1.895336\n",
      "Epoch: 24\tFidelity = 0.519923\tKL_Divergence = 1.934382\n",
      "Epoch: 25\tFidelity = 0.519379\tKL_Divergence = 1.949920\n",
      "Epoch: 26\tFidelity = 0.523931\tKL_Divergence = 1.830961\n",
      "Epoch: 27\tFidelity = 0.521318\tKL_Divergence = 1.896249\n",
      "Epoch: 28\tFidelity = 0.519454\tKL_Divergence = 1.947848\n",
      "Epoch: 29\tFidelity = 0.520765\tKL_Divergence = 1.911087\n",
      "Epoch: 30\tFidelity = 0.521726\tKL_Divergence = 1.885508\n",
      "Epoch: 31\tFidelity = 0.521714\tKL_Divergence = 1.885874\n",
      "Epoch: 32\tFidelity = 0.520512\tKL_Divergence = 1.918010\n",
      "Epoch: 33\tFidelity = 0.516818\tKL_Divergence = 2.029601\n",
      "Epoch: 34\tFidelity = 0.519583\tKL_Divergence = 1.944121\n",
      "Epoch: 35\tFidelity = 0.517699\tKL_Divergence = 2.001069\n",
      "Epoch: 36\tFidelity = 0.518938\tKL_Divergence = 1.963000\n",
      "Epoch: 37\tFidelity = 0.517967\tKL_Divergence = 1.992587\n",
      "Epoch: 38\tFidelity = 0.519093\tKL_Divergence = 1.958409\n",
      "Epoch: 39\tFidelity = 0.517554\tKL_Divergence = 2.005624\n",
      "Epoch: 40\tFidelity = 0.518941\tKL_Divergence = 1.962785\n",
      "Epoch: 41\tFidelity = 0.518379\tKL_Divergence = 1.979873\n",
      "Epoch: 42\tFidelity = 0.519577\tKL_Divergence = 1.944307\n",
      "Epoch: 43\tFidelity = 0.520852\tKL_Divergence = 1.908762\n",
      "Epoch: 44\tFidelity = 0.515414\tKL_Divergence = 2.078696\n",
      "Epoch: 45\tFidelity = 0.519163\tKL_Divergence = 1.956319\n",
      "Epoch: 46\tFidelity = 0.519611\tKL_Divergence = 1.943284\n",
      "Epoch: 47\tFidelity = 0.519658\tKL_Divergence = 1.941982\n",
      "Epoch: 48\tFidelity = 0.520779\tKL_Divergence = 1.910727\n",
      "Epoch: 49\tFidelity = 0.518409\tKL_Divergence = 1.978914\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:14:28,001] Trial 123 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.517714\tKL_Divergence = 2.000600\n",
      "Total time elapsed during training: 79.525 s\n",
      "Trial 123 pruned. \n",
      "Epoch: 1\tFidelity = 0.518552\tKL_Divergence = 1.974502\n",
      "Epoch: 2\tFidelity = 0.519445\tKL_Divergence = 1.948122\n",
      "Epoch: 3\tFidelity = 0.520220\tKL_Divergence = 1.926040\n",
      "Epoch: 4\tFidelity = 0.516688\tKL_Divergence = 2.034062\n",
      "Epoch: 5\tFidelity = 0.521029\tKL_Divergence = 1.903992\n",
      "Epoch: 6\tFidelity = 0.520768\tKL_Divergence = 1.911011\n",
      "Epoch: 7\tFidelity = 0.522456\tKL_Divergence = 1.866856\n",
      "Epoch: 8\tFidelity = 0.517924\tKL_Divergence = 1.993939\n",
      "Epoch: 9\tFidelity = 0.519342\tKL_Divergence = 1.951073\n",
      "Epoch: 10\tFidelity = 0.517382\tKL_Divergence = 2.011206\n",
      "Epoch: 11\tFidelity = 0.518336\tKL_Divergence = 1.981126\n",
      "Epoch: 12\tFidelity = 0.522244\tKL_Divergence = 1.872104\n",
      "Epoch: 13\tFidelity = 0.517366\tKL_Divergence = 2.011680\n",
      "Epoch: 14\tFidelity = 0.518284\tKL_Divergence = 1.982731\n",
      "Epoch: 15\tFidelity = 0.521822\tKL_Divergence = 1.883007\n",
      "Epoch: 16\tFidelity = 0.520638\tKL_Divergence = 1.914518\n",
      "Epoch: 17\tFidelity = 0.520983\tKL_Divergence = 1.905209\n",
      "Epoch: 18\tFidelity = 0.517598\tKL_Divergence = 2.004256\n",
      "Epoch: 19\tFidelity = 0.516786\tKL_Divergence = 2.030758\n",
      "Epoch: 20\tFidelity = 0.518823\tKL_Divergence = 1.966337\n",
      "Epoch: 21\tFidelity = 0.520220\tKL_Divergence = 1.925973\n",
      "Epoch: 22\tFidelity = 0.516766\tKL_Divergence = 2.031419\n",
      "Epoch: 23\tFidelity = 0.519216\tKL_Divergence = 1.954718\n",
      "Epoch: 24\tFidelity = 0.516418\tKL_Divergence = 2.043221\n",
      "Epoch: 25\tFidelity = 0.519151\tKL_Divergence = 1.956638\n",
      "Epoch: 26\tFidelity = 0.516962\tKL_Divergence = 2.024916\n",
      "Epoch: 27\tFidelity = 0.517303\tKL_Divergence = 2.013716\n",
      "Epoch: 28\tFidelity = 0.519166\tKL_Divergence = 1.956249\n",
      "Epoch: 29\tFidelity = 0.522029\tKL_Divergence = 1.877742\n",
      "Epoch: 30\tFidelity = 0.518002\tKL_Divergence = 1.991475\n",
      "Epoch: 31\tFidelity = 0.517478\tKL_Divergence = 2.008059\n",
      "Epoch: 32\tFidelity = 0.516098\tKL_Divergence = 2.054261\n",
      "Epoch: 33\tFidelity = 0.521826\tKL_Divergence = 1.882942\n",
      "Epoch: 34\tFidelity = 0.517314\tKL_Divergence = 2.013301\n",
      "Epoch: 35\tFidelity = 0.518587\tKL_Divergence = 1.973466\n",
      "Epoch: 36\tFidelity = 0.519181\tKL_Divergence = 1.955757\n",
      "Epoch: 37\tFidelity = 0.517435\tKL_Divergence = 2.009457\n",
      "Epoch: 38\tFidelity = 0.520334\tKL_Divergence = 1.922809\n",
      "Epoch: 39\tFidelity = 0.517326\tKL_Divergence = 2.012978\n",
      "Epoch: 40\tFidelity = 0.517165\tKL_Divergence = 2.018267\n",
      "Epoch: 41\tFidelity = 0.519314\tKL_Divergence = 1.951875\n",
      "Epoch: 42\tFidelity = 0.518611\tKL_Divergence = 1.972724\n",
      "Epoch: 43\tFidelity = 0.518409\tKL_Divergence = 1.978828\n",
      "Epoch: 44\tFidelity = 0.520478\tKL_Divergence = 1.918888\n",
      "Epoch: 45\tFidelity = 0.520550\tKL_Divergence = 1.916930\n",
      "Epoch: 46\tFidelity = 0.518684\tKL_Divergence = 1.970566\n",
      "Epoch: 47\tFidelity = 0.519058\tKL_Divergence = 1.959446\n",
      "Epoch: 48\tFidelity = 0.516070\tKL_Divergence = 2.055291\n",
      "Epoch: 49\tFidelity = 0.517876\tKL_Divergence = 1.995460\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:15:46,857] Trial 124 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.521765\tKL_Divergence = 1.884581\n",
      "Total time elapsed during training: 78.709 s\n",
      "Trial 124 pruned. \n",
      "Epoch: 1\tFidelity = 0.519115\tKL_Divergence = 1.957756\n",
      "Epoch: 2\tFidelity = 0.517955\tKL_Divergence = 1.992973\n",
      "Epoch: 3\tFidelity = 0.518734\tKL_Divergence = 1.969084\n",
      "Epoch: 4\tFidelity = 0.519863\tKL_Divergence = 1.936114\n",
      "Epoch: 5\tFidelity = 0.517842\tKL_Divergence = 1.996511\n",
      "Epoch: 6\tFidelity = 0.518531\tKL_Divergence = 1.975187\n",
      "Epoch: 7\tFidelity = 0.518255\tKL_Divergence = 1.983650\n",
      "Epoch: 8\tFidelity = 0.519146\tKL_Divergence = 1.956840\n",
      "Epoch: 9\tFidelity = 0.518801\tKL_Divergence = 1.967079\n",
      "Epoch: 10\tFidelity = 0.518133\tKL_Divergence = 1.987420\n",
      "Epoch: 11\tFidelity = 0.518216\tKL_Divergence = 1.984866\n",
      "Epoch: 12\tFidelity = 0.518748\tKL_Divergence = 1.968658\n",
      "Epoch: 13\tFidelity = 0.517893\tKL_Divergence = 1.994934\n",
      "Epoch: 14\tFidelity = 0.517529\tKL_Divergence = 2.006475\n",
      "Epoch: 15\tFidelity = 0.518985\tKL_Divergence = 1.961589\n",
      "Epoch: 16\tFidelity = 0.517516\tKL_Divergence = 2.006909\n",
      "Epoch: 17\tFidelity = 0.518220\tKL_Divergence = 1.984746\n",
      "Epoch: 18\tFidelity = 0.517882\tKL_Divergence = 1.995262\n",
      "Epoch: 19\tFidelity = 0.517656\tKL_Divergence = 2.002427\n",
      "Epoch: 20\tFidelity = 0.518175\tKL_Divergence = 1.986123\n",
      "Epoch: 21\tFidelity = 0.516977\tKL_Divergence = 2.024469\n",
      "Epoch: 22\tFidelity = 0.518577\tKL_Divergence = 1.973823\n",
      "Epoch: 23\tFidelity = 0.520143\tKL_Divergence = 1.928267\n",
      "Epoch: 24\tFidelity = 0.517872\tKL_Divergence = 1.995588\n",
      "Epoch: 25\tFidelity = 0.518871\tKL_Divergence = 1.964980\n",
      "Epoch: 26\tFidelity = 0.519558\tKL_Divergence = 1.944881\n",
      "Epoch: 27\tFidelity = 0.518399\tKL_Divergence = 1.979247\n",
      "Epoch: 28\tFidelity = 0.518899\tKL_Divergence = 1.964178\n",
      "Epoch: 29\tFidelity = 0.518893\tKL_Divergence = 1.964349\n",
      "Epoch: 30\tFidelity = 0.518886\tKL_Divergence = 1.964547\n",
      "Epoch: 31\tFidelity = 0.518992\tKL_Divergence = 1.961407\n",
      "Epoch: 32\tFidelity = 0.518689\tKL_Divergence = 1.970466\n",
      "Epoch: 33\tFidelity = 0.518293\tKL_Divergence = 1.982523\n",
      "Epoch: 34\tFidelity = 0.518356\tKL_Divergence = 1.980574\n",
      "Epoch: 35\tFidelity = 0.519299\tKL_Divergence = 1.952376\n",
      "Epoch: 36\tFidelity = 0.518134\tKL_Divergence = 1.987412\n",
      "Epoch: 37\tFidelity = 0.517225\tKL_Divergence = 2.016342\n",
      "Epoch: 38\tFidelity = 0.518911\tKL_Divergence = 1.963833\n",
      "Epoch: 39\tFidelity = 0.518094\tKL_Divergence = 1.988662\n",
      "Epoch: 40\tFidelity = 0.518706\tKL_Divergence = 1.969951\n",
      "Epoch: 41\tFidelity = 0.517199\tKL_Divergence = 2.017201\n",
      "Epoch: 42\tFidelity = 0.517550\tKL_Divergence = 2.005847\n",
      "Epoch: 43\tFidelity = 0.519162\tKL_Divergence = 1.956393\n",
      "Epoch: 44\tFidelity = 0.520526\tKL_Divergence = 1.917672\n",
      "Epoch: 45\tFidelity = 0.517956\tKL_Divergence = 1.992962\n",
      "Epoch: 46\tFidelity = 0.518168\tKL_Divergence = 1.986367\n",
      "Epoch: 47\tFidelity = 0.519891\tKL_Divergence = 1.935354\n",
      "Epoch: 48\tFidelity = 0.517594\tKL_Divergence = 2.004417\n",
      "Epoch: 49\tFidelity = 0.517600\tKL_Divergence = 2.004224\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:16:24,421] Trial 125 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.517145\tKL_Divergence = 2.018935\n",
      "Total time elapsed during training: 37.422 s\n",
      "Trial 125 pruned. \n",
      "Epoch: 1\tFidelity = 0.517831\tKL_Divergence = 1.996885\n",
      "Epoch: 2\tFidelity = 0.516982\tKL_Divergence = 2.024329\n",
      "Epoch: 3\tFidelity = 0.518990\tKL_Divergence = 1.961483\n",
      "Epoch: 4\tFidelity = 0.517303\tKL_Divergence = 2.013799\n",
      "Epoch: 5\tFidelity = 0.519727\tKL_Divergence = 1.940032\n",
      "Epoch: 6\tFidelity = 0.519172\tKL_Divergence = 1.956105\n",
      "Epoch: 7\tFidelity = 0.519122\tKL_Divergence = 1.957574\n",
      "Epoch: 8\tFidelity = 0.519103\tKL_Divergence = 1.958136\n",
      "Epoch: 9\tFidelity = 0.518891\tKL_Divergence = 1.964399\n",
      "Epoch: 10\tFidelity = 0.518226\tKL_Divergence = 1.984590\n",
      "Epoch: 11\tFidelity = 0.517821\tKL_Divergence = 1.997230\n",
      "Epoch: 12\tFidelity = 0.518132\tKL_Divergence = 1.987476\n",
      "Epoch: 13\tFidelity = 0.517367\tKL_Divergence = 2.011745\n",
      "Epoch: 14\tFidelity = 0.517695\tKL_Divergence = 2.001199\n",
      "Epoch: 15\tFidelity = 0.519130\tKL_Divergence = 1.957338\n",
      "Epoch: 16\tFidelity = 0.520226\tKL_Divergence = 1.925942\n",
      "Epoch: 17\tFidelity = 0.516868\tKL_Divergence = 2.028126\n",
      "Epoch: 18\tFidelity = 0.517822\tKL_Divergence = 1.997162\n",
      "Epoch: 19\tFidelity = 0.519105\tKL_Divergence = 1.958056\n",
      "Epoch: 20\tFidelity = 0.519349\tKL_Divergence = 1.950903\n",
      "Epoch: 21\tFidelity = 0.517128\tKL_Divergence = 2.019474\n",
      "Epoch: 22\tFidelity = 0.516481\tKL_Divergence = 2.041107\n",
      "Epoch: 23\tFidelity = 0.518596\tKL_Divergence = 1.973236\n",
      "Epoch: 24\tFidelity = 0.517055\tKL_Divergence = 2.021908\n",
      "Epoch: 25\tFidelity = 0.519322\tKL_Divergence = 1.951688\n",
      "Epoch: 26\tFidelity = 0.519031\tKL_Divergence = 1.960234\n",
      "Epoch: 27\tFidelity = 0.519888\tKL_Divergence = 1.935422\n",
      "Epoch: 28\tFidelity = 0.518929\tKL_Divergence = 1.963249\n",
      "Epoch: 29\tFidelity = 0.517505\tKL_Divergence = 2.007252\n",
      "Epoch: 30\tFidelity = 0.519507\tKL_Divergence = 1.946336\n",
      "Epoch: 31\tFidelity = 0.517128\tKL_Divergence = 2.019486\n",
      "Epoch: 32\tFidelity = 0.518150\tKL_Divergence = 1.986900\n",
      "Epoch: 33\tFidelity = 0.518667\tKL_Divergence = 1.971116\n",
      "Epoch: 34\tFidelity = 0.517728\tKL_Divergence = 2.000128\n",
      "Epoch: 35\tFidelity = 0.518259\tKL_Divergence = 1.983543\n",
      "Epoch: 36\tFidelity = 0.517926\tKL_Divergence = 1.993893\n",
      "Epoch: 37\tFidelity = 0.517954\tKL_Divergence = 1.993037\n",
      "Epoch: 38\tFidelity = 0.518842\tKL_Divergence = 1.965873\n",
      "Epoch: 39\tFidelity = 0.519191\tKL_Divergence = 1.955540\n",
      "Epoch: 40\tFidelity = 0.519829\tKL_Divergence = 1.937100\n",
      "Epoch: 41\tFidelity = 0.518387\tKL_Divergence = 1.979634\n",
      "Epoch: 42\tFidelity = 0.517745\tKL_Divergence = 1.999611\n",
      "Epoch: 43\tFidelity = 0.518496\tKL_Divergence = 1.976299\n",
      "Epoch: 44\tFidelity = 0.517644\tKL_Divergence = 2.002779\n",
      "Epoch: 45\tFidelity = 0.519392\tKL_Divergence = 1.949648\n",
      "Epoch: 46\tFidelity = 0.519444\tKL_Divergence = 1.948147\n",
      "Epoch: 47\tFidelity = 0.519880\tKL_Divergence = 1.935679\n",
      "Epoch: 48\tFidelity = 0.519212\tKL_Divergence = 1.954895\n",
      "Epoch: 49\tFidelity = 0.518457\tKL_Divergence = 1.977472\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:17:01,786] Trial 126 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.517366\tKL_Divergence = 2.011750\n",
      "Total time elapsed during training: 37.223 s\n",
      "Trial 126 pruned. \n",
      "Epoch: 1\tFidelity = 0.517182\tKL_Divergence = 2.017727\n",
      "Epoch: 2\tFidelity = 0.517637\tKL_Divergence = 2.003045\n",
      "Epoch: 3\tFidelity = 0.519701\tKL_Divergence = 1.940766\n",
      "Epoch: 4\tFidelity = 0.517663\tKL_Divergence = 2.002213\n",
      "Epoch: 5\tFidelity = 0.516189\tKL_Divergence = 2.051188\n",
      "Epoch: 6\tFidelity = 0.517534\tKL_Divergence = 2.006344\n",
      "Epoch: 7\tFidelity = 0.517581\tKL_Divergence = 2.004836\n",
      "Epoch: 8\tFidelity = 0.518529\tKL_Divergence = 1.975291\n",
      "Epoch: 9\tFidelity = 0.517902\tKL_Divergence = 1.994690\n",
      "Epoch: 10\tFidelity = 0.518218\tKL_Divergence = 1.984831\n",
      "Epoch: 11\tFidelity = 0.519286\tKL_Divergence = 1.952746\n",
      "Epoch: 12\tFidelity = 0.517342\tKL_Divergence = 2.012558\n",
      "Epoch: 13\tFidelity = 0.516052\tKL_Divergence = 2.055968\n",
      "Epoch: 14\tFidelity = 0.519200\tKL_Divergence = 1.955261\n",
      "Epoch: 15\tFidelity = 0.516928\tKL_Divergence = 2.026136\n",
      "Epoch: 16\tFidelity = 0.519746\tKL_Divergence = 1.939498\n",
      "Epoch: 17\tFidelity = 0.517599\tKL_Divergence = 2.004290\n",
      "Epoch: 18\tFidelity = 0.517655\tKL_Divergence = 2.002502\n",
      "Epoch: 19\tFidelity = 0.517461\tKL_Divergence = 2.008607\n",
      "Epoch: 20\tFidelity = 0.518658\tKL_Divergence = 1.971348\n",
      "Epoch: 21\tFidelity = 0.519039\tKL_Divergence = 1.960020\n",
      "Epoch: 22\tFidelity = 0.518537\tKL_Divergence = 1.975064\n",
      "Epoch: 23\tFidelity = 0.519694\tKL_Divergence = 1.940978\n",
      "Epoch: 24\tFidelity = 0.515080\tKL_Divergence = 2.091051\n",
      "Epoch: 25\tFidelity = 0.517693\tKL_Divergence = 2.001052\n",
      "Epoch: 26\tFidelity = 0.517266\tKL_Divergence = 2.014898\n",
      "Epoch: 27\tFidelity = 0.519388\tKL_Divergence = 1.949713\n",
      "Epoch: 28\tFidelity = 0.517826\tKL_Divergence = 1.996999\n",
      "Epoch: 29\tFidelity = 0.517100\tKL_Divergence = 2.020401\n",
      "Epoch: 30\tFidelity = 0.520132\tKL_Divergence = 1.928484\n",
      "Epoch: 31\tFidelity = 0.521441\tKL_Divergence = 1.892919\n",
      "Epoch: 32\tFidelity = 0.520049\tKL_Divergence = 1.930822\n",
      "Epoch: 33\tFidelity = 0.517381\tKL_Divergence = 2.011054\n",
      "Epoch: 34\tFidelity = 0.520252\tKL_Divergence = 1.925050\n",
      "Epoch: 35\tFidelity = 0.516464\tKL_Divergence = 2.041542\n",
      "Epoch: 36\tFidelity = 0.518001\tKL_Divergence = 1.991363\n",
      "Epoch: 37\tFidelity = 0.515768\tKL_Divergence = 2.065695\n",
      "Epoch: 38\tFidelity = 0.519161\tKL_Divergence = 1.956237\n",
      "Epoch: 39\tFidelity = 0.517886\tKL_Divergence = 1.994976\n",
      "Epoch: 40\tFidelity = 0.519683\tKL_Divergence = 1.941107\n",
      "Epoch: 41\tFidelity = 0.521538\tKL_Divergence = 1.890340\n",
      "Epoch: 42\tFidelity = 0.516186\tKL_Divergence = 2.051120\n",
      "Epoch: 43\tFidelity = 0.517946\tKL_Divergence = 1.993100\n",
      "Epoch: 44\tFidelity = 0.516165\tKL_Divergence = 2.051915\n",
      "Epoch: 45\tFidelity = 0.516965\tKL_Divergence = 2.024816\n",
      "Epoch: 46\tFidelity = 0.516708\tKL_Divergence = 2.033395\n",
      "Epoch: 47\tFidelity = 0.519238\tKL_Divergence = 1.954025\n",
      "Epoch: 48\tFidelity = 0.515859\tKL_Divergence = 2.062665\n",
      "Epoch: 49\tFidelity = 0.518424\tKL_Divergence = 1.978302\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:17:38,930] Trial 127 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.517022\tKL_Divergence = 2.022875\n",
      "Total time elapsed during training: 37.004 s\n",
      "Trial 127 pruned. \n",
      "Epoch: 1\tFidelity = 0.517202\tKL_Divergence = 2.017035\n",
      "Epoch: 2\tFidelity = 0.518882\tKL_Divergence = 1.964599\n",
      "Epoch: 3\tFidelity = 0.523227\tKL_Divergence = 1.847812\n",
      "Epoch: 4\tFidelity = 0.521018\tKL_Divergence = 1.904055\n",
      "Epoch: 5\tFidelity = 0.517991\tKL_Divergence = 1.991744\n",
      "Epoch: 6\tFidelity = 0.519422\tKL_Divergence = 1.948746\n",
      "Epoch: 7\tFidelity = 0.521151\tKL_Divergence = 1.900547\n",
      "Epoch: 8\tFidelity = 0.516876\tKL_Divergence = 2.027788\n",
      "Epoch: 9\tFidelity = 0.519786\tKL_Divergence = 1.938205\n",
      "Epoch: 10\tFidelity = 0.522187\tKL_Divergence = 1.873688\n",
      "Epoch: 11\tFidelity = 0.517939\tKL_Divergence = 1.993428\n",
      "Epoch: 12\tFidelity = 0.519016\tKL_Divergence = 1.960509\n",
      "Epoch: 13\tFidelity = 0.519128\tKL_Divergence = 1.957160\n",
      "Epoch: 14\tFidelity = 0.517094\tKL_Divergence = 2.020599\n",
      "Epoch: 15\tFidelity = 0.517913\tKL_Divergence = 1.994270\n",
      "Epoch: 16\tFidelity = 0.518926\tKL_Divergence = 1.963295\n",
      "Epoch: 17\tFidelity = 0.520119\tKL_Divergence = 1.928804\n",
      "Epoch: 18\tFidelity = 0.516534\tKL_Divergence = 2.039278\n",
      "Epoch: 19\tFidelity = 0.521893\tKL_Divergence = 1.881218\n",
      "Epoch: 20\tFidelity = 0.522108\tKL_Divergence = 1.875699\n",
      "Epoch: 21\tFidelity = 0.515953\tKL_Divergence = 2.059401\n",
      "Epoch: 22\tFidelity = 0.517813\tKL_Divergence = 1.997412\n",
      "Epoch: 23\tFidelity = 0.516029\tKL_Divergence = 2.056760\n",
      "Epoch: 24\tFidelity = 0.518124\tKL_Divergence = 1.987307\n",
      "Epoch: 25\tFidelity = 0.521969\tKL_Divergence = 1.879155\n",
      "Epoch: 26\tFidelity = 0.520771\tKL_Divergence = 1.910841\n",
      "Epoch: 27\tFidelity = 0.521585\tKL_Divergence = 1.889140\n",
      "Epoch: 28\tFidelity = 0.521665\tKL_Divergence = 1.887189\n",
      "Epoch: 29\tFidelity = 0.516566\tKL_Divergence = 2.038234\n",
      "Epoch: 30\tFidelity = 0.516127\tKL_Divergence = 2.053282\n",
      "Epoch: 31\tFidelity = 0.520875\tKL_Divergence = 1.908064\n",
      "Epoch: 32\tFidelity = 0.521998\tKL_Divergence = 1.878562\n",
      "Epoch: 33\tFidelity = 0.521186\tKL_Divergence = 1.899770\n",
      "Epoch: 34\tFidelity = 0.516927\tKL_Divergence = 2.026121\n",
      "Epoch: 35\tFidelity = 0.520339\tKL_Divergence = 1.922794\n",
      "Epoch: 36\tFidelity = 0.517473\tKL_Divergence = 2.008280\n",
      "Epoch: 37\tFidelity = 0.516000\tKL_Divergence = 2.057641\n",
      "Epoch: 38\tFidelity = 0.516357\tKL_Divergence = 2.045320\n",
      "Epoch: 39\tFidelity = 0.518427\tKL_Divergence = 1.978364\n",
      "Epoch: 40\tFidelity = 0.521568\tKL_Divergence = 1.889698\n",
      "Epoch: 41\tFidelity = 0.517242\tKL_Divergence = 2.015788\n",
      "Epoch: 42\tFidelity = 0.517359\tKL_Divergence = 2.011805\n",
      "Epoch: 43\tFidelity = 0.515794\tKL_Divergence = 2.064880\n",
      "Epoch: 44\tFidelity = 0.519248\tKL_Divergence = 1.953522\n",
      "Epoch: 45\tFidelity = 0.516703\tKL_Divergence = 2.033531\n",
      "Epoch: 46\tFidelity = 0.517066\tKL_Divergence = 2.021267\n",
      "Epoch: 47\tFidelity = 0.515877\tKL_Divergence = 2.061815\n",
      "Epoch: 48\tFidelity = 0.520757\tKL_Divergence = 1.910746\n",
      "Epoch: 49\tFidelity = 0.522998\tKL_Divergence = 1.853222\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:18:15,298] Trial 128 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.516288\tKL_Divergence = 2.047731\n",
      "Total time elapsed during training: 36.215 s\n",
      "Trial 128 pruned. \n",
      "Epoch: 1\tFidelity = 0.519144\tKL_Divergence = 1.956691\n",
      "Epoch: 2\tFidelity = 0.516886\tKL_Divergence = 2.027393\n",
      "Epoch: 3\tFidelity = 0.517345\tKL_Divergence = 2.012341\n",
      "Epoch: 4\tFidelity = 0.520326\tKL_Divergence = 1.923045\n",
      "Epoch: 5\tFidelity = 0.520051\tKL_Divergence = 1.930767\n",
      "Epoch: 6\tFidelity = 0.520531\tKL_Divergence = 1.917408\n",
      "Epoch: 7\tFidelity = 0.521365\tKL_Divergence = 1.894964\n",
      "Epoch: 8\tFidelity = 0.520853\tKL_Divergence = 1.908594\n",
      "Epoch: 9\tFidelity = 0.520174\tKL_Divergence = 1.927271\n",
      "Epoch: 10\tFidelity = 0.517963\tKL_Divergence = 1.992672\n",
      "Epoch: 11\tFidelity = 0.519708\tKL_Divergence = 1.940457\n",
      "Epoch: 12\tFidelity = 0.520607\tKL_Divergence = 1.915263\n",
      "Epoch: 13\tFidelity = 0.520096\tKL_Divergence = 1.929360\n",
      "Epoch: 14\tFidelity = 0.518216\tKL_Divergence = 1.984764\n",
      "Epoch: 15\tFidelity = 0.517457\tKL_Divergence = 2.008715\n",
      "Epoch: 16\tFidelity = 0.520119\tKL_Divergence = 1.928732\n",
      "Epoch: 17\tFidelity = 0.520570\tKL_Divergence = 1.916266\n",
      "Epoch: 18\tFidelity = 0.521556\tKL_Divergence = 1.889804\n",
      "Epoch: 19\tFidelity = 0.519441\tKL_Divergence = 1.948082\n",
      "Epoch: 20\tFidelity = 0.520271\tKL_Divergence = 1.924630\n",
      "Epoch: 21\tFidelity = 0.518060\tKL_Divergence = 1.989632\n",
      "Epoch: 22\tFidelity = 0.517837\tKL_Divergence = 1.996595\n",
      "Epoch: 23\tFidelity = 0.520294\tKL_Divergence = 1.923988\n",
      "Epoch: 24\tFidelity = 0.518611\tKL_Divergence = 1.972738\n",
      "Epoch: 25\tFidelity = 0.520021\tKL_Divergence = 1.931539\n",
      "Epoch: 26\tFidelity = 0.519550\tKL_Divergence = 1.945014\n",
      "Epoch: 27\tFidelity = 0.519222\tKL_Divergence = 1.954502\n",
      "Epoch: 28\tFidelity = 0.521616\tKL_Divergence = 1.888395\n",
      "Epoch: 29\tFidelity = 0.518800\tKL_Divergence = 1.967060\n",
      "Epoch: 30\tFidelity = 0.523863\tKL_Divergence = 1.832524\n",
      "Epoch: 31\tFidelity = 0.518309\tKL_Divergence = 1.981936\n",
      "Epoch: 32\tFidelity = 0.517910\tKL_Divergence = 1.994257\n",
      "Epoch: 33\tFidelity = 0.518563\tKL_Divergence = 1.974185\n",
      "Epoch: 34\tFidelity = 0.517659\tKL_Divergence = 2.002212\n",
      "Epoch: 35\tFidelity = 0.520867\tKL_Divergence = 1.908309\n",
      "Epoch: 36\tFidelity = 0.519988\tKL_Divergence = 1.932565\n",
      "Epoch: 37\tFidelity = 0.519718\tKL_Divergence = 1.940150\n",
      "Epoch: 38\tFidelity = 0.519790\tKL_Divergence = 1.938175\n",
      "Epoch: 39\tFidelity = 0.521052\tKL_Divergence = 1.903281\n",
      "Epoch: 40\tFidelity = 0.516540\tKL_Divergence = 2.039113\n",
      "Epoch: 41\tFidelity = 0.518765\tKL_Divergence = 1.968076\n",
      "Epoch: 42\tFidelity = 0.517369\tKL_Divergence = 2.011464\n",
      "Epoch: 43\tFidelity = 0.518417\tKL_Divergence = 1.978609\n",
      "Epoch: 44\tFidelity = 0.520211\tKL_Divergence = 1.926261\n",
      "Epoch: 45\tFidelity = 0.521040\tKL_Divergence = 1.903617\n",
      "Epoch: 46\tFidelity = 0.520099\tKL_Divergence = 1.929433\n",
      "Epoch: 47\tFidelity = 0.518456\tKL_Divergence = 1.977441\n",
      "Epoch: 48\tFidelity = 0.519660\tKL_Divergence = 1.941819\n",
      "Epoch: 49\tFidelity = 0.517844\tKL_Divergence = 1.996387\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:19:31,130] Trial 129 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.516991\tKL_Divergence = 2.023887\n",
      "Total time elapsed during training: 75.700 s\n",
      "Trial 129 pruned. \n",
      "Epoch: 1\tFidelity = 0.519298\tKL_Divergence = 1.952297\n",
      "Epoch: 2\tFidelity = 0.517833\tKL_Divergence = 1.996727\n",
      "Epoch: 3\tFidelity = 0.517814\tKL_Divergence = 1.997339\n",
      "Epoch: 4\tFidelity = 0.519935\tKL_Divergence = 1.934022\n",
      "Epoch: 5\tFidelity = 0.516491\tKL_Divergence = 2.040717\n",
      "Epoch: 6\tFidelity = 0.519889\tKL_Divergence = 1.935349\n",
      "Epoch: 7\tFidelity = 0.516523\tKL_Divergence = 2.039629\n",
      "Epoch: 8\tFidelity = 0.519623\tKL_Divergence = 1.942929\n",
      "Epoch: 9\tFidelity = 0.518966\tKL_Divergence = 1.962128\n",
      "Epoch: 10\tFidelity = 0.516316\tKL_Divergence = 2.046740\n",
      "Epoch: 11\tFidelity = 0.517669\tKL_Divergence = 2.001972\n",
      "Epoch: 12\tFidelity = 0.518754\tKL_Divergence = 1.968436\n",
      "Epoch: 13\tFidelity = 0.519178\tKL_Divergence = 1.955870\n",
      "Epoch: 14\tFidelity = 0.518342\tKL_Divergence = 1.980959\n",
      "Epoch: 15\tFidelity = 0.518503\tKL_Divergence = 1.976044\n",
      "Epoch: 16\tFidelity = 0.519252\tKL_Divergence = 1.953686\n",
      "Epoch: 17\tFidelity = 0.518537\tKL_Divergence = 1.975013\n",
      "Epoch: 18\tFidelity = 0.517067\tKL_Divergence = 2.021460\n",
      "Epoch: 19\tFidelity = 0.518633\tKL_Divergence = 1.972091\n",
      "Epoch: 20\tFidelity = 0.518584\tKL_Divergence = 1.973579\n",
      "Epoch: 21\tFidelity = 0.518727\tKL_Divergence = 1.969266\n",
      "Epoch: 22\tFidelity = 0.517408\tKL_Divergence = 2.010337\n",
      "Epoch: 23\tFidelity = 0.516444\tKL_Divergence = 2.042330\n",
      "Epoch: 24\tFidelity = 0.520274\tKL_Divergence = 1.924556\n",
      "Epoch: 25\tFidelity = 0.517790\tKL_Divergence = 1.998131\n",
      "Epoch: 26\tFidelity = 0.517963\tKL_Divergence = 1.992692\n",
      "Epoch: 27\tFidelity = 0.518662\tKL_Divergence = 1.971210\n",
      "Epoch: 28\tFidelity = 0.517407\tKL_Divergence = 2.010346\n",
      "Epoch: 29\tFidelity = 0.519504\tKL_Divergence = 1.946345\n",
      "Epoch: 30\tFidelity = 0.519639\tKL_Divergence = 1.942482\n",
      "Epoch: 31\tFidelity = 0.517946\tKL_Divergence = 1.993201\n",
      "Epoch: 32\tFidelity = 0.519208\tKL_Divergence = 1.954959\n",
      "Epoch: 33\tFidelity = 0.520250\tKL_Divergence = 1.925229\n",
      "Epoch: 34\tFidelity = 0.516860\tKL_Divergence = 2.028296\n",
      "Epoch: 35\tFidelity = 0.519578\tKL_Divergence = 1.944224\n",
      "Epoch: 36\tFidelity = 0.518507\tKL_Divergence = 1.975900\n",
      "Epoch: 37\tFidelity = 0.518868\tKL_Divergence = 1.965027\n",
      "Epoch: 38\tFidelity = 0.518300\tKL_Divergence = 1.982235\n",
      "Epoch: 39\tFidelity = 0.520452\tKL_Divergence = 1.919636\n",
      "Epoch: 40\tFidelity = 0.517414\tKL_Divergence = 2.010157\n",
      "Epoch: 41\tFidelity = 0.520649\tKL_Divergence = 1.914218\n",
      "Epoch: 42\tFidelity = 0.519429\tKL_Divergence = 1.948539\n",
      "Epoch: 43\tFidelity = 0.517579\tKL_Divergence = 2.004854\n",
      "Epoch: 44\tFidelity = 0.516647\tKL_Divergence = 2.035475\n",
      "Epoch: 45\tFidelity = 0.518266\tKL_Divergence = 1.983275\n",
      "Epoch: 46\tFidelity = 0.518644\tKL_Divergence = 1.971739\n",
      "Epoch: 47\tFidelity = 0.517328\tKL_Divergence = 2.012926\n",
      "Epoch: 48\tFidelity = 0.518886\tKL_Divergence = 1.964502\n",
      "Epoch: 49\tFidelity = 0.518782\tKL_Divergence = 1.967594\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:20:02,007] Trial 130 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.519040\tKL_Divergence = 1.959930\n",
      "Total time elapsed during training: 30.737 s\n",
      "Trial 130 pruned. \n",
      "Epoch: 1\tFidelity = 0.516915\tKL_Divergence = 2.026480\n",
      "Epoch: 2\tFidelity = 0.519705\tKL_Divergence = 1.940603\n",
      "Epoch: 3\tFidelity = 0.517821\tKL_Divergence = 1.997142\n",
      "Epoch: 4\tFidelity = 0.517801\tKL_Divergence = 1.997774\n",
      "Epoch: 5\tFidelity = 0.517338\tKL_Divergence = 2.012611\n",
      "Epoch: 6\tFidelity = 0.518996\tKL_Divergence = 1.961220\n",
      "Epoch: 7\tFidelity = 0.516784\tKL_Divergence = 2.030856\n",
      "Epoch: 8\tFidelity = 0.519925\tKL_Divergence = 1.934343\n",
      "Epoch: 9\tFidelity = 0.517093\tKL_Divergence = 2.020596\n",
      "Epoch: 10\tFidelity = 0.519952\tKL_Divergence = 1.933561\n",
      "Epoch: 11\tFidelity = 0.517167\tKL_Divergence = 2.018157\n",
      "Epoch: 12\tFidelity = 0.519086\tKL_Divergence = 1.958560\n",
      "Epoch: 13\tFidelity = 0.517695\tKL_Divergence = 2.001135\n",
      "Epoch: 14\tFidelity = 0.518526\tKL_Divergence = 1.975299\n",
      "Epoch: 15\tFidelity = 0.517923\tKL_Divergence = 1.993925\n",
      "Epoch: 16\tFidelity = 0.518385\tKL_Divergence = 1.979610\n",
      "Epoch: 17\tFidelity = 0.516966\tKL_Divergence = 2.024763\n",
      "Epoch: 18\tFidelity = 0.519317\tKL_Divergence = 1.951778\n",
      "Epoch: 19\tFidelity = 0.519080\tKL_Divergence = 1.958717\n",
      "Epoch: 20\tFidelity = 0.518748\tKL_Divergence = 1.968599\n",
      "Epoch: 21\tFidelity = 0.517705\tKL_Divergence = 2.000811\n",
      "Epoch: 22\tFidelity = 0.518478\tKL_Divergence = 1.976770\n",
      "Epoch: 23\tFidelity = 0.518076\tKL_Divergence = 1.989122\n",
      "Epoch: 24\tFidelity = 0.518671\tKL_Divergence = 1.970928\n",
      "Epoch: 25\tFidelity = 0.516907\tKL_Divergence = 2.026728\n",
      "Epoch: 26\tFidelity = 0.519861\tKL_Divergence = 1.936130\n",
      "Epoch: 27\tFidelity = 0.517587\tKL_Divergence = 2.004577\n",
      "Epoch: 28\tFidelity = 0.518539\tKL_Divergence = 1.974916\n",
      "Epoch: 29\tFidelity = 0.519798\tKL_Divergence = 1.937912\n",
      "Epoch: 30\tFidelity = 0.517286\tKL_Divergence = 2.014269\n",
      "Epoch: 31\tFidelity = 0.519690\tKL_Divergence = 1.940992\n",
      "Epoch: 32\tFidelity = 0.517622\tKL_Divergence = 2.003453\n",
      "Epoch: 33\tFidelity = 0.518278\tKL_Divergence = 1.982891\n",
      "Epoch: 34\tFidelity = 0.520946\tKL_Divergence = 1.906147\n",
      "Epoch: 35\tFidelity = 0.515950\tKL_Divergence = 2.059458\n",
      "Epoch: 36\tFidelity = 0.518770\tKL_Divergence = 1.967939\n",
      "Epoch: 37\tFidelity = 0.519083\tKL_Divergence = 1.958633\n",
      "Epoch: 38\tFidelity = 0.517703\tKL_Divergence = 2.000888\n",
      "Epoch: 39\tFidelity = 0.518327\tKL_Divergence = 1.981394\n",
      "Epoch: 40\tFidelity = 0.520243\tKL_Divergence = 1.925391\n",
      "Epoch: 41\tFidelity = 0.516692\tKL_Divergence = 2.033916\n",
      "Epoch: 42\tFidelity = 0.519725\tKL_Divergence = 1.940010\n",
      "Epoch: 43\tFidelity = 0.520017\tKL_Divergence = 1.931715\n",
      "Epoch: 44\tFidelity = 0.516655\tKL_Divergence = 2.035156\n",
      "Epoch: 45\tFidelity = 0.519022\tKL_Divergence = 1.960454\n",
      "Epoch: 46\tFidelity = 0.517300\tKL_Divergence = 2.013803\n",
      "Epoch: 47\tFidelity = 0.519630\tKL_Divergence = 1.942731\n",
      "Epoch: 48\tFidelity = 0.517239\tKL_Divergence = 2.015815\n",
      "Epoch: 49\tFidelity = 0.520689\tKL_Divergence = 1.913119\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:20:32,577] Trial 131 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.517520\tKL_Divergence = 2.006738\n",
      "Total time elapsed during training: 30.423 s\n",
      "Trial 131 pruned. \n",
      "Epoch: 1\tFidelity = 0.519925\tKL_Divergence = 1.934349\n",
      "Epoch: 2\tFidelity = 0.516673\tKL_Divergence = 2.034578\n",
      "Epoch: 3\tFidelity = 0.520134\tKL_Divergence = 1.928467\n",
      "Epoch: 4\tFidelity = 0.516983\tKL_Divergence = 2.024224\n",
      "Epoch: 5\tFidelity = 0.518359\tKL_Divergence = 1.980423\n",
      "Epoch: 6\tFidelity = 0.515961\tKL_Divergence = 2.059090\n",
      "Epoch: 7\tFidelity = 0.520335\tKL_Divergence = 1.922863\n",
      "Epoch: 8\tFidelity = 0.516495\tKL_Divergence = 2.040610\n",
      "Epoch: 9\tFidelity = 0.519609\tKL_Divergence = 1.943350\n",
      "Epoch: 10\tFidelity = 0.516486\tKL_Divergence = 2.040917\n",
      "Epoch: 11\tFidelity = 0.519970\tKL_Divergence = 1.933081\n",
      "Epoch: 12\tFidelity = 0.516700\tKL_Divergence = 2.033699\n",
      "Epoch: 13\tFidelity = 0.520212\tKL_Divergence = 1.926294\n",
      "Epoch: 14\tFidelity = 0.516686\tKL_Divergence = 2.034162\n",
      "Epoch: 15\tFidelity = 0.519670\tKL_Divergence = 1.941585\n",
      "Epoch: 16\tFidelity = 0.516849\tKL_Divergence = 2.028677\n",
      "Epoch: 17\tFidelity = 0.520099\tKL_Divergence = 1.929417\n",
      "Epoch: 18\tFidelity = 0.515773\tKL_Divergence = 2.065719\n",
      "Epoch: 19\tFidelity = 0.520698\tKL_Divergence = 1.912868\n",
      "Epoch: 20\tFidelity = 0.516953\tKL_Divergence = 2.025210\n",
      "Epoch: 21\tFidelity = 0.521209\tKL_Divergence = 1.899117\n",
      "Epoch: 22\tFidelity = 0.515939\tKL_Divergence = 2.059833\n",
      "Epoch: 23\tFidelity = 0.522481\tKL_Divergence = 1.866252\n",
      "Epoch: 24\tFidelity = 0.516215\tKL_Divergence = 2.050205\n",
      "Epoch: 25\tFidelity = 0.520449\tKL_Divergence = 1.919676\n",
      "Epoch: 26\tFidelity = 0.517528\tKL_Divergence = 2.006434\n",
      "Epoch: 27\tFidelity = 0.519271\tKL_Divergence = 1.953097\n",
      "Epoch: 28\tFidelity = 0.518666\tKL_Divergence = 1.971071\n",
      "Epoch: 29\tFidelity = 0.517132\tKL_Divergence = 2.019285\n",
      "Epoch: 30\tFidelity = 0.519216\tKL_Divergence = 1.954717\n",
      "Epoch: 31\tFidelity = 0.518158\tKL_Divergence = 1.986600\n",
      "Epoch: 32\tFidelity = 0.518642\tKL_Divergence = 1.971798\n",
      "Epoch: 33\tFidelity = 0.518649\tKL_Divergence = 1.971591\n",
      "Epoch: 34\tFidelity = 0.519703\tKL_Divergence = 1.940627\n",
      "Epoch: 35\tFidelity = 0.515654\tKL_Divergence = 2.069997\n",
      "Epoch: 36\tFidelity = 0.521785\tKL_Divergence = 1.884021\n",
      "Epoch: 37\tFidelity = 0.517774\tKL_Divergence = 1.998636\n",
      "Epoch: 38\tFidelity = 0.517685\tKL_Divergence = 2.001454\n",
      "Epoch: 39\tFidelity = 0.519293\tKL_Divergence = 1.952492\n",
      "Epoch: 40\tFidelity = 0.518277\tKL_Divergence = 1.982924\n",
      "Epoch: 41\tFidelity = 0.517591\tKL_Divergence = 2.004458\n",
      "Epoch: 42\tFidelity = 0.518218\tKL_Divergence = 1.984769\n",
      "Epoch: 43\tFidelity = 0.519938\tKL_Divergence = 1.933961\n",
      "Epoch: 44\tFidelity = 0.517395\tKL_Divergence = 2.010756\n",
      "Epoch: 45\tFidelity = 0.517957\tKL_Divergence = 1.992866\n",
      "Epoch: 46\tFidelity = 0.518900\tKL_Divergence = 1.964067\n",
      "Epoch: 47\tFidelity = 0.517611\tKL_Divergence = 2.003824\n",
      "Epoch: 48\tFidelity = 0.517511\tKL_Divergence = 2.007010\n",
      "Epoch: 49\tFidelity = 0.518300\tKL_Divergence = 1.982246\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:21:02,959] Trial 132 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.519380\tKL_Divergence = 1.949952\n",
      "Total time elapsed during training: 30.245 s\n",
      "Trial 132 pruned. \n",
      "Epoch: 1\tFidelity = 0.517660\tKL_Divergence = 2.002263\n",
      "Epoch: 2\tFidelity = 0.519397\tKL_Divergence = 1.949460\n",
      "Epoch: 3\tFidelity = 0.517621\tKL_Divergence = 2.003483\n",
      "Epoch: 4\tFidelity = 0.517878\tKL_Divergence = 1.995371\n",
      "Epoch: 5\tFidelity = 0.519572\tKL_Divergence = 1.944423\n",
      "Epoch: 6\tFidelity = 0.517382\tKL_Divergence = 2.011183\n",
      "Epoch: 7\tFidelity = 0.517325\tKL_Divergence = 2.013029\n",
      "Epoch: 8\tFidelity = 0.518935\tKL_Divergence = 1.963037\n",
      "Epoch: 9\tFidelity = 0.518071\tKL_Divergence = 1.989318\n",
      "Epoch: 10\tFidelity = 0.518045\tKL_Divergence = 1.990126\n",
      "Epoch: 11\tFidelity = 0.517964\tKL_Divergence = 1.992650\n",
      "Epoch: 12\tFidelity = 0.519572\tKL_Divergence = 1.944415\n",
      "Epoch: 13\tFidelity = 0.517241\tKL_Divergence = 2.015743\n",
      "Epoch: 14\tFidelity = 0.518780\tKL_Divergence = 1.967653\n",
      "Epoch: 15\tFidelity = 0.517506\tKL_Divergence = 2.007168\n",
      "Epoch: 16\tFidelity = 0.518771\tKL_Divergence = 1.967937\n",
      "Epoch: 17\tFidelity = 0.516507\tKL_Divergence = 2.040204\n",
      "Epoch: 18\tFidelity = 0.520026\tKL_Divergence = 1.931481\n",
      "Epoch: 19\tFidelity = 0.517946\tKL_Divergence = 1.993214\n",
      "Epoch: 20\tFidelity = 0.518858\tKL_Divergence = 1.965320\n",
      "Epoch: 21\tFidelity = 0.516915\tKL_Divergence = 2.026476\n",
      "Epoch: 22\tFidelity = 0.517832\tKL_Divergence = 1.996804\n",
      "Epoch: 23\tFidelity = 0.520563\tKL_Divergence = 1.916569\n",
      "Epoch: 24\tFidelity = 0.517691\tKL_Divergence = 2.001266\n",
      "Epoch: 25\tFidelity = 0.518196\tKL_Divergence = 1.985448\n",
      "Epoch: 26\tFidelity = 0.518119\tKL_Divergence = 1.987828\n",
      "Epoch: 27\tFidelity = 0.518170\tKL_Divergence = 1.986240\n",
      "Epoch: 28\tFidelity = 0.519021\tKL_Divergence = 1.960483\n",
      "Epoch: 29\tFidelity = 0.516536\tKL_Divergence = 2.039230\n",
      "Epoch: 30\tFidelity = 0.519396\tKL_Divergence = 1.949488\n",
      "Epoch: 31\tFidelity = 0.517937\tKL_Divergence = 1.993486\n",
      "Epoch: 32\tFidelity = 0.519200\tKL_Divergence = 1.955215\n",
      "Epoch: 33\tFidelity = 0.517464\tKL_Divergence = 2.008528\n",
      "Epoch: 34\tFidelity = 0.519228\tKL_Divergence = 1.954392\n",
      "Epoch: 35\tFidelity = 0.517469\tKL_Divergence = 2.008375\n",
      "Epoch: 36\tFidelity = 0.518667\tKL_Divergence = 1.971063\n",
      "Epoch: 37\tFidelity = 0.518377\tKL_Divergence = 1.979854\n",
      "Epoch: 38\tFidelity = 0.518038\tKL_Divergence = 1.990331\n",
      "Epoch: 39\tFidelity = 0.519115\tKL_Divergence = 1.957713\n",
      "Epoch: 40\tFidelity = 0.517063\tKL_Divergence = 2.021606\n",
      "Epoch: 41\tFidelity = 0.519059\tKL_Divergence = 1.959380\n",
      "Epoch: 42\tFidelity = 0.516923\tKL_Divergence = 2.026220\n",
      "Epoch: 43\tFidelity = 0.518229\tKL_Divergence = 1.984436\n",
      "Epoch: 44\tFidelity = 0.517770\tKL_Divergence = 1.998763\n",
      "Epoch: 45\tFidelity = 0.517615\tKL_Divergence = 2.003712\n",
      "Epoch: 46\tFidelity = 0.518776\tKL_Divergence = 1.967787\n",
      "Epoch: 47\tFidelity = 0.517499\tKL_Divergence = 2.007433\n",
      "Epoch: 48\tFidelity = 0.518159\tKL_Divergence = 1.986613\n",
      "Epoch: 49\tFidelity = 0.518444\tKL_Divergence = 1.977845\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:21:33,491] Trial 133 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.518050\tKL_Divergence = 1.989983\n",
      "Total time elapsed during training: 30.392 s\n",
      "Trial 133 pruned. \n",
      "Epoch: 1\tFidelity = 0.519075\tKL_Divergence = 1.958888\n",
      "Epoch: 2\tFidelity = 0.519395\tKL_Divergence = 1.949525\n",
      "Epoch: 3\tFidelity = 0.518548\tKL_Divergence = 1.974597\n",
      "Epoch: 4\tFidelity = 0.520374\tKL_Divergence = 1.921669\n",
      "Epoch: 5\tFidelity = 0.516645\tKL_Divergence = 2.035543\n",
      "Epoch: 6\tFidelity = 0.522003\tKL_Divergence = 1.878382\n",
      "Epoch: 7\tFidelity = 0.521200\tKL_Divergence = 1.899260\n",
      "Epoch: 8\tFidelity = 0.517997\tKL_Divergence = 1.991618\n",
      "Epoch: 9\tFidelity = 0.514735\tKL_Divergence = 2.103760\n",
      "Epoch: 10\tFidelity = 0.518782\tKL_Divergence = 1.967250\n",
      "Epoch: 11\tFidelity = 0.515589\tKL_Divergence = 2.072137\n",
      "Epoch: 12\tFidelity = 0.520983\tKL_Divergence = 1.905107\n",
      "Epoch: 13\tFidelity = 0.519876\tKL_Divergence = 1.935734\n",
      "Epoch: 14\tFidelity = 0.516841\tKL_Divergence = 2.028926\n",
      "Epoch: 15\tFidelity = 0.516999\tKL_Divergence = 2.023675\n",
      "Epoch: 16\tFidelity = 0.520167\tKL_Divergence = 1.927223\n",
      "Epoch: 17\tFidelity = 0.519618\tKL_Divergence = 1.943122\n",
      "Epoch: 18\tFidelity = 0.515276\tKL_Divergence = 2.083626\n",
      "Epoch: 19\tFidelity = 0.519112\tKL_Divergence = 1.957843\n",
      "Epoch: 20\tFidelity = 0.520470\tKL_Divergence = 1.919116\n",
      "Epoch: 21\tFidelity = 0.519038\tKL_Divergence = 1.960007\n",
      "Epoch: 22\tFidelity = 0.516643\tKL_Divergence = 2.035604\n",
      "Epoch: 23\tFidelity = 0.517023\tKL_Divergence = 2.022953\n",
      "Epoch: 24\tFidelity = 0.515314\tKL_Divergence = 2.082365\n",
      "Epoch: 25\tFidelity = 0.518236\tKL_Divergence = 1.984225\n",
      "Epoch: 26\tFidelity = 0.517172\tKL_Divergence = 2.017819\n",
      "Epoch: 27\tFidelity = 0.519363\tKL_Divergence = 1.950461\n",
      "Epoch: 28\tFidelity = 0.520837\tKL_Divergence = 1.909130\n",
      "Epoch: 29\tFidelity = 0.518824\tKL_Divergence = 1.966334\n",
      "Epoch: 30\tFidelity = 0.516523\tKL_Divergence = 2.039491\n",
      "Epoch: 31\tFidelity = 0.518154\tKL_Divergence = 1.986322\n",
      "Epoch: 32\tFidelity = 0.515419\tKL_Divergence = 2.078359\n",
      "Epoch: 33\tFidelity = 0.515453\tKL_Divergence = 2.077012\n",
      "Epoch: 34\tFidelity = 0.516456\tKL_Divergence = 2.041847\n",
      "Epoch: 35\tFidelity = 0.516125\tKL_Divergence = 2.053382\n",
      "Epoch: 36\tFidelity = 0.514937\tKL_Divergence = 2.096323\n",
      "Epoch: 37\tFidelity = 0.518712\tKL_Divergence = 1.969689\n",
      "Epoch: 38\tFidelity = 0.515867\tKL_Divergence = 2.062453\n",
      "Epoch: 39\tFidelity = 0.520085\tKL_Divergence = 1.929403\n",
      "Epoch: 40\tFidelity = 0.516361\tKL_Divergence = 2.044457\n",
      "Epoch: 41\tFidelity = 0.517023\tKL_Divergence = 2.022367\n",
      "Epoch: 42\tFidelity = 0.515722\tKL_Divergence = 2.067089\n",
      "Epoch: 43\tFidelity = 0.519513\tKL_Divergence = 1.945694\n",
      "Epoch: 44\tFidelity = 0.517495\tKL_Divergence = 2.007051\n",
      "Epoch: 45\tFidelity = 0.518849\tKL_Divergence = 1.965272\n",
      "Epoch: 46\tFidelity = 0.518744\tKL_Divergence = 1.968553\n",
      "Epoch: 47\tFidelity = 0.517933\tKL_Divergence = 1.993348\n",
      "Epoch: 48\tFidelity = 0.515586\tKL_Divergence = 2.072210\n",
      "Epoch: 49\tFidelity = 0.518464\tKL_Divergence = 1.976752\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:22:10,596] Trial 134 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.516233\tKL_Divergence = 2.049408\n",
      "Total time elapsed during training: 36.958 s\n",
      "Trial 134 pruned. \n",
      "Epoch: 1\tFidelity = 0.516887\tKL_Divergence = 2.027323\n",
      "Epoch: 2\tFidelity = 0.518588\tKL_Divergence = 1.973398\n",
      "Epoch: 3\tFidelity = 0.518388\tKL_Divergence = 1.979544\n",
      "Epoch: 4\tFidelity = 0.517192\tKL_Divergence = 2.017384\n",
      "Epoch: 5\tFidelity = 0.518257\tKL_Divergence = 1.983574\n",
      "Epoch: 6\tFidelity = 0.516845\tKL_Divergence = 2.028848\n",
      "Epoch: 7\tFidelity = 0.518451\tKL_Divergence = 1.977621\n",
      "Epoch: 8\tFidelity = 0.517396\tKL_Divergence = 2.010732\n",
      "Epoch: 9\tFidelity = 0.517620\tKL_Divergence = 2.003552\n",
      "Epoch: 10\tFidelity = 0.520625\tKL_Divergence = 1.914899\n",
      "Epoch: 11\tFidelity = 0.517650\tKL_Divergence = 2.002599\n",
      "Epoch: 12\tFidelity = 0.516476\tKL_Divergence = 2.041279\n",
      "Epoch: 13\tFidelity = 0.518161\tKL_Divergence = 1.986537\n",
      "Epoch: 14\tFidelity = 0.517823\tKL_Divergence = 1.997121\n",
      "Epoch: 15\tFidelity = 0.517572\tKL_Divergence = 2.005105\n",
      "Epoch: 16\tFidelity = 0.517679\tKL_Divergence = 2.001685\n",
      "Epoch: 17\tFidelity = 0.517492\tKL_Divergence = 2.007672\n",
      "Epoch: 18\tFidelity = 0.520142\tKL_Divergence = 1.928293\n",
      "Epoch: 19\tFidelity = 0.516363\tKL_Divergence = 2.045183\n",
      "Epoch: 20\tFidelity = 0.517634\tKL_Divergence = 2.003122\n",
      "Epoch: 21\tFidelity = 0.515732\tKL_Divergence = 2.067250\n",
      "Epoch: 22\tFidelity = 0.519600\tKL_Divergence = 1.943637\n",
      "Epoch: 23\tFidelity = 0.520259\tKL_Divergence = 1.925013\n",
      "Epoch: 24\tFidelity = 0.518137\tKL_Divergence = 1.987311\n",
      "Epoch: 25\tFidelity = 0.514404\tKL_Divergence = 2.116740\n",
      "Epoch: 26\tFidelity = 0.518000\tKL_Divergence = 1.991577\n",
      "Epoch: 27\tFidelity = 0.519123\tKL_Divergence = 1.957521\n",
      "Epoch: 28\tFidelity = 0.519734\tKL_Divergence = 1.939803\n",
      "Epoch: 29\tFidelity = 0.517176\tKL_Divergence = 2.017918\n",
      "Epoch: 30\tFidelity = 0.517190\tKL_Divergence = 2.017485\n",
      "Epoch: 31\tFidelity = 0.518827\tKL_Divergence = 1.966314\n",
      "Epoch: 32\tFidelity = 0.516749\tKL_Divergence = 2.032109\n",
      "Epoch: 33\tFidelity = 0.520520\tKL_Divergence = 1.917800\n",
      "Epoch: 34\tFidelity = 0.516893\tKL_Divergence = 2.027283\n",
      "Epoch: 35\tFidelity = 0.515474\tKL_Divergence = 2.076568\n",
      "Epoch: 36\tFidelity = 0.519065\tKL_Divergence = 1.959231\n",
      "Epoch: 37\tFidelity = 0.517747\tKL_Divergence = 1.999545\n",
      "Epoch: 38\tFidelity = 0.519156\tKL_Divergence = 1.956575\n",
      "Epoch: 39\tFidelity = 0.518738\tKL_Divergence = 1.968971\n",
      "Epoch: 40\tFidelity = 0.518436\tKL_Divergence = 1.978123\n",
      "Epoch: 41\tFidelity = 0.519246\tKL_Divergence = 1.953923\n",
      "Epoch: 42\tFidelity = 0.516614\tKL_Divergence = 2.036672\n",
      "Epoch: 43\tFidelity = 0.517634\tKL_Divergence = 2.003145\n",
      "Epoch: 44\tFidelity = 0.518675\tKL_Divergence = 1.970888\n",
      "Epoch: 45\tFidelity = 0.519904\tKL_Divergence = 1.934998\n",
      "Epoch: 46\tFidelity = 0.520631\tKL_Divergence = 1.914811\n",
      "Epoch: 47\tFidelity = 0.519353\tKL_Divergence = 1.950854\n",
      "Epoch: 48\tFidelity = 0.518578\tKL_Divergence = 1.973883\n",
      "Epoch: 49\tFidelity = 0.517443\tKL_Divergence = 2.009314\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:22:47,255] Trial 135 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.518323\tKL_Divergence = 1.981642\n",
      "Total time elapsed during training: 36.517 s\n",
      "Trial 135 pruned. \n",
      "Epoch: 1\tFidelity = 0.514754\tKL_Divergence = 2.103359\n",
      "Epoch: 2\tFidelity = 0.515246\tKL_Divergence = 2.084968\n",
      "Epoch: 3\tFidelity = 0.519831\tKL_Divergence = 1.937099\n",
      "Epoch: 4\tFidelity = 0.521733\tKL_Divergence = 1.885426\n",
      "Epoch: 5\tFidelity = 0.518573\tKL_Divergence = 1.974008\n",
      "Epoch: 6\tFidelity = 0.516705\tKL_Divergence = 2.033587\n",
      "Epoch: 7\tFidelity = 0.519589\tKL_Divergence = 1.943970\n",
      "Epoch: 8\tFidelity = 0.520127\tKL_Divergence = 1.928611\n",
      "Epoch: 9\tFidelity = 0.517104\tKL_Divergence = 2.020317\n",
      "Epoch: 10\tFidelity = 0.514386\tKL_Divergence = 2.117479\n",
      "Epoch: 11\tFidelity = 0.516734\tKL_Divergence = 2.032569\n",
      "Epoch: 12\tFidelity = 0.517281\tKL_Divergence = 2.014415\n",
      "Epoch: 13\tFidelity = 0.515135\tKL_Divergence = 2.088923\n",
      "Epoch: 14\tFidelity = 0.521189\tKL_Divergence = 1.899446\n",
      "Epoch: 15\tFidelity = 0.517847\tKL_Divergence = 1.996380\n",
      "Epoch: 16\tFidelity = 0.515159\tKL_Divergence = 2.088144\n",
      "Epoch: 17\tFidelity = 0.518460\tKL_Divergence = 1.977421\n",
      "Epoch: 18\tFidelity = 0.519862\tKL_Divergence = 1.935976\n",
      "Epoch: 19\tFidelity = 0.519114\tKL_Divergence = 1.957745\n",
      "Epoch: 20\tFidelity = 0.515658\tKL_Divergence = 2.069950\n",
      "Epoch: 21\tFidelity = 0.517268\tKL_Divergence = 2.014989\n",
      "Epoch: 22\tFidelity = 0.516078\tKL_Divergence = 2.055096\n",
      "Epoch: 23\tFidelity = 0.520639\tKL_Divergence = 1.914551\n",
      "Epoch: 24\tFidelity = 0.516349\tKL_Divergence = 2.045600\n",
      "Epoch: 25\tFidelity = 0.516453\tKL_Divergence = 2.042055\n",
      "Epoch: 26\tFidelity = 0.519910\tKL_Divergence = 1.934845\n",
      "Epoch: 27\tFidelity = 0.516819\tKL_Divergence = 2.029784\n",
      "Epoch: 28\tFidelity = 0.518501\tKL_Divergence = 1.975932\n",
      "Epoch: 29\tFidelity = 0.516413\tKL_Divergence = 2.043405\n",
      "Epoch: 30\tFidelity = 0.517305\tKL_Divergence = 2.013746\n",
      "Epoch: 31\tFidelity = 0.518700\tKL_Divergence = 1.969840\n",
      "Epoch: 32\tFidelity = 0.518838\tKL_Divergence = 1.966013\n",
      "Epoch: 33\tFidelity = 0.517613\tKL_Divergence = 2.003779\n",
      "Epoch: 34\tFidelity = 0.520763\tKL_Divergence = 1.911205\n",
      "Epoch: 35\tFidelity = 0.518478\tKL_Divergence = 1.976825\n",
      "Epoch: 36\tFidelity = 0.518410\tKL_Divergence = 1.978966\n",
      "Epoch: 37\tFidelity = 0.517057\tKL_Divergence = 2.021801\n",
      "Epoch: 38\tFidelity = 0.516168\tKL_Divergence = 2.051865\n",
      "Epoch: 39\tFidelity = 0.514664\tKL_Divergence = 2.106482\n",
      "Epoch: 40\tFidelity = 0.517910\tKL_Divergence = 1.994430\n",
      "Epoch: 41\tFidelity = 0.517888\tKL_Divergence = 1.994934\n",
      "Epoch: 42\tFidelity = 0.517023\tKL_Divergence = 2.022825\n",
      "Epoch: 43\tFidelity = 0.518588\tKL_Divergence = 1.973532\n",
      "Epoch: 44\tFidelity = 0.519238\tKL_Divergence = 1.954169\n",
      "Epoch: 45\tFidelity = 0.519816\tKL_Divergence = 1.937518\n",
      "Epoch: 46\tFidelity = 0.516705\tKL_Divergence = 2.033598\n",
      "Epoch: 47\tFidelity = 0.518354\tKL_Divergence = 1.980675\n",
      "Epoch: 48\tFidelity = 0.516566\tKL_Divergence = 2.038300\n",
      "Epoch: 49\tFidelity = 0.515530\tKL_Divergence = 2.074583\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:23:29,626] Trial 136 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.519110\tKL_Divergence = 1.957960\n",
      "Total time elapsed during training: 42.230 s\n",
      "Trial 136 pruned. \n",
      "Epoch: 1\tFidelity = 0.514311\tKL_Divergence = 2.120412\n",
      "Epoch: 2\tFidelity = 0.515660\tKL_Divergence = 2.069890\n",
      "Epoch: 3\tFidelity = 0.518076\tKL_Divergence = 1.989255\n",
      "Epoch: 4\tFidelity = 0.517560\tKL_Divergence = 2.005556\n",
      "Epoch: 5\tFidelity = 0.515973\tKL_Divergence = 2.058785\n",
      "Epoch: 6\tFidelity = 0.515885\tKL_Divergence = 2.061911\n",
      "Epoch: 7\tFidelity = 0.515472\tKL_Divergence = 2.076686\n",
      "Epoch: 8\tFidelity = 0.517569\tKL_Divergence = 2.005275\n",
      "Epoch: 9\tFidelity = 0.516865\tKL_Divergence = 2.028246\n",
      "Epoch: 10\tFidelity = 0.516678\tKL_Divergence = 2.034537\n",
      "Epoch: 11\tFidelity = 0.517435\tKL_Divergence = 2.009575\n",
      "Epoch: 12\tFidelity = 0.516854\tKL_Divergence = 2.028639\n",
      "Epoch: 13\tFidelity = 0.516887\tKL_Divergence = 2.027544\n",
      "Epoch: 14\tFidelity = 0.517388\tKL_Divergence = 2.011101\n",
      "Epoch: 15\tFidelity = 0.517473\tKL_Divergence = 2.008349\n",
      "Epoch: 16\tFidelity = 0.515739\tKL_Divergence = 2.067069\n",
      "Epoch: 17\tFidelity = 0.517521\tKL_Divergence = 2.006808\n",
      "Epoch: 18\tFidelity = 0.520654\tKL_Divergence = 1.914160\n",
      "Epoch: 19\tFidelity = 0.518032\tKL_Divergence = 1.990661\n",
      "Epoch: 20\tFidelity = 0.516543\tKL_Divergence = 2.039107\n",
      "Epoch: 21\tFidelity = 0.518063\tKL_Divergence = 1.989651\n",
      "Epoch: 22\tFidelity = 0.516529\tKL_Divergence = 2.039561\n",
      "Epoch: 23\tFidelity = 0.518642\tKL_Divergence = 1.971919\n",
      "Epoch: 24\tFidelity = 0.516810\tKL_Divergence = 2.030073\n",
      "Epoch: 25\tFidelity = 0.516628\tKL_Divergence = 2.036199\n",
      "Epoch: 26\tFidelity = 0.517066\tKL_Divergence = 2.021590\n",
      "Epoch: 27\tFidelity = 0.517011\tKL_Divergence = 2.023407\n",
      "Epoch: 28\tFidelity = 0.517590\tKL_Divergence = 2.004593\n",
      "Epoch: 29\tFidelity = 0.517893\tKL_Divergence = 1.994985\n",
      "Epoch: 30\tFidelity = 0.518146\tKL_Divergence = 1.987074\n",
      "Epoch: 31\tFidelity = 0.516252\tKL_Divergence = 2.049041\n",
      "Epoch: 32\tFidelity = 0.517572\tKL_Divergence = 2.005159\n",
      "Epoch: 33\tFidelity = 0.517531\tKL_Divergence = 2.006454\n",
      "Epoch: 34\tFidelity = 0.517969\tKL_Divergence = 1.992607\n",
      "Epoch: 35\tFidelity = 0.518227\tKL_Divergence = 1.984565\n",
      "Epoch: 36\tFidelity = 0.516790\tKL_Divergence = 2.030738\n",
      "Epoch: 37\tFidelity = 0.518357\tKL_Divergence = 1.980551\n",
      "Epoch: 38\tFidelity = 0.514716\tKL_Divergence = 2.104781\n",
      "Epoch: 39\tFidelity = 0.519109\tKL_Divergence = 1.957977\n",
      "Epoch: 40\tFidelity = 0.516091\tKL_Divergence = 2.054663\n",
      "Epoch: 41\tFidelity = 0.516335\tKL_Divergence = 2.046200\n",
      "Epoch: 42\tFidelity = 0.516287\tKL_Divergence = 2.047834\n",
      "Epoch: 43\tFidelity = 0.517006\tKL_Divergence = 2.023586\n",
      "Epoch: 44\tFidelity = 0.520556\tKL_Divergence = 1.916841\n",
      "Epoch: 45\tFidelity = 0.517116\tKL_Divergence = 2.019961\n",
      "Epoch: 46\tFidelity = 0.515459\tKL_Divergence = 2.077131\n",
      "Epoch: 47\tFidelity = 0.515691\tKL_Divergence = 2.068772\n",
      "Epoch: 48\tFidelity = 0.517627\tKL_Divergence = 2.003382\n",
      "Epoch: 49\tFidelity = 0.517083\tKL_Divergence = 2.021015\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:24:06,799] Trial 137 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.518835\tKL_Divergence = 1.966084\n",
      "Total time elapsed during training: 36.943 s\n",
      "Trial 137 pruned. \n",
      "Epoch: 1\tFidelity = 0.516019\tKL_Divergence = 2.057164\n",
      "Epoch: 2\tFidelity = 0.516107\tKL_Divergence = 2.054067\n",
      "Epoch: 3\tFidelity = 0.518054\tKL_Divergence = 1.989923\n",
      "Epoch: 4\tFidelity = 0.516731\tKL_Divergence = 2.032731\n",
      "Epoch: 5\tFidelity = 0.518921\tKL_Divergence = 1.963531\n",
      "Epoch: 6\tFidelity = 0.517231\tKL_Divergence = 2.016173\n",
      "Epoch: 7\tFidelity = 0.517837\tKL_Divergence = 1.996727\n",
      "Epoch: 8\tFidelity = 0.514975\tKL_Divergence = 2.094985\n",
      "Epoch: 9\tFidelity = 0.519156\tKL_Divergence = 1.956554\n",
      "Epoch: 10\tFidelity = 0.515441\tKL_Divergence = 2.077787\n",
      "Epoch: 11\tFidelity = 0.516865\tKL_Divergence = 2.028228\n",
      "Epoch: 12\tFidelity = 0.520633\tKL_Divergence = 1.914723\n",
      "Epoch: 13\tFidelity = 0.517313\tKL_Divergence = 2.013472\n",
      "Epoch: 14\tFidelity = 0.518782\tKL_Divergence = 1.967664\n",
      "Epoch: 15\tFidelity = 0.516475\tKL_Divergence = 2.041377\n",
      "Epoch: 16\tFidelity = 0.518000\tKL_Divergence = 1.991582\n",
      "Epoch: 17\tFidelity = 0.517652\tKL_Divergence = 2.002564\n",
      "Epoch: 18\tFidelity = 0.518577\tKL_Divergence = 1.973823\n",
      "Epoch: 19\tFidelity = 0.516729\tKL_Divergence = 2.032783\n",
      "Epoch: 20\tFidelity = 0.518060\tKL_Divergence = 1.989721\n",
      "Epoch: 21\tFidelity = 0.516098\tKL_Divergence = 2.054346\n",
      "Epoch: 22\tFidelity = 0.518486\tKL_Divergence = 1.976583\n",
      "Epoch: 23\tFidelity = 0.515194\tKL_Divergence = 2.086824\n",
      "Epoch: 24\tFidelity = 0.517418\tKL_Divergence = 2.010059\n",
      "Epoch: 25\tFidelity = 0.518454\tKL_Divergence = 1.977549\n",
      "Epoch: 26\tFidelity = 0.516548\tKL_Divergence = 2.038875\n",
      "Epoch: 27\tFidelity = 0.518917\tKL_Divergence = 1.963604\n",
      "Epoch: 28\tFidelity = 0.515382\tKL_Divergence = 2.079926\n",
      "Epoch: 29\tFidelity = 0.518877\tKL_Divergence = 1.964822\n",
      "Epoch: 30\tFidelity = 0.516884\tKL_Divergence = 2.027610\n",
      "Epoch: 31\tFidelity = 0.520135\tKL_Divergence = 1.928498\n",
      "Epoch: 32\tFidelity = 0.516292\tKL_Divergence = 2.047656\n",
      "Epoch: 33\tFidelity = 0.519749\tKL_Divergence = 1.939387\n",
      "Epoch: 34\tFidelity = 0.516637\tKL_Divergence = 2.035862\n",
      "Epoch: 35\tFidelity = 0.520590\tKL_Divergence = 1.915900\n",
      "Epoch: 36\tFidelity = 0.516246\tKL_Divergence = 2.049244\n",
      "Epoch: 37\tFidelity = 0.518153\tKL_Divergence = 1.986839\n",
      "Epoch: 38\tFidelity = 0.517991\tKL_Divergence = 1.991918\n",
      "Epoch: 39\tFidelity = 0.515536\tKL_Divergence = 2.074374\n",
      "Epoch: 40\tFidelity = 0.516078\tKL_Divergence = 2.055128\n",
      "Epoch: 41\tFidelity = 0.517025\tKL_Divergence = 2.022964\n",
      "Epoch: 42\tFidelity = 0.516671\tKL_Divergence = 2.034759\n",
      "Epoch: 43\tFidelity = 0.515736\tKL_Divergence = 2.067179\n",
      "Epoch: 44\tFidelity = 0.519034\tKL_Divergence = 1.960178\n",
      "Epoch: 45\tFidelity = 0.516193\tKL_Divergence = 2.051110\n",
      "Epoch: 46\tFidelity = 0.518814\tKL_Divergence = 1.966746\n",
      "Epoch: 47\tFidelity = 0.518027\tKL_Divergence = 1.990795\n",
      "Epoch: 48\tFidelity = 0.518131\tKL_Divergence = 1.987565\n",
      "Epoch: 49\tFidelity = 0.515002\tKL_Divergence = 2.094033\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:24:37,743] Trial 138 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.518961\tKL_Divergence = 1.962370\n",
      "Total time elapsed during training: 30.791 s\n",
      "Trial 138 pruned. \n",
      "Epoch: 1\tFidelity = 0.516984\tKL_Divergence = 2.024327\n",
      "Epoch: 2\tFidelity = 0.517757\tKL_Divergence = 1.999302\n",
      "Epoch: 3\tFidelity = 0.517780\tKL_Divergence = 1.998562\n",
      "Epoch: 4\tFidelity = 0.514492\tKL_Divergence = 2.113409\n",
      "Epoch: 5\tFidelity = 0.515817\tKL_Divergence = 2.064290\n",
      "Epoch: 6\tFidelity = 0.517565\tKL_Divergence = 2.005401\n",
      "Epoch: 7\tFidelity = 0.517749\tKL_Divergence = 1.999537\n",
      "Epoch: 8\tFidelity = 0.516516\tKL_Divergence = 2.040033\n",
      "Epoch: 9\tFidelity = 0.517113\tKL_Divergence = 2.020050\n",
      "Epoch: 10\tFidelity = 0.518018\tKL_Divergence = 1.991081\n",
      "Epoch: 11\tFidelity = 0.519081\tKL_Divergence = 1.958799\n",
      "Epoch: 12\tFidelity = 0.516163\tKL_Divergence = 2.052156\n",
      "Epoch: 13\tFidelity = 0.516291\tKL_Divergence = 2.047713\n",
      "Epoch: 14\tFidelity = 0.515216\tKL_Divergence = 2.086051\n",
      "Epoch: 15\tFidelity = 0.517077\tKL_Divergence = 2.021214\n",
      "Epoch: 16\tFidelity = 0.516737\tKL_Divergence = 2.032510\n",
      "Epoch: 17\tFidelity = 0.516542\tKL_Divergence = 2.039087\n",
      "Epoch: 18\tFidelity = 0.517563\tKL_Divergence = 2.005412\n",
      "Epoch: 19\tFidelity = 0.516259\tKL_Divergence = 2.048801\n",
      "Epoch: 20\tFidelity = 0.516317\tKL_Divergence = 2.046776\n",
      "Epoch: 21\tFidelity = 0.519297\tKL_Divergence = 1.952465\n",
      "Epoch: 22\tFidelity = 0.515945\tKL_Divergence = 2.059746\n",
      "Epoch: 23\tFidelity = 0.519772\tKL_Divergence = 1.938714\n",
      "Epoch: 24\tFidelity = 0.517273\tKL_Divergence = 2.014817\n",
      "Epoch: 25\tFidelity = 0.517420\tKL_Divergence = 2.010037\n",
      "Epoch: 26\tFidelity = 0.516944\tKL_Divergence = 2.025587\n",
      "Epoch: 27\tFidelity = 0.516646\tKL_Divergence = 2.035602\n",
      "Epoch: 28\tFidelity = 0.515615\tKL_Divergence = 2.071479\n",
      "Epoch: 29\tFidelity = 0.515931\tKL_Divergence = 2.060258\n",
      "Epoch: 30\tFidelity = 0.515813\tKL_Divergence = 2.064445\n",
      "Epoch: 31\tFidelity = 0.516333\tKL_Divergence = 2.046258\n",
      "Epoch: 32\tFidelity = 0.516572\tKL_Divergence = 2.038074\n",
      "Epoch: 33\tFidelity = 0.517683\tKL_Divergence = 2.001615\n",
      "Epoch: 34\tFidelity = 0.516530\tKL_Divergence = 2.039525\n",
      "Epoch: 35\tFidelity = 0.515774\tKL_Divergence = 2.065847\n",
      "Epoch: 36\tFidelity = 0.515272\tKL_Divergence = 2.083997\n",
      "Epoch: 37\tFidelity = 0.518372\tKL_Divergence = 1.980121\n",
      "Epoch: 38\tFidelity = 0.516222\tKL_Divergence = 2.050110\n",
      "Epoch: 39\tFidelity = 0.517366\tKL_Divergence = 2.011813\n",
      "Epoch: 40\tFidelity = 0.519392\tKL_Divergence = 1.949707\n",
      "Epoch: 41\tFidelity = 0.514652\tKL_Divergence = 2.107246\n",
      "Epoch: 42\tFidelity = 0.517058\tKL_Divergence = 2.021862\n",
      "Epoch: 43\tFidelity = 0.516614\tKL_Divergence = 2.036681\n",
      "Epoch: 44\tFidelity = 0.516194\tKL_Divergence = 2.051071\n",
      "Epoch: 45\tFidelity = 0.517201\tKL_Divergence = 2.017164\n",
      "Epoch: 46\tFidelity = 0.516185\tKL_Divergence = 2.051389\n",
      "Epoch: 47\tFidelity = 0.516600\tKL_Divergence = 2.037166\n",
      "Epoch: 48\tFidelity = 0.517041\tKL_Divergence = 2.022435\n",
      "Epoch: 49\tFidelity = 0.517008\tKL_Divergence = 2.023523\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:25:57,074] Trial 139 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.517433\tKL_Divergence = 2.009626\n",
      "Total time elapsed during training: 79.183 s\n",
      "Trial 139 pruned. \n",
      "Epoch: 1\tFidelity = 0.518928\tKL_Divergence = 1.963356\n",
      "Epoch: 2\tFidelity = 0.519693\tKL_Divergence = 1.940961\n",
      "Epoch: 3\tFidelity = 0.515248\tKL_Divergence = 2.084853\n",
      "Epoch: 4\tFidelity = 0.518407\tKL_Divergence = 1.979019\n",
      "Epoch: 5\tFidelity = 0.517541\tKL_Divergence = 2.006143\n",
      "Epoch: 6\tFidelity = 0.517466\tKL_Divergence = 2.008535\n",
      "Epoch: 7\tFidelity = 0.517386\tKL_Divergence = 2.010970\n",
      "Epoch: 8\tFidelity = 0.517494\tKL_Divergence = 2.007591\n",
      "Epoch: 9\tFidelity = 0.519606\tKL_Divergence = 1.943477\n",
      "Epoch: 10\tFidelity = 0.520386\tKL_Divergence = 1.921467\n",
      "Epoch: 11\tFidelity = 0.514904\tKL_Divergence = 2.097367\n",
      "Epoch: 12\tFidelity = 0.519196\tKL_Divergence = 1.955407\n",
      "Epoch: 13\tFidelity = 0.515243\tKL_Divergence = 2.084869\n",
      "Epoch: 14\tFidelity = 0.514051\tKL_Divergence = 2.130672\n",
      "Epoch: 15\tFidelity = 0.514854\tKL_Divergence = 2.099531\n",
      "Epoch: 16\tFidelity = 0.519266\tKL_Divergence = 1.953274\n",
      "Epoch: 17\tFidelity = 0.516801\tKL_Divergence = 2.030315\n",
      "Epoch: 18\tFidelity = 0.519958\tKL_Divergence = 1.933457\n",
      "Epoch: 19\tFidelity = 0.517106\tKL_Divergence = 2.020210\n",
      "Epoch: 20\tFidelity = 0.514652\tKL_Divergence = 2.107140\n",
      "Epoch: 21\tFidelity = 0.518182\tKL_Divergence = 1.985921\n",
      "Epoch: 22\tFidelity = 0.515088\tKL_Divergence = 2.090740\n",
      "Epoch: 23\tFidelity = 0.515804\tKL_Divergence = 2.064518\n",
      "Epoch: 24\tFidelity = 0.517487\tKL_Divergence = 2.007870\n",
      "Epoch: 25\tFidelity = 0.515959\tKL_Divergence = 2.059286\n",
      "Epoch: 26\tFidelity = 0.515742\tKL_Divergence = 2.066890\n",
      "Epoch: 27\tFidelity = 0.517144\tKL_Divergence = 2.018886\n",
      "Epoch: 28\tFidelity = 0.515075\tKL_Divergence = 2.091059\n",
      "Epoch: 29\tFidelity = 0.514404\tKL_Divergence = 2.116801\n",
      "Epoch: 30\tFidelity = 0.514863\tKL_Divergence = 2.099190\n",
      "Epoch: 31\tFidelity = 0.520120\tKL_Divergence = 1.928944\n",
      "Epoch: 32\tFidelity = 0.514002\tKL_Divergence = 2.132678\n",
      "Epoch: 33\tFidelity = 0.515302\tKL_Divergence = 2.082876\n",
      "Epoch: 34\tFidelity = 0.515547\tKL_Divergence = 2.073969\n",
      "Epoch: 35\tFidelity = 0.519434\tKL_Divergence = 1.948486\n",
      "Epoch: 36\tFidelity = 0.516057\tKL_Divergence = 2.055825\n",
      "Epoch: 37\tFidelity = 0.518084\tKL_Divergence = 1.988958\n",
      "Epoch: 38\tFidelity = 0.516482\tKL_Divergence = 2.041133\n",
      "Epoch: 39\tFidelity = 0.514679\tKL_Divergence = 2.106100\n",
      "Epoch: 40\tFidelity = 0.519673\tKL_Divergence = 1.941546\n",
      "Epoch: 41\tFidelity = 0.517711\tKL_Divergence = 2.000628\n",
      "Epoch: 42\tFidelity = 0.515393\tKL_Divergence = 2.079531\n",
      "Epoch: 43\tFidelity = 0.518505\tKL_Divergence = 1.975947\n",
      "Epoch: 44\tFidelity = 0.515902\tKL_Divergence = 2.061268\n",
      "Epoch: 45\tFidelity = 0.516061\tKL_Divergence = 2.055572\n",
      "Epoch: 46\tFidelity = 0.517082\tKL_Divergence = 2.021078\n",
      "Epoch: 47\tFidelity = 0.518047\tKL_Divergence = 1.990154\n",
      "Epoch: 48\tFidelity = 0.520323\tKL_Divergence = 1.923238\n",
      "Epoch: 49\tFidelity = 0.514267\tKL_Divergence = 2.121820\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:26:55,813] Trial 140 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.516523\tKL_Divergence = 2.039751\n",
      "Total time elapsed during training: 58.589 s\n",
      "Trial 140 pruned. \n",
      "Epoch: 1\tFidelity = 0.517506\tKL_Divergence = 2.007275\n",
      "Epoch: 2\tFidelity = 0.516703\tKL_Divergence = 2.033627\n",
      "Epoch: 3\tFidelity = 0.516604\tKL_Divergence = 2.036985\n",
      "Epoch: 4\tFidelity = 0.516809\tKL_Divergence = 2.030089\n",
      "Epoch: 5\tFidelity = 0.516608\tKL_Divergence = 2.036868\n",
      "Epoch: 6\tFidelity = 0.516742\tKL_Divergence = 2.032366\n",
      "Epoch: 7\tFidelity = 0.519195\tKL_Divergence = 1.955230\n",
      "Epoch: 8\tFidelity = 0.518235\tKL_Divergence = 1.984270\n",
      "Epoch: 9\tFidelity = 0.516376\tKL_Divergence = 2.044746\n",
      "Epoch: 10\tFidelity = 0.517250\tKL_Divergence = 2.015564\n",
      "Epoch: 11\tFidelity = 0.516679\tKL_Divergence = 2.034476\n",
      "Epoch: 12\tFidelity = 0.515504\tKL_Divergence = 2.075513\n",
      "Epoch: 13\tFidelity = 0.518827\tKL_Divergence = 1.966243\n",
      "Epoch: 14\tFidelity = 0.516607\tKL_Divergence = 2.036868\n",
      "Epoch: 15\tFidelity = 0.515296\tKL_Divergence = 2.083054\n",
      "Epoch: 16\tFidelity = 0.516464\tKL_Divergence = 2.041541\n",
      "Epoch: 17\tFidelity = 0.516961\tKL_Divergence = 2.024918\n",
      "Epoch: 18\tFidelity = 0.518460\tKL_Divergence = 1.977338\n",
      "Epoch: 19\tFidelity = 0.516330\tKL_Divergence = 2.046245\n",
      "Epoch: 20\tFidelity = 0.518377\tKL_Divergence = 1.979885\n",
      "Epoch: 21\tFidelity = 0.515510\tKL_Divergence = 2.075245\n",
      "Epoch: 22\tFidelity = 0.518989\tKL_Divergence = 1.961423\n",
      "Epoch: 23\tFidelity = 0.515958\tKL_Divergence = 2.059283\n",
      "Epoch: 24\tFidelity = 0.515014\tKL_Divergence = 2.093503\n",
      "Epoch: 25\tFidelity = 0.514944\tKL_Divergence = 2.096070\n",
      "Epoch: 26\tFidelity = 0.518318\tKL_Divergence = 1.981724\n",
      "Epoch: 27\tFidelity = 0.516745\tKL_Divergence = 2.032142\n",
      "Epoch: 28\tFidelity = 0.515382\tKL_Divergence = 2.079871\n",
      "Epoch: 29\tFidelity = 0.518604\tKL_Divergence = 1.973013\n",
      "Epoch: 30\tFidelity = 0.518374\tKL_Divergence = 1.979926\n",
      "Epoch: 31\tFidelity = 0.518189\tKL_Divergence = 1.985641\n",
      "Epoch: 32\tFidelity = 0.520496\tKL_Divergence = 1.918399\n",
      "Epoch: 33\tFidelity = 0.517234\tKL_Divergence = 2.015860\n",
      "Epoch: 34\tFidelity = 0.516027\tKL_Divergence = 2.056797\n",
      "Epoch: 35\tFidelity = 0.518997\tKL_Divergence = 1.961101\n",
      "Epoch: 36\tFidelity = 0.517629\tKL_Divergence = 2.003246\n",
      "Epoch: 37\tFidelity = 0.517675\tKL_Divergence = 2.001819\n",
      "Epoch: 38\tFidelity = 0.519224\tKL_Divergence = 1.954475\n",
      "Epoch: 39\tFidelity = 0.514500\tKL_Divergence = 2.112948\n",
      "Epoch: 40\tFidelity = 0.517443\tKL_Divergence = 2.009222\n",
      "Epoch: 41\tFidelity = 0.516093\tKL_Divergence = 2.054512\n",
      "Epoch: 42\tFidelity = 0.516545\tKL_Divergence = 2.038927\n",
      "Epoch: 43\tFidelity = 0.517287\tKL_Divergence = 2.014187\n",
      "Epoch: 44\tFidelity = 0.514680\tKL_Divergence = 2.106133\n",
      "Epoch: 45\tFidelity = 0.516664\tKL_Divergence = 2.034947\n",
      "Epoch: 46\tFidelity = 0.518186\tKL_Divergence = 1.985806\n",
      "Epoch: 47\tFidelity = 0.517143\tKL_Divergence = 2.019066\n",
      "Epoch: 48\tFidelity = 0.515927\tKL_Divergence = 2.060383\n",
      "Epoch: 49\tFidelity = 0.515327\tKL_Divergence = 2.081907\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:28:15,704] Trial 141 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.516719\tKL_Divergence = 2.033117\n",
      "Total time elapsed during training: 79.694 s\n",
      "Trial 141 pruned. \n",
      "Epoch: 1\tFidelity = 0.517248\tKL_Divergence = 2.015645\n",
      "Epoch: 2\tFidelity = 0.514600\tKL_Divergence = 2.109234\n",
      "Epoch: 3\tFidelity = 0.514994\tKL_Divergence = 2.094288\n",
      "Epoch: 4\tFidelity = 0.517444\tKL_Divergence = 2.009064\n",
      "Epoch: 5\tFidelity = 0.516836\tKL_Divergence = 2.029188\n",
      "Epoch: 6\tFidelity = 0.516086\tKL_Divergence = 2.054750\n",
      "Epoch: 7\tFidelity = 0.514976\tKL_Divergence = 2.094902\n",
      "Epoch: 8\tFidelity = 0.516558\tKL_Divergence = 2.038533\n",
      "Epoch: 9\tFidelity = 0.522421\tKL_Divergence = 1.867811\n",
      "Epoch: 10\tFidelity = 0.515667\tKL_Divergence = 2.069592\n",
      "Epoch: 11\tFidelity = 0.515628\tKL_Divergence = 2.070907\n",
      "Epoch: 12\tFidelity = 0.518575\tKL_Divergence = 1.973877\n",
      "Epoch: 13\tFidelity = 0.514753\tKL_Divergence = 2.103311\n",
      "Epoch: 14\tFidelity = 0.517858\tKL_Divergence = 1.995972\n",
      "Epoch: 15\tFidelity = 0.515373\tKL_Divergence = 2.080252\n",
      "Epoch: 16\tFidelity = 0.515952\tKL_Divergence = 2.059487\n",
      "Epoch: 17\tFidelity = 0.516318\tKL_Divergence = 2.046744\n",
      "Epoch: 18\tFidelity = 0.515832\tKL_Divergence = 2.063705\n",
      "Epoch: 19\tFidelity = 0.516400\tKL_Divergence = 2.043936\n",
      "Epoch: 20\tFidelity = 0.516910\tKL_Divergence = 2.026616\n",
      "Epoch: 21\tFidelity = 0.518318\tKL_Divergence = 1.981745\n",
      "Epoch: 22\tFidelity = 0.516884\tKL_Divergence = 2.027543\n",
      "Epoch: 23\tFidelity = 0.519660\tKL_Divergence = 1.941908\n",
      "Epoch: 24\tFidelity = 0.514531\tKL_Divergence = 2.111639\n",
      "Epoch: 25\tFidelity = 0.514447\tKL_Divergence = 2.115172\n",
      "Epoch: 26\tFidelity = 0.516310\tKL_Divergence = 2.047020\n",
      "Epoch: 27\tFidelity = 0.515332\tKL_Divergence = 2.081743\n",
      "Epoch: 28\tFidelity = 0.517429\tKL_Divergence = 2.009684\n",
      "Epoch: 29\tFidelity = 0.516662\tKL_Divergence = 2.034869\n",
      "Epoch: 30\tFidelity = 0.517392\tKL_Divergence = 2.010928\n",
      "Epoch: 31\tFidelity = 0.515097\tKL_Divergence = 2.090406\n",
      "Epoch: 32\tFidelity = 0.516124\tKL_Divergence = 2.053489\n",
      "Epoch: 33\tFidelity = 0.514578\tKL_Divergence = 2.110028\n",
      "Epoch: 34\tFidelity = 0.514612\tKL_Divergence = 2.108733\n",
      "Epoch: 35\tFidelity = 0.517238\tKL_Divergence = 2.015945\n",
      "Epoch: 36\tFidelity = 0.519252\tKL_Divergence = 1.953702\n",
      "Epoch: 37\tFidelity = 0.516489\tKL_Divergence = 2.040910\n",
      "Epoch: 38\tFidelity = 0.515583\tKL_Divergence = 2.072564\n",
      "Epoch: 39\tFidelity = 0.515927\tKL_Divergence = 2.060223\n",
      "Epoch: 40\tFidelity = 0.516418\tKL_Divergence = 2.043074\n",
      "Epoch: 41\tFidelity = 0.513708\tKL_Divergence = 2.144538\n",
      "Epoch: 42\tFidelity = 0.516581\tKL_Divergence = 2.037763\n",
      "Epoch: 43\tFidelity = 0.516341\tKL_Divergence = 2.045969\n",
      "Epoch: 44\tFidelity = 0.516218\tKL_Divergence = 2.050245\n",
      "Epoch: 45\tFidelity = 0.514841\tKL_Divergence = 2.100022\n",
      "Epoch: 46\tFidelity = 0.519480\tKL_Divergence = 1.947115\n",
      "Epoch: 47\tFidelity = 0.515961\tKL_Divergence = 2.059089\n",
      "Epoch: 48\tFidelity = 0.518015\tKL_Divergence = 1.991056\n",
      "Epoch: 49\tFidelity = 0.515053\tKL_Divergence = 2.091934\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:29:35,649] Trial 142 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.516507\tKL_Divergence = 2.040255\n",
      "Total time elapsed during training: 79.799 s\n",
      "Trial 142 pruned. \n",
      "Epoch: 1\tFidelity = 0.518021\tKL_Divergence = 1.990866\n",
      "Epoch: 2\tFidelity = 0.517143\tKL_Divergence = 2.018973\n",
      "Epoch: 3\tFidelity = 0.514546\tKL_Divergence = 2.111076\n",
      "Epoch: 4\tFidelity = 0.517303\tKL_Divergence = 2.013709\n",
      "Epoch: 5\tFidelity = 0.513473\tKL_Divergence = 2.154211\n",
      "Epoch: 6\tFidelity = 0.516766\tKL_Divergence = 2.031500\n",
      "Epoch: 7\tFidelity = 0.514249\tKL_Divergence = 2.122776\n",
      "Epoch: 8\tFidelity = 0.516806\tKL_Divergence = 2.030164\n",
      "Epoch: 9\tFidelity = 0.518718\tKL_Divergence = 1.969473\n",
      "Epoch: 10\tFidelity = 0.517458\tKL_Divergence = 2.008741\n",
      "Epoch: 11\tFidelity = 0.516051\tKL_Divergence = 2.056023\n",
      "Epoch: 12\tFidelity = 0.519345\tKL_Divergence = 1.951055\n",
      "Epoch: 13\tFidelity = 0.516272\tKL_Divergence = 2.048294\n",
      "Epoch: 14\tFidelity = 0.519949\tKL_Divergence = 1.933692\n",
      "Epoch: 15\tFidelity = 0.513029\tKL_Divergence = 2.173002\n",
      "Epoch: 16\tFidelity = 0.517599\tKL_Divergence = 2.004246\n",
      "Epoch: 17\tFidelity = 0.516365\tKL_Divergence = 2.045070\n",
      "Epoch: 18\tFidelity = 0.516095\tKL_Divergence = 2.054403\n",
      "Epoch: 19\tFidelity = 0.515395\tKL_Divergence = 2.079392\n",
      "Epoch: 20\tFidelity = 0.519029\tKL_Divergence = 1.960245\n",
      "Epoch: 21\tFidelity = 0.517675\tKL_Divergence = 2.001752\n",
      "Epoch: 22\tFidelity = 0.515676\tKL_Divergence = 2.069206\n",
      "Epoch: 23\tFidelity = 0.518298\tKL_Divergence = 1.982370\n",
      "Epoch: 24\tFidelity = 0.513614\tKL_Divergence = 2.148432\n",
      "Epoch: 25\tFidelity = 0.516103\tKL_Divergence = 2.054196\n",
      "Epoch: 26\tFidelity = 0.517488\tKL_Divergence = 2.007795\n",
      "Epoch: 27\tFidelity = 0.514847\tKL_Divergence = 2.099694\n",
      "Epoch: 28\tFidelity = 0.514381\tKL_Divergence = 2.117707\n",
      "Epoch: 29\tFidelity = 0.514159\tKL_Divergence = 2.126418\n",
      "Epoch: 30\tFidelity = 0.517842\tKL_Divergence = 1.996567\n",
      "Epoch: 31\tFidelity = 0.515582\tKL_Divergence = 2.072658\n",
      "Epoch: 32\tFidelity = 0.517477\tKL_Divergence = 2.008197\n",
      "Epoch: 33\tFidelity = 0.514961\tKL_Divergence = 2.095216\n",
      "Epoch: 34\tFidelity = 0.516552\tKL_Divergence = 2.038791\n",
      "Epoch: 35\tFidelity = 0.516378\tKL_Divergence = 2.044662\n",
      "Epoch: 36\tFidelity = 0.517797\tKL_Divergence = 1.997856\n",
      "Epoch: 37\tFidelity = 0.513983\tKL_Divergence = 2.133411\n",
      "Epoch: 38\tFidelity = 0.514701\tKL_Divergence = 2.105347\n",
      "Epoch: 39\tFidelity = 0.514634\tKL_Divergence = 2.107839\n",
      "Epoch: 40\tFidelity = 0.515011\tKL_Divergence = 2.093653\n",
      "Epoch: 41\tFidelity = 0.514393\tKL_Divergence = 2.117231\n",
      "Epoch: 42\tFidelity = 0.518304\tKL_Divergence = 1.982202\n",
      "Epoch: 43\tFidelity = 0.517762\tKL_Divergence = 1.999109\n",
      "Epoch: 44\tFidelity = 0.515802\tKL_Divergence = 2.064823\n",
      "Epoch: 45\tFidelity = 0.513220\tKL_Divergence = 2.164915\n",
      "Epoch: 46\tFidelity = 0.518198\tKL_Divergence = 1.985459\n",
      "Epoch: 47\tFidelity = 0.515434\tKL_Divergence = 2.078007\n",
      "Epoch: 48\tFidelity = 0.516909\tKL_Divergence = 2.026790\n",
      "Epoch: 49\tFidelity = 0.517223\tKL_Divergence = 2.016388\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:30:55,873] Trial 143 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.515892\tKL_Divergence = 2.061632\n",
      "Total time elapsed during training: 80.079 s\n",
      "Trial 143 pruned. \n",
      "Epoch: 1\tFidelity = 0.516498\tKL_Divergence = 2.040627\n",
      "Epoch: 2\tFidelity = 0.517513\tKL_Divergence = 2.007073\n",
      "Epoch: 3\tFidelity = 0.517627\tKL_Divergence = 2.003422\n",
      "Epoch: 4\tFidelity = 0.516934\tKL_Divergence = 2.025980\n",
      "Epoch: 5\tFidelity = 0.515608\tKL_Divergence = 2.071789\n",
      "Epoch: 6\tFidelity = 0.515543\tKL_Divergence = 2.074112\n",
      "Epoch: 7\tFidelity = 0.515487\tKL_Divergence = 2.076155\n",
      "Epoch: 8\tFidelity = 0.516087\tKL_Divergence = 2.054795\n",
      "Epoch: 9\tFidelity = 0.516658\tKL_Divergence = 2.035212\n",
      "Epoch: 10\tFidelity = 0.516743\tKL_Divergence = 2.032380\n",
      "Epoch: 11\tFidelity = 0.514480\tKL_Divergence = 2.113878\n",
      "Epoch: 12\tFidelity = 0.513427\tKL_Divergence = 2.156198\n",
      "Epoch: 13\tFidelity = 0.514653\tKL_Divergence = 2.107251\n",
      "Epoch: 14\tFidelity = 0.514505\tKL_Divergence = 2.112940\n",
      "Epoch: 15\tFidelity = 0.515746\tKL_Divergence = 2.066859\n",
      "Epoch: 16\tFidelity = 0.512753\tKL_Divergence = 2.185099\n",
      "Epoch: 17\tFidelity = 0.517786\tKL_Divergence = 1.998398\n",
      "Epoch: 18\tFidelity = 0.515783\tKL_Divergence = 2.065554\n",
      "Epoch: 19\tFidelity = 0.515823\tKL_Divergence = 2.064115\n",
      "Epoch: 20\tFidelity = 0.515070\tKL_Divergence = 2.091486\n",
      "Epoch: 21\tFidelity = 0.514303\tKL_Divergence = 2.120773\n",
      "Epoch: 22\tFidelity = 0.516669\tKL_Divergence = 2.034855\n",
      "Epoch: 23\tFidelity = 0.518226\tKL_Divergence = 1.984649\n",
      "Epoch: 24\tFidelity = 0.516127\tKL_Divergence = 2.053429\n",
      "Epoch: 25\tFidelity = 0.516485\tKL_Divergence = 2.041087\n",
      "Epoch: 26\tFidelity = 0.513039\tKL_Divergence = 2.172662\n",
      "Epoch: 27\tFidelity = 0.516350\tKL_Divergence = 2.045730\n",
      "Epoch: 28\tFidelity = 0.516201\tKL_Divergence = 2.050875\n",
      "Epoch: 29\tFidelity = 0.516084\tKL_Divergence = 2.054967\n",
      "Epoch: 30\tFidelity = 0.515867\tKL_Divergence = 2.062569\n",
      "Epoch: 31\tFidelity = 0.514447\tKL_Divergence = 2.115193\n",
      "Epoch: 32\tFidelity = 0.515922\tKL_Divergence = 2.060644\n",
      "Epoch: 33\tFidelity = 0.516963\tKL_Divergence = 2.025057\n",
      "Epoch: 34\tFidelity = 0.515864\tKL_Divergence = 2.062666\n",
      "Epoch: 35\tFidelity = 0.514921\tKL_Divergence = 2.097085\n",
      "Epoch: 36\tFidelity = 0.515018\tKL_Divergence = 2.093437\n",
      "Epoch: 37\tFidelity = 0.515125\tKL_Divergence = 2.089480\n",
      "Epoch: 38\tFidelity = 0.517978\tKL_Divergence = 1.992363\n",
      "Epoch: 39\tFidelity = 0.515431\tKL_Divergence = 2.078208\n",
      "Epoch: 40\tFidelity = 0.514561\tKL_Divergence = 2.110756\n",
      "Epoch: 41\tFidelity = 0.515237\tKL_Divergence = 2.085293\n",
      "Epoch: 42\tFidelity = 0.516428\tKL_Divergence = 2.043019\n",
      "Epoch: 43\tFidelity = 0.514238\tKL_Divergence = 2.123349\n",
      "Epoch: 44\tFidelity = 0.515690\tKL_Divergence = 2.068817\n",
      "Epoch: 45\tFidelity = 0.514302\tKL_Divergence = 2.120828\n",
      "Epoch: 46\tFidelity = 0.518742\tKL_Divergence = 1.968915\n",
      "Epoch: 47\tFidelity = 0.517086\tKL_Divergence = 2.020960\n",
      "Epoch: 48\tFidelity = 0.516386\tKL_Divergence = 2.044456\n",
      "Epoch: 49\tFidelity = 0.517513\tKL_Divergence = 2.007070\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:31:41,409] Trial 144 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.515007\tKL_Divergence = 2.093822\n",
      "Total time elapsed during training: 45.383 s\n",
      "Trial 144 pruned. \n",
      "Epoch: 1\tFidelity = 0.516806\tKL_Divergence = 2.030267\n",
      "Epoch: 2\tFidelity = 0.516818\tKL_Divergence = 2.029835\n",
      "Epoch: 3\tFidelity = 0.516209\tKL_Divergence = 2.050568\n",
      "Epoch: 4\tFidelity = 0.515428\tKL_Divergence = 2.078288\n",
      "Epoch: 5\tFidelity = 0.514278\tKL_Divergence = 2.121766\n",
      "Epoch: 6\tFidelity = 0.518383\tKL_Divergence = 1.979822\n",
      "Epoch: 7\tFidelity = 0.515012\tKL_Divergence = 2.093629\n",
      "Epoch: 8\tFidelity = 0.514326\tKL_Divergence = 2.119875\n",
      "Epoch: 9\tFidelity = 0.517665\tKL_Divergence = 2.002195\n",
      "Epoch: 10\tFidelity = 0.513883\tKL_Divergence = 2.137429\n",
      "Epoch: 11\tFidelity = 0.512601\tKL_Divergence = 2.191761\n",
      "Epoch: 12\tFidelity = 0.515501\tKL_Divergence = 2.075627\n",
      "Epoch: 13\tFidelity = 0.514284\tKL_Divergence = 2.121494\n",
      "Epoch: 14\tFidelity = 0.516819\tKL_Divergence = 2.029749\n",
      "Epoch: 15\tFidelity = 0.515140\tKL_Divergence = 2.088722\n",
      "Epoch: 16\tFidelity = 0.513924\tKL_Divergence = 2.135770\n",
      "Epoch: 17\tFidelity = 0.515536\tKL_Divergence = 2.074360\n",
      "Epoch: 18\tFidelity = 0.515446\tKL_Divergence = 2.077635\n",
      "Epoch: 19\tFidelity = 0.515992\tKL_Divergence = 2.058082\n",
      "Epoch: 20\tFidelity = 0.516478\tKL_Divergence = 2.041301\n",
      "Epoch: 21\tFidelity = 0.514583\tKL_Divergence = 2.109851\n",
      "Epoch: 22\tFidelity = 0.517831\tKL_Divergence = 1.996919\n",
      "Epoch: 23\tFidelity = 0.514188\tKL_Divergence = 2.125248\n",
      "Epoch: 24\tFidelity = 0.516334\tKL_Divergence = 2.046191\n",
      "Epoch: 25\tFidelity = 0.512155\tKL_Divergence = 2.211897\n",
      "Epoch: 26\tFidelity = 0.516935\tKL_Divergence = 2.025889\n",
      "Epoch: 27\tFidelity = 0.516154\tKL_Divergence = 2.052411\n",
      "Epoch: 28\tFidelity = 0.513165\tKL_Divergence = 2.167182\n",
      "Epoch: 29\tFidelity = 0.516467\tKL_Divergence = 2.041603\n",
      "Epoch: 30\tFidelity = 0.514436\tKL_Divergence = 2.115551\n",
      "Epoch: 31\tFidelity = 0.516743\tKL_Divergence = 2.032221\n",
      "Epoch: 32\tFidelity = 0.514299\tKL_Divergence = 2.120754\n",
      "Epoch: 33\tFidelity = 0.515958\tKL_Divergence = 2.059294\n",
      "Epoch: 34\tFidelity = 0.514852\tKL_Divergence = 2.099641\n",
      "Epoch: 35\tFidelity = 0.513724\tKL_Divergence = 2.143902\n",
      "Epoch: 36\tFidelity = 0.517147\tKL_Divergence = 2.018954\n",
      "Epoch: 37\tFidelity = 0.517964\tKL_Divergence = 1.992743\n",
      "Epoch: 38\tFidelity = 0.515580\tKL_Divergence = 2.072753\n",
      "Epoch: 39\tFidelity = 0.515997\tKL_Divergence = 2.057926\n",
      "Epoch: 40\tFidelity = 0.515902\tKL_Divergence = 2.061273\n",
      "Epoch: 41\tFidelity = 0.512666\tKL_Divergence = 2.188857\n",
      "Epoch: 42\tFidelity = 0.513751\tKL_Divergence = 2.142813\n",
      "Epoch: 43\tFidelity = 0.515134\tKL_Divergence = 2.089062\n",
      "Epoch: 44\tFidelity = 0.514223\tKL_Divergence = 2.123914\n",
      "Epoch: 45\tFidelity = 0.515616\tKL_Divergence = 2.071472\n",
      "Epoch: 46\tFidelity = 0.516283\tKL_Divergence = 2.047958\n",
      "Epoch: 47\tFidelity = 0.515925\tKL_Divergence = 2.060479\n",
      "Epoch: 48\tFidelity = 0.517305\tKL_Divergence = 2.013788\n",
      "Epoch: 49\tFidelity = 0.513584\tKL_Divergence = 2.149676\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:32:18,085] Trial 145 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.514861\tKL_Divergence = 2.099319\n",
      "Total time elapsed during training: 36.537 s\n",
      "Trial 145 pruned. \n",
      "Epoch: 1\tFidelity = 0.515114\tKL_Divergence = 2.089855\n",
      "Epoch: 2\tFidelity = 0.516018\tKL_Divergence = 2.057200\n",
      "Epoch: 3\tFidelity = 0.514383\tKL_Divergence = 2.117641\n",
      "Epoch: 4\tFidelity = 0.514837\tKL_Divergence = 2.100219\n",
      "Epoch: 5\tFidelity = 0.514549\tKL_Divergence = 2.111221\n",
      "Epoch: 6\tFidelity = 0.513577\tKL_Divergence = 2.149999\n",
      "Epoch: 7\tFidelity = 0.514612\tKL_Divergence = 2.108783\n",
      "Epoch: 8\tFidelity = 0.516079\tKL_Divergence = 2.055078\n",
      "Epoch: 9\tFidelity = 0.515658\tKL_Divergence = 2.069926\n",
      "Epoch: 10\tFidelity = 0.515932\tKL_Divergence = 2.060209\n",
      "Epoch: 11\tFidelity = 0.515520\tKL_Divergence = 2.074946\n",
      "Epoch: 12\tFidelity = 0.517911\tKL_Divergence = 1.994430\n",
      "Epoch: 13\tFidelity = 0.516571\tKL_Divergence = 2.038096\n",
      "Epoch: 14\tFidelity = 0.514309\tKL_Divergence = 2.120564\n",
      "Epoch: 15\tFidelity = 0.514926\tKL_Divergence = 2.096893\n",
      "Epoch: 16\tFidelity = 0.513340\tKL_Divergence = 2.159870\n",
      "Epoch: 17\tFidelity = 0.516007\tKL_Divergence = 2.057614\n",
      "Epoch: 18\tFidelity = 0.515982\tKL_Divergence = 2.058470\n",
      "Epoch: 19\tFidelity = 0.515474\tKL_Divergence = 2.076606\n",
      "Epoch: 20\tFidelity = 0.515842\tKL_Divergence = 2.063394\n",
      "Epoch: 21\tFidelity = 0.514704\tKL_Divergence = 2.105205\n",
      "Epoch: 22\tFidelity = 0.516284\tKL_Divergence = 2.047923\n",
      "Epoch: 23\tFidelity = 0.517198\tKL_Divergence = 2.017275\n",
      "Epoch: 24\tFidelity = 0.514418\tKL_Divergence = 2.116282\n",
      "Epoch: 25\tFidelity = 0.514656\tKL_Divergence = 2.107040\n",
      "Epoch: 26\tFidelity = 0.513716\tKL_Divergence = 2.144268\n",
      "Epoch: 27\tFidelity = 0.517326\tKL_Divergence = 2.013062\n",
      "Epoch: 28\tFidelity = 0.514248\tKL_Divergence = 2.122943\n",
      "Epoch: 29\tFidelity = 0.517417\tKL_Divergence = 2.010122\n",
      "Epoch: 30\tFidelity = 0.514093\tKL_Divergence = 2.129037\n",
      "Epoch: 31\tFidelity = 0.516620\tKL_Divergence = 2.036437\n",
      "Epoch: 32\tFidelity = 0.515763\tKL_Divergence = 2.066228\n",
      "Epoch: 33\tFidelity = 0.516569\tKL_Divergence = 2.038212\n",
      "Epoch: 34\tFidelity = 0.514388\tKL_Divergence = 2.117448\n",
      "Epoch: 35\tFidelity = 0.515535\tKL_Divergence = 2.074363\n",
      "Epoch: 36\tFidelity = 0.515658\tKL_Divergence = 2.069974\n",
      "Epoch: 37\tFidelity = 0.515123\tKL_Divergence = 2.089521\n",
      "Epoch: 38\tFidelity = 0.515427\tKL_Divergence = 2.078291\n",
      "Epoch: 39\tFidelity = 0.513959\tKL_Divergence = 2.134441\n",
      "Epoch: 40\tFidelity = 0.516531\tKL_Divergence = 2.039419\n",
      "Epoch: 41\tFidelity = 0.515410\tKL_Divergence = 2.078925\n",
      "Epoch: 42\tFidelity = 0.515406\tKL_Divergence = 2.079114\n",
      "Epoch: 43\tFidelity = 0.515894\tKL_Divergence = 2.061608\n",
      "Epoch: 44\tFidelity = 0.514114\tKL_Divergence = 2.128247\n",
      "Epoch: 45\tFidelity = 0.515929\tKL_Divergence = 2.060364\n",
      "Epoch: 46\tFidelity = 0.515122\tKL_Divergence = 2.089521\n",
      "Epoch: 47\tFidelity = 0.514661\tKL_Divergence = 2.106919\n",
      "Epoch: 48\tFidelity = 0.514541\tKL_Divergence = 2.111529\n",
      "Epoch: 49\tFidelity = 0.514239\tKL_Divergence = 2.123332\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:33:34,518] Trial 146 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.512778\tKL_Divergence = 2.183966\n",
      "Total time elapsed during training: 76.279 s\n",
      "Trial 146 pruned. \n",
      "Epoch: 1\tFidelity = 0.514226\tKL_Divergence = 2.123827\n",
      "Epoch: 2\tFidelity = 0.514714\tKL_Divergence = 2.104899\n",
      "Epoch: 3\tFidelity = 0.515300\tKL_Divergence = 2.082987\n",
      "Epoch: 4\tFidelity = 0.514997\tKL_Divergence = 2.094226\n",
      "Epoch: 5\tFidelity = 0.514544\tKL_Divergence = 2.111415\n",
      "Epoch: 6\tFidelity = 0.516053\tKL_Divergence = 2.056024\n",
      "Epoch: 7\tFidelity = 0.515405\tKL_Divergence = 2.079152\n",
      "Epoch: 8\tFidelity = 0.515218\tKL_Divergence = 2.086023\n",
      "Epoch: 9\tFidelity = 0.514582\tKL_Divergence = 2.109953\n",
      "Epoch: 10\tFidelity = 0.514119\tKL_Divergence = 2.128070\n",
      "Epoch: 11\tFidelity = 0.515283\tKL_Divergence = 2.083629\n",
      "Epoch: 12\tFidelity = 0.515926\tKL_Divergence = 2.060474\n",
      "Epoch: 13\tFidelity = 0.515886\tKL_Divergence = 2.061914\n",
      "Epoch: 14\tFidelity = 0.513988\tKL_Divergence = 2.133320\n",
      "Epoch: 15\tFidelity = 0.515702\tKL_Divergence = 2.068427\n",
      "Epoch: 16\tFidelity = 0.515641\tKL_Divergence = 2.070639\n",
      "Epoch: 17\tFidelity = 0.514564\tKL_Divergence = 2.110692\n",
      "Epoch: 18\tFidelity = 0.515605\tKL_Divergence = 2.071915\n",
      "Epoch: 19\tFidelity = 0.514496\tKL_Divergence = 2.113298\n",
      "Epoch: 20\tFidelity = 0.514941\tKL_Divergence = 2.096344\n",
      "Epoch: 21\tFidelity = 0.516439\tKL_Divergence = 2.042686\n",
      "Epoch: 22\tFidelity = 0.515489\tKL_Divergence = 2.076106\n",
      "Epoch: 23\tFidelity = 0.514226\tKL_Divergence = 2.123843\n",
      "Epoch: 24\tFidelity = 0.514593\tKL_Divergence = 2.109550\n",
      "Epoch: 25\tFidelity = 0.514446\tKL_Divergence = 2.115234\n",
      "Epoch: 26\tFidelity = 0.515539\tKL_Divergence = 2.074315\n",
      "Epoch: 27\tFidelity = 0.516856\tKL_Divergence = 2.028608\n",
      "Epoch: 28\tFidelity = 0.516223\tKL_Divergence = 2.050133\n",
      "Epoch: 29\tFidelity = 0.515501\tKL_Divergence = 2.075679\n",
      "Epoch: 30\tFidelity = 0.514942\tKL_Divergence = 2.096313\n",
      "Epoch: 31\tFidelity = 0.514176\tKL_Divergence = 2.125830\n",
      "Epoch: 32\tFidelity = 0.515605\tKL_Divergence = 2.071949\n",
      "Epoch: 33\tFidelity = 0.516368\tKL_Divergence = 2.045118\n",
      "Epoch: 34\tFidelity = 0.514678\tKL_Divergence = 2.106330\n",
      "Epoch: 35\tFidelity = 0.514776\tKL_Divergence = 2.102588\n",
      "Epoch: 36\tFidelity = 0.513833\tKL_Divergence = 2.139556\n",
      "Epoch: 37\tFidelity = 0.514516\tKL_Divergence = 2.112534\n",
      "Epoch: 38\tFidelity = 0.515198\tKL_Divergence = 2.086771\n",
      "Epoch: 39\tFidelity = 0.514251\tKL_Divergence = 2.122867\n",
      "Epoch: 40\tFidelity = 0.515451\tKL_Divergence = 2.077489\n",
      "Epoch: 41\tFidelity = 0.514777\tKL_Divergence = 2.102528\n",
      "Epoch: 42\tFidelity = 0.516004\tKL_Divergence = 2.057770\n",
      "Epoch: 43\tFidelity = 0.513699\tKL_Divergence = 2.145006\n",
      "Epoch: 44\tFidelity = 0.513799\tKL_Divergence = 2.140941\n",
      "Epoch: 45\tFidelity = 0.515801\tKL_Divergence = 2.064909\n",
      "Epoch: 46\tFidelity = 0.515646\tKL_Divergence = 2.070471\n",
      "Epoch: 47\tFidelity = 0.515838\tKL_Divergence = 2.063622\n",
      "Epoch: 48\tFidelity = 0.513968\tKL_Divergence = 2.134129\n",
      "Epoch: 49\tFidelity = 0.514358\tKL_Divergence = 2.118694\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:34:05,305] Trial 147 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.515617\tKL_Divergence = 2.071518\n",
      "Total time elapsed during training: 30.646 s\n",
      "Trial 147 pruned. \n",
      "Epoch: 1\tFidelity = 0.515268\tKL_Divergence = 2.084163\n",
      "Epoch: 2\tFidelity = 0.515040\tKL_Divergence = 2.092604\n",
      "Epoch: 3\tFidelity = 0.514637\tKL_Divergence = 2.107858\n",
      "Epoch: 4\tFidelity = 0.513012\tKL_Divergence = 2.173865\n",
      "Epoch: 5\tFidelity = 0.519266\tKL_Divergence = 1.953429\n",
      "Epoch: 6\tFidelity = 0.517834\tKL_Divergence = 1.996905\n",
      "Epoch: 7\tFidelity = 0.515505\tKL_Divergence = 2.075523\n",
      "Epoch: 8\tFidelity = 0.516798\tKL_Divergence = 2.030523\n",
      "Epoch: 9\tFidelity = 0.517070\tKL_Divergence = 2.021471\n",
      "Epoch: 10\tFidelity = 0.515914\tKL_Divergence = 2.060903\n",
      "Epoch: 11\tFidelity = 0.515980\tKL_Divergence = 2.058593\n",
      "Epoch: 12\tFidelity = 0.517415\tKL_Divergence = 2.010246\n",
      "Epoch: 13\tFidelity = 0.513185\tKL_Divergence = 2.166439\n",
      "Epoch: 14\tFidelity = 0.515645\tKL_Divergence = 2.070480\n",
      "Epoch: 15\tFidelity = 0.515404\tKL_Divergence = 2.079220\n",
      "Epoch: 16\tFidelity = 0.515510\tKL_Divergence = 2.075385\n",
      "Epoch: 17\tFidelity = 0.516757\tKL_Divergence = 2.031934\n",
      "Epoch: 18\tFidelity = 0.516141\tKL_Divergence = 2.052969\n",
      "Epoch: 19\tFidelity = 0.515806\tKL_Divergence = 2.064753\n",
      "Epoch: 20\tFidelity = 0.514009\tKL_Divergence = 2.132455\n",
      "Epoch: 21\tFidelity = 0.516304\tKL_Divergence = 2.047346\n",
      "Epoch: 22\tFidelity = 0.513760\tKL_Divergence = 2.142555\n",
      "Epoch: 23\tFidelity = 0.514615\tKL_Divergence = 2.108722\n",
      "Epoch: 24\tFidelity = 0.515907\tKL_Divergence = 2.061188\n",
      "Epoch: 25\tFidelity = 0.516875\tKL_Divergence = 2.027983\n",
      "Epoch: 26\tFidelity = 0.511202\tKL_Divergence = 2.257703\n",
      "Epoch: 27\tFidelity = 0.514864\tKL_Divergence = 2.099269\n",
      "Epoch: 28\tFidelity = 0.513276\tKL_Divergence = 2.162639\n",
      "Epoch: 29\tFidelity = 0.513597\tKL_Divergence = 2.149250\n",
      "Epoch: 30\tFidelity = 0.516332\tKL_Divergence = 2.046407\n",
      "Epoch: 31\tFidelity = 0.517955\tKL_Divergence = 1.993127\n",
      "Epoch: 32\tFidelity = 0.515600\tKL_Divergence = 2.072129\n",
      "Epoch: 33\tFidelity = 0.515397\tKL_Divergence = 2.079493\n",
      "Epoch: 34\tFidelity = 0.513851\tKL_Divergence = 2.138844\n",
      "Epoch: 35\tFidelity = 0.513540\tKL_Divergence = 2.151579\n",
      "Epoch: 36\tFidelity = 0.515090\tKL_Divergence = 2.090785\n",
      "Epoch: 37\tFidelity = 0.515339\tKL_Divergence = 2.081594\n",
      "Epoch: 38\tFidelity = 0.515963\tKL_Divergence = 2.059205\n",
      "Epoch: 39\tFidelity = 0.516018\tKL_Divergence = 2.057266\n",
      "Epoch: 40\tFidelity = 0.515293\tKL_Divergence = 2.083280\n",
      "Epoch: 41\tFidelity = 0.516512\tKL_Divergence = 2.040224\n",
      "Epoch: 42\tFidelity = 0.515780\tKL_Divergence = 2.065701\n",
      "Epoch: 43\tFidelity = 0.513304\tKL_Divergence = 2.161428\n",
      "Epoch: 44\tFidelity = 0.513829\tKL_Divergence = 2.139755\n",
      "Epoch: 45\tFidelity = 0.515648\tKL_Divergence = 2.070401\n",
      "Epoch: 46\tFidelity = 0.516477\tKL_Divergence = 2.041446\n",
      "Epoch: 47\tFidelity = 0.515870\tKL_Divergence = 2.062513\n",
      "Epoch: 48\tFidelity = 0.515543\tKL_Divergence = 2.074203\n",
      "Epoch: 49\tFidelity = 0.515118\tKL_Divergence = 2.089771\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:34:42,276] Trial 148 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.514329\tKL_Divergence = 2.119809\n",
      "Total time elapsed during training: 36.826 s\n",
      "Trial 148 pruned. \n",
      "Epoch: 1\tFidelity = 0.515495\tKL_Divergence = 2.075924\n",
      "Epoch: 2\tFidelity = 0.513676\tKL_Divergence = 2.145997\n",
      "Epoch: 3\tFidelity = 0.514629\tKL_Divergence = 2.108202\n",
      "Epoch: 4\tFidelity = 0.515104\tKL_Divergence = 2.090239\n",
      "Epoch: 5\tFidelity = 0.514215\tKL_Divergence = 2.124283\n",
      "Epoch: 6\tFidelity = 0.513817\tKL_Divergence = 2.140180\n",
      "Epoch: 7\tFidelity = 0.513099\tKL_Divergence = 2.170112\n",
      "Epoch: 8\tFidelity = 0.514078\tKL_Divergence = 2.129741\n",
      "Epoch: 9\tFidelity = 0.515728\tKL_Divergence = 2.067500\n",
      "Epoch: 10\tFidelity = 0.515444\tKL_Divergence = 2.077758\n",
      "Epoch: 11\tFidelity = 0.515957\tKL_Divergence = 2.059398\n",
      "Epoch: 12\tFidelity = 0.513007\tKL_Divergence = 2.174098\n",
      "Epoch: 13\tFidelity = 0.516005\tKL_Divergence = 2.057723\n",
      "Epoch: 14\tFidelity = 0.516788\tKL_Divergence = 2.030899\n",
      "Epoch: 15\tFidelity = 0.515686\tKL_Divergence = 2.069017\n",
      "Epoch: 16\tFidelity = 0.516264\tKL_Divergence = 2.048696\n",
      "Epoch: 17\tFidelity = 0.514787\tKL_Divergence = 2.102159\n",
      "Epoch: 18\tFidelity = 0.514074\tKL_Divergence = 2.129868\n",
      "Epoch: 19\tFidelity = 0.515570\tKL_Divergence = 2.073156\n",
      "Epoch: 20\tFidelity = 0.515638\tKL_Divergence = 2.070716\n",
      "Epoch: 21\tFidelity = 0.514963\tKL_Divergence = 2.095477\n",
      "Epoch: 22\tFidelity = 0.515627\tKL_Divergence = 2.071134\n",
      "Epoch: 23\tFidelity = 0.513353\tKL_Divergence = 2.159342\n",
      "Epoch: 24\tFidelity = 0.512682\tKL_Divergence = 2.188251\n",
      "Epoch: 25\tFidelity = 0.516689\tKL_Divergence = 2.034207\n",
      "Epoch: 26\tFidelity = 0.514111\tKL_Divergence = 2.128417\n",
      "Epoch: 27\tFidelity = 0.516180\tKL_Divergence = 2.051631\n",
      "Epoch: 28\tFidelity = 0.514666\tKL_Divergence = 2.106769\n",
      "Epoch: 29\tFidelity = 0.514948\tKL_Divergence = 2.096089\n",
      "Epoch: 30\tFidelity = 0.514961\tKL_Divergence = 2.095599\n",
      "Epoch: 31\tFidelity = 0.516979\tKL_Divergence = 2.024553\n",
      "Epoch: 32\tFidelity = 0.514979\tKL_Divergence = 2.094952\n",
      "Epoch: 33\tFidelity = 0.513493\tKL_Divergence = 2.153555\n",
      "Epoch: 34\tFidelity = 0.515711\tKL_Divergence = 2.068149\n",
      "Epoch: 35\tFidelity = 0.514986\tKL_Divergence = 2.094654\n",
      "Epoch: 36\tFidelity = 0.515292\tKL_Divergence = 2.083280\n",
      "Epoch: 37\tFidelity = 0.514289\tKL_Divergence = 2.121388\n",
      "Epoch: 38\tFidelity = 0.516360\tKL_Divergence = 2.045402\n",
      "Epoch: 39\tFidelity = 0.514545\tKL_Divergence = 2.111431\n",
      "Epoch: 40\tFidelity = 0.514351\tKL_Divergence = 2.118978\n",
      "Epoch: 41\tFidelity = 0.515644\tKL_Divergence = 2.070561\n",
      "Epoch: 42\tFidelity = 0.514214\tKL_Divergence = 2.124379\n",
      "Epoch: 43\tFidelity = 0.514372\tKL_Divergence = 2.118150\n",
      "Epoch: 44\tFidelity = 0.515277\tKL_Divergence = 2.083866\n",
      "Epoch: 45\tFidelity = 0.513083\tKL_Divergence = 2.170813\n",
      "Epoch: 46\tFidelity = 0.515059\tKL_Divergence = 2.091930\n",
      "Epoch: 47\tFidelity = 0.514081\tKL_Divergence = 2.129629\n",
      "Epoch: 48\tFidelity = 0.513779\tKL_Divergence = 2.141813\n",
      "Epoch: 49\tFidelity = 0.514160\tKL_Divergence = 2.126524\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:35:19,204] Trial 149 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.515358\tKL_Divergence = 2.080918\n",
      "Total time elapsed during training: 36.786 s\n",
      "Trial 149 pruned. \n",
      "Epoch: 1\tFidelity = 0.514374\tKL_Divergence = 2.118113\n",
      "Epoch: 2\tFidelity = 0.516580\tKL_Divergence = 2.037947\n",
      "Epoch: 3\tFidelity = 0.513764\tKL_Divergence = 2.142440\n",
      "Epoch: 4\tFidelity = 0.516640\tKL_Divergence = 2.035880\n",
      "Epoch: 5\tFidelity = 0.515167\tKL_Divergence = 2.087696\n",
      "Epoch: 6\tFidelity = 0.512406\tKL_Divergence = 2.200029\n",
      "Epoch: 7\tFidelity = 0.514200\tKL_Divergence = 2.124045\n",
      "Epoch: 8\tFidelity = 0.513668\tKL_Divergence = 2.145521\n",
      "Epoch: 9\tFidelity = 0.516800\tKL_Divergence = 2.030047\n",
      "Epoch: 10\tFidelity = 0.516809\tKL_Divergence = 2.030220\n",
      "Epoch: 11\tFidelity = 0.515116\tKL_Divergence = 2.089856\n",
      "Epoch: 12\tFidelity = 0.516110\tKL_Divergence = 2.054036\n",
      "Epoch: 13\tFidelity = 0.513902\tKL_Divergence = 2.136839\n",
      "Epoch: 14\tFidelity = 0.515791\tKL_Divergence = 2.065335\n",
      "Epoch: 15\tFidelity = 0.516294\tKL_Divergence = 2.047688\n",
      "Epoch: 16\tFidelity = 0.514775\tKL_Divergence = 2.102538\n",
      "Epoch: 17\tFidelity = 0.514722\tKL_Divergence = 2.104620\n",
      "Epoch: 18\tFidelity = 0.512596\tKL_Divergence = 2.192087\n",
      "Epoch: 19\tFidelity = 0.512902\tKL_Divergence = 2.178668\n",
      "Epoch: 20\tFidelity = 0.514913\tKL_Divergence = 2.097440\n",
      "Epoch: 21\tFidelity = 0.517421\tKL_Divergence = 2.010060\n",
      "Epoch: 22\tFidelity = 0.518036\tKL_Divergence = 1.990578\n",
      "Epoch: 23\tFidelity = 0.517137\tKL_Divergence = 2.019333\n",
      "Epoch: 24\tFidelity = 0.514286\tKL_Divergence = 2.121534\n",
      "Epoch: 25\tFidelity = 0.513922\tKL_Divergence = 2.135877\n",
      "Epoch: 26\tFidelity = 0.519589\tKL_Divergence = 1.944089\n",
      "Epoch: 27\tFidelity = 0.514574\tKL_Divergence = 2.110333\n",
      "Epoch: 28\tFidelity = 0.514474\tKL_Divergence = 2.114198\n",
      "Epoch: 29\tFidelity = 0.515497\tKL_Divergence = 2.075830\n",
      "Epoch: 30\tFidelity = 0.513494\tKL_Divergence = 2.153425\n",
      "Epoch: 31\tFidelity = 0.517780\tKL_Divergence = 1.998481\n",
      "Epoch: 32\tFidelity = 0.512355\tKL_Divergence = 2.202750\n",
      "Epoch: 33\tFidelity = 0.514619\tKL_Divergence = 2.108203\n",
      "Epoch: 34\tFidelity = 0.514015\tKL_Divergence = 2.131997\n",
      "Epoch: 35\tFidelity = 0.517775\tKL_Divergence = 1.998745\n",
      "Epoch: 36\tFidelity = 0.514383\tKL_Divergence = 2.117629\n",
      "Epoch: 37\tFidelity = 0.512276\tKL_Divergence = 2.206376\n",
      "Epoch: 38\tFidelity = 0.516659\tKL_Divergence = 2.035146\n",
      "Epoch: 39\tFidelity = 0.515964\tKL_Divergence = 2.058911\n",
      "Epoch: 40\tFidelity = 0.515278\tKL_Divergence = 2.083384\n",
      "Epoch: 41\tFidelity = 0.517935\tKL_Divergence = 1.993648\n",
      "Epoch: 42\tFidelity = 0.514681\tKL_Divergence = 2.106067\n",
      "Epoch: 43\tFidelity = 0.514669\tKL_Divergence = 2.106607\n",
      "Epoch: 44\tFidelity = 0.511931\tKL_Divergence = 2.222369\n",
      "Epoch: 45\tFidelity = 0.516451\tKL_Divergence = 2.042127\n",
      "Epoch: 46\tFidelity = 0.515764\tKL_Divergence = 2.065781\n",
      "Epoch: 47\tFidelity = 0.515780\tKL_Divergence = 2.065502\n",
      "Epoch: 48\tFidelity = 0.513006\tKL_Divergence = 2.173898\n",
      "Epoch: 49\tFidelity = 0.512937\tKL_Divergence = 2.176790\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:35:55,734] Trial 150 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.517656\tKL_Divergence = 2.002502\n",
      "Total time elapsed during training: 36.381 s\n",
      "Trial 150 pruned. \n",
      "Epoch: 1\tFidelity = 0.515223\tKL_Divergence = 2.085810\n",
      "Epoch: 2\tFidelity = 0.514274\tKL_Divergence = 2.121922\n",
      "Epoch: 3\tFidelity = 0.515206\tKL_Divergence = 2.086402\n",
      "Epoch: 4\tFidelity = 0.515122\tKL_Divergence = 2.089510\n",
      "Epoch: 5\tFidelity = 0.515038\tKL_Divergence = 2.092666\n",
      "Epoch: 6\tFidelity = 0.515962\tKL_Divergence = 2.059208\n",
      "Epoch: 7\tFidelity = 0.513972\tKL_Divergence = 2.133905\n",
      "Epoch: 8\tFidelity = 0.514452\tKL_Divergence = 2.114989\n",
      "Epoch: 9\tFidelity = 0.513481\tKL_Divergence = 2.153986\n",
      "Epoch: 10\tFidelity = 0.515779\tKL_Divergence = 2.065683\n",
      "Epoch: 11\tFidelity = 0.516088\tKL_Divergence = 2.054761\n",
      "Epoch: 12\tFidelity = 0.516280\tKL_Divergence = 2.048100\n",
      "Epoch: 13\tFidelity = 0.514751\tKL_Divergence = 2.103464\n",
      "Epoch: 14\tFidelity = 0.515654\tKL_Divergence = 2.070131\n",
      "Epoch: 15\tFidelity = 0.516430\tKL_Divergence = 2.042950\n",
      "Epoch: 16\tFidelity = 0.515431\tKL_Divergence = 2.078183\n",
      "Epoch: 17\tFidelity = 0.516528\tKL_Divergence = 2.039616\n",
      "Epoch: 18\tFidelity = 0.515427\tKL_Divergence = 2.078337\n",
      "Epoch: 19\tFidelity = 0.514814\tKL_Divergence = 2.101093\n",
      "Epoch: 20\tFidelity = 0.515119\tKL_Divergence = 2.089669\n",
      "Epoch: 21\tFidelity = 0.514424\tKL_Divergence = 2.116090\n",
      "Epoch: 22\tFidelity = 0.515090\tKL_Divergence = 2.090744\n",
      "Epoch: 23\tFidelity = 0.515169\tKL_Divergence = 2.087824\n",
      "Epoch: 24\tFidelity = 0.513787\tKL_Divergence = 2.141402\n",
      "Epoch: 25\tFidelity = 0.514868\tKL_Divergence = 2.099090\n",
      "Epoch: 26\tFidelity = 0.514133\tKL_Divergence = 2.127511\n",
      "Epoch: 27\tFidelity = 0.516106\tKL_Divergence = 2.054191\n",
      "Epoch: 28\tFidelity = 0.514181\tKL_Divergence = 2.125608\n",
      "Epoch: 29\tFidelity = 0.515143\tKL_Divergence = 2.088796\n",
      "Epoch: 30\tFidelity = 0.515793\tKL_Divergence = 2.065164\n",
      "Epoch: 31\tFidelity = 0.514227\tKL_Divergence = 2.123766\n",
      "Epoch: 32\tFidelity = 0.515256\tKL_Divergence = 2.084611\n",
      "Epoch: 33\tFidelity = 0.514570\tKL_Divergence = 2.110419\n",
      "Epoch: 34\tFidelity = 0.515426\tKL_Divergence = 2.078360\n",
      "Epoch: 35\tFidelity = 0.514772\tKL_Divergence = 2.102670\n",
      "Epoch: 36\tFidelity = 0.515185\tKL_Divergence = 2.087201\n",
      "Epoch: 37\tFidelity = 0.515693\tKL_Divergence = 2.068727\n",
      "Epoch: 38\tFidelity = 0.514839\tKL_Divergence = 2.100131\n",
      "Epoch: 39\tFidelity = 0.516612\tKL_Divergence = 2.036732\n",
      "Epoch: 40\tFidelity = 0.515105\tKL_Divergence = 2.090140\n",
      "Epoch: 41\tFidelity = 0.515530\tKL_Divergence = 2.074596\n",
      "Epoch: 42\tFidelity = 0.515398\tKL_Divergence = 2.079370\n",
      "Epoch: 43\tFidelity = 0.515184\tKL_Divergence = 2.087253\n",
      "Epoch: 44\tFidelity = 0.516677\tKL_Divergence = 2.034569\n",
      "Epoch: 45\tFidelity = 0.516171\tKL_Divergence = 2.051862\n",
      "Epoch: 46\tFidelity = 0.516556\tKL_Divergence = 2.038642\n",
      "Epoch: 47\tFidelity = 0.514509\tKL_Divergence = 2.112749\n",
      "Epoch: 48\tFidelity = 0.516611\tKL_Divergence = 2.036748\n",
      "Epoch: 49\tFidelity = 0.516210\tKL_Divergence = 2.050515\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:36:32,643] Trial 151 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.515721\tKL_Divergence = 2.067726\n",
      "Total time elapsed during training: 36.765 s\n",
      "Trial 151 pruned. \n",
      "Epoch: 1\tFidelity = 0.513109\tKL_Divergence = 2.169623\n",
      "Epoch: 2\tFidelity = 0.515959\tKL_Divergence = 2.059252\n",
      "Epoch: 3\tFidelity = 0.515275\tKL_Divergence = 2.083867\n",
      "Epoch: 4\tFidelity = 0.516399\tKL_Divergence = 2.043957\n",
      "Epoch: 5\tFidelity = 0.515265\tKL_Divergence = 2.084165\n",
      "Epoch: 6\tFidelity = 0.516615\tKL_Divergence = 2.036579\n",
      "Epoch: 7\tFidelity = 0.514371\tKL_Divergence = 2.118048\n",
      "Epoch: 8\tFidelity = 0.515025\tKL_Divergence = 2.093092\n",
      "Epoch: 9\tFidelity = 0.514791\tKL_Divergence = 2.101918\n",
      "Epoch: 10\tFidelity = 0.515517\tKL_Divergence = 2.075016\n",
      "Epoch: 11\tFidelity = 0.515121\tKL_Divergence = 2.089490\n",
      "Epoch: 12\tFidelity = 0.515142\tKL_Divergence = 2.088737\n",
      "Epoch: 13\tFidelity = 0.515451\tKL_Divergence = 2.077400\n",
      "Epoch: 14\tFidelity = 0.515164\tKL_Divergence = 2.087959\n",
      "Epoch: 15\tFidelity = 0.515957\tKL_Divergence = 2.059331\n",
      "Epoch: 16\tFidelity = 0.515645\tKL_Divergence = 2.070431\n",
      "Epoch: 17\tFidelity = 0.514435\tKL_Divergence = 2.115595\n",
      "Epoch: 18\tFidelity = 0.514068\tKL_Divergence = 2.130051\n",
      "Epoch: 19\tFidelity = 0.513913\tKL_Divergence = 2.136246\n",
      "Epoch: 20\tFidelity = 0.516372\tKL_Divergence = 2.044891\n",
      "Epoch: 21\tFidelity = 0.517018\tKL_Divergence = 2.023149\n",
      "Epoch: 22\tFidelity = 0.514806\tKL_Divergence = 2.101343\n",
      "Epoch: 23\tFidelity = 0.516707\tKL_Divergence = 2.033533\n",
      "Epoch: 24\tFidelity = 0.516333\tKL_Divergence = 2.046233\n",
      "Epoch: 25\tFidelity = 0.516918\tKL_Divergence = 2.026478\n",
      "Epoch: 26\tFidelity = 0.514638\tKL_Divergence = 2.107771\n",
      "Epoch: 27\tFidelity = 0.514171\tKL_Divergence = 2.125958\n",
      "Epoch: 28\tFidelity = 0.516583\tKL_Divergence = 2.037743\n",
      "Epoch: 29\tFidelity = 0.515900\tKL_Divergence = 2.061336\n",
      "Epoch: 30\tFidelity = 0.515809\tKL_Divergence = 2.064542\n",
      "Epoch: 31\tFidelity = 0.515447\tKL_Divergence = 2.077552\n",
      "Epoch: 32\tFidelity = 0.514872\tKL_Divergence = 2.098887\n",
      "Epoch: 33\tFidelity = 0.515046\tKL_Divergence = 2.092342\n",
      "Epoch: 34\tFidelity = 0.514458\tKL_Divergence = 2.114693\n",
      "Epoch: 35\tFidelity = 0.517224\tKL_Divergence = 2.016412\n",
      "Epoch: 36\tFidelity = 0.515460\tKL_Divergence = 2.077116\n",
      "Epoch: 37\tFidelity = 0.514870\tKL_Divergence = 2.098933\n",
      "Epoch: 38\tFidelity = 0.514375\tKL_Divergence = 2.117919\n",
      "Epoch: 39\tFidelity = 0.516599\tKL_Divergence = 2.037132\n",
      "Epoch: 40\tFidelity = 0.516643\tKL_Divergence = 2.035651\n",
      "Epoch: 41\tFidelity = 0.516524\tKL_Divergence = 2.039698\n",
      "Epoch: 42\tFidelity = 0.515451\tKL_Divergence = 2.077414\n",
      "Epoch: 43\tFidelity = 0.515143\tKL_Divergence = 2.088722\n",
      "Epoch: 44\tFidelity = 0.514318\tKL_Divergence = 2.120162\n",
      "Epoch: 45\tFidelity = 0.515511\tKL_Divergence = 2.075227\n",
      "Epoch: 46\tFidelity = 0.516494\tKL_Divergence = 2.040742\n",
      "Epoch: 47\tFidelity = 0.514179\tKL_Divergence = 2.125641\n",
      "Epoch: 48\tFidelity = 0.516810\tKL_Divergence = 2.030083\n",
      "Epoch: 49\tFidelity = 0.514761\tKL_Divergence = 2.103043\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:37:09,397] Trial 152 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.514603\tKL_Divergence = 2.109104\n",
      "Total time elapsed during training: 36.614 s\n",
      "Trial 152 pruned. \n",
      "Epoch: 1\tFidelity = 0.517792\tKL_Divergence = 1.998133\n",
      "Epoch: 2\tFidelity = 0.515205\tKL_Divergence = 2.086434\n",
      "Epoch: 3\tFidelity = 0.517217\tKL_Divergence = 2.016619\n",
      "Epoch: 4\tFidelity = 0.514038\tKL_Divergence = 2.131247\n",
      "Epoch: 5\tFidelity = 0.514468\tKL_Divergence = 2.114303\n",
      "Epoch: 6\tFidelity = 0.516979\tKL_Divergence = 2.024431\n",
      "Epoch: 7\tFidelity = 0.515335\tKL_Divergence = 2.081643\n",
      "Epoch: 8\tFidelity = 0.518134\tKL_Divergence = 1.987414\n",
      "Epoch: 9\tFidelity = 0.514771\tKL_Divergence = 2.102672\n",
      "Epoch: 10\tFidelity = 0.515113\tKL_Divergence = 2.089832\n",
      "Epoch: 11\tFidelity = 0.515880\tKL_Divergence = 2.062046\n",
      "Epoch: 12\tFidelity = 0.514264\tKL_Divergence = 2.122259\n",
      "Epoch: 13\tFidelity = 0.516878\tKL_Divergence = 2.027788\n",
      "Epoch: 14\tFidelity = 0.517796\tKL_Divergence = 1.998009\n",
      "Epoch: 15\tFidelity = 0.516861\tKL_Divergence = 2.028371\n",
      "Epoch: 16\tFidelity = 0.515978\tKL_Divergence = 2.058597\n",
      "Epoch: 17\tFidelity = 0.516286\tKL_Divergence = 2.047862\n",
      "Epoch: 18\tFidelity = 0.516682\tKL_Divergence = 2.034365\n",
      "Epoch: 19\tFidelity = 0.515426\tKL_Divergence = 2.078336\n",
      "Epoch: 20\tFidelity = 0.515007\tKL_Divergence = 2.093773\n",
      "Epoch: 21\tFidelity = 0.516411\tKL_Divergence = 2.043566\n",
      "Epoch: 22\tFidelity = 0.513744\tKL_Divergence = 2.143077\n",
      "Epoch: 23\tFidelity = 0.518164\tKL_Divergence = 1.986477\n",
      "Epoch: 24\tFidelity = 0.515118\tKL_Divergence = 2.089623\n",
      "Epoch: 25\tFidelity = 0.516607\tKL_Divergence = 2.036856\n",
      "Epoch: 26\tFidelity = 0.516878\tKL_Divergence = 2.027757\n",
      "Epoch: 27\tFidelity = 0.515212\tKL_Divergence = 2.086135\n",
      "Epoch: 28\tFidelity = 0.515834\tKL_Divergence = 2.063651\n",
      "Epoch: 29\tFidelity = 0.514802\tKL_Divergence = 2.101505\n",
      "Epoch: 30\tFidelity = 0.517565\tKL_Divergence = 2.005366\n",
      "Epoch: 31\tFidelity = 0.516972\tKL_Divergence = 2.024685\n",
      "Epoch: 32\tFidelity = 0.515212\tKL_Divergence = 2.086154\n",
      "Epoch: 33\tFidelity = 0.517397\tKL_Divergence = 2.010735\n",
      "Epoch: 34\tFidelity = 0.517456\tKL_Divergence = 2.008807\n",
      "Epoch: 35\tFidelity = 0.516024\tKL_Divergence = 2.056920\n",
      "Epoch: 36\tFidelity = 0.515172\tKL_Divergence = 2.087605\n",
      "Epoch: 37\tFidelity = 0.515303\tKL_Divergence = 2.082769\n",
      "Epoch: 38\tFidelity = 0.516995\tKL_Divergence = 2.023840\n",
      "Epoch: 39\tFidelity = 0.516025\tKL_Divergence = 2.056896\n",
      "Epoch: 40\tFidelity = 0.515574\tKL_Divergence = 2.072909\n",
      "Epoch: 41\tFidelity = 0.515959\tKL_Divergence = 2.059143\n",
      "Epoch: 42\tFidelity = 0.515063\tKL_Divergence = 2.091614\n",
      "Epoch: 43\tFidelity = 0.514484\tKL_Divergence = 2.113647\n",
      "Epoch: 44\tFidelity = 0.515584\tKL_Divergence = 2.072522\n",
      "Epoch: 45\tFidelity = 0.516814\tKL_Divergence = 2.029871\n",
      "Epoch: 46\tFidelity = 0.516167\tKL_Divergence = 2.051929\n",
      "Epoch: 47\tFidelity = 0.514631\tKL_Divergence = 2.107967\n",
      "Epoch: 48\tFidelity = 0.513723\tKL_Divergence = 2.143911\n",
      "Epoch: 49\tFidelity = 0.514145\tKL_Divergence = 2.126917\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:37:46,637] Trial 153 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.515847\tKL_Divergence = 2.063148\n",
      "Total time elapsed during training: 37.093 s\n",
      "Trial 153 pruned. \n",
      "Epoch: 1\tFidelity = 0.518211\tKL_Divergence = 1.984974\n",
      "Epoch: 2\tFidelity = 0.516401\tKL_Divergence = 2.043881\n",
      "Epoch: 3\tFidelity = 0.516042\tKL_Divergence = 2.056182\n",
      "Epoch: 4\tFidelity = 0.517820\tKL_Divergence = 1.997108\n",
      "Epoch: 5\tFidelity = 0.516490\tKL_Divergence = 2.040798\n",
      "Epoch: 6\tFidelity = 0.516276\tKL_Divergence = 2.048128\n",
      "Epoch: 7\tFidelity = 0.516685\tKL_Divergence = 2.034165\n",
      "Epoch: 8\tFidelity = 0.516154\tKL_Divergence = 2.052352\n",
      "Epoch: 9\tFidelity = 0.514454\tKL_Divergence = 2.114723\n",
      "Epoch: 10\tFidelity = 0.515300\tKL_Divergence = 2.082842\n",
      "Epoch: 11\tFidelity = 0.516899\tKL_Divergence = 2.026953\n",
      "Epoch: 12\tFidelity = 0.517853\tKL_Divergence = 1.996151\n",
      "Epoch: 13\tFidelity = 0.515157\tKL_Divergence = 2.088082\n",
      "Epoch: 14\tFidelity = 0.514576\tKL_Divergence = 2.109988\n",
      "Epoch: 15\tFidelity = 0.514032\tKL_Divergence = 2.131241\n",
      "Epoch: 16\tFidelity = 0.515500\tKL_Divergence = 2.075251\n",
      "Epoch: 17\tFidelity = 0.514462\tKL_Divergence = 2.114444\n",
      "Epoch: 18\tFidelity = 0.515652\tKL_Divergence = 2.070124\n",
      "Epoch: 19\tFidelity = 0.516076\tKL_Divergence = 2.055082\n",
      "Epoch: 20\tFidelity = 0.516935\tKL_Divergence = 2.025764\n",
      "Epoch: 21\tFidelity = 0.516251\tKL_Divergence = 2.048838\n",
      "Epoch: 22\tFidelity = 0.516031\tKL_Divergence = 2.056611\n",
      "Epoch: 23\tFidelity = 0.516376\tKL_Divergence = 2.044667\n",
      "Epoch: 24\tFidelity = 0.515395\tKL_Divergence = 2.079394\n",
      "Epoch: 25\tFidelity = 0.515433\tKL_Divergence = 2.078054\n",
      "Epoch: 26\tFidelity = 0.517645\tKL_Divergence = 2.002675\n",
      "Epoch: 27\tFidelity = 0.516424\tKL_Divergence = 2.042975\n",
      "Epoch: 28\tFidelity = 0.515751\tKL_Divergence = 2.066569\n",
      "Epoch: 29\tFidelity = 0.514240\tKL_Divergence = 2.123177\n",
      "Epoch: 30\tFidelity = 0.515069\tKL_Divergence = 2.091442\n",
      "Epoch: 31\tFidelity = 0.514996\tKL_Divergence = 2.094150\n",
      "Epoch: 32\tFidelity = 0.516258\tKL_Divergence = 2.048785\n",
      "Epoch: 33\tFidelity = 0.514317\tKL_Divergence = 2.120117\n",
      "Epoch: 34\tFidelity = 0.514757\tKL_Divergence = 2.102981\n",
      "Epoch: 35\tFidelity = 0.517369\tKL_Divergence = 2.011469\n",
      "Epoch: 36\tFidelity = 0.517450\tKL_Divergence = 2.008964\n",
      "Epoch: 37\tFidelity = 0.515236\tKL_Divergence = 2.085260\n",
      "Epoch: 38\tFidelity = 0.515912\tKL_Divergence = 2.060892\n",
      "Epoch: 39\tFidelity = 0.517823\tKL_Divergence = 1.997053\n",
      "Epoch: 40\tFidelity = 0.516087\tKL_Divergence = 2.054723\n",
      "Epoch: 41\tFidelity = 0.515524\tKL_Divergence = 2.074749\n",
      "Epoch: 42\tFidelity = 0.513782\tKL_Divergence = 2.141455\n",
      "Epoch: 43\tFidelity = 0.514427\tKL_Divergence = 2.115761\n",
      "Epoch: 44\tFidelity = 0.514445\tKL_Divergence = 2.114930\n",
      "Epoch: 45\tFidelity = 0.517324\tKL_Divergence = 2.012584\n",
      "Epoch: 46\tFidelity = 0.516189\tKL_Divergence = 2.050876\n",
      "Epoch: 47\tFidelity = 0.514208\tKL_Divergence = 2.124196\n",
      "Epoch: 48\tFidelity = 0.515653\tKL_Divergence = 2.070069\n",
      "Epoch: 49\tFidelity = 0.513813\tKL_Divergence = 2.140252\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:38:28,972] Trial 154 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.513815\tKL_Divergence = 2.140178\n",
      "Total time elapsed during training: 42.183 s\n",
      "Trial 154 pruned. \n",
      "Epoch: 1\tFidelity = 0.514429\tKL_Divergence = 2.115811\n",
      "Epoch: 2\tFidelity = 0.516653\tKL_Divergence = 2.035337\n",
      "Epoch: 3\tFidelity = 0.516202\tKL_Divergence = 2.050750\n",
      "Epoch: 4\tFidelity = 0.515022\tKL_Divergence = 2.093212\n",
      "Epoch: 5\tFidelity = 0.517768\tKL_Divergence = 1.998891\n",
      "Epoch: 6\tFidelity = 0.516178\tKL_Divergence = 2.051609\n",
      "Epoch: 7\tFidelity = 0.516013\tKL_Divergence = 2.057371\n",
      "Epoch: 8\tFidelity = 0.516024\tKL_Divergence = 2.056994\n",
      "Epoch: 9\tFidelity = 0.514409\tKL_Divergence = 2.116651\n",
      "Epoch: 10\tFidelity = 0.515626\tKL_Divergence = 2.071153\n",
      "Epoch: 11\tFidelity = 0.515615\tKL_Divergence = 2.071555\n",
      "Epoch: 12\tFidelity = 0.516212\tKL_Divergence = 2.050482\n",
      "Epoch: 13\tFidelity = 0.515077\tKL_Divergence = 2.091235\n",
      "Epoch: 14\tFidelity = 0.515444\tKL_Divergence = 2.077737\n",
      "Epoch: 15\tFidelity = 0.516458\tKL_Divergence = 2.041981\n",
      "Epoch: 16\tFidelity = 0.516249\tKL_Divergence = 2.049190\n",
      "Epoch: 17\tFidelity = 0.514764\tKL_Divergence = 2.103012\n",
      "Epoch: 18\tFidelity = 0.514963\tKL_Divergence = 2.095512\n",
      "Epoch: 19\tFidelity = 0.515632\tKL_Divergence = 2.070953\n",
      "Epoch: 20\tFidelity = 0.515675\tKL_Divergence = 2.069420\n",
      "Epoch: 21\tFidelity = 0.515421\tKL_Divergence = 2.078564\n",
      "Epoch: 22\tFidelity = 0.517739\tKL_Divergence = 1.999885\n",
      "Epoch: 23\tFidelity = 0.515215\tKL_Divergence = 2.086120\n",
      "Epoch: 24\tFidelity = 0.515858\tKL_Divergence = 2.062874\n",
      "Epoch: 25\tFidelity = 0.516237\tKL_Divergence = 2.049631\n",
      "Epoch: 26\tFidelity = 0.517765\tKL_Divergence = 1.999043\n",
      "Epoch: 27\tFidelity = 0.515822\tKL_Divergence = 2.064114\n",
      "Epoch: 28\tFidelity = 0.516133\tKL_Divergence = 2.053235\n",
      "Epoch: 29\tFidelity = 0.516312\tKL_Divergence = 2.047010\n",
      "Epoch: 30\tFidelity = 0.514950\tKL_Divergence = 2.095931\n",
      "Epoch: 31\tFidelity = 0.515544\tKL_Divergence = 2.074063\n",
      "Epoch: 32\tFidelity = 0.515252\tKL_Divergence = 2.084720\n",
      "Epoch: 33\tFidelity = 0.516012\tKL_Divergence = 2.057393\n",
      "Epoch: 34\tFidelity = 0.515524\tKL_Divergence = 2.074773\n",
      "Epoch: 35\tFidelity = 0.514667\tKL_Divergence = 2.106636\n",
      "Epoch: 36\tFidelity = 0.515393\tKL_Divergence = 2.079533\n",
      "Epoch: 37\tFidelity = 0.516337\tKL_Divergence = 2.046079\n",
      "Epoch: 38\tFidelity = 0.515712\tKL_Divergence = 2.068043\n",
      "Epoch: 39\tFidelity = 0.514900\tKL_Divergence = 2.097848\n",
      "Epoch: 40\tFidelity = 0.515519\tKL_Divergence = 2.075006\n",
      "Epoch: 41\tFidelity = 0.516162\tKL_Divergence = 2.052157\n",
      "Epoch: 42\tFidelity = 0.514958\tKL_Divergence = 2.095662\n",
      "Epoch: 43\tFidelity = 0.514613\tKL_Divergence = 2.108735\n",
      "Epoch: 44\tFidelity = 0.514848\tKL_Divergence = 2.099780\n",
      "Epoch: 45\tFidelity = 0.515285\tKL_Divergence = 2.083487\n",
      "Epoch: 46\tFidelity = 0.515637\tKL_Divergence = 2.070707\n",
      "Epoch: 47\tFidelity = 0.514860\tKL_Divergence = 2.099338\n",
      "Epoch: 48\tFidelity = 0.516468\tKL_Divergence = 2.041611\n",
      "Epoch: 49\tFidelity = 0.516159\tKL_Divergence = 2.052258\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:39:46,330] Trial 155 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.512669\tKL_Divergence = 2.188711\n",
      "Total time elapsed during training: 77.215 s\n",
      "Trial 155 pruned. \n",
      "Epoch: 1\tFidelity = 0.514175\tKL_Divergence = 2.125779\n",
      "Epoch: 2\tFidelity = 0.516071\tKL_Divergence = 2.055327\n",
      "Epoch: 3\tFidelity = 0.516422\tKL_Divergence = 2.043191\n",
      "Epoch: 4\tFidelity = 0.515507\tKL_Divergence = 2.075378\n",
      "Epoch: 5\tFidelity = 0.515388\tKL_Divergence = 2.079726\n",
      "Epoch: 6\tFidelity = 0.515964\tKL_Divergence = 2.059078\n",
      "Epoch: 7\tFidelity = 0.516099\tKL_Divergence = 2.054353\n",
      "Epoch: 8\tFidelity = 0.515473\tKL_Divergence = 2.076631\n",
      "Epoch: 9\tFidelity = 0.516752\tKL_Divergence = 2.032011\n",
      "Epoch: 10\tFidelity = 0.516162\tKL_Divergence = 2.052145\n",
      "Epoch: 11\tFidelity = 0.515656\tKL_Divergence = 2.070011\n",
      "Epoch: 12\tFidelity = 0.514762\tKL_Divergence = 2.103030\n",
      "Epoch: 13\tFidelity = 0.516088\tKL_Divergence = 2.054757\n",
      "Epoch: 14\tFidelity = 0.516322\tKL_Divergence = 2.046644\n",
      "Epoch: 15\tFidelity = 0.515572\tKL_Divergence = 2.073080\n",
      "Epoch: 16\tFidelity = 0.515734\tKL_Divergence = 2.067252\n",
      "Epoch: 17\tFidelity = 0.516146\tKL_Divergence = 2.052724\n",
      "Epoch: 18\tFidelity = 0.516880\tKL_Divergence = 2.027729\n",
      "Epoch: 19\tFidelity = 0.515929\tKL_Divergence = 2.060314\n",
      "Epoch: 20\tFidelity = 0.515538\tKL_Divergence = 2.074302\n",
      "Epoch: 21\tFidelity = 0.516073\tKL_Divergence = 2.055263\n",
      "Epoch: 22\tFidelity = 0.514314\tKL_Divergence = 2.120332\n",
      "Epoch: 23\tFidelity = 0.514869\tKL_Divergence = 2.098991\n",
      "Epoch: 24\tFidelity = 0.515007\tKL_Divergence = 2.093825\n",
      "Epoch: 25\tFidelity = 0.515306\tKL_Divergence = 2.082754\n",
      "Epoch: 26\tFidelity = 0.515134\tKL_Divergence = 2.089082\n",
      "Epoch: 27\tFidelity = 0.515163\tKL_Divergence = 2.088005\n",
      "Epoch: 28\tFidelity = 0.517056\tKL_Divergence = 2.021943\n",
      "Epoch: 29\tFidelity = 0.514750\tKL_Divergence = 2.103516\n",
      "Epoch: 30\tFidelity = 0.516279\tKL_Divergence = 2.048152\n",
      "Epoch: 31\tFidelity = 0.515771\tKL_Divergence = 2.065960\n",
      "Epoch: 32\tFidelity = 0.517350\tKL_Divergence = 2.012319\n",
      "Epoch: 33\tFidelity = 0.515447\tKL_Divergence = 2.077602\n",
      "Epoch: 34\tFidelity = 0.514018\tKL_Divergence = 2.132071\n",
      "Epoch: 35\tFidelity = 0.515365\tKL_Divergence = 2.080564\n",
      "Epoch: 36\tFidelity = 0.515493\tKL_Divergence = 2.075912\n",
      "Epoch: 37\tFidelity = 0.516393\tKL_Divergence = 2.044193\n",
      "Epoch: 38\tFidelity = 0.517151\tKL_Divergence = 2.018802\n",
      "Epoch: 39\tFidelity = 0.516032\tKL_Divergence = 2.056719\n",
      "Epoch: 40\tFidelity = 0.515803\tKL_Divergence = 2.064795\n",
      "Epoch: 41\tFidelity = 0.515552\tKL_Divergence = 2.073763\n",
      "Epoch: 42\tFidelity = 0.516053\tKL_Divergence = 2.055986\n",
      "Epoch: 43\tFidelity = 0.517690\tKL_Divergence = 2.001378\n",
      "Epoch: 44\tFidelity = 0.515770\tKL_Divergence = 2.065941\n",
      "Epoch: 45\tFidelity = 0.515475\tKL_Divergence = 2.076577\n",
      "Epoch: 46\tFidelity = 0.514579\tKL_Divergence = 2.110050\n",
      "Epoch: 47\tFidelity = 0.516232\tKL_Divergence = 2.049744\n",
      "Epoch: 48\tFidelity = 0.514958\tKL_Divergence = 2.095652\n",
      "Epoch: 49\tFidelity = 0.516143\tKL_Divergence = 2.052826\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:40:23,457] Trial 156 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.514202\tKL_Divergence = 2.124724\n",
      "Total time elapsed during training: 36.981 s\n",
      "Trial 156 pruned. \n",
      "Epoch: 1\tFidelity = 0.517568\tKL_Divergence = 2.005306\n",
      "Epoch: 2\tFidelity = 0.514667\tKL_Divergence = 2.106653\n",
      "Epoch: 3\tFidelity = 0.516022\tKL_Divergence = 2.057051\n",
      "Epoch: 4\tFidelity = 0.514185\tKL_Divergence = 2.125375\n",
      "Epoch: 5\tFidelity = 0.515063\tKL_Divergence = 2.091710\n",
      "Epoch: 6\tFidelity = 0.514567\tKL_Divergence = 2.110469\n",
      "Epoch: 7\tFidelity = 0.514578\tKL_Divergence = 2.109998\n",
      "Epoch: 8\tFidelity = 0.518476\tKL_Divergence = 1.976927\n",
      "Epoch: 9\tFidelity = 0.514428\tKL_Divergence = 2.115756\n",
      "Epoch: 10\tFidelity = 0.514809\tKL_Divergence = 2.101025\n",
      "Epoch: 11\tFidelity = 0.517493\tKL_Divergence = 2.007580\n",
      "Epoch: 12\tFidelity = 0.513938\tKL_Divergence = 2.135156\n",
      "Epoch: 13\tFidelity = 0.515565\tKL_Divergence = 2.073282\n",
      "Epoch: 14\tFidelity = 0.515427\tKL_Divergence = 2.078309\n",
      "Epoch: 15\tFidelity = 0.515164\tKL_Divergence = 2.087939\n",
      "Epoch: 16\tFidelity = 0.515625\tKL_Divergence = 2.071161\n",
      "Epoch: 17\tFidelity = 0.518114\tKL_Divergence = 1.988086\n",
      "Epoch: 18\tFidelity = 0.516771\tKL_Divergence = 2.031388\n",
      "Epoch: 19\tFidelity = 0.517631\tKL_Divergence = 2.003260\n",
      "Epoch: 20\tFidelity = 0.517210\tKL_Divergence = 2.016831\n",
      "Epoch: 21\tFidelity = 0.518367\tKL_Divergence = 1.980250\n",
      "Epoch: 22\tFidelity = 0.515907\tKL_Divergence = 2.061089\n",
      "Epoch: 23\tFidelity = 0.513963\tKL_Divergence = 2.134215\n",
      "Epoch: 24\tFidelity = 0.515838\tKL_Divergence = 2.063529\n",
      "Epoch: 25\tFidelity = 0.515968\tKL_Divergence = 2.058905\n",
      "Epoch: 26\tFidelity = 0.513409\tKL_Divergence = 2.156947\n",
      "Epoch: 27\tFidelity = 0.515441\tKL_Divergence = 2.077820\n",
      "Epoch: 28\tFidelity = 0.514616\tKL_Divergence = 2.108621\n",
      "Epoch: 29\tFidelity = 0.517515\tKL_Divergence = 2.006977\n",
      "Epoch: 30\tFidelity = 0.514049\tKL_Divergence = 2.130790\n",
      "Epoch: 31\tFidelity = 0.514449\tKL_Divergence = 2.115050\n",
      "Epoch: 32\tFidelity = 0.515717\tKL_Divergence = 2.067841\n",
      "Epoch: 33\tFidelity = 0.516273\tKL_Divergence = 2.048310\n",
      "Epoch: 34\tFidelity = 0.515704\tKL_Divergence = 2.068309\n",
      "Epoch: 35\tFidelity = 0.515925\tKL_Divergence = 2.060462\n",
      "Epoch: 36\tFidelity = 0.515122\tKL_Divergence = 2.089463\n",
      "Epoch: 37\tFidelity = 0.515130\tKL_Divergence = 2.089085\n",
      "Epoch: 38\tFidelity = 0.517551\tKL_Divergence = 2.005763\n",
      "Epoch: 39\tFidelity = 0.513658\tKL_Divergence = 2.146580\n",
      "Epoch: 40\tFidelity = 0.514947\tKL_Divergence = 2.096030\n",
      "Epoch: 41\tFidelity = 0.514499\tKL_Divergence = 2.113120\n",
      "Epoch: 42\tFidelity = 0.515910\tKL_Divergence = 2.060994\n",
      "Epoch: 43\tFidelity = 0.515697\tKL_Divergence = 2.068558\n",
      "Epoch: 44\tFidelity = 0.514028\tKL_Divergence = 2.131636\n",
      "Epoch: 45\tFidelity = 0.517677\tKL_Divergence = 2.001802\n",
      "Epoch: 46\tFidelity = 0.515230\tKL_Divergence = 2.085528\n",
      "Epoch: 47\tFidelity = 0.514573\tKL_Divergence = 2.110255\n",
      "Epoch: 48\tFidelity = 0.516042\tKL_Divergence = 2.056353\n",
      "Epoch: 49\tFidelity = 0.515561\tKL_Divergence = 2.073429\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:41:00,403] Trial 157 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.515692\tKL_Divergence = 2.068621\n",
      "Total time elapsed during training: 36.803 s\n",
      "Trial 157 pruned. \n",
      "Epoch: 1\tFidelity = 0.513029\tKL_Divergence = 2.172941\n",
      "Epoch: 2\tFidelity = 0.513453\tKL_Divergence = 2.155023\n",
      "Epoch: 3\tFidelity = 0.515537\tKL_Divergence = 2.074238\n",
      "Epoch: 4\tFidelity = 0.514675\tKL_Divergence = 2.106325\n",
      "Epoch: 5\tFidelity = 0.515310\tKL_Divergence = 2.082525\n",
      "Epoch: 6\tFidelity = 0.516452\tKL_Divergence = 2.042140\n",
      "Epoch: 7\tFidelity = 0.516121\tKL_Divergence = 2.053560\n",
      "Epoch: 8\tFidelity = 0.515607\tKL_Divergence = 2.071775\n",
      "Epoch: 9\tFidelity = 0.514668\tKL_Divergence = 2.106617\n",
      "Epoch: 10\tFidelity = 0.516799\tKL_Divergence = 2.030455\n",
      "Epoch: 11\tFidelity = 0.518495\tKL_Divergence = 1.976365\n",
      "Epoch: 12\tFidelity = 0.515104\tKL_Divergence = 2.090161\n",
      "Epoch: 13\tFidelity = 0.514362\tKL_Divergence = 2.118426\n",
      "Epoch: 14\tFidelity = 0.516251\tKL_Divergence = 2.049068\n",
      "Epoch: 15\tFidelity = 0.514835\tKL_Divergence = 2.100241\n",
      "Epoch: 16\tFidelity = 0.514534\tKL_Divergence = 2.111760\n",
      "Epoch: 17\tFidelity = 0.515824\tKL_Divergence = 2.064031\n",
      "Epoch: 18\tFidelity = 0.515891\tKL_Divergence = 2.061653\n",
      "Epoch: 19\tFidelity = 0.518330\tKL_Divergence = 1.981382\n",
      "Epoch: 20\tFidelity = 0.514666\tKL_Divergence = 2.106674\n",
      "Epoch: 21\tFidelity = 0.516374\tKL_Divergence = 2.044832\n",
      "Epoch: 22\tFidelity = 0.516940\tKL_Divergence = 2.025749\n",
      "Epoch: 23\tFidelity = 0.517007\tKL_Divergence = 2.023515\n",
      "Epoch: 24\tFidelity = 0.515421\tKL_Divergence = 2.078524\n",
      "Epoch: 25\tFidelity = 0.515156\tKL_Divergence = 2.088265\n",
      "Epoch: 26\tFidelity = 0.516042\tKL_Divergence = 2.056333\n",
      "Epoch: 27\tFidelity = 0.514872\tKL_Divergence = 2.098863\n",
      "Epoch: 28\tFidelity = 0.516790\tKL_Divergence = 2.030737\n",
      "Epoch: 29\tFidelity = 0.515467\tKL_Divergence = 2.076838\n",
      "Epoch: 30\tFidelity = 0.515501\tKL_Divergence = 2.075595\n",
      "Epoch: 31\tFidelity = 0.516170\tKL_Divergence = 2.051870\n",
      "Epoch: 32\tFidelity = 0.515373\tKL_Divergence = 2.080238\n",
      "Epoch: 33\tFidelity = 0.514414\tKL_Divergence = 2.116393\n",
      "Epoch: 34\tFidelity = 0.514130\tKL_Divergence = 2.127540\n",
      "Epoch: 35\tFidelity = 0.513788\tKL_Divergence = 2.141300\n",
      "Epoch: 36\tFidelity = 0.515971\tKL_Divergence = 2.058859\n",
      "Epoch: 37\tFidelity = 0.515720\tKL_Divergence = 2.067736\n",
      "Epoch: 38\tFidelity = 0.515975\tKL_Divergence = 2.058690\n",
      "Epoch: 39\tFidelity = 0.515226\tKL_Divergence = 2.085653\n",
      "Epoch: 40\tFidelity = 0.516381\tKL_Divergence = 2.044603\n",
      "Epoch: 41\tFidelity = 0.513595\tKL_Divergence = 2.149232\n",
      "Epoch: 42\tFidelity = 0.516593\tKL_Divergence = 2.037389\n",
      "Epoch: 43\tFidelity = 0.515280\tKL_Divergence = 2.083679\n",
      "Epoch: 44\tFidelity = 0.515903\tKL_Divergence = 2.061237\n",
      "Epoch: 45\tFidelity = 0.516595\tKL_Divergence = 2.037333\n",
      "Epoch: 46\tFidelity = 0.514645\tKL_Divergence = 2.107511\n",
      "Epoch: 47\tFidelity = 0.516381\tKL_Divergence = 2.044627\n",
      "Epoch: 48\tFidelity = 0.514257\tKL_Divergence = 2.122572\n",
      "Epoch: 49\tFidelity = 0.514394\tKL_Divergence = 2.117250\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:41:37,775] Trial 158 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.514091\tKL_Divergence = 2.129167\n",
      "Total time elapsed during training: 37.225 s\n",
      "Trial 158 pruned. \n",
      "Epoch: 1\tFidelity = 0.514738\tKL_Divergence = 2.104006\n",
      "Epoch: 2\tFidelity = 0.514675\tKL_Divergence = 2.106394\n",
      "Epoch: 3\tFidelity = 0.513533\tKL_Divergence = 2.151849\n",
      "Epoch: 4\tFidelity = 0.515762\tKL_Divergence = 2.066307\n",
      "Epoch: 5\tFidelity = 0.514695\tKL_Divergence = 2.105624\n",
      "Epoch: 6\tFidelity = 0.514969\tKL_Divergence = 2.095272\n",
      "Epoch: 7\tFidelity = 0.513733\tKL_Divergence = 2.143616\n",
      "Epoch: 8\tFidelity = 0.515219\tKL_Divergence = 2.085973\n",
      "Epoch: 9\tFidelity = 0.515975\tKL_Divergence = 2.058763\n",
      "Epoch: 10\tFidelity = 0.516435\tKL_Divergence = 2.042816\n",
      "Epoch: 11\tFidelity = 0.516337\tKL_Divergence = 2.046183\n",
      "Epoch: 12\tFidelity = 0.515735\tKL_Divergence = 2.067248\n",
      "Epoch: 13\tFidelity = 0.514670\tKL_Divergence = 2.106586\n",
      "Epoch: 14\tFidelity = 0.514889\tKL_Divergence = 2.098287\n",
      "Epoch: 15\tFidelity = 0.515684\tKL_Divergence = 2.069098\n",
      "Epoch: 16\tFidelity = 0.515044\tKL_Divergence = 2.092480\n",
      "Epoch: 17\tFidelity = 0.514994\tKL_Divergence = 2.094346\n",
      "Epoch: 18\tFidelity = 0.514597\tKL_Divergence = 2.109401\n",
      "Epoch: 19\tFidelity = 0.515758\tKL_Divergence = 2.066436\n",
      "Epoch: 20\tFidelity = 0.515795\tKL_Divergence = 2.065132\n",
      "Epoch: 21\tFidelity = 0.515475\tKL_Divergence = 2.076598\n",
      "Epoch: 22\tFidelity = 0.515732\tKL_Divergence = 2.067343\n",
      "Epoch: 23\tFidelity = 0.515947\tKL_Divergence = 2.059728\n",
      "Epoch: 24\tFidelity = 0.515115\tKL_Divergence = 2.089824\n",
      "Epoch: 25\tFidelity = 0.515647\tKL_Divergence = 2.070366\n",
      "Epoch: 26\tFidelity = 0.516007\tKL_Divergence = 2.057604\n",
      "Epoch: 27\tFidelity = 0.515896\tKL_Divergence = 2.061539\n",
      "Epoch: 28\tFidelity = 0.515262\tKL_Divergence = 2.084363\n",
      "Epoch: 29\tFidelity = 0.514519\tKL_Divergence = 2.112347\n",
      "Epoch: 30\tFidelity = 0.517098\tKL_Divergence = 2.020560\n",
      "Epoch: 31\tFidelity = 0.514472\tKL_Divergence = 2.114175\n",
      "Epoch: 32\tFidelity = 0.516279\tKL_Divergence = 2.048134\n",
      "Epoch: 33\tFidelity = 0.516424\tKL_Divergence = 2.043158\n",
      "Epoch: 34\tFidelity = 0.516309\tKL_Divergence = 2.047091\n",
      "Epoch: 35\tFidelity = 0.515198\tKL_Divergence = 2.086730\n",
      "Epoch: 36\tFidelity = 0.515522\tKL_Divergence = 2.074883\n",
      "Epoch: 37\tFidelity = 0.515309\tKL_Divergence = 2.082629\n",
      "Epoch: 38\tFidelity = 0.515420\tKL_Divergence = 2.078579\n",
      "Epoch: 39\tFidelity = 0.514827\tKL_Divergence = 2.100577\n",
      "Epoch: 40\tFidelity = 0.516109\tKL_Divergence = 2.054045\n",
      "Epoch: 41\tFidelity = 0.515709\tKL_Divergence = 2.068137\n",
      "Epoch: 42\tFidelity = 0.517077\tKL_Divergence = 2.021229\n",
      "Epoch: 43\tFidelity = 0.514793\tKL_Divergence = 2.101867\n",
      "Epoch: 44\tFidelity = 0.514794\tKL_Divergence = 2.101816\n",
      "Epoch: 45\tFidelity = 0.514969\tKL_Divergence = 2.095230\n",
      "Epoch: 46\tFidelity = 0.512946\tKL_Divergence = 2.176653\n",
      "Epoch: 47\tFidelity = 0.515305\tKL_Divergence = 2.082768\n",
      "Epoch: 48\tFidelity = 0.515049\tKL_Divergence = 2.092242\n",
      "Epoch: 49\tFidelity = 0.516487\tKL_Divergence = 2.041004\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:42:21,703] Trial 159 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.514264\tKL_Divergence = 2.122296\n",
      "Total time elapsed during training: 43.782 s\n",
      "Trial 159 pruned. \n",
      "Epoch: 1\tFidelity = 0.515725\tKL_Divergence = 2.067586\n",
      "Epoch: 2\tFidelity = 0.515312\tKL_Divergence = 2.082522\n",
      "Epoch: 3\tFidelity = 0.515062\tKL_Divergence = 2.091761\n",
      "Epoch: 4\tFidelity = 0.515683\tKL_Divergence = 2.069071\n",
      "Epoch: 5\tFidelity = 0.514849\tKL_Divergence = 2.099761\n",
      "Epoch: 6\tFidelity = 0.514847\tKL_Divergence = 2.099834\n",
      "Epoch: 7\tFidelity = 0.516447\tKL_Divergence = 2.042369\n",
      "Epoch: 8\tFidelity = 0.514918\tKL_Divergence = 2.097153\n",
      "Epoch: 9\tFidelity = 0.514682\tKL_Divergence = 2.106091\n",
      "Epoch: 10\tFidelity = 0.515407\tKL_Divergence = 2.079067\n",
      "Epoch: 11\tFidelity = 0.514520\tKL_Divergence = 2.112346\n",
      "Epoch: 12\tFidelity = 0.514389\tKL_Divergence = 2.117411\n",
      "Epoch: 13\tFidelity = 0.515194\tKL_Divergence = 2.086874\n",
      "Epoch: 14\tFidelity = 0.514366\tKL_Divergence = 2.118302\n",
      "Epoch: 15\tFidelity = 0.514927\tKL_Divergence = 2.096824\n",
      "Epoch: 16\tFidelity = 0.516598\tKL_Divergence = 2.037245\n",
      "Epoch: 17\tFidelity = 0.515477\tKL_Divergence = 2.076522\n",
      "Epoch: 18\tFidelity = 0.515450\tKL_Divergence = 2.077488\n",
      "Epoch: 19\tFidelity = 0.515248\tKL_Divergence = 2.084883\n",
      "Epoch: 20\tFidelity = 0.514435\tKL_Divergence = 2.115611\n",
      "Epoch: 21\tFidelity = 0.516142\tKL_Divergence = 2.052870\n",
      "Epoch: 22\tFidelity = 0.514555\tKL_Divergence = 2.110992\n",
      "Epoch: 23\tFidelity = 0.515243\tKL_Divergence = 2.085047\n",
      "Epoch: 24\tFidelity = 0.513730\tKL_Divergence = 2.143692\n",
      "Epoch: 25\tFidelity = 0.515333\tKL_Divergence = 2.081764\n",
      "Epoch: 26\tFidelity = 0.516099\tKL_Divergence = 2.054389\n",
      "Epoch: 27\tFidelity = 0.514204\tKL_Divergence = 2.124677\n",
      "Epoch: 28\tFidelity = 0.515938\tKL_Divergence = 2.060024\n",
      "Epoch: 29\tFidelity = 0.514355\tKL_Divergence = 2.118711\n",
      "Epoch: 30\tFidelity = 0.515385\tKL_Divergence = 2.079834\n",
      "Epoch: 31\tFidelity = 0.514536\tKL_Divergence = 2.111694\n",
      "Epoch: 32\tFidelity = 0.516132\tKL_Divergence = 2.053232\n",
      "Epoch: 33\tFidelity = 0.516306\tKL_Divergence = 2.047190\n",
      "Epoch: 34\tFidelity = 0.514918\tKL_Divergence = 2.097142\n",
      "Epoch: 35\tFidelity = 0.516058\tKL_Divergence = 2.055810\n",
      "Epoch: 36\tFidelity = 0.514292\tKL_Divergence = 2.121186\n",
      "Epoch: 37\tFidelity = 0.515888\tKL_Divergence = 2.061775\n",
      "Epoch: 38\tFidelity = 0.514548\tKL_Divergence = 2.111240\n",
      "Epoch: 39\tFidelity = 0.514882\tKL_Divergence = 2.098523\n",
      "Epoch: 40\tFidelity = 0.515867\tKL_Divergence = 2.062540\n",
      "Epoch: 41\tFidelity = 0.514351\tKL_Divergence = 2.118883\n",
      "Epoch: 42\tFidelity = 0.515960\tKL_Divergence = 2.059247\n",
      "Epoch: 43\tFidelity = 0.514096\tKL_Divergence = 2.128956\n",
      "Epoch: 44\tFidelity = 0.515711\tKL_Divergence = 2.068057\n",
      "Epoch: 45\tFidelity = 0.515188\tKL_Divergence = 2.087076\n",
      "Epoch: 46\tFidelity = 0.514496\tKL_Divergence = 2.113232\n",
      "Epoch: 47\tFidelity = 0.515557\tKL_Divergence = 2.073605\n",
      "Epoch: 48\tFidelity = 0.515509\tKL_Divergence = 2.075318\n",
      "Epoch: 49\tFidelity = 0.514368\tKL_Divergence = 2.118204\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:42:52,610] Trial 160 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.515871\tKL_Divergence = 2.062394\n",
      "Total time elapsed during training: 30.763 s\n",
      "Trial 160 pruned. \n",
      "Epoch: 1\tFidelity = 0.515025\tKL_Divergence = 2.092996\n",
      "Epoch: 2\tFidelity = 0.514201\tKL_Divergence = 2.124740\n",
      "Epoch: 3\tFidelity = 0.514511\tKL_Divergence = 2.112654\n",
      "Epoch: 4\tFidelity = 0.514322\tKL_Divergence = 2.119995\n",
      "Epoch: 5\tFidelity = 0.518122\tKL_Divergence = 1.987800\n",
      "Epoch: 6\tFidelity = 0.516738\tKL_Divergence = 2.032490\n",
      "Epoch: 7\tFidelity = 0.516768\tKL_Divergence = 2.031508\n",
      "Epoch: 8\tFidelity = 0.515157\tKL_Divergence = 2.088230\n",
      "Epoch: 9\tFidelity = 0.515826\tKL_Divergence = 2.064018\n",
      "Epoch: 10\tFidelity = 0.512840\tKL_Divergence = 2.181305\n",
      "Epoch: 11\tFidelity = 0.514569\tKL_Divergence = 2.110463\n",
      "Epoch: 12\tFidelity = 0.515531\tKL_Divergence = 2.074614\n",
      "Epoch: 13\tFidelity = 0.516172\tKL_Divergence = 2.051890\n",
      "Epoch: 14\tFidelity = 0.514245\tKL_Divergence = 2.123145\n",
      "Epoch: 15\tFidelity = 0.515424\tKL_Divergence = 2.078490\n",
      "Epoch: 16\tFidelity = 0.514360\tKL_Divergence = 2.118640\n",
      "Epoch: 17\tFidelity = 0.514719\tKL_Divergence = 2.104772\n",
      "Epoch: 18\tFidelity = 0.514599\tKL_Divergence = 2.109352\n",
      "Epoch: 19\tFidelity = 0.514743\tKL_Divergence = 2.103808\n",
      "Epoch: 20\tFidelity = 0.514706\tKL_Divergence = 2.105276\n",
      "Epoch: 21\tFidelity = 0.514659\tKL_Divergence = 2.107061\n",
      "Epoch: 22\tFidelity = 0.514114\tKL_Divergence = 2.128298\n",
      "Epoch: 23\tFidelity = 0.516432\tKL_Divergence = 2.042911\n",
      "Epoch: 24\tFidelity = 0.512899\tKL_Divergence = 2.178744\n",
      "Epoch: 25\tFidelity = 0.515244\tKL_Divergence = 2.085060\n",
      "Epoch: 26\tFidelity = 0.513727\tKL_Divergence = 2.143867\n",
      "Epoch: 27\tFidelity = 0.516699\tKL_Divergence = 2.033825\n",
      "Epoch: 28\tFidelity = 0.516213\tKL_Divergence = 2.050482\n",
      "Epoch: 29\tFidelity = 0.513695\tKL_Divergence = 2.145195\n",
      "Epoch: 30\tFidelity = 0.513925\tKL_Divergence = 2.135864\n",
      "Epoch: 31\tFidelity = 0.514025\tKL_Divergence = 2.131861\n",
      "Epoch: 32\tFidelity = 0.516342\tKL_Divergence = 2.046050\n",
      "Epoch: 33\tFidelity = 0.516349\tKL_Divergence = 2.045798\n",
      "Epoch: 34\tFidelity = 0.514409\tKL_Divergence = 2.116744\n",
      "Epoch: 35\tFidelity = 0.515970\tKL_Divergence = 2.058992\n",
      "Epoch: 36\tFidelity = 0.514275\tKL_Divergence = 2.121985\n",
      "Epoch: 37\tFidelity = 0.514168\tKL_Divergence = 2.126207\n",
      "Epoch: 38\tFidelity = 0.514446\tKL_Divergence = 2.115292\n",
      "Epoch: 39\tFidelity = 0.513171\tKL_Divergence = 2.167122\n",
      "Epoch: 40\tFidelity = 0.514096\tKL_Divergence = 2.129004\n",
      "Epoch: 41\tFidelity = 0.514351\tKL_Divergence = 2.118936\n",
      "Epoch: 42\tFidelity = 0.513872\tKL_Divergence = 2.137971\n",
      "Epoch: 43\tFidelity = 0.512612\tKL_Divergence = 2.191313\n",
      "Epoch: 44\tFidelity = 0.514363\tKL_Divergence = 2.118470\n",
      "Epoch: 45\tFidelity = 0.515544\tKL_Divergence = 2.074130\n",
      "Epoch: 46\tFidelity = 0.515554\tKL_Divergence = 2.073768\n",
      "Epoch: 47\tFidelity = 0.516190\tKL_Divergence = 2.051211\n",
      "Epoch: 48\tFidelity = 0.515400\tKL_Divergence = 2.079376\n",
      "Epoch: 49\tFidelity = 0.513740\tKL_Divergence = 2.143355\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:44:09,880] Trial 161 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.512521\tKL_Divergence = 2.195369\n",
      "Total time elapsed during training: 77.127 s\n",
      "Trial 161 pruned. \n",
      "Epoch: 1\tFidelity = 0.513362\tKL_Divergence = 2.158932\n",
      "Epoch: 2\tFidelity = 0.512920\tKL_Divergence = 2.177798\n",
      "Epoch: 3\tFidelity = 0.513661\tKL_Divergence = 2.146417\n",
      "Epoch: 4\tFidelity = 0.514317\tKL_Divergence = 2.120253\n",
      "Epoch: 5\tFidelity = 0.515593\tKL_Divergence = 2.072358\n",
      "Epoch: 6\tFidelity = 0.514304\tKL_Divergence = 2.120815\n",
      "Epoch: 7\tFidelity = 0.514208\tKL_Divergence = 2.124564\n",
      "Epoch: 8\tFidelity = 0.515035\tKL_Divergence = 2.092829\n",
      "Epoch: 9\tFidelity = 0.513525\tKL_Divergence = 2.152107\n",
      "Epoch: 10\tFidelity = 0.515388\tKL_Divergence = 2.079805\n",
      "Epoch: 11\tFidelity = 0.515510\tKL_Divergence = 2.075255\n",
      "Epoch: 12\tFidelity = 0.515522\tKL_Divergence = 2.074932\n",
      "Epoch: 13\tFidelity = 0.516037\tKL_Divergence = 2.056620\n",
      "Epoch: 14\tFidelity = 0.515106\tKL_Divergence = 2.090155\n",
      "Epoch: 15\tFidelity = 0.514900\tKL_Divergence = 2.097883\n",
      "Epoch: 16\tFidelity = 0.513626\tKL_Divergence = 2.148056\n",
      "Epoch: 17\tFidelity = 0.514396\tKL_Divergence = 2.117234\n",
      "Epoch: 18\tFidelity = 0.515247\tKL_Divergence = 2.085018\n",
      "Epoch: 19\tFidelity = 0.514196\tKL_Divergence = 2.125088\n",
      "Epoch: 20\tFidelity = 0.513678\tKL_Divergence = 2.145939\n",
      "Epoch: 21\tFidelity = 0.513723\tKL_Divergence = 2.144066\n",
      "Epoch: 22\tFidelity = 0.513499\tKL_Divergence = 2.153309\n",
      "Epoch: 23\tFidelity = 0.516537\tKL_Divergence = 2.039358\n",
      "Epoch: 24\tFidelity = 0.514395\tKL_Divergence = 2.117268\n",
      "Epoch: 25\tFidelity = 0.513236\tKL_Divergence = 2.164277\n",
      "Epoch: 26\tFidelity = 0.516924\tKL_Divergence = 2.026267\n",
      "Epoch: 27\tFidelity = 0.516048\tKL_Divergence = 2.056256\n",
      "Epoch: 28\tFidelity = 0.512876\tKL_Divergence = 2.179732\n",
      "Epoch: 29\tFidelity = 0.515211\tKL_Divergence = 2.086403\n",
      "Epoch: 30\tFidelity = 0.514372\tKL_Divergence = 2.118161\n",
      "Epoch: 31\tFidelity = 0.513650\tKL_Divergence = 2.146986\n",
      "Epoch: 32\tFidelity = 0.515521\tKL_Divergence = 2.074981\n",
      "Epoch: 33\tFidelity = 0.515670\tKL_Divergence = 2.069711\n",
      "Epoch: 34\tFidelity = 0.512196\tKL_Divergence = 2.210197\n",
      "Epoch: 35\tFidelity = 0.514234\tKL_Divergence = 2.123642\n",
      "Epoch: 36\tFidelity = 0.516101\tKL_Divergence = 2.054421\n",
      "Epoch: 37\tFidelity = 0.513112\tKL_Divergence = 2.169626\n",
      "Epoch: 38\tFidelity = 0.515506\tKL_Divergence = 2.075528\n",
      "Epoch: 39\tFidelity = 0.513905\tKL_Divergence = 2.136699\n",
      "Epoch: 40\tFidelity = 0.515650\tKL_Divergence = 2.070332\n",
      "Epoch: 41\tFidelity = 0.516206\tKL_Divergence = 2.050750\n",
      "Epoch: 42\tFidelity = 0.513730\tKL_Divergence = 2.143789\n",
      "Epoch: 43\tFidelity = 0.515470\tKL_Divergence = 2.076847\n",
      "Epoch: 44\tFidelity = 0.513110\tKL_Divergence = 2.169683\n",
      "Epoch: 45\tFidelity = 0.513074\tKL_Divergence = 2.171234\n",
      "Epoch: 46\tFidelity = 0.515465\tKL_Divergence = 2.077055\n",
      "Epoch: 47\tFidelity = 0.514692\tKL_Divergence = 2.105807\n",
      "Epoch: 48\tFidelity = 0.514232\tKL_Divergence = 2.123654\n",
      "Epoch: 49\tFidelity = 0.515847\tKL_Divergence = 2.063333\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:45:28,885] Trial 162 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.513956\tKL_Divergence = 2.134646\n",
      "Total time elapsed during training: 78.857 s\n",
      "Trial 162 pruned. \n",
      "Epoch: 1\tFidelity = 0.512428\tKL_Divergence = 2.199636\n",
      "Epoch: 2\tFidelity = 0.514431\tKL_Divergence = 2.115893\n",
      "Epoch: 3\tFidelity = 0.514637\tKL_Divergence = 2.107965\n",
      "Epoch: 4\tFidelity = 0.513188\tKL_Divergence = 2.166369\n",
      "Epoch: 5\tFidelity = 0.513972\tKL_Divergence = 2.134002\n",
      "Epoch: 6\tFidelity = 0.513308\tKL_Divergence = 2.161307\n",
      "Epoch: 7\tFidelity = 0.513267\tKL_Divergence = 2.163054\n",
      "Epoch: 8\tFidelity = 0.516334\tKL_Divergence = 2.046331\n",
      "Epoch: 9\tFidelity = 0.514931\tKL_Divergence = 2.096777\n",
      "Epoch: 10\tFidelity = 0.515119\tKL_Divergence = 2.089690\n",
      "Epoch: 11\tFidelity = 0.515155\tKL_Divergence = 2.088355\n",
      "Epoch: 12\tFidelity = 0.517056\tKL_Divergence = 2.021888\n",
      "Epoch: 13\tFidelity = 0.515237\tKL_Divergence = 2.085265\n",
      "Epoch: 14\tFidelity = 0.514203\tKL_Divergence = 2.124754\n",
      "Epoch: 15\tFidelity = 0.515681\tKL_Divergence = 2.069157\n",
      "Epoch: 16\tFidelity = 0.515323\tKL_Divergence = 2.082151\n",
      "Epoch: 17\tFidelity = 0.514388\tKL_Divergence = 2.117449\n",
      "Epoch: 18\tFidelity = 0.513996\tKL_Divergence = 2.132980\n",
      "Epoch: 19\tFidelity = 0.513572\tKL_Divergence = 2.150261\n",
      "Epoch: 20\tFidelity = 0.513798\tKL_Divergence = 2.141020\n",
      "Epoch: 21\tFidelity = 0.514057\tKL_Divergence = 2.130602\n",
      "Epoch: 22\tFidelity = 0.513330\tKL_Divergence = 2.160366\n",
      "Epoch: 23\tFidelity = 0.516100\tKL_Divergence = 2.054436\n",
      "Epoch: 24\tFidelity = 0.512881\tKL_Divergence = 2.179557\n",
      "Epoch: 25\tFidelity = 0.514082\tKL_Divergence = 2.129628\n",
      "Epoch: 26\tFidelity = 0.514160\tKL_Divergence = 2.126445\n",
      "Epoch: 27\tFidelity = 0.513721\tKL_Divergence = 2.144179\n",
      "Epoch: 28\tFidelity = 0.513658\tKL_Divergence = 2.146761\n",
      "Epoch: 29\tFidelity = 0.514247\tKL_Divergence = 2.123070\n",
      "Epoch: 30\tFidelity = 0.516459\tKL_Divergence = 2.042021\n",
      "Epoch: 31\tFidelity = 0.512481\tKL_Divergence = 2.197264\n",
      "Epoch: 32\tFidelity = 0.515550\tKL_Divergence = 2.073939\n",
      "Epoch: 33\tFidelity = 0.513563\tKL_Divergence = 2.150658\n",
      "Epoch: 34\tFidelity = 0.513962\tKL_Divergence = 2.134428\n",
      "Epoch: 35\tFidelity = 0.515506\tKL_Divergence = 2.075553\n",
      "Epoch: 36\tFidelity = 0.513763\tKL_Divergence = 2.142472\n",
      "Epoch: 37\tFidelity = 0.513355\tKL_Divergence = 2.159334\n",
      "Epoch: 38\tFidelity = 0.511983\tKL_Divergence = 2.220084\n",
      "Epoch: 39\tFidelity = 0.514090\tKL_Divergence = 2.129315\n",
      "Epoch: 40\tFidelity = 0.511751\tKL_Divergence = 2.231024\n",
      "Epoch: 41\tFidelity = 0.514359\tKL_Divergence = 2.118658\n",
      "Epoch: 42\tFidelity = 0.513018\tKL_Divergence = 2.173665\n",
      "Epoch: 43\tFidelity = 0.514060\tKL_Divergence = 2.130482\n",
      "Epoch: 44\tFidelity = 0.513709\tKL_Divergence = 2.144597\n",
      "Epoch: 45\tFidelity = 0.514700\tKL_Divergence = 2.105565\n",
      "Epoch: 46\tFidelity = 0.516586\tKL_Divergence = 2.037735\n",
      "Epoch: 47\tFidelity = 0.513351\tKL_Divergence = 2.159542\n",
      "Epoch: 48\tFidelity = 0.515470\tKL_Divergence = 2.076866\n",
      "Epoch: 49\tFidelity = 0.514535\tKL_Divergence = 2.111798\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:46:46,138] Trial 163 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.515328\tKL_Divergence = 2.082041\n",
      "Total time elapsed during training: 77.105 s\n",
      "Trial 163 pruned. \n",
      "Epoch: 1\tFidelity = 0.512633\tKL_Divergence = 2.190486\n",
      "Epoch: 2\tFidelity = 0.513331\tKL_Divergence = 2.160342\n",
      "Epoch: 3\tFidelity = 0.514053\tKL_Divergence = 2.130798\n",
      "Epoch: 4\tFidelity = 0.512920\tKL_Divergence = 2.177890\n",
      "Epoch: 5\tFidelity = 0.512969\tKL_Divergence = 2.175783\n",
      "Epoch: 6\tFidelity = 0.512297\tKL_Divergence = 2.205584\n",
      "Epoch: 7\tFidelity = 0.511712\tKL_Divergence = 2.232890\n",
      "Epoch: 8\tFidelity = 0.516678\tKL_Divergence = 2.034577\n",
      "Epoch: 9\tFidelity = 0.516028\tKL_Divergence = 2.056953\n",
      "Epoch: 10\tFidelity = 0.513180\tKL_Divergence = 2.166740\n",
      "Epoch: 11\tFidelity = 0.513336\tKL_Divergence = 2.160137\n",
      "Epoch: 12\tFidelity = 0.513555\tKL_Divergence = 2.151008\n",
      "Epoch: 13\tFidelity = 0.516307\tKL_Divergence = 2.047234\n",
      "Epoch: 14\tFidelity = 0.513298\tKL_Divergence = 2.161734\n",
      "Epoch: 15\tFidelity = 0.514995\tKL_Divergence = 2.094333\n",
      "Epoch: 16\tFidelity = 0.513988\tKL_Divergence = 2.133298\n",
      "Epoch: 17\tFidelity = 0.514899\tKL_Divergence = 2.097795\n",
      "Epoch: 18\tFidelity = 0.510951\tKL_Divergence = 2.269920\n",
      "Epoch: 19\tFidelity = 0.515107\tKL_Divergence = 2.090192\n",
      "Epoch: 20\tFidelity = 0.512141\tKL_Divergence = 2.212723\n",
      "Epoch: 21\tFidelity = 0.514492\tKL_Divergence = 2.113368\n",
      "Epoch: 22\tFidelity = 0.515157\tKL_Divergence = 2.088095\n",
      "Epoch: 23\tFidelity = 0.515310\tKL_Divergence = 2.082556\n",
      "Epoch: 24\tFidelity = 0.516375\tKL_Divergence = 2.044775\n",
      "Epoch: 25\tFidelity = 0.513211\tKL_Divergence = 2.165270\n",
      "Epoch: 26\tFidelity = 0.514371\tKL_Divergence = 2.118147\n",
      "Epoch: 27\tFidelity = 0.512867\tKL_Divergence = 2.180083\n",
      "Epoch: 28\tFidelity = 0.513821\tKL_Divergence = 2.139959\n",
      "Epoch: 29\tFidelity = 0.514006\tKL_Divergence = 2.132589\n",
      "Epoch: 30\tFidelity = 0.515754\tKL_Divergence = 2.066647\n",
      "Epoch: 31\tFidelity = 0.514687\tKL_Divergence = 2.106004\n",
      "Epoch: 32\tFidelity = 0.512736\tKL_Divergence = 2.185868\n",
      "Epoch: 33\tFidelity = 0.514177\tKL_Divergence = 2.125777\n",
      "Epoch: 34\tFidelity = 0.513412\tKL_Divergence = 2.156348\n",
      "Epoch: 35\tFidelity = 0.512708\tKL_Divergence = 2.186780\n",
      "Epoch: 36\tFidelity = 0.513546\tKL_Divergence = 2.151356\n",
      "Epoch: 37\tFidelity = 0.515726\tKL_Divergence = 2.067664\n",
      "Epoch: 38\tFidelity = 0.515343\tKL_Divergence = 2.081448\n",
      "Epoch: 39\tFidelity = 0.513117\tKL_Divergence = 2.169255\n",
      "Epoch: 40\tFidelity = 0.513412\tKL_Divergence = 2.156550\n",
      "Epoch: 41\tFidelity = 0.512783\tKL_Divergence = 2.183321\n",
      "Epoch: 42\tFidelity = 0.515609\tKL_Divergence = 2.071593\n",
      "Epoch: 43\tFidelity = 0.513342\tKL_Divergence = 2.159752\n",
      "Epoch: 44\tFidelity = 0.514278\tKL_Divergence = 2.121745\n",
      "Epoch: 45\tFidelity = 0.514272\tKL_Divergence = 2.122143\n",
      "Epoch: 46\tFidelity = 0.513616\tKL_Divergence = 2.148331\n",
      "Epoch: 47\tFidelity = 0.511744\tKL_Divergence = 2.231339\n",
      "Epoch: 48\tFidelity = 0.514595\tKL_Divergence = 2.109403\n",
      "Epoch: 49\tFidelity = 0.515222\tKL_Divergence = 2.085702\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:47:23,173] Trial 164 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.512667\tKL_Divergence = 2.188758\n",
      "Total time elapsed during training: 36.886 s\n",
      "Trial 164 pruned. \n",
      "Epoch: 1\tFidelity = 0.514519\tKL_Divergence = 2.112471\n",
      "Epoch: 2\tFidelity = 0.511954\tKL_Divergence = 2.221443\n",
      "Epoch: 3\tFidelity = 0.513569\tKL_Divergence = 2.150430\n",
      "Epoch: 4\tFidelity = 0.513400\tKL_Divergence = 2.157394\n",
      "Epoch: 5\tFidelity = 0.514402\tKL_Divergence = 2.116953\n",
      "Epoch: 6\tFidelity = 0.514891\tKL_Divergence = 2.098143\n",
      "Epoch: 7\tFidelity = 0.514590\tKL_Divergence = 2.109731\n",
      "Epoch: 8\tFidelity = 0.513435\tKL_Divergence = 2.155933\n",
      "Epoch: 9\tFidelity = 0.513429\tKL_Divergence = 2.156285\n",
      "Epoch: 10\tFidelity = 0.512446\tKL_Divergence = 2.198886\n",
      "Epoch: 11\tFidelity = 0.511917\tKL_Divergence = 2.223204\n",
      "Epoch: 12\tFidelity = 0.514634\tKL_Divergence = 2.108074\n",
      "Epoch: 13\tFidelity = 0.513171\tKL_Divergence = 2.167090\n",
      "Epoch: 14\tFidelity = 0.511446\tKL_Divergence = 2.245696\n",
      "Epoch: 15\tFidelity = 0.515439\tKL_Divergence = 2.078054\n",
      "Epoch: 16\tFidelity = 0.513535\tKL_Divergence = 2.151859\n",
      "Epoch: 17\tFidelity = 0.514203\tKL_Divergence = 2.124840\n",
      "Epoch: 18\tFidelity = 0.512492\tKL_Divergence = 2.196822\n",
      "Epoch: 19\tFidelity = 0.513287\tKL_Divergence = 2.162224\n",
      "Epoch: 20\tFidelity = 0.513745\tKL_Divergence = 2.143244\n",
      "Epoch: 21\tFidelity = 0.514579\tKL_Divergence = 2.110026\n",
      "Epoch: 22\tFidelity = 0.514710\tKL_Divergence = 2.105126\n",
      "Epoch: 23\tFidelity = 0.512423\tKL_Divergence = 2.199855\n",
      "Epoch: 24\tFidelity = 0.513988\tKL_Divergence = 2.133237\n",
      "Epoch: 25\tFidelity = 0.513219\tKL_Divergence = 2.165099\n",
      "Epoch: 26\tFidelity = 0.514659\tKL_Divergence = 2.107113\n",
      "Epoch: 27\tFidelity = 0.512578\tKL_Divergence = 2.192975\n",
      "Epoch: 28\tFidelity = 0.514234\tKL_Divergence = 2.123628\n",
      "Epoch: 29\tFidelity = 0.514001\tKL_Divergence = 2.132869\n",
      "Epoch: 30\tFidelity = 0.511372\tKL_Divergence = 2.249295\n",
      "Epoch: 31\tFidelity = 0.514300\tKL_Divergence = 2.120941\n",
      "Epoch: 32\tFidelity = 0.513430\tKL_Divergence = 2.156222\n",
      "Epoch: 33\tFidelity = 0.516711\tKL_Divergence = 2.033420\n",
      "Epoch: 34\tFidelity = 0.512655\tKL_Divergence = 2.189486\n",
      "Epoch: 35\tFidelity = 0.514630\tKL_Divergence = 2.108155\n",
      "Epoch: 36\tFidelity = 0.514689\tKL_Divergence = 2.105907\n",
      "Epoch: 37\tFidelity = 0.513293\tKL_Divergence = 2.161910\n",
      "Epoch: 38\tFidelity = 0.514229\tKL_Divergence = 2.123720\n",
      "Epoch: 39\tFidelity = 0.513125\tKL_Divergence = 2.169037\n",
      "Epoch: 40\tFidelity = 0.513506\tKL_Divergence = 2.153047\n",
      "Epoch: 41\tFidelity = 0.514616\tKL_Divergence = 2.108802\n",
      "Epoch: 42\tFidelity = 0.514657\tKL_Divergence = 2.107229\n",
      "Epoch: 43\tFidelity = 0.516539\tKL_Divergence = 2.039361\n",
      "Epoch: 44\tFidelity = 0.513406\tKL_Divergence = 2.157294\n",
      "Epoch: 45\tFidelity = 0.514326\tKL_Divergence = 2.120043\n",
      "Epoch: 46\tFidelity = 0.513521\tKL_Divergence = 2.152498\n",
      "Epoch: 47\tFidelity = 0.513171\tKL_Divergence = 2.167151\n",
      "Epoch: 48\tFidelity = 0.513798\tKL_Divergence = 2.141075\n",
      "Epoch: 49\tFidelity = 0.513076\tKL_Divergence = 2.171183\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:48:42,210] Trial 165 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.514385\tKL_Divergence = 2.117733\n",
      "Total time elapsed during training: 78.893 s\n",
      "Trial 165 pruned. \n",
      "Epoch: 1\tFidelity = 0.514403\tKL_Divergence = 2.117049\n",
      "Epoch: 2\tFidelity = 0.514208\tKL_Divergence = 2.124702\n",
      "Epoch: 3\tFidelity = 0.511869\tKL_Divergence = 2.225504\n",
      "Epoch: 4\tFidelity = 0.514654\tKL_Divergence = 2.107387\n",
      "Epoch: 5\tFidelity = 0.511883\tKL_Divergence = 2.224831\n",
      "Epoch: 6\tFidelity = 0.512889\tKL_Divergence = 2.179350\n",
      "Epoch: 7\tFidelity = 0.512046\tKL_Divergence = 2.217201\n",
      "Epoch: 8\tFidelity = 0.511630\tKL_Divergence = 2.236887\n",
      "Epoch: 9\tFidelity = 0.512839\tKL_Divergence = 2.181494\n",
      "Epoch: 10\tFidelity = 0.512765\tKL_Divergence = 2.184718\n",
      "Epoch: 11\tFidelity = 0.512395\tKL_Divergence = 2.201215\n",
      "Epoch: 12\tFidelity = 0.512616\tKL_Divergence = 2.191335\n",
      "Epoch: 13\tFidelity = 0.514603\tKL_Divergence = 2.109268\n",
      "Epoch: 14\tFidelity = 0.513498\tKL_Divergence = 2.153425\n",
      "Epoch: 15\tFidelity = 0.513583\tKL_Divergence = 2.149935\n",
      "Epoch: 16\tFidelity = 0.513187\tKL_Divergence = 2.166529\n",
      "Epoch: 17\tFidelity = 0.514269\tKL_Divergence = 2.122325\n",
      "Epoch: 18\tFidelity = 0.512329\tKL_Divergence = 2.204216\n",
      "Epoch: 19\tFidelity = 0.514743\tKL_Divergence = 2.103951\n",
      "Epoch: 20\tFidelity = 0.513127\tKL_Divergence = 2.169078\n",
      "Epoch: 21\tFidelity = 0.513165\tKL_Divergence = 2.167452\n",
      "Epoch: 22\tFidelity = 0.513110\tKL_Divergence = 2.169790\n",
      "Epoch: 23\tFidelity = 0.514399\tKL_Divergence = 2.117194\n",
      "Epoch: 24\tFidelity = 0.512163\tKL_Divergence = 2.211796\n",
      "Epoch: 25\tFidelity = 0.512318\tKL_Divergence = 2.204685\n",
      "Epoch: 26\tFidelity = 0.514103\tKL_Divergence = 2.128815\n",
      "Epoch: 27\tFidelity = 0.515019\tKL_Divergence = 2.093512\n",
      "Epoch: 28\tFidelity = 0.512881\tKL_Divergence = 2.179634\n",
      "Epoch: 29\tFidelity = 0.515209\tKL_Divergence = 2.086479\n",
      "Epoch: 30\tFidelity = 0.516335\tKL_Divergence = 2.046378\n",
      "Epoch: 31\tFidelity = 0.512783\tKL_Divergence = 2.183929\n",
      "Epoch: 32\tFidelity = 0.513944\tKL_Divergence = 2.135232\n",
      "Epoch: 33\tFidelity = 0.512167\tKL_Divergence = 2.211634\n",
      "Epoch: 34\tFidelity = 0.515658\tKL_Divergence = 2.070163\n",
      "Epoch: 35\tFidelity = 0.513190\tKL_Divergence = 2.166404\n",
      "Epoch: 36\tFidelity = 0.513935\tKL_Divergence = 2.135634\n",
      "Epoch: 37\tFidelity = 0.513314\tKL_Divergence = 2.161186\n",
      "Epoch: 38\tFidelity = 0.514795\tKL_Divergence = 2.102025\n",
      "Epoch: 39\tFidelity = 0.512894\tKL_Divergence = 2.179156\n",
      "Epoch: 40\tFidelity = 0.512734\tKL_Divergence = 2.186125\n",
      "Epoch: 41\tFidelity = 0.514522\tKL_Divergence = 2.112487\n",
      "Epoch: 42\tFidelity = 0.513666\tKL_Divergence = 2.146548\n",
      "Epoch: 43\tFidelity = 0.512220\tKL_Divergence = 2.209230\n",
      "Epoch: 44\tFidelity = 0.513100\tKL_Divergence = 2.170249\n",
      "Epoch: 45\tFidelity = 0.513000\tKL_Divergence = 2.174532\n",
      "Epoch: 46\tFidelity = 0.511603\tKL_Divergence = 2.238234\n",
      "Epoch: 47\tFidelity = 0.512233\tKL_Divergence = 2.208630\n",
      "Epoch: 48\tFidelity = 0.513039\tKL_Divergence = 2.172911\n",
      "Epoch: 49\tFidelity = 0.511271\tKL_Divergence = 2.254484\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:49:19,267] Trial 166 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.512528\tKL_Divergence = 2.195305\n",
      "Total time elapsed during training: 36.905 s\n",
      "Trial 166 pruned. \n",
      "Epoch: 1\tFidelity = 0.514485\tKL_Divergence = 2.113906\n",
      "Epoch: 2\tFidelity = 0.512763\tKL_Divergence = 2.184857\n",
      "Epoch: 3\tFidelity = 0.513066\tKL_Divergence = 2.171711\n",
      "Epoch: 4\tFidelity = 0.514086\tKL_Divergence = 2.129501\n",
      "Epoch: 5\tFidelity = 0.512395\tKL_Divergence = 2.201276\n",
      "Epoch: 6\tFidelity = 0.514813\tKL_Divergence = 2.101356\n",
      "Epoch: 7\tFidelity = 0.515443\tKL_Divergence = 2.077920\n",
      "Epoch: 8\tFidelity = 0.512851\tKL_Divergence = 2.180837\n",
      "Epoch: 9\tFidelity = 0.514442\tKL_Divergence = 2.115294\n",
      "Epoch: 10\tFidelity = 0.510476\tKL_Divergence = 2.295304\n",
      "Epoch: 11\tFidelity = 0.512544\tKL_Divergence = 2.194456\n",
      "Epoch: 12\tFidelity = 0.511181\tKL_Divergence = 2.258955\n",
      "Epoch: 13\tFidelity = 0.511524\tKL_Divergence = 2.242048\n",
      "Epoch: 14\tFidelity = 0.513555\tKL_Divergence = 2.151112\n",
      "Epoch: 15\tFidelity = 0.513462\tKL_Divergence = 2.154973\n",
      "Epoch: 16\tFidelity = 0.511070\tKL_Divergence = 2.264482\n",
      "Epoch: 17\tFidelity = 0.514436\tKL_Divergence = 2.115697\n",
      "Epoch: 18\tFidelity = 0.513119\tKL_Divergence = 2.169446\n",
      "Epoch: 19\tFidelity = 0.513395\tKL_Divergence = 2.157657\n",
      "Epoch: 20\tFidelity = 0.513470\tKL_Divergence = 2.154340\n",
      "Epoch: 21\tFidelity = 0.512069\tKL_Divergence = 2.215516\n",
      "Epoch: 22\tFidelity = 0.513588\tKL_Divergence = 2.149590\n",
      "Epoch: 23\tFidelity = 0.512183\tKL_Divergence = 2.210546\n",
      "Epoch: 24\tFidelity = 0.512172\tKL_Divergence = 2.211259\n",
      "Epoch: 25\tFidelity = 0.512654\tKL_Divergence = 2.189561\n",
      "Epoch: 26\tFidelity = 0.513718\tKL_Divergence = 2.144380\n",
      "Epoch: 27\tFidelity = 0.513034\tKL_Divergence = 2.173023\n",
      "Epoch: 28\tFidelity = 0.513273\tKL_Divergence = 2.162825\n",
      "Epoch: 29\tFidelity = 0.513052\tKL_Divergence = 2.172254\n",
      "Epoch: 30\tFidelity = 0.512494\tKL_Divergence = 2.196755\n",
      "Epoch: 31\tFidelity = 0.513120\tKL_Divergence = 2.169191\n",
      "Epoch: 32\tFidelity = 0.513074\tKL_Divergence = 2.171272\n",
      "Epoch: 33\tFidelity = 0.512834\tKL_Divergence = 2.181713\n",
      "Epoch: 34\tFidelity = 0.512982\tKL_Divergence = 2.175293\n",
      "Epoch: 35\tFidelity = 0.512014\tKL_Divergence = 2.218696\n",
      "Epoch: 36\tFidelity = 0.515209\tKL_Divergence = 2.086248\n",
      "Epoch: 37\tFidelity = 0.515112\tKL_Divergence = 2.089862\n",
      "Epoch: 38\tFidelity = 0.513350\tKL_Divergence = 2.159594\n",
      "Epoch: 39\tFidelity = 0.512297\tKL_Divergence = 2.205617\n",
      "Epoch: 40\tFidelity = 0.511172\tKL_Divergence = 2.259353\n",
      "Epoch: 41\tFidelity = 0.510632\tKL_Divergence = 2.286998\n",
      "Epoch: 42\tFidelity = 0.515355\tKL_Divergence = 2.081126\n",
      "Epoch: 43\tFidelity = 0.512891\tKL_Divergence = 2.179228\n",
      "Epoch: 44\tFidelity = 0.512924\tKL_Divergence = 2.177762\n",
      "Epoch: 45\tFidelity = 0.513335\tKL_Divergence = 2.160243\n",
      "Epoch: 46\tFidelity = 0.514890\tKL_Divergence = 2.098409\n",
      "Epoch: 47\tFidelity = 0.512771\tKL_Divergence = 2.184498\n",
      "Epoch: 48\tFidelity = 0.512190\tKL_Divergence = 2.210431\n",
      "Epoch: 49\tFidelity = 0.512910\tKL_Divergence = 2.178397\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:49:55,614] Trial 167 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.512784\tKL_Divergence = 2.183781\n",
      "Total time elapsed during training: 36.202 s\n",
      "Trial 167 pruned. \n",
      "Epoch: 1\tFidelity = 0.512158\tKL_Divergence = 2.211937\n",
      "Epoch: 2\tFidelity = 0.511892\tKL_Divergence = 2.224356\n",
      "Epoch: 3\tFidelity = 0.513499\tKL_Divergence = 2.153402\n",
      "Epoch: 4\tFidelity = 0.512595\tKL_Divergence = 2.192249\n",
      "Epoch: 5\tFidelity = 0.511984\tKL_Divergence = 2.220095\n",
      "Epoch: 6\tFidelity = 0.514623\tKL_Divergence = 2.108558\n",
      "Epoch: 7\tFidelity = 0.511875\tKL_Divergence = 2.225205\n",
      "Epoch: 8\tFidelity = 0.511820\tKL_Divergence = 2.227810\n",
      "Epoch: 9\tFidelity = 0.511335\tKL_Divergence = 2.251262\n",
      "Epoch: 10\tFidelity = 0.512734\tKL_Divergence = 2.186117\n",
      "Epoch: 11\tFidelity = 0.511334\tKL_Divergence = 2.251283\n",
      "Epoch: 12\tFidelity = 0.512551\tKL_Divergence = 2.194217\n",
      "Epoch: 13\tFidelity = 0.513417\tKL_Divergence = 2.156808\n",
      "Epoch: 14\tFidelity = 0.511808\tKL_Divergence = 2.228384\n",
      "Epoch: 15\tFidelity = 0.514266\tKL_Divergence = 2.122416\n",
      "Epoch: 16\tFidelity = 0.513937\tKL_Divergence = 2.135488\n",
      "Epoch: 17\tFidelity = 0.513612\tKL_Divergence = 2.148732\n",
      "Epoch: 18\tFidelity = 0.512717\tKL_Divergence = 2.186831\n",
      "Epoch: 19\tFidelity = 0.514443\tKL_Divergence = 2.115509\n",
      "Epoch: 20\tFidelity = 0.511484\tKL_Divergence = 2.243947\n",
      "Epoch: 21\tFidelity = 0.511203\tKL_Divergence = 2.257802\n",
      "Epoch: 22\tFidelity = 0.513495\tKL_Divergence = 2.153577\n",
      "Epoch: 23\tFidelity = 0.512915\tKL_Divergence = 2.178218\n",
      "Epoch: 24\tFidelity = 0.510728\tKL_Divergence = 2.282039\n",
      "Epoch: 25\tFidelity = 0.512420\tKL_Divergence = 2.200080\n",
      "Epoch: 26\tFidelity = 0.511781\tKL_Divergence = 2.229669\n",
      "Epoch: 27\tFidelity = 0.511308\tKL_Divergence = 2.252561\n",
      "Epoch: 28\tFidelity = 0.511873\tKL_Divergence = 2.225287\n",
      "Epoch: 29\tFidelity = 0.511291\tKL_Divergence = 2.253420\n",
      "Epoch: 30\tFidelity = 0.512118\tKL_Divergence = 2.213890\n",
      "Epoch: 31\tFidelity = 0.511051\tKL_Divergence = 2.265472\n",
      "Epoch: 32\tFidelity = 0.511840\tKL_Divergence = 2.226857\n",
      "Epoch: 33\tFidelity = 0.513004\tKL_Divergence = 2.174339\n",
      "Epoch: 34\tFidelity = 0.512287\tKL_Divergence = 2.206091\n",
      "Epoch: 35\tFidelity = 0.513254\tKL_Divergence = 2.163668\n",
      "Epoch: 36\tFidelity = 0.512296\tKL_Divergence = 2.205666\n",
      "Epoch: 37\tFidelity = 0.514044\tKL_Divergence = 2.131154\n",
      "Epoch: 38\tFidelity = 0.513915\tKL_Divergence = 2.136308\n",
      "Epoch: 39\tFidelity = 0.514363\tKL_Divergence = 2.118563\n",
      "Epoch: 40\tFidelity = 0.512941\tKL_Divergence = 2.176986\n",
      "Epoch: 41\tFidelity = 0.512756\tKL_Divergence = 2.185056\n",
      "Epoch: 42\tFidelity = 0.513701\tKL_Divergence = 2.145009\n",
      "Epoch: 43\tFidelity = 0.512058\tKL_Divergence = 2.216609\n",
      "Epoch: 44\tFidelity = 0.513160\tKL_Divergence = 2.167628\n",
      "Epoch: 45\tFidelity = 0.511616\tKL_Divergence = 2.237522\n",
      "Epoch: 46\tFidelity = 0.512867\tKL_Divergence = 2.180208\n",
      "Epoch: 47\tFidelity = 0.514453\tKL_Divergence = 2.115045\n",
      "Epoch: 48\tFidelity = 0.513265\tKL_Divergence = 2.163141\n",
      "Epoch: 49\tFidelity = 0.513438\tKL_Divergence = 2.155877\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:50:32,361] Trial 168 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.512623\tKL_Divergence = 2.190954\n",
      "Total time elapsed during training: 36.598 s\n",
      "Trial 168 pruned. \n",
      "Epoch: 1\tFidelity = 0.513027\tKL_Divergence = 2.173315\n",
      "Epoch: 2\tFidelity = 0.512594\tKL_Divergence = 2.192251\n",
      "Epoch: 3\tFidelity = 0.512579\tKL_Divergence = 2.192895\n",
      "Epoch: 4\tFidelity = 0.511637\tKL_Divergence = 2.236459\n",
      "Epoch: 5\tFidelity = 0.514281\tKL_Divergence = 2.121794\n",
      "Epoch: 6\tFidelity = 0.511786\tKL_Divergence = 2.229380\n",
      "Epoch: 7\tFidelity = 0.512835\tKL_Divergence = 2.181645\n",
      "Epoch: 8\tFidelity = 0.512867\tKL_Divergence = 2.180247\n",
      "Epoch: 9\tFidelity = 0.511907\tKL_Divergence = 2.223684\n",
      "Epoch: 10\tFidelity = 0.513412\tKL_Divergence = 2.156993\n",
      "Epoch: 11\tFidelity = 0.512680\tKL_Divergence = 2.188470\n",
      "Epoch: 12\tFidelity = 0.511146\tKL_Divergence = 2.260639\n",
      "Epoch: 13\tFidelity = 0.512003\tKL_Divergence = 2.219202\n",
      "Epoch: 14\tFidelity = 0.514186\tKL_Divergence = 2.125559\n",
      "Epoch: 15\tFidelity = 0.512297\tKL_Divergence = 2.205659\n",
      "Epoch: 16\tFidelity = 0.513155\tKL_Divergence = 2.167868\n",
      "Epoch: 17\tFidelity = 0.511501\tKL_Divergence = 2.243124\n",
      "Epoch: 18\tFidelity = 0.512785\tKL_Divergence = 2.183889\n",
      "Epoch: 19\tFidelity = 0.513760\tKL_Divergence = 2.142670\n",
      "Epoch: 20\tFidelity = 0.512984\tKL_Divergence = 2.175219\n",
      "Epoch: 21\tFidelity = 0.512584\tKL_Divergence = 2.192791\n",
      "Epoch: 22\tFidelity = 0.510783\tKL_Divergence = 2.279222\n",
      "Epoch: 23\tFidelity = 0.511970\tKL_Divergence = 2.220767\n",
      "Epoch: 24\tFidelity = 0.512015\tKL_Divergence = 2.218698\n",
      "Epoch: 25\tFidelity = 0.512932\tKL_Divergence = 2.177502\n",
      "Epoch: 26\tFidelity = 0.513597\tKL_Divergence = 2.149362\n",
      "Epoch: 27\tFidelity = 0.512287\tKL_Divergence = 2.206158\n",
      "Epoch: 28\tFidelity = 0.512430\tKL_Divergence = 2.199641\n",
      "Epoch: 29\tFidelity = 0.511825\tKL_Divergence = 2.227596\n",
      "Epoch: 30\tFidelity = 0.513346\tKL_Divergence = 2.159806\n",
      "Epoch: 31\tFidelity = 0.513462\tKL_Divergence = 2.154984\n",
      "Epoch: 32\tFidelity = 0.512213\tKL_Divergence = 2.209502\n",
      "Epoch: 33\tFidelity = 0.512645\tKL_Divergence = 2.190036\n",
      "Epoch: 34\tFidelity = 0.511844\tKL_Divergence = 2.226719\n",
      "Epoch: 35\tFidelity = 0.514379\tKL_Divergence = 2.117997\n",
      "Epoch: 36\tFidelity = 0.513486\tKL_Divergence = 2.153924\n",
      "Epoch: 37\tFidelity = 0.511914\tKL_Divergence = 2.223302\n",
      "Epoch: 38\tFidelity = 0.511512\tKL_Divergence = 2.242585\n",
      "Epoch: 39\tFidelity = 0.511678\tKL_Divergence = 2.234601\n",
      "Epoch: 40\tFidelity = 0.512105\tKL_Divergence = 2.214431\n",
      "Epoch: 41\tFidelity = 0.511454\tKL_Divergence = 2.245397\n",
      "Epoch: 42\tFidelity = 0.513250\tKL_Divergence = 2.163792\n",
      "Epoch: 43\tFidelity = 0.513647\tKL_Divergence = 2.147310\n",
      "Epoch: 44\tFidelity = 0.514381\tKL_Divergence = 2.117899\n",
      "Epoch: 45\tFidelity = 0.512647\tKL_Divergence = 2.189845\n",
      "Epoch: 46\tFidelity = 0.512096\tKL_Divergence = 2.214785\n",
      "Epoch: 47\tFidelity = 0.512893\tKL_Divergence = 2.179136\n",
      "Epoch: 48\tFidelity = 0.511811\tKL_Divergence = 2.228236\n",
      "Epoch: 49\tFidelity = 0.512371\tKL_Divergence = 2.202263\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:51:51,766] Trial 169 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.512903\tKL_Divergence = 2.178679\n",
      "Total time elapsed during training: 79.256 s\n",
      "Trial 169 pruned. \n",
      "Epoch: 1\tFidelity = 0.513395\tKL_Divergence = 2.157703\n",
      "Epoch: 2\tFidelity = 0.512229\tKL_Divergence = 2.208709\n",
      "Epoch: 3\tFidelity = 0.511962\tKL_Divergence = 2.221086\n",
      "Epoch: 4\tFidelity = 0.512423\tKL_Divergence = 2.199911\n",
      "Epoch: 5\tFidelity = 0.511868\tKL_Divergence = 2.225512\n",
      "Epoch: 6\tFidelity = 0.512268\tKL_Divergence = 2.206930\n",
      "Epoch: 7\tFidelity = 0.511631\tKL_Divergence = 2.236799\n",
      "Epoch: 8\tFidelity = 0.512936\tKL_Divergence = 2.177233\n",
      "Epoch: 9\tFidelity = 0.512070\tKL_Divergence = 2.216054\n",
      "Epoch: 10\tFidelity = 0.512404\tKL_Divergence = 2.200765\n",
      "Epoch: 11\tFidelity = 0.511188\tKL_Divergence = 2.258518\n",
      "Epoch: 12\tFidelity = 0.512926\tKL_Divergence = 2.177704\n",
      "Epoch: 13\tFidelity = 0.512124\tKL_Divergence = 2.213578\n",
      "Epoch: 14\tFidelity = 0.513560\tKL_Divergence = 2.150842\n",
      "Epoch: 15\tFidelity = 0.512382\tKL_Divergence = 2.201761\n",
      "Epoch: 16\tFidelity = 0.511921\tKL_Divergence = 2.222995\n",
      "Epoch: 17\tFidelity = 0.513258\tKL_Divergence = 2.163476\n",
      "Epoch: 18\tFidelity = 0.511399\tKL_Divergence = 2.248061\n",
      "Epoch: 19\tFidelity = 0.513197\tKL_Divergence = 2.166041\n",
      "Epoch: 20\tFidelity = 0.512620\tKL_Divergence = 2.191118\n",
      "Epoch: 21\tFidelity = 0.513245\tKL_Divergence = 2.164035\n",
      "Epoch: 22\tFidelity = 0.512097\tKL_Divergence = 2.214816\n",
      "Epoch: 23\tFidelity = 0.512701\tKL_Divergence = 2.187516\n",
      "Epoch: 24\tFidelity = 0.512742\tKL_Divergence = 2.185715\n",
      "Epoch: 25\tFidelity = 0.512137\tKL_Divergence = 2.212963\n",
      "Epoch: 26\tFidelity = 0.512968\tKL_Divergence = 2.175840\n",
      "Epoch: 27\tFidelity = 0.512424\tKL_Divergence = 2.199888\n",
      "Epoch: 28\tFidelity = 0.512705\tKL_Divergence = 2.187327\n",
      "Epoch: 29\tFidelity = 0.512058\tKL_Divergence = 2.216621\n",
      "Epoch: 30\tFidelity = 0.513071\tKL_Divergence = 2.171413\n",
      "Epoch: 31\tFidelity = 0.511857\tKL_Divergence = 2.226037\n",
      "Epoch: 32\tFidelity = 0.511718\tKL_Divergence = 2.232643\n",
      "Epoch: 33\tFidelity = 0.512641\tKL_Divergence = 2.190159\n",
      "Epoch: 34\tFidelity = 0.511674\tKL_Divergence = 2.234721\n",
      "Epoch: 35\tFidelity = 0.513606\tKL_Divergence = 2.148945\n",
      "Epoch: 36\tFidelity = 0.513343\tKL_Divergence = 2.159867\n",
      "Epoch: 37\tFidelity = 0.512278\tKL_Divergence = 2.206512\n",
      "Epoch: 38\tFidelity = 0.512492\tKL_Divergence = 2.196827\n",
      "Epoch: 39\tFidelity = 0.511259\tKL_Divergence = 2.254973\n",
      "Epoch: 40\tFidelity = 0.513150\tKL_Divergence = 2.168060\n",
      "Epoch: 41\tFidelity = 0.512169\tKL_Divergence = 2.211488\n",
      "Epoch: 42\tFidelity = 0.512393\tKL_Divergence = 2.201266\n",
      "Epoch: 43\tFidelity = 0.512496\tKL_Divergence = 2.196624\n",
      "Epoch: 44\tFidelity = 0.512189\tKL_Divergence = 2.210589\n",
      "Epoch: 45\tFidelity = 0.512564\tKL_Divergence = 2.193594\n",
      "Epoch: 46\tFidelity = 0.511510\tKL_Divergence = 2.242654\n",
      "Epoch: 47\tFidelity = 0.513096\tKL_Divergence = 2.170348\n",
      "Epoch: 48\tFidelity = 0.511265\tKL_Divergence = 2.254701\n",
      "Epoch: 49\tFidelity = 0.513650\tKL_Divergence = 2.147146\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:52:22,926] Trial 170 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.512128\tKL_Divergence = 2.213359\n",
      "Total time elapsed during training: 30.982 s\n",
      "Trial 170 pruned. \n",
      "Epoch: 1\tFidelity = 0.513363\tKL_Divergence = 2.159047\n",
      "Epoch: 2\tFidelity = 0.511878\tKL_Divergence = 2.225048\n",
      "Epoch: 3\tFidelity = 0.513813\tKL_Divergence = 2.140479\n",
      "Epoch: 4\tFidelity = 0.511673\tKL_Divergence = 2.234791\n",
      "Epoch: 5\tFidelity = 0.513317\tKL_Divergence = 2.160980\n",
      "Epoch: 6\tFidelity = 0.511805\tKL_Divergence = 2.228509\n",
      "Epoch: 7\tFidelity = 0.512276\tKL_Divergence = 2.206581\n",
      "Epoch: 8\tFidelity = 0.511374\tKL_Divergence = 2.249295\n",
      "Epoch: 9\tFidelity = 0.512680\tKL_Divergence = 2.188431\n",
      "Epoch: 10\tFidelity = 0.512284\tKL_Divergence = 2.206203\n",
      "Epoch: 11\tFidelity = 0.512562\tKL_Divergence = 2.193680\n",
      "Epoch: 12\tFidelity = 0.513295\tKL_Divergence = 2.161898\n",
      "Epoch: 13\tFidelity = 0.511553\tKL_Divergence = 2.240555\n",
      "Epoch: 14\tFidelity = 0.513500\tKL_Divergence = 2.153343\n",
      "Epoch: 15\tFidelity = 0.511385\tKL_Divergence = 2.248771\n",
      "Epoch: 16\tFidelity = 0.512397\tKL_Divergence = 2.201111\n",
      "Epoch: 17\tFidelity = 0.512796\tKL_Divergence = 2.183370\n",
      "Epoch: 18\tFidelity = 0.512690\tKL_Divergence = 2.188039\n",
      "Epoch: 19\tFidelity = 0.512107\tKL_Divergence = 2.214374\n",
      "Epoch: 20\tFidelity = 0.512037\tKL_Divergence = 2.217623\n",
      "Epoch: 21\tFidelity = 0.511033\tKL_Divergence = 2.266376\n",
      "Epoch: 22\tFidelity = 0.512402\tKL_Divergence = 2.200911\n",
      "Epoch: 23\tFidelity = 0.512444\tKL_Divergence = 2.198989\n",
      "Epoch: 24\tFidelity = 0.512636\tKL_Divergence = 2.190437\n",
      "Epoch: 25\tFidelity = 0.511638\tKL_Divergence = 2.236483\n",
      "Epoch: 26\tFidelity = 0.512999\tKL_Divergence = 2.174546\n",
      "Epoch: 27\tFidelity = 0.511758\tKL_Divergence = 2.230728\n",
      "Epoch: 28\tFidelity = 0.512153\tKL_Divergence = 2.212240\n",
      "Epoch: 29\tFidelity = 0.513192\tKL_Divergence = 2.166298\n",
      "Epoch: 30\tFidelity = 0.512149\tKL_Divergence = 2.212430\n",
      "Epoch: 31\tFidelity = 0.514111\tKL_Divergence = 2.128530\n",
      "Epoch: 32\tFidelity = 0.512059\tKL_Divergence = 2.216613\n",
      "Epoch: 33\tFidelity = 0.512397\tKL_Divergence = 2.201091\n",
      "Epoch: 34\tFidelity = 0.513169\tKL_Divergence = 2.167252\n",
      "Epoch: 35\tFidelity = 0.512738\tKL_Divergence = 2.185915\n",
      "Epoch: 36\tFidelity = 0.512262\tKL_Divergence = 2.207261\n",
      "Epoch: 37\tFidelity = 0.511851\tKL_Divergence = 2.226336\n",
      "Epoch: 38\tFidelity = 0.513034\tKL_Divergence = 2.173027\n",
      "Epoch: 39\tFidelity = 0.511808\tKL_Divergence = 2.228382\n",
      "Epoch: 40\tFidelity = 0.512360\tKL_Divergence = 2.202785\n",
      "Epoch: 41\tFidelity = 0.511661\tKL_Divergence = 2.235342\n",
      "Epoch: 42\tFidelity = 0.512831\tKL_Divergence = 2.181828\n",
      "Epoch: 43\tFidelity = 0.511587\tKL_Divergence = 2.238902\n",
      "Epoch: 44\tFidelity = 0.512653\tKL_Divergence = 2.189658\n",
      "Epoch: 45\tFidelity = 0.512176\tKL_Divergence = 2.211151\n",
      "Epoch: 46\tFidelity = 0.513473\tKL_Divergence = 2.154446\n",
      "Epoch: 47\tFidelity = 0.511377\tKL_Divergence = 2.249166\n",
      "Epoch: 48\tFidelity = 0.512460\tKL_Divergence = 2.198225\n",
      "Epoch: 49\tFidelity = 0.512040\tKL_Divergence = 2.217440\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:52:53,379] Trial 171 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.512340\tKL_Divergence = 2.203639\n",
      "Total time elapsed during training: 30.311 s\n",
      "Trial 171 pruned. \n",
      "Epoch: 1\tFidelity = 0.512018\tKL_Divergence = 2.218450\n",
      "Epoch: 2\tFidelity = 0.510730\tKL_Divergence = 2.281902\n",
      "Epoch: 3\tFidelity = 0.511233\tKL_Divergence = 2.256254\n",
      "Epoch: 4\tFidelity = 0.513685\tKL_Divergence = 2.145691\n",
      "Epoch: 5\tFidelity = 0.511919\tKL_Divergence = 2.223064\n",
      "Epoch: 6\tFidelity = 0.511859\tKL_Divergence = 2.225881\n",
      "Epoch: 7\tFidelity = 0.512406\tKL_Divergence = 2.200536\n",
      "Epoch: 8\tFidelity = 0.511931\tKL_Divergence = 2.222557\n",
      "Epoch: 9\tFidelity = 0.511355\tKL_Divergence = 2.250243\n",
      "Epoch: 10\tFidelity = 0.512927\tKL_Divergence = 2.177545\n",
      "Epoch: 11\tFidelity = 0.513262\tKL_Divergence = 2.163236\n",
      "Epoch: 12\tFidelity = 0.511088\tKL_Divergence = 2.263340\n",
      "Epoch: 13\tFidelity = 0.512435\tKL_Divergence = 2.199047\n",
      "Epoch: 14\tFidelity = 0.511479\tKL_Divergence = 2.244031\n",
      "Epoch: 15\tFidelity = 0.511106\tKL_Divergence = 2.262556\n",
      "Epoch: 16\tFidelity = 0.513019\tKL_Divergence = 2.173677\n",
      "Epoch: 17\tFidelity = 0.511593\tKL_Divergence = 2.238683\n",
      "Epoch: 18\tFidelity = 0.514347\tKL_Divergence = 2.119225\n",
      "Epoch: 19\tFidelity = 0.513475\tKL_Divergence = 2.154367\n",
      "Epoch: 20\tFidelity = 0.513749\tKL_Divergence = 2.143127\n",
      "Epoch: 21\tFidelity = 0.512620\tKL_Divergence = 2.191143\n",
      "Epoch: 22\tFidelity = 0.510979\tKL_Divergence = 2.269081\n",
      "Epoch: 23\tFidelity = 0.510711\tKL_Divergence = 2.282950\n",
      "Epoch: 24\tFidelity = 0.510765\tKL_Divergence = 2.280137\n",
      "Epoch: 25\tFidelity = 0.512580\tKL_Divergence = 2.192908\n",
      "Epoch: 26\tFidelity = 0.512563\tKL_Divergence = 2.193671\n",
      "Epoch: 27\tFidelity = 0.513077\tKL_Divergence = 2.171199\n",
      "Epoch: 28\tFidelity = 0.512040\tKL_Divergence = 2.217496\n",
      "Epoch: 29\tFidelity = 0.510922\tKL_Divergence = 2.272078\n",
      "Epoch: 30\tFidelity = 0.510934\tKL_Divergence = 2.271329\n",
      "Epoch: 31\tFidelity = 0.513383\tKL_Divergence = 2.158176\n",
      "Epoch: 32\tFidelity = 0.511905\tKL_Divergence = 2.223821\n",
      "Epoch: 33\tFidelity = 0.515424\tKL_Divergence = 2.078610\n",
      "Epoch: 34\tFidelity = 0.511117\tKL_Divergence = 2.262139\n",
      "Epoch: 35\tFidelity = 0.513712\tKL_Divergence = 2.144657\n",
      "Epoch: 36\tFidelity = 0.511215\tKL_Divergence = 2.257233\n",
      "Epoch: 37\tFidelity = 0.512050\tKL_Divergence = 2.217055\n",
      "Epoch: 38\tFidelity = 0.510758\tKL_Divergence = 2.280515\n",
      "Epoch: 39\tFidelity = 0.512075\tKL_Divergence = 2.215808\n",
      "Epoch: 40\tFidelity = 0.513388\tKL_Divergence = 2.158076\n",
      "Epoch: 41\tFidelity = 0.511351\tKL_Divergence = 2.250495\n",
      "Epoch: 42\tFidelity = 0.512987\tKL_Divergence = 2.175077\n",
      "Epoch: 43\tFidelity = 0.511717\tKL_Divergence = 2.232715\n",
      "Epoch: 44\tFidelity = 0.511365\tKL_Divergence = 2.249797\n",
      "Epoch: 45\tFidelity = 0.509946\tKL_Divergence = 2.324372\n",
      "Epoch: 46\tFidelity = 0.512203\tKL_Divergence = 2.209973\n",
      "Epoch: 47\tFidelity = 0.509771\tKL_Divergence = 2.334316\n",
      "Epoch: 48\tFidelity = 0.514275\tKL_Divergence = 2.122068\n",
      "Epoch: 49\tFidelity = 0.513603\tKL_Divergence = 2.149121\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:53:36,087] Trial 172 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.512989\tKL_Divergence = 2.175015\n",
      "Total time elapsed during training: 42.554 s\n",
      "Trial 172 pruned. \n",
      "Epoch: 1\tFidelity = 0.511804\tKL_Divergence = 2.228618\n",
      "Epoch: 2\tFidelity = 0.512153\tKL_Divergence = 2.212309\n",
      "Epoch: 3\tFidelity = 0.511509\tKL_Divergence = 2.242785\n",
      "Epoch: 4\tFidelity = 0.512016\tKL_Divergence = 2.218630\n",
      "Epoch: 5\tFidelity = 0.512404\tKL_Divergence = 2.200836\n",
      "Epoch: 6\tFidelity = 0.511654\tKL_Divergence = 2.235786\n",
      "Epoch: 7\tFidelity = 0.512245\tKL_Divergence = 2.208060\n",
      "Epoch: 8\tFidelity = 0.512703\tKL_Divergence = 2.187509\n",
      "Epoch: 9\tFidelity = 0.512618\tKL_Divergence = 2.191272\n",
      "Epoch: 10\tFidelity = 0.512364\tKL_Divergence = 2.202687\n",
      "Epoch: 11\tFidelity = 0.512794\tKL_Divergence = 2.183538\n",
      "Epoch: 12\tFidelity = 0.512159\tKL_Divergence = 2.212040\n",
      "Epoch: 13\tFidelity = 0.511938\tKL_Divergence = 2.222302\n",
      "Epoch: 14\tFidelity = 0.512107\tKL_Divergence = 2.214437\n",
      "Epoch: 15\tFidelity = 0.511289\tKL_Divergence = 2.253565\n",
      "Epoch: 16\tFidelity = 0.511636\tKL_Divergence = 2.236636\n",
      "Epoch: 17\tFidelity = 0.512145\tKL_Divergence = 2.212688\n",
      "Epoch: 18\tFidelity = 0.511451\tKL_Divergence = 2.245597\n",
      "Epoch: 19\tFidelity = 0.512297\tKL_Divergence = 2.205686\n",
      "Epoch: 20\tFidelity = 0.511593\tKL_Divergence = 2.238708\n",
      "Epoch: 21\tFidelity = 0.512975\tKL_Divergence = 2.175626\n",
      "Epoch: 22\tFidelity = 0.511294\tKL_Divergence = 2.253343\n",
      "Epoch: 23\tFidelity = 0.512265\tKL_Divergence = 2.207144\n",
      "Epoch: 24\tFidelity = 0.512005\tKL_Divergence = 2.219147\n",
      "Epoch: 25\tFidelity = 0.511968\tKL_Divergence = 2.220904\n",
      "Epoch: 26\tFidelity = 0.512580\tKL_Divergence = 2.192975\n",
      "Epoch: 27\tFidelity = 0.511577\tKL_Divergence = 2.239462\n",
      "Epoch: 28\tFidelity = 0.511469\tKL_Divergence = 2.244740\n",
      "Epoch: 29\tFidelity = 0.512445\tKL_Divergence = 2.198983\n",
      "Epoch: 30\tFidelity = 0.512034\tKL_Divergence = 2.217794\n",
      "Epoch: 31\tFidelity = 0.511328\tKL_Divergence = 2.251635\n",
      "Epoch: 32\tFidelity = 0.512085\tKL_Divergence = 2.215430\n",
      "Epoch: 33\tFidelity = 0.511547\tKL_Divergence = 2.240912\n",
      "Epoch: 34\tFidelity = 0.512789\tKL_Divergence = 2.183716\n",
      "Epoch: 35\tFidelity = 0.511421\tKL_Divergence = 2.247075\n",
      "Epoch: 36\tFidelity = 0.511882\tKL_Divergence = 2.224915\n",
      "Epoch: 37\tFidelity = 0.512583\tKL_Divergence = 2.192823\n",
      "Epoch: 38\tFidelity = 0.510983\tKL_Divergence = 2.268965\n",
      "Epoch: 39\tFidelity = 0.512846\tKL_Divergence = 2.181223\n",
      "Epoch: 40\tFidelity = 0.511362\tKL_Divergence = 2.249972\n",
      "Epoch: 41\tFidelity = 0.512384\tKL_Divergence = 2.201731\n",
      "Epoch: 42\tFidelity = 0.511796\tKL_Divergence = 2.228992\n",
      "Epoch: 43\tFidelity = 0.512076\tKL_Divergence = 2.215845\n",
      "Epoch: 44\tFidelity = 0.511843\tKL_Divergence = 2.226757\n",
      "Epoch: 45\tFidelity = 0.511847\tKL_Divergence = 2.226544\n",
      "Epoch: 46\tFidelity = 0.511360\tKL_Divergence = 2.250044\n",
      "Epoch: 47\tFidelity = 0.511483\tKL_Divergence = 2.244021\n",
      "Epoch: 48\tFidelity = 0.511601\tKL_Divergence = 2.238319\n",
      "Epoch: 49\tFidelity = 0.512178\tKL_Divergence = 2.211120\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:54:07,067] Trial 173 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.511460\tKL_Divergence = 2.245151\n",
      "Total time elapsed during training: 30.826 s\n",
      "Trial 173 pruned. \n",
      "Epoch: 1\tFidelity = 0.512352\tKL_Divergence = 2.203187\n",
      "Epoch: 2\tFidelity = 0.511876\tKL_Divergence = 2.225214\n",
      "Epoch: 3\tFidelity = 0.513096\tKL_Divergence = 2.170429\n",
      "Epoch: 4\tFidelity = 0.511174\tKL_Divergence = 2.259326\n",
      "Epoch: 5\tFidelity = 0.511230\tKL_Divergence = 2.256499\n",
      "Epoch: 6\tFidelity = 0.512995\tKL_Divergence = 2.174789\n",
      "Epoch: 7\tFidelity = 0.512036\tKL_Divergence = 2.217736\n",
      "Epoch: 8\tFidelity = 0.511352\tKL_Divergence = 2.250471\n",
      "Epoch: 9\tFidelity = 0.512000\tKL_Divergence = 2.219418\n",
      "Epoch: 10\tFidelity = 0.511192\tKL_Divergence = 2.258408\n",
      "Epoch: 11\tFidelity = 0.512021\tKL_Divergence = 2.218433\n",
      "Epoch: 12\tFidelity = 0.512105\tKL_Divergence = 2.214550\n",
      "Epoch: 13\tFidelity = 0.513404\tKL_Divergence = 2.157395\n",
      "Epoch: 14\tFidelity = 0.512153\tKL_Divergence = 2.212323\n",
      "Epoch: 15\tFidelity = 0.511805\tKL_Divergence = 2.228572\n",
      "Epoch: 16\tFidelity = 0.512493\tKL_Divergence = 2.196849\n",
      "Epoch: 17\tFidelity = 0.511013\tKL_Divergence = 2.267431\n",
      "Epoch: 18\tFidelity = 0.512258\tKL_Divergence = 2.207490\n",
      "Epoch: 19\tFidelity = 0.512702\tKL_Divergence = 2.187549\n",
      "Epoch: 20\tFidelity = 0.511426\tKL_Divergence = 2.246823\n",
      "Epoch: 21\tFidelity = 0.512206\tKL_Divergence = 2.209863\n",
      "Epoch: 22\tFidelity = 0.511281\tKL_Divergence = 2.254012\n",
      "Epoch: 23\tFidelity = 0.512842\tKL_Divergence = 2.181437\n",
      "Epoch: 24\tFidelity = 0.512235\tKL_Divergence = 2.208556\n",
      "Epoch: 25\tFidelity = 0.511528\tKL_Divergence = 2.241890\n",
      "Epoch: 26\tFidelity = 0.511324\tKL_Divergence = 2.251862\n",
      "Epoch: 27\tFidelity = 0.511850\tKL_Divergence = 2.226469\n",
      "Epoch: 28\tFidelity = 0.511886\tKL_Divergence = 2.224748\n",
      "Epoch: 29\tFidelity = 0.511636\tKL_Divergence = 2.236658\n",
      "Epoch: 30\tFidelity = 0.510772\tKL_Divergence = 2.279818\n",
      "Epoch: 31\tFidelity = 0.512342\tKL_Divergence = 2.203689\n",
      "Epoch: 32\tFidelity = 0.512607\tKL_Divergence = 2.191780\n",
      "Epoch: 33\tFidelity = 0.511364\tKL_Divergence = 2.249876\n",
      "Epoch: 34\tFidelity = 0.512341\tKL_Divergence = 2.203720\n",
      "Epoch: 35\tFidelity = 0.511152\tKL_Divergence = 2.260414\n",
      "Epoch: 36\tFidelity = 0.512920\tKL_Divergence = 2.178039\n",
      "Epoch: 37\tFidelity = 0.510887\tKL_Divergence = 2.273906\n",
      "Epoch: 38\tFidelity = 0.511470\tKL_Divergence = 2.244723\n",
      "Epoch: 39\tFidelity = 0.511374\tKL_Divergence = 2.249416\n",
      "Epoch: 40\tFidelity = 0.511234\tKL_Divergence = 2.256351\n",
      "Epoch: 41\tFidelity = 0.511606\tKL_Divergence = 2.238133\n",
      "Epoch: 42\tFidelity = 0.511714\tKL_Divergence = 2.232937\n",
      "Epoch: 43\tFidelity = 0.511343\tKL_Divergence = 2.250937\n",
      "Epoch: 44\tFidelity = 0.512118\tKL_Divergence = 2.213951\n",
      "Epoch: 45\tFidelity = 0.512291\tKL_Divergence = 2.205989\n",
      "Epoch: 46\tFidelity = 0.512064\tKL_Divergence = 2.216423\n",
      "Epoch: 47\tFidelity = 0.511811\tKL_Divergence = 2.228330\n",
      "Epoch: 48\tFidelity = 0.512483\tKL_Divergence = 2.197298\n",
      "Epoch: 49\tFidelity = 0.512695\tKL_Divergence = 2.187886\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:54:37,679] Trial 174 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.512820\tKL_Divergence = 2.182401\n",
      "Total time elapsed during training: 30.469 s\n",
      "Trial 174 pruned. \n",
      "Epoch: 1\tFidelity = 0.511338\tKL_Divergence = 2.251171\n",
      "Epoch: 2\tFidelity = 0.512329\tKL_Divergence = 2.204286\n",
      "Epoch: 3\tFidelity = 0.511392\tKL_Divergence = 2.248537\n",
      "Epoch: 4\tFidelity = 0.512572\tKL_Divergence = 2.193355\n",
      "Epoch: 5\tFidelity = 0.511244\tKL_Divergence = 2.255861\n",
      "Epoch: 6\tFidelity = 0.512761\tKL_Divergence = 2.184963\n",
      "Epoch: 7\tFidelity = 0.511232\tKL_Divergence = 2.256431\n",
      "Epoch: 8\tFidelity = 0.511589\tKL_Divergence = 2.238917\n",
      "Epoch: 9\tFidelity = 0.512433\tKL_Divergence = 2.199556\n",
      "Epoch: 10\tFidelity = 0.511536\tKL_Divergence = 2.241498\n",
      "Epoch: 11\tFidelity = 0.511622\tKL_Divergence = 2.237344\n",
      "Epoch: 12\tFidelity = 0.512522\tKL_Divergence = 2.195590\n",
      "Epoch: 13\tFidelity = 0.510860\tKL_Divergence = 2.275254\n",
      "Epoch: 14\tFidelity = 0.511657\tKL_Divergence = 2.235645\n",
      "Epoch: 15\tFidelity = 0.511312\tKL_Divergence = 2.252475\n",
      "Epoch: 16\tFidelity = 0.511968\tKL_Divergence = 2.220929\n",
      "Epoch: 17\tFidelity = 0.511594\tKL_Divergence = 2.238670\n",
      "Epoch: 18\tFidelity = 0.511949\tKL_Divergence = 2.221811\n",
      "Epoch: 19\tFidelity = 0.512840\tKL_Divergence = 2.181508\n",
      "Epoch: 20\tFidelity = 0.513113\tKL_Divergence = 2.169705\n",
      "Epoch: 21\tFidelity = 0.511679\tKL_Divergence = 2.234575\n",
      "Epoch: 22\tFidelity = 0.511937\tKL_Divergence = 2.222355\n",
      "Epoch: 23\tFidelity = 0.512912\tKL_Divergence = 2.178361\n",
      "Epoch: 24\tFidelity = 0.511494\tKL_Divergence = 2.243527\n",
      "Epoch: 25\tFidelity = 0.512243\tKL_Divergence = 2.208189\n",
      "Epoch: 26\tFidelity = 0.511897\tKL_Divergence = 2.224223\n",
      "Epoch: 27\tFidelity = 0.512032\tKL_Divergence = 2.217913\n",
      "Epoch: 28\tFidelity = 0.512737\tKL_Divergence = 2.186045\n",
      "Epoch: 29\tFidelity = 0.511478\tKL_Divergence = 2.244298\n",
      "Epoch: 30\tFidelity = 0.512009\tKL_Divergence = 2.218989\n",
      "Epoch: 31\tFidelity = 0.511155\tKL_Divergence = 2.260254\n",
      "Epoch: 32\tFidelity = 0.511787\tKL_Divergence = 2.229406\n",
      "Epoch: 33\tFidelity = 0.511644\tKL_Divergence = 2.236243\n",
      "Epoch: 34\tFidelity = 0.511788\tKL_Divergence = 2.229398\n",
      "Epoch: 35\tFidelity = 0.511540\tKL_Divergence = 2.241296\n",
      "Epoch: 36\tFidelity = 0.513165\tKL_Divergence = 2.167492\n",
      "Epoch: 37\tFidelity = 0.511287\tKL_Divergence = 2.253710\n",
      "Epoch: 38\tFidelity = 0.512167\tKL_Divergence = 2.211647\n",
      "Epoch: 39\tFidelity = 0.512267\tKL_Divergence = 2.207055\n",
      "Epoch: 40\tFidelity = 0.512739\tKL_Divergence = 2.185943\n",
      "Epoch: 41\tFidelity = 0.512068\tKL_Divergence = 2.216212\n",
      "Epoch: 42\tFidelity = 0.511302\tKL_Divergence = 2.252921\n",
      "Epoch: 43\tFidelity = 0.512777\tKL_Divergence = 2.184249\n",
      "Epoch: 44\tFidelity = 0.511613\tKL_Divergence = 2.237730\n",
      "Epoch: 45\tFidelity = 0.512016\tKL_Divergence = 2.218666\n",
      "Epoch: 46\tFidelity = 0.512133\tKL_Divergence = 2.213237\n",
      "Epoch: 47\tFidelity = 0.512265\tKL_Divergence = 2.207159\n",
      "Epoch: 48\tFidelity = 0.510631\tKL_Divergence = 2.287156\n",
      "Epoch: 49\tFidelity = 0.512128\tKL_Divergence = 2.213442\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:55:08,773] Trial 175 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.511120\tKL_Divergence = 2.262005\n",
      "Total time elapsed during training: 30.947 s\n",
      "Trial 175 pruned. \n",
      "Epoch: 1\tFidelity = 0.510650\tKL_Divergence = 2.286110\n",
      "Epoch: 2\tFidelity = 0.511789\tKL_Divergence = 2.229199\n",
      "Epoch: 3\tFidelity = 0.513054\tKL_Divergence = 2.172011\n",
      "Epoch: 4\tFidelity = 0.512367\tKL_Divergence = 2.202304\n",
      "Epoch: 5\tFidelity = 0.510920\tKL_Divergence = 2.272103\n",
      "Epoch: 6\tFidelity = 0.511824\tKL_Divergence = 2.227576\n",
      "Epoch: 7\tFidelity = 0.510804\tKL_Divergence = 2.278062\n",
      "Epoch: 8\tFidelity = 0.511766\tKL_Divergence = 2.230349\n",
      "Epoch: 9\tFidelity = 0.511076\tKL_Divergence = 2.264123\n",
      "Epoch: 10\tFidelity = 0.512572\tKL_Divergence = 2.193208\n",
      "Epoch: 11\tFidelity = 0.512304\tKL_Divergence = 2.205253\n",
      "Epoch: 12\tFidelity = 0.513969\tKL_Divergence = 2.134165\n",
      "Epoch: 13\tFidelity = 0.512213\tKL_Divergence = 2.209425\n",
      "Epoch: 14\tFidelity = 0.511912\tKL_Divergence = 2.223420\n",
      "Epoch: 15\tFidelity = 0.512115\tKL_Divergence = 2.213983\n",
      "Epoch: 16\tFidelity = 0.510684\tKL_Divergence = 2.284310\n",
      "Epoch: 17\tFidelity = 0.512832\tKL_Divergence = 2.181786\n",
      "Epoch: 18\tFidelity = 0.512935\tKL_Divergence = 2.177299\n",
      "Epoch: 19\tFidelity = 0.513463\tKL_Divergence = 2.154887\n",
      "Epoch: 20\tFidelity = 0.512918\tKL_Divergence = 2.178012\n",
      "Epoch: 21\tFidelity = 0.513257\tKL_Divergence = 2.163443\n",
      "Epoch: 22\tFidelity = 0.511356\tKL_Divergence = 2.250161\n",
      "Epoch: 23\tFidelity = 0.512576\tKL_Divergence = 2.193037\n",
      "Epoch: 24\tFidelity = 0.510924\tKL_Divergence = 2.271884\n",
      "Epoch: 25\tFidelity = 0.513282\tKL_Divergence = 2.162494\n",
      "Epoch: 26\tFidelity = 0.511495\tKL_Divergence = 2.243413\n",
      "Epoch: 27\tFidelity = 0.513220\tKL_Divergence = 2.165098\n",
      "Epoch: 28\tFidelity = 0.513412\tKL_Divergence = 2.157014\n",
      "Epoch: 29\tFidelity = 0.512003\tKL_Divergence = 2.219171\n",
      "Epoch: 30\tFidelity = 0.512117\tKL_Divergence = 2.213892\n",
      "Epoch: 31\tFidelity = 0.511381\tKL_Divergence = 2.248955\n",
      "Epoch: 32\tFidelity = 0.512073\tKL_Divergence = 2.215943\n",
      "Epoch: 33\tFidelity = 0.514021\tKL_Divergence = 2.132100\n",
      "Epoch: 34\tFidelity = 0.512300\tKL_Divergence = 2.205503\n",
      "Epoch: 35\tFidelity = 0.513604\tKL_Divergence = 2.148943\n",
      "Epoch: 36\tFidelity = 0.512697\tKL_Divergence = 2.187661\n",
      "Epoch: 37\tFidelity = 0.514206\tKL_Divergence = 2.124743\n",
      "Epoch: 38\tFidelity = 0.513358\tKL_Divergence = 2.159246\n",
      "Epoch: 39\tFidelity = 0.511371\tKL_Divergence = 2.249482\n",
      "Epoch: 40\tFidelity = 0.511667\tKL_Divergence = 2.235104\n",
      "Epoch: 41\tFidelity = 0.510248\tKL_Divergence = 2.307636\n",
      "Epoch: 42\tFidelity = 0.510962\tKL_Divergence = 2.269960\n",
      "Epoch: 43\tFidelity = 0.513743\tKL_Divergence = 2.143333\n",
      "Epoch: 44\tFidelity = 0.512233\tKL_Divergence = 2.208542\n",
      "Epoch: 45\tFidelity = 0.514280\tKL_Divergence = 2.121836\n",
      "Epoch: 46\tFidelity = 0.512633\tKL_Divergence = 2.190432\n",
      "Epoch: 47\tFidelity = 0.511916\tKL_Divergence = 2.223212\n",
      "Epoch: 48\tFidelity = 0.511128\tKL_Divergence = 2.261548\n",
      "Epoch: 49\tFidelity = 0.512009\tKL_Divergence = 2.218897\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:56:26,459] Trial 176 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.512180\tKL_Divergence = 2.210979\n",
      "Total time elapsed during training: 77.538 s\n",
      "Trial 176 pruned. \n",
      "Epoch: 1\tFidelity = 0.511509\tKL_Divergence = 2.242688\n",
      "Epoch: 2\tFidelity = 0.510953\tKL_Divergence = 2.270379\n",
      "Epoch: 3\tFidelity = 0.512380\tKL_Divergence = 2.201861\n",
      "Epoch: 4\tFidelity = 0.511361\tKL_Divergence = 2.249926\n",
      "Epoch: 5\tFidelity = 0.513036\tKL_Divergence = 2.172854\n",
      "Epoch: 6\tFidelity = 0.511283\tKL_Divergence = 2.253617\n",
      "Epoch: 7\tFidelity = 0.511805\tKL_Divergence = 2.228449\n",
      "Epoch: 8\tFidelity = 0.511399\tKL_Divergence = 2.248102\n",
      "Epoch: 9\tFidelity = 0.511503\tKL_Divergence = 2.243014\n",
      "Epoch: 10\tFidelity = 0.511805\tKL_Divergence = 2.228487\n",
      "Epoch: 11\tFidelity = 0.512963\tKL_Divergence = 2.176130\n",
      "Epoch: 12\tFidelity = 0.512930\tKL_Divergence = 2.177534\n",
      "Epoch: 13\tFidelity = 0.511135\tKL_Divergence = 2.261210\n",
      "Epoch: 14\tFidelity = 0.511106\tKL_Divergence = 2.262692\n",
      "Epoch: 15\tFidelity = 0.511212\tKL_Divergence = 2.257357\n",
      "Epoch: 16\tFidelity = 0.512061\tKL_Divergence = 2.216555\n",
      "Epoch: 17\tFidelity = 0.511241\tKL_Divergence = 2.255960\n",
      "Epoch: 18\tFidelity = 0.511464\tKL_Divergence = 2.244962\n",
      "Epoch: 19\tFidelity = 0.510443\tKL_Divergence = 2.297160\n",
      "Epoch: 20\tFidelity = 0.511723\tKL_Divergence = 2.232470\n",
      "Epoch: 21\tFidelity = 0.512981\tKL_Divergence = 2.175339\n",
      "Epoch: 22\tFidelity = 0.514254\tKL_Divergence = 2.122923\n",
      "Epoch: 23\tFidelity = 0.511951\tKL_Divergence = 2.221653\n",
      "Epoch: 24\tFidelity = 0.510868\tKL_Divergence = 2.274791\n",
      "Epoch: 25\tFidelity = 0.513185\tKL_Divergence = 2.166610\n",
      "Epoch: 26\tFidelity = 0.511324\tKL_Divergence = 2.251814\n",
      "Epoch: 27\tFidelity = 0.511572\tKL_Divergence = 2.239683\n",
      "Epoch: 28\tFidelity = 0.512683\tKL_Divergence = 2.188381\n",
      "Epoch: 29\tFidelity = 0.514305\tKL_Divergence = 2.120886\n",
      "Epoch: 30\tFidelity = 0.510968\tKL_Divergence = 2.269679\n",
      "Epoch: 31\tFidelity = 0.510962\tKL_Divergence = 2.270001\n",
      "Epoch: 32\tFidelity = 0.511996\tKL_Divergence = 2.219547\n",
      "Epoch: 33\tFidelity = 0.512217\tKL_Divergence = 2.209349\n",
      "Epoch: 34\tFidelity = 0.510858\tKL_Divergence = 2.275284\n",
      "Epoch: 35\tFidelity = 0.511218\tKL_Divergence = 2.257032\n",
      "Epoch: 36\tFidelity = 0.513012\tKL_Divergence = 2.173992\n",
      "Epoch: 37\tFidelity = 0.511993\tKL_Divergence = 2.219688\n",
      "Epoch: 38\tFidelity = 0.511990\tKL_Divergence = 2.219832\n",
      "Epoch: 39\tFidelity = 0.513240\tKL_Divergence = 2.164260\n",
      "Epoch: 40\tFidelity = 0.512361\tKL_Divergence = 2.202767\n",
      "Epoch: 41\tFidelity = 0.511373\tKL_Divergence = 2.249413\n",
      "Epoch: 42\tFidelity = 0.510651\tKL_Divergence = 2.286077\n",
      "Epoch: 43\tFidelity = 0.511672\tKL_Divergence = 2.234844\n",
      "Epoch: 44\tFidelity = 0.513630\tKL_Divergence = 2.147993\n",
      "Epoch: 45\tFidelity = 0.511356\tKL_Divergence = 2.250253\n",
      "Epoch: 46\tFidelity = 0.511296\tKL_Divergence = 2.253212\n",
      "Epoch: 47\tFidelity = 0.512795\tKL_Divergence = 2.183446\n",
      "Epoch: 48\tFidelity = 0.512584\tKL_Divergence = 2.192759\n",
      "Epoch: 49\tFidelity = 0.511027\tKL_Divergence = 2.266720\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:57:22,742] Trial 177 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.511660\tKL_Divergence = 2.235456\n",
      "Total time elapsed during training: 56.132 s\n",
      "Trial 177 pruned. \n",
      "Epoch: 1\tFidelity = 0.511518\tKL_Divergence = 2.242275\n",
      "Epoch: 2\tFidelity = 0.511816\tKL_Divergence = 2.227936\n",
      "Epoch: 3\tFidelity = 0.511892\tKL_Divergence = 2.224361\n",
      "Epoch: 4\tFidelity = 0.510388\tKL_Divergence = 2.299798\n",
      "Epoch: 5\tFidelity = 0.510528\tKL_Divergence = 2.292315\n",
      "Epoch: 6\tFidelity = 0.511551\tKL_Divergence = 2.240597\n",
      "Epoch: 7\tFidelity = 0.512662\tKL_Divergence = 2.189288\n",
      "Epoch: 8\tFidelity = 0.512142\tKL_Divergence = 2.212765\n",
      "Epoch: 9\tFidelity = 0.512147\tKL_Divergence = 2.212502\n",
      "Epoch: 10\tFidelity = 0.512315\tKL_Divergence = 2.204741\n",
      "Epoch: 11\tFidelity = 0.511257\tKL_Divergence = 2.255034\n",
      "Epoch: 12\tFidelity = 0.513349\tKL_Divergence = 2.159561\n",
      "Epoch: 13\tFidelity = 0.512584\tKL_Divergence = 2.192676\n",
      "Epoch: 14\tFidelity = 0.511831\tKL_Divergence = 2.227271\n",
      "Epoch: 15\tFidelity = 0.509945\tKL_Divergence = 2.324442\n",
      "Epoch: 16\tFidelity = 0.511660\tKL_Divergence = 2.235429\n",
      "Epoch: 17\tFidelity = 0.512011\tKL_Divergence = 2.218862\n",
      "Epoch: 18\tFidelity = 0.512782\tKL_Divergence = 2.184048\n",
      "Epoch: 19\tFidelity = 0.512984\tKL_Divergence = 2.175295\n",
      "Epoch: 20\tFidelity = 0.510982\tKL_Divergence = 2.269013\n",
      "Epoch: 21\tFidelity = 0.511120\tKL_Divergence = 2.261975\n",
      "Epoch: 22\tFidelity = 0.509515\tKL_Divergence = 2.349145\n",
      "Epoch: 23\tFidelity = 0.512016\tKL_Divergence = 2.218531\n",
      "Epoch: 24\tFidelity = 0.512034\tKL_Divergence = 2.217785\n",
      "Epoch: 25\tFidelity = 0.511294\tKL_Divergence = 2.253353\n",
      "Epoch: 26\tFidelity = 0.512098\tKL_Divergence = 2.214877\n",
      "Epoch: 27\tFidelity = 0.509949\tKL_Divergence = 2.324156\n",
      "Epoch: 28\tFidelity = 0.511238\tKL_Divergence = 2.255858\n",
      "Epoch: 29\tFidelity = 0.511072\tKL_Divergence = 2.263940\n",
      "Epoch: 30\tFidelity = 0.512850\tKL_Divergence = 2.180945\n",
      "Epoch: 31\tFidelity = 0.512305\tKL_Divergence = 2.205217\n",
      "Epoch: 32\tFidelity = 0.513187\tKL_Divergence = 2.166476\n",
      "Epoch: 33\tFidelity = 0.512524\tKL_Divergence = 2.195344\n",
      "Epoch: 34\tFidelity = 0.512066\tKL_Divergence = 2.216251\n",
      "Epoch: 35\tFidelity = 0.512151\tKL_Divergence = 2.212401\n",
      "Epoch: 36\tFidelity = 0.510038\tKL_Divergence = 2.319282\n",
      "Epoch: 37\tFidelity = 0.511914\tKL_Divergence = 2.223447\n",
      "Epoch: 38\tFidelity = 0.511382\tKL_Divergence = 2.249010\n",
      "Epoch: 39\tFidelity = 0.512106\tKL_Divergence = 2.214434\n",
      "Epoch: 40\tFidelity = 0.511866\tKL_Divergence = 2.225658\n",
      "Epoch: 41\tFidelity = 0.511379\tKL_Divergence = 2.249138\n",
      "Epoch: 42\tFidelity = 0.512399\tKL_Divergence = 2.201044\n",
      "Epoch: 43\tFidelity = 0.511596\tKL_Divergence = 2.238522\n",
      "Epoch: 44\tFidelity = 0.510369\tKL_Divergence = 2.301089\n",
      "Epoch: 45\tFidelity = 0.511053\tKL_Divergence = 2.265393\n",
      "Epoch: 46\tFidelity = 0.511188\tKL_Divergence = 2.258599\n",
      "Epoch: 47\tFidelity = 0.512152\tKL_Divergence = 2.212308\n",
      "Epoch: 48\tFidelity = 0.510990\tKL_Divergence = 2.268509\n",
      "Epoch: 49\tFidelity = 0.512831\tKL_Divergence = 2.181789\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:57:59,262] Trial 178 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.510885\tKL_Divergence = 2.273607\n",
      "Total time elapsed during training: 36.371 s\n",
      "Trial 178 pruned. \n",
      "Epoch: 1\tFidelity = 0.510748\tKL_Divergence = 2.280801\n",
      "Epoch: 2\tFidelity = 0.511360\tKL_Divergence = 2.249936\n",
      "Epoch: 3\tFidelity = 0.511248\tKL_Divergence = 2.255494\n",
      "Epoch: 4\tFidelity = 0.511208\tKL_Divergence = 2.257544\n",
      "Epoch: 5\tFidelity = 0.510677\tKL_Divergence = 2.284684\n",
      "Epoch: 6\tFidelity = 0.512291\tKL_Divergence = 2.205955\n",
      "Epoch: 7\tFidelity = 0.512506\tKL_Divergence = 2.196234\n",
      "Epoch: 8\tFidelity = 0.511733\tKL_Divergence = 2.231949\n",
      "Epoch: 9\tFidelity = 0.512444\tKL_Divergence = 2.199000\n",
      "Epoch: 10\tFidelity = 0.512981\tKL_Divergence = 2.175352\n",
      "Epoch: 11\tFidelity = 0.511316\tKL_Divergence = 2.252210\n",
      "Epoch: 12\tFidelity = 0.512302\tKL_Divergence = 2.205424\n",
      "Epoch: 13\tFidelity = 0.512172\tKL_Divergence = 2.211389\n",
      "Epoch: 14\tFidelity = 0.511633\tKL_Divergence = 2.236741\n",
      "Epoch: 15\tFidelity = 0.512670\tKL_Divergence = 2.188954\n",
      "Epoch: 16\tFidelity = 0.511647\tKL_Divergence = 2.236059\n",
      "Epoch: 17\tFidelity = 0.512460\tKL_Divergence = 2.198285\n",
      "Epoch: 18\tFidelity = 0.512295\tKL_Divergence = 2.205737\n",
      "Epoch: 19\tFidelity = 0.511700\tKL_Divergence = 2.233540\n",
      "Epoch: 20\tFidelity = 0.512297\tKL_Divergence = 2.205636\n",
      "Epoch: 21\tFidelity = 0.510600\tKL_Divergence = 2.288745\n",
      "Epoch: 22\tFidelity = 0.512477\tKL_Divergence = 2.197518\n",
      "Epoch: 23\tFidelity = 0.512716\tKL_Divergence = 2.186875\n",
      "Epoch: 24\tFidelity = 0.510427\tKL_Divergence = 2.297967\n",
      "Epoch: 25\tFidelity = 0.512063\tKL_Divergence = 2.216421\n",
      "Epoch: 26\tFidelity = 0.512391\tKL_Divergence = 2.201396\n",
      "Epoch: 27\tFidelity = 0.512280\tKL_Divergence = 2.206424\n",
      "Epoch: 28\tFidelity = 0.512149\tKL_Divergence = 2.212463\n",
      "Epoch: 29\tFidelity = 0.511388\tKL_Divergence = 2.248654\n",
      "Epoch: 30\tFidelity = 0.512402\tKL_Divergence = 2.200935\n",
      "Epoch: 31\tFidelity = 0.511464\tKL_Divergence = 2.244917\n",
      "Epoch: 32\tFidelity = 0.512478\tKL_Divergence = 2.197465\n",
      "Epoch: 33\tFidelity = 0.511751\tKL_Divergence = 2.231102\n",
      "Epoch: 34\tFidelity = 0.511907\tKL_Divergence = 2.223725\n",
      "Epoch: 35\tFidelity = 0.512828\tKL_Divergence = 2.182003\n",
      "Epoch: 36\tFidelity = 0.511349\tKL_Divergence = 2.250582\n",
      "Epoch: 37\tFidelity = 0.511032\tKL_Divergence = 2.266469\n",
      "Epoch: 38\tFidelity = 0.512449\tKL_Divergence = 2.198789\n",
      "Epoch: 39\tFidelity = 0.511559\tKL_Divergence = 2.240365\n",
      "Epoch: 40\tFidelity = 0.511760\tKL_Divergence = 2.230709\n",
      "Epoch: 41\tFidelity = 0.512056\tKL_Divergence = 2.216766\n",
      "Epoch: 42\tFidelity = 0.511509\tKL_Divergence = 2.242779\n",
      "Epoch: 43\tFidelity = 0.511223\tKL_Divergence = 2.256842\n",
      "Epoch: 44\tFidelity = 0.511505\tKL_Divergence = 2.242968\n",
      "Epoch: 45\tFidelity = 0.511480\tKL_Divergence = 2.244176\n",
      "Epoch: 46\tFidelity = 0.511879\tKL_Divergence = 2.225036\n",
      "Epoch: 47\tFidelity = 0.512180\tKL_Divergence = 2.211035\n",
      "Epoch: 48\tFidelity = 0.510523\tKL_Divergence = 2.292849\n",
      "Epoch: 49\tFidelity = 0.511834\tKL_Divergence = 2.227167\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:58:42,415] Trial 179 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.511878\tKL_Divergence = 2.225120\n",
      "Total time elapsed during training: 43.005 s\n",
      "Trial 179 pruned. \n",
      "Epoch: 1\tFidelity = 0.510497\tKL_Divergence = 2.294272\n",
      "Epoch: 2\tFidelity = 0.511694\tKL_Divergence = 2.233826\n",
      "Epoch: 3\tFidelity = 0.510594\tKL_Divergence = 2.289083\n",
      "Epoch: 4\tFidelity = 0.511852\tKL_Divergence = 2.226328\n",
      "Epoch: 5\tFidelity = 0.511475\tKL_Divergence = 2.244430\n",
      "Epoch: 6\tFidelity = 0.513201\tKL_Divergence = 2.165959\n",
      "Epoch: 7\tFidelity = 0.513047\tKL_Divergence = 2.172497\n",
      "Epoch: 8\tFidelity = 0.512926\tKL_Divergence = 2.177724\n",
      "Epoch: 9\tFidelity = 0.513483\tKL_Divergence = 2.154106\n",
      "Epoch: 10\tFidelity = 0.511479\tKL_Divergence = 2.244239\n",
      "Epoch: 11\tFidelity = 0.511317\tKL_Divergence = 2.252189\n",
      "Epoch: 12\tFidelity = 0.512984\tKL_Divergence = 2.175257\n",
      "Epoch: 13\tFidelity = 0.511374\tKL_Divergence = 2.249385\n",
      "Epoch: 14\tFidelity = 0.510964\tKL_Divergence = 2.269904\n",
      "Epoch: 15\tFidelity = 0.511899\tKL_Divergence = 2.224105\n",
      "Epoch: 16\tFidelity = 0.510941\tKL_Divergence = 2.271089\n",
      "Epoch: 17\tFidelity = 0.513806\tKL_Divergence = 2.140850\n",
      "Epoch: 18\tFidelity = 0.511547\tKL_Divergence = 2.240924\n",
      "Epoch: 19\tFidelity = 0.513526\tKL_Divergence = 2.152330\n",
      "Epoch: 20\tFidelity = 0.513680\tKL_Divergence = 2.145976\n",
      "Epoch: 21\tFidelity = 0.510275\tKL_Divergence = 2.306197\n",
      "Epoch: 22\tFidelity = 0.511862\tKL_Divergence = 2.225833\n",
      "Epoch: 23\tFidelity = 0.512219\tKL_Divergence = 2.209264\n",
      "Epoch: 24\tFidelity = 0.512010\tKL_Divergence = 2.218916\n",
      "Epoch: 25\tFidelity = 0.513062\tKL_Divergence = 2.171871\n",
      "Epoch: 26\tFidelity = 0.511980\tKL_Divergence = 2.220323\n",
      "Epoch: 27\tFidelity = 0.511948\tKL_Divergence = 2.221838\n",
      "Epoch: 28\tFidelity = 0.510601\tKL_Divergence = 2.288709\n",
      "Epoch: 29\tFidelity = 0.510986\tKL_Divergence = 2.268778\n",
      "Epoch: 30\tFidelity = 0.511582\tKL_Divergence = 2.239189\n",
      "Epoch: 31\tFidelity = 0.512623\tKL_Divergence = 2.191023\n",
      "Epoch: 32\tFidelity = 0.510674\tKL_Divergence = 2.284846\n",
      "Epoch: 33\tFidelity = 0.510919\tKL_Divergence = 2.272175\n",
      "Epoch: 34\tFidelity = 0.512016\tKL_Divergence = 2.218603\n",
      "Epoch: 35\tFidelity = 0.510907\tKL_Divergence = 2.272777\n",
      "Epoch: 36\tFidelity = 0.511968\tKL_Divergence = 2.220855\n",
      "Epoch: 37\tFidelity = 0.511058\tKL_Divergence = 2.265131\n",
      "Epoch: 38\tFidelity = 0.511310\tKL_Divergence = 2.252493\n",
      "Epoch: 39\tFidelity = 0.510481\tKL_Divergence = 2.295053\n",
      "Epoch: 40\tFidelity = 0.509915\tKL_Divergence = 2.326095\n",
      "Epoch: 41\tFidelity = 0.513300\tKL_Divergence = 2.161754\n",
      "Epoch: 42\tFidelity = 0.512065\tKL_Divergence = 2.216327\n",
      "Epoch: 43\tFidelity = 0.511405\tKL_Divergence = 2.247816\n",
      "Epoch: 44\tFidelity = 0.510786\tKL_Divergence = 2.279020\n",
      "Epoch: 45\tFidelity = 0.511225\tKL_Divergence = 2.256735\n",
      "Epoch: 46\tFidelity = 0.512494\tKL_Divergence = 2.196784\n",
      "Epoch: 47\tFidelity = 0.512770\tKL_Divergence = 2.184529\n",
      "Epoch: 48\tFidelity = 0.512209\tKL_Divergence = 2.209697\n",
      "Epoch: 49\tFidelity = 0.512316\tKL_Divergence = 2.204812\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 05:59:20,014] Trial 180 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.513390\tKL_Divergence = 2.157949\n",
      "Total time elapsed during training: 37.378 s\n",
      "Trial 180 pruned. \n",
      "Epoch: 1\tFidelity = 0.516238\tKL_Divergence = 2.049697\n",
      "Epoch: 2\tFidelity = 0.511116\tKL_Divergence = 2.262081\n",
      "Epoch: 3\tFidelity = 0.515110\tKL_Divergence = 2.089707\n",
      "Epoch: 4\tFidelity = 0.512926\tKL_Divergence = 2.177478\n",
      "Epoch: 5\tFidelity = 0.511552\tKL_Divergence = 2.240091\n",
      "Epoch: 6\tFidelity = 0.508684\tKL_Divergence = 2.400040\n",
      "Epoch: 7\tFidelity = 0.511241\tKL_Divergence = 2.255915\n",
      "Epoch: 8\tFidelity = 0.509689\tKL_Divergence = 2.338893\n",
      "Epoch: 9\tFidelity = 0.516420\tKL_Divergence = 2.043144\n",
      "Epoch: 10\tFidelity = 0.512168\tKL_Divergence = 2.211545\n",
      "Epoch: 11\tFidelity = 0.512582\tKL_Divergence = 2.192728\n",
      "Epoch: 12\tFidelity = 0.512007\tKL_Divergence = 2.219022\n",
      "Epoch: 13\tFidelity = 0.513468\tKL_Divergence = 2.154405\n",
      "Epoch: 14\tFidelity = 0.509805\tKL_Divergence = 2.332393\n",
      "Epoch: 15\tFidelity = 0.513515\tKL_Divergence = 2.152432\n",
      "Epoch: 16\tFidelity = 0.513063\tKL_Divergence = 2.171858\n",
      "Epoch: 17\tFidelity = 0.511687\tKL_Divergence = 2.234064\n",
      "Epoch: 18\tFidelity = 0.515648\tKL_Divergence = 2.070518\n",
      "Epoch: 19\tFidelity = 0.512358\tKL_Divergence = 2.202613\n",
      "Epoch: 20\tFidelity = 0.514426\tKL_Divergence = 2.116066\n",
      "Epoch: 21\tFidelity = 0.512334\tKL_Divergence = 2.203874\n",
      "Epoch: 22\tFidelity = 0.509421\tKL_Divergence = 2.354641\n",
      "Epoch: 23\tFidelity = 0.513302\tKL_Divergence = 2.161622\n",
      "Epoch: 24\tFidelity = 0.510407\tKL_Divergence = 2.298831\n",
      "Epoch: 25\tFidelity = 0.510331\tKL_Divergence = 2.303084\n",
      "Epoch: 26\tFidelity = 0.514344\tKL_Divergence = 2.118961\n",
      "Epoch: 27\tFidelity = 0.511877\tKL_Divergence = 2.224808\n",
      "Epoch: 28\tFidelity = 0.510548\tKL_Divergence = 2.291537\n",
      "Epoch: 29\tFidelity = 0.511235\tKL_Divergence = 2.256220\n",
      "Epoch: 30\tFidelity = 0.512027\tKL_Divergence = 2.218055\n",
      "Epoch: 31\tFidelity = 0.515349\tKL_Divergence = 2.081236\n",
      "Epoch: 32\tFidelity = 0.513630\tKL_Divergence = 2.147986\n",
      "Epoch: 33\tFidelity = 0.509074\tKL_Divergence = 2.375610\n",
      "Epoch: 34\tFidelity = 0.509975\tKL_Divergence = 2.322551\n",
      "Epoch: 35\tFidelity = 0.513065\tKL_Divergence = 2.171480\n",
      "Epoch: 36\tFidelity = 0.517120\tKL_Divergence = 2.019975\n",
      "Epoch: 37\tFidelity = 0.510582\tKL_Divergence = 2.289410\n",
      "Epoch: 38\tFidelity = 0.514376\tKL_Divergence = 2.117727\n",
      "Epoch: 39\tFidelity = 0.512308\tKL_Divergence = 2.204997\n",
      "Epoch: 40\tFidelity = 0.509713\tKL_Divergence = 2.337424\n",
      "Epoch: 41\tFidelity = 0.512478\tKL_Divergence = 2.196893\n",
      "Epoch: 42\tFidelity = 0.514304\tKL_Divergence = 2.120660\n",
      "Epoch: 43\tFidelity = 0.510485\tKL_Divergence = 2.294624\n",
      "Epoch: 44\tFidelity = 0.510928\tKL_Divergence = 2.271697\n",
      "Epoch: 45\tFidelity = 0.513777\tKL_Divergence = 2.141580\n",
      "Epoch: 46\tFidelity = 0.509296\tKL_Divergence = 2.361744\n",
      "Epoch: 47\tFidelity = 0.515526\tKL_Divergence = 2.075002\n",
      "Epoch: 48\tFidelity = 0.515193\tKL_Divergence = 2.087037\n",
      "Epoch: 49\tFidelity = 0.511004\tKL_Divergence = 2.267829\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:00:15,986] Trial 181 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.508142\tKL_Divergence = 2.435867\n",
      "Total time elapsed during training: 55.821 s\n",
      "Trial 181 pruned. \n",
      "Epoch: 1\tFidelity = 0.511747\tKL_Divergence = 2.231325\n",
      "Epoch: 2\tFidelity = 0.512793\tKL_Divergence = 2.183580\n",
      "Epoch: 3\tFidelity = 0.510988\tKL_Divergence = 2.268769\n",
      "Epoch: 4\tFidelity = 0.512313\tKL_Divergence = 2.205030\n",
      "Epoch: 5\tFidelity = 0.509812\tKL_Divergence = 2.331953\n",
      "Epoch: 6\tFidelity = 0.511876\tKL_Divergence = 2.224708\n",
      "Epoch: 7\tFidelity = 0.511096\tKL_Divergence = 2.263219\n",
      "Epoch: 8\tFidelity = 0.513991\tKL_Divergence = 2.133373\n",
      "Epoch: 9\tFidelity = 0.511902\tKL_Divergence = 2.223588\n",
      "Epoch: 10\tFidelity = 0.511925\tKL_Divergence = 2.222849\n",
      "Epoch: 11\tFidelity = 0.512049\tKL_Divergence = 2.217080\n",
      "Epoch: 12\tFidelity = 0.512316\tKL_Divergence = 2.204905\n",
      "Epoch: 13\tFidelity = 0.512838\tKL_Divergence = 2.181667\n",
      "Epoch: 14\tFidelity = 0.512429\tKL_Divergence = 2.199744\n",
      "Epoch: 15\tFidelity = 0.510380\tKL_Divergence = 2.300470\n",
      "Epoch: 16\tFidelity = 0.511100\tKL_Divergence = 2.263061\n",
      "Epoch: 17\tFidelity = 0.512742\tKL_Divergence = 2.185810\n",
      "Epoch: 18\tFidelity = 0.513972\tKL_Divergence = 2.134120\n",
      "Epoch: 19\tFidelity = 0.510491\tKL_Divergence = 2.294603\n",
      "Epoch: 20\tFidelity = 0.512937\tKL_Divergence = 2.176952\n",
      "Epoch: 21\tFidelity = 0.510515\tKL_Divergence = 2.293297\n",
      "Epoch: 22\tFidelity = 0.510463\tKL_Divergence = 2.296071\n",
      "Epoch: 23\tFidelity = 0.510787\tKL_Divergence = 2.278838\n",
      "Epoch: 24\tFidelity = 0.511699\tKL_Divergence = 2.233680\n",
      "Epoch: 25\tFidelity = 0.513966\tKL_Divergence = 2.134415\n",
      "Epoch: 26\tFidelity = 0.512346\tKL_Divergence = 2.203525\n",
      "Epoch: 27\tFidelity = 0.515334\tKL_Divergence = 2.081997\n",
      "Epoch: 28\tFidelity = 0.510762\tKL_Divergence = 2.280386\n",
      "Epoch: 29\tFidelity = 0.509615\tKL_Divergence = 2.343317\n",
      "Epoch: 30\tFidelity = 0.513288\tKL_Divergence = 2.162301\n",
      "Epoch: 31\tFidelity = 0.511212\tKL_Divergence = 2.257273\n",
      "Epoch: 32\tFidelity = 0.512800\tKL_Divergence = 2.183319\n",
      "Epoch: 33\tFidelity = 0.508695\tKL_Divergence = 2.399556\n",
      "Epoch: 34\tFidelity = 0.511850\tKL_Divergence = 2.226532\n",
      "Epoch: 35\tFidelity = 0.509428\tKL_Divergence = 2.354361\n",
      "Epoch: 36\tFidelity = 0.509936\tKL_Divergence = 2.324971\n",
      "Epoch: 37\tFidelity = 0.510891\tKL_Divergence = 2.273527\n",
      "Epoch: 38\tFidelity = 0.510351\tKL_Divergence = 2.302144\n",
      "Epoch: 39\tFidelity = 0.512516\tKL_Divergence = 2.195881\n",
      "Epoch: 40\tFidelity = 0.510825\tKL_Divergence = 2.277095\n",
      "Epoch: 41\tFidelity = 0.512712\tKL_Divergence = 2.187220\n",
      "Epoch: 42\tFidelity = 0.510091\tKL_Divergence = 2.316298\n",
      "Epoch: 43\tFidelity = 0.511012\tKL_Divergence = 2.267579\n",
      "Epoch: 44\tFidelity = 0.510897\tKL_Divergence = 2.273442\n",
      "Epoch: 45\tFidelity = 0.512684\tKL_Divergence = 2.188402\n",
      "Epoch: 46\tFidelity = 0.511626\tKL_Divergence = 2.237226\n",
      "Epoch: 47\tFidelity = 0.511002\tKL_Divergence = 2.268100\n",
      "Epoch: 48\tFidelity = 0.512832\tKL_Divergence = 2.181971\n",
      "Epoch: 49\tFidelity = 0.510125\tKL_Divergence = 2.314571\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:01:12,151] Trial 182 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.512498\tKL_Divergence = 2.196758\n",
      "Total time elapsed during training: 56.019 s\n",
      "Trial 182 pruned. \n",
      "Epoch: 1\tFidelity = 0.511637\tKL_Divergence = 2.236692\n",
      "Epoch: 2\tFidelity = 0.511236\tKL_Divergence = 2.256359\n",
      "Epoch: 3\tFidelity = 0.510868\tKL_Divergence = 2.275000\n",
      "Epoch: 4\tFidelity = 0.511524\tKL_Divergence = 2.242186\n",
      "Epoch: 5\tFidelity = 0.511040\tKL_Divergence = 2.266180\n",
      "Epoch: 6\tFidelity = 0.509824\tKL_Divergence = 2.331466\n",
      "Epoch: 7\tFidelity = 0.512053\tKL_Divergence = 2.217051\n",
      "Epoch: 8\tFidelity = 0.509677\tKL_Divergence = 2.339829\n",
      "Epoch: 9\tFidelity = 0.510628\tKL_Divergence = 2.287339\n",
      "Epoch: 10\tFidelity = 0.509459\tKL_Divergence = 2.352562\n",
      "Epoch: 11\tFidelity = 0.511365\tKL_Divergence = 2.249953\n",
      "Epoch: 12\tFidelity = 0.510567\tKL_Divergence = 2.290656\n",
      "Epoch: 13\tFidelity = 0.512302\tKL_Divergence = 2.205580\n",
      "Epoch: 14\tFidelity = 0.512035\tKL_Divergence = 2.217843\n",
      "Epoch: 15\tFidelity = 0.510866\tKL_Divergence = 2.275000\n",
      "Epoch: 16\tFidelity = 0.509168\tKL_Divergence = 2.370006\n",
      "Epoch: 17\tFidelity = 0.511124\tKL_Divergence = 2.261896\n",
      "Epoch: 18\tFidelity = 0.513732\tKL_Divergence = 2.143898\n",
      "Epoch: 19\tFidelity = 0.509713\tKL_Divergence = 2.337766\n",
      "Epoch: 20\tFidelity = 0.510586\tKL_Divergence = 2.289676\n",
      "Epoch: 21\tFidelity = 0.510907\tKL_Divergence = 2.272858\n",
      "Epoch: 22\tFidelity = 0.511652\tKL_Divergence = 2.235955\n",
      "Epoch: 23\tFidelity = 0.511388\tKL_Divergence = 2.248805\n",
      "Epoch: 24\tFidelity = 0.510679\tKL_Divergence = 2.284710\n",
      "Epoch: 25\tFidelity = 0.511914\tKL_Divergence = 2.223444\n",
      "Epoch: 26\tFidelity = 0.510298\tKL_Divergence = 2.304993\n",
      "Epoch: 27\tFidelity = 0.511662\tKL_Divergence = 2.235488\n",
      "Epoch: 28\tFidelity = 0.512419\tKL_Divergence = 2.200199\n",
      "Epoch: 29\tFidelity = 0.508734\tKL_Divergence = 2.397057\n",
      "Epoch: 30\tFidelity = 0.512589\tKL_Divergence = 2.192595\n",
      "Epoch: 31\tFidelity = 0.509225\tKL_Divergence = 2.366537\n",
      "Epoch: 32\tFidelity = 0.512658\tKL_Divergence = 2.189556\n",
      "Epoch: 33\tFidelity = 0.510569\tKL_Divergence = 2.290527\n",
      "Epoch: 34\tFidelity = 0.510991\tKL_Divergence = 2.268649\n",
      "Epoch: 35\tFidelity = 0.513067\tKL_Divergence = 2.171734\n",
      "Epoch: 36\tFidelity = 0.510207\tKL_Divergence = 2.309978\n",
      "Epoch: 37\tFidelity = 0.511660\tKL_Divergence = 2.235458\n",
      "Epoch: 38\tFidelity = 0.510328\tKL_Divergence = 2.303344\n",
      "Epoch: 39\tFidelity = 0.509325\tKL_Divergence = 2.360516\n",
      "Epoch: 40\tFidelity = 0.509254\tKL_Divergence = 2.364791\n",
      "Epoch: 41\tFidelity = 0.510231\tKL_Divergence = 2.308716\n",
      "Epoch: 42\tFidelity = 0.509381\tKL_Divergence = 2.357120\n",
      "Epoch: 43\tFidelity = 0.509786\tKL_Divergence = 2.333555\n",
      "Epoch: 44\tFidelity = 0.510478\tKL_Divergence = 2.295331\n",
      "Epoch: 45\tFidelity = 0.512459\tKL_Divergence = 2.198444\n",
      "Epoch: 46\tFidelity = 0.510665\tKL_Divergence = 2.285458\n",
      "Epoch: 47\tFidelity = 0.509463\tKL_Divergence = 2.352247\n",
      "Epoch: 48\tFidelity = 0.509076\tKL_Divergence = 2.375397\n",
      "Epoch: 49\tFidelity = 0.510800\tKL_Divergence = 2.278293\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:02:07,814] Trial 183 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.510568\tKL_Divergence = 2.290382\n",
      "Total time elapsed during training: 55.512 s\n",
      "Trial 183 pruned. \n",
      "Epoch: 1\tFidelity = 0.509286\tKL_Divergence = 2.362644\n",
      "Epoch: 2\tFidelity = 0.508536\tKL_Divergence = 2.409806\n",
      "Epoch: 3\tFidelity = 0.509559\tKL_Divergence = 2.346647\n",
      "Epoch: 4\tFidelity = 0.509623\tKL_Divergence = 2.342940\n",
      "Epoch: 5\tFidelity = 0.509729\tKL_Divergence = 2.336829\n",
      "Epoch: 6\tFidelity = 0.508503\tKL_Divergence = 2.412074\n",
      "Epoch: 7\tFidelity = 0.508677\tKL_Divergence = 2.400734\n",
      "Epoch: 8\tFidelity = 0.509632\tKL_Divergence = 2.342466\n",
      "Epoch: 9\tFidelity = 0.508902\tKL_Divergence = 2.386454\n",
      "Epoch: 10\tFidelity = 0.510766\tKL_Divergence = 2.280221\n",
      "Epoch: 11\tFidelity = 0.509396\tKL_Divergence = 2.356293\n",
      "Epoch: 12\tFidelity = 0.509287\tKL_Divergence = 2.362784\n",
      "Epoch: 13\tFidelity = 0.509522\tKL_Divergence = 2.348846\n",
      "Epoch: 14\tFidelity = 0.509328\tKL_Divergence = 2.360343\n",
      "Epoch: 15\tFidelity = 0.509894\tKL_Divergence = 2.327425\n",
      "Epoch: 16\tFidelity = 0.509496\tKL_Divergence = 2.350321\n",
      "Epoch: 17\tFidelity = 0.508310\tKL_Divergence = 2.424797\n",
      "Epoch: 18\tFidelity = 0.507819\tKL_Divergence = 2.458860\n",
      "Epoch: 19\tFidelity = 0.510073\tKL_Divergence = 2.317433\n",
      "Epoch: 20\tFidelity = 0.510735\tKL_Divergence = 2.281795\n",
      "Epoch: 21\tFidelity = 0.511385\tKL_Divergence = 2.248902\n",
      "Epoch: 22\tFidelity = 0.514365\tKL_Divergence = 2.118652\n",
      "Epoch: 23\tFidelity = 0.512023\tKL_Divergence = 2.218384\n",
      "Epoch: 24\tFidelity = 0.512574\tKL_Divergence = 2.193337\n",
      "Epoch: 25\tFidelity = 0.512311\tKL_Divergence = 2.205193\n",
      "Epoch: 26\tFidelity = 0.512842\tKL_Divergence = 2.181536\n",
      "Epoch: 27\tFidelity = 0.511836\tKL_Divergence = 2.227165\n",
      "Epoch: 28\tFidelity = 0.509074\tKL_Divergence = 2.375722\n",
      "Epoch: 29\tFidelity = 0.509358\tKL_Divergence = 2.358551\n",
      "Epoch: 30\tFidelity = 0.508850\tKL_Divergence = 2.389768\n",
      "Epoch: 31\tFidelity = 0.509994\tKL_Divergence = 2.321825\n",
      "Epoch: 32\tFidelity = 0.509080\tKL_Divergence = 2.375448\n",
      "Epoch: 33\tFidelity = 0.510153\tKL_Divergence = 2.313031\n",
      "Epoch: 34\tFidelity = 0.509750\tKL_Divergence = 2.335652\n",
      "Epoch: 35\tFidelity = 0.509142\tKL_Divergence = 2.371619\n",
      "Epoch: 36\tFidelity = 0.507656\tKL_Divergence = 2.470625\n",
      "Epoch: 37\tFidelity = 0.509057\tKL_Divergence = 2.376860\n",
      "Epoch: 38\tFidelity = 0.511612\tKL_Divergence = 2.237930\n",
      "Epoch: 39\tFidelity = 0.510807\tKL_Divergence = 2.278124\n",
      "Epoch: 40\tFidelity = 0.511501\tKL_Divergence = 2.243288\n",
      "Epoch: 41\tFidelity = 0.513250\tKL_Divergence = 2.164005\n",
      "Epoch: 42\tFidelity = 0.510742\tKL_Divergence = 2.281457\n",
      "Epoch: 43\tFidelity = 0.511354\tKL_Divergence = 2.250451\n",
      "Epoch: 44\tFidelity = 0.509745\tKL_Divergence = 2.335965\n",
      "Epoch: 45\tFidelity = 0.508724\tKL_Divergence = 2.397778\n",
      "Epoch: 46\tFidelity = 0.509028\tKL_Divergence = 2.378630\n",
      "Epoch: 47\tFidelity = 0.508395\tKL_Divergence = 2.419247\n",
      "Epoch: 48\tFidelity = 0.509458\tKL_Divergence = 2.352618\n",
      "Epoch: 49\tFidelity = 0.509104\tKL_Divergence = 2.373940\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:02:44,925] Trial 184 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.508060\tKL_Divergence = 2.441934\n",
      "Total time elapsed during training: 36.966 s\n",
      "Trial 184 pruned. \n",
      "Epoch: 1\tFidelity = 0.509507\tKL_Divergence = 2.349757\n",
      "Epoch: 2\tFidelity = 0.510408\tKL_Divergence = 2.299158\n",
      "Epoch: 3\tFidelity = 0.511030\tKL_Divergence = 2.266698\n",
      "Epoch: 4\tFidelity = 0.511049\tKL_Divergence = 2.265745\n",
      "Epoch: 5\tFidelity = 0.510387\tKL_Divergence = 2.300272\n",
      "Epoch: 6\tFidelity = 0.510491\tKL_Divergence = 2.294709\n",
      "Epoch: 7\tFidelity = 0.510063\tKL_Divergence = 2.318030\n",
      "Epoch: 8\tFidelity = 0.510242\tKL_Divergence = 2.308146\n",
      "Epoch: 9\tFidelity = 0.510470\tKL_Divergence = 2.295849\n",
      "Epoch: 10\tFidelity = 0.510962\tKL_Divergence = 2.270199\n",
      "Epoch: 11\tFidelity = 0.510031\tKL_Divergence = 2.319796\n",
      "Epoch: 12\tFidelity = 0.509784\tKL_Divergence = 2.333735\n",
      "Epoch: 13\tFidelity = 0.509289\tKL_Divergence = 2.362758\n",
      "Epoch: 14\tFidelity = 0.511039\tKL_Divergence = 2.266268\n",
      "Epoch: 15\tFidelity = 0.511107\tKL_Divergence = 2.262855\n",
      "Epoch: 16\tFidelity = 0.510307\tKL_Divergence = 2.304624\n",
      "Epoch: 17\tFidelity = 0.511451\tKL_Divergence = 2.245744\n",
      "Epoch: 18\tFidelity = 0.510542\tKL_Divergence = 2.292052\n",
      "Epoch: 19\tFidelity = 0.511172\tKL_Divergence = 2.259584\n",
      "Epoch: 20\tFidelity = 0.511404\tKL_Divergence = 2.248059\n",
      "Epoch: 21\tFidelity = 0.509927\tKL_Divergence = 2.325642\n",
      "Epoch: 22\tFidelity = 0.511162\tKL_Divergence = 2.260073\n",
      "Epoch: 23\tFidelity = 0.509879\tKL_Divergence = 2.328306\n",
      "Epoch: 24\tFidelity = 0.510469\tKL_Divergence = 2.295886\n",
      "Epoch: 25\tFidelity = 0.510664\tKL_Divergence = 2.285586\n",
      "Epoch: 26\tFidelity = 0.512406\tKL_Divergence = 2.200895\n",
      "Epoch: 27\tFidelity = 0.509786\tKL_Divergence = 2.333620\n",
      "Epoch: 28\tFidelity = 0.509112\tKL_Divergence = 2.373468\n",
      "Epoch: 29\tFidelity = 0.510910\tKL_Divergence = 2.272839\n",
      "Epoch: 30\tFidelity = 0.510968\tKL_Divergence = 2.269859\n",
      "Epoch: 31\tFidelity = 0.509784\tKL_Divergence = 2.333764\n",
      "Epoch: 32\tFidelity = 0.510390\tKL_Divergence = 2.300157\n",
      "Epoch: 33\tFidelity = 0.510176\tKL_Divergence = 2.311832\n",
      "Epoch: 34\tFidelity = 0.512303\tKL_Divergence = 2.205609\n",
      "Epoch: 35\tFidelity = 0.510882\tKL_Divergence = 2.274301\n",
      "Epoch: 36\tFidelity = 0.510651\tKL_Divergence = 2.286273\n",
      "Epoch: 37\tFidelity = 0.510277\tKL_Divergence = 2.306260\n",
      "Epoch: 38\tFidelity = 0.511363\tKL_Divergence = 2.250083\n",
      "Epoch: 39\tFidelity = 0.510820\tKL_Divergence = 2.277494\n",
      "Epoch: 40\tFidelity = 0.510850\tKL_Divergence = 2.275934\n",
      "Epoch: 41\tFidelity = 0.509818\tKL_Divergence = 2.331858\n",
      "Epoch: 42\tFidelity = 0.509993\tKL_Divergence = 2.321962\n",
      "Epoch: 43\tFidelity = 0.511271\tKL_Divergence = 2.254635\n",
      "Epoch: 44\tFidelity = 0.510915\tKL_Divergence = 2.272599\n",
      "Epoch: 45\tFidelity = 0.509023\tKL_Divergence = 2.378994\n",
      "Epoch: 46\tFidelity = 0.510950\tKL_Divergence = 2.270817\n",
      "Epoch: 47\tFidelity = 0.510043\tKL_Divergence = 2.319188\n",
      "Epoch: 48\tFidelity = 0.511013\tKL_Divergence = 2.267600\n",
      "Epoch: 49\tFidelity = 0.510673\tKL_Divergence = 2.285166\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:03:15,961] Trial 185 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.510117\tKL_Divergence = 2.315079\n",
      "Total time elapsed during training: 30.886 s\n",
      "Trial 185 pruned. \n",
      "Epoch: 1\tFidelity = 0.511455\tKL_Divergence = 2.245581\n",
      "Epoch: 2\tFidelity = 0.511271\tKL_Divergence = 2.254613\n",
      "Epoch: 3\tFidelity = 0.510789\tKL_Divergence = 2.279009\n",
      "Epoch: 4\tFidelity = 0.508566\tKL_Divergence = 2.407974\n",
      "Epoch: 5\tFidelity = 0.510378\tKL_Divergence = 2.300721\n",
      "Epoch: 6\tFidelity = 0.510650\tKL_Divergence = 2.286376\n",
      "Epoch: 7\tFidelity = 0.510923\tKL_Divergence = 2.272258\n",
      "Epoch: 8\tFidelity = 0.509915\tKL_Divergence = 2.326279\n",
      "Epoch: 9\tFidelity = 0.510238\tKL_Divergence = 2.308430\n",
      "Epoch: 10\tFidelity = 0.510086\tKL_Divergence = 2.316608\n",
      "Epoch: 11\tFidelity = 0.510404\tKL_Divergence = 2.299444\n",
      "Epoch: 12\tFidelity = 0.511248\tKL_Divergence = 2.255808\n",
      "Epoch: 13\tFidelity = 0.511492\tKL_Divergence = 2.243840\n",
      "Epoch: 14\tFidelity = 0.511196\tKL_Divergence = 2.258351\n",
      "Epoch: 15\tFidelity = 0.511380\tKL_Divergence = 2.249348\n",
      "Epoch: 16\tFidelity = 0.510438\tKL_Divergence = 2.297653\n",
      "Epoch: 17\tFidelity = 0.509443\tKL_Divergence = 2.353606\n",
      "Epoch: 18\tFidelity = 0.508371\tKL_Divergence = 2.420919\n",
      "Epoch: 19\tFidelity = 0.510333\tKL_Divergence = 2.303005\n",
      "Epoch: 20\tFidelity = 0.510169\tKL_Divergence = 2.312197\n",
      "Epoch: 21\tFidelity = 0.512141\tKL_Divergence = 2.212863\n",
      "Epoch: 22\tFidelity = 0.508735\tKL_Divergence = 2.396989\n",
      "Epoch: 23\tFidelity = 0.511865\tKL_Divergence = 2.225820\n",
      "Epoch: 24\tFidelity = 0.509701\tKL_Divergence = 2.338594\n",
      "Epoch: 25\tFidelity = 0.511161\tKL_Divergence = 2.260189\n",
      "Epoch: 26\tFidelity = 0.509709\tKL_Divergence = 2.338113\n",
      "Epoch: 27\tFidelity = 0.509798\tKL_Divergence = 2.332950\n",
      "Epoch: 28\tFidelity = 0.508756\tKL_Divergence = 2.395833\n",
      "Epoch: 29\tFidelity = 0.509287\tKL_Divergence = 2.362964\n",
      "Epoch: 30\tFidelity = 0.511832\tKL_Divergence = 2.227519\n",
      "Epoch: 31\tFidelity = 0.509336\tKL_Divergence = 2.360047\n",
      "Epoch: 32\tFidelity = 0.509666\tKL_Divergence = 2.340658\n",
      "Epoch: 33\tFidelity = 0.509897\tKL_Divergence = 2.327497\n",
      "Epoch: 34\tFidelity = 0.509915\tKL_Divergence = 2.326463\n",
      "Epoch: 35\tFidelity = 0.510549\tKL_Divergence = 2.291800\n",
      "Epoch: 36\tFidelity = 0.510299\tKL_Divergence = 2.305172\n",
      "Epoch: 37\tFidelity = 0.510841\tKL_Divergence = 2.276494\n",
      "Epoch: 38\tFidelity = 0.510839\tKL_Divergence = 2.276638\n",
      "Epoch: 39\tFidelity = 0.508742\tKL_Divergence = 2.396776\n",
      "Epoch: 40\tFidelity = 0.509577\tKL_Divergence = 2.345767\n",
      "Epoch: 41\tFidelity = 0.510016\tKL_Divergence = 2.320755\n",
      "Epoch: 42\tFidelity = 0.508261\tKL_Divergence = 2.428277\n",
      "Epoch: 43\tFidelity = 0.511197\tKL_Divergence = 2.258381\n",
      "Epoch: 44\tFidelity = 0.508167\tKL_Divergence = 2.434715\n",
      "Epoch: 45\tFidelity = 0.511142\tKL_Divergence = 2.261143\n",
      "Epoch: 46\tFidelity = 0.508748\tKL_Divergence = 2.396372\n",
      "Epoch: 47\tFidelity = 0.508683\tKL_Divergence = 2.400511\n",
      "Epoch: 48\tFidelity = 0.512047\tKL_Divergence = 2.217425\n",
      "Epoch: 49\tFidelity = 0.509951\tKL_Divergence = 2.324381\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:04:33,343] Trial 186 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.508758\tKL_Divergence = 2.395621\n",
      "Total time elapsed during training: 77.230 s\n",
      "Trial 186 pruned. \n",
      "Epoch: 1\tFidelity = 0.510454\tKL_Divergence = 2.296634\n",
      "Epoch: 2\tFidelity = 0.509078\tKL_Divergence = 2.375550\n",
      "Epoch: 3\tFidelity = 0.511092\tKL_Divergence = 2.263540\n",
      "Epoch: 4\tFidelity = 0.509828\tKL_Divergence = 2.331218\n",
      "Epoch: 5\tFidelity = 0.510506\tKL_Divergence = 2.293869\n",
      "Epoch: 6\tFidelity = 0.510833\tKL_Divergence = 2.276789\n",
      "Epoch: 7\tFidelity = 0.508646\tKL_Divergence = 2.402782\n",
      "Epoch: 8\tFidelity = 0.511251\tKL_Divergence = 2.255453\n",
      "Epoch: 9\tFidelity = 0.510785\tKL_Divergence = 2.279086\n",
      "Epoch: 10\tFidelity = 0.508872\tKL_Divergence = 2.388320\n",
      "Epoch: 11\tFidelity = 0.508666\tKL_Divergence = 2.401199\n",
      "Epoch: 12\tFidelity = 0.511527\tKL_Divergence = 2.241490\n",
      "Epoch: 13\tFidelity = 0.509134\tKL_Divergence = 2.371333\n",
      "Epoch: 14\tFidelity = 0.510484\tKL_Divergence = 2.294246\n",
      "Epoch: 15\tFidelity = 0.510765\tKL_Divergence = 2.280035\n",
      "Epoch: 16\tFidelity = 0.510088\tKL_Divergence = 2.316550\n",
      "Epoch: 17\tFidelity = 0.508456\tKL_Divergence = 2.415248\n",
      "Epoch: 18\tFidelity = 0.508649\tKL_Divergence = 2.402615\n",
      "Epoch: 19\tFidelity = 0.511061\tKL_Divergence = 2.264927\n",
      "Epoch: 20\tFidelity = 0.510155\tKL_Divergence = 2.312485\n",
      "Epoch: 21\tFidelity = 0.510272\tKL_Divergence = 2.306107\n",
      "Epoch: 22\tFidelity = 0.511259\tKL_Divergence = 2.255147\n",
      "Epoch: 23\tFidelity = 0.510468\tKL_Divergence = 2.295725\n",
      "Epoch: 24\tFidelity = 0.508995\tKL_Divergence = 2.380483\n",
      "Epoch: 25\tFidelity = 0.510351\tKL_Divergence = 2.302310\n",
      "Epoch: 26\tFidelity = 0.510109\tKL_Divergence = 2.315522\n",
      "Epoch: 27\tFidelity = 0.509176\tKL_Divergence = 2.369620\n",
      "Epoch: 28\tFidelity = 0.508209\tKL_Divergence = 2.431821\n",
      "Epoch: 29\tFidelity = 0.509045\tKL_Divergence = 2.377701\n",
      "Epoch: 30\tFidelity = 0.510296\tKL_Divergence = 2.305282\n",
      "Epoch: 31\tFidelity = 0.510724\tKL_Divergence = 2.282446\n",
      "Epoch: 32\tFidelity = 0.509650\tKL_Divergence = 2.341356\n",
      "Epoch: 33\tFidelity = 0.510354\tKL_Divergence = 2.302117\n",
      "Epoch: 34\tFidelity = 0.509577\tKL_Divergence = 2.345358\n",
      "Epoch: 35\tFidelity = 0.509914\tKL_Divergence = 2.326188\n",
      "Epoch: 36\tFidelity = 0.510954\tKL_Divergence = 2.270590\n",
      "Epoch: 37\tFidelity = 0.509322\tKL_Divergence = 2.360739\n",
      "Epoch: 38\tFidelity = 0.511302\tKL_Divergence = 2.253090\n",
      "Epoch: 39\tFidelity = 0.510697\tKL_Divergence = 2.283534\n",
      "Epoch: 40\tFidelity = 0.510223\tKL_Divergence = 2.308721\n",
      "Epoch: 41\tFidelity = 0.508432\tKL_Divergence = 2.416443\n",
      "Epoch: 42\tFidelity = 0.507956\tKL_Divergence = 2.449131\n",
      "Epoch: 43\tFidelity = 0.510138\tKL_Divergence = 2.313939\n",
      "Epoch: 44\tFidelity = 0.510781\tKL_Divergence = 2.279498\n",
      "Epoch: 45\tFidelity = 0.510490\tKL_Divergence = 2.294588\n",
      "Epoch: 46\tFidelity = 0.508543\tKL_Divergence = 2.409477\n",
      "Epoch: 47\tFidelity = 0.511577\tKL_Divergence = 2.239501\n",
      "Epoch: 48\tFidelity = 0.508695\tKL_Divergence = 2.399708\n",
      "Epoch: 49\tFidelity = 0.508520\tKL_Divergence = 2.411007\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:05:10,058] Trial 187 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.512191\tKL_Divergence = 2.210655\n",
      "Total time elapsed during training: 36.569 s\n",
      "Trial 187 pruned. \n",
      "Epoch: 1\tFidelity = 0.510431\tKL_Divergence = 2.297881\n",
      "Epoch: 2\tFidelity = 0.509693\tKL_Divergence = 2.338935\n",
      "Epoch: 3\tFidelity = 0.509383\tKL_Divergence = 2.357131\n",
      "Epoch: 4\tFidelity = 0.509082\tKL_Divergence = 2.375255\n",
      "Epoch: 5\tFidelity = 0.510708\tKL_Divergence = 2.283186\n",
      "Epoch: 6\tFidelity = 0.510307\tKL_Divergence = 2.304550\n",
      "Epoch: 7\tFidelity = 0.510685\tKL_Divergence = 2.284415\n",
      "Epoch: 8\tFidelity = 0.509653\tKL_Divergence = 2.341314\n",
      "Epoch: 9\tFidelity = 0.509305\tKL_Divergence = 2.361823\n",
      "Epoch: 10\tFidelity = 0.509970\tKL_Divergence = 2.323251\n",
      "Epoch: 11\tFidelity = 0.509215\tKL_Divergence = 2.367287\n",
      "Epoch: 12\tFidelity = 0.510135\tKL_Divergence = 2.314090\n",
      "Epoch: 13\tFidelity = 0.509958\tKL_Divergence = 2.323930\n",
      "Epoch: 14\tFidelity = 0.511049\tKL_Divergence = 2.265780\n",
      "Epoch: 15\tFidelity = 0.509495\tKL_Divergence = 2.350549\n",
      "Epoch: 16\tFidelity = 0.510442\tKL_Divergence = 2.297400\n",
      "Epoch: 17\tFidelity = 0.510673\tKL_Divergence = 2.285136\n",
      "Epoch: 18\tFidelity = 0.509217\tKL_Divergence = 2.367169\n",
      "Epoch: 19\tFidelity = 0.509584\tKL_Divergence = 2.345309\n",
      "Epoch: 20\tFidelity = 0.509638\tKL_Divergence = 2.342192\n",
      "Epoch: 21\tFidelity = 0.509658\tKL_Divergence = 2.341047\n",
      "Epoch: 22\tFidelity = 0.509008\tKL_Divergence = 2.379986\n",
      "Epoch: 23\tFidelity = 0.509022\tKL_Divergence = 2.379039\n",
      "Epoch: 24\tFidelity = 0.510372\tKL_Divergence = 2.301172\n",
      "Epoch: 25\tFidelity = 0.509805\tKL_Divergence = 2.332571\n",
      "Epoch: 26\tFidelity = 0.509767\tKL_Divergence = 2.334739\n",
      "Epoch: 27\tFidelity = 0.509504\tKL_Divergence = 2.350008\n",
      "Epoch: 28\tFidelity = 0.509500\tKL_Divergence = 2.350226\n",
      "Epoch: 29\tFidelity = 0.508507\tKL_Divergence = 2.411938\n",
      "Epoch: 30\tFidelity = 0.508921\tKL_Divergence = 2.385386\n",
      "Epoch: 31\tFidelity = 0.509501\tKL_Divergence = 2.350173\n",
      "Epoch: 32\tFidelity = 0.510025\tKL_Divergence = 2.320149\n",
      "Epoch: 33\tFidelity = 0.508951\tKL_Divergence = 2.383449\n",
      "Epoch: 34\tFidelity = 0.509853\tKL_Divergence = 2.329854\n",
      "Epoch: 35\tFidelity = 0.510278\tKL_Divergence = 2.306207\n",
      "Epoch: 36\tFidelity = 0.509507\tKL_Divergence = 2.349804\n",
      "Epoch: 37\tFidelity = 0.508764\tKL_Divergence = 2.395265\n",
      "Epoch: 38\tFidelity = 0.509442\tKL_Divergence = 2.353650\n",
      "Epoch: 39\tFidelity = 0.510254\tKL_Divergence = 2.307546\n",
      "Epoch: 40\tFidelity = 0.510091\tKL_Divergence = 2.316547\n",
      "Epoch: 41\tFidelity = 0.509865\tKL_Divergence = 2.329215\n",
      "Epoch: 42\tFidelity = 0.509755\tKL_Divergence = 2.335414\n",
      "Epoch: 43\tFidelity = 0.509652\tKL_Divergence = 2.341368\n",
      "Epoch: 44\tFidelity = 0.508322\tKL_Divergence = 2.424169\n",
      "Epoch: 45\tFidelity = 0.508817\tKL_Divergence = 2.391933\n",
      "Epoch: 46\tFidelity = 0.509517\tKL_Divergence = 2.349202\n",
      "Epoch: 47\tFidelity = 0.508875\tKL_Divergence = 2.388234\n",
      "Epoch: 48\tFidelity = 0.508560\tKL_Divergence = 2.408442\n",
      "Epoch: 49\tFidelity = 0.509695\tKL_Divergence = 2.338878\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:05:47,176] Trial 188 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.509179\tKL_Divergence = 2.369417\n",
      "Total time elapsed during training: 36.968 s\n",
      "Trial 188 pruned. \n",
      "Epoch: 1\tFidelity = 0.510929\tKL_Divergence = 2.271823\n",
      "Epoch: 2\tFidelity = 0.508785\tKL_Divergence = 2.393888\n",
      "Epoch: 3\tFidelity = 0.510904\tKL_Divergence = 2.273110\n",
      "Epoch: 4\tFidelity = 0.509559\tKL_Divergence = 2.346768\n",
      "Epoch: 5\tFidelity = 0.508835\tKL_Divergence = 2.390729\n",
      "Epoch: 6\tFidelity = 0.510711\tKL_Divergence = 2.283159\n",
      "Epoch: 7\tFidelity = 0.509190\tKL_Divergence = 2.368740\n",
      "Epoch: 8\tFidelity = 0.509267\tKL_Divergence = 2.364082\n",
      "Epoch: 9\tFidelity = 0.510561\tKL_Divergence = 2.291000\n",
      "Epoch: 10\tFidelity = 0.508677\tKL_Divergence = 2.400836\n",
      "Epoch: 11\tFidelity = 0.510640\tKL_Divergence = 2.286850\n",
      "Epoch: 12\tFidelity = 0.508971\tKL_Divergence = 2.382204\n",
      "Epoch: 13\tFidelity = 0.511107\tKL_Divergence = 2.262830\n",
      "Epoch: 14\tFidelity = 0.509147\tKL_Divergence = 2.371392\n",
      "Epoch: 15\tFidelity = 0.509322\tKL_Divergence = 2.360820\n",
      "Epoch: 16\tFidelity = 0.509219\tKL_Divergence = 2.367027\n",
      "Epoch: 17\tFidelity = 0.509214\tKL_Divergence = 2.367290\n",
      "Epoch: 18\tFidelity = 0.509936\tKL_Divergence = 2.325138\n",
      "Epoch: 19\tFidelity = 0.509480\tKL_Divergence = 2.351399\n",
      "Epoch: 20\tFidelity = 0.510655\tKL_Divergence = 2.286067\n",
      "Epoch: 21\tFidelity = 0.508856\tKL_Divergence = 2.389443\n",
      "Epoch: 22\tFidelity = 0.509932\tKL_Divergence = 2.325379\n",
      "Epoch: 23\tFidelity = 0.508297\tKL_Divergence = 2.425838\n",
      "Epoch: 24\tFidelity = 0.511246\tKL_Divergence = 2.255908\n",
      "Epoch: 25\tFidelity = 0.509135\tKL_Divergence = 2.372132\n",
      "Epoch: 26\tFidelity = 0.509986\tKL_Divergence = 2.322367\n",
      "Epoch: 27\tFidelity = 0.509764\tKL_Divergence = 2.334965\n",
      "Epoch: 28\tFidelity = 0.510998\tKL_Divergence = 2.268370\n",
      "Epoch: 29\tFidelity = 0.509050\tKL_Divergence = 2.377389\n",
      "Epoch: 30\tFidelity = 0.508864\tKL_Divergence = 2.388966\n",
      "Epoch: 31\tFidelity = 0.510367\tKL_Divergence = 2.301420\n",
      "Epoch: 32\tFidelity = 0.509818\tKL_Divergence = 2.331845\n",
      "Epoch: 33\tFidelity = 0.509307\tKL_Divergence = 2.361726\n",
      "Epoch: 34\tFidelity = 0.509553\tKL_Divergence = 2.347177\n",
      "Epoch: 35\tFidelity = 0.509434\tKL_Divergence = 2.354147\n",
      "Epoch: 36\tFidelity = 0.508727\tKL_Divergence = 2.397651\n",
      "Epoch: 37\tFidelity = 0.510657\tKL_Divergence = 2.285979\n",
      "Epoch: 38\tFidelity = 0.509497\tKL_Divergence = 2.350414\n",
      "Epoch: 39\tFidelity = 0.510350\tKL_Divergence = 2.302375\n",
      "Epoch: 40\tFidelity = 0.509436\tKL_Divergence = 2.354027\n",
      "Epoch: 41\tFidelity = 0.508621\tKL_Divergence = 2.404485\n",
      "Epoch: 42\tFidelity = 0.509994\tKL_Divergence = 2.321955\n",
      "Epoch: 43\tFidelity = 0.509209\tKL_Divergence = 2.367667\n",
      "Epoch: 44\tFidelity = 0.509857\tKL_Divergence = 2.329627\n",
      "Epoch: 45\tFidelity = 0.510192\tKL_Divergence = 2.310949\n",
      "Epoch: 46\tFidelity = 0.509464\tKL_Divergence = 2.352386\n",
      "Epoch: 47\tFidelity = 0.509115\tKL_Divergence = 2.373360\n",
      "Epoch: 48\tFidelity = 0.508619\tKL_Divergence = 2.404626\n",
      "Epoch: 49\tFidelity = 0.510478\tKL_Divergence = 2.295498\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:06:18,088] Trial 189 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.507914\tKL_Divergence = 2.452271\n",
      "Total time elapsed during training: 30.750 s\n",
      "Trial 189 pruned. \n",
      "Epoch: 1\tFidelity = 0.512255\tKL_Divergence = 2.207783\n",
      "Epoch: 2\tFidelity = 0.508533\tKL_Divergence = 2.410176\n",
      "Epoch: 3\tFidelity = 0.510612\tKL_Divergence = 2.288332\n",
      "Epoch: 4\tFidelity = 0.507955\tKL_Divergence = 2.449199\n",
      "Epoch: 5\tFidelity = 0.512013\tKL_Divergence = 2.218407\n",
      "Epoch: 6\tFidelity = 0.511939\tKL_Divergence = 2.222113\n",
      "Epoch: 7\tFidelity = 0.510358\tKL_Divergence = 2.300964\n",
      "Epoch: 8\tFidelity = 0.507863\tKL_Divergence = 2.455442\n",
      "Epoch: 9\tFidelity = 0.510549\tKL_Divergence = 2.291653\n",
      "Epoch: 10\tFidelity = 0.510767\tKL_Divergence = 2.280219\n",
      "Epoch: 11\tFidelity = 0.509228\tKL_Divergence = 2.366291\n",
      "Epoch: 12\tFidelity = 0.510522\tKL_Divergence = 2.293064\n",
      "Epoch: 13\tFidelity = 0.507058\tKL_Divergence = 2.516036\n",
      "Epoch: 14\tFidelity = 0.509088\tKL_Divergence = 2.374952\n",
      "Epoch: 15\tFidelity = 0.510988\tKL_Divergence = 2.268828\n",
      "Epoch: 16\tFidelity = 0.507910\tKL_Divergence = 2.452490\n",
      "Epoch: 17\tFidelity = 0.508935\tKL_Divergence = 2.384352\n",
      "Epoch: 18\tFidelity = 0.509500\tKL_Divergence = 2.349560\n",
      "Epoch: 19\tFidelity = 0.508576\tKL_Divergence = 2.406470\n",
      "Epoch: 20\tFidelity = 0.511202\tKL_Divergence = 2.257433\n",
      "Epoch: 21\tFidelity = 0.507555\tKL_Divergence = 2.477853\n",
      "Epoch: 22\tFidelity = 0.509489\tKL_Divergence = 2.350819\n",
      "Epoch: 23\tFidelity = 0.509834\tKL_Divergence = 2.330782\n",
      "Epoch: 24\tFidelity = 0.511586\tKL_Divergence = 2.239152\n",
      "Epoch: 25\tFidelity = 0.511043\tKL_Divergence = 2.265994\n",
      "Epoch: 26\tFidelity = 0.509693\tKL_Divergence = 2.338882\n",
      "Epoch: 27\tFidelity = 0.508565\tKL_Divergence = 2.408051\n",
      "Epoch: 28\tFidelity = 0.509898\tKL_Divergence = 2.326860\n",
      "Epoch: 29\tFidelity = 0.508940\tKL_Divergence = 2.383231\n",
      "Epoch: 30\tFidelity = 0.508433\tKL_Divergence = 2.416171\n",
      "Epoch: 31\tFidelity = 0.511270\tKL_Divergence = 2.254346\n",
      "Epoch: 32\tFidelity = 0.508962\tKL_Divergence = 2.382663\n",
      "Epoch: 33\tFidelity = 0.508415\tKL_Divergence = 2.417745\n",
      "Epoch: 34\tFidelity = 0.508113\tKL_Divergence = 2.438035\n",
      "Epoch: 35\tFidelity = 0.510131\tKL_Divergence = 2.314176\n",
      "Epoch: 36\tFidelity = 0.508819\tKL_Divergence = 2.391400\n",
      "Epoch: 37\tFidelity = 0.509126\tKL_Divergence = 2.372620\n",
      "Epoch: 38\tFidelity = 0.510398\tKL_Divergence = 2.299642\n",
      "Epoch: 39\tFidelity = 0.510461\tKL_Divergence = 2.296143\n",
      "Epoch: 40\tFidelity = 0.509372\tKL_Divergence = 2.357459\n",
      "Epoch: 41\tFidelity = 0.512072\tKL_Divergence = 2.216065\n",
      "Epoch: 42\tFidelity = 0.508529\tKL_Divergence = 2.410195\n",
      "Epoch: 43\tFidelity = 0.508821\tKL_Divergence = 2.391424\n",
      "Epoch: 44\tFidelity = 0.512080\tKL_Divergence = 2.215662\n",
      "Epoch: 45\tFidelity = 0.510453\tKL_Divergence = 2.296192\n",
      "Epoch: 46\tFidelity = 0.509263\tKL_Divergence = 2.364212\n",
      "Epoch: 47\tFidelity = 0.509204\tKL_Divergence = 2.367383\n",
      "Epoch: 48\tFidelity = 0.509335\tKL_Divergence = 2.359301\n",
      "Epoch: 49\tFidelity = 0.509545\tKL_Divergence = 2.346031\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:07:01,011] Trial 190 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.511294\tKL_Divergence = 2.252685\n",
      "Total time elapsed during training: 42.776 s\n",
      "Trial 190 pruned. \n",
      "Epoch: 1\tFidelity = 0.509978\tKL_Divergence = 2.322099\n",
      "Epoch: 2\tFidelity = 0.508548\tKL_Divergence = 2.408539\n",
      "Epoch: 3\tFidelity = 0.510130\tKL_Divergence = 2.313747\n",
      "Epoch: 4\tFidelity = 0.512669\tKL_Divergence = 2.188667\n",
      "Epoch: 5\tFidelity = 0.510109\tKL_Divergence = 2.315059\n",
      "Epoch: 6\tFidelity = 0.511660\tKL_Divergence = 2.235242\n",
      "Epoch: 7\tFidelity = 0.508683\tKL_Divergence = 2.400090\n",
      "Epoch: 8\tFidelity = 0.510854\tKL_Divergence = 2.275370\n",
      "Epoch: 9\tFidelity = 0.511138\tKL_Divergence = 2.260951\n",
      "Epoch: 10\tFidelity = 0.510828\tKL_Divergence = 2.276783\n",
      "Epoch: 11\tFidelity = 0.509099\tKL_Divergence = 2.374049\n",
      "Epoch: 12\tFidelity = 0.510693\tKL_Divergence = 2.283856\n",
      "Epoch: 13\tFidelity = 0.511267\tKL_Divergence = 2.254597\n",
      "Epoch: 14\tFidelity = 0.511070\tKL_Divergence = 2.264489\n",
      "Epoch: 15\tFidelity = 0.511591\tKL_Divergence = 2.238749\n",
      "Epoch: 16\tFidelity = 0.509683\tKL_Divergence = 2.339376\n",
      "Epoch: 17\tFidelity = 0.509899\tKL_Divergence = 2.327072\n",
      "Epoch: 18\tFidelity = 0.509510\tKL_Divergence = 2.349448\n",
      "Epoch: 19\tFidelity = 0.509253\tKL_Divergence = 2.364785\n",
      "Epoch: 20\tFidelity = 0.509154\tKL_Divergence = 2.370820\n",
      "Epoch: 21\tFidelity = 0.509114\tKL_Divergence = 2.373235\n",
      "Epoch: 22\tFidelity = 0.508412\tKL_Divergence = 2.417997\n",
      "Epoch: 23\tFidelity = 0.509802\tKL_Divergence = 2.332560\n",
      "Epoch: 24\tFidelity = 0.510555\tKL_Divergence = 2.291178\n",
      "Epoch: 25\tFidelity = 0.509545\tKL_Divergence = 2.347413\n",
      "Epoch: 26\tFidelity = 0.510369\tKL_Divergence = 2.301082\n",
      "Epoch: 27\tFidelity = 0.510161\tKL_Divergence = 2.312426\n",
      "Epoch: 28\tFidelity = 0.510851\tKL_Divergence = 2.275687\n",
      "Epoch: 29\tFidelity = 0.512817\tKL_Divergence = 2.182434\n",
      "Epoch: 30\tFidelity = 0.510412\tKL_Divergence = 2.298773\n",
      "Epoch: 31\tFidelity = 0.510752\tKL_Divergence = 2.280785\n",
      "Epoch: 32\tFidelity = 0.511081\tKL_Divergence = 2.263932\n",
      "Epoch: 33\tFidelity = 0.508997\tKL_Divergence = 2.380422\n",
      "Epoch: 34\tFidelity = 0.510545\tKL_Divergence = 2.291708\n",
      "Epoch: 35\tFidelity = 0.509864\tKL_Divergence = 2.329025\n",
      "Epoch: 36\tFidelity = 0.508741\tKL_Divergence = 2.396513\n",
      "Epoch: 37\tFidelity = 0.509982\tKL_Divergence = 2.322385\n",
      "Epoch: 38\tFidelity = 0.509571\tKL_Divergence = 2.345856\n",
      "Epoch: 39\tFidelity = 0.509604\tKL_Divergence = 2.343946\n",
      "Epoch: 40\tFidelity = 0.509092\tKL_Divergence = 2.374601\n",
      "Epoch: 41\tFidelity = 0.509052\tKL_Divergence = 2.377062\n",
      "Epoch: 42\tFidelity = 0.509633\tKL_Divergence = 2.342285\n",
      "Epoch: 43\tFidelity = 0.511174\tKL_Divergence = 2.259332\n",
      "Epoch: 44\tFidelity = 0.509803\tKL_Divergence = 2.332514\n",
      "Epoch: 45\tFidelity = 0.512122\tKL_Divergence = 2.213726\n",
      "Epoch: 46\tFidelity = 0.510690\tKL_Divergence = 2.284098\n",
      "Epoch: 47\tFidelity = 0.509608\tKL_Divergence = 2.343758\n",
      "Epoch: 48\tFidelity = 0.509392\tKL_Divergence = 2.356501\n",
      "Epoch: 49\tFidelity = 0.509337\tKL_Divergence = 2.359747\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:07:31,836] Trial 191 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.510247\tKL_Divergence = 2.307770\n",
      "Total time elapsed during training: 30.676 s\n",
      "Trial 191 pruned. \n",
      "Epoch: 1\tFidelity = 0.509251\tKL_Divergence = 2.364931\n",
      "Epoch: 2\tFidelity = 0.510624\tKL_Divergence = 2.287590\n",
      "Epoch: 3\tFidelity = 0.509542\tKL_Divergence = 2.347639\n",
      "Epoch: 4\tFidelity = 0.509019\tKL_Divergence = 2.379194\n",
      "Epoch: 5\tFidelity = 0.508749\tKL_Divergence = 2.396122\n",
      "Epoch: 6\tFidelity = 0.510135\tKL_Divergence = 2.313991\n",
      "Epoch: 7\tFidelity = 0.510457\tKL_Divergence = 2.296499\n",
      "Epoch: 8\tFidelity = 0.510123\tKL_Divergence = 2.314634\n",
      "Epoch: 9\tFidelity = 0.510572\tKL_Divergence = 2.290376\n",
      "Epoch: 10\tFidelity = 0.508968\tKL_Divergence = 2.382324\n",
      "Epoch: 11\tFidelity = 0.509262\tKL_Divergence = 2.364358\n",
      "Epoch: 12\tFidelity = 0.510107\tKL_Divergence = 2.315553\n",
      "Epoch: 13\tFidelity = 0.510817\tKL_Divergence = 2.277571\n",
      "Epoch: 14\tFidelity = 0.511008\tKL_Divergence = 2.267773\n",
      "Epoch: 15\tFidelity = 0.510560\tKL_Divergence = 2.291003\n",
      "Epoch: 16\tFidelity = 0.510051\tKL_Divergence = 2.318620\n",
      "Epoch: 17\tFidelity = 0.508649\tKL_Divergence = 2.402541\n",
      "Epoch: 18\tFidelity = 0.509659\tKL_Divergence = 2.340882\n",
      "Epoch: 19\tFidelity = 0.508963\tKL_Divergence = 2.382616\n",
      "Epoch: 20\tFidelity = 0.510410\tKL_Divergence = 2.298982\n",
      "Epoch: 21\tFidelity = 0.511164\tKL_Divergence = 2.259864\n",
      "Epoch: 22\tFidelity = 0.509443\tKL_Divergence = 2.353469\n",
      "Epoch: 23\tFidelity = 0.510769\tKL_Divergence = 2.280053\n",
      "Epoch: 24\tFidelity = 0.508993\tKL_Divergence = 2.380766\n",
      "Epoch: 25\tFidelity = 0.508731\tKL_Divergence = 2.397277\n",
      "Epoch: 26\tFidelity = 0.508901\tKL_Divergence = 2.386488\n",
      "Epoch: 27\tFidelity = 0.509708\tKL_Divergence = 2.338017\n",
      "Epoch: 28\tFidelity = 0.509814\tKL_Divergence = 2.331980\n",
      "Epoch: 29\tFidelity = 0.510278\tKL_Divergence = 2.306127\n",
      "Epoch: 30\tFidelity = 0.509108\tKL_Divergence = 2.373694\n",
      "Epoch: 31\tFidelity = 0.511184\tKL_Divergence = 2.258906\n",
      "Epoch: 32\tFidelity = 0.509831\tKL_Divergence = 2.331033\n",
      "Epoch: 33\tFidelity = 0.508152\tKL_Divergence = 2.435626\n",
      "Epoch: 34\tFidelity = 0.509740\tKL_Divergence = 2.336213\n",
      "Epoch: 35\tFidelity = 0.509506\tKL_Divergence = 2.349790\n",
      "Epoch: 36\tFidelity = 0.510059\tKL_Divergence = 2.318182\n",
      "Epoch: 37\tFidelity = 0.510205\tKL_Divergence = 2.310123\n",
      "Epoch: 38\tFidelity = 0.511819\tKL_Divergence = 2.227997\n",
      "Epoch: 39\tFidelity = 0.509529\tKL_Divergence = 2.348424\n",
      "Epoch: 40\tFidelity = 0.509936\tKL_Divergence = 2.325073\n",
      "Epoch: 41\tFidelity = 0.508586\tKL_Divergence = 2.406656\n",
      "Epoch: 42\tFidelity = 0.508815\tKL_Divergence = 2.391963\n",
      "Epoch: 43\tFidelity = 0.508726\tKL_Divergence = 2.397661\n",
      "Epoch: 44\tFidelity = 0.510860\tKL_Divergence = 2.275367\n",
      "Epoch: 45\tFidelity = 0.509035\tKL_Divergence = 2.378215\n",
      "Epoch: 46\tFidelity = 0.510796\tKL_Divergence = 2.278696\n",
      "Epoch: 47\tFidelity = 0.509363\tKL_Divergence = 2.358308\n",
      "Epoch: 48\tFidelity = 0.507968\tKL_Divergence = 2.448379\n",
      "Epoch: 49\tFidelity = 0.509206\tKL_Divergence = 2.367758\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:08:03,456] Trial 192 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.509073\tKL_Divergence = 2.375875\n",
      "Total time elapsed during training: 31.471 s\n",
      "Trial 192 pruned. \n",
      "Epoch: 1\tFidelity = 0.510969\tKL_Divergence = 2.269780\n",
      "Epoch: 2\tFidelity = 0.509189\tKL_Divergence = 2.368758\n",
      "Epoch: 3\tFidelity = 0.511060\tKL_Divergence = 2.265162\n",
      "Epoch: 4\tFidelity = 0.508497\tKL_Divergence = 2.412531\n",
      "Epoch: 5\tFidelity = 0.511039\tKL_Divergence = 2.266231\n",
      "Epoch: 6\tFidelity = 0.509312\tKL_Divergence = 2.361335\n",
      "Epoch: 7\tFidelity = 0.510180\tKL_Divergence = 2.311510\n",
      "Epoch: 8\tFidelity = 0.508672\tKL_Divergence = 2.401088\n",
      "Epoch: 9\tFidelity = 0.510971\tKL_Divergence = 2.269684\n",
      "Epoch: 10\tFidelity = 0.508907\tKL_Divergence = 2.386180\n",
      "Epoch: 11\tFidelity = 0.510405\tKL_Divergence = 2.299334\n",
      "Epoch: 12\tFidelity = 0.510844\tKL_Divergence = 2.276210\n",
      "Epoch: 13\tFidelity = 0.510671\tKL_Divergence = 2.285184\n",
      "Epoch: 14\tFidelity = 0.511654\tKL_Divergence = 2.235882\n",
      "Epoch: 15\tFidelity = 0.511768\tKL_Divergence = 2.230427\n",
      "Epoch: 16\tFidelity = 0.510072\tKL_Divergence = 2.317530\n",
      "Epoch: 17\tFidelity = 0.509341\tKL_Divergence = 2.359620\n",
      "Epoch: 18\tFidelity = 0.510029\tKL_Divergence = 2.319920\n",
      "Epoch: 19\tFidelity = 0.509259\tKL_Divergence = 2.364572\n",
      "Epoch: 20\tFidelity = 0.510146\tKL_Divergence = 2.313407\n",
      "Epoch: 21\tFidelity = 0.512098\tKL_Divergence = 2.214971\n",
      "Epoch: 22\tFidelity = 0.510260\tKL_Divergence = 2.307193\n",
      "Epoch: 23\tFidelity = 0.510912\tKL_Divergence = 2.272732\n",
      "Epoch: 24\tFidelity = 0.508575\tKL_Divergence = 2.407442\n",
      "Epoch: 25\tFidelity = 0.509429\tKL_Divergence = 2.354404\n",
      "Epoch: 26\tFidelity = 0.507434\tKL_Divergence = 2.487115\n",
      "Epoch: 27\tFidelity = 0.510268\tKL_Divergence = 2.306792\n",
      "Epoch: 28\tFidelity = 0.509948\tKL_Divergence = 2.324463\n",
      "Epoch: 29\tFidelity = 0.510167\tKL_Divergence = 2.312334\n",
      "Epoch: 30\tFidelity = 0.510690\tKL_Divergence = 2.284263\n",
      "Epoch: 31\tFidelity = 0.511255\tKL_Divergence = 2.255440\n",
      "Epoch: 32\tFidelity = 0.510876\tKL_Divergence = 2.274614\n",
      "Epoch: 33\tFidelity = 0.509683\tKL_Divergence = 2.339567\n",
      "Epoch: 34\tFidelity = 0.508791\tKL_Divergence = 2.393542\n",
      "Epoch: 35\tFidelity = 0.511340\tKL_Divergence = 2.251209\n",
      "Epoch: 36\tFidelity = 0.507828\tKL_Divergence = 2.458292\n",
      "Epoch: 37\tFidelity = 0.510180\tKL_Divergence = 2.311549\n",
      "Epoch: 38\tFidelity = 0.509142\tKL_Divergence = 2.371673\n",
      "Epoch: 39\tFidelity = 0.508888\tKL_Divergence = 2.387468\n",
      "Epoch: 40\tFidelity = 0.510435\tKL_Divergence = 2.297760\n",
      "Epoch: 41\tFidelity = 0.510733\tKL_Divergence = 2.282008\n",
      "Epoch: 42\tFidelity = 0.509993\tKL_Divergence = 2.322023\n",
      "Epoch: 43\tFidelity = 0.509951\tKL_Divergence = 2.324363\n",
      "Epoch: 44\tFidelity = 0.509904\tKL_Divergence = 2.326964\n",
      "Epoch: 45\tFidelity = 0.512019\tKL_Divergence = 2.218701\n",
      "Epoch: 46\tFidelity = 0.509411\tKL_Divergence = 2.355497\n",
      "Epoch: 47\tFidelity = 0.511677\tKL_Divergence = 2.234848\n",
      "Epoch: 48\tFidelity = 0.510602\tKL_Divergence = 2.288925\n",
      "Epoch: 49\tFidelity = 0.508403\tKL_Divergence = 2.418812\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:08:35,424] Trial 193 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.508802\tKL_Divergence = 2.392936\n",
      "Total time elapsed during training: 31.806 s\n",
      "Trial 193 pruned. \n",
      "Epoch: 1\tFidelity = 0.509849\tKL_Divergence = 2.330069\n",
      "Epoch: 2\tFidelity = 0.508800\tKL_Divergence = 2.393022\n",
      "Epoch: 3\tFidelity = 0.510233\tKL_Divergence = 2.308726\n",
      "Epoch: 4\tFidelity = 0.509895\tKL_Divergence = 2.327510\n",
      "Epoch: 5\tFidelity = 0.509562\tKL_Divergence = 2.346639\n",
      "Epoch: 6\tFidelity = 0.510486\tKL_Divergence = 2.295062\n",
      "Epoch: 7\tFidelity = 0.508805\tKL_Divergence = 2.392710\n",
      "Epoch: 8\tFidelity = 0.509836\tKL_Divergence = 2.330852\n",
      "Epoch: 9\tFidelity = 0.509224\tKL_Divergence = 2.366722\n",
      "Epoch: 10\tFidelity = 0.507710\tKL_Divergence = 2.466781\n",
      "Epoch: 11\tFidelity = 0.508878\tKL_Divergence = 2.388045\n",
      "Epoch: 12\tFidelity = 0.508641\tKL_Divergence = 2.403095\n",
      "Epoch: 13\tFidelity = 0.509489\tKL_Divergence = 2.350926\n",
      "Epoch: 14\tFidelity = 0.509654\tKL_Divergence = 2.341247\n",
      "Epoch: 15\tFidelity = 0.510319\tKL_Divergence = 2.304034\n",
      "Epoch: 16\tFidelity = 0.508921\tKL_Divergence = 2.385401\n",
      "Epoch: 17\tFidelity = 0.508895\tKL_Divergence = 2.387038\n",
      "Epoch: 18\tFidelity = 0.509209\tKL_Divergence = 2.367598\n",
      "Epoch: 19\tFidelity = 0.509640\tKL_Divergence = 2.342059\n",
      "Epoch: 20\tFidelity = 0.509583\tKL_Divergence = 2.345334\n",
      "Epoch: 21\tFidelity = 0.508272\tKL_Divergence = 2.427535\n",
      "Epoch: 22\tFidelity = 0.508254\tKL_Divergence = 2.428726\n",
      "Epoch: 23\tFidelity = 0.509656\tKL_Divergence = 2.341112\n",
      "Epoch: 24\tFidelity = 0.509055\tKL_Divergence = 2.377057\n",
      "Epoch: 25\tFidelity = 0.510141\tKL_Divergence = 2.313802\n",
      "Epoch: 26\tFidelity = 0.510455\tKL_Divergence = 2.296696\n",
      "Epoch: 27\tFidelity = 0.509687\tKL_Divergence = 2.339359\n",
      "Epoch: 28\tFidelity = 0.509488\tKL_Divergence = 2.350945\n",
      "Epoch: 29\tFidelity = 0.509843\tKL_Divergence = 2.330443\n",
      "Epoch: 30\tFidelity = 0.509157\tKL_Divergence = 2.370846\n",
      "Epoch: 31\tFidelity = 0.509030\tKL_Divergence = 2.378633\n",
      "Epoch: 32\tFidelity = 0.508689\tKL_Divergence = 2.400157\n",
      "Epoch: 33\tFidelity = 0.508077\tKL_Divergence = 2.440936\n",
      "Epoch: 34\tFidelity = 0.508416\tKL_Divergence = 2.417974\n",
      "Epoch: 35\tFidelity = 0.510610\tKL_Divergence = 2.288475\n",
      "Epoch: 36\tFidelity = 0.509995\tKL_Divergence = 2.321860\n",
      "Epoch: 37\tFidelity = 0.508274\tKL_Divergence = 2.427441\n",
      "Epoch: 38\tFidelity = 0.508747\tKL_Divergence = 2.396418\n",
      "Epoch: 39\tFidelity = 0.509375\tKL_Divergence = 2.357733\n",
      "Epoch: 40\tFidelity = 0.508300\tKL_Divergence = 2.425739\n",
      "Epoch: 41\tFidelity = 0.510451\tKL_Divergence = 2.296969\n",
      "Epoch: 42\tFidelity = 0.509468\tKL_Divergence = 2.352107\n",
      "Epoch: 43\tFidelity = 0.508324\tKL_Divergence = 2.424121\n",
      "Epoch: 44\tFidelity = 0.508455\tKL_Divergence = 2.415398\n",
      "Epoch: 45\tFidelity = 0.509745\tKL_Divergence = 2.336046\n",
      "Epoch: 46\tFidelity = 0.509383\tKL_Divergence = 2.357196\n",
      "Epoch: 47\tFidelity = 0.509408\tKL_Divergence = 2.355695\n",
      "Epoch: 48\tFidelity = 0.508908\tKL_Divergence = 2.386141\n",
      "Epoch: 49\tFidelity = 0.508113\tKL_Divergence = 2.438381\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:09:55,263] Trial 194 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.509313\tKL_Divergence = 2.361344\n",
      "Total time elapsed during training: 79.657 s\n",
      "Trial 194 pruned. \n",
      "Epoch: 1\tFidelity = 0.507718\tKL_Divergence = 2.466263\n",
      "Epoch: 2\tFidelity = 0.507755\tKL_Divergence = 2.463516\n",
      "Epoch: 3\tFidelity = 0.508338\tKL_Divergence = 2.423091\n",
      "Epoch: 4\tFidelity = 0.510018\tKL_Divergence = 2.320510\n",
      "Epoch: 5\tFidelity = 0.510505\tKL_Divergence = 2.293965\n",
      "Epoch: 6\tFidelity = 0.510541\tKL_Divergence = 2.292009\n",
      "Epoch: 7\tFidelity = 0.509442\tKL_Divergence = 2.353631\n",
      "Epoch: 8\tFidelity = 0.509228\tKL_Divergence = 2.366418\n",
      "Epoch: 9\tFidelity = 0.507733\tKL_Divergence = 2.465004\n",
      "Epoch: 10\tFidelity = 0.508923\tKL_Divergence = 2.385164\n",
      "Epoch: 11\tFidelity = 0.507502\tKL_Divergence = 2.481989\n",
      "Epoch: 12\tFidelity = 0.509767\tKL_Divergence = 2.334538\n",
      "Epoch: 13\tFidelity = 0.508096\tKL_Divergence = 2.439394\n",
      "Epoch: 14\tFidelity = 0.507756\tKL_Divergence = 2.463304\n",
      "Epoch: 15\tFidelity = 0.508214\tKL_Divergence = 2.431429\n",
      "Epoch: 16\tFidelity = 0.508498\tKL_Divergence = 2.412003\n",
      "Epoch: 17\tFidelity = 0.508968\tKL_Divergence = 2.382053\n",
      "Epoch: 18\tFidelity = 0.509311\tKL_Divergence = 2.360954\n",
      "Epoch: 19\tFidelity = 0.507449\tKL_Divergence = 2.485551\n",
      "Epoch: 20\tFidelity = 0.508501\tKL_Divergence = 2.411989\n",
      "Epoch: 21\tFidelity = 0.511492\tKL_Divergence = 2.243528\n",
      "Epoch: 22\tFidelity = 0.512399\tKL_Divergence = 2.201093\n",
      "Epoch: 23\tFidelity = 0.513853\tKL_Divergence = 2.138890\n",
      "Epoch: 24\tFidelity = 0.509838\tKL_Divergence = 2.330589\n",
      "Epoch: 25\tFidelity = 0.507745\tKL_Divergence = 2.464219\n",
      "Epoch: 26\tFidelity = 0.508236\tKL_Divergence = 2.429953\n",
      "Epoch: 27\tFidelity = 0.510301\tKL_Divergence = 2.304879\n",
      "Epoch: 28\tFidelity = 0.511265\tKL_Divergence = 2.254888\n",
      "Epoch: 29\tFidelity = 0.509728\tKL_Divergence = 2.336893\n",
      "Epoch: 30\tFidelity = 0.509296\tKL_Divergence = 2.362109\n",
      "Epoch: 31\tFidelity = 0.508904\tKL_Divergence = 2.386333\n",
      "Epoch: 32\tFidelity = 0.508129\tKL_Divergence = 2.437231\n",
      "Epoch: 33\tFidelity = 0.510456\tKL_Divergence = 2.296520\n",
      "Epoch: 34\tFidelity = 0.509949\tKL_Divergence = 2.324164\n",
      "Epoch: 35\tFidelity = 0.508104\tKL_Divergence = 2.438757\n",
      "Epoch: 36\tFidelity = 0.509288\tKL_Divergence = 2.362809\n",
      "Epoch: 37\tFidelity = 0.511616\tKL_Divergence = 2.237753\n",
      "Epoch: 38\tFidelity = 0.508657\tKL_Divergence = 2.402097\n",
      "Epoch: 39\tFidelity = 0.507250\tKL_Divergence = 2.501169\n",
      "Epoch: 40\tFidelity = 0.508585\tKL_Divergence = 2.406893\n",
      "Epoch: 41\tFidelity = 0.509440\tKL_Divergence = 2.353757\n",
      "Epoch: 42\tFidelity = 0.508953\tKL_Divergence = 2.383316\n",
      "Epoch: 43\tFidelity = 0.508657\tKL_Divergence = 2.402104\n",
      "Epoch: 44\tFidelity = 0.508862\tKL_Divergence = 2.388990\n",
      "Epoch: 45\tFidelity = 0.511283\tKL_Divergence = 2.254109\n",
      "Epoch: 46\tFidelity = 0.507792\tKL_Divergence = 2.460888\n",
      "Epoch: 47\tFidelity = 0.508915\tKL_Divergence = 2.385650\n",
      "Epoch: 48\tFidelity = 0.508032\tKL_Divergence = 2.443960\n",
      "Epoch: 49\tFidelity = 0.507772\tKL_Divergence = 2.462382\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:10:34,059] Trial 195 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.508202\tKL_Divergence = 2.432373\n",
      "Total time elapsed during training: 38.631 s\n",
      "Trial 195 pruned. \n",
      "Epoch: 1\tFidelity = 0.508863\tKL_Divergence = 2.389044\n",
      "Epoch: 2\tFidelity = 0.509235\tKL_Divergence = 2.366108\n",
      "Epoch: 3\tFidelity = 0.509942\tKL_Divergence = 2.324839\n",
      "Epoch: 4\tFidelity = 0.508344\tKL_Divergence = 2.422734\n",
      "Epoch: 5\tFidelity = 0.509425\tKL_Divergence = 2.354714\n",
      "Epoch: 6\tFidelity = 0.509903\tKL_Divergence = 2.327053\n",
      "Epoch: 7\tFidelity = 0.509714\tKL_Divergence = 2.337791\n",
      "Epoch: 8\tFidelity = 0.509855\tKL_Divergence = 2.329769\n",
      "Epoch: 9\tFidelity = 0.508280\tKL_Divergence = 2.427097\n",
      "Epoch: 10\tFidelity = 0.509602\tKL_Divergence = 2.344333\n",
      "Epoch: 11\tFidelity = 0.508418\tKL_Divergence = 2.417855\n",
      "Epoch: 12\tFidelity = 0.508592\tKL_Divergence = 2.406423\n",
      "Epoch: 13\tFidelity = 0.507514\tKL_Divergence = 2.481267\n",
      "Epoch: 14\tFidelity = 0.508834\tKL_Divergence = 2.390924\n",
      "Epoch: 15\tFidelity = 0.508277\tKL_Divergence = 2.427329\n",
      "Epoch: 16\tFidelity = 0.509479\tKL_Divergence = 2.351597\n",
      "Epoch: 17\tFidelity = 0.507979\tKL_Divergence = 2.447793\n",
      "Epoch: 18\tFidelity = 0.508800\tKL_Divergence = 2.393091\n",
      "Epoch: 19\tFidelity = 0.508982\tKL_Divergence = 2.381644\n",
      "Epoch: 20\tFidelity = 0.508410\tKL_Divergence = 2.418394\n",
      "Epoch: 21\tFidelity = 0.509388\tKL_Divergence = 2.356899\n",
      "Epoch: 22\tFidelity = 0.508166\tKL_Divergence = 2.434816\n",
      "Epoch: 23\tFidelity = 0.508850\tKL_Divergence = 2.389933\n",
      "Epoch: 24\tFidelity = 0.510310\tKL_Divergence = 2.304535\n",
      "Epoch: 25\tFidelity = 0.509366\tKL_Divergence = 2.358218\n",
      "Epoch: 26\tFidelity = 0.508193\tKL_Divergence = 2.432972\n",
      "Epoch: 27\tFidelity = 0.507652\tKL_Divergence = 2.471116\n",
      "Epoch: 28\tFidelity = 0.508734\tKL_Divergence = 2.397275\n",
      "Epoch: 29\tFidelity = 0.508082\tKL_Divergence = 2.440601\n",
      "Epoch: 30\tFidelity = 0.509405\tKL_Divergence = 2.355930\n",
      "Epoch: 31\tFidelity = 0.510128\tKL_Divergence = 2.314553\n",
      "Epoch: 32\tFidelity = 0.510237\tKL_Divergence = 2.308529\n",
      "Epoch: 33\tFidelity = 0.507759\tKL_Divergence = 2.463402\n",
      "Epoch: 34\tFidelity = 0.508242\tKL_Divergence = 2.429654\n",
      "Epoch: 35\tFidelity = 0.508161\tKL_Divergence = 2.435173\n",
      "Epoch: 36\tFidelity = 0.508764\tKL_Divergence = 2.395394\n",
      "Epoch: 37\tFidelity = 0.508618\tKL_Divergence = 2.404802\n",
      "Epoch: 38\tFidelity = 0.508997\tKL_Divergence = 2.380774\n",
      "Epoch: 39\tFidelity = 0.509296\tKL_Divergence = 2.362475\n",
      "Epoch: 40\tFidelity = 0.508440\tKL_Divergence = 2.416475\n",
      "Epoch: 41\tFidelity = 0.508854\tKL_Divergence = 2.389700\n",
      "Epoch: 42\tFidelity = 0.507981\tKL_Divergence = 2.447690\n",
      "Epoch: 43\tFidelity = 0.508251\tKL_Divergence = 2.429097\n",
      "Epoch: 44\tFidelity = 0.509328\tKL_Divergence = 2.360554\n",
      "Epoch: 45\tFidelity = 0.508147\tKL_Divergence = 2.436144\n",
      "Epoch: 46\tFidelity = 0.508074\tKL_Divergence = 2.441154\n",
      "Epoch: 47\tFidelity = 0.509539\tKL_Divergence = 2.348015\n",
      "Epoch: 48\tFidelity = 0.509289\tKL_Divergence = 2.362852\n",
      "Epoch: 49\tFidelity = 0.508517\tKL_Divergence = 2.411342\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:11:12,416] Trial 196 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.508922\tKL_Divergence = 2.385394\n",
      "Total time elapsed during training: 38.202 s\n",
      "Trial 196 pruned. \n",
      "Epoch: 1\tFidelity = 0.507088\tKL_Divergence = 2.513486\n",
      "Epoch: 2\tFidelity = 0.507902\tKL_Divergence = 2.453048\n",
      "Epoch: 3\tFidelity = 0.506689\tKL_Divergence = 2.545970\n",
      "Epoch: 4\tFidelity = 0.506903\tKL_Divergence = 2.528615\n",
      "Epoch: 5\tFidelity = 0.509196\tKL_Divergence = 2.368482\n",
      "Epoch: 6\tFidelity = 0.510552\tKL_Divergence = 2.291572\n",
      "Epoch: 7\tFidelity = 0.505350\tKL_Divergence = 2.670620\n",
      "Epoch: 8\tFidelity = 0.512907\tKL_Divergence = 2.178555\n",
      "Epoch: 9\tFidelity = 0.508333\tKL_Divergence = 2.423451\n",
      "Epoch: 10\tFidelity = 0.510577\tKL_Divergence = 2.290305\n",
      "Epoch: 11\tFidelity = 0.508078\tKL_Divergence = 2.440952\n",
      "Epoch: 12\tFidelity = 0.507878\tKL_Divergence = 2.454253\n",
      "Epoch: 13\tFidelity = 0.506978\tKL_Divergence = 2.522133\n",
      "Epoch: 14\tFidelity = 0.509941\tKL_Divergence = 2.324960\n",
      "Epoch: 15\tFidelity = 0.511418\tKL_Divergence = 2.247388\n",
      "Epoch: 16\tFidelity = 0.510439\tKL_Divergence = 2.297313\n",
      "Epoch: 17\tFidelity = 0.512263\tKL_Divergence = 2.207233\n",
      "Epoch: 18\tFidelity = 0.506777\tKL_Divergence = 2.538825\n",
      "Epoch: 19\tFidelity = 0.507516\tKL_Divergence = 2.480878\n",
      "Epoch: 20\tFidelity = 0.507794\tKL_Divergence = 2.460636\n",
      "Epoch: 21\tFidelity = 0.512158\tKL_Divergence = 2.212296\n",
      "Epoch: 22\tFidelity = 0.508055\tKL_Divergence = 2.442531\n",
      "Epoch: 23\tFidelity = 0.508345\tKL_Divergence = 2.422064\n",
      "Epoch: 24\tFidelity = 0.507258\tKL_Divergence = 2.500674\n",
      "Epoch: 25\tFidelity = 0.507316\tKL_Divergence = 2.496132\n",
      "Epoch: 26\tFidelity = 0.512204\tKL_Divergence = 2.210084\n",
      "Epoch: 27\tFidelity = 0.509500\tKL_Divergence = 2.350383\n",
      "Epoch: 28\tFidelity = 0.505990\tKL_Divergence = 2.607596\n",
      "Epoch: 29\tFidelity = 0.510029\tKL_Divergence = 2.320082\n",
      "Epoch: 30\tFidelity = 0.508793\tKL_Divergence = 2.393567\n",
      "Epoch: 31\tFidelity = 0.507693\tKL_Divergence = 2.468168\n",
      "Epoch: 32\tFidelity = 0.510417\tKL_Divergence = 2.298803\n",
      "Epoch: 33\tFidelity = 0.509841\tKL_Divergence = 2.330498\n",
      "Epoch: 34\tFidelity = 0.508513\tKL_Divergence = 2.411694\n",
      "Epoch: 35\tFidelity = 0.507696\tKL_Divergence = 2.468048\n",
      "Epoch: 36\tFidelity = 0.508534\tKL_Divergence = 2.410093\n",
      "Epoch: 37\tFidelity = 0.510831\tKL_Divergence = 2.277136\n",
      "Epoch: 38\tFidelity = 0.506362\tKL_Divergence = 2.573911\n",
      "Epoch: 39\tFidelity = 0.510892\tKL_Divergence = 2.273947\n",
      "Epoch: 40\tFidelity = 0.509020\tKL_Divergence = 2.379267\n",
      "Epoch: 41\tFidelity = 0.509948\tKL_Divergence = 2.324069\n",
      "Epoch: 42\tFidelity = 0.508165\tKL_Divergence = 2.435020\n",
      "Epoch: 43\tFidelity = 0.507228\tKL_Divergence = 2.503037\n",
      "Epoch: 44\tFidelity = 0.508711\tKL_Divergence = 2.398331\n",
      "Epoch: 45\tFidelity = 0.508187\tKL_Divergence = 2.431020\n",
      "Epoch: 46\tFidelity = 0.509849\tKL_Divergence = 2.329559\n",
      "Epoch: 47\tFidelity = 0.506045\tKL_Divergence = 2.601926\n",
      "Epoch: 48\tFidelity = 0.509842\tKL_Divergence = 2.330620\n",
      "Epoch: 49\tFidelity = 0.507782\tKL_Divergence = 2.461652\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:12:10,804] Trial 197 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.509963\tKL_Divergence = 2.323348\n",
      "Total time elapsed during training: 58.241 s\n",
      "Trial 197 pruned. \n",
      "Epoch: 1\tFidelity = 0.508735\tKL_Divergence = 2.396928\n",
      "Epoch: 2\tFidelity = 0.508793\tKL_Divergence = 2.393304\n",
      "Epoch: 3\tFidelity = 0.509128\tKL_Divergence = 2.372445\n",
      "Epoch: 4\tFidelity = 0.508591\tKL_Divergence = 2.406331\n",
      "Epoch: 5\tFidelity = 0.509157\tKL_Divergence = 2.370737\n",
      "Epoch: 6\tFidelity = 0.509122\tKL_Divergence = 2.372926\n",
      "Epoch: 7\tFidelity = 0.508282\tKL_Divergence = 2.426900\n",
      "Epoch: 8\tFidelity = 0.509042\tKL_Divergence = 2.377871\n",
      "Epoch: 9\tFidelity = 0.508809\tKL_Divergence = 2.392451\n",
      "Epoch: 10\tFidelity = 0.508367\tKL_Divergence = 2.421268\n",
      "Epoch: 11\tFidelity = 0.509446\tKL_Divergence = 2.353516\n",
      "Epoch: 12\tFidelity = 0.509041\tKL_Divergence = 2.378004\n",
      "Epoch: 13\tFidelity = 0.509026\tKL_Divergence = 2.378939\n",
      "Epoch: 14\tFidelity = 0.508368\tKL_Divergence = 2.421206\n",
      "Epoch: 15\tFidelity = 0.508619\tKL_Divergence = 2.404717\n",
      "Epoch: 16\tFidelity = 0.509118\tKL_Divergence = 2.373323\n",
      "Epoch: 17\tFidelity = 0.508684\tKL_Divergence = 2.400572\n",
      "Epoch: 18\tFidelity = 0.509146\tKL_Divergence = 2.371579\n",
      "Epoch: 19\tFidelity = 0.508728\tKL_Divergence = 2.397723\n",
      "Epoch: 20\tFidelity = 0.509180\tKL_Divergence = 2.369544\n",
      "Epoch: 21\tFidelity = 0.508074\tKL_Divergence = 2.441252\n",
      "Epoch: 22\tFidelity = 0.508857\tKL_Divergence = 2.389574\n",
      "Epoch: 23\tFidelity = 0.508952\tKL_Divergence = 2.383606\n",
      "Epoch: 24\tFidelity = 0.508205\tKL_Divergence = 2.432229\n",
      "Epoch: 25\tFidelity = 0.508874\tKL_Divergence = 2.388490\n",
      "Epoch: 26\tFidelity = 0.508197\tKL_Divergence = 2.432827\n",
      "Epoch: 27\tFidelity = 0.508184\tKL_Divergence = 2.433693\n",
      "Epoch: 28\tFidelity = 0.508604\tKL_Divergence = 2.405763\n",
      "Epoch: 29\tFidelity = 0.508868\tKL_Divergence = 2.388879\n",
      "Epoch: 30\tFidelity = 0.508328\tKL_Divergence = 2.423972\n",
      "Epoch: 31\tFidelity = 0.509016\tKL_Divergence = 2.379640\n",
      "Epoch: 32\tFidelity = 0.508268\tKL_Divergence = 2.428037\n",
      "Epoch: 33\tFidelity = 0.508602\tKL_Divergence = 2.405880\n",
      "Epoch: 34\tFidelity = 0.508723\tKL_Divergence = 2.398070\n",
      "Epoch: 35\tFidelity = 0.508876\tKL_Divergence = 2.388398\n",
      "Epoch: 36\tFidelity = 0.508452\tKL_Divergence = 2.415727\n",
      "Epoch: 37\tFidelity = 0.508602\tKL_Divergence = 2.405942\n",
      "Epoch: 38\tFidelity = 0.508087\tKL_Divergence = 2.440353\n",
      "Epoch: 39\tFidelity = 0.508289\tKL_Divergence = 2.426584\n",
      "Epoch: 40\tFidelity = 0.508840\tKL_Divergence = 2.390667\n",
      "Epoch: 41\tFidelity = 0.508381\tKL_Divergence = 2.420455\n",
      "Epoch: 42\tFidelity = 0.508429\tKL_Divergence = 2.417263\n",
      "Epoch: 43\tFidelity = 0.508093\tKL_Divergence = 2.439944\n",
      "Epoch: 44\tFidelity = 0.508731\tKL_Divergence = 2.397586\n",
      "Epoch: 45\tFidelity = 0.507887\tKL_Divergence = 2.454359\n",
      "Epoch: 46\tFidelity = 0.509259\tKL_Divergence = 2.364792\n",
      "Epoch: 47\tFidelity = 0.507870\tKL_Divergence = 2.455534\n",
      "Epoch: 48\tFidelity = 0.508507\tKL_Divergence = 2.412111\n",
      "Epoch: 49\tFidelity = 0.508191\tKL_Divergence = 2.433230\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:12:42,884] Trial 198 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.508122\tKL_Divergence = 2.437929\n",
      "Total time elapsed during training: 31.929 s\n",
      "Trial 198 pruned. \n",
      "Epoch: 1\tFidelity = 0.508653\tKL_Divergence = 2.402591\n",
      "Epoch: 2\tFidelity = 0.509262\tKL_Divergence = 2.364608\n",
      "Epoch: 3\tFidelity = 0.507370\tKL_Divergence = 2.492154\n",
      "Epoch: 4\tFidelity = 0.508610\tKL_Divergence = 2.405371\n",
      "Epoch: 5\tFidelity = 0.508622\tKL_Divergence = 2.404596\n",
      "Epoch: 6\tFidelity = 0.508236\tKL_Divergence = 2.430145\n",
      "Epoch: 7\tFidelity = 0.509240\tKL_Divergence = 2.365926\n",
      "Epoch: 8\tFidelity = 0.509533\tKL_Divergence = 2.348486\n",
      "Epoch: 9\tFidelity = 0.508580\tKL_Divergence = 2.407289\n",
      "Epoch: 10\tFidelity = 0.507520\tKL_Divergence = 2.480912\n",
      "Epoch: 11\tFidelity = 0.509427\tKL_Divergence = 2.354729\n",
      "Epoch: 12\tFidelity = 0.508498\tKL_Divergence = 2.412708\n",
      "Epoch: 13\tFidelity = 0.508473\tKL_Divergence = 2.414317\n",
      "Epoch: 14\tFidelity = 0.507942\tKL_Divergence = 2.450441\n",
      "Epoch: 15\tFidelity = 0.508228\tKL_Divergence = 2.430772\n",
      "Epoch: 16\tFidelity = 0.508113\tKL_Divergence = 2.438584\n",
      "Epoch: 17\tFidelity = 0.508108\tKL_Divergence = 2.438937\n",
      "Epoch: 18\tFidelity = 0.508653\tKL_Divergence = 2.402626\n",
      "Epoch: 19\tFidelity = 0.508365\tKL_Divergence = 2.421527\n",
      "Epoch: 20\tFidelity = 0.508006\tKL_Divergence = 2.445999\n",
      "Epoch: 21\tFidelity = 0.508973\tKL_Divergence = 2.382336\n",
      "Epoch: 22\tFidelity = 0.508037\tKL_Divergence = 2.443870\n",
      "Epoch: 23\tFidelity = 0.507979\tKL_Divergence = 2.447877\n",
      "Epoch: 24\tFidelity = 0.509189\tKL_Divergence = 2.369075\n",
      "Epoch: 25\tFidelity = 0.508426\tKL_Divergence = 2.417457\n",
      "Epoch: 26\tFidelity = 0.507968\tKL_Divergence = 2.448655\n",
      "Epoch: 27\tFidelity = 0.507907\tKL_Divergence = 2.452954\n",
      "Epoch: 28\tFidelity = 0.508305\tKL_Divergence = 2.425543\n",
      "Epoch: 29\tFidelity = 0.509469\tKL_Divergence = 2.352272\n",
      "Epoch: 30\tFidelity = 0.507939\tKL_Divergence = 2.450694\n",
      "Epoch: 31\tFidelity = 0.507948\tKL_Divergence = 2.450077\n",
      "Epoch: 32\tFidelity = 0.509120\tKL_Divergence = 2.373249\n",
      "Epoch: 33\tFidelity = 0.508397\tKL_Divergence = 2.419379\n",
      "Epoch: 34\tFidelity = 0.507591\tKL_Divergence = 2.475661\n",
      "Epoch: 35\tFidelity = 0.508246\tKL_Divergence = 2.429488\n",
      "Epoch: 36\tFidelity = 0.507834\tKL_Divergence = 2.458109\n",
      "Epoch: 37\tFidelity = 0.507857\tKL_Divergence = 2.456501\n",
      "Epoch: 38\tFidelity = 0.508555\tKL_Divergence = 2.408959\n",
      "Epoch: 39\tFidelity = 0.507980\tKL_Divergence = 2.447799\n",
      "Epoch: 40\tFidelity = 0.508559\tKL_Divergence = 2.408689\n",
      "Epoch: 41\tFidelity = 0.507036\tKL_Divergence = 2.518016\n",
      "Epoch: 42\tFidelity = 0.509128\tKL_Divergence = 2.372746\n",
      "Epoch: 43\tFidelity = 0.508900\tKL_Divergence = 2.386849\n",
      "Epoch: 44\tFidelity = 0.507906\tKL_Divergence = 2.453028\n",
      "Epoch: 45\tFidelity = 0.508735\tKL_Divergence = 2.397286\n",
      "Epoch: 46\tFidelity = 0.508735\tKL_Divergence = 2.397345\n",
      "Epoch: 47\tFidelity = 0.509153\tKL_Divergence = 2.371196\n",
      "Epoch: 48\tFidelity = 0.508481\tKL_Divergence = 2.413794\n",
      "Epoch: 49\tFidelity = 0.508695\tKL_Divergence = 2.399879\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:13:29,137] Trial 199 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.509024\tKL_Divergence = 2.379132\n",
      "Total time elapsed during training: 46.096 s\n",
      "Trial 199 pruned. \n",
      "Epoch: 1\tFidelity = 0.509050\tKL_Divergence = 2.377512\n",
      "Epoch: 2\tFidelity = 0.509564\tKL_Divergence = 2.346617\n",
      "Epoch: 3\tFidelity = 0.508505\tKL_Divergence = 2.412120\n",
      "Epoch: 4\tFidelity = 0.508926\tKL_Divergence = 2.385119\n",
      "Epoch: 5\tFidelity = 0.508958\tKL_Divergence = 2.383138\n",
      "Epoch: 6\tFidelity = 0.508985\tKL_Divergence = 2.381530\n",
      "Epoch: 7\tFidelity = 0.508510\tKL_Divergence = 2.411919\n",
      "Epoch: 8\tFidelity = 0.508895\tKL_Divergence = 2.387223\n",
      "Epoch: 9\tFidelity = 0.508194\tKL_Divergence = 2.433056\n",
      "Epoch: 10\tFidelity = 0.508016\tKL_Divergence = 2.445279\n",
      "Epoch: 11\tFidelity = 0.509040\tKL_Divergence = 2.378140\n",
      "Epoch: 12\tFidelity = 0.509239\tKL_Divergence = 2.365852\n",
      "Epoch: 13\tFidelity = 0.510060\tKL_Divergence = 2.318342\n",
      "Epoch: 14\tFidelity = 0.509311\tKL_Divergence = 2.361615\n",
      "Epoch: 15\tFidelity = 0.509967\tKL_Divergence = 2.323562\n",
      "Epoch: 16\tFidelity = 0.508975\tKL_Divergence = 2.382203\n",
      "Epoch: 17\tFidelity = 0.509210\tKL_Divergence = 2.367755\n",
      "Epoch: 18\tFidelity = 0.508862\tKL_Divergence = 2.389221\n",
      "Epoch: 19\tFidelity = 0.507793\tKL_Divergence = 2.460987\n",
      "Epoch: 20\tFidelity = 0.509217\tKL_Divergence = 2.367071\n",
      "Epoch: 21\tFidelity = 0.509127\tKL_Divergence = 2.372444\n",
      "Epoch: 22\tFidelity = 0.508676\tKL_Divergence = 2.400707\n",
      "Epoch: 23\tFidelity = 0.508627\tKL_Divergence = 2.403852\n",
      "Epoch: 24\tFidelity = 0.509773\tKL_Divergence = 2.334374\n",
      "Epoch: 25\tFidelity = 0.508494\tKL_Divergence = 2.412839\n",
      "Epoch: 26\tFidelity = 0.508347\tKL_Divergence = 2.422438\n",
      "Epoch: 27\tFidelity = 0.508453\tKL_Divergence = 2.415473\n",
      "Epoch: 28\tFidelity = 0.507684\tKL_Divergence = 2.468788\n",
      "Epoch: 29\tFidelity = 0.507943\tKL_Divergence = 2.450362\n",
      "Epoch: 30\tFidelity = 0.507776\tKL_Divergence = 2.462241\n",
      "Epoch: 31\tFidelity = 0.508189\tKL_Divergence = 2.433385\n",
      "Epoch: 32\tFidelity = 0.508455\tKL_Divergence = 2.415539\n",
      "Epoch: 33\tFidelity = 0.508506\tKL_Divergence = 2.412142\n",
      "Epoch: 34\tFidelity = 0.508994\tKL_Divergence = 2.381009\n",
      "Epoch: 35\tFidelity = 0.508127\tKL_Divergence = 2.437617\n",
      "Epoch: 36\tFidelity = 0.508603\tKL_Divergence = 2.405850\n",
      "Epoch: 37\tFidelity = 0.509331\tKL_Divergence = 2.360420\n",
      "Epoch: 38\tFidelity = 0.507605\tKL_Divergence = 2.474689\n",
      "Epoch: 39\tFidelity = 0.507990\tKL_Divergence = 2.447103\n",
      "Epoch: 40\tFidelity = 0.509167\tKL_Divergence = 2.370262\n",
      "Epoch: 41\tFidelity = 0.508679\tKL_Divergence = 2.400768\n",
      "Epoch: 42\tFidelity = 0.509507\tKL_Divergence = 2.349563\n",
      "Epoch: 43\tFidelity = 0.507907\tKL_Divergence = 2.452380\n",
      "Epoch: 44\tFidelity = 0.508363\tKL_Divergence = 2.420989\n",
      "Epoch: 45\tFidelity = 0.507736\tKL_Divergence = 2.464298\n",
      "Epoch: 46\tFidelity = 0.508071\tKL_Divergence = 2.441155\n",
      "Epoch: 47\tFidelity = 0.507831\tKL_Divergence = 2.458003\n",
      "Epoch: 48\tFidelity = 0.508702\tKL_Divergence = 2.399191\n",
      "Epoch: 49\tFidelity = 0.508268\tKL_Divergence = 2.427482\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:14:06,695] Trial 200 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.508858\tKL_Divergence = 2.389326\n",
      "Total time elapsed during training: 37.399 s\n",
      "Trial 200 pruned. \n",
      "Epoch: 1\tFidelity = 0.508260\tKL_Divergence = 2.428575\n",
      "Epoch: 2\tFidelity = 0.507499\tKL_Divergence = 2.482459\n",
      "Epoch: 3\tFidelity = 0.510099\tKL_Divergence = 2.316173\n",
      "Epoch: 4\tFidelity = 0.508888\tKL_Divergence = 2.387570\n",
      "Epoch: 5\tFidelity = 0.507539\tKL_Divergence = 2.479387\n",
      "Epoch: 6\tFidelity = 0.509091\tKL_Divergence = 2.374560\n",
      "Epoch: 7\tFidelity = 0.509389\tKL_Divergence = 2.356170\n",
      "Epoch: 8\tFidelity = 0.508657\tKL_Divergence = 2.401493\n",
      "Epoch: 9\tFidelity = 0.509447\tKL_Divergence = 2.352082\n",
      "Epoch: 10\tFidelity = 0.510044\tKL_Divergence = 2.318602\n",
      "Epoch: 11\tFidelity = 0.507205\tKL_Divergence = 2.504246\n",
      "Epoch: 12\tFidelity = 0.509444\tKL_Divergence = 2.353252\n",
      "Epoch: 13\tFidelity = 0.509991\tKL_Divergence = 2.321740\n",
      "Epoch: 14\tFidelity = 0.507623\tKL_Divergence = 2.472488\n",
      "Epoch: 15\tFidelity = 0.507676\tKL_Divergence = 2.469078\n",
      "Epoch: 16\tFidelity = 0.508003\tKL_Divergence = 2.445999\n",
      "Epoch: 17\tFidelity = 0.507480\tKL_Divergence = 2.483888\n",
      "Epoch: 18\tFidelity = 0.507820\tKL_Divergence = 2.458966\n",
      "Epoch: 19\tFidelity = 0.509648\tKL_Divergence = 2.341574\n",
      "Epoch: 20\tFidelity = 0.509337\tKL_Divergence = 2.359942\n",
      "Epoch: 21\tFidelity = 0.509654\tKL_Divergence = 2.341368\n",
      "Epoch: 22\tFidelity = 0.510593\tKL_Divergence = 2.289513\n",
      "Epoch: 23\tFidelity = 0.509155\tKL_Divergence = 2.371016\n",
      "Epoch: 24\tFidelity = 0.509989\tKL_Divergence = 2.322325\n",
      "Epoch: 25\tFidelity = 0.508022\tKL_Divergence = 2.444876\n",
      "Epoch: 26\tFidelity = 0.508377\tKL_Divergence = 2.420673\n",
      "Epoch: 27\tFidelity = 0.509167\tKL_Divergence = 2.370250\n",
      "Epoch: 28\tFidelity = 0.507190\tKL_Divergence = 2.505970\n",
      "Epoch: 29\tFidelity = 0.508263\tKL_Divergence = 2.428343\n",
      "Epoch: 30\tFidelity = 0.508924\tKL_Divergence = 2.385333\n",
      "Epoch: 31\tFidelity = 0.507745\tKL_Divergence = 2.464247\n",
      "Epoch: 32\tFidelity = 0.507555\tKL_Divergence = 2.478234\n",
      "Epoch: 33\tFidelity = 0.507006\tKL_Divergence = 2.520415\n",
      "Epoch: 34\tFidelity = 0.507347\tKL_Divergence = 2.493870\n",
      "Epoch: 35\tFidelity = 0.507480\tKL_Divergence = 2.483927\n",
      "Epoch: 36\tFidelity = 0.510164\tKL_Divergence = 2.312660\n",
      "Epoch: 37\tFidelity = 0.506539\tKL_Divergence = 2.558880\n",
      "Epoch: 38\tFidelity = 0.506985\tKL_Divergence = 2.522063\n",
      "Epoch: 39\tFidelity = 0.508163\tKL_Divergence = 2.435171\n",
      "Epoch: 40\tFidelity = 0.508958\tKL_Divergence = 2.383225\n",
      "Epoch: 41\tFidelity = 0.507727\tKL_Divergence = 2.465737\n",
      "Epoch: 42\tFidelity = 0.507716\tKL_Divergence = 2.466426\n",
      "Epoch: 43\tFidelity = 0.507104\tKL_Divergence = 2.512661\n",
      "Epoch: 44\tFidelity = 0.508404\tKL_Divergence = 2.418894\n",
      "Epoch: 45\tFidelity = 0.506792\tKL_Divergence = 2.537770\n",
      "Epoch: 46\tFidelity = 0.509103\tKL_Divergence = 2.374075\n",
      "Epoch: 47\tFidelity = 0.508439\tKL_Divergence = 2.416329\n",
      "Epoch: 48\tFidelity = 0.508431\tKL_Divergence = 2.416638\n",
      "Epoch: 49\tFidelity = 0.509513\tKL_Divergence = 2.349403\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:14:44,178] Trial 201 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.508099\tKL_Divergence = 2.439404\n",
      "Total time elapsed during training: 37.326 s\n",
      "Trial 201 pruned. \n",
      "Epoch: 1\tFidelity = 0.508953\tKL_Divergence = 2.383230\n",
      "Epoch: 2\tFidelity = 0.507271\tKL_Divergence = 2.499424\n",
      "Epoch: 3\tFidelity = 0.509393\tKL_Divergence = 2.356678\n",
      "Epoch: 4\tFidelity = 0.509866\tKL_Divergence = 2.328199\n",
      "Epoch: 5\tFidelity = 0.510070\tKL_Divergence = 2.317616\n",
      "Epoch: 6\tFidelity = 0.510187\tKL_Divergence = 2.311307\n",
      "Epoch: 7\tFidelity = 0.508968\tKL_Divergence = 2.382607\n",
      "Epoch: 8\tFidelity = 0.509605\tKL_Divergence = 2.344257\n",
      "Epoch: 9\tFidelity = 0.509109\tKL_Divergence = 2.373917\n",
      "Epoch: 10\tFidelity = 0.506688\tKL_Divergence = 2.546304\n",
      "Epoch: 11\tFidelity = 0.508252\tKL_Divergence = 2.428771\n",
      "Epoch: 12\tFidelity = 0.508507\tKL_Divergence = 2.411660\n",
      "Epoch: 13\tFidelity = 0.508846\tKL_Divergence = 2.390243\n",
      "Epoch: 14\tFidelity = 0.508736\tKL_Divergence = 2.397233\n",
      "Epoch: 15\tFidelity = 0.506840\tKL_Divergence = 2.533768\n",
      "Epoch: 16\tFidelity = 0.507778\tKL_Divergence = 2.461941\n",
      "Epoch: 17\tFidelity = 0.510259\tKL_Divergence = 2.306280\n",
      "Epoch: 18\tFidelity = 0.506595\tKL_Divergence = 2.552214\n",
      "Epoch: 19\tFidelity = 0.508161\tKL_Divergence = 2.433829\n",
      "Epoch: 20\tFidelity = 0.506749\tKL_Divergence = 2.540491\n",
      "Epoch: 21\tFidelity = 0.509145\tKL_Divergence = 2.370963\n",
      "Epoch: 22\tFidelity = 0.509059\tKL_Divergence = 2.376638\n",
      "Epoch: 23\tFidelity = 0.507161\tKL_Divergence = 2.508188\n",
      "Epoch: 24\tFidelity = 0.506585\tKL_Divergence = 2.554915\n",
      "Epoch: 25\tFidelity = 0.508311\tKL_Divergence = 2.425021\n",
      "Epoch: 26\tFidelity = 0.510366\tKL_Divergence = 2.301606\n",
      "Epoch: 27\tFidelity = 0.509398\tKL_Divergence = 2.356302\n",
      "Epoch: 28\tFidelity = 0.510306\tKL_Divergence = 2.304776\n",
      "Epoch: 29\tFidelity = 0.509648\tKL_Divergence = 2.341574\n",
      "Epoch: 30\tFidelity = 0.508659\tKL_Divergence = 2.401127\n",
      "Epoch: 31\tFidelity = 0.506799\tKL_Divergence = 2.535557\n",
      "Epoch: 32\tFidelity = 0.509125\tKL_Divergence = 2.372343\n",
      "Epoch: 33\tFidelity = 0.508794\tKL_Divergence = 2.393550\n",
      "Epoch: 34\tFidelity = 0.509210\tKL_Divergence = 2.367273\n",
      "Epoch: 35\tFidelity = 0.509587\tKL_Divergence = 2.345320\n",
      "Epoch: 36\tFidelity = 0.508626\tKL_Divergence = 2.404334\n",
      "Epoch: 37\tFidelity = 0.508391\tKL_Divergence = 2.419756\n",
      "Epoch: 38\tFidelity = 0.509532\tKL_Divergence = 2.347828\n",
      "Epoch: 39\tFidelity = 0.507278\tKL_Divergence = 2.498805\n",
      "Epoch: 40\tFidelity = 0.506500\tKL_Divergence = 2.562112\n",
      "Epoch: 41\tFidelity = 0.508581\tKL_Divergence = 2.407202\n",
      "Epoch: 42\tFidelity = 0.509689\tKL_Divergence = 2.339343\n",
      "Epoch: 43\tFidelity = 0.509747\tKL_Divergence = 2.335925\n",
      "Epoch: 44\tFidelity = 0.509447\tKL_Divergence = 2.353467\n",
      "Epoch: 45\tFidelity = 0.509305\tKL_Divergence = 2.361813\n",
      "Epoch: 46\tFidelity = 0.507876\tKL_Divergence = 2.455060\n",
      "Epoch: 47\tFidelity = 0.507323\tKL_Divergence = 2.495731\n",
      "Epoch: 48\tFidelity = 0.507435\tKL_Divergence = 2.487115\n",
      "Epoch: 49\tFidelity = 0.509055\tKL_Divergence = 2.376774\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:15:22,188] Trial 202 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.508655\tKL_Divergence = 2.401207\n",
      "Total time elapsed during training: 37.857 s\n",
      "Trial 202 pruned. \n",
      "Epoch: 1\tFidelity = 0.509240\tKL_Divergence = 2.365387\n",
      "Epoch: 2\tFidelity = 0.508944\tKL_Divergence = 2.384003\n",
      "Epoch: 3\tFidelity = 0.507313\tKL_Divergence = 2.496488\n",
      "Epoch: 4\tFidelity = 0.508321\tKL_Divergence = 2.424328\n",
      "Epoch: 5\tFidelity = 0.507160\tKL_Divergence = 2.508091\n",
      "Epoch: 6\tFidelity = 0.508678\tKL_Divergence = 2.400484\n",
      "Epoch: 7\tFidelity = 0.508706\tKL_Divergence = 2.399030\n",
      "Epoch: 8\tFidelity = 0.508498\tKL_Divergence = 2.412311\n",
      "Epoch: 9\tFidelity = 0.507947\tKL_Divergence = 2.449571\n",
      "Epoch: 10\tFidelity = 0.507357\tKL_Divergence = 2.492476\n",
      "Epoch: 11\tFidelity = 0.509385\tKL_Divergence = 2.356994\n",
      "Epoch: 12\tFidelity = 0.509761\tKL_Divergence = 2.334823\n",
      "Epoch: 13\tFidelity = 0.506415\tKL_Divergence = 2.569098\n",
      "Epoch: 14\tFidelity = 0.509584\tKL_Divergence = 2.345266\n",
      "Epoch: 15\tFidelity = 0.507734\tKL_Divergence = 2.465144\n",
      "Epoch: 16\tFidelity = 0.507274\tKL_Divergence = 2.499316\n",
      "Epoch: 17\tFidelity = 0.507265\tKL_Divergence = 2.500061\n",
      "Epoch: 18\tFidelity = 0.507110\tKL_Divergence = 2.511997\n",
      "Epoch: 19\tFidelity = 0.508423\tKL_Divergence = 2.417543\n",
      "Epoch: 20\tFidelity = 0.508564\tKL_Divergence = 2.408357\n",
      "Epoch: 21\tFidelity = 0.508687\tKL_Divergence = 2.400239\n",
      "Epoch: 22\tFidelity = 0.507459\tKL_Divergence = 2.485367\n",
      "Epoch: 23\tFidelity = 0.508038\tKL_Divergence = 2.443463\n",
      "Epoch: 24\tFidelity = 0.507636\tKL_Divergence = 2.472302\n",
      "Epoch: 25\tFidelity = 0.508768\tKL_Divergence = 2.395033\n",
      "Epoch: 26\tFidelity = 0.509338\tKL_Divergence = 2.359720\n",
      "Epoch: 27\tFidelity = 0.509254\tKL_Divergence = 2.364628\n",
      "Epoch: 28\tFidelity = 0.506564\tKL_Divergence = 2.556413\n",
      "Epoch: 29\tFidelity = 0.508617\tKL_Divergence = 2.404818\n",
      "Epoch: 30\tFidelity = 0.508239\tKL_Divergence = 2.429978\n",
      "Epoch: 31\tFidelity = 0.510213\tKL_Divergence = 2.309967\n",
      "Epoch: 32\tFidelity = 0.507714\tKL_Divergence = 2.466732\n",
      "Epoch: 33\tFidelity = 0.509058\tKL_Divergence = 2.376961\n",
      "Epoch: 34\tFidelity = 0.507862\tKL_Divergence = 2.455765\n",
      "Epoch: 35\tFidelity = 0.507212\tKL_Divergence = 2.504219\n",
      "Epoch: 36\tFidelity = 0.507231\tKL_Divergence = 2.502525\n",
      "Epoch: 37\tFidelity = 0.508258\tKL_Divergence = 2.428623\n",
      "Epoch: 38\tFidelity = 0.507629\tKL_Divergence = 2.472891\n",
      "Epoch: 39\tFidelity = 0.507378\tKL_Divergence = 2.491565\n",
      "Epoch: 40\tFidelity = 0.508248\tKL_Divergence = 2.429328\n",
      "Epoch: 41\tFidelity = 0.509084\tKL_Divergence = 2.375450\n",
      "Epoch: 42\tFidelity = 0.508656\tKL_Divergence = 2.402374\n",
      "Epoch: 43\tFidelity = 0.507232\tKL_Divergence = 2.502598\n",
      "Epoch: 44\tFidelity = 0.508925\tKL_Divergence = 2.385345\n",
      "Epoch: 45\tFidelity = 0.508745\tKL_Divergence = 2.396658\n",
      "Epoch: 46\tFidelity = 0.508183\tKL_Divergence = 2.433740\n",
      "Epoch: 47\tFidelity = 0.508011\tKL_Divergence = 2.445627\n",
      "Epoch: 48\tFidelity = 0.508930\tKL_Divergence = 2.385035\n",
      "Epoch: 49\tFidelity = 0.507031\tKL_Divergence = 2.518432\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:15:59,853] Trial 203 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.509308\tKL_Divergence = 2.361835\n",
      "Total time elapsed during training: 37.512 s\n",
      "Trial 203 pruned. \n",
      "Epoch: 1\tFidelity = 0.508017\tKL_Divergence = 2.445208\n",
      "Epoch: 2\tFidelity = 0.509249\tKL_Divergence = 2.365362\n",
      "Epoch: 3\tFidelity = 0.507436\tKL_Divergence = 2.487251\n",
      "Epoch: 4\tFidelity = 0.507317\tKL_Divergence = 2.496265\n",
      "Epoch: 5\tFidelity = 0.508393\tKL_Divergence = 2.419664\n",
      "Epoch: 6\tFidelity = 0.508031\tKL_Divergence = 2.444243\n",
      "Epoch: 7\tFidelity = 0.507547\tKL_Divergence = 2.479007\n",
      "Epoch: 8\tFidelity = 0.507726\tKL_Divergence = 2.465884\n",
      "Epoch: 9\tFidelity = 0.509265\tKL_Divergence = 2.364387\n",
      "Epoch: 10\tFidelity = 0.506903\tKL_Divergence = 2.528674\n",
      "Epoch: 11\tFidelity = 0.508663\tKL_Divergence = 2.401886\n",
      "Epoch: 12\tFidelity = 0.508717\tKL_Divergence = 2.398404\n",
      "Epoch: 13\tFidelity = 0.507602\tKL_Divergence = 2.474936\n",
      "Epoch: 14\tFidelity = 0.508496\tKL_Divergence = 2.412831\n",
      "Epoch: 15\tFidelity = 0.507444\tKL_Divergence = 2.486552\n",
      "Epoch: 16\tFidelity = 0.508867\tKL_Divergence = 2.388896\n",
      "Epoch: 17\tFidelity = 0.507696\tKL_Divergence = 2.468068\n",
      "Epoch: 18\tFidelity = 0.506626\tKL_Divergence = 2.551530\n",
      "Epoch: 19\tFidelity = 0.507966\tKL_Divergence = 2.448776\n",
      "Epoch: 20\tFidelity = 0.508638\tKL_Divergence = 2.403487\n",
      "Epoch: 21\tFidelity = 0.507702\tKL_Divergence = 2.467498\n",
      "Epoch: 22\tFidelity = 0.508444\tKL_Divergence = 2.416249\n",
      "Epoch: 23\tFidelity = 0.508698\tKL_Divergence = 2.399647\n",
      "Epoch: 24\tFidelity = 0.509540\tKL_Divergence = 2.347927\n",
      "Epoch: 25\tFidelity = 0.508785\tKL_Divergence = 2.394118\n",
      "Epoch: 26\tFidelity = 0.508147\tKL_Divergence = 2.436244\n",
      "Epoch: 27\tFidelity = 0.508393\tKL_Divergence = 2.419632\n",
      "Epoch: 28\tFidelity = 0.508651\tKL_Divergence = 2.402754\n",
      "Epoch: 29\tFidelity = 0.507415\tKL_Divergence = 2.488767\n",
      "Epoch: 30\tFidelity = 0.509136\tKL_Divergence = 2.372248\n",
      "Epoch: 31\tFidelity = 0.508845\tKL_Divergence = 2.390378\n",
      "Epoch: 32\tFidelity = 0.507992\tKL_Divergence = 2.446974\n",
      "Epoch: 33\tFidelity = 0.508478\tKL_Divergence = 2.414061\n",
      "Epoch: 34\tFidelity = 0.506971\tKL_Divergence = 2.523223\n",
      "Epoch: 35\tFidelity = 0.507030\tKL_Divergence = 2.518467\n",
      "Epoch: 36\tFidelity = 0.508586\tKL_Divergence = 2.406852\n",
      "Epoch: 37\tFidelity = 0.508146\tKL_Divergence = 2.436349\n",
      "Epoch: 38\tFidelity = 0.508435\tKL_Divergence = 2.416930\n",
      "Epoch: 39\tFidelity = 0.507741\tKL_Divergence = 2.464876\n",
      "Epoch: 40\tFidelity = 0.508128\tKL_Divergence = 2.437653\n",
      "Epoch: 41\tFidelity = 0.507270\tKL_Divergence = 2.499883\n",
      "Epoch: 42\tFidelity = 0.507977\tKL_Divergence = 2.448029\n",
      "Epoch: 43\tFidelity = 0.507212\tKL_Divergence = 2.504272\n",
      "Epoch: 44\tFidelity = 0.508348\tKL_Divergence = 2.422701\n",
      "Epoch: 45\tFidelity = 0.508441\tKL_Divergence = 2.416560\n",
      "Epoch: 46\tFidelity = 0.507988\tKL_Divergence = 2.447261\n",
      "Epoch: 47\tFidelity = 0.507313\tKL_Divergence = 2.496572\n",
      "Epoch: 48\tFidelity = 0.507112\tKL_Divergence = 2.512189\n",
      "Epoch: 49\tFidelity = 0.507504\tKL_Divergence = 2.482254\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:17:20,019] Trial 204 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.507047\tKL_Divergence = 2.517303\n",
      "Total time elapsed during training: 80.014 s\n",
      "Trial 204 pruned. \n",
      "Epoch: 1\tFidelity = 0.507824\tKL_Divergence = 2.458920\n",
      "Epoch: 2\tFidelity = 0.508045\tKL_Divergence = 2.443352\n",
      "Epoch: 3\tFidelity = 0.507814\tKL_Divergence = 2.459601\n",
      "Epoch: 4\tFidelity = 0.507186\tKL_Divergence = 2.506415\n",
      "Epoch: 5\tFidelity = 0.507136\tKL_Divergence = 2.510261\n",
      "Epoch: 6\tFidelity = 0.507833\tKL_Divergence = 2.458274\n",
      "Epoch: 7\tFidelity = 0.508206\tKL_Divergence = 2.432216\n",
      "Epoch: 8\tFidelity = 0.508152\tKL_Divergence = 2.435915\n",
      "Epoch: 9\tFidelity = 0.508043\tKL_Divergence = 2.443433\n",
      "Epoch: 10\tFidelity = 0.507246\tKL_Divergence = 2.501651\n",
      "Epoch: 11\tFidelity = 0.508332\tKL_Divergence = 2.423755\n",
      "Epoch: 12\tFidelity = 0.507327\tKL_Divergence = 2.495515\n",
      "Epoch: 13\tFidelity = 0.507776\tKL_Divergence = 2.462316\n",
      "Epoch: 14\tFidelity = 0.507385\tKL_Divergence = 2.491111\n",
      "Epoch: 15\tFidelity = 0.507494\tKL_Divergence = 2.482909\n",
      "Epoch: 16\tFidelity = 0.507911\tKL_Divergence = 2.452640\n",
      "Epoch: 17\tFidelity = 0.508727\tKL_Divergence = 2.397734\n",
      "Epoch: 18\tFidelity = 0.507657\tKL_Divergence = 2.470861\n",
      "Epoch: 19\tFidelity = 0.506927\tKL_Divergence = 2.526748\n",
      "Epoch: 20\tFidelity = 0.507683\tKL_Divergence = 2.468976\n",
      "Epoch: 21\tFidelity = 0.508964\tKL_Divergence = 2.382824\n",
      "Epoch: 22\tFidelity = 0.507594\tKL_Divergence = 2.475531\n",
      "Epoch: 23\tFidelity = 0.508557\tKL_Divergence = 2.408873\n",
      "Epoch: 24\tFidelity = 0.507715\tKL_Divergence = 2.466717\n",
      "Epoch: 25\tFidelity = 0.508582\tKL_Divergence = 2.407270\n",
      "Epoch: 26\tFidelity = 0.506990\tKL_Divergence = 2.521799\n",
      "Epoch: 27\tFidelity = 0.507669\tKL_Divergence = 2.470116\n",
      "Epoch: 28\tFidelity = 0.507245\tKL_Divergence = 2.501768\n",
      "Epoch: 29\tFidelity = 0.507344\tKL_Divergence = 2.494248\n",
      "Epoch: 30\tFidelity = 0.508747\tKL_Divergence = 2.396637\n",
      "Epoch: 31\tFidelity = 0.506792\tKL_Divergence = 2.537800\n",
      "Epoch: 32\tFidelity = 0.507106\tKL_Divergence = 2.512641\n",
      "Epoch: 33\tFidelity = 0.507254\tKL_Divergence = 2.501111\n",
      "Epoch: 34\tFidelity = 0.508102\tKL_Divergence = 2.439412\n",
      "Epoch: 35\tFidelity = 0.506805\tKL_Divergence = 2.536763\n",
      "Epoch: 36\tFidelity = 0.507427\tKL_Divergence = 2.488022\n",
      "Epoch: 37\tFidelity = 0.506841\tKL_Divergence = 2.533861\n",
      "Epoch: 38\tFidelity = 0.508386\tKL_Divergence = 2.420187\n",
      "Epoch: 39\tFidelity = 0.507117\tKL_Divergence = 2.511783\n",
      "Epoch: 40\tFidelity = 0.507865\tKL_Divergence = 2.456024\n",
      "Epoch: 41\tFidelity = 0.508492\tKL_Divergence = 2.413207\n",
      "Epoch: 42\tFidelity = 0.507453\tKL_Divergence = 2.486101\n",
      "Epoch: 43\tFidelity = 0.507124\tKL_Divergence = 2.511297\n",
      "Epoch: 44\tFidelity = 0.506673\tKL_Divergence = 2.547779\n",
      "Epoch: 45\tFidelity = 0.508225\tKL_Divergence = 2.431077\n",
      "Epoch: 46\tFidelity = 0.507167\tKL_Divergence = 2.507952\n",
      "Epoch: 47\tFidelity = 0.506568\tKL_Divergence = 2.556587\n",
      "Epoch: 48\tFidelity = 0.507072\tKL_Divergence = 2.515383\n",
      "Epoch: 49\tFidelity = 0.507800\tKL_Divergence = 2.460705\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:17:57,946] Trial 205 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.509310\tKL_Divergence = 2.361804\n",
      "Total time elapsed during training: 37.767 s\n",
      "Trial 205 pruned. \n",
      "Epoch: 1\tFidelity = 0.509436\tKL_Divergence = 2.354241\n",
      "Epoch: 2\tFidelity = 0.508512\tKL_Divergence = 2.411751\n",
      "Epoch: 3\tFidelity = 0.508435\tKL_Divergence = 2.416869\n",
      "Epoch: 4\tFidelity = 0.506838\tKL_Divergence = 2.533954\n",
      "Epoch: 5\tFidelity = 0.507997\tKL_Divergence = 2.446533\n",
      "Epoch: 6\tFidelity = 0.508723\tKL_Divergence = 2.397956\n",
      "Epoch: 7\tFidelity = 0.507407\tKL_Divergence = 2.489374\n",
      "Epoch: 8\tFidelity = 0.507541\tKL_Divergence = 2.479398\n",
      "Epoch: 9\tFidelity = 0.507781\tKL_Divergence = 2.461928\n",
      "Epoch: 10\tFidelity = 0.507148\tKL_Divergence = 2.509271\n",
      "Epoch: 11\tFidelity = 0.507712\tKL_Divergence = 2.466915\n",
      "Epoch: 12\tFidelity = 0.506781\tKL_Divergence = 2.538800\n",
      "Epoch: 13\tFidelity = 0.508340\tKL_Divergence = 2.423345\n",
      "Epoch: 14\tFidelity = 0.507449\tKL_Divergence = 2.486291\n",
      "Epoch: 15\tFidelity = 0.508528\tKL_Divergence = 2.410740\n",
      "Epoch: 16\tFidelity = 0.507376\tKL_Divergence = 2.491606\n",
      "Epoch: 17\tFidelity = 0.508065\tKL_Divergence = 2.441859\n",
      "Epoch: 18\tFidelity = 0.506972\tKL_Divergence = 2.523261\n",
      "Epoch: 19\tFidelity = 0.507039\tKL_Divergence = 2.517912\n",
      "Epoch: 20\tFidelity = 0.506753\tKL_Divergence = 2.541038\n",
      "Epoch: 21\tFidelity = 0.508670\tKL_Divergence = 2.401586\n",
      "Epoch: 22\tFidelity = 0.507210\tKL_Divergence = 2.504492\n",
      "Epoch: 23\tFidelity = 0.507263\tKL_Divergence = 2.500074\n",
      "Epoch: 24\tFidelity = 0.505982\tKL_Divergence = 2.608126\n",
      "Epoch: 25\tFidelity = 0.505671\tKL_Divergence = 2.637854\n",
      "Epoch: 26\tFidelity = 0.508857\tKL_Divergence = 2.389402\n",
      "Epoch: 27\tFidelity = 0.506452\tKL_Divergence = 2.566023\n",
      "Epoch: 28\tFidelity = 0.506364\tKL_Divergence = 2.573864\n",
      "Epoch: 29\tFidelity = 0.506857\tKL_Divergence = 2.532496\n",
      "Epoch: 30\tFidelity = 0.507362\tKL_Divergence = 2.492937\n",
      "Epoch: 31\tFidelity = 0.506037\tKL_Divergence = 2.603395\n",
      "Epoch: 32\tFidelity = 0.508994\tKL_Divergence = 2.381042\n",
      "Epoch: 33\tFidelity = 0.506352\tKL_Divergence = 2.575170\n",
      "Epoch: 34\tFidelity = 0.508804\tKL_Divergence = 2.392868\n",
      "Epoch: 35\tFidelity = 0.506964\tKL_Divergence = 2.523281\n",
      "Epoch: 36\tFidelity = 0.506669\tKL_Divergence = 2.547820\n",
      "Epoch: 37\tFidelity = 0.507026\tKL_Divergence = 2.518888\n",
      "Epoch: 38\tFidelity = 0.506515\tKL_Divergence = 2.561052\n",
      "Epoch: 39\tFidelity = 0.508600\tKL_Divergence = 2.406088\n",
      "Epoch: 40\tFidelity = 0.506931\tKL_Divergence = 2.526534\n",
      "Epoch: 41\tFidelity = 0.508285\tKL_Divergence = 2.426909\n",
      "Epoch: 42\tFidelity = 0.507056\tKL_Divergence = 2.516371\n",
      "Epoch: 43\tFidelity = 0.506156\tKL_Divergence = 2.592096\n",
      "Epoch: 44\tFidelity = 0.506684\tKL_Divergence = 2.546182\n",
      "Epoch: 45\tFidelity = 0.506567\tKL_Divergence = 2.555946\n",
      "Epoch: 46\tFidelity = 0.507116\tKL_Divergence = 2.510732\n",
      "Epoch: 47\tFidelity = 0.506496\tKL_Divergence = 2.561747\n",
      "Epoch: 48\tFidelity = 0.507524\tKL_Divergence = 2.480028\n",
      "Epoch: 49\tFidelity = 0.509052\tKL_Divergence = 2.376868\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:18:35,470] Trial 206 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.509186\tKL_Divergence = 2.368484\n",
      "Total time elapsed during training: 37.368 s\n",
      "Trial 206 pruned. \n",
      "Epoch: 1\tFidelity = 0.507558\tKL_Divergence = 2.478062\n",
      "Epoch: 2\tFidelity = 0.507273\tKL_Divergence = 2.499608\n",
      "Epoch: 3\tFidelity = 0.507359\tKL_Divergence = 2.493105\n",
      "Epoch: 4\tFidelity = 0.507740\tKL_Divergence = 2.464919\n",
      "Epoch: 5\tFidelity = 0.507747\tKL_Divergence = 2.464362\n",
      "Epoch: 6\tFidelity = 0.506673\tKL_Divergence = 2.547706\n",
      "Epoch: 7\tFidelity = 0.508067\tKL_Divergence = 2.441797\n",
      "Epoch: 8\tFidelity = 0.507336\tKL_Divergence = 2.494798\n",
      "Epoch: 9\tFidelity = 0.508126\tKL_Divergence = 2.437728\n",
      "Epoch: 10\tFidelity = 0.507354\tKL_Divergence = 2.493439\n",
      "Epoch: 11\tFidelity = 0.507098\tKL_Divergence = 2.513174\n",
      "Epoch: 12\tFidelity = 0.507198\tKL_Divergence = 2.505395\n",
      "Epoch: 13\tFidelity = 0.507121\tKL_Divergence = 2.511413\n",
      "Epoch: 14\tFidelity = 0.507321\tKL_Divergence = 2.495965\n",
      "Epoch: 15\tFidelity = 0.508080\tKL_Divergence = 2.440880\n",
      "Epoch: 16\tFidelity = 0.506983\tKL_Divergence = 2.522356\n",
      "Epoch: 17\tFidelity = 0.507012\tKL_Divergence = 2.519996\n",
      "Epoch: 18\tFidelity = 0.507514\tKL_Divergence = 2.481418\n",
      "Epoch: 19\tFidelity = 0.506476\tKL_Divergence = 2.564393\n",
      "Epoch: 20\tFidelity = 0.506903\tKL_Divergence = 2.528762\n",
      "Epoch: 21\tFidelity = 0.506750\tKL_Divergence = 2.541301\n",
      "Epoch: 22\tFidelity = 0.507395\tKL_Divergence = 2.490375\n",
      "Epoch: 23\tFidelity = 0.507084\tKL_Divergence = 2.514317\n",
      "Epoch: 24\tFidelity = 0.506980\tKL_Divergence = 2.522604\n",
      "Epoch: 25\tFidelity = 0.507898\tKL_Divergence = 2.453617\n",
      "Epoch: 26\tFidelity = 0.508088\tKL_Divergence = 2.440377\n",
      "Epoch: 27\tFidelity = 0.507142\tKL_Divergence = 2.509818\n",
      "Epoch: 28\tFidelity = 0.507571\tKL_Divergence = 2.477247\n",
      "Epoch: 29\tFidelity = 0.507940\tKL_Divergence = 2.450681\n",
      "Epoch: 30\tFidelity = 0.506622\tKL_Divergence = 2.551901\n",
      "Epoch: 31\tFidelity = 0.507538\tKL_Divergence = 2.479636\n",
      "Epoch: 32\tFidelity = 0.506583\tKL_Divergence = 2.555273\n",
      "Epoch: 33\tFidelity = 0.507743\tKL_Divergence = 2.464706\n",
      "Epoch: 34\tFidelity = 0.506360\tKL_Divergence = 2.574523\n",
      "Epoch: 35\tFidelity = 0.506719\tKL_Divergence = 2.543835\n",
      "Epoch: 36\tFidelity = 0.507339\tKL_Divergence = 2.494621\n",
      "Epoch: 37\tFidelity = 0.507354\tKL_Divergence = 2.493530\n",
      "Epoch: 38\tFidelity = 0.506585\tKL_Divergence = 2.555107\n",
      "Epoch: 39\tFidelity = 0.506749\tKL_Divergence = 2.541397\n",
      "Epoch: 40\tFidelity = 0.506811\tKL_Divergence = 2.536313\n",
      "Epoch: 41\tFidelity = 0.505966\tKL_Divergence = 2.610040\n",
      "Epoch: 42\tFidelity = 0.507557\tKL_Divergence = 2.478271\n",
      "Epoch: 43\tFidelity = 0.506156\tKL_Divergence = 2.592691\n",
      "Epoch: 44\tFidelity = 0.506350\tKL_Divergence = 2.575460\n",
      "Epoch: 45\tFidelity = 0.507002\tKL_Divergence = 2.520915\n",
      "Epoch: 46\tFidelity = 0.506740\tKL_Divergence = 2.542213\n",
      "Epoch: 47\tFidelity = 0.506817\tKL_Divergence = 2.535845\n",
      "Epoch: 48\tFidelity = 0.507421\tKL_Divergence = 2.488478\n",
      "Epoch: 49\tFidelity = 0.506201\tKL_Divergence = 2.588709\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:19:56,752] Trial 207 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.506496\tKL_Divergence = 2.562774\n",
      "Total time elapsed during training: 81.123 s\n",
      "Trial 207 pruned. \n",
      "Epoch: 1\tFidelity = 0.505994\tKL_Divergence = 2.607616\n",
      "Epoch: 2\tFidelity = 0.506699\tKL_Divergence = 2.545546\n",
      "Epoch: 3\tFidelity = 0.506742\tKL_Divergence = 2.542005\n",
      "Epoch: 4\tFidelity = 0.507561\tKL_Divergence = 2.478070\n",
      "Epoch: 5\tFidelity = 0.506918\tKL_Divergence = 2.527619\n",
      "Epoch: 6\tFidelity = 0.506679\tKL_Divergence = 2.547233\n",
      "Epoch: 7\tFidelity = 0.507115\tKL_Divergence = 2.511927\n",
      "Epoch: 8\tFidelity = 0.506210\tKL_Divergence = 2.587853\n",
      "Epoch: 9\tFidelity = 0.506389\tKL_Divergence = 2.571981\n",
      "Epoch: 10\tFidelity = 0.506592\tKL_Divergence = 2.554543\n",
      "Epoch: 11\tFidelity = 0.506965\tKL_Divergence = 2.523860\n",
      "Epoch: 12\tFidelity = 0.506473\tKL_Divergence = 2.564723\n",
      "Epoch: 13\tFidelity = 0.506417\tKL_Divergence = 2.569550\n",
      "Epoch: 14\tFidelity = 0.506944\tKL_Divergence = 2.525525\n",
      "Epoch: 15\tFidelity = 0.507276\tKL_Divergence = 2.499472\n",
      "Epoch: 16\tFidelity = 0.506247\tKL_Divergence = 2.584507\n",
      "Epoch: 17\tFidelity = 0.507325\tKL_Divergence = 2.495732\n",
      "Epoch: 18\tFidelity = 0.507246\tKL_Divergence = 2.501754\n",
      "Epoch: 19\tFidelity = 0.507519\tKL_Divergence = 2.481130\n",
      "Epoch: 20\tFidelity = 0.507048\tKL_Divergence = 2.517237\n",
      "Epoch: 21\tFidelity = 0.506844\tKL_Divergence = 2.533585\n",
      "Epoch: 22\tFidelity = 0.507267\tKL_Divergence = 2.500097\n",
      "Epoch: 23\tFidelity = 0.506610\tKL_Divergence = 2.552973\n",
      "Epoch: 24\tFidelity = 0.505873\tKL_Divergence = 2.618862\n",
      "Epoch: 25\tFidelity = 0.506706\tKL_Divergence = 2.544915\n",
      "Epoch: 26\tFidelity = 0.506821\tKL_Divergence = 2.535505\n",
      "Epoch: 27\tFidelity = 0.507796\tKL_Divergence = 2.460898\n",
      "Epoch: 28\tFidelity = 0.506680\tKL_Divergence = 2.547156\n",
      "Epoch: 29\tFidelity = 0.506699\tKL_Divergence = 2.545524\n",
      "Epoch: 30\tFidelity = 0.506593\tKL_Divergence = 2.554437\n",
      "Epoch: 31\tFidelity = 0.507508\tKL_Divergence = 2.481932\n",
      "Epoch: 32\tFidelity = 0.506424\tKL_Divergence = 2.568892\n",
      "Epoch: 33\tFidelity = 0.507546\tKL_Divergence = 2.479095\n",
      "Epoch: 34\tFidelity = 0.506749\tKL_Divergence = 2.541372\n",
      "Epoch: 35\tFidelity = 0.507174\tKL_Divergence = 2.507263\n",
      "Epoch: 36\tFidelity = 0.507955\tKL_Divergence = 2.449593\n",
      "Epoch: 37\tFidelity = 0.508002\tKL_Divergence = 2.446352\n",
      "Epoch: 38\tFidelity = 0.506638\tKL_Divergence = 2.550585\n",
      "Epoch: 39\tFidelity = 0.506674\tKL_Divergence = 2.547624\n",
      "Epoch: 40\tFidelity = 0.507669\tKL_Divergence = 2.470030\n",
      "Epoch: 41\tFidelity = 0.506496\tKL_Divergence = 2.562683\n",
      "Epoch: 42\tFidelity = 0.507593\tKL_Divergence = 2.475602\n",
      "Epoch: 43\tFidelity = 0.507893\tKL_Divergence = 2.453947\n",
      "Epoch: 44\tFidelity = 0.507037\tKL_Divergence = 2.518038\n",
      "Epoch: 45\tFidelity = 0.507079\tKL_Divergence = 2.514691\n",
      "Epoch: 46\tFidelity = 0.506303\tKL_Divergence = 2.579500\n",
      "Epoch: 47\tFidelity = 0.507055\tKL_Divergence = 2.516587\n",
      "Epoch: 48\tFidelity = 0.507276\tKL_Divergence = 2.499360\n",
      "Epoch: 49\tFidelity = 0.507383\tKL_Divergence = 2.491255\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:20:28,840] Trial 208 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.506324\tKL_Divergence = 2.577571\n",
      "Total time elapsed during training: 31.930 s\n",
      "Trial 208 pruned. \n",
      "Epoch: 1\tFidelity = 0.507031\tKL_Divergence = 2.518506\n",
      "Epoch: 2\tFidelity = 0.507076\tKL_Divergence = 2.514903\n",
      "Epoch: 3\tFidelity = 0.506836\tKL_Divergence = 2.534178\n",
      "Epoch: 4\tFidelity = 0.507075\tKL_Divergence = 2.515023\n",
      "Epoch: 5\tFidelity = 0.506593\tKL_Divergence = 2.554371\n",
      "Epoch: 6\tFidelity = 0.506982\tKL_Divergence = 2.522422\n",
      "Epoch: 7\tFidelity = 0.506630\tKL_Divergence = 2.551273\n",
      "Epoch: 8\tFidelity = 0.506719\tKL_Divergence = 2.543834\n",
      "Epoch: 9\tFidelity = 0.507000\tKL_Divergence = 2.520993\n",
      "Epoch: 10\tFidelity = 0.506808\tKL_Divergence = 2.536458\n",
      "Epoch: 11\tFidelity = 0.507002\tKL_Divergence = 2.520855\n",
      "Epoch: 12\tFidelity = 0.506717\tKL_Divergence = 2.544009\n",
      "Epoch: 13\tFidelity = 0.506862\tKL_Divergence = 2.532048\n",
      "Epoch: 14\tFidelity = 0.507044\tKL_Divergence = 2.517487\n",
      "Epoch: 15\tFidelity = 0.506992\tKL_Divergence = 2.521587\n",
      "Epoch: 16\tFidelity = 0.506579\tKL_Divergence = 2.555575\n",
      "Epoch: 17\tFidelity = 0.506824\tKL_Divergence = 2.535158\n",
      "Epoch: 18\tFidelity = 0.507070\tKL_Divergence = 2.515458\n",
      "Epoch: 19\tFidelity = 0.507132\tKL_Divergence = 2.510580\n",
      "Epoch: 20\tFidelity = 0.506456\tKL_Divergence = 2.566077\n",
      "Epoch: 21\tFidelity = 0.507392\tKL_Divergence = 2.490557\n",
      "Epoch: 22\tFidelity = 0.506877\tKL_Divergence = 2.530879\n",
      "Epoch: 23\tFidelity = 0.506613\tKL_Divergence = 2.552691\n",
      "Epoch: 24\tFidelity = 0.507080\tKL_Divergence = 2.514673\n",
      "Epoch: 25\tFidelity = 0.507339\tKL_Divergence = 2.494568\n",
      "Epoch: 26\tFidelity = 0.506918\tKL_Divergence = 2.527515\n",
      "Epoch: 27\tFidelity = 0.507120\tKL_Divergence = 2.511486\n",
      "Epoch: 28\tFidelity = 0.506626\tKL_Divergence = 2.551600\n",
      "Epoch: 29\tFidelity = 0.506872\tKL_Divergence = 2.531237\n",
      "Epoch: 30\tFidelity = 0.507357\tKL_Divergence = 2.493187\n",
      "Epoch: 31\tFidelity = 0.506868\tKL_Divergence = 2.531555\n",
      "Epoch: 32\tFidelity = 0.507198\tKL_Divergence = 2.505420\n",
      "Epoch: 33\tFidelity = 0.506807\tKL_Divergence = 2.536618\n",
      "Epoch: 34\tFidelity = 0.506969\tKL_Divergence = 2.523436\n",
      "Epoch: 35\tFidelity = 0.507590\tKL_Divergence = 2.475863\n",
      "Epoch: 36\tFidelity = 0.506410\tKL_Divergence = 2.570071\n",
      "Epoch: 37\tFidelity = 0.507011\tKL_Divergence = 2.520115\n",
      "Epoch: 38\tFidelity = 0.506596\tKL_Divergence = 2.554118\n",
      "Epoch: 39\tFidelity = 0.506883\tKL_Divergence = 2.530354\n",
      "Epoch: 40\tFidelity = 0.506463\tKL_Divergence = 2.565459\n",
      "Epoch: 41\tFidelity = 0.506493\tKL_Divergence = 2.562940\n",
      "Epoch: 42\tFidelity = 0.506694\tKL_Divergence = 2.545947\n",
      "Epoch: 43\tFidelity = 0.507143\tKL_Divergence = 2.509684\n",
      "Epoch: 44\tFidelity = 0.506822\tKL_Divergence = 2.535352\n",
      "Epoch: 45\tFidelity = 0.506598\tKL_Divergence = 2.553983\n",
      "Epoch: 46\tFidelity = 0.506530\tKL_Divergence = 2.559718\n",
      "Epoch: 47\tFidelity = 0.507298\tKL_Divergence = 2.497752\n",
      "Epoch: 48\tFidelity = 0.506906\tKL_Divergence = 2.528521\n",
      "Epoch: 49\tFidelity = 0.507146\tKL_Divergence = 2.509441\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:21:07,482] Trial 209 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.506456\tKL_Divergence = 2.566149\n",
      "Total time elapsed during training: 38.489 s\n",
      "Trial 209 pruned. \n",
      "Epoch: 1\tFidelity = 0.507251\tKL_Divergence = 2.501359\n",
      "Epoch: 2\tFidelity = 0.506281\tKL_Divergence = 2.581475\n",
      "Epoch: 3\tFidelity = 0.507383\tKL_Divergence = 2.491274\n",
      "Epoch: 4\tFidelity = 0.506614\tKL_Divergence = 2.552603\n",
      "Epoch: 5\tFidelity = 0.506980\tKL_Divergence = 2.522583\n",
      "Epoch: 6\tFidelity = 0.507038\tKL_Divergence = 2.517973\n",
      "Epoch: 7\tFidelity = 0.506510\tKL_Divergence = 2.561467\n",
      "Epoch: 8\tFidelity = 0.507202\tKL_Divergence = 2.505114\n",
      "Epoch: 9\tFidelity = 0.507112\tKL_Divergence = 2.512135\n",
      "Epoch: 10\tFidelity = 0.506800\tKL_Divergence = 2.537128\n",
      "Epoch: 11\tFidelity = 0.506867\tKL_Divergence = 2.531662\n",
      "Epoch: 12\tFidelity = 0.506893\tKL_Divergence = 2.529619\n",
      "Epoch: 13\tFidelity = 0.506808\tKL_Divergence = 2.536490\n",
      "Epoch: 14\tFidelity = 0.507077\tKL_Divergence = 2.514841\n",
      "Epoch: 15\tFidelity = 0.506965\tKL_Divergence = 2.523776\n",
      "Epoch: 16\tFidelity = 0.507297\tKL_Divergence = 2.497782\n",
      "Epoch: 17\tFidelity = 0.506889\tKL_Divergence = 2.529865\n",
      "Epoch: 18\tFidelity = 0.506325\tKL_Divergence = 2.577546\n",
      "Epoch: 19\tFidelity = 0.507051\tKL_Divergence = 2.516963\n",
      "Epoch: 20\tFidelity = 0.506357\tKL_Divergence = 2.574745\n",
      "Epoch: 21\tFidelity = 0.507358\tKL_Divergence = 2.493128\n",
      "Epoch: 22\tFidelity = 0.506374\tKL_Divergence = 2.573248\n",
      "Epoch: 23\tFidelity = 0.507361\tKL_Divergence = 2.492955\n",
      "Epoch: 24\tFidelity = 0.506610\tKL_Divergence = 2.552979\n",
      "Epoch: 25\tFidelity = 0.507002\tKL_Divergence = 2.520830\n",
      "Epoch: 26\tFidelity = 0.507005\tKL_Divergence = 2.520611\n",
      "Epoch: 27\tFidelity = 0.507299\tKL_Divergence = 2.497665\n",
      "Epoch: 28\tFidelity = 0.506460\tKL_Divergence = 2.565817\n",
      "Epoch: 29\tFidelity = 0.506807\tKL_Divergence = 2.536606\n",
      "Epoch: 30\tFidelity = 0.506654\tKL_Divergence = 2.549267\n",
      "Epoch: 31\tFidelity = 0.507696\tKL_Divergence = 2.468116\n",
      "Epoch: 32\tFidelity = 0.506471\tKL_Divergence = 2.564826\n",
      "Epoch: 33\tFidelity = 0.506428\tKL_Divergence = 2.568556\n",
      "Epoch: 34\tFidelity = 0.506675\tKL_Divergence = 2.547504\n",
      "Epoch: 35\tFidelity = 0.506799\tKL_Divergence = 2.537277\n",
      "Epoch: 36\tFidelity = 0.507229\tKL_Divergence = 2.503040\n",
      "Epoch: 37\tFidelity = 0.506907\tKL_Divergence = 2.528455\n",
      "Epoch: 38\tFidelity = 0.506704\tKL_Divergence = 2.545135\n",
      "Epoch: 39\tFidelity = 0.506702\tKL_Divergence = 2.545237\n",
      "Epoch: 40\tFidelity = 0.506808\tKL_Divergence = 2.536502\n",
      "Epoch: 41\tFidelity = 0.507634\tKL_Divergence = 2.472619\n",
      "Epoch: 42\tFidelity = 0.507004\tKL_Divergence = 2.520676\n",
      "Epoch: 43\tFidelity = 0.506800\tKL_Divergence = 2.537195\n",
      "Epoch: 44\tFidelity = 0.505988\tKL_Divergence = 2.608075\n",
      "Epoch: 45\tFidelity = 0.507373\tKL_Divergence = 2.492047\n",
      "Epoch: 46\tFidelity = 0.506351\tKL_Divergence = 2.575253\n",
      "Epoch: 47\tFidelity = 0.506518\tKL_Divergence = 2.560816\n",
      "Epoch: 48\tFidelity = 0.507166\tKL_Divergence = 2.507947\n",
      "Epoch: 49\tFidelity = 0.506685\tKL_Divergence = 2.546720\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:21:39,240] Trial 210 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.507086\tKL_Divergence = 2.514179\n",
      "Total time elapsed during training: 31.598 s\n",
      "Trial 210 pruned. \n",
      "Epoch: 1\tFidelity = 0.506640\tKL_Divergence = 2.550475\n",
      "Epoch: 2\tFidelity = 0.506255\tKL_Divergence = 2.583708\n",
      "Epoch: 3\tFidelity = 0.507155\tKL_Divergence = 2.508769\n",
      "Epoch: 4\tFidelity = 0.507123\tKL_Divergence = 2.511286\n",
      "Epoch: 5\tFidelity = 0.506980\tKL_Divergence = 2.522602\n",
      "Epoch: 6\tFidelity = 0.507350\tKL_Divergence = 2.493773\n",
      "Epoch: 7\tFidelity = 0.506466\tKL_Divergence = 2.565220\n",
      "Epoch: 8\tFidelity = 0.507206\tKL_Divergence = 2.504839\n",
      "Epoch: 9\tFidelity = 0.507317\tKL_Divergence = 2.496317\n",
      "Epoch: 10\tFidelity = 0.506670\tKL_Divergence = 2.547957\n",
      "Epoch: 11\tFidelity = 0.506790\tKL_Divergence = 2.538021\n",
      "Epoch: 12\tFidelity = 0.505968\tKL_Divergence = 2.609914\n",
      "Epoch: 13\tFidelity = 0.506484\tKL_Divergence = 2.563697\n",
      "Epoch: 14\tFidelity = 0.506444\tKL_Divergence = 2.567134\n",
      "Epoch: 15\tFidelity = 0.507081\tKL_Divergence = 2.514611\n",
      "Epoch: 16\tFidelity = 0.507394\tKL_Divergence = 2.490438\n",
      "Epoch: 17\tFidelity = 0.506501\tKL_Divergence = 2.562212\n",
      "Epoch: 18\tFidelity = 0.506900\tKL_Divergence = 2.528991\n",
      "Epoch: 19\tFidelity = 0.506957\tKL_Divergence = 2.524440\n",
      "Epoch: 20\tFidelity = 0.506763\tKL_Divergence = 2.540193\n",
      "Epoch: 21\tFidelity = 0.506603\tKL_Divergence = 2.553583\n",
      "Epoch: 22\tFidelity = 0.507342\tKL_Divergence = 2.494377\n",
      "Epoch: 23\tFidelity = 0.506784\tKL_Divergence = 2.538483\n",
      "Epoch: 24\tFidelity = 0.507013\tKL_Divergence = 2.519980\n",
      "Epoch: 25\tFidelity = 0.506654\tKL_Divergence = 2.549274\n",
      "Epoch: 26\tFidelity = 0.506569\tKL_Divergence = 2.556426\n",
      "Epoch: 27\tFidelity = 0.506862\tKL_Divergence = 2.532097\n",
      "Epoch: 28\tFidelity = 0.506563\tKL_Divergence = 2.556965\n",
      "Epoch: 29\tFidelity = 0.506223\tKL_Divergence = 2.586638\n",
      "Epoch: 30\tFidelity = 0.506323\tKL_Divergence = 2.577689\n",
      "Epoch: 31\tFidelity = 0.506802\tKL_Divergence = 2.537039\n",
      "Epoch: 32\tFidelity = 0.507310\tKL_Divergence = 2.496800\n",
      "Epoch: 33\tFidelity = 0.507058\tKL_Divergence = 2.516440\n",
      "Epoch: 34\tFidelity = 0.507804\tKL_Divergence = 2.460342\n",
      "Epoch: 35\tFidelity = 0.506829\tKL_Divergence = 2.534824\n",
      "Epoch: 36\tFidelity = 0.506851\tKL_Divergence = 2.532986\n",
      "Epoch: 37\tFidelity = 0.506791\tKL_Divergence = 2.537914\n",
      "Epoch: 38\tFidelity = 0.506598\tKL_Divergence = 2.554001\n",
      "Epoch: 39\tFidelity = 0.507700\tKL_Divergence = 2.467838\n",
      "Epoch: 40\tFidelity = 0.507219\tKL_Divergence = 2.503800\n",
      "Epoch: 41\tFidelity = 0.506681\tKL_Divergence = 2.546999\n",
      "Epoch: 42\tFidelity = 0.507423\tKL_Divergence = 2.488240\n",
      "Epoch: 43\tFidelity = 0.507210\tKL_Divergence = 2.504535\n",
      "Epoch: 44\tFidelity = 0.506715\tKL_Divergence = 2.544198\n",
      "Epoch: 45\tFidelity = 0.506121\tKL_Divergence = 2.595860\n",
      "Epoch: 46\tFidelity = 0.506473\tKL_Divergence = 2.564641\n",
      "Epoch: 47\tFidelity = 0.506732\tKL_Divergence = 2.542806\n",
      "Epoch: 48\tFidelity = 0.506837\tKL_Divergence = 2.534176\n",
      "Epoch: 49\tFidelity = 0.506546\tKL_Divergence = 2.558473\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:22:24,939] Trial 211 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.506775\tKL_Divergence = 2.539270\n",
      "Total time elapsed during training: 45.541 s\n",
      "Trial 211 pruned. \n",
      "Epoch: 1\tFidelity = 0.506282\tKL_Divergence = 2.581388\n",
      "Epoch: 2\tFidelity = 0.506674\tKL_Divergence = 2.547650\n",
      "Epoch: 3\tFidelity = 0.506523\tKL_Divergence = 2.560383\n",
      "Epoch: 4\tFidelity = 0.506782\tKL_Divergence = 2.538657\n",
      "Epoch: 5\tFidelity = 0.507535\tKL_Divergence = 2.479941\n",
      "Epoch: 6\tFidelity = 0.507351\tKL_Divergence = 2.493709\n",
      "Epoch: 7\tFidelity = 0.507512\tKL_Divergence = 2.481644\n",
      "Epoch: 8\tFidelity = 0.506235\tKL_Divergence = 2.585545\n",
      "Epoch: 9\tFidelity = 0.506760\tKL_Divergence = 2.540479\n",
      "Epoch: 10\tFidelity = 0.506706\tKL_Divergence = 2.544969\n",
      "Epoch: 11\tFidelity = 0.505998\tKL_Divergence = 2.607152\n",
      "Epoch: 12\tFidelity = 0.506238\tKL_Divergence = 2.585266\n",
      "Epoch: 13\tFidelity = 0.506103\tKL_Divergence = 2.597510\n",
      "Epoch: 14\tFidelity = 0.507241\tKL_Divergence = 2.502167\n",
      "Epoch: 15\tFidelity = 0.505999\tKL_Divergence = 2.607078\n",
      "Epoch: 16\tFidelity = 0.507722\tKL_Divergence = 2.466238\n",
      "Epoch: 17\tFidelity = 0.508020\tKL_Divergence = 2.445128\n",
      "Epoch: 18\tFidelity = 0.507144\tKL_Divergence = 2.509639\n",
      "Epoch: 19\tFidelity = 0.506739\tKL_Divergence = 2.542250\n",
      "Epoch: 20\tFidelity = 0.508214\tKL_Divergence = 2.431777\n",
      "Epoch: 21\tFidelity = 0.506066\tKL_Divergence = 2.600834\n",
      "Epoch: 22\tFidelity = 0.506810\tKL_Divergence = 2.536381\n",
      "Epoch: 23\tFidelity = 0.506701\tKL_Divergence = 2.545351\n",
      "Epoch: 24\tFidelity = 0.507304\tKL_Divergence = 2.497312\n",
      "Epoch: 25\tFidelity = 0.506900\tKL_Divergence = 2.528994\n",
      "Epoch: 26\tFidelity = 0.506106\tKL_Divergence = 2.597166\n",
      "Epoch: 27\tFidelity = 0.506668\tKL_Divergence = 2.548135\n",
      "Epoch: 28\tFidelity = 0.506817\tKL_Divergence = 2.535829\n",
      "Epoch: 29\tFidelity = 0.506652\tKL_Divergence = 2.549470\n",
      "Epoch: 30\tFidelity = 0.506568\tKL_Divergence = 2.556523\n",
      "Epoch: 31\tFidelity = 0.507167\tKL_Divergence = 2.507849\n",
      "Epoch: 32\tFidelity = 0.506538\tKL_Divergence = 2.559144\n",
      "Epoch: 33\tFidelity = 0.507728\tKL_Divergence = 2.465800\n",
      "Epoch: 34\tFidelity = 0.506486\tKL_Divergence = 2.563577\n",
      "Epoch: 35\tFidelity = 0.506079\tKL_Divergence = 2.599665\n",
      "Epoch: 36\tFidelity = 0.507144\tKL_Divergence = 2.509697\n",
      "Epoch: 37\tFidelity = 0.507125\tKL_Divergence = 2.511187\n",
      "Epoch: 38\tFidelity = 0.506475\tKL_Divergence = 2.564558\n",
      "Epoch: 39\tFidelity = 0.507131\tKL_Divergence = 2.510673\n",
      "Epoch: 40\tFidelity = 0.506570\tKL_Divergence = 2.556396\n",
      "Epoch: 41\tFidelity = 0.507711\tKL_Divergence = 2.467065\n",
      "Epoch: 42\tFidelity = 0.506888\tKL_Divergence = 2.529989\n",
      "Epoch: 43\tFidelity = 0.507635\tKL_Divergence = 2.472540\n",
      "Epoch: 44\tFidelity = 0.506541\tKL_Divergence = 2.558883\n",
      "Epoch: 45\tFidelity = 0.506626\tKL_Divergence = 2.551684\n",
      "Epoch: 46\tFidelity = 0.506750\tKL_Divergence = 2.541303\n",
      "Epoch: 47\tFidelity = 0.506449\tKL_Divergence = 2.566746\n",
      "Epoch: 48\tFidelity = 0.507346\tKL_Divergence = 2.494098\n",
      "Epoch: 49\tFidelity = 0.505942\tKL_Divergence = 2.612380\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:23:10,089] Trial 212 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.506567\tKL_Divergence = 2.556665\n",
      "Total time elapsed during training: 44.997 s\n",
      "Trial 212 pruned. \n",
      "Epoch: 1\tFidelity = 0.506206\tKL_Divergence = 2.588170\n",
      "Epoch: 2\tFidelity = 0.507292\tKL_Divergence = 2.498205\n",
      "Epoch: 3\tFidelity = 0.506783\tKL_Divergence = 2.538579\n",
      "Epoch: 4\tFidelity = 0.506622\tKL_Divergence = 2.552033\n",
      "Epoch: 5\tFidelity = 0.507197\tKL_Divergence = 2.505554\n",
      "Epoch: 6\tFidelity = 0.505932\tKL_Divergence = 2.613377\n",
      "Epoch: 7\tFidelity = 0.507297\tKL_Divergence = 2.497906\n",
      "Epoch: 8\tFidelity = 0.505921\tKL_Divergence = 2.614358\n",
      "Epoch: 9\tFidelity = 0.506944\tKL_Divergence = 2.525518\n",
      "Epoch: 10\tFidelity = 0.506565\tKL_Divergence = 2.556835\n",
      "Epoch: 11\tFidelity = 0.506513\tKL_Divergence = 2.561241\n",
      "Epoch: 12\tFidelity = 0.506543\tKL_Divergence = 2.558681\n",
      "Epoch: 13\tFidelity = 0.507054\tKL_Divergence = 2.516720\n",
      "Epoch: 14\tFidelity = 0.506317\tKL_Divergence = 2.578285\n",
      "Epoch: 15\tFidelity = 0.506088\tKL_Divergence = 2.598919\n",
      "Epoch: 16\tFidelity = 0.507130\tKL_Divergence = 2.510775\n",
      "Epoch: 17\tFidelity = 0.507170\tKL_Divergence = 2.507663\n",
      "Epoch: 18\tFidelity = 0.507144\tKL_Divergence = 2.509693\n",
      "Epoch: 19\tFidelity = 0.506673\tKL_Divergence = 2.547744\n",
      "Epoch: 20\tFidelity = 0.506438\tKL_Divergence = 2.567684\n",
      "Epoch: 21\tFidelity = 0.506692\tKL_Divergence = 2.546150\n",
      "Epoch: 22\tFidelity = 0.507235\tKL_Divergence = 2.502618\n",
      "Epoch: 23\tFidelity = 0.506793\tKL_Divergence = 2.537793\n",
      "Epoch: 24\tFidelity = 0.506431\tKL_Divergence = 2.568347\n",
      "Epoch: 25\tFidelity = 0.505918\tKL_Divergence = 2.614671\n",
      "Epoch: 26\tFidelity = 0.506941\tKL_Divergence = 2.525777\n",
      "Epoch: 27\tFidelity = 0.506628\tKL_Divergence = 2.551501\n",
      "Epoch: 28\tFidelity = 0.506110\tKL_Divergence = 2.596924\n",
      "Epoch: 29\tFidelity = 0.506944\tKL_Divergence = 2.525533\n",
      "Epoch: 30\tFidelity = 0.506976\tKL_Divergence = 2.522952\n",
      "Epoch: 31\tFidelity = 0.506893\tKL_Divergence = 2.529656\n",
      "Epoch: 32\tFidelity = 0.506309\tKL_Divergence = 2.579013\n",
      "Epoch: 33\tFidelity = 0.506760\tKL_Divergence = 2.540497\n",
      "Epoch: 34\tFidelity = 0.506191\tKL_Divergence = 2.589554\n",
      "Epoch: 35\tFidelity = 0.506758\tKL_Divergence = 2.540675\n",
      "Epoch: 36\tFidelity = 0.506643\tKL_Divergence = 2.550282\n",
      "Epoch: 37\tFidelity = 0.507243\tKL_Divergence = 2.502061\n",
      "Epoch: 38\tFidelity = 0.507152\tKL_Divergence = 2.509072\n",
      "Epoch: 39\tFidelity = 0.506166\tKL_Divergence = 2.591808\n",
      "Epoch: 40\tFidelity = 0.506485\tKL_Divergence = 2.563660\n",
      "Epoch: 41\tFidelity = 0.507059\tKL_Divergence = 2.516355\n",
      "Epoch: 42\tFidelity = 0.506383\tKL_Divergence = 2.572500\n",
      "Epoch: 43\tFidelity = 0.506846\tKL_Divergence = 2.533488\n",
      "Epoch: 44\tFidelity = 0.506250\tKL_Divergence = 2.584235\n",
      "Epoch: 45\tFidelity = 0.506699\tKL_Divergence = 2.545572\n",
      "Epoch: 46\tFidelity = 0.506212\tKL_Divergence = 2.587616\n",
      "Epoch: 47\tFidelity = 0.506621\tKL_Divergence = 2.552098\n",
      "Epoch: 48\tFidelity = 0.506317\tKL_Divergence = 2.578269\n",
      "Epoch: 49\tFidelity = 0.506658\tKL_Divergence = 2.548990\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:23:55,666] Trial 213 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.506491\tKL_Divergence = 2.563156\n",
      "Total time elapsed during training: 45.405 s\n",
      "Trial 213 pruned. \n",
      "Epoch: 1\tFidelity = 0.507343\tKL_Divergence = 2.494369\n",
      "Epoch: 2\tFidelity = 0.507412\tKL_Divergence = 2.489144\n",
      "Epoch: 3\tFidelity = 0.506267\tKL_Divergence = 2.582677\n",
      "Epoch: 4\tFidelity = 0.507079\tKL_Divergence = 2.514802\n",
      "Epoch: 5\tFidelity = 0.506165\tKL_Divergence = 2.591847\n",
      "Epoch: 6\tFidelity = 0.507187\tKL_Divergence = 2.506323\n",
      "Epoch: 7\tFidelity = 0.507091\tKL_Divergence = 2.513815\n",
      "Epoch: 8\tFidelity = 0.506780\tKL_Divergence = 2.538869\n",
      "Epoch: 9\tFidelity = 0.507043\tKL_Divergence = 2.517576\n",
      "Epoch: 10\tFidelity = 0.506300\tKL_Divergence = 2.579807\n",
      "Epoch: 11\tFidelity = 0.507433\tKL_Divergence = 2.487556\n",
      "Epoch: 12\tFidelity = 0.506262\tKL_Divergence = 2.583157\n",
      "Epoch: 13\tFidelity = 0.506744\tKL_Divergence = 2.541830\n",
      "Epoch: 14\tFidelity = 0.506872\tKL_Divergence = 2.531298\n",
      "Epoch: 15\tFidelity = 0.506360\tKL_Divergence = 2.574539\n",
      "Epoch: 16\tFidelity = 0.506191\tKL_Divergence = 2.589533\n",
      "Epoch: 17\tFidelity = 0.506317\tKL_Divergence = 2.578282\n",
      "Epoch: 18\tFidelity = 0.506529\tKL_Divergence = 2.559866\n",
      "Epoch: 19\tFidelity = 0.506735\tKL_Divergence = 2.542568\n",
      "Epoch: 20\tFidelity = 0.506348\tKL_Divergence = 2.575611\n",
      "Epoch: 21\tFidelity = 0.507040\tKL_Divergence = 2.517846\n",
      "Epoch: 22\tFidelity = 0.506740\tKL_Divergence = 2.542179\n",
      "Epoch: 23\tFidelity = 0.506093\tKL_Divergence = 2.598426\n",
      "Epoch: 24\tFidelity = 0.506507\tKL_Divergence = 2.561784\n",
      "Epoch: 25\tFidelity = 0.506614\tKL_Divergence = 2.552634\n",
      "Epoch: 26\tFidelity = 0.506255\tKL_Divergence = 2.583801\n",
      "Epoch: 27\tFidelity = 0.507154\tKL_Divergence = 2.508903\n",
      "Epoch: 28\tFidelity = 0.506558\tKL_Divergence = 2.557416\n",
      "Epoch: 29\tFidelity = 0.506572\tKL_Divergence = 2.556243\n",
      "Epoch: 30\tFidelity = 0.506452\tKL_Divergence = 2.566498\n",
      "Epoch: 31\tFidelity = 0.507042\tKL_Divergence = 2.517664\n",
      "Epoch: 32\tFidelity = 0.506907\tKL_Divergence = 2.528469\n",
      "Epoch: 33\tFidelity = 0.506793\tKL_Divergence = 2.537751\n",
      "Epoch: 34\tFidelity = 0.506576\tKL_Divergence = 2.555841\n",
      "Epoch: 35\tFidelity = 0.506306\tKL_Divergence = 2.579248\n",
      "Epoch: 36\tFidelity = 0.506662\tKL_Divergence = 2.548618\n",
      "Epoch: 37\tFidelity = 0.506398\tKL_Divergence = 2.571193\n",
      "Epoch: 38\tFidelity = 0.506128\tKL_Divergence = 2.595243\n",
      "Epoch: 39\tFidelity = 0.507208\tKL_Divergence = 2.504698\n",
      "Epoch: 40\tFidelity = 0.506585\tKL_Divergence = 2.555097\n",
      "Epoch: 41\tFidelity = 0.506586\tKL_Divergence = 2.555005\n",
      "Epoch: 42\tFidelity = 0.506335\tKL_Divergence = 2.576685\n",
      "Epoch: 43\tFidelity = 0.506261\tKL_Divergence = 2.583252\n",
      "Epoch: 44\tFidelity = 0.505925\tKL_Divergence = 2.613985\n",
      "Epoch: 45\tFidelity = 0.506157\tKL_Divergence = 2.592563\n",
      "Epoch: 46\tFidelity = 0.507146\tKL_Divergence = 2.509526\n",
      "Epoch: 47\tFidelity = 0.506671\tKL_Divergence = 2.547898\n",
      "Epoch: 48\tFidelity = 0.506600\tKL_Divergence = 2.553804\n",
      "Epoch: 49\tFidelity = 0.506871\tKL_Divergence = 2.531393\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:24:41,303] Trial 214 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.506469\tKL_Divergence = 2.565029\n",
      "Total time elapsed during training: 45.483 s\n",
      "Trial 214 pruned. \n",
      "Epoch: 1\tFidelity = 0.506327\tKL_Divergence = 2.577414\n",
      "Epoch: 2\tFidelity = 0.506231\tKL_Divergence = 2.585902\n",
      "Epoch: 3\tFidelity = 0.506226\tKL_Divergence = 2.586413\n",
      "Epoch: 4\tFidelity = 0.505831\tKL_Divergence = 2.622875\n",
      "Epoch: 5\tFidelity = 0.507069\tKL_Divergence = 2.515537\n",
      "Epoch: 6\tFidelity = 0.506481\tKL_Divergence = 2.564001\n",
      "Epoch: 7\tFidelity = 0.506744\tKL_Divergence = 2.541823\n",
      "Epoch: 8\tFidelity = 0.506933\tKL_Divergence = 2.526381\n",
      "Epoch: 9\tFidelity = 0.505867\tKL_Divergence = 2.619461\n",
      "Epoch: 10\tFidelity = 0.506293\tKL_Divergence = 2.580462\n",
      "Epoch: 11\tFidelity = 0.506675\tKL_Divergence = 2.547590\n",
      "Epoch: 12\tFidelity = 0.505976\tKL_Divergence = 2.609274\n",
      "Epoch: 13\tFidelity = 0.507300\tKL_Divergence = 2.497671\n",
      "Epoch: 14\tFidelity = 0.507200\tKL_Divergence = 2.505347\n",
      "Epoch: 15\tFidelity = 0.506508\tKL_Divergence = 2.561714\n",
      "Epoch: 16\tFidelity = 0.507336\tKL_Divergence = 2.494913\n",
      "Epoch: 17\tFidelity = 0.506061\tKL_Divergence = 2.601344\n",
      "Epoch: 18\tFidelity = 0.507014\tKL_Divergence = 2.519899\n",
      "Epoch: 19\tFidelity = 0.506522\tKL_Divergence = 2.560478\n",
      "Epoch: 20\tFidelity = 0.506885\tKL_Divergence = 2.530300\n",
      "Epoch: 21\tFidelity = 0.507613\tKL_Divergence = 2.474187\n",
      "Epoch: 22\tFidelity = 0.506065\tKL_Divergence = 2.600961\n",
      "Epoch: 23\tFidelity = 0.506486\tKL_Divergence = 2.563541\n",
      "Epoch: 24\tFidelity = 0.506257\tKL_Divergence = 2.583596\n",
      "Epoch: 25\tFidelity = 0.507374\tKL_Divergence = 2.492052\n",
      "Epoch: 26\tFidelity = 0.507133\tKL_Divergence = 2.510565\n",
      "Epoch: 27\tFidelity = 0.506023\tKL_Divergence = 2.604922\n",
      "Epoch: 28\tFidelity = 0.506725\tKL_Divergence = 2.543424\n",
      "Epoch: 29\tFidelity = 0.506653\tKL_Divergence = 2.549465\n",
      "Epoch: 30\tFidelity = 0.506858\tKL_Divergence = 2.532508\n",
      "Epoch: 31\tFidelity = 0.507362\tKL_Divergence = 2.492918\n",
      "Epoch: 32\tFidelity = 0.506511\tKL_Divergence = 2.561420\n",
      "Epoch: 33\tFidelity = 0.506273\tKL_Divergence = 2.582218\n",
      "Epoch: 34\tFidelity = 0.505951\tKL_Divergence = 2.611562\n",
      "Epoch: 35\tFidelity = 0.506927\tKL_Divergence = 2.526923\n",
      "Epoch: 36\tFidelity = 0.506523\tKL_Divergence = 2.560420\n",
      "Epoch: 37\tFidelity = 0.506934\tKL_Divergence = 2.526341\n",
      "Epoch: 38\tFidelity = 0.506255\tKL_Divergence = 2.583887\n",
      "Epoch: 39\tFidelity = 0.506288\tKL_Divergence = 2.580925\n",
      "Epoch: 40\tFidelity = 0.506453\tKL_Divergence = 2.566499\n",
      "Epoch: 41\tFidelity = 0.506457\tKL_Divergence = 2.566128\n",
      "Epoch: 42\tFidelity = 0.505550\tKL_Divergence = 2.650468\n",
      "Epoch: 43\tFidelity = 0.507004\tKL_Divergence = 2.520770\n",
      "Epoch: 44\tFidelity = 0.506249\tKL_Divergence = 2.584367\n",
      "Epoch: 45\tFidelity = 0.507230\tKL_Divergence = 2.503053\n",
      "Epoch: 46\tFidelity = 0.507095\tKL_Divergence = 2.513615\n",
      "Epoch: 47\tFidelity = 0.506204\tKL_Divergence = 2.588396\n",
      "Epoch: 48\tFidelity = 0.506663\tKL_Divergence = 2.548612\n",
      "Epoch: 49\tFidelity = 0.507116\tKL_Divergence = 2.511941\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:25:19,842] Trial 215 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.506253\tKL_Divergence = 2.584030\n",
      "Total time elapsed during training: 38.382 s\n",
      "Trial 215 pruned. \n",
      "Epoch: 1\tFidelity = 0.506100\tKL_Divergence = 2.597798\n",
      "Epoch: 2\tFidelity = 0.506007\tKL_Divergence = 2.606357\n",
      "Epoch: 3\tFidelity = 0.506073\tKL_Divergence = 2.600316\n",
      "Epoch: 4\tFidelity = 0.507644\tKL_Divergence = 2.471899\n",
      "Epoch: 5\tFidelity = 0.505673\tKL_Divergence = 2.638019\n",
      "Epoch: 6\tFidelity = 0.506387\tKL_Divergence = 2.571893\n",
      "Epoch: 7\tFidelity = 0.506628\tKL_Divergence = 2.551381\n",
      "Epoch: 8\tFidelity = 0.506996\tKL_Divergence = 2.521148\n",
      "Epoch: 9\tFidelity = 0.507255\tKL_Divergence = 2.500917\n",
      "Epoch: 10\tFidelity = 0.506762\tKL_Divergence = 2.540194\n",
      "Epoch: 11\tFidelity = 0.506671\tKL_Divergence = 2.547888\n",
      "Epoch: 12\tFidelity = 0.505543\tKL_Divergence = 2.651192\n",
      "Epoch: 13\tFidelity = 0.506375\tKL_Divergence = 2.573239\n",
      "Epoch: 14\tFidelity = 0.505815\tKL_Divergence = 2.624513\n",
      "Epoch: 15\tFidelity = 0.506332\tKL_Divergence = 2.577024\n",
      "Epoch: 16\tFidelity = 0.505983\tKL_Divergence = 2.608512\n",
      "Epoch: 17\tFidelity = 0.505827\tKL_Divergence = 2.623275\n",
      "Epoch: 18\tFidelity = 0.505904\tKL_Divergence = 2.616069\n",
      "Epoch: 19\tFidelity = 0.506214\tKL_Divergence = 2.587477\n",
      "Epoch: 20\tFidelity = 0.506827\tKL_Divergence = 2.535037\n",
      "Epoch: 21\tFidelity = 0.506722\tKL_Divergence = 2.543629\n",
      "Epoch: 22\tFidelity = 0.506153\tKL_Divergence = 2.592988\n",
      "Epoch: 23\tFidelity = 0.507428\tKL_Divergence = 2.487910\n",
      "Epoch: 24\tFidelity = 0.505753\tKL_Divergence = 2.630348\n",
      "Epoch: 25\tFidelity = 0.506489\tKL_Divergence = 2.563279\n",
      "Epoch: 26\tFidelity = 0.506821\tKL_Divergence = 2.535495\n",
      "Epoch: 27\tFidelity = 0.506942\tKL_Divergence = 2.525720\n",
      "Epoch: 28\tFidelity = 0.507052\tKL_Divergence = 2.516909\n",
      "Epoch: 29\tFidelity = 0.506679\tKL_Divergence = 2.547186\n",
      "Epoch: 30\tFidelity = 0.505991\tKL_Divergence = 2.607743\n",
      "Epoch: 31\tFidelity = 0.506714\tKL_Divergence = 2.544231\n",
      "Epoch: 32\tFidelity = 0.505851\tKL_Divergence = 2.620961\n",
      "Epoch: 33\tFidelity = 0.506826\tKL_Divergence = 2.535114\n",
      "Epoch: 34\tFidelity = 0.505965\tKL_Divergence = 2.610311\n",
      "Epoch: 35\tFidelity = 0.505722\tKL_Divergence = 2.633526\n",
      "Epoch: 36\tFidelity = 0.506636\tKL_Divergence = 2.550821\n",
      "Epoch: 37\tFidelity = 0.507294\tKL_Divergence = 2.498051\n",
      "Epoch: 38\tFidelity = 0.506300\tKL_Divergence = 2.579833\n",
      "Epoch: 39\tFidelity = 0.506503\tKL_Divergence = 2.562093\n",
      "Epoch: 40\tFidelity = 0.505958\tKL_Divergence = 2.610920\n",
      "Epoch: 41\tFidelity = 0.506230\tKL_Divergence = 2.586030\n",
      "Epoch: 42\tFidelity = 0.506111\tKL_Divergence = 2.596764\n",
      "Epoch: 43\tFidelity = 0.506496\tKL_Divergence = 2.562725\n",
      "Epoch: 44\tFidelity = 0.505842\tKL_Divergence = 2.621936\n",
      "Epoch: 45\tFidelity = 0.506787\tKL_Divergence = 2.538329\n",
      "Epoch: 46\tFidelity = 0.505908\tKL_Divergence = 2.615646\n",
      "Epoch: 47\tFidelity = 0.506661\tKL_Divergence = 2.548771\n",
      "Epoch: 48\tFidelity = 0.506205\tKL_Divergence = 2.588307\n",
      "Epoch: 49\tFidelity = 0.505752\tKL_Divergence = 2.630541\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:26:04,865] Trial 216 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.505738\tKL_Divergence = 2.631796\n",
      "Total time elapsed during training: 44.858 s\n",
      "Trial 216 pruned. \n",
      "Epoch: 1\tFidelity = 0.506513\tKL_Divergence = 2.561217\n",
      "Epoch: 2\tFidelity = 0.507043\tKL_Divergence = 2.517606\n",
      "Epoch: 3\tFidelity = 0.506944\tKL_Divergence = 2.525475\n",
      "Epoch: 4\tFidelity = 0.505963\tKL_Divergence = 2.610463\n",
      "Epoch: 5\tFidelity = 0.506541\tKL_Divergence = 2.558784\n",
      "Epoch: 6\tFidelity = 0.506596\tKL_Divergence = 2.554216\n",
      "Epoch: 7\tFidelity = 0.506818\tKL_Divergence = 2.535717\n",
      "Epoch: 8\tFidelity = 0.505414\tKL_Divergence = 2.664231\n",
      "Epoch: 9\tFidelity = 0.506563\tKL_Divergence = 2.556984\n",
      "Epoch: 10\tFidelity = 0.506693\tKL_Divergence = 2.546072\n",
      "Epoch: 11\tFidelity = 0.506492\tKL_Divergence = 2.563087\n",
      "Epoch: 12\tFidelity = 0.505488\tKL_Divergence = 2.656702\n",
      "Epoch: 13\tFidelity = 0.507435\tKL_Divergence = 2.487426\n",
      "Epoch: 14\tFidelity = 0.505406\tKL_Divergence = 2.665125\n",
      "Epoch: 15\tFidelity = 0.506927\tKL_Divergence = 2.526942\n",
      "Epoch: 16\tFidelity = 0.506161\tKL_Divergence = 2.592287\n",
      "Epoch: 17\tFidelity = 0.506628\tKL_Divergence = 2.551578\n",
      "Epoch: 18\tFidelity = 0.506565\tKL_Divergence = 2.556858\n",
      "Epoch: 19\tFidelity = 0.506530\tKL_Divergence = 2.559807\n",
      "Epoch: 20\tFidelity = 0.506470\tKL_Divergence = 2.564983\n",
      "Epoch: 21\tFidelity = 0.506140\tKL_Divergence = 2.594255\n",
      "Epoch: 22\tFidelity = 0.506146\tKL_Divergence = 2.593570\n",
      "Epoch: 23\tFidelity = 0.505447\tKL_Divergence = 2.660893\n",
      "Epoch: 24\tFidelity = 0.505066\tKL_Divergence = 2.701336\n",
      "Epoch: 25\tFidelity = 0.506423\tKL_Divergence = 2.569037\n",
      "Epoch: 26\tFidelity = 0.506487\tKL_Divergence = 2.563458\n",
      "Epoch: 27\tFidelity = 0.506190\tKL_Divergence = 2.589693\n",
      "Epoch: 28\tFidelity = 0.505856\tKL_Divergence = 2.620561\n",
      "Epoch: 29\tFidelity = 0.506337\tKL_Divergence = 2.576593\n",
      "Epoch: 30\tFidelity = 0.506019\tKL_Divergence = 2.605342\n",
      "Epoch: 31\tFidelity = 0.506091\tKL_Divergence = 2.598654\n",
      "Epoch: 32\tFidelity = 0.506785\tKL_Divergence = 2.538451\n",
      "Epoch: 33\tFidelity = 0.507414\tKL_Divergence = 2.489066\n",
      "Epoch: 34\tFidelity = 0.505610\tKL_Divergence = 2.644448\n",
      "Epoch: 35\tFidelity = 0.505948\tKL_Divergence = 2.611946\n",
      "Epoch: 36\tFidelity = 0.506211\tKL_Divergence = 2.587769\n",
      "Epoch: 37\tFidelity = 0.506424\tKL_Divergence = 2.568982\n",
      "Epoch: 38\tFidelity = 0.506482\tKL_Divergence = 2.563823\n",
      "Epoch: 39\tFidelity = 0.507391\tKL_Divergence = 2.490627\n",
      "Epoch: 40\tFidelity = 0.507430\tKL_Divergence = 2.487759\n",
      "Epoch: 41\tFidelity = 0.505337\tKL_Divergence = 2.672337\n",
      "Epoch: 42\tFidelity = 0.505719\tKL_Divergence = 2.633803\n",
      "Epoch: 43\tFidelity = 0.506468\tKL_Divergence = 2.565127\n",
      "Epoch: 44\tFidelity = 0.507392\tKL_Divergence = 2.490686\n",
      "Epoch: 45\tFidelity = 0.505612\tKL_Divergence = 2.644175\n",
      "Epoch: 46\tFidelity = 0.506205\tKL_Divergence = 2.588207\n",
      "Epoch: 47\tFidelity = 0.505998\tKL_Divergence = 2.607033\n",
      "Epoch: 48\tFidelity = 0.506189\tKL_Divergence = 2.589604\n",
      "Epoch: 49\tFidelity = 0.505656\tKL_Divergence = 2.639787\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:27:25,482] Trial 217 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.506511\tKL_Divergence = 2.561377\n",
      "Total time elapsed during training: 80.460 s\n",
      "Trial 217 pruned. \n",
      "Epoch: 1\tFidelity = 0.506555\tKL_Divergence = 2.557379\n",
      "Epoch: 2\tFidelity = 0.507089\tKL_Divergence = 2.513164\n",
      "Epoch: 3\tFidelity = 0.507139\tKL_Divergence = 2.509589\n",
      "Epoch: 4\tFidelity = 0.507502\tKL_Divergence = 2.481719\n",
      "Epoch: 5\tFidelity = 0.506810\tKL_Divergence = 2.535901\n",
      "Epoch: 6\tFidelity = 0.507021\tKL_Divergence = 2.518444\n",
      "Epoch: 7\tFidelity = 0.506086\tKL_Divergence = 2.598130\n",
      "Epoch: 8\tFidelity = 0.505879\tKL_Divergence = 2.617960\n",
      "Epoch: 9\tFidelity = 0.506486\tKL_Divergence = 2.563486\n",
      "Epoch: 10\tFidelity = 0.507294\tKL_Divergence = 2.497902\n",
      "Epoch: 11\tFidelity = 0.505687\tKL_Divergence = 2.636569\n",
      "Epoch: 12\tFidelity = 0.506238\tKL_Divergence = 2.585123\n",
      "Epoch: 13\tFidelity = 0.505326\tKL_Divergence = 2.673278\n",
      "Epoch: 14\tFidelity = 0.506538\tKL_Divergence = 2.558855\n",
      "Epoch: 15\tFidelity = 0.506412\tKL_Divergence = 2.569413\n",
      "Epoch: 16\tFidelity = 0.507382\tKL_Divergence = 2.490779\n",
      "Epoch: 17\tFidelity = 0.506208\tKL_Divergence = 2.587401\n",
      "Epoch: 18\tFidelity = 0.507064\tKL_Divergence = 2.515510\n",
      "Epoch: 19\tFidelity = 0.505931\tKL_Divergence = 2.613036\n",
      "Epoch: 20\tFidelity = 0.505297\tKL_Divergence = 2.675966\n",
      "Epoch: 21\tFidelity = 0.507307\tKL_Divergence = 2.496056\n",
      "Epoch: 22\tFidelity = 0.506830\tKL_Divergence = 2.533785\n",
      "Epoch: 23\tFidelity = 0.508042\tKL_Divergence = 2.442919\n",
      "Epoch: 24\tFidelity = 0.506239\tKL_Divergence = 2.584153\n",
      "Epoch: 25\tFidelity = 0.506009\tKL_Divergence = 2.605558\n",
      "Epoch: 26\tFidelity = 0.505711\tKL_Divergence = 2.634287\n",
      "Epoch: 27\tFidelity = 0.505941\tKL_Divergence = 2.612409\n",
      "Epoch: 28\tFidelity = 0.506332\tKL_Divergence = 2.576885\n",
      "Epoch: 29\tFidelity = 0.506910\tKL_Divergence = 2.528199\n",
      "Epoch: 30\tFidelity = 0.507059\tKL_Divergence = 2.516205\n",
      "Epoch: 31\tFidelity = 0.508647\tKL_Divergence = 2.402890\n",
      "Epoch: 32\tFidelity = 0.505783\tKL_Divergence = 2.627146\n",
      "Epoch: 33\tFidelity = 0.505542\tKL_Divergence = 2.650836\n",
      "Epoch: 34\tFidelity = 0.506498\tKL_Divergence = 2.562273\n",
      "Epoch: 35\tFidelity = 0.507224\tKL_Divergence = 2.503211\n",
      "Epoch: 36\tFidelity = 0.506084\tKL_Divergence = 2.599083\n",
      "Epoch: 37\tFidelity = 0.505812\tKL_Divergence = 2.624613\n",
      "Epoch: 38\tFidelity = 0.507067\tKL_Divergence = 2.515508\n",
      "Epoch: 39\tFidelity = 0.506231\tKL_Divergence = 2.585867\n",
      "Epoch: 40\tFidelity = 0.505963\tKL_Divergence = 2.610314\n",
      "Epoch: 41\tFidelity = 0.506491\tKL_Divergence = 2.562810\n",
      "Epoch: 42\tFidelity = 0.507292\tKL_Divergence = 2.498084\n",
      "Epoch: 43\tFidelity = 0.507052\tKL_Divergence = 2.516801\n",
      "Epoch: 44\tFidelity = 0.507714\tKL_Divergence = 2.466720\n",
      "Epoch: 45\tFidelity = 0.507624\tKL_Divergence = 2.473256\n",
      "Epoch: 46\tFidelity = 0.505956\tKL_Divergence = 2.610977\n",
      "Epoch: 47\tFidelity = 0.507351\tKL_Divergence = 2.493599\n",
      "Epoch: 48\tFidelity = 0.505921\tKL_Divergence = 2.614250\n",
      "Epoch: 49\tFidelity = 0.508298\tKL_Divergence = 2.425964\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:28:02,193] Trial 218 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.506035\tKL_Divergence = 2.603430\n",
      "Total time elapsed during training: 36.568 s\n",
      "Trial 218 pruned. \n",
      "Epoch: 1\tFidelity = 0.507189\tKL_Divergence = 2.505825\n",
      "Epoch: 2\tFidelity = 0.506519\tKL_Divergence = 2.560447\n",
      "Epoch: 3\tFidelity = 0.505801\tKL_Divergence = 2.625619\n",
      "Epoch: 4\tFidelity = 0.506611\tKL_Divergence = 2.552710\n",
      "Epoch: 5\tFidelity = 0.506595\tKL_Divergence = 2.554073\n",
      "Epoch: 6\tFidelity = 0.506443\tKL_Divergence = 2.567163\n",
      "Epoch: 7\tFidelity = 0.505763\tKL_Divergence = 2.629371\n",
      "Epoch: 8\tFidelity = 0.506712\tKL_Divergence = 2.544349\n",
      "Epoch: 9\tFidelity = 0.506360\tKL_Divergence = 2.574316\n",
      "Epoch: 10\tFidelity = 0.505888\tKL_Divergence = 2.617343\n",
      "Epoch: 11\tFidelity = 0.506598\tKL_Divergence = 2.553829\n",
      "Epoch: 12\tFidelity = 0.506935\tKL_Divergence = 2.526087\n",
      "Epoch: 13\tFidelity = 0.506469\tKL_Divergence = 2.564864\n",
      "Epoch: 14\tFidelity = 0.507303\tKL_Divergence = 2.497184\n",
      "Epoch: 15\tFidelity = 0.506432\tKL_Divergence = 2.567983\n",
      "Epoch: 16\tFidelity = 0.506726\tKL_Divergence = 2.543161\n",
      "Epoch: 17\tFidelity = 0.506468\tKL_Divergence = 2.564931\n",
      "Epoch: 18\tFidelity = 0.507309\tKL_Divergence = 2.496748\n",
      "Epoch: 19\tFidelity = 0.506256\tKL_Divergence = 2.583520\n",
      "Epoch: 20\tFidelity = 0.507304\tKL_Divergence = 2.497141\n",
      "Epoch: 21\tFidelity = 0.506123\tKL_Divergence = 2.595554\n",
      "Epoch: 22\tFidelity = 0.506665\tKL_Divergence = 2.548292\n",
      "Epoch: 23\tFidelity = 0.505996\tKL_Divergence = 2.607274\n",
      "Epoch: 24\tFidelity = 0.507134\tKL_Divergence = 2.510312\n",
      "Epoch: 25\tFidelity = 0.506951\tKL_Divergence = 2.524851\n",
      "Epoch: 26\tFidelity = 0.506340\tKL_Divergence = 2.576204\n",
      "Epoch: 27\tFidelity = 0.505612\tKL_Divergence = 2.644190\n",
      "Epoch: 28\tFidelity = 0.506270\tKL_Divergence = 2.582390\n",
      "Epoch: 29\tFidelity = 0.507241\tKL_Divergence = 2.502092\n",
      "Epoch: 30\tFidelity = 0.505814\tKL_Divergence = 2.624532\n",
      "Epoch: 31\tFidelity = 0.506119\tKL_Divergence = 2.595999\n",
      "Epoch: 32\tFidelity = 0.506067\tKL_Divergence = 2.600802\n",
      "Epoch: 33\tFidelity = 0.506863\tKL_Divergence = 2.532047\n",
      "Epoch: 34\tFidelity = 0.507142\tKL_Divergence = 2.509850\n",
      "Epoch: 35\tFidelity = 0.506378\tKL_Divergence = 2.572925\n",
      "Epoch: 36\tFidelity = 0.506709\tKL_Divergence = 2.544737\n",
      "Epoch: 37\tFidelity = 0.505324\tKL_Divergence = 2.673695\n",
      "Epoch: 38\tFidelity = 0.506528\tKL_Divergence = 2.560016\n",
      "Epoch: 39\tFidelity = 0.507242\tKL_Divergence = 2.502116\n",
      "Epoch: 40\tFidelity = 0.507258\tKL_Divergence = 2.500855\n",
      "Epoch: 41\tFidelity = 0.506429\tKL_Divergence = 2.568480\n",
      "Epoch: 42\tFidelity = 0.506157\tKL_Divergence = 2.592556\n",
      "Epoch: 43\tFidelity = 0.506376\tKL_Divergence = 2.573139\n",
      "Epoch: 44\tFidelity = 0.506071\tKL_Divergence = 2.600404\n",
      "Epoch: 45\tFidelity = 0.506531\tKL_Divergence = 2.559693\n",
      "Epoch: 46\tFidelity = 0.506393\tKL_Divergence = 2.571626\n",
      "Epoch: 47\tFidelity = 0.508158\tKL_Divergence = 2.435559\n",
      "Epoch: 48\tFidelity = 0.505985\tKL_Divergence = 2.608449\n",
      "Epoch: 49\tFidelity = 0.506550\tKL_Divergence = 2.558101\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:29:18,512] Trial 219 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.506960\tKL_Divergence = 2.524161\n",
      "Total time elapsed during training: 76.171 s\n",
      "Trial 219 pruned. \n",
      "Epoch: 1\tFidelity = 0.506462\tKL_Divergence = 2.565634\n",
      "Epoch: 2\tFidelity = 0.506425\tKL_Divergence = 2.568809\n",
      "Epoch: 3\tFidelity = 0.506446\tKL_Divergence = 2.567005\n",
      "Epoch: 4\tFidelity = 0.506131\tKL_Divergence = 2.594961\n",
      "Epoch: 5\tFidelity = 0.506750\tKL_Divergence = 2.541339\n",
      "Epoch: 6\tFidelity = 0.506525\tKL_Divergence = 2.560178\n",
      "Epoch: 7\tFidelity = 0.506062\tKL_Divergence = 2.601292\n",
      "Epoch: 8\tFidelity = 0.506466\tKL_Divergence = 2.565326\n",
      "Epoch: 9\tFidelity = 0.507180\tKL_Divergence = 2.506834\n",
      "Epoch: 10\tFidelity = 0.506541\tKL_Divergence = 2.558901\n",
      "Epoch: 11\tFidelity = 0.506498\tKL_Divergence = 2.562553\n",
      "Epoch: 12\tFidelity = 0.507039\tKL_Divergence = 2.517940\n",
      "Epoch: 13\tFidelity = 0.506057\tKL_Divergence = 2.601764\n",
      "Epoch: 14\tFidelity = 0.506213\tKL_Divergence = 2.587529\n",
      "Epoch: 15\tFidelity = 0.506175\tKL_Divergence = 2.590969\n",
      "Epoch: 16\tFidelity = 0.506552\tKL_Divergence = 2.557947\n",
      "Epoch: 17\tFidelity = 0.506631\tKL_Divergence = 2.551237\n",
      "Epoch: 18\tFidelity = 0.506566\tKL_Divergence = 2.556730\n",
      "Epoch: 19\tFidelity = 0.506299\tKL_Divergence = 2.579919\n",
      "Epoch: 20\tFidelity = 0.506025\tKL_Divergence = 2.604676\n",
      "Epoch: 21\tFidelity = 0.506418\tKL_Divergence = 2.569469\n",
      "Epoch: 22\tFidelity = 0.506655\tKL_Divergence = 2.549197\n",
      "Epoch: 23\tFidelity = 0.506243\tKL_Divergence = 2.584834\n",
      "Epoch: 24\tFidelity = 0.506883\tKL_Divergence = 2.530397\n",
      "Epoch: 25\tFidelity = 0.506596\tKL_Divergence = 2.554180\n",
      "Epoch: 26\tFidelity = 0.506188\tKL_Divergence = 2.589771\n",
      "Epoch: 27\tFidelity = 0.506471\tKL_Divergence = 2.564820\n",
      "Epoch: 28\tFidelity = 0.506247\tKL_Divergence = 2.584448\n",
      "Epoch: 29\tFidelity = 0.506220\tKL_Divergence = 2.586896\n",
      "Epoch: 30\tFidelity = 0.506505\tKL_Divergence = 2.561953\n",
      "Epoch: 31\tFidelity = 0.505998\tKL_Divergence = 2.607116\n",
      "Epoch: 32\tFidelity = 0.506341\tKL_Divergence = 2.576099\n",
      "Epoch: 33\tFidelity = 0.506396\tKL_Divergence = 2.571349\n",
      "Epoch: 34\tFidelity = 0.506200\tKL_Divergence = 2.588669\n",
      "Epoch: 35\tFidelity = 0.506171\tKL_Divergence = 2.591351\n",
      "Epoch: 36\tFidelity = 0.506131\tKL_Divergence = 2.594998\n",
      "Epoch: 37\tFidelity = 0.506576\tKL_Divergence = 2.555850\n",
      "Epoch: 38\tFidelity = 0.506521\tKL_Divergence = 2.560594\n",
      "Epoch: 39\tFidelity = 0.507060\tKL_Divergence = 2.516274\n",
      "Epoch: 40\tFidelity = 0.506428\tKL_Divergence = 2.568540\n",
      "Epoch: 41\tFidelity = 0.506321\tKL_Divergence = 2.577906\n",
      "Epoch: 42\tFidelity = 0.506269\tKL_Divergence = 2.582486\n",
      "Epoch: 43\tFidelity = 0.506853\tKL_Divergence = 2.532848\n",
      "Epoch: 44\tFidelity = 0.506701\tKL_Divergence = 2.545358\n",
      "Epoch: 45\tFidelity = 0.505975\tKL_Divergence = 2.609269\n",
      "Epoch: 46\tFidelity = 0.506851\tKL_Divergence = 2.533000\n",
      "Epoch: 47\tFidelity = 0.506659\tKL_Divergence = 2.548844\n",
      "Epoch: 48\tFidelity = 0.506442\tKL_Divergence = 2.567337\n",
      "Epoch: 49\tFidelity = 0.506689\tKL_Divergence = 2.546386\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:29:55,391] Trial 220 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.506328\tKL_Divergence = 2.577300\n",
      "Total time elapsed during training: 36.732 s\n",
      "Trial 220 pruned. \n",
      "Epoch: 1\tFidelity = 0.505755\tKL_Divergence = 2.629937\n",
      "Epoch: 2\tFidelity = 0.506106\tKL_Divergence = 2.597233\n",
      "Epoch: 3\tFidelity = 0.505567\tKL_Divergence = 2.648545\n",
      "Epoch: 4\tFidelity = 0.505129\tKL_Divergence = 2.694334\n",
      "Epoch: 5\tFidelity = 0.506013\tKL_Divergence = 2.605532\n",
      "Epoch: 6\tFidelity = 0.507398\tKL_Divergence = 2.489913\n",
      "Epoch: 7\tFidelity = 0.506569\tKL_Divergence = 2.556261\n",
      "Epoch: 8\tFidelity = 0.505488\tKL_Divergence = 2.656503\n",
      "Epoch: 9\tFidelity = 0.505526\tKL_Divergence = 2.652709\n",
      "Epoch: 10\tFidelity = 0.507255\tKL_Divergence = 2.501003\n",
      "Epoch: 11\tFidelity = 0.508359\tKL_Divergence = 2.421554\n",
      "Epoch: 12\tFidelity = 0.507444\tKL_Divergence = 2.486074\n",
      "Epoch: 13\tFidelity = 0.508454\tKL_Divergence = 2.415055\n",
      "Epoch: 14\tFidelity = 0.504821\tKL_Divergence = 2.728660\n",
      "Epoch: 15\tFidelity = 0.505597\tKL_Divergence = 2.645830\n",
      "Epoch: 16\tFidelity = 0.505197\tKL_Divergence = 2.686992\n",
      "Epoch: 17\tFidelity = 0.505166\tKL_Divergence = 2.690433\n",
      "Epoch: 18\tFidelity = 0.506334\tKL_Divergence = 2.576919\n",
      "Epoch: 19\tFidelity = 0.508187\tKL_Divergence = 2.433715\n",
      "Epoch: 20\tFidelity = 0.506289\tKL_Divergence = 2.580679\n",
      "Epoch: 21\tFidelity = 0.505832\tKL_Divergence = 2.622864\n",
      "Epoch: 22\tFidelity = 0.507118\tKL_Divergence = 2.511783\n",
      "Epoch: 23\tFidelity = 0.506817\tKL_Divergence = 2.535940\n",
      "Epoch: 24\tFidelity = 0.506879\tKL_Divergence = 2.530898\n",
      "Epoch: 25\tFidelity = 0.505617\tKL_Divergence = 2.643745\n",
      "Epoch: 26\tFidelity = 0.506509\tKL_Divergence = 2.561716\n",
      "Epoch: 27\tFidelity = 0.505168\tKL_Divergence = 2.690227\n",
      "Epoch: 28\tFidelity = 0.506388\tKL_Divergence = 2.572098\n",
      "Epoch: 29\tFidelity = 0.505433\tKL_Divergence = 2.662395\n",
      "Epoch: 30\tFidelity = 0.506456\tKL_Divergence = 2.566231\n",
      "Epoch: 31\tFidelity = 0.506025\tKL_Divergence = 2.604771\n",
      "Epoch: 32\tFidelity = 0.505689\tKL_Divergence = 2.636245\n",
      "Epoch: 33\tFidelity = 0.504588\tKL_Divergence = 2.755973\n",
      "Epoch: 34\tFidelity = 0.504747\tKL_Divergence = 2.737192\n",
      "Epoch: 35\tFidelity = 0.506594\tKL_Divergence = 2.554401\n",
      "Epoch: 36\tFidelity = 0.507169\tKL_Divergence = 2.507809\n",
      "Epoch: 37\tFidelity = 0.506342\tKL_Divergence = 2.576034\n",
      "Epoch: 38\tFidelity = 0.507511\tKL_Divergence = 2.481786\n",
      "Epoch: 39\tFidelity = 0.505682\tKL_Divergence = 2.637317\n",
      "Epoch: 40\tFidelity = 0.505864\tKL_Divergence = 2.619711\n",
      "Epoch: 41\tFidelity = 0.505594\tKL_Divergence = 2.645285\n",
      "Epoch: 42\tFidelity = 0.506496\tKL_Divergence = 2.562355\n",
      "Epoch: 43\tFidelity = 0.505695\tKL_Divergence = 2.636023\n",
      "Epoch: 44\tFidelity = 0.506286\tKL_Divergence = 2.581109\n",
      "Epoch: 45\tFidelity = 0.506349\tKL_Divergence = 2.575523\n",
      "Epoch: 46\tFidelity = 0.505612\tKL_Divergence = 2.644190\n",
      "Epoch: 47\tFidelity = 0.507272\tKL_Divergence = 2.499742\n",
      "Epoch: 48\tFidelity = 0.507292\tKL_Divergence = 2.497952\n",
      "Epoch: 49\tFidelity = 0.508366\tKL_Divergence = 2.421115\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:30:31,923] Trial 221 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.505966\tKL_Divergence = 2.608522\n",
      "Total time elapsed during training: 36.376 s\n",
      "Trial 221 pruned. \n",
      "Epoch: 1\tFidelity = 0.505607\tKL_Divergence = 2.644063\n",
      "Epoch: 2\tFidelity = 0.508837\tKL_Divergence = 2.389993\n",
      "Epoch: 3\tFidelity = 0.506331\tKL_Divergence = 2.576411\n",
      "Epoch: 4\tFidelity = 0.506330\tKL_Divergence = 2.576970\n",
      "Epoch: 5\tFidelity = 0.507527\tKL_Divergence = 2.480123\n",
      "Epoch: 6\tFidelity = 0.507440\tKL_Divergence = 2.486451\n",
      "Epoch: 7\tFidelity = 0.506575\tKL_Divergence = 2.555268\n",
      "Epoch: 8\tFidelity = 0.507519\tKL_Divergence = 2.481007\n",
      "Epoch: 9\tFidelity = 0.506566\tKL_Divergence = 2.556565\n",
      "Epoch: 10\tFidelity = 0.506287\tKL_Divergence = 2.580870\n",
      "Epoch: 11\tFidelity = 0.506162\tKL_Divergence = 2.591978\n",
      "Epoch: 12\tFidelity = 0.505274\tKL_Divergence = 2.678717\n",
      "Epoch: 13\tFidelity = 0.508093\tKL_Divergence = 2.440066\n",
      "Epoch: 14\tFidelity = 0.506627\tKL_Divergence = 2.551153\n",
      "Epoch: 15\tFidelity = 0.504428\tKL_Divergence = 2.775281\n",
      "Epoch: 16\tFidelity = 0.506541\tKL_Divergence = 2.557926\n",
      "Epoch: 17\tFidelity = 0.507426\tKL_Divergence = 2.487119\n",
      "Epoch: 18\tFidelity = 0.507158\tKL_Divergence = 2.507899\n",
      "Epoch: 19\tFidelity = 0.505270\tKL_Divergence = 2.678334\n",
      "Epoch: 20\tFidelity = 0.505158\tKL_Divergence = 2.691165\n",
      "Epoch: 21\tFidelity = 0.506508\tKL_Divergence = 2.561361\n",
      "Epoch: 22\tFidelity = 0.508342\tKL_Divergence = 2.422453\n",
      "Epoch: 23\tFidelity = 0.507101\tKL_Divergence = 2.513052\n",
      "Epoch: 24\tFidelity = 0.506906\tKL_Divergence = 2.528453\n",
      "Epoch: 25\tFidelity = 0.506161\tKL_Divergence = 2.592191\n",
      "Epoch: 26\tFidelity = 0.504696\tKL_Divergence = 2.743287\n",
      "Epoch: 27\tFidelity = 0.506366\tKL_Divergence = 2.573660\n",
      "Epoch: 28\tFidelity = 0.505339\tKL_Divergence = 2.671749\n",
      "Epoch: 29\tFidelity = 0.505739\tKL_Divergence = 2.631648\n",
      "Epoch: 30\tFidelity = 0.506305\tKL_Divergence = 2.579026\n",
      "Epoch: 31\tFidelity = 0.505988\tKL_Divergence = 2.608055\n",
      "Epoch: 32\tFidelity = 0.506663\tKL_Divergence = 2.548281\n",
      "Epoch: 33\tFidelity = 0.506551\tKL_Divergence = 2.557447\n",
      "Epoch: 34\tFidelity = 0.507310\tKL_Divergence = 2.496748\n",
      "Epoch: 35\tFidelity = 0.508255\tKL_Divergence = 2.428895\n",
      "Epoch: 36\tFidelity = 0.506325\tKL_Divergence = 2.577552\n",
      "Epoch: 37\tFidelity = 0.505284\tKL_Divergence = 2.677723\n",
      "Epoch: 38\tFidelity = 0.505223\tKL_Divergence = 2.683896\n",
      "Epoch: 39\tFidelity = 0.507442\tKL_Divergence = 2.486772\n",
      "Epoch: 40\tFidelity = 0.506182\tKL_Divergence = 2.589519\n",
      "Epoch: 41\tFidelity = 0.506054\tKL_Divergence = 2.601582\n",
      "Epoch: 42\tFidelity = 0.506761\tKL_Divergence = 2.538922\n",
      "Epoch: 43\tFidelity = 0.507033\tKL_Divergence = 2.517024\n",
      "Epoch: 44\tFidelity = 0.507181\tKL_Divergence = 2.506063\n",
      "Epoch: 45\tFidelity = 0.507447\tKL_Divergence = 2.485913\n",
      "Epoch: 46\tFidelity = 0.506945\tKL_Divergence = 2.524709\n",
      "Epoch: 47\tFidelity = 0.506990\tKL_Divergence = 2.521155\n",
      "Epoch: 48\tFidelity = 0.506820\tKL_Divergence = 2.533877\n",
      "Epoch: 49\tFidelity = 0.505641\tKL_Divergence = 2.641199\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:31:09,457] Trial 222 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.504295\tKL_Divergence = 2.793031\n",
      "Total time elapsed during training: 37.385 s\n",
      "Trial 222 pruned. \n",
      "Epoch: 1\tFidelity = 0.505697\tKL_Divergence = 2.635698\n",
      "Epoch: 2\tFidelity = 0.507143\tKL_Divergence = 2.509817\n",
      "Epoch: 3\tFidelity = 0.507144\tKL_Divergence = 2.509670\n",
      "Epoch: 4\tFidelity = 0.505812\tKL_Divergence = 2.624726\n",
      "Epoch: 5\tFidelity = 0.506482\tKL_Divergence = 2.563872\n",
      "Epoch: 6\tFidelity = 0.506215\tKL_Divergence = 2.587350\n",
      "Epoch: 7\tFidelity = 0.505630\tKL_Divergence = 2.642510\n",
      "Epoch: 8\tFidelity = 0.506465\tKL_Divergence = 2.565126\n",
      "Epoch: 9\tFidelity = 0.506390\tKL_Divergence = 2.571025\n",
      "Epoch: 10\tFidelity = 0.504875\tKL_Divergence = 2.721984\n",
      "Epoch: 11\tFidelity = 0.505851\tKL_Divergence = 2.620895\n",
      "Epoch: 12\tFidelity = 0.506792\tKL_Divergence = 2.537975\n",
      "Epoch: 13\tFidelity = 0.505605\tKL_Divergence = 2.645024\n",
      "Epoch: 14\tFidelity = 0.504996\tKL_Divergence = 2.709138\n",
      "Epoch: 15\tFidelity = 0.507372\tKL_Divergence = 2.492089\n",
      "Epoch: 16\tFidelity = 0.506289\tKL_Divergence = 2.580639\n",
      "Epoch: 17\tFidelity = 0.507496\tKL_Divergence = 2.482782\n",
      "Epoch: 18\tFidelity = 0.504944\tKL_Divergence = 2.714799\n",
      "Epoch: 19\tFidelity = 0.506157\tKL_Divergence = 2.592658\n",
      "Epoch: 20\tFidelity = 0.505966\tKL_Divergence = 2.610168\n",
      "Epoch: 21\tFidelity = 0.505903\tKL_Divergence = 2.616099\n",
      "Epoch: 22\tFidelity = 0.504681\tKL_Divergence = 2.745151\n",
      "Epoch: 23\tFidelity = 0.505971\tKL_Divergence = 2.609683\n",
      "Epoch: 24\tFidelity = 0.506311\tKL_Divergence = 2.578946\n",
      "Epoch: 25\tFidelity = 0.506161\tKL_Divergence = 2.592377\n",
      "Epoch: 26\tFidelity = 0.506122\tKL_Divergence = 2.595884\n",
      "Epoch: 27\tFidelity = 0.504968\tKL_Divergence = 2.712198\n",
      "Epoch: 28\tFidelity = 0.506879\tKL_Divergence = 2.530816\n",
      "Epoch: 29\tFidelity = 0.504795\tKL_Divergence = 2.731985\n",
      "Epoch: 30\tFidelity = 0.506513\tKL_Divergence = 2.561356\n",
      "Epoch: 31\tFidelity = 0.504858\tKL_Divergence = 2.724637\n",
      "Epoch: 32\tFidelity = 0.505338\tKL_Divergence = 2.671993\n",
      "Epoch: 33\tFidelity = 0.506135\tKL_Divergence = 2.594364\n",
      "Epoch: 34\tFidelity = 0.505550\tKL_Divergence = 2.650564\n",
      "Epoch: 35\tFidelity = 0.507130\tKL_Divergence = 2.510756\n",
      "Epoch: 36\tFidelity = 0.506497\tKL_Divergence = 2.562522\n",
      "Epoch: 37\tFidelity = 0.506669\tKL_Divergence = 2.547094\n",
      "Epoch: 38\tFidelity = 0.505149\tKL_Divergence = 2.690681\n",
      "Epoch: 39\tFidelity = 0.506595\tKL_Divergence = 2.553314\n",
      "Epoch: 40\tFidelity = 0.505182\tKL_Divergence = 2.688643\n",
      "Epoch: 41\tFidelity = 0.506153\tKL_Divergence = 2.593067\n",
      "Epoch: 42\tFidelity = 0.504857\tKL_Divergence = 2.724818\n",
      "Epoch: 43\tFidelity = 0.506361\tKL_Divergence = 2.574551\n",
      "Epoch: 44\tFidelity = 0.505486\tKL_Divergence = 2.657115\n",
      "Epoch: 45\tFidelity = 0.505547\tKL_Divergence = 2.650879\n",
      "Epoch: 46\tFidelity = 0.505930\tKL_Divergence = 2.613708\n",
      "Epoch: 47\tFidelity = 0.506596\tKL_Divergence = 2.554356\n",
      "Epoch: 48\tFidelity = 0.505764\tKL_Divergence = 2.629453\n",
      "Epoch: 49\tFidelity = 0.505226\tKL_Divergence = 2.684139\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:31:45,960] Trial 223 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.505289\tKL_Divergence = 2.677346\n",
      "Total time elapsed during training: 36.357 s\n",
      "Trial 223 pruned. \n",
      "Epoch: 1\tFidelity = 0.505556\tKL_Divergence = 2.649875\n",
      "Epoch: 2\tFidelity = 0.505457\tKL_Divergence = 2.659998\n",
      "Epoch: 3\tFidelity = 0.505553\tKL_Divergence = 2.650169\n",
      "Epoch: 4\tFidelity = 0.506072\tKL_Divergence = 2.600497\n",
      "Epoch: 5\tFidelity = 0.505842\tKL_Divergence = 2.621906\n",
      "Epoch: 6\tFidelity = 0.505683\tKL_Divergence = 2.637251\n",
      "Epoch: 7\tFidelity = 0.505855\tKL_Divergence = 2.620659\n",
      "Epoch: 8\tFidelity = 0.505978\tKL_Divergence = 2.609139\n",
      "Epoch: 9\tFidelity = 0.505906\tKL_Divergence = 2.615720\n",
      "Epoch: 10\tFidelity = 0.505343\tKL_Divergence = 2.671593\n",
      "Epoch: 11\tFidelity = 0.505134\tKL_Divergence = 2.693884\n",
      "Epoch: 12\tFidelity = 0.506642\tKL_Divergence = 2.550431\n",
      "Epoch: 13\tFidelity = 0.505252\tKL_Divergence = 2.681452\n",
      "Epoch: 14\tFidelity = 0.505178\tKL_Divergence = 2.689276\n",
      "Epoch: 15\tFidelity = 0.505622\tKL_Divergence = 2.643301\n",
      "Epoch: 16\tFidelity = 0.505388\tKL_Divergence = 2.667091\n",
      "Epoch: 17\tFidelity = 0.505638\tKL_Divergence = 2.641687\n",
      "Epoch: 18\tFidelity = 0.505523\tKL_Divergence = 2.652771\n",
      "Epoch: 19\tFidelity = 0.505523\tKL_Divergence = 2.652739\n",
      "Epoch: 20\tFidelity = 0.505238\tKL_Divergence = 2.682285\n",
      "Epoch: 21\tFidelity = 0.506589\tKL_Divergence = 2.554559\n",
      "Epoch: 22\tFidelity = 0.506230\tKL_Divergence = 2.585903\n",
      "Epoch: 23\tFidelity = 0.505657\tKL_Divergence = 2.639865\n",
      "Epoch: 24\tFidelity = 0.506428\tKL_Divergence = 2.568735\n",
      "Epoch: 25\tFidelity = 0.506226\tKL_Divergence = 2.586492\n",
      "Epoch: 26\tFidelity = 0.506090\tKL_Divergence = 2.598822\n",
      "Epoch: 27\tFidelity = 0.506196\tKL_Divergence = 2.589253\n",
      "Epoch: 28\tFidelity = 0.506412\tKL_Divergence = 2.570138\n",
      "Epoch: 29\tFidelity = 0.506041\tKL_Divergence = 2.603321\n",
      "Epoch: 30\tFidelity = 0.505875\tKL_Divergence = 2.618847\n",
      "Epoch: 31\tFidelity = 0.505480\tKL_Divergence = 2.657666\n",
      "Epoch: 32\tFidelity = 0.505244\tKL_Divergence = 2.682204\n",
      "Epoch: 33\tFidelity = 0.504788\tKL_Divergence = 2.732801\n",
      "Epoch: 34\tFidelity = 0.505124\tKL_Divergence = 2.695078\n",
      "Epoch: 35\tFidelity = 0.505646\tKL_Divergence = 2.640994\n",
      "Epoch: 36\tFidelity = 0.505269\tKL_Divergence = 2.679401\n",
      "Epoch: 37\tFidelity = 0.505477\tKL_Divergence = 2.657605\n",
      "Epoch: 38\tFidelity = 0.505331\tKL_Divergence = 2.672845\n",
      "Epoch: 39\tFidelity = 0.504871\tKL_Divergence = 2.722756\n",
      "Epoch: 40\tFidelity = 0.505905\tKL_Divergence = 2.615529\n",
      "Epoch: 41\tFidelity = 0.505819\tKL_Divergence = 2.623655\n",
      "Epoch: 42\tFidelity = 0.506216\tKL_Divergence = 2.586958\n",
      "Epoch: 43\tFidelity = 0.505789\tKL_Divergence = 2.626760\n",
      "Epoch: 44\tFidelity = 0.505467\tKL_Divergence = 2.658541\n",
      "Epoch: 45\tFidelity = 0.505511\tKL_Divergence = 2.654451\n",
      "Epoch: 46\tFidelity = 0.505612\tKL_Divergence = 2.644387\n",
      "Epoch: 47\tFidelity = 0.505749\tKL_Divergence = 2.630968\n",
      "Epoch: 48\tFidelity = 0.506236\tKL_Divergence = 2.585694\n",
      "Epoch: 49\tFidelity = 0.505261\tKL_Divergence = 2.680383\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:32:23,322] Trial 224 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.506162\tKL_Divergence = 2.592310\n",
      "Total time elapsed during training: 37.113 s\n",
      "Trial 224 pruned. \n",
      "Epoch: 1\tFidelity = 0.506097\tKL_Divergence = 2.598247\n",
      "Epoch: 2\tFidelity = 0.506329\tKL_Divergence = 2.577377\n",
      "Epoch: 3\tFidelity = 0.505792\tKL_Divergence = 2.626771\n",
      "Epoch: 4\tFidelity = 0.506056\tKL_Divergence = 2.601970\n",
      "Epoch: 5\tFidelity = 0.506034\tKL_Divergence = 2.604009\n",
      "Epoch: 6\tFidelity = 0.506545\tKL_Divergence = 2.558701\n",
      "Epoch: 7\tFidelity = 0.505817\tKL_Divergence = 2.624411\n",
      "Epoch: 8\tFidelity = 0.506152\tKL_Divergence = 2.593192\n",
      "Epoch: 9\tFidelity = 0.506348\tKL_Divergence = 2.575700\n",
      "Epoch: 10\tFidelity = 0.506128\tKL_Divergence = 2.595396\n",
      "Epoch: 11\tFidelity = 0.506230\tKL_Divergence = 2.586197\n",
      "Epoch: 12\tFidelity = 0.506510\tKL_Divergence = 2.561662\n",
      "Epoch: 13\tFidelity = 0.506114\tKL_Divergence = 2.596693\n",
      "Epoch: 14\tFidelity = 0.505991\tKL_Divergence = 2.607971\n",
      "Epoch: 15\tFidelity = 0.506488\tKL_Divergence = 2.563559\n",
      "Epoch: 16\tFidelity = 0.505842\tKL_Divergence = 2.622036\n",
      "Epoch: 17\tFidelity = 0.505831\tKL_Divergence = 2.623046\n",
      "Epoch: 18\tFidelity = 0.506259\tKL_Divergence = 2.583527\n",
      "Epoch: 19\tFidelity = 0.506831\tKL_Divergence = 2.534834\n",
      "Epoch: 20\tFidelity = 0.505743\tKL_Divergence = 2.631533\n",
      "Epoch: 21\tFidelity = 0.505261\tKL_Divergence = 2.680435\n",
      "Epoch: 22\tFidelity = 0.505783\tKL_Divergence = 2.627683\n",
      "Epoch: 23\tFidelity = 0.505743\tKL_Divergence = 2.631549\n",
      "Epoch: 24\tFidelity = 0.505551\tKL_Divergence = 2.650450\n",
      "Epoch: 25\tFidelity = 0.504977\tKL_Divergence = 2.711242\n",
      "Epoch: 26\tFidelity = 0.505256\tKL_Divergence = 2.680936\n",
      "Epoch: 27\tFidelity = 0.506185\tKL_Divergence = 2.590210\n",
      "Epoch: 28\tFidelity = 0.506116\tKL_Divergence = 2.596449\n",
      "Epoch: 29\tFidelity = 0.505072\tKL_Divergence = 2.700772\n",
      "Epoch: 30\tFidelity = 0.505329\tKL_Divergence = 2.673297\n",
      "Epoch: 31\tFidelity = 0.505952\tKL_Divergence = 2.611634\n",
      "Epoch: 32\tFidelity = 0.505238\tKL_Divergence = 2.682875\n",
      "Epoch: 33\tFidelity = 0.504784\tKL_Divergence = 2.733315\n",
      "Epoch: 34\tFidelity = 0.505276\tKL_Divergence = 2.678870\n",
      "Epoch: 35\tFidelity = 0.505961\tKL_Divergence = 2.610796\n",
      "Epoch: 36\tFidelity = 0.505590\tKL_Divergence = 2.646654\n",
      "Epoch: 37\tFidelity = 0.506061\tKL_Divergence = 2.601534\n",
      "Epoch: 38\tFidelity = 0.505592\tKL_Divergence = 2.646407\n",
      "Epoch: 39\tFidelity = 0.504897\tKL_Divergence = 2.720346\n",
      "Epoch: 40\tFidelity = 0.505817\tKL_Divergence = 2.624448\n",
      "Epoch: 41\tFidelity = 0.506062\tKL_Divergence = 2.601410\n",
      "Epoch: 42\tFidelity = 0.504982\tKL_Divergence = 2.710777\n",
      "Epoch: 43\tFidelity = 0.505277\tKL_Divergence = 2.678722\n",
      "Epoch: 44\tFidelity = 0.505446\tKL_Divergence = 2.661198\n",
      "Epoch: 45\tFidelity = 0.505284\tKL_Divergence = 2.678009\n",
      "Epoch: 46\tFidelity = 0.505459\tKL_Divergence = 2.659828\n",
      "Epoch: 47\tFidelity = 0.505133\tKL_Divergence = 2.694176\n",
      "Epoch: 48\tFidelity = 0.505023\tKL_Divergence = 2.706225\n",
      "Epoch: 49\tFidelity = 0.505642\tKL_Divergence = 2.641515\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:33:02,117] Trial 225 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.506877\tKL_Divergence = 2.531107\n",
      "Total time elapsed during training: 38.639 s\n",
      "Trial 225 pruned. \n",
      "Epoch: 1\tFidelity = 0.505058\tKL_Divergence = 2.702348\n",
      "Epoch: 2\tFidelity = 0.506318\tKL_Divergence = 2.578394\n",
      "Epoch: 3\tFidelity = 0.506399\tKL_Divergence = 2.571326\n",
      "Epoch: 4\tFidelity = 0.506039\tKL_Divergence = 2.603516\n",
      "Epoch: 5\tFidelity = 0.505207\tKL_Divergence = 2.686099\n",
      "Epoch: 6\tFidelity = 0.505332\tKL_Divergence = 2.672910\n",
      "Epoch: 7\tFidelity = 0.505835\tKL_Divergence = 2.622631\n",
      "Epoch: 8\tFidelity = 0.505645\tKL_Divergence = 2.641093\n",
      "Epoch: 9\tFidelity = 0.505338\tKL_Divergence = 2.672233\n",
      "Epoch: 10\tFidelity = 0.505791\tKL_Divergence = 2.626841\n",
      "Epoch: 11\tFidelity = 0.505424\tKL_Divergence = 2.663288\n",
      "Epoch: 12\tFidelity = 0.506019\tKL_Divergence = 2.605295\n",
      "Epoch: 13\tFidelity = 0.505202\tKL_Divergence = 2.686543\n",
      "Epoch: 14\tFidelity = 0.505227\tKL_Divergence = 2.683987\n",
      "Epoch: 15\tFidelity = 0.507093\tKL_Divergence = 2.513764\n",
      "Epoch: 16\tFidelity = 0.504699\tKL_Divergence = 2.743268\n",
      "Epoch: 17\tFidelity = 0.505677\tKL_Divergence = 2.637997\n",
      "Epoch: 18\tFidelity = 0.505577\tKL_Divergence = 2.647883\n",
      "Epoch: 19\tFidelity = 0.505937\tKL_Divergence = 2.613007\n",
      "Epoch: 20\tFidelity = 0.505943\tKL_Divergence = 2.612450\n",
      "Epoch: 21\tFidelity = 0.505978\tKL_Divergence = 2.609184\n",
      "Epoch: 22\tFidelity = 0.505840\tKL_Divergence = 2.622194\n",
      "Epoch: 23\tFidelity = 0.506213\tKL_Divergence = 2.587730\n",
      "Epoch: 24\tFidelity = 0.505698\tKL_Divergence = 2.635854\n",
      "Epoch: 25\tFidelity = 0.506560\tKL_Divergence = 2.557417\n",
      "Epoch: 26\tFidelity = 0.506432\tKL_Divergence = 2.568444\n",
      "Epoch: 27\tFidelity = 0.506259\tKL_Divergence = 2.583608\n",
      "Epoch: 28\tFidelity = 0.506011\tKL_Divergence = 2.606208\n",
      "Epoch: 29\tFidelity = 0.505637\tKL_Divergence = 2.641975\n",
      "Epoch: 30\tFidelity = 0.506036\tKL_Divergence = 2.603919\n",
      "Epoch: 31\tFidelity = 0.506394\tKL_Divergence = 2.571730\n",
      "Epoch: 32\tFidelity = 0.505358\tKL_Divergence = 2.670242\n",
      "Epoch: 33\tFidelity = 0.505498\tKL_Divergence = 2.655954\n",
      "Epoch: 34\tFidelity = 0.505563\tKL_Divergence = 2.649409\n",
      "Epoch: 35\tFidelity = 0.505153\tKL_Divergence = 2.691985\n",
      "Epoch: 36\tFidelity = 0.506002\tKL_Divergence = 2.607001\n",
      "Epoch: 37\tFidelity = 0.505295\tKL_Divergence = 2.676888\n",
      "Epoch: 38\tFidelity = 0.505208\tKL_Divergence = 2.686032\n",
      "Epoch: 39\tFidelity = 0.505585\tKL_Divergence = 2.647070\n",
      "Epoch: 40\tFidelity = 0.505917\tKL_Divergence = 2.614907\n",
      "Epoch: 41\tFidelity = 0.505847\tKL_Divergence = 2.621591\n",
      "Epoch: 42\tFidelity = 0.505554\tKL_Divergence = 2.650204\n",
      "Epoch: 43\tFidelity = 0.504786\tKL_Divergence = 2.733081\n",
      "Epoch: 44\tFidelity = 0.505678\tKL_Divergence = 2.637900\n",
      "Epoch: 45\tFidelity = 0.505081\tKL_Divergence = 2.699713\n",
      "Epoch: 46\tFidelity = 0.504677\tKL_Divergence = 2.745839\n",
      "Epoch: 47\tFidelity = 0.505385\tKL_Divergence = 2.667335\n",
      "Epoch: 48\tFidelity = 0.504988\tKL_Divergence = 2.710016\n",
      "Epoch: 49\tFidelity = 0.506052\tKL_Divergence = 2.602274\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:34:00,922] Trial 226 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.505451\tKL_Divergence = 2.660551\n",
      "Total time elapsed during training: 58.651 s\n",
      "Trial 226 pruned. \n",
      "Epoch: 1\tFidelity = 0.506192\tKL_Divergence = 2.589575\n",
      "Epoch: 2\tFidelity = 0.505377\tKL_Divergence = 2.668210\n",
      "Epoch: 3\tFidelity = 0.506209\tKL_Divergence = 2.588000\n",
      "Epoch: 4\tFidelity = 0.505108\tKL_Divergence = 2.696813\n",
      "Epoch: 5\tFidelity = 0.506009\tKL_Divergence = 2.606271\n",
      "Epoch: 6\tFidelity = 0.505222\tKL_Divergence = 2.684538\n",
      "Epoch: 7\tFidelity = 0.506255\tKL_Divergence = 2.583922\n",
      "Epoch: 8\tFidelity = 0.505230\tKL_Divergence = 2.683690\n",
      "Epoch: 9\tFidelity = 0.504982\tKL_Divergence = 2.710680\n",
      "Epoch: 10\tFidelity = 0.506095\tKL_Divergence = 2.598313\n",
      "Epoch: 11\tFidelity = 0.504993\tKL_Divergence = 2.709478\n",
      "Epoch: 12\tFidelity = 0.506506\tKL_Divergence = 2.562002\n",
      "Epoch: 13\tFidelity = 0.504851\tKL_Divergence = 2.725548\n",
      "Epoch: 14\tFidelity = 0.506341\tKL_Divergence = 2.576264\n",
      "Epoch: 15\tFidelity = 0.505003\tKL_Divergence = 2.708350\n",
      "Epoch: 16\tFidelity = 0.506361\tKL_Divergence = 2.574523\n",
      "Epoch: 17\tFidelity = 0.504861\tKL_Divergence = 2.724410\n",
      "Epoch: 18\tFidelity = 0.506097\tKL_Divergence = 2.598210\n",
      "Epoch: 19\tFidelity = 0.505267\tKL_Divergence = 2.679712\n",
      "Epoch: 20\tFidelity = 0.506218\tKL_Divergence = 2.587224\n",
      "Epoch: 21\tFidelity = 0.505507\tKL_Divergence = 2.654881\n",
      "Epoch: 22\tFidelity = 0.505745\tKL_Divergence = 2.631370\n",
      "Epoch: 23\tFidelity = 0.505462\tKL_Divergence = 2.659432\n",
      "Epoch: 24\tFidelity = 0.506293\tKL_Divergence = 2.580546\n",
      "Epoch: 25\tFidelity = 0.504915\tKL_Divergence = 2.718236\n",
      "Epoch: 26\tFidelity = 0.506162\tKL_Divergence = 2.592293\n",
      "Epoch: 27\tFidelity = 0.505572\tKL_Divergence = 2.648324\n",
      "Epoch: 28\tFidelity = 0.506187\tKL_Divergence = 2.589979\n",
      "Epoch: 29\tFidelity = 0.505489\tKL_Divergence = 2.656697\n",
      "Epoch: 30\tFidelity = 0.505782\tKL_Divergence = 2.627729\n",
      "Epoch: 31\tFidelity = 0.506684\tKL_Divergence = 2.546894\n",
      "Epoch: 32\tFidelity = 0.505302\tKL_Divergence = 2.675979\n",
      "Epoch: 33\tFidelity = 0.506199\tKL_Divergence = 2.588908\n",
      "Epoch: 34\tFidelity = 0.505693\tKL_Divergence = 2.636375\n",
      "Epoch: 35\tFidelity = 0.506038\tKL_Divergence = 2.603588\n",
      "Epoch: 36\tFidelity = 0.505116\tKL_Divergence = 2.695921\n",
      "Epoch: 37\tFidelity = 0.505606\tKL_Divergence = 2.644912\n",
      "Epoch: 38\tFidelity = 0.505509\tKL_Divergence = 2.654622\n",
      "Epoch: 39\tFidelity = 0.505685\tKL_Divergence = 2.637108\n",
      "Epoch: 40\tFidelity = 0.505814\tKL_Divergence = 2.624605\n",
      "Epoch: 41\tFidelity = 0.505224\tKL_Divergence = 2.684265\n",
      "Epoch: 42\tFidelity = 0.506031\tKL_Divergence = 2.604170\n",
      "Epoch: 43\tFidelity = 0.505005\tKL_Divergence = 2.708130\n",
      "Epoch: 44\tFidelity = 0.506249\tKL_Divergence = 2.584430\n",
      "Epoch: 45\tFidelity = 0.504990\tKL_Divergence = 2.709816\n",
      "Epoch: 46\tFidelity = 0.506381\tKL_Divergence = 2.572789\n",
      "Epoch: 47\tFidelity = 0.505153\tKL_Divergence = 2.691898\n",
      "Epoch: 48\tFidelity = 0.506514\tKL_Divergence = 2.561230\n",
      "Epoch: 49\tFidelity = 0.505076\tKL_Divergence = 2.700207\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:34:33,009] Trial 227 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.506127\tKL_Divergence = 2.595396\n",
      "Total time elapsed during training: 31.915 s\n",
      "Trial 227 pruned. \n",
      "Epoch: 1\tFidelity = 0.504996\tKL_Divergence = 2.709104\n",
      "Epoch: 2\tFidelity = 0.506378\tKL_Divergence = 2.573049\n",
      "Epoch: 3\tFidelity = 0.505921\tKL_Divergence = 2.614530\n",
      "Epoch: 4\tFidelity = 0.505551\tKL_Divergence = 2.650492\n",
      "Epoch: 5\tFidelity = 0.506105\tKL_Divergence = 2.597483\n",
      "Epoch: 6\tFidelity = 0.505250\tKL_Divergence = 2.681475\n",
      "Epoch: 7\tFidelity = 0.504986\tKL_Divergence = 2.710217\n",
      "Epoch: 8\tFidelity = 0.506140\tKL_Divergence = 2.594278\n",
      "Epoch: 9\tFidelity = 0.505754\tKL_Divergence = 2.630423\n",
      "Epoch: 10\tFidelity = 0.505816\tKL_Divergence = 2.624469\n",
      "Epoch: 11\tFidelity = 0.505068\tKL_Divergence = 2.701172\n",
      "Epoch: 12\tFidelity = 0.505622\tKL_Divergence = 2.643343\n",
      "Epoch: 13\tFidelity = 0.505195\tKL_Divergence = 2.687338\n",
      "Epoch: 14\tFidelity = 0.505387\tKL_Divergence = 2.667125\n",
      "Epoch: 15\tFidelity = 0.505861\tKL_Divergence = 2.620150\n",
      "Epoch: 16\tFidelity = 0.506163\tKL_Divergence = 2.592117\n",
      "Epoch: 17\tFidelity = 0.505442\tKL_Divergence = 2.661447\n",
      "Epoch: 18\tFidelity = 0.505981\tKL_Divergence = 2.608900\n",
      "Epoch: 19\tFidelity = 0.505948\tKL_Divergence = 2.611950\n",
      "Epoch: 20\tFidelity = 0.505436\tKL_Divergence = 2.662075\n",
      "Epoch: 21\tFidelity = 0.506489\tKL_Divergence = 2.563380\n",
      "Epoch: 22\tFidelity = 0.506512\tKL_Divergence = 2.561455\n",
      "Epoch: 23\tFidelity = 0.505378\tKL_Divergence = 2.668074\n",
      "Epoch: 24\tFidelity = 0.505985\tKL_Divergence = 2.608445\n",
      "Epoch: 25\tFidelity = 0.506424\tKL_Divergence = 2.569007\n",
      "Epoch: 26\tFidelity = 0.505025\tKL_Divergence = 2.705894\n",
      "Epoch: 27\tFidelity = 0.507087\tKL_Divergence = 2.514232\n",
      "Epoch: 28\tFidelity = 0.506282\tKL_Divergence = 2.581475\n",
      "Epoch: 29\tFidelity = 0.506508\tKL_Divergence = 2.561725\n",
      "Epoch: 30\tFidelity = 0.505307\tKL_Divergence = 2.675432\n",
      "Epoch: 31\tFidelity = 0.506455\tKL_Divergence = 2.566302\n",
      "Epoch: 32\tFidelity = 0.505399\tKL_Divergence = 2.665879\n",
      "Epoch: 33\tFidelity = 0.505925\tKL_Divergence = 2.614071\n",
      "Epoch: 34\tFidelity = 0.505561\tKL_Divergence = 2.649389\n",
      "Epoch: 35\tFidelity = 0.506093\tKL_Divergence = 2.598490\n",
      "Epoch: 36\tFidelity = 0.505562\tKL_Divergence = 2.649326\n",
      "Epoch: 37\tFidelity = 0.505848\tKL_Divergence = 2.621348\n",
      "Epoch: 38\tFidelity = 0.505577\tKL_Divergence = 2.647831\n",
      "Epoch: 39\tFidelity = 0.506771\tKL_Divergence = 2.539716\n",
      "Epoch: 40\tFidelity = 0.505074\tKL_Divergence = 2.700492\n",
      "Epoch: 41\tFidelity = 0.506360\tKL_Divergence = 2.574563\n",
      "Epoch: 42\tFidelity = 0.505736\tKL_Divergence = 2.632142\n",
      "Epoch: 43\tFidelity = 0.505175\tKL_Divergence = 2.689500\n",
      "Epoch: 44\tFidelity = 0.506038\tKL_Divergence = 2.603551\n",
      "Epoch: 45\tFidelity = 0.505990\tKL_Divergence = 2.608054\n",
      "Epoch: 46\tFidelity = 0.504731\tKL_Divergence = 2.739469\n",
      "Epoch: 47\tFidelity = 0.506317\tKL_Divergence = 2.578430\n",
      "Epoch: 48\tFidelity = 0.506044\tKL_Divergence = 2.603052\n",
      "Epoch: 49\tFidelity = 0.505869\tKL_Divergence = 2.619441\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:35:04,795] Trial 228 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.505332\tKL_Divergence = 2.672862\n",
      "Total time elapsed during training: 31.612 s\n",
      "Trial 228 pruned. \n",
      "Epoch: 1\tFidelity = 0.505710\tKL_Divergence = 2.634794\n",
      "Epoch: 2\tFidelity = 0.505265\tKL_Divergence = 2.679925\n",
      "Epoch: 3\tFidelity = 0.505768\tKL_Divergence = 2.629090\n",
      "Epoch: 4\tFidelity = 0.505668\tKL_Divergence = 2.638906\n",
      "Epoch: 5\tFidelity = 0.505708\tKL_Divergence = 2.634892\n",
      "Epoch: 6\tFidelity = 0.505746\tKL_Divergence = 2.631254\n",
      "Epoch: 7\tFidelity = 0.505329\tKL_Divergence = 2.673198\n",
      "Epoch: 8\tFidelity = 0.505487\tKL_Divergence = 2.656907\n",
      "Epoch: 9\tFidelity = 0.505669\tKL_Divergence = 2.638749\n",
      "Epoch: 10\tFidelity = 0.505966\tKL_Divergence = 2.610262\n",
      "Epoch: 11\tFidelity = 0.505535\tKL_Divergence = 2.652036\n",
      "Epoch: 12\tFidelity = 0.506075\tKL_Divergence = 2.600177\n",
      "Epoch: 13\tFidelity = 0.505620\tKL_Divergence = 2.643552\n",
      "Epoch: 14\tFidelity = 0.506143\tKL_Divergence = 2.593961\n",
      "Epoch: 15\tFidelity = 0.505918\tKL_Divergence = 2.614761\n",
      "Epoch: 16\tFidelity = 0.505132\tKL_Divergence = 2.694198\n",
      "Epoch: 17\tFidelity = 0.505910\tKL_Divergence = 2.615529\n",
      "Epoch: 18\tFidelity = 0.505112\tKL_Divergence = 2.696426\n",
      "Epoch: 19\tFidelity = 0.505335\tKL_Divergence = 2.672592\n",
      "Epoch: 20\tFidelity = 0.505952\tKL_Divergence = 2.611633\n",
      "Epoch: 21\tFidelity = 0.505464\tKL_Divergence = 2.659231\n",
      "Epoch: 22\tFidelity = 0.506002\tKL_Divergence = 2.606906\n",
      "Epoch: 23\tFidelity = 0.505591\tKL_Divergence = 2.646451\n",
      "Epoch: 24\tFidelity = 0.504973\tKL_Divergence = 2.711786\n",
      "Epoch: 25\tFidelity = 0.506122\tKL_Divergence = 2.595951\n",
      "Epoch: 26\tFidelity = 0.505632\tKL_Divergence = 2.642371\n",
      "Epoch: 27\tFidelity = 0.505670\tKL_Divergence = 2.638614\n",
      "Epoch: 28\tFidelity = 0.505851\tKL_Divergence = 2.621172\n",
      "Epoch: 29\tFidelity = 0.505884\tKL_Divergence = 2.618001\n",
      "Epoch: 30\tFidelity = 0.505275\tKL_Divergence = 2.678880\n",
      "Epoch: 31\tFidelity = 0.505472\tKL_Divergence = 2.658436\n",
      "Epoch: 32\tFidelity = 0.506172\tKL_Divergence = 2.591359\n",
      "Epoch: 33\tFidelity = 0.506195\tKL_Divergence = 2.589305\n",
      "Epoch: 34\tFidelity = 0.506031\tKL_Divergence = 2.604224\n",
      "Epoch: 35\tFidelity = 0.505630\tKL_Divergence = 2.642628\n",
      "Epoch: 36\tFidelity = 0.505850\tKL_Divergence = 2.621191\n",
      "Epoch: 37\tFidelity = 0.505630\tKL_Divergence = 2.642540\n",
      "Epoch: 38\tFidelity = 0.505720\tKL_Divergence = 2.633686\n",
      "Epoch: 39\tFidelity = 0.505572\tKL_Divergence = 2.648360\n",
      "Epoch: 40\tFidelity = 0.505872\tKL_Divergence = 2.619127\n",
      "Epoch: 41\tFidelity = 0.505869\tKL_Divergence = 2.619409\n",
      "Epoch: 42\tFidelity = 0.505769\tKL_Divergence = 2.628946\n",
      "Epoch: 43\tFidelity = 0.505814\tKL_Divergence = 2.624660\n",
      "Epoch: 44\tFidelity = 0.506063\tKL_Divergence = 2.601267\n",
      "Epoch: 45\tFidelity = 0.505539\tKL_Divergence = 2.651649\n",
      "Epoch: 46\tFidelity = 0.506103\tKL_Divergence = 2.597616\n",
      "Epoch: 47\tFidelity = 0.505379\tKL_Divergence = 2.667991\n",
      "Epoch: 48\tFidelity = 0.506141\tKL_Divergence = 2.594167\n",
      "Epoch: 49\tFidelity = 0.505496\tKL_Divergence = 2.655996\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:35:49,684] Trial 229 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.505766\tKL_Divergence = 2.629272\n",
      "Total time elapsed during training: 44.728 s\n",
      "Trial 229 pruned. \n",
      "Epoch: 1\tFidelity = 0.505812\tKL_Divergence = 2.624804\n",
      "Epoch: 2\tFidelity = 0.505301\tKL_Divergence = 2.676164\n",
      "Epoch: 3\tFidelity = 0.505325\tKL_Divergence = 2.673664\n",
      "Epoch: 4\tFidelity = 0.505596\tKL_Divergence = 2.645959\n",
      "Epoch: 5\tFidelity = 0.505020\tKL_Divergence = 2.706484\n",
      "Epoch: 6\tFidelity = 0.505577\tKL_Divergence = 2.647832\n",
      "Epoch: 7\tFidelity = 0.505943\tKL_Divergence = 2.612430\n",
      "Epoch: 8\tFidelity = 0.506050\tKL_Divergence = 2.602508\n",
      "Epoch: 9\tFidelity = 0.505828\tKL_Divergence = 2.623297\n",
      "Epoch: 10\tFidelity = 0.505007\tKL_Divergence = 2.707868\n",
      "Epoch: 11\tFidelity = 0.506491\tKL_Divergence = 2.563204\n",
      "Epoch: 12\tFidelity = 0.506159\tKL_Divergence = 2.592519\n",
      "Epoch: 13\tFidelity = 0.505932\tKL_Divergence = 2.613430\n",
      "Epoch: 14\tFidelity = 0.506600\tKL_Divergence = 2.553981\n",
      "Epoch: 15\tFidelity = 0.505171\tKL_Divergence = 2.689971\n",
      "Epoch: 16\tFidelity = 0.505667\tKL_Divergence = 2.638967\n",
      "Epoch: 17\tFidelity = 0.505934\tKL_Divergence = 2.613289\n",
      "Epoch: 18\tFidelity = 0.505532\tKL_Divergence = 2.652348\n",
      "Epoch: 19\tFidelity = 0.505185\tKL_Divergence = 2.688482\n",
      "Epoch: 20\tFidelity = 0.505671\tKL_Divergence = 2.638517\n",
      "Epoch: 21\tFidelity = 0.505327\tKL_Divergence = 2.673385\n",
      "Epoch: 22\tFidelity = 0.505317\tKL_Divergence = 2.674488\n",
      "Epoch: 23\tFidelity = 0.505275\tKL_Divergence = 2.678850\n",
      "Epoch: 24\tFidelity = 0.505430\tKL_Divergence = 2.662810\n",
      "Epoch: 25\tFidelity = 0.505774\tKL_Divergence = 2.628562\n",
      "Epoch: 26\tFidelity = 0.505735\tKL_Divergence = 2.632346\n",
      "Epoch: 27\tFidelity = 0.505179\tKL_Divergence = 2.689107\n",
      "Epoch: 28\tFidelity = 0.505488\tKL_Divergence = 2.656891\n",
      "Epoch: 29\tFidelity = 0.505635\tKL_Divergence = 2.642160\n",
      "Epoch: 30\tFidelity = 0.505779\tKL_Divergence = 2.628053\n",
      "Epoch: 31\tFidelity = 0.505488\tKL_Divergence = 2.656810\n",
      "Epoch: 32\tFidelity = 0.504991\tKL_Divergence = 2.709719\n",
      "Epoch: 33\tFidelity = 0.505173\tKL_Divergence = 2.689805\n",
      "Epoch: 34\tFidelity = 0.505429\tKL_Divergence = 2.662926\n",
      "Epoch: 35\tFidelity = 0.505193\tKL_Divergence = 2.687607\n",
      "Epoch: 36\tFidelity = 0.505158\tKL_Divergence = 2.691409\n",
      "Epoch: 37\tFidelity = 0.505142\tKL_Divergence = 2.693171\n",
      "Epoch: 38\tFidelity = 0.505736\tKL_Divergence = 2.632270\n",
      "Epoch: 39\tFidelity = 0.505380\tKL_Divergence = 2.667948\n",
      "Epoch: 40\tFidelity = 0.505702\tKL_Divergence = 2.635532\n",
      "Epoch: 41\tFidelity = 0.505886\tKL_Divergence = 2.617763\n",
      "Epoch: 42\tFidelity = 0.505712\tKL_Divergence = 2.634487\n",
      "Epoch: 43\tFidelity = 0.505002\tKL_Divergence = 2.708496\n",
      "Epoch: 44\tFidelity = 0.505661\tKL_Divergence = 2.639537\n",
      "Epoch: 45\tFidelity = 0.505456\tKL_Divergence = 2.660114\n",
      "Epoch: 46\tFidelity = 0.505704\tKL_Divergence = 2.635365\n",
      "Epoch: 47\tFidelity = 0.505628\tKL_Divergence = 2.642780\n",
      "Epoch: 48\tFidelity = 0.505772\tKL_Divergence = 2.628758\n",
      "Epoch: 49\tFidelity = 0.505653\tKL_Divergence = 2.640329\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:37:10,880] Trial 230 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.505598\tKL_Divergence = 2.645821\n",
      "Total time elapsed during training: 81.039 s\n",
      "Trial 230 pruned. \n",
      "Epoch: 1\tFidelity = 0.504910\tKL_Divergence = 2.718852\n",
      "Epoch: 2\tFidelity = 0.505438\tKL_Divergence = 2.661940\n",
      "Epoch: 3\tFidelity = 0.506045\tKL_Divergence = 2.602914\n",
      "Epoch: 4\tFidelity = 0.505645\tKL_Divergence = 2.641148\n",
      "Epoch: 5\tFidelity = 0.505849\tKL_Divergence = 2.621269\n",
      "Epoch: 6\tFidelity = 0.504696\tKL_Divergence = 2.743599\n",
      "Epoch: 7\tFidelity = 0.505091\tKL_Divergence = 2.698610\n",
      "Epoch: 8\tFidelity = 0.505865\tKL_Divergence = 2.619827\n",
      "Epoch: 9\tFidelity = 0.504699\tKL_Divergence = 2.743242\n",
      "Epoch: 10\tFidelity = 0.504664\tKL_Divergence = 2.747348\n",
      "Epoch: 11\tFidelity = 0.504989\tKL_Divergence = 2.709914\n",
      "Epoch: 12\tFidelity = 0.505827\tKL_Divergence = 2.623354\n",
      "Epoch: 13\tFidelity = 0.505587\tKL_Divergence = 2.646852\n",
      "Epoch: 14\tFidelity = 0.506655\tKL_Divergence = 2.549286\n",
      "Epoch: 15\tFidelity = 0.505585\tKL_Divergence = 2.646959\n",
      "Epoch: 16\tFidelity = 0.505260\tKL_Divergence = 2.680367\n",
      "Epoch: 17\tFidelity = 0.506510\tKL_Divergence = 2.561563\n",
      "Epoch: 18\tFidelity = 0.505770\tKL_Divergence = 2.628789\n",
      "Epoch: 19\tFidelity = 0.505299\tKL_Divergence = 2.676227\n",
      "Epoch: 20\tFidelity = 0.505988\tKL_Divergence = 2.608146\n",
      "Epoch: 21\tFidelity = 0.505771\tKL_Divergence = 2.628641\n",
      "Epoch: 22\tFidelity = 0.505727\tKL_Divergence = 2.632921\n",
      "Epoch: 23\tFidelity = 0.504270\tKL_Divergence = 2.796400\n",
      "Epoch: 24\tFidelity = 0.506132\tKL_Divergence = 2.594819\n",
      "Epoch: 25\tFidelity = 0.506163\tKL_Divergence = 2.592042\n",
      "Epoch: 26\tFidelity = 0.505557\tKL_Divergence = 2.649767\n",
      "Epoch: 27\tFidelity = 0.505972\tKL_Divergence = 2.609581\n",
      "Epoch: 28\tFidelity = 0.505146\tKL_Divergence = 2.692585\n",
      "Epoch: 29\tFidelity = 0.506754\tKL_Divergence = 2.540990\n",
      "Epoch: 30\tFidelity = 0.504691\tKL_Divergence = 2.744127\n",
      "Epoch: 31\tFidelity = 0.504996\tKL_Divergence = 2.709049\n",
      "Epoch: 32\tFidelity = 0.505964\tKL_Divergence = 2.610431\n",
      "Epoch: 33\tFidelity = 0.505050\tKL_Divergence = 2.703089\n",
      "Epoch: 34\tFidelity = 0.505254\tKL_Divergence = 2.681077\n",
      "Epoch: 35\tFidelity = 0.505727\tKL_Divergence = 2.633041\n",
      "Epoch: 36\tFidelity = 0.506338\tKL_Divergence = 2.576465\n",
      "Epoch: 37\tFidelity = 0.505499\tKL_Divergence = 2.655619\n",
      "Epoch: 38\tFidelity = 0.505297\tKL_Divergence = 2.676462\n",
      "Epoch: 39\tFidelity = 0.504892\tKL_Divergence = 2.720762\n",
      "Epoch: 40\tFidelity = 0.504868\tKL_Divergence = 2.723579\n",
      "Epoch: 41\tFidelity = 0.505666\tKL_Divergence = 2.638956\n",
      "Epoch: 42\tFidelity = 0.506172\tKL_Divergence = 2.591309\n",
      "Epoch: 43\tFidelity = 0.506415\tKL_Divergence = 2.569739\n",
      "Epoch: 44\tFidelity = 0.506086\tKL_Divergence = 2.599111\n",
      "Epoch: 45\tFidelity = 0.506464\tKL_Divergence = 2.565483\n",
      "Epoch: 46\tFidelity = 0.505438\tKL_Divergence = 2.661834\n",
      "Epoch: 47\tFidelity = 0.505455\tKL_Divergence = 2.660150\n",
      "Epoch: 48\tFidelity = 0.506306\tKL_Divergence = 2.579313\n",
      "Epoch: 49\tFidelity = 0.505342\tKL_Divergence = 2.671846\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:37:55,979] Trial 231 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.506215\tKL_Divergence = 2.587415\n",
      "Total time elapsed during training: 44.948 s\n",
      "Trial 231 pruned. \n",
      "Epoch: 1\tFidelity = 0.505935\tKL_Divergence = 2.613180\n",
      "Epoch: 2\tFidelity = 0.505383\tKL_Divergence = 2.667549\n",
      "Epoch: 3\tFidelity = 0.505757\tKL_Divergence = 2.630138\n",
      "Epoch: 4\tFidelity = 0.505737\tKL_Divergence = 2.632090\n",
      "Epoch: 5\tFidelity = 0.505757\tKL_Divergence = 2.630158\n",
      "Epoch: 6\tFidelity = 0.504905\tKL_Divergence = 2.719347\n",
      "Epoch: 7\tFidelity = 0.505513\tKL_Divergence = 2.654267\n",
      "Epoch: 8\tFidelity = 0.505660\tKL_Divergence = 2.639589\n",
      "Epoch: 9\tFidelity = 0.505623\tKL_Divergence = 2.643280\n",
      "Epoch: 10\tFidelity = 0.505483\tKL_Divergence = 2.657313\n",
      "Epoch: 11\tFidelity = 0.505162\tKL_Divergence = 2.690955\n",
      "Epoch: 12\tFidelity = 0.505823\tKL_Divergence = 2.623870\n",
      "Epoch: 13\tFidelity = 0.505896\tKL_Divergence = 2.616913\n",
      "Epoch: 14\tFidelity = 0.505315\tKL_Divergence = 2.674684\n",
      "Epoch: 15\tFidelity = 0.505343\tKL_Divergence = 2.671782\n",
      "Epoch: 16\tFidelity = 0.505572\tKL_Divergence = 2.648399\n",
      "Epoch: 17\tFidelity = 0.505500\tKL_Divergence = 2.655578\n",
      "Epoch: 18\tFidelity = 0.505271\tKL_Divergence = 2.679272\n",
      "Epoch: 19\tFidelity = 0.505666\tKL_Divergence = 2.639080\n",
      "Epoch: 20\tFidelity = 0.505224\tKL_Divergence = 2.684297\n",
      "Epoch: 21\tFidelity = 0.505259\tKL_Divergence = 2.680631\n",
      "Epoch: 22\tFidelity = 0.506105\tKL_Divergence = 2.597523\n",
      "Epoch: 23\tFidelity = 0.506303\tKL_Divergence = 2.579711\n",
      "Epoch: 24\tFidelity = 0.506036\tKL_Divergence = 2.603852\n",
      "Epoch: 25\tFidelity = 0.505815\tKL_Divergence = 2.624579\n",
      "Epoch: 26\tFidelity = 0.506255\tKL_Divergence = 2.583923\n",
      "Epoch: 27\tFidelity = 0.505465\tKL_Divergence = 2.659203\n",
      "Epoch: 28\tFidelity = 0.505126\tKL_Divergence = 2.694832\n",
      "Epoch: 29\tFidelity = 0.505794\tKL_Divergence = 2.626586\n",
      "Epoch: 30\tFidelity = 0.505493\tKL_Divergence = 2.656328\n",
      "Epoch: 31\tFidelity = 0.505731\tKL_Divergence = 2.632697\n",
      "Epoch: 32\tFidelity = 0.505206\tKL_Divergence = 2.686214\n",
      "Epoch: 33\tFidelity = 0.506227\tKL_Divergence = 2.586488\n",
      "Epoch: 34\tFidelity = 0.505584\tKL_Divergence = 2.647216\n",
      "Epoch: 35\tFidelity = 0.505135\tKL_Divergence = 2.693903\n",
      "Epoch: 36\tFidelity = 0.505429\tKL_Divergence = 2.662908\n",
      "Epoch: 37\tFidelity = 0.505216\tKL_Divergence = 2.685152\n",
      "Epoch: 38\tFidelity = 0.505563\tKL_Divergence = 2.649329\n",
      "Epoch: 39\tFidelity = 0.505996\tKL_Divergence = 2.607541\n",
      "Epoch: 40\tFidelity = 0.505069\tKL_Divergence = 2.701094\n",
      "Epoch: 41\tFidelity = 0.505453\tKL_Divergence = 2.660407\n",
      "Epoch: 42\tFidelity = 0.505122\tKL_Divergence = 2.695376\n",
      "Epoch: 43\tFidelity = 0.505703\tKL_Divergence = 2.635496\n",
      "Epoch: 44\tFidelity = 0.505530\tKL_Divergence = 2.652691\n",
      "Epoch: 45\tFidelity = 0.505071\tKL_Divergence = 2.700966\n",
      "Epoch: 46\tFidelity = 0.505570\tKL_Divergence = 2.648654\n",
      "Epoch: 47\tFidelity = 0.506022\tKL_Divergence = 2.605182\n",
      "Epoch: 48\tFidelity = 0.505069\tKL_Divergence = 2.701094\n",
      "Epoch: 49\tFidelity = 0.505925\tKL_Divergence = 2.614175\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:38:42,109] Trial 232 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.504870\tKL_Divergence = 2.723405\n",
      "Total time elapsed during training: 45.966 s\n",
      "Trial 232 pruned. \n",
      "Epoch: 1\tFidelity = 0.505049\tKL_Divergence = 2.703315\n",
      "Epoch: 2\tFidelity = 0.504941\tKL_Divergence = 2.715423\n",
      "Epoch: 3\tFidelity = 0.506440\tKL_Divergence = 2.567753\n",
      "Epoch: 4\tFidelity = 0.505178\tKL_Divergence = 2.689229\n",
      "Epoch: 5\tFidelity = 0.505345\tKL_Divergence = 2.671638\n",
      "Epoch: 6\tFidelity = 0.505406\tKL_Divergence = 2.665302\n",
      "Epoch: 7\tFidelity = 0.505248\tKL_Divergence = 2.681828\n",
      "Epoch: 8\tFidelity = 0.505787\tKL_Divergence = 2.627307\n",
      "Epoch: 9\tFidelity = 0.505432\tKL_Divergence = 2.662651\n",
      "Epoch: 10\tFidelity = 0.505179\tKL_Divergence = 2.689179\n",
      "Epoch: 11\tFidelity = 0.505578\tKL_Divergence = 2.647854\n",
      "Epoch: 12\tFidelity = 0.505425\tKL_Divergence = 2.663305\n",
      "Epoch: 13\tFidelity = 0.505367\tKL_Divergence = 2.669330\n",
      "Epoch: 14\tFidelity = 0.504835\tKL_Divergence = 2.727473\n",
      "Epoch: 15\tFidelity = 0.505820\tKL_Divergence = 2.624187\n",
      "Epoch: 16\tFidelity = 0.504971\tKL_Divergence = 2.712066\n",
      "Epoch: 17\tFidelity = 0.505673\tKL_Divergence = 2.638414\n",
      "Epoch: 18\tFidelity = 0.505627\tKL_Divergence = 2.642972\n",
      "Epoch: 19\tFidelity = 0.506304\tKL_Divergence = 2.579630\n",
      "Epoch: 20\tFidelity = 0.504586\tKL_Divergence = 2.756873\n",
      "Epoch: 21\tFidelity = 0.504623\tKL_Divergence = 2.752400\n",
      "Epoch: 22\tFidelity = 0.505801\tKL_Divergence = 2.625979\n",
      "Epoch: 23\tFidelity = 0.506405\tKL_Divergence = 2.570767\n",
      "Epoch: 24\tFidelity = 0.505597\tKL_Divergence = 2.645996\n",
      "Epoch: 25\tFidelity = 0.505213\tKL_Divergence = 2.685591\n",
      "Epoch: 26\tFidelity = 0.505039\tKL_Divergence = 2.704418\n",
      "Epoch: 27\tFidelity = 0.505565\tKL_Divergence = 2.649139\n",
      "Epoch: 28\tFidelity = 0.505592\tKL_Divergence = 2.646451\n",
      "Epoch: 29\tFidelity = 0.504910\tKL_Divergence = 2.718947\n",
      "Epoch: 30\tFidelity = 0.505056\tKL_Divergence = 2.702548\n",
      "Epoch: 31\tFidelity = 0.505419\tKL_Divergence = 2.664004\n",
      "Epoch: 32\tFidelity = 0.505314\tKL_Divergence = 2.674857\n",
      "Epoch: 33\tFidelity = 0.504827\tKL_Divergence = 2.728435\n",
      "Epoch: 34\tFidelity = 0.505830\tKL_Divergence = 2.623217\n",
      "Epoch: 35\tFidelity = 0.505289\tKL_Divergence = 2.677525\n",
      "Epoch: 36\tFidelity = 0.505443\tKL_Divergence = 2.661479\n",
      "Epoch: 37\tFidelity = 0.505711\tKL_Divergence = 2.634769\n",
      "Epoch: 38\tFidelity = 0.505157\tKL_Divergence = 2.691545\n",
      "Epoch: 39\tFidelity = 0.505097\tKL_Divergence = 2.698099\n",
      "Epoch: 40\tFidelity = 0.505951\tKL_Divergence = 2.611744\n",
      "Epoch: 41\tFidelity = 0.505139\tKL_Divergence = 2.693554\n",
      "Epoch: 42\tFidelity = 0.505962\tKL_Divergence = 2.610786\n",
      "Epoch: 43\tFidelity = 0.506250\tKL_Divergence = 2.584430\n",
      "Epoch: 44\tFidelity = 0.504915\tKL_Divergence = 2.718342\n",
      "Epoch: 45\tFidelity = 0.505232\tKL_Divergence = 2.683520\n",
      "Epoch: 46\tFidelity = 0.504972\tKL_Divergence = 2.711936\n",
      "Epoch: 47\tFidelity = 0.505546\tKL_Divergence = 2.651018\n",
      "Epoch: 48\tFidelity = 0.505663\tKL_Divergence = 2.639364\n",
      "Epoch: 49\tFidelity = 0.504704\tKL_Divergence = 2.742783\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:39:29,036] Trial 233 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.504699\tKL_Divergence = 2.743370\n",
      "Total time elapsed during training: 46.762 s\n",
      "Trial 233 pruned. \n",
      "Epoch: 1\tFidelity = 0.504978\tKL_Divergence = 2.711240\n",
      "Epoch: 2\tFidelity = 0.505258\tKL_Divergence = 2.680781\n",
      "Epoch: 3\tFidelity = 0.505132\tKL_Divergence = 2.694288\n",
      "Epoch: 4\tFidelity = 0.506063\tKL_Divergence = 2.601315\n",
      "Epoch: 5\tFidelity = 0.505319\tKL_Divergence = 2.674125\n",
      "Epoch: 6\tFidelity = 0.506147\tKL_Divergence = 2.593687\n",
      "Epoch: 7\tFidelity = 0.505514\tKL_Divergence = 2.654209\n",
      "Epoch: 8\tFidelity = 0.504799\tKL_Divergence = 2.731574\n",
      "Epoch: 9\tFidelity = 0.505969\tKL_Divergence = 2.609793\n",
      "Epoch: 10\tFidelity = 0.504814\tKL_Divergence = 2.729823\n",
      "Epoch: 11\tFidelity = 0.505324\tKL_Divergence = 2.673703\n",
      "Epoch: 12\tFidelity = 0.505578\tKL_Divergence = 2.647586\n",
      "Epoch: 13\tFidelity = 0.504586\tKL_Divergence = 2.756241\n",
      "Epoch: 14\tFidelity = 0.505669\tKL_Divergence = 2.638474\n",
      "Epoch: 15\tFidelity = 0.506054\tKL_Divergence = 2.602055\n",
      "Epoch: 16\tFidelity = 0.504617\tKL_Divergence = 2.753025\n",
      "Epoch: 17\tFidelity = 0.505760\tKL_Divergence = 2.629587\n",
      "Epoch: 18\tFidelity = 0.504969\tKL_Divergence = 2.711385\n",
      "Epoch: 19\tFidelity = 0.505103\tKL_Divergence = 2.697245\n",
      "Epoch: 20\tFidelity = 0.505687\tKL_Divergence = 2.637093\n",
      "Epoch: 21\tFidelity = 0.505524\tKL_Divergence = 2.653220\n",
      "Epoch: 22\tFidelity = 0.505556\tKL_Divergence = 2.649971\n",
      "Epoch: 23\tFidelity = 0.505806\tKL_Divergence = 2.625407\n",
      "Epoch: 24\tFidelity = 0.504802\tKL_Divergence = 2.731174\n",
      "Epoch: 25\tFidelity = 0.504657\tKL_Divergence = 2.748248\n",
      "Epoch: 26\tFidelity = 0.505360\tKL_Divergence = 2.669941\n",
      "Epoch: 27\tFidelity = 0.505713\tKL_Divergence = 2.634466\n",
      "Epoch: 28\tFidelity = 0.505586\tKL_Divergence = 2.647013\n",
      "Epoch: 29\tFidelity = 0.505303\tKL_Divergence = 2.676001\n",
      "Epoch: 30\tFidelity = 0.506064\tKL_Divergence = 2.601195\n",
      "Epoch: 31\tFidelity = 0.505734\tKL_Divergence = 2.632384\n",
      "Epoch: 32\tFidelity = 0.504943\tKL_Divergence = 2.715067\n",
      "Epoch: 33\tFidelity = 0.504968\tKL_Divergence = 2.712315\n",
      "Epoch: 34\tFidelity = 0.505401\tKL_Divergence = 2.665814\n",
      "Epoch: 35\tFidelity = 0.504757\tKL_Divergence = 2.736325\n",
      "Epoch: 36\tFidelity = 0.505767\tKL_Divergence = 2.629224\n",
      "Epoch: 37\tFidelity = 0.505703\tKL_Divergence = 2.635360\n",
      "Epoch: 38\tFidelity = 0.506302\tKL_Divergence = 2.579743\n",
      "Epoch: 39\tFidelity = 0.505989\tKL_Divergence = 2.608114\n",
      "Epoch: 40\tFidelity = 0.506639\tKL_Divergence = 2.550650\n",
      "Epoch: 41\tFidelity = 0.505437\tKL_Divergence = 2.662080\n",
      "Epoch: 42\tFidelity = 0.505220\tKL_Divergence = 2.684666\n",
      "Epoch: 43\tFidelity = 0.506283\tKL_Divergence = 2.581468\n",
      "Epoch: 44\tFidelity = 0.505586\tKL_Divergence = 2.647011\n",
      "Epoch: 45\tFidelity = 0.504837\tKL_Divergence = 2.727072\n",
      "Epoch: 46\tFidelity = 0.504996\tKL_Divergence = 2.709060\n",
      "Epoch: 47\tFidelity = 0.506259\tKL_Divergence = 2.583315\n",
      "Epoch: 48\tFidelity = 0.505626\tKL_Divergence = 2.642793\n",
      "Epoch: 49\tFidelity = 0.506000\tKL_Divergence = 2.606860\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:40:06,080] Trial 234 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.506218\tKL_Divergence = 2.586915\n",
      "Total time elapsed during training: 36.888 s\n",
      "Trial 234 pruned. \n",
      "Epoch: 1\tFidelity = 0.505104\tKL_Divergence = 2.696951\n",
      "Epoch: 2\tFidelity = 0.505837\tKL_Divergence = 2.622147\n",
      "Epoch: 3\tFidelity = 0.505375\tKL_Divergence = 2.668239\n",
      "Epoch: 4\tFidelity = 0.506382\tKL_Divergence = 2.572662\n",
      "Epoch: 5\tFidelity = 0.504707\tKL_Divergence = 2.742349\n",
      "Epoch: 6\tFidelity = 0.504691\tKL_Divergence = 2.744151\n",
      "Epoch: 7\tFidelity = 0.505564\tKL_Divergence = 2.649203\n",
      "Epoch: 8\tFidelity = 0.506333\tKL_Divergence = 2.576975\n",
      "Epoch: 9\tFidelity = 0.506130\tKL_Divergence = 2.595120\n",
      "Epoch: 10\tFidelity = 0.504731\tKL_Divergence = 2.739528\n",
      "Epoch: 11\tFidelity = 0.504641\tKL_Divergence = 2.750167\n",
      "Epoch: 12\tFidelity = 0.506108\tKL_Divergence = 2.597161\n",
      "Epoch: 13\tFidelity = 0.505416\tKL_Divergence = 2.664187\n",
      "Epoch: 14\tFidelity = 0.505941\tKL_Divergence = 2.612636\n",
      "Epoch: 15\tFidelity = 0.505457\tKL_Divergence = 2.659994\n",
      "Epoch: 16\tFidelity = 0.506015\tKL_Divergence = 2.605775\n",
      "Epoch: 17\tFidelity = 0.505095\tKL_Divergence = 2.698272\n",
      "Epoch: 18\tFidelity = 0.505920\tKL_Divergence = 2.614652\n",
      "Epoch: 19\tFidelity = 0.505551\tKL_Divergence = 2.650500\n",
      "Epoch: 20\tFidelity = 0.505358\tKL_Divergence = 2.670167\n",
      "Epoch: 21\tFidelity = 0.506067\tKL_Divergence = 2.600937\n",
      "Epoch: 22\tFidelity = 0.505595\tKL_Divergence = 2.646106\n",
      "Epoch: 23\tFidelity = 0.504997\tKL_Divergence = 2.709025\n",
      "Epoch: 24\tFidelity = 0.504881\tKL_Divergence = 2.722134\n",
      "Epoch: 25\tFidelity = 0.505296\tKL_Divergence = 2.676672\n",
      "Epoch: 26\tFidelity = 0.505793\tKL_Divergence = 2.626748\n",
      "Epoch: 27\tFidelity = 0.505584\tKL_Divergence = 2.647182\n",
      "Epoch: 28\tFidelity = 0.505731\tKL_Divergence = 2.632681\n",
      "Epoch: 29\tFidelity = 0.505882\tKL_Divergence = 2.618199\n",
      "Epoch: 30\tFidelity = 0.505326\tKL_Divergence = 2.673434\n",
      "Epoch: 31\tFidelity = 0.505614\tKL_Divergence = 2.644121\n",
      "Epoch: 32\tFidelity = 0.505526\tKL_Divergence = 2.652988\n",
      "Epoch: 33\tFidelity = 0.505199\tKL_Divergence = 2.686895\n",
      "Epoch: 34\tFidelity = 0.505843\tKL_Divergence = 2.621856\n",
      "Epoch: 35\tFidelity = 0.505313\tKL_Divergence = 2.674876\n",
      "Epoch: 36\tFidelity = 0.505426\tKL_Divergence = 2.663080\n",
      "Epoch: 37\tFidelity = 0.505026\tKL_Divergence = 2.705705\n",
      "Epoch: 38\tFidelity = 0.505694\tKL_Divergence = 2.636215\n",
      "Epoch: 39\tFidelity = 0.505416\tKL_Divergence = 2.664149\n",
      "Epoch: 40\tFidelity = 0.505189\tKL_Divergence = 2.688073\n",
      "Epoch: 41\tFidelity = 0.505778\tKL_Divergence = 2.628133\n",
      "Epoch: 42\tFidelity = 0.504918\tKL_Divergence = 2.717918\n",
      "Epoch: 43\tFidelity = 0.504752\tKL_Divergence = 2.736996\n",
      "Epoch: 44\tFidelity = 0.504927\tKL_Divergence = 2.716934\n",
      "Epoch: 45\tFidelity = 0.505368\tKL_Divergence = 2.669167\n",
      "Epoch: 46\tFidelity = 0.506006\tKL_Divergence = 2.606554\n",
      "Epoch: 47\tFidelity = 0.504822\tKL_Divergence = 2.728856\n",
      "Epoch: 48\tFidelity = 0.505734\tKL_Divergence = 2.632372\n",
      "Epoch: 49\tFidelity = 0.506088\tKL_Divergence = 2.598991\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:40:43,497] Trial 235 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.505350\tKL_Divergence = 2.671019\n",
      "Total time elapsed during training: 37.268 s\n",
      "Trial 235 pruned. \n",
      "Epoch: 1\tFidelity = 0.505072\tKL_Divergence = 2.700749\n",
      "Epoch: 2\tFidelity = 0.505634\tKL_Divergence = 2.642103\n",
      "Epoch: 3\tFidelity = 0.506015\tKL_Divergence = 2.605610\n",
      "Epoch: 4\tFidelity = 0.505369\tKL_Divergence = 2.668975\n",
      "Epoch: 5\tFidelity = 0.505990\tKL_Divergence = 2.608026\n",
      "Epoch: 6\tFidelity = 0.505383\tKL_Divergence = 2.667514\n",
      "Epoch: 7\tFidelity = 0.505996\tKL_Divergence = 2.607440\n",
      "Epoch: 8\tFidelity = 0.506162\tKL_Divergence = 2.592249\n",
      "Epoch: 9\tFidelity = 0.505673\tKL_Divergence = 2.638277\n",
      "Epoch: 10\tFidelity = 0.505167\tKL_Divergence = 2.690408\n",
      "Epoch: 11\tFidelity = 0.505945\tKL_Divergence = 2.612220\n",
      "Epoch: 12\tFidelity = 0.506184\tKL_Divergence = 2.590197\n",
      "Epoch: 13\tFidelity = 0.505610\tKL_Divergence = 2.644546\n",
      "Epoch: 14\tFidelity = 0.504926\tKL_Divergence = 2.717063\n",
      "Epoch: 15\tFidelity = 0.504731\tKL_Divergence = 2.739523\n",
      "Epoch: 16\tFidelity = 0.505356\tKL_Divergence = 2.670454\n",
      "Epoch: 17\tFidelity = 0.504852\tKL_Divergence = 2.725439\n",
      "Epoch: 18\tFidelity = 0.504874\tKL_Divergence = 2.722970\n",
      "Epoch: 19\tFidelity = 0.505059\tKL_Divergence = 2.702227\n",
      "Epoch: 20\tFidelity = 0.504495\tKL_Divergence = 2.767967\n",
      "Epoch: 21\tFidelity = 0.505216\tKL_Divergence = 2.685160\n",
      "Epoch: 22\tFidelity = 0.504593\tKL_Divergence = 2.755979\n",
      "Epoch: 23\tFidelity = 0.505034\tKL_Divergence = 2.704925\n",
      "Epoch: 24\tFidelity = 0.505359\tKL_Divergence = 2.670044\n",
      "Epoch: 25\tFidelity = 0.506507\tKL_Divergence = 2.561872\n",
      "Epoch: 26\tFidelity = 0.506185\tKL_Divergence = 2.590243\n",
      "Epoch: 27\tFidelity = 0.505817\tKL_Divergence = 2.624356\n",
      "Epoch: 28\tFidelity = 0.506137\tKL_Divergence = 2.594535\n",
      "Epoch: 29\tFidelity = 0.506308\tKL_Divergence = 2.579187\n",
      "Epoch: 30\tFidelity = 0.504663\tKL_Divergence = 2.747527\n",
      "Epoch: 31\tFidelity = 0.505057\tKL_Divergence = 2.702375\n",
      "Epoch: 32\tFidelity = 0.506896\tKL_Divergence = 2.529471\n",
      "Epoch: 33\tFidelity = 0.505441\tKL_Divergence = 2.661651\n",
      "Epoch: 34\tFidelity = 0.505008\tKL_Divergence = 2.707798\n",
      "Epoch: 35\tFidelity = 0.504986\tKL_Divergence = 2.710236\n",
      "Epoch: 36\tFidelity = 0.505491\tKL_Divergence = 2.656540\n",
      "Epoch: 37\tFidelity = 0.504442\tKL_Divergence = 2.774620\n",
      "Epoch: 38\tFidelity = 0.504654\tKL_Divergence = 2.748674\n",
      "Epoch: 39\tFidelity = 0.505467\tKL_Divergence = 2.658961\n",
      "Epoch: 40\tFidelity = 0.505981\tKL_Divergence = 2.608939\n",
      "Epoch: 41\tFidelity = 0.505676\tKL_Divergence = 2.638091\n",
      "Epoch: 42\tFidelity = 0.505809\tKL_Divergence = 2.625205\n",
      "Epoch: 43\tFidelity = 0.505619\tKL_Divergence = 2.643752\n",
      "Epoch: 44\tFidelity = 0.505924\tKL_Divergence = 2.614314\n",
      "Epoch: 45\tFidelity = 0.505254\tKL_Divergence = 2.681178\n",
      "Epoch: 46\tFidelity = 0.504973\tKL_Divergence = 2.711715\n",
      "Epoch: 47\tFidelity = 0.505191\tKL_Divergence = 2.687819\n",
      "Epoch: 48\tFidelity = 0.505040\tKL_Divergence = 2.704337\n",
      "Epoch: 49\tFidelity = 0.505467\tKL_Divergence = 2.659022\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:41:21,116] Trial 236 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.505530\tKL_Divergence = 2.652573\n",
      "Total time elapsed during training: 37.454 s\n",
      "Trial 236 pruned. \n",
      "Epoch: 1\tFidelity = 0.505854\tKL_Divergence = 2.620887\n",
      "Epoch: 2\tFidelity = 0.505701\tKL_Divergence = 2.635591\n",
      "Epoch: 3\tFidelity = 0.506329\tKL_Divergence = 2.577360\n",
      "Epoch: 4\tFidelity = 0.506146\tKL_Divergence = 2.593748\n",
      "Epoch: 5\tFidelity = 0.506500\tKL_Divergence = 2.562476\n",
      "Epoch: 6\tFidelity = 0.506095\tKL_Divergence = 2.598343\n",
      "Epoch: 7\tFidelity = 0.505602\tKL_Divergence = 2.645413\n",
      "Epoch: 8\tFidelity = 0.504994\tKL_Divergence = 2.709385\n",
      "Epoch: 9\tFidelity = 0.504546\tKL_Divergence = 2.761742\n",
      "Epoch: 10\tFidelity = 0.505036\tKL_Divergence = 2.704664\n",
      "Epoch: 11\tFidelity = 0.504286\tKL_Divergence = 2.794477\n",
      "Epoch: 12\tFidelity = 0.504686\tKL_Divergence = 2.744873\n",
      "Epoch: 13\tFidelity = 0.504383\tKL_Divergence = 2.782064\n",
      "Epoch: 14\tFidelity = 0.505422\tKL_Divergence = 2.663556\n",
      "Epoch: 15\tFidelity = 0.505066\tKL_Divergence = 2.701474\n",
      "Epoch: 16\tFidelity = 0.505408\tKL_Divergence = 2.665062\n",
      "Epoch: 17\tFidelity = 0.504938\tKL_Divergence = 2.715747\n",
      "Epoch: 18\tFidelity = 0.504919\tKL_Divergence = 2.717900\n",
      "Epoch: 19\tFidelity = 0.504042\tKL_Divergence = 2.827152\n",
      "Epoch: 20\tFidelity = 0.505583\tKL_Divergence = 2.647364\n",
      "Epoch: 21\tFidelity = 0.504485\tKL_Divergence = 2.769325\n",
      "Epoch: 22\tFidelity = 0.505492\tKL_Divergence = 2.656553\n",
      "Epoch: 23\tFidelity = 0.506235\tKL_Divergence = 2.585836\n",
      "Epoch: 24\tFidelity = 0.504756\tKL_Divergence = 2.736708\n",
      "Epoch: 25\tFidelity = 0.504711\tKL_Divergence = 2.742083\n",
      "Epoch: 26\tFidelity = 0.504731\tKL_Divergence = 2.739673\n",
      "Epoch: 27\tFidelity = 0.505624\tKL_Divergence = 2.643296\n",
      "Epoch: 28\tFidelity = 0.504794\tKL_Divergence = 2.732306\n",
      "Epoch: 29\tFidelity = 0.504952\tKL_Divergence = 2.714193\n",
      "Epoch: 30\tFidelity = 0.505599\tKL_Divergence = 2.645835\n",
      "Epoch: 31\tFidelity = 0.504707\tKL_Divergence = 2.742463\n",
      "Epoch: 32\tFidelity = 0.504616\tKL_Divergence = 2.753372\n",
      "Epoch: 33\tFidelity = 0.504017\tKL_Divergence = 2.830753\n",
      "Epoch: 34\tFidelity = 0.505797\tKL_Divergence = 2.626475\n",
      "Epoch: 35\tFidelity = 0.506250\tKL_Divergence = 2.584514\n",
      "Epoch: 36\tFidelity = 0.505494\tKL_Divergence = 2.656344\n",
      "Epoch: 37\tFidelity = 0.506212\tKL_Divergence = 2.587893\n",
      "Epoch: 38\tFidelity = 0.506277\tKL_Divergence = 2.582139\n",
      "Epoch: 39\tFidelity = 0.506095\tKL_Divergence = 2.598531\n",
      "Epoch: 40\tFidelity = 0.504821\tKL_Divergence = 2.729138\n",
      "Epoch: 41\tFidelity = 0.505349\tKL_Divergence = 2.671291\n",
      "Epoch: 42\tFidelity = 0.505071\tKL_Divergence = 2.701062\n",
      "Epoch: 43\tFidelity = 0.505956\tKL_Divergence = 2.611341\n",
      "Epoch: 44\tFidelity = 0.505540\tKL_Divergence = 2.651751\n",
      "Epoch: 45\tFidelity = 0.506237\tKL_Divergence = 2.585627\n",
      "Epoch: 46\tFidelity = 0.505136\tKL_Divergence = 2.693863\n",
      "Epoch: 47\tFidelity = 0.505095\tKL_Divergence = 2.698289\n",
      "Epoch: 48\tFidelity = 0.504033\tKL_Divergence = 2.828415\n",
      "Epoch: 49\tFidelity = 0.504709\tKL_Divergence = 2.742244\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:41:58,602] Trial 237 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.504397\tKL_Divergence = 2.780429\n",
      "Total time elapsed during training: 37.338 s\n",
      "Trial 237 pruned. \n",
      "Epoch: 1\tFidelity = 0.505287\tKL_Divergence = 2.677706\n",
      "Epoch: 2\tFidelity = 0.506335\tKL_Divergence = 2.576903\n",
      "Epoch: 3\tFidelity = 0.505847\tKL_Divergence = 2.621585\n",
      "Epoch: 4\tFidelity = 0.505462\tKL_Divergence = 2.659549\n",
      "Epoch: 5\tFidelity = 0.504815\tKL_Divergence = 2.729781\n",
      "Epoch: 6\tFidelity = 0.505181\tKL_Divergence = 2.688871\n",
      "Epoch: 7\tFidelity = 0.504865\tKL_Divergence = 2.724051\n",
      "Epoch: 8\tFidelity = 0.506079\tKL_Divergence = 2.599963\n",
      "Epoch: 9\tFidelity = 0.506987\tKL_Divergence = 2.522284\n",
      "Epoch: 10\tFidelity = 0.505342\tKL_Divergence = 2.671921\n",
      "Epoch: 11\tFidelity = 0.505909\tKL_Divergence = 2.615691\n",
      "Epoch: 12\tFidelity = 0.504998\tKL_Divergence = 2.708999\n",
      "Epoch: 13\tFidelity = 0.505034\tKL_Divergence = 2.705055\n",
      "Epoch: 14\tFidelity = 0.505188\tKL_Divergence = 2.688173\n",
      "Epoch: 15\tFidelity = 0.505057\tKL_Divergence = 2.702359\n",
      "Epoch: 16\tFidelity = 0.505485\tKL_Divergence = 2.657153\n",
      "Epoch: 17\tFidelity = 0.505422\tKL_Divergence = 2.663581\n",
      "Epoch: 18\tFidelity = 0.505227\tKL_Divergence = 2.684070\n",
      "Epoch: 19\tFidelity = 0.504756\tKL_Divergence = 2.736636\n",
      "Epoch: 20\tFidelity = 0.505153\tKL_Divergence = 2.691943\n",
      "Epoch: 21\tFidelity = 0.505874\tKL_Divergence = 2.618941\n",
      "Epoch: 22\tFidelity = 0.506127\tKL_Divergence = 2.595274\n",
      "Epoch: 23\tFidelity = 0.506512\tKL_Divergence = 2.560931\n",
      "Epoch: 24\tFidelity = 0.505554\tKL_Divergence = 2.649964\n",
      "Epoch: 25\tFidelity = 0.505286\tKL_Divergence = 2.677667\n",
      "Epoch: 26\tFidelity = 0.505535\tKL_Divergence = 2.651970\n",
      "Epoch: 27\tFidelity = 0.504624\tKL_Divergence = 2.752144\n",
      "Epoch: 28\tFidelity = 0.505266\tKL_Divergence = 2.679797\n",
      "Epoch: 29\tFidelity = 0.505375\tKL_Divergence = 2.668427\n",
      "Epoch: 30\tFidelity = 0.505651\tKL_Divergence = 2.640552\n",
      "Epoch: 31\tFidelity = 0.505057\tKL_Divergence = 2.702352\n",
      "Epoch: 32\tFidelity = 0.504931\tKL_Divergence = 2.716362\n",
      "Epoch: 33\tFidelity = 0.505804\tKL_Divergence = 2.625565\n",
      "Epoch: 34\tFidelity = 0.504647\tKL_Divergence = 2.749256\n",
      "Epoch: 35\tFidelity = 0.506190\tKL_Divergence = 2.589497\n",
      "Epoch: 36\tFidelity = 0.504766\tKL_Divergence = 2.735163\n",
      "Epoch: 37\tFidelity = 0.505748\tKL_Divergence = 2.630994\n",
      "Epoch: 38\tFidelity = 0.505279\tKL_Divergence = 2.678304\n",
      "Epoch: 39\tFidelity = 0.504723\tKL_Divergence = 2.740155\n",
      "Epoch: 40\tFidelity = 0.504876\tKL_Divergence = 2.722472\n",
      "Epoch: 41\tFidelity = 0.505612\tKL_Divergence = 2.644274\n",
      "Epoch: 42\tFidelity = 0.504925\tKL_Divergence = 2.717102\n",
      "Epoch: 43\tFidelity = 0.505082\tKL_Divergence = 2.699565\n",
      "Epoch: 44\tFidelity = 0.505031\tKL_Divergence = 2.705063\n",
      "Epoch: 45\tFidelity = 0.505628\tKL_Divergence = 2.642723\n",
      "Epoch: 46\tFidelity = 0.505194\tKL_Divergence = 2.687427\n",
      "Epoch: 47\tFidelity = 0.504771\tKL_Divergence = 2.734763\n",
      "Epoch: 48\tFidelity = 0.506857\tKL_Divergence = 2.532504\n",
      "Epoch: 49\tFidelity = 0.505922\tKL_Divergence = 2.613803\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:42:43,011] Trial 238 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.505425\tKL_Divergence = 2.662988\n",
      "Total time elapsed during training: 44.258 s\n",
      "Trial 238 pruned. \n",
      "Epoch: 1\tFidelity = 0.505283\tKL_Divergence = 2.677881\n",
      "Epoch: 2\tFidelity = 0.505319\tKL_Divergence = 2.674215\n",
      "Epoch: 3\tFidelity = 0.505014\tKL_Divergence = 2.707109\n",
      "Epoch: 4\tFidelity = 0.504957\tKL_Divergence = 2.713489\n",
      "Epoch: 5\tFidelity = 0.504606\tKL_Divergence = 2.754374\n",
      "Epoch: 6\tFidelity = 0.505204\tKL_Divergence = 2.686386\n",
      "Epoch: 7\tFidelity = 0.505547\tKL_Divergence = 2.650885\n",
      "Epoch: 8\tFidelity = 0.505562\tKL_Divergence = 2.649420\n",
      "Epoch: 9\tFidelity = 0.505444\tKL_Divergence = 2.661277\n",
      "Epoch: 10\tFidelity = 0.504933\tKL_Divergence = 2.716232\n",
      "Epoch: 11\tFidelity = 0.504489\tKL_Divergence = 2.768704\n",
      "Epoch: 12\tFidelity = 0.505505\tKL_Divergence = 2.655117\n",
      "Epoch: 13\tFidelity = 0.504495\tKL_Divergence = 2.767975\n",
      "Epoch: 14\tFidelity = 0.505356\tKL_Divergence = 2.670398\n",
      "Epoch: 15\tFidelity = 0.505229\tKL_Divergence = 2.683750\n",
      "Epoch: 16\tFidelity = 0.505082\tKL_Divergence = 2.699655\n",
      "Epoch: 17\tFidelity = 0.504739\tKL_Divergence = 2.738602\n",
      "Epoch: 18\tFidelity = 0.505550\tKL_Divergence = 2.650665\n",
      "Epoch: 19\tFidelity = 0.505409\tKL_Divergence = 2.665036\n",
      "Epoch: 20\tFidelity = 0.504805\tKL_Divergence = 2.730909\n",
      "Epoch: 21\tFidelity = 0.505089\tKL_Divergence = 2.698884\n",
      "Epoch: 22\tFidelity = 0.505527\tKL_Divergence = 2.652931\n",
      "Epoch: 23\tFidelity = 0.505984\tKL_Divergence = 2.608576\n",
      "Epoch: 24\tFidelity = 0.504536\tKL_Divergence = 2.762861\n",
      "Epoch: 25\tFidelity = 0.505079\tKL_Divergence = 2.700002\n",
      "Epoch: 26\tFidelity = 0.505514\tKL_Divergence = 2.654253\n",
      "Epoch: 27\tFidelity = 0.504822\tKL_Divergence = 2.729031\n",
      "Epoch: 28\tFidelity = 0.504670\tKL_Divergence = 2.746797\n",
      "Epoch: 29\tFidelity = 0.504481\tKL_Divergence = 2.769726\n",
      "Epoch: 30\tFidelity = 0.505026\tKL_Divergence = 2.705839\n",
      "Epoch: 31\tFidelity = 0.504700\tKL_Divergence = 2.743379\n",
      "Epoch: 32\tFidelity = 0.505203\tKL_Divergence = 2.686786\n",
      "Epoch: 33\tFidelity = 0.504067\tKL_Divergence = 2.823882\n",
      "Epoch: 34\tFidelity = 0.503961\tKL_Divergence = 2.838521\n",
      "Epoch: 35\tFidelity = 0.505008\tKL_Divergence = 2.707834\n",
      "Epoch: 36\tFidelity = 0.504655\tKL_Divergence = 2.748577\n",
      "Epoch: 37\tFidelity = 0.504982\tKL_Divergence = 2.710814\n",
      "Epoch: 38\tFidelity = 0.504688\tKL_Divergence = 2.744710\n",
      "Epoch: 39\tFidelity = 0.504907\tKL_Divergence = 2.719410\n",
      "Epoch: 40\tFidelity = 0.504466\tKL_Divergence = 2.771778\n",
      "Epoch: 41\tFidelity = 0.505346\tKL_Divergence = 2.671607\n",
      "Epoch: 42\tFidelity = 0.505008\tKL_Divergence = 2.708021\n",
      "Epoch: 43\tFidelity = 0.504277\tKL_Divergence = 2.795847\n",
      "Epoch: 44\tFidelity = 0.504549\tKL_Divergence = 2.761506\n",
      "Epoch: 45\tFidelity = 0.505048\tKL_Divergence = 2.703595\n",
      "Epoch: 46\tFidelity = 0.504392\tKL_Divergence = 2.781162\n",
      "Epoch: 47\tFidelity = 0.504842\tKL_Divergence = 2.726792\n",
      "Epoch: 48\tFidelity = 0.505486\tKL_Divergence = 2.657248\n",
      "Epoch: 49\tFidelity = 0.505239\tKL_Divergence = 2.682919\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:44:01,218] Trial 239 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.504510\tKL_Divergence = 2.766263\n",
      "Total time elapsed during training: 78.052 s\n",
      "Trial 239 pruned. \n",
      "Epoch: 1\tFidelity = 0.504716\tKL_Divergence = 2.741503\n",
      "Epoch: 2\tFidelity = 0.504661\tKL_Divergence = 2.747959\n",
      "Epoch: 3\tFidelity = 0.504402\tKL_Divergence = 2.779865\n",
      "Epoch: 4\tFidelity = 0.505004\tKL_Divergence = 2.708518\n",
      "Epoch: 5\tFidelity = 0.504649\tKL_Divergence = 2.749343\n",
      "Epoch: 6\tFidelity = 0.504961\tKL_Divergence = 2.713332\n",
      "Epoch: 7\tFidelity = 0.505255\tKL_Divergence = 2.681247\n",
      "Epoch: 8\tFidelity = 0.504189\tKL_Divergence = 2.807434\n",
      "Epoch: 9\tFidelity = 0.505076\tKL_Divergence = 2.700260\n",
      "Epoch: 10\tFidelity = 0.504238\tKL_Divergence = 2.800754\n",
      "Epoch: 11\tFidelity = 0.504079\tKL_Divergence = 2.822104\n",
      "Epoch: 12\tFidelity = 0.505212\tKL_Divergence = 2.685595\n",
      "Epoch: 13\tFidelity = 0.504186\tKL_Divergence = 2.807898\n",
      "Epoch: 14\tFidelity = 0.505303\tKL_Divergence = 2.676142\n",
      "Epoch: 15\tFidelity = 0.504357\tKL_Divergence = 2.785569\n",
      "Epoch: 16\tFidelity = 0.505322\tKL_Divergence = 2.674223\n",
      "Epoch: 17\tFidelity = 0.504278\tKL_Divergence = 2.795816\n",
      "Epoch: 18\tFidelity = 0.504274\tKL_Divergence = 2.796342\n",
      "Epoch: 19\tFidelity = 0.504931\tKL_Divergence = 2.716686\n",
      "Epoch: 20\tFidelity = 0.504877\tKL_Divergence = 2.722831\n",
      "Epoch: 21\tFidelity = 0.504734\tKL_Divergence = 2.739389\n",
      "Epoch: 22\tFidelity = 0.504812\tKL_Divergence = 2.730113\n",
      "Epoch: 23\tFidelity = 0.504784\tKL_Divergence = 2.733428\n",
      "Epoch: 24\tFidelity = 0.505018\tKL_Divergence = 2.706846\n",
      "Epoch: 25\tFidelity = 0.505319\tKL_Divergence = 2.674304\n",
      "Epoch: 26\tFidelity = 0.504999\tKL_Divergence = 2.708860\n",
      "Epoch: 27\tFidelity = 0.504481\tKL_Divergence = 2.769938\n",
      "Epoch: 28\tFidelity = 0.504510\tKL_Divergence = 2.766301\n",
      "Epoch: 29\tFidelity = 0.504497\tKL_Divergence = 2.767822\n",
      "Epoch: 30\tFidelity = 0.504878\tKL_Divergence = 2.722650\n",
      "Epoch: 31\tFidelity = 0.504969\tKL_Divergence = 2.712134\n",
      "Epoch: 32\tFidelity = 0.504974\tKL_Divergence = 2.711157\n",
      "Epoch: 33\tFidelity = 0.504360\tKL_Divergence = 2.784619\n",
      "Epoch: 34\tFidelity = 0.503967\tKL_Divergence = 2.837526\n",
      "Epoch: 35\tFidelity = 0.504719\tKL_Divergence = 2.740888\n",
      "Epoch: 36\tFidelity = 0.505250\tKL_Divergence = 2.681070\n",
      "Epoch: 37\tFidelity = 0.504408\tKL_Divergence = 2.778548\n",
      "Epoch: 38\tFidelity = 0.504402\tKL_Divergence = 2.778884\n",
      "Epoch: 39\tFidelity = 0.504623\tKL_Divergence = 2.751691\n",
      "Epoch: 40\tFidelity = 0.504252\tKL_Divergence = 2.798462\n",
      "Epoch: 41\tFidelity = 0.505067\tKL_Divergence = 2.700693\n",
      "Epoch: 42\tFidelity = 0.505339\tKL_Divergence = 2.671687\n",
      "Epoch: 43\tFidelity = 0.504058\tKL_Divergence = 2.824541\n",
      "Epoch: 44\tFidelity = 0.504748\tKL_Divergence = 2.737286\n",
      "Epoch: 45\tFidelity = 0.504445\tKL_Divergence = 2.774010\n",
      "Epoch: 46\tFidelity = 0.504868\tKL_Divergence = 2.723251\n",
      "Epoch: 47\tFidelity = 0.504519\tKL_Divergence = 2.764666\n",
      "Epoch: 48\tFidelity = 0.505042\tKL_Divergence = 2.703501\n",
      "Epoch: 49\tFidelity = 0.505025\tKL_Divergence = 2.705714\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:44:38,770] Trial 240 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.504777\tKL_Divergence = 2.733992\n",
      "Total time elapsed during training: 37.402 s\n",
      "Trial 240 pruned. \n",
      "Epoch: 1\tFidelity = 0.504944\tKL_Divergence = 2.714872\n",
      "Epoch: 2\tFidelity = 0.504386\tKL_Divergence = 2.781584\n",
      "Epoch: 3\tFidelity = 0.504553\tKL_Divergence = 2.760886\n",
      "Epoch: 4\tFidelity = 0.504775\tKL_Divergence = 2.734421\n",
      "Epoch: 5\tFidelity = 0.504427\tKL_Divergence = 2.776488\n",
      "Epoch: 6\tFidelity = 0.504311\tKL_Divergence = 2.791393\n",
      "Epoch: 7\tFidelity = 0.504209\tKL_Divergence = 2.804684\n",
      "Epoch: 8\tFidelity = 0.504778\tKL_Divergence = 2.734128\n",
      "Epoch: 9\tFidelity = 0.504616\tKL_Divergence = 2.753403\n",
      "Epoch: 10\tFidelity = 0.504729\tKL_Divergence = 2.739915\n",
      "Epoch: 11\tFidelity = 0.504892\tKL_Divergence = 2.721063\n",
      "Epoch: 12\tFidelity = 0.504730\tKL_Divergence = 2.739750\n",
      "Epoch: 13\tFidelity = 0.504618\tKL_Divergence = 2.753131\n",
      "Epoch: 14\tFidelity = 0.504239\tKL_Divergence = 2.800886\n",
      "Epoch: 15\tFidelity = 0.504389\tKL_Divergence = 2.781483\n",
      "Epoch: 16\tFidelity = 0.505017\tKL_Divergence = 2.707013\n",
      "Epoch: 17\tFidelity = 0.504886\tKL_Divergence = 2.721744\n",
      "Epoch: 18\tFidelity = 0.504655\tKL_Divergence = 2.748723\n",
      "Epoch: 19\tFidelity = 0.504590\tKL_Divergence = 2.756645\n",
      "Epoch: 20\tFidelity = 0.504484\tKL_Divergence = 2.769588\n",
      "Epoch: 21\tFidelity = 0.504740\tKL_Divergence = 2.738723\n",
      "Epoch: 22\tFidelity = 0.504494\tKL_Divergence = 2.768361\n",
      "Epoch: 23\tFidelity = 0.504266\tKL_Divergence = 2.797390\n",
      "Epoch: 24\tFidelity = 0.504691\tKL_Divergence = 2.744515\n",
      "Epoch: 25\tFidelity = 0.504581\tKL_Divergence = 2.757749\n",
      "Epoch: 26\tFidelity = 0.504350\tKL_Divergence = 2.786571\n",
      "Epoch: 27\tFidelity = 0.504317\tKL_Divergence = 2.790711\n",
      "Epoch: 28\tFidelity = 0.504298\tKL_Divergence = 2.793178\n",
      "Epoch: 29\tFidelity = 0.504486\tKL_Divergence = 2.769318\n",
      "Epoch: 30\tFidelity = 0.504804\tKL_Divergence = 2.731272\n",
      "Epoch: 31\tFidelity = 0.504297\tKL_Divergence = 2.793339\n",
      "Epoch: 32\tFidelity = 0.504596\tKL_Divergence = 2.755871\n",
      "Epoch: 33\tFidelity = 0.504718\tKL_Divergence = 2.741324\n",
      "Epoch: 34\tFidelity = 0.504859\tKL_Divergence = 2.724842\n",
      "Epoch: 35\tFidelity = 0.504831\tKL_Divergence = 2.728109\n",
      "Epoch: 36\tFidelity = 0.504292\tKL_Divergence = 2.794020\n",
      "Epoch: 37\tFidelity = 0.504849\tKL_Divergence = 2.726069\n",
      "Epoch: 38\tFidelity = 0.504699\tKL_Divergence = 2.743564\n",
      "Epoch: 39\tFidelity = 0.504591\tKL_Divergence = 2.756505\n",
      "Epoch: 40\tFidelity = 0.504516\tKL_Divergence = 2.765687\n",
      "Epoch: 41\tFidelity = 0.504668\tKL_Divergence = 2.747258\n",
      "Epoch: 42\tFidelity = 0.504797\tKL_Divergence = 2.732072\n",
      "Epoch: 43\tFidelity = 0.504862\tKL_Divergence = 2.724582\n",
      "Epoch: 44\tFidelity = 0.504920\tKL_Divergence = 2.717900\n",
      "Epoch: 45\tFidelity = 0.505008\tKL_Divergence = 2.708099\n",
      "Epoch: 46\tFidelity = 0.504390\tKL_Divergence = 2.781371\n",
      "Epoch: 47\tFidelity = 0.504437\tKL_Divergence = 2.775471\n",
      "Epoch: 48\tFidelity = 0.504253\tKL_Divergence = 2.799011\n",
      "Epoch: 49\tFidelity = 0.504402\tKL_Divergence = 2.779874\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:45:16,765] Trial 241 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.505027\tKL_Divergence = 2.705944\n",
      "Total time elapsed during training: 37.833 s\n",
      "Trial 241 pruned. \n",
      "Epoch: 1\tFidelity = 0.504434\tKL_Divergence = 2.775849\n",
      "Epoch: 2\tFidelity = 0.504559\tKL_Divergence = 2.760349\n",
      "Epoch: 3\tFidelity = 0.504971\tKL_Divergence = 2.712157\n",
      "Epoch: 4\tFidelity = 0.504654\tKL_Divergence = 2.748848\n",
      "Epoch: 5\tFidelity = 0.504502\tKL_Divergence = 2.767315\n",
      "Epoch: 6\tFidelity = 0.504888\tKL_Divergence = 2.721612\n",
      "Epoch: 7\tFidelity = 0.504524\tKL_Divergence = 2.764684\n",
      "Epoch: 8\tFidelity = 0.504777\tKL_Divergence = 2.734342\n",
      "Epoch: 9\tFidelity = 0.504361\tKL_Divergence = 2.785064\n",
      "Epoch: 10\tFidelity = 0.504630\tKL_Divergence = 2.751764\n",
      "Epoch: 11\tFidelity = 0.504429\tKL_Divergence = 2.776483\n",
      "Epoch: 12\tFidelity = 0.504419\tKL_Divergence = 2.777691\n",
      "Epoch: 13\tFidelity = 0.504775\tKL_Divergence = 2.734552\n",
      "Epoch: 14\tFidelity = 0.504341\tKL_Divergence = 2.787628\n",
      "Epoch: 15\tFidelity = 0.504459\tKL_Divergence = 2.772765\n",
      "Epoch: 16\tFidelity = 0.504659\tKL_Divergence = 2.748277\n",
      "Epoch: 17\tFidelity = 0.504206\tKL_Divergence = 2.805183\n",
      "Epoch: 18\tFidelity = 0.504617\tKL_Divergence = 2.753377\n",
      "Epoch: 19\tFidelity = 0.504586\tKL_Divergence = 2.757086\n",
      "Epoch: 20\tFidelity = 0.504312\tKL_Divergence = 2.791347\n",
      "Epoch: 21\tFidelity = 0.504520\tKL_Divergence = 2.765181\n",
      "Epoch: 22\tFidelity = 0.504952\tKL_Divergence = 2.714295\n",
      "Epoch: 23\tFidelity = 0.504892\tKL_Divergence = 2.721051\n",
      "Epoch: 24\tFidelity = 0.504389\tKL_Divergence = 2.781490\n",
      "Epoch: 25\tFidelity = 0.504804\tKL_Divergence = 2.731154\n",
      "Epoch: 26\tFidelity = 0.504910\tKL_Divergence = 2.719042\n",
      "Epoch: 27\tFidelity = 0.504768\tKL_Divergence = 2.735378\n",
      "Epoch: 28\tFidelity = 0.504907\tKL_Divergence = 2.719419\n",
      "Epoch: 29\tFidelity = 0.504740\tKL_Divergence = 2.738636\n",
      "Epoch: 30\tFidelity = 0.504329\tKL_Divergence = 2.789134\n",
      "Epoch: 31\tFidelity = 0.504608\tKL_Divergence = 2.754364\n",
      "Epoch: 32\tFidelity = 0.504862\tKL_Divergence = 2.724504\n",
      "Epoch: 33\tFidelity = 0.505157\tKL_Divergence = 2.691674\n",
      "Epoch: 34\tFidelity = 0.504806\tKL_Divergence = 2.730931\n",
      "Epoch: 35\tFidelity = 0.504881\tKL_Divergence = 2.722322\n",
      "Epoch: 36\tFidelity = 0.504928\tKL_Divergence = 2.717035\n",
      "Epoch: 37\tFidelity = 0.504795\tKL_Divergence = 2.732186\n",
      "Epoch: 38\tFidelity = 0.504396\tKL_Divergence = 2.780603\n",
      "Epoch: 39\tFidelity = 0.504922\tKL_Divergence = 2.717704\n",
      "Epoch: 40\tFidelity = 0.504458\tKL_Divergence = 2.772830\n",
      "Epoch: 41\tFidelity = 0.504754\tKL_Divergence = 2.736980\n",
      "Epoch: 42\tFidelity = 0.504922\tKL_Divergence = 2.717641\n",
      "Epoch: 43\tFidelity = 0.504284\tKL_Divergence = 2.794903\n",
      "Epoch: 44\tFidelity = 0.504641\tKL_Divergence = 2.750369\n",
      "Epoch: 45\tFidelity = 0.504754\tKL_Divergence = 2.736974\n",
      "Epoch: 46\tFidelity = 0.504558\tKL_Divergence = 2.760488\n",
      "Epoch: 47\tFidelity = 0.504548\tKL_Divergence = 2.761691\n",
      "Epoch: 48\tFidelity = 0.504756\tKL_Divergence = 2.736773\n",
      "Epoch: 49\tFidelity = 0.504838\tKL_Divergence = 2.727265\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:45:54,429] Trial 242 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.504363\tKL_Divergence = 2.784846\n",
      "Total time elapsed during training: 37.508 s\n",
      "Trial 242 pruned. \n",
      "Epoch: 1\tFidelity = 0.504481\tKL_Divergence = 2.769970\n",
      "Epoch: 2\tFidelity = 0.503992\tKL_Divergence = 2.834333\n",
      "Epoch: 3\tFidelity = 0.504044\tKL_Divergence = 2.827017\n",
      "Epoch: 4\tFidelity = 0.504019\tKL_Divergence = 2.830515\n",
      "Epoch: 5\tFidelity = 0.503632\tKL_Divergence = 2.886869\n",
      "Epoch: 6\tFidelity = 0.503446\tKL_Divergence = 2.916038\n",
      "Epoch: 7\tFidelity = 0.503477\tKL_Divergence = 2.911126\n",
      "Epoch: 8\tFidelity = 0.503496\tKL_Divergence = 2.908032\n",
      "Epoch: 9\tFidelity = 0.503631\tKL_Divergence = 2.886985\n",
      "Epoch: 10\tFidelity = 0.503414\tKL_Divergence = 2.921298\n",
      "Epoch: 11\tFidelity = 0.503388\tKL_Divergence = 2.925601\n",
      "Epoch: 12\tFidelity = 0.503790\tKL_Divergence = 2.863122\n",
      "Epoch: 13\tFidelity = 0.505470\tKL_Divergence = 2.658910\n",
      "Epoch: 14\tFidelity = 0.505438\tKL_Divergence = 2.662122\n",
      "Epoch: 15\tFidelity = 0.506740\tKL_Divergence = 2.542507\n",
      "Epoch: 16\tFidelity = 0.505945\tKL_Divergence = 2.612491\n",
      "Epoch: 17\tFidelity = 0.504190\tKL_Divergence = 2.807365\n",
      "Epoch: 18\tFidelity = 0.503998\tKL_Divergence = 2.833506\n",
      "Epoch: 19\tFidelity = 0.504432\tKL_Divergence = 2.776096\n",
      "Epoch: 20\tFidelity = 0.503439\tKL_Divergence = 2.917170\n",
      "Epoch: 21\tFidelity = 0.503473\tKL_Divergence = 2.911673\n",
      "Epoch: 22\tFidelity = 0.504729\tKL_Divergence = 2.739995\n",
      "Epoch: 23\tFidelity = 0.506172\tKL_Divergence = 2.591567\n",
      "Epoch: 24\tFidelity = 0.505797\tKL_Divergence = 2.626522\n",
      "Epoch: 25\tFidelity = 0.505832\tKL_Divergence = 2.623150\n",
      "Epoch: 26\tFidelity = 0.505411\tKL_Divergence = 2.664960\n",
      "Epoch: 27\tFidelity = 0.505321\tKL_Divergence = 2.674287\n",
      "Epoch: 28\tFidelity = 0.506569\tKL_Divergence = 2.556757\n",
      "Epoch: 29\tFidelity = 0.506320\tKL_Divergence = 2.578309\n",
      "Epoch: 30\tFidelity = 0.506564\tKL_Divergence = 2.557224\n",
      "Epoch: 31\tFidelity = 0.507348\tKL_Divergence = 2.494217\n",
      "Epoch: 32\tFidelity = 0.506213\tKL_Divergence = 2.587896\n",
      "Epoch: 33\tFidelity = 0.504700\tKL_Divergence = 2.743402\n",
      "Epoch: 34\tFidelity = 0.503856\tKL_Divergence = 2.853490\n",
      "Epoch: 35\tFidelity = 0.504478\tKL_Divergence = 2.770361\n",
      "Epoch: 36\tFidelity = 0.504996\tKL_Divergence = 2.709403\n",
      "Epoch: 37\tFidelity = 0.506573\tKL_Divergence = 2.556446\n",
      "Epoch: 38\tFidelity = 0.506580\tKL_Divergence = 2.555836\n",
      "Epoch: 39\tFidelity = 0.506155\tKL_Divergence = 2.593078\n",
      "Epoch: 40\tFidelity = 0.505274\tKL_Divergence = 2.679234\n",
      "Epoch: 41\tFidelity = 0.505342\tKL_Divergence = 2.672083\n",
      "Epoch: 42\tFidelity = 0.506932\tKL_Divergence = 2.526825\n",
      "Epoch: 43\tFidelity = 0.505980\tKL_Divergence = 2.609170\n",
      "Epoch: 44\tFidelity = 0.505497\tKL_Divergence = 2.656077\n",
      "Epoch: 45\tFidelity = 0.504795\tKL_Divergence = 2.732229\n",
      "Epoch: 46\tFidelity = 0.504287\tKL_Divergence = 2.794575\n",
      "Epoch: 47\tFidelity = 0.504810\tKL_Divergence = 2.730554\n",
      "Epoch: 48\tFidelity = 0.506129\tKL_Divergence = 2.595416\n",
      "Epoch: 49\tFidelity = 0.505584\tKL_Divergence = 2.647373\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:46:32,079] Trial 243 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.506040\tKL_Divergence = 2.603638\n",
      "Total time elapsed during training: 37.495 s\n",
      "Trial 243 pruned. \n",
      "Epoch: 1\tFidelity = 0.505288\tKL_Divergence = 2.677729\n",
      "Epoch: 2\tFidelity = 0.504841\tKL_Divergence = 2.726949\n",
      "Epoch: 3\tFidelity = 0.504640\tKL_Divergence = 2.750575\n",
      "Epoch: 4\tFidelity = 0.504763\tKL_Divergence = 2.735927\n",
      "Epoch: 5\tFidelity = 0.504877\tKL_Divergence = 2.722849\n",
      "Epoch: 6\tFidelity = 0.504857\tKL_Divergence = 2.725080\n",
      "Epoch: 7\tFidelity = 0.504668\tKL_Divergence = 2.747208\n",
      "Epoch: 8\tFidelity = 0.504909\tKL_Divergence = 2.719144\n",
      "Epoch: 9\tFidelity = 0.504603\tKL_Divergence = 2.755025\n",
      "Epoch: 10\tFidelity = 0.504931\tKL_Divergence = 2.716643\n",
      "Epoch: 11\tFidelity = 0.504650\tKL_Divergence = 2.749381\n",
      "Epoch: 12\tFidelity = 0.504730\tKL_Divergence = 2.739837\n",
      "Epoch: 13\tFidelity = 0.504776\tKL_Divergence = 2.734440\n",
      "Epoch: 14\tFidelity = 0.504788\tKL_Divergence = 2.733055\n",
      "Epoch: 15\tFidelity = 0.504879\tKL_Divergence = 2.722558\n",
      "Epoch: 16\tFidelity = 0.504860\tKL_Divergence = 2.724662\n",
      "Epoch: 17\tFidelity = 0.504658\tKL_Divergence = 2.748360\n",
      "Epoch: 18\tFidelity = 0.504930\tKL_Divergence = 2.716745\n",
      "Epoch: 19\tFidelity = 0.504739\tKL_Divergence = 2.738791\n",
      "Epoch: 20\tFidelity = 0.504775\tKL_Divergence = 2.734580\n",
      "Epoch: 21\tFidelity = 0.504940\tKL_Divergence = 2.715608\n",
      "Epoch: 22\tFidelity = 0.505078\tKL_Divergence = 2.700265\n",
      "Epoch: 23\tFidelity = 0.504742\tKL_Divergence = 2.738392\n",
      "Epoch: 24\tFidelity = 0.504609\tKL_Divergence = 2.754268\n",
      "Epoch: 25\tFidelity = 0.505063\tKL_Divergence = 2.701907\n",
      "Epoch: 26\tFidelity = 0.504432\tKL_Divergence = 2.776071\n",
      "Epoch: 27\tFidelity = 0.504740\tKL_Divergence = 2.738660\n",
      "Epoch: 28\tFidelity = 0.504591\tKL_Divergence = 2.756371\n",
      "Epoch: 29\tFidelity = 0.504619\tKL_Divergence = 2.753050\n",
      "Epoch: 30\tFidelity = 0.504995\tKL_Divergence = 2.709436\n",
      "Epoch: 31\tFidelity = 0.504630\tKL_Divergence = 2.751712\n",
      "Epoch: 32\tFidelity = 0.504910\tKL_Divergence = 2.718987\n",
      "Epoch: 33\tFidelity = 0.504698\tKL_Divergence = 2.743632\n",
      "Epoch: 34\tFidelity = 0.504680\tKL_Divergence = 2.745724\n",
      "Epoch: 35\tFidelity = 0.504780\tKL_Divergence = 2.733920\n",
      "Epoch: 36\tFidelity = 0.504809\tKL_Divergence = 2.730597\n",
      "Epoch: 37\tFidelity = 0.504867\tKL_Divergence = 2.723895\n",
      "Epoch: 38\tFidelity = 0.504517\tKL_Divergence = 2.765469\n",
      "Epoch: 39\tFidelity = 0.504915\tKL_Divergence = 2.718494\n",
      "Epoch: 40\tFidelity = 0.504760\tKL_Divergence = 2.736248\n",
      "Epoch: 41\tFidelity = 0.504848\tKL_Divergence = 2.726054\n",
      "Epoch: 42\tFidelity = 0.504458\tKL_Divergence = 2.772750\n",
      "Epoch: 43\tFidelity = 0.504928\tKL_Divergence = 2.716990\n",
      "Epoch: 44\tFidelity = 0.504775\tKL_Divergence = 2.734552\n",
      "Epoch: 45\tFidelity = 0.504785\tKL_Divergence = 2.733347\n",
      "Epoch: 46\tFidelity = 0.504146\tKL_Divergence = 2.813189\n",
      "Epoch: 47\tFidelity = 0.504929\tKL_Divergence = 2.716859\n",
      "Epoch: 48\tFidelity = 0.504911\tKL_Divergence = 2.718925\n",
      "Epoch: 49\tFidelity = 0.504814\tKL_Divergence = 2.730032\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:47:03,169] Trial 244 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.504320\tKL_Divergence = 2.790325\n",
      "Total time elapsed during training: 30.925 s\n",
      "Trial 244 pruned. \n",
      "Epoch: 1\tFidelity = 0.504710\tKL_Divergence = 2.742195\n",
      "Epoch: 2\tFidelity = 0.504684\tKL_Divergence = 2.745217\n",
      "Epoch: 3\tFidelity = 0.504942\tKL_Divergence = 2.715439\n",
      "Epoch: 4\tFidelity = 0.504695\tKL_Divergence = 2.743916\n",
      "Epoch: 5\tFidelity = 0.504744\tKL_Divergence = 2.738228\n",
      "Epoch: 6\tFidelity = 0.504916\tKL_Divergence = 2.718307\n",
      "Epoch: 7\tFidelity = 0.504698\tKL_Divergence = 2.743670\n",
      "Epoch: 8\tFidelity = 0.504508\tKL_Divergence = 2.766626\n",
      "Epoch: 9\tFidelity = 0.504709\tKL_Divergence = 2.742358\n",
      "Epoch: 10\tFidelity = 0.504701\tKL_Divergence = 2.743298\n",
      "Epoch: 11\tFidelity = 0.505105\tKL_Divergence = 2.697391\n",
      "Epoch: 12\tFidelity = 0.504800\tKL_Divergence = 2.731603\n",
      "Epoch: 13\tFidelity = 0.504749\tKL_Divergence = 2.737641\n",
      "Epoch: 14\tFidelity = 0.504696\tKL_Divergence = 2.743844\n",
      "Epoch: 15\tFidelity = 0.504893\tKL_Divergence = 2.720986\n",
      "Epoch: 16\tFidelity = 0.504583\tKL_Divergence = 2.757421\n",
      "Epoch: 17\tFidelity = 0.504701\tKL_Divergence = 2.743237\n",
      "Epoch: 18\tFidelity = 0.505072\tKL_Divergence = 2.700968\n",
      "Epoch: 19\tFidelity = 0.504692\tKL_Divergence = 2.744273\n",
      "Epoch: 20\tFidelity = 0.504792\tKL_Divergence = 2.732621\n",
      "Epoch: 21\tFidelity = 0.504557\tKL_Divergence = 2.760631\n",
      "Epoch: 22\tFidelity = 0.504751\tKL_Divergence = 2.737395\n",
      "Epoch: 23\tFidelity = 0.504390\tKL_Divergence = 2.781385\n",
      "Epoch: 24\tFidelity = 0.504844\tKL_Divergence = 2.726562\n",
      "Epoch: 25\tFidelity = 0.504631\tKL_Divergence = 2.751646\n",
      "Epoch: 26\tFidelity = 0.504743\tKL_Divergence = 2.738267\n",
      "Epoch: 27\tFidelity = 0.504745\tKL_Divergence = 2.738075\n",
      "Epoch: 28\tFidelity = 0.504463\tKL_Divergence = 2.772144\n",
      "Epoch: 29\tFidelity = 0.504891\tKL_Divergence = 2.721222\n",
      "Epoch: 30\tFidelity = 0.504727\tKL_Divergence = 2.740202\n",
      "Epoch: 31\tFidelity = 0.504573\tKL_Divergence = 2.758647\n",
      "Epoch: 32\tFidelity = 0.504684\tKL_Divergence = 2.745311\n",
      "Epoch: 33\tFidelity = 0.504877\tKL_Divergence = 2.722739\n",
      "Epoch: 34\tFidelity = 0.504719\tKL_Divergence = 2.741099\n",
      "Epoch: 35\tFidelity = 0.504703\tKL_Divergence = 2.743031\n",
      "Epoch: 36\tFidelity = 0.505132\tKL_Divergence = 2.694347\n",
      "Epoch: 37\tFidelity = 0.505033\tKL_Divergence = 2.705294\n",
      "Epoch: 38\tFidelity = 0.504665\tKL_Divergence = 2.747522\n",
      "Epoch: 39\tFidelity = 0.504775\tKL_Divergence = 2.734598\n",
      "Epoch: 40\tFidelity = 0.504678\tKL_Divergence = 2.745996\n",
      "Epoch: 41\tFidelity = 0.504517\tKL_Divergence = 2.765493\n",
      "Epoch: 42\tFidelity = 0.504922\tKL_Divergence = 2.717621\n",
      "Epoch: 43\tFidelity = 0.504560\tKL_Divergence = 2.760230\n",
      "Epoch: 44\tFidelity = 0.504857\tKL_Divergence = 2.725098\n",
      "Epoch: 45\tFidelity = 0.504732\tKL_Divergence = 2.739558\n",
      "Epoch: 46\tFidelity = 0.504665\tKL_Divergence = 2.747567\n",
      "Epoch: 47\tFidelity = 0.504546\tKL_Divergence = 2.761912\n",
      "Epoch: 48\tFidelity = 0.504555\tKL_Divergence = 2.760837\n",
      "Epoch: 49\tFidelity = 0.504869\tKL_Divergence = 2.723637\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:47:34,642] Trial 245 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.504710\tKL_Divergence = 2.742206\n",
      "Total time elapsed during training: 31.308 s\n",
      "Trial 245 pruned. \n",
      "Epoch: 1\tFidelity = 0.504485\tKL_Divergence = 2.769442\n",
      "Epoch: 2\tFidelity = 0.505041\tKL_Divergence = 2.704311\n",
      "Epoch: 3\tFidelity = 0.504658\tKL_Divergence = 2.748356\n",
      "Epoch: 4\tFidelity = 0.505133\tKL_Divergence = 2.694219\n",
      "Epoch: 5\tFidelity = 0.504237\tKL_Divergence = 2.801018\n",
      "Epoch: 6\tFidelity = 0.504565\tKL_Divergence = 2.759543\n",
      "Epoch: 7\tFidelity = 0.504841\tKL_Divergence = 2.726877\n",
      "Epoch: 8\tFidelity = 0.505138\tKL_Divergence = 2.693705\n",
      "Epoch: 9\tFidelity = 0.505120\tKL_Divergence = 2.695671\n",
      "Epoch: 10\tFidelity = 0.504437\tKL_Divergence = 2.775451\n",
      "Epoch: 11\tFidelity = 0.504704\tKL_Divergence = 2.742853\n",
      "Epoch: 12\tFidelity = 0.504350\tKL_Divergence = 2.786398\n",
      "Epoch: 13\tFidelity = 0.504602\tKL_Divergence = 2.755075\n",
      "Epoch: 14\tFidelity = 0.505023\tKL_Divergence = 2.706373\n",
      "Epoch: 15\tFidelity = 0.504961\tKL_Divergence = 2.713282\n",
      "Epoch: 16\tFidelity = 0.504548\tKL_Divergence = 2.761642\n",
      "Epoch: 17\tFidelity = 0.504696\tKL_Divergence = 2.743826\n",
      "Epoch: 18\tFidelity = 0.504734\tKL_Divergence = 2.739289\n",
      "Epoch: 19\tFidelity = 0.505048\tKL_Divergence = 2.703609\n",
      "Epoch: 20\tFidelity = 0.505187\tKL_Divergence = 2.688444\n",
      "Epoch: 21\tFidelity = 0.504797\tKL_Divergence = 2.731934\n",
      "Epoch: 22\tFidelity = 0.504300\tKL_Divergence = 2.792880\n",
      "Epoch: 23\tFidelity = 0.504836\tKL_Divergence = 2.727474\n",
      "Epoch: 24\tFidelity = 0.504601\tKL_Divergence = 2.755165\n",
      "Epoch: 25\tFidelity = 0.504708\tKL_Divergence = 2.742369\n",
      "Epoch: 26\tFidelity = 0.504870\tKL_Divergence = 2.723543\n",
      "Epoch: 27\tFidelity = 0.505357\tKL_Divergence = 2.670524\n",
      "Epoch: 28\tFidelity = 0.504787\tKL_Divergence = 2.733104\n",
      "Epoch: 29\tFidelity = 0.504622\tKL_Divergence = 2.752671\n",
      "Epoch: 30\tFidelity = 0.505122\tKL_Divergence = 2.695410\n",
      "Epoch: 31\tFidelity = 0.504565\tKL_Divergence = 2.759556\n",
      "Epoch: 32\tFidelity = 0.504643\tKL_Divergence = 2.750129\n",
      "Epoch: 33\tFidelity = 0.504814\tKL_Divergence = 2.729997\n",
      "Epoch: 34\tFidelity = 0.505215\tKL_Divergence = 2.685398\n",
      "Epoch: 35\tFidelity = 0.504467\tKL_Divergence = 2.771602\n",
      "Epoch: 36\tFidelity = 0.504252\tKL_Divergence = 2.799095\n",
      "Epoch: 37\tFidelity = 0.504947\tKL_Divergence = 2.714892\n",
      "Epoch: 38\tFidelity = 0.504617\tKL_Divergence = 2.753283\n",
      "Epoch: 39\tFidelity = 0.505100\tKL_Divergence = 2.697868\n",
      "Epoch: 40\tFidelity = 0.505254\tKL_Divergence = 2.681319\n",
      "Epoch: 41\tFidelity = 0.504957\tKL_Divergence = 2.713744\n",
      "Epoch: 42\tFidelity = 0.505091\tKL_Divergence = 2.698847\n",
      "Epoch: 43\tFidelity = 0.504771\tKL_Divergence = 2.735001\n",
      "Epoch: 44\tFidelity = 0.504728\tKL_Divergence = 2.740065\n",
      "Epoch: 45\tFidelity = 0.505242\tKL_Divergence = 2.682601\n",
      "Epoch: 46\tFidelity = 0.504564\tKL_Divergence = 2.759711\n",
      "Epoch: 47\tFidelity = 0.504751\tKL_Divergence = 2.737347\n",
      "Epoch: 48\tFidelity = 0.505178\tKL_Divergence = 2.689405\n",
      "Epoch: 49\tFidelity = 0.504491\tKL_Divergence = 2.768680\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:48:18,285] Trial 246 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.504437\tKL_Divergence = 2.775388\n",
      "Total time elapsed during training: 43.481 s\n",
      "Trial 246 pruned. \n",
      "Epoch: 1\tFidelity = 0.504438\tKL_Divergence = 2.775243\n",
      "Epoch: 2\tFidelity = 0.503960\tKL_Divergence = 2.838681\n",
      "Epoch: 3\tFidelity = 0.505263\tKL_Divergence = 2.680346\n",
      "Epoch: 4\tFidelity = 0.504275\tKL_Divergence = 2.796119\n",
      "Epoch: 5\tFidelity = 0.503949\tKL_Divergence = 2.840263\n",
      "Epoch: 6\tFidelity = 0.504695\tKL_Divergence = 2.744010\n",
      "Epoch: 7\tFidelity = 0.504212\tKL_Divergence = 2.804494\n",
      "Epoch: 8\tFidelity = 0.504939\tKL_Divergence = 2.715843\n",
      "Epoch: 9\tFidelity = 0.504184\tKL_Divergence = 2.808174\n",
      "Epoch: 10\tFidelity = 0.504989\tKL_Divergence = 2.710162\n",
      "Epoch: 11\tFidelity = 0.504235\tKL_Divergence = 2.801468\n",
      "Epoch: 12\tFidelity = 0.505470\tKL_Divergence = 2.658927\n",
      "Epoch: 13\tFidelity = 0.503654\tKL_Divergence = 2.883601\n",
      "Epoch: 14\tFidelity = 0.504259\tKL_Divergence = 2.798347\n",
      "Epoch: 15\tFidelity = 0.503799\tKL_Divergence = 2.861874\n",
      "Epoch: 16\tFidelity = 0.505448\tKL_Divergence = 2.661213\n",
      "Epoch: 17\tFidelity = 0.503814\tKL_Divergence = 2.859741\n",
      "Epoch: 18\tFidelity = 0.504458\tKL_Divergence = 2.772934\n",
      "Epoch: 19\tFidelity = 0.504120\tKL_Divergence = 2.816850\n",
      "Epoch: 20\tFidelity = 0.504837\tKL_Divergence = 2.727519\n",
      "Epoch: 21\tFidelity = 0.504338\tKL_Divergence = 2.788162\n",
      "Epoch: 22\tFidelity = 0.504246\tKL_Divergence = 2.800056\n",
      "Epoch: 23\tFidelity = 0.504672\tKL_Divergence = 2.746857\n",
      "Epoch: 24\tFidelity = 0.504705\tKL_Divergence = 2.742951\n",
      "Epoch: 25\tFidelity = 0.504639\tKL_Divergence = 2.750774\n",
      "Epoch: 26\tFidelity = 0.505425\tKL_Divergence = 2.663613\n",
      "Epoch: 27\tFidelity = 0.504314\tKL_Divergence = 2.791240\n",
      "Epoch: 28\tFidelity = 0.504545\tKL_Divergence = 2.762197\n",
      "Epoch: 29\tFidelity = 0.504195\tKL_Divergence = 2.806822\n",
      "Epoch: 30\tFidelity = 0.504887\tKL_Divergence = 2.721777\n",
      "Epoch: 31\tFidelity = 0.504929\tKL_Divergence = 2.717020\n",
      "Epoch: 32\tFidelity = 0.505374\tKL_Divergence = 2.668880\n",
      "Epoch: 33\tFidelity = 0.504055\tKL_Divergence = 2.825681\n",
      "Epoch: 34\tFidelity = 0.504490\tKL_Divergence = 2.769009\n",
      "Epoch: 35\tFidelity = 0.504324\tKL_Divergence = 2.789988\n",
      "Epoch: 36\tFidelity = 0.504921\tKL_Divergence = 2.717959\n",
      "Epoch: 37\tFidelity = 0.504595\tKL_Divergence = 2.756171\n",
      "Epoch: 38\tFidelity = 0.504881\tKL_Divergence = 2.722520\n",
      "Epoch: 39\tFidelity = 0.503820\tKL_Divergence = 2.858974\n",
      "Epoch: 40\tFidelity = 0.503992\tKL_Divergence = 2.834482\n",
      "Epoch: 41\tFidelity = 0.504812\tKL_Divergence = 2.730493\n",
      "Epoch: 42\tFidelity = 0.503926\tKL_Divergence = 2.843752\n",
      "Epoch: 43\tFidelity = 0.504491\tKL_Divergence = 2.768906\n",
      "Epoch: 44\tFidelity = 0.503868\tKL_Divergence = 2.852001\n",
      "Epoch: 45\tFidelity = 0.505099\tKL_Divergence = 2.698145\n",
      "Epoch: 46\tFidelity = 0.503353\tKL_Divergence = 2.931411\n",
      "Epoch: 47\tFidelity = 0.504020\tKL_Divergence = 2.830601\n",
      "Epoch: 48\tFidelity = 0.504983\tKL_Divergence = 2.710997\n",
      "Epoch: 49\tFidelity = 0.503589\tKL_Divergence = 2.893694\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:48:56,119] Trial 247 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.504271\tKL_Divergence = 2.796858\n",
      "Total time elapsed during training: 37.680 s\n",
      "Trial 247 pruned. \n",
      "Epoch: 1\tFidelity = 0.504277\tKL_Divergence = 2.796111\n",
      "Epoch: 2\tFidelity = 0.504071\tKL_Divergence = 2.823547\n",
      "Epoch: 3\tFidelity = 0.504535\tKL_Divergence = 2.763494\n",
      "Epoch: 4\tFidelity = 0.504433\tKL_Divergence = 2.776102\n",
      "Epoch: 5\tFidelity = 0.504548\tKL_Divergence = 2.761904\n",
      "Epoch: 6\tFidelity = 0.504440\tKL_Divergence = 2.775264\n",
      "Epoch: 7\tFidelity = 0.504704\tKL_Divergence = 2.743078\n",
      "Epoch: 8\tFidelity = 0.504245\tKL_Divergence = 2.800283\n",
      "Epoch: 9\tFidelity = 0.504248\tKL_Divergence = 2.799810\n",
      "Epoch: 10\tFidelity = 0.504626\tKL_Divergence = 2.752398\n",
      "Epoch: 11\tFidelity = 0.504584\tKL_Divergence = 2.757525\n",
      "Epoch: 12\tFidelity = 0.504630\tKL_Divergence = 2.751862\n",
      "Epoch: 13\tFidelity = 0.504655\tKL_Divergence = 2.748897\n",
      "Epoch: 14\tFidelity = 0.505051\tKL_Divergence = 2.703453\n",
      "Epoch: 15\tFidelity = 0.504693\tKL_Divergence = 2.744300\n",
      "Epoch: 16\tFidelity = 0.504754\tKL_Divergence = 2.737050\n",
      "Epoch: 17\tFidelity = 0.504676\tKL_Divergence = 2.746376\n",
      "Epoch: 18\tFidelity = 0.504408\tKL_Divergence = 2.779190\n",
      "Epoch: 19\tFidelity = 0.504631\tKL_Divergence = 2.751672\n",
      "Epoch: 20\tFidelity = 0.504952\tKL_Divergence = 2.714360\n",
      "Epoch: 21\tFidelity = 0.505206\tKL_Divergence = 2.686522\n",
      "Epoch: 22\tFidelity = 0.504902\tKL_Divergence = 2.720054\n",
      "Epoch: 23\tFidelity = 0.504476\tKL_Divergence = 2.770701\n",
      "Epoch: 24\tFidelity = 0.504764\tKL_Divergence = 2.735862\n",
      "Epoch: 25\tFidelity = 0.505476\tKL_Divergence = 2.658340\n",
      "Epoch: 26\tFidelity = 0.504772\tKL_Divergence = 2.734970\n",
      "Epoch: 27\tFidelity = 0.504770\tKL_Divergence = 2.735222\n",
      "Epoch: 28\tFidelity = 0.504325\tKL_Divergence = 2.789744\n",
      "Epoch: 29\tFidelity = 0.504730\tKL_Divergence = 2.739883\n",
      "Epoch: 30\tFidelity = 0.504768\tKL_Divergence = 2.735459\n",
      "Epoch: 31\tFidelity = 0.504377\tKL_Divergence = 2.783067\n",
      "Epoch: 32\tFidelity = 0.504835\tKL_Divergence = 2.727697\n",
      "Epoch: 33\tFidelity = 0.505221\tKL_Divergence = 2.684910\n",
      "Epoch: 34\tFidelity = 0.504210\tKL_Divergence = 2.804815\n",
      "Epoch: 35\tFidelity = 0.504202\tKL_Divergence = 2.805811\n",
      "Epoch: 36\tFidelity = 0.505076\tKL_Divergence = 2.700617\n",
      "Epoch: 37\tFidelity = 0.504807\tKL_Divergence = 2.730976\n",
      "Epoch: 38\tFidelity = 0.504286\tKL_Divergence = 2.794809\n",
      "Epoch: 39\tFidelity = 0.504300\tKL_Divergence = 2.792972\n",
      "Epoch: 40\tFidelity = 0.504348\tKL_Divergence = 2.786877\n",
      "Epoch: 41\tFidelity = 0.503987\tKL_Divergence = 2.835121\n",
      "Epoch: 42\tFidelity = 0.504164\tKL_Divergence = 2.810915\n",
      "Epoch: 43\tFidelity = 0.504670\tKL_Divergence = 2.747016\n",
      "Epoch: 44\tFidelity = 0.505092\tKL_Divergence = 2.698891\n",
      "Epoch: 45\tFidelity = 0.504459\tKL_Divergence = 2.772784\n",
      "Epoch: 46\tFidelity = 0.504233\tKL_Divergence = 2.801762\n",
      "Epoch: 47\tFidelity = 0.504602\tKL_Divergence = 2.755227\n",
      "Epoch: 48\tFidelity = 0.504407\tKL_Divergence = 2.779319\n",
      "Epoch: 49\tFidelity = 0.504892\tKL_Divergence = 2.721223\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:49:52,072] Trial 248 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.504350\tKL_Divergence = 2.786536\n",
      "Total time elapsed during training: 55.795 s\n",
      "Trial 248 pruned. \n",
      "Epoch: 1\tFidelity = 0.503897\tKL_Divergence = 2.847814\n",
      "Epoch: 2\tFidelity = 0.504222\tKL_Divergence = 2.803200\n",
      "Epoch: 3\tFidelity = 0.504763\tKL_Divergence = 2.736023\n",
      "Epoch: 4\tFidelity = 0.504382\tKL_Divergence = 2.782452\n",
      "Epoch: 5\tFidelity = 0.504824\tKL_Divergence = 2.728939\n",
      "Epoch: 6\tFidelity = 0.504175\tKL_Divergence = 2.809389\n",
      "Epoch: 7\tFidelity = 0.504547\tKL_Divergence = 2.761905\n",
      "Epoch: 8\tFidelity = 0.504329\tKL_Divergence = 2.789251\n",
      "Epoch: 9\tFidelity = 0.504326\tKL_Divergence = 2.789502\n",
      "Epoch: 10\tFidelity = 0.504973\tKL_Divergence = 2.711902\n",
      "Epoch: 11\tFidelity = 0.504420\tKL_Divergence = 2.777596\n",
      "Epoch: 12\tFidelity = 0.504803\tKL_Divergence = 2.731352\n",
      "Epoch: 13\tFidelity = 0.504797\tKL_Divergence = 2.732014\n",
      "Epoch: 14\tFidelity = 0.504484\tKL_Divergence = 2.769643\n",
      "Epoch: 15\tFidelity = 0.504019\tKL_Divergence = 2.830654\n",
      "Epoch: 16\tFidelity = 0.504501\tKL_Divergence = 2.767514\n",
      "Epoch: 17\tFidelity = 0.504834\tKL_Divergence = 2.727766\n",
      "Epoch: 18\tFidelity = 0.504502\tKL_Divergence = 2.767458\n",
      "Epoch: 19\tFidelity = 0.504893\tKL_Divergence = 2.720979\n",
      "Epoch: 20\tFidelity = 0.503868\tKL_Divergence = 2.851880\n",
      "Epoch: 21\tFidelity = 0.504469\tKL_Divergence = 2.771454\n",
      "Epoch: 22\tFidelity = 0.504412\tKL_Divergence = 2.778604\n",
      "Epoch: 23\tFidelity = 0.504089\tKL_Divergence = 2.821035\n",
      "Epoch: 24\tFidelity = 0.504077\tKL_Divergence = 2.822584\n",
      "Epoch: 25\tFidelity = 0.504653\tKL_Divergence = 2.749028\n",
      "Epoch: 26\tFidelity = 0.504400\tKL_Divergence = 2.780136\n",
      "Epoch: 27\tFidelity = 0.504541\tKL_Divergence = 2.762627\n",
      "Epoch: 28\tFidelity = 0.505045\tKL_Divergence = 2.704027\n",
      "Epoch: 29\tFidelity = 0.504667\tKL_Divergence = 2.747371\n",
      "Epoch: 30\tFidelity = 0.504608\tKL_Divergence = 2.754470\n",
      "Epoch: 31\tFidelity = 0.504668\tKL_Divergence = 2.747232\n",
      "Epoch: 32\tFidelity = 0.504652\tKL_Divergence = 2.749211\n",
      "Epoch: 33\tFidelity = 0.504181\tKL_Divergence = 2.808568\n",
      "Epoch: 34\tFidelity = 0.504046\tKL_Divergence = 2.826858\n",
      "Epoch: 35\tFidelity = 0.504677\tKL_Divergence = 2.746231\n",
      "Epoch: 36\tFidelity = 0.504190\tKL_Divergence = 2.807458\n",
      "Epoch: 37\tFidelity = 0.504444\tKL_Divergence = 2.774612\n",
      "Epoch: 38\tFidelity = 0.504694\tKL_Divergence = 2.744151\n",
      "Epoch: 39\tFidelity = 0.504099\tKL_Divergence = 2.819700\n",
      "Epoch: 40\tFidelity = 0.504645\tKL_Divergence = 2.750033\n",
      "Epoch: 41\tFidelity = 0.504931\tKL_Divergence = 2.716778\n",
      "Epoch: 42\tFidelity = 0.504337\tKL_Divergence = 2.788245\n",
      "Epoch: 43\tFidelity = 0.504475\tKL_Divergence = 2.770825\n",
      "Epoch: 44\tFidelity = 0.504366\tKL_Divergence = 2.784507\n",
      "Epoch: 45\tFidelity = 0.504109\tKL_Divergence = 2.818281\n",
      "Epoch: 46\tFidelity = 0.504386\tKL_Divergence = 2.781934\n",
      "Epoch: 47\tFidelity = 0.504154\tKL_Divergence = 2.812191\n",
      "Epoch: 48\tFidelity = 0.504377\tKL_Divergence = 2.783118\n",
      "Epoch: 49\tFidelity = 0.504291\tKL_Divergence = 2.794169\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:51:09,150] Trial 249 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.504478\tKL_Divergence = 2.770354\n",
      "Total time elapsed during training: 76.927 s\n",
      "Trial 249 pruned. \n",
      "Epoch: 1\tFidelity = 0.504700\tKL_Divergence = 2.743430\n",
      "Epoch: 2\tFidelity = 0.504631\tKL_Divergence = 2.751743\n",
      "Epoch: 3\tFidelity = 0.504918\tKL_Divergence = 2.718249\n",
      "Epoch: 4\tFidelity = 0.504210\tKL_Divergence = 2.804702\n",
      "Epoch: 5\tFidelity = 0.504038\tKL_Divergence = 2.827984\n",
      "Epoch: 6\tFidelity = 0.504245\tKL_Divergence = 2.800189\n",
      "Epoch: 7\tFidelity = 0.504743\tKL_Divergence = 2.738376\n",
      "Epoch: 8\tFidelity = 0.504911\tKL_Divergence = 2.718942\n",
      "Epoch: 9\tFidelity = 0.504855\tKL_Divergence = 2.725434\n",
      "Epoch: 10\tFidelity = 0.503863\tKL_Divergence = 2.852587\n",
      "Epoch: 11\tFidelity = 0.504113\tKL_Divergence = 2.817763\n",
      "Epoch: 12\tFidelity = 0.504710\tKL_Divergence = 2.742268\n",
      "Epoch: 13\tFidelity = 0.505079\tKL_Divergence = 2.700260\n",
      "Epoch: 14\tFidelity = 0.505033\tKL_Divergence = 2.705285\n",
      "Epoch: 15\tFidelity = 0.505097\tKL_Divergence = 2.698288\n",
      "Epoch: 16\tFidelity = 0.505019\tKL_Divergence = 2.706804\n",
      "Epoch: 17\tFidelity = 0.505171\tKL_Divergence = 2.690286\n",
      "Epoch: 18\tFidelity = 0.504408\tKL_Divergence = 2.779176\n",
      "Epoch: 19\tFidelity = 0.504079\tKL_Divergence = 2.822355\n",
      "Epoch: 20\tFidelity = 0.503941\tKL_Divergence = 2.841455\n",
      "Epoch: 21\tFidelity = 0.503793\tKL_Divergence = 2.862685\n",
      "Epoch: 22\tFidelity = 0.504113\tKL_Divergence = 2.817617\n",
      "Epoch: 23\tFidelity = 0.504476\tKL_Divergence = 2.770499\n",
      "Epoch: 24\tFidelity = 0.504590\tKL_Divergence = 2.756389\n",
      "Epoch: 25\tFidelity = 0.504560\tKL_Divergence = 2.760079\n",
      "Epoch: 26\tFidelity = 0.504040\tKL_Divergence = 2.827449\n",
      "Epoch: 27\tFidelity = 0.504390\tKL_Divergence = 2.781348\n",
      "Epoch: 28\tFidelity = 0.504094\tKL_Divergence = 2.820115\n",
      "Epoch: 29\tFidelity = 0.504031\tKL_Divergence = 2.828757\n",
      "Epoch: 30\tFidelity = 0.504388\tKL_Divergence = 2.781570\n",
      "Epoch: 31\tFidelity = 0.504479\tKL_Divergence = 2.770230\n",
      "Epoch: 32\tFidelity = 0.504288\tKL_Divergence = 2.794479\n",
      "Epoch: 33\tFidelity = 0.504499\tKL_Divergence = 2.767748\n",
      "Epoch: 34\tFidelity = 0.504489\tKL_Divergence = 2.768932\n",
      "Epoch: 35\tFidelity = 0.504565\tKL_Divergence = 2.759670\n",
      "Epoch: 36\tFidelity = 0.504351\tKL_Divergence = 2.786375\n",
      "Epoch: 37\tFidelity = 0.504241\tKL_Divergence = 2.800694\n",
      "Epoch: 38\tFidelity = 0.504475\tKL_Divergence = 2.770747\n",
      "Epoch: 39\tFidelity = 0.504520\tKL_Divergence = 2.765102\n",
      "Epoch: 40\tFidelity = 0.505035\tKL_Divergence = 2.705089\n",
      "Epoch: 41\tFidelity = 0.504755\tKL_Divergence = 2.736933\n",
      "Epoch: 42\tFidelity = 0.503731\tKL_Divergence = 2.871975\n",
      "Epoch: 43\tFidelity = 0.504517\tKL_Divergence = 2.765537\n",
      "Epoch: 44\tFidelity = 0.503714\tKL_Divergence = 2.874522\n",
      "Epoch: 45\tFidelity = 0.504959\tKL_Divergence = 2.713550\n",
      "Epoch: 46\tFidelity = 0.505160\tKL_Divergence = 2.691467\n",
      "Epoch: 47\tFidelity = 0.504713\tKL_Divergence = 2.742013\n",
      "Epoch: 48\tFidelity = 0.504156\tKL_Divergence = 2.812002\n",
      "Epoch: 49\tFidelity = 0.504324\tKL_Divergence = 2.789857\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:51:47,090] Trial 250 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.503548\tKL_Divergence = 2.900010\n",
      "Total time elapsed during training: 37.787 s\n",
      "Trial 250 pruned. \n",
      "Epoch: 1\tFidelity = 0.504389\tKL_Divergence = 2.781574\n",
      "Epoch: 2\tFidelity = 0.504299\tKL_Divergence = 2.793043\n",
      "Epoch: 3\tFidelity = 0.503905\tKL_Divergence = 2.846506\n",
      "Epoch: 4\tFidelity = 0.504264\tKL_Divergence = 2.797640\n",
      "Epoch: 5\tFidelity = 0.504013\tKL_Divergence = 2.831490\n",
      "Epoch: 6\tFidelity = 0.504775\tKL_Divergence = 2.734608\n",
      "Epoch: 7\tFidelity = 0.504404\tKL_Divergence = 2.779700\n",
      "Epoch: 8\tFidelity = 0.504156\tKL_Divergence = 2.811985\n",
      "Epoch: 9\tFidelity = 0.504626\tKL_Divergence = 2.752335\n",
      "Epoch: 10\tFidelity = 0.504157\tKL_Divergence = 2.811835\n",
      "Epoch: 11\tFidelity = 0.503867\tKL_Divergence = 2.852157\n",
      "Epoch: 12\tFidelity = 0.504380\tKL_Divergence = 2.782701\n",
      "Epoch: 13\tFidelity = 0.504022\tKL_Divergence = 2.830153\n",
      "Epoch: 14\tFidelity = 0.503891\tKL_Divergence = 2.848524\n",
      "Epoch: 15\tFidelity = 0.504066\tKL_Divergence = 2.824109\n",
      "Epoch: 16\tFidelity = 0.504311\tKL_Divergence = 2.791501\n",
      "Epoch: 17\tFidelity = 0.504688\tKL_Divergence = 2.744918\n",
      "Epoch: 18\tFidelity = 0.504688\tKL_Divergence = 2.744875\n",
      "Epoch: 19\tFidelity = 0.504420\tKL_Divergence = 2.777659\n",
      "Epoch: 20\tFidelity = 0.503911\tKL_Divergence = 2.845593\n",
      "Epoch: 21\tFidelity = 0.504802\tKL_Divergence = 2.731499\n",
      "Epoch: 22\tFidelity = 0.504588\tKL_Divergence = 2.756770\n",
      "Epoch: 23\tFidelity = 0.504184\tKL_Divergence = 2.808160\n",
      "Epoch: 24\tFidelity = 0.505032\tKL_Divergence = 2.705277\n",
      "Epoch: 25\tFidelity = 0.504398\tKL_Divergence = 2.780327\n",
      "Epoch: 26\tFidelity = 0.503874\tKL_Divergence = 2.850958\n",
      "Epoch: 27\tFidelity = 0.503953\tKL_Divergence = 2.839909\n",
      "Epoch: 28\tFidelity = 0.504387\tKL_Divergence = 2.781882\n",
      "Epoch: 29\tFidelity = 0.504125\tKL_Divergence = 2.816113\n",
      "Epoch: 30\tFidelity = 0.504350\tKL_Divergence = 2.786474\n",
      "Epoch: 31\tFidelity = 0.504366\tKL_Divergence = 2.784584\n",
      "Epoch: 32\tFidelity = 0.503936\tKL_Divergence = 2.842252\n",
      "Epoch: 33\tFidelity = 0.504002\tKL_Divergence = 2.833061\n",
      "Epoch: 34\tFidelity = 0.504451\tKL_Divergence = 2.773748\n",
      "Epoch: 35\tFidelity = 0.504593\tKL_Divergence = 2.756382\n",
      "Epoch: 36\tFidelity = 0.504197\tKL_Divergence = 2.806537\n",
      "Epoch: 37\tFidelity = 0.503992\tKL_Divergence = 2.834430\n",
      "Epoch: 38\tFidelity = 0.504014\tKL_Divergence = 2.831395\n",
      "Epoch: 39\tFidelity = 0.504353\tKL_Divergence = 2.786181\n",
      "Epoch: 40\tFidelity = 0.504161\tKL_Divergence = 2.811360\n",
      "Epoch: 41\tFidelity = 0.503674\tKL_Divergence = 2.880595\n",
      "Epoch: 42\tFidelity = 0.504143\tKL_Divergence = 2.813714\n",
      "Epoch: 43\tFidelity = 0.504930\tKL_Divergence = 2.716955\n",
      "Epoch: 44\tFidelity = 0.503826\tKL_Divergence = 2.858124\n",
      "Epoch: 45\tFidelity = 0.504618\tKL_Divergence = 2.753279\n",
      "Epoch: 46\tFidelity = 0.503647\tKL_Divergence = 2.884721\n",
      "Epoch: 47\tFidelity = 0.504105\tKL_Divergence = 2.818829\n",
      "Epoch: 48\tFidelity = 0.504316\tKL_Divergence = 2.790891\n",
      "Epoch: 49\tFidelity = 0.504919\tKL_Divergence = 2.718181\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:52:24,170] Trial 251 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.503876\tKL_Divergence = 2.850661\n",
      "Total time elapsed during training: 36.925 s\n",
      "Trial 251 pruned. \n",
      "Epoch: 1\tFidelity = 0.504173\tKL_Divergence = 2.809664\n",
      "Epoch: 2\tFidelity = 0.504589\tKL_Divergence = 2.756732\n",
      "Epoch: 3\tFidelity = 0.503846\tKL_Divergence = 2.855027\n",
      "Epoch: 4\tFidelity = 0.503733\tKL_Divergence = 2.871686\n",
      "Epoch: 5\tFidelity = 0.504296\tKL_Divergence = 2.793531\n",
      "Epoch: 6\tFidelity = 0.504023\tKL_Divergence = 2.829966\n",
      "Epoch: 7\tFidelity = 0.504384\tKL_Divergence = 2.782186\n",
      "Epoch: 8\tFidelity = 0.504710\tKL_Divergence = 2.742235\n",
      "Epoch: 9\tFidelity = 0.504618\tKL_Divergence = 2.753245\n",
      "Epoch: 10\tFidelity = 0.504080\tKL_Divergence = 2.822163\n",
      "Epoch: 11\tFidelity = 0.503916\tKL_Divergence = 2.845027\n",
      "Epoch: 12\tFidelity = 0.503721\tKL_Divergence = 2.873492\n",
      "Epoch: 13\tFidelity = 0.503963\tKL_Divergence = 2.838490\n",
      "Epoch: 14\tFidelity = 0.503985\tKL_Divergence = 2.835387\n",
      "Epoch: 15\tFidelity = 0.504122\tKL_Divergence = 2.816623\n",
      "Epoch: 16\tFidelity = 0.504199\tKL_Divergence = 2.806216\n",
      "Epoch: 17\tFidelity = 0.503809\tKL_Divergence = 2.860559\n",
      "Epoch: 18\tFidelity = 0.503791\tKL_Divergence = 2.863165\n",
      "Epoch: 19\tFidelity = 0.504230\tKL_Divergence = 2.802177\n",
      "Epoch: 20\tFidelity = 0.504394\tKL_Divergence = 2.781017\n",
      "Epoch: 21\tFidelity = 0.503755\tKL_Divergence = 2.868386\n",
      "Epoch: 22\tFidelity = 0.503775\tKL_Divergence = 2.865463\n",
      "Epoch: 23\tFidelity = 0.504045\tKL_Divergence = 2.827004\n",
      "Epoch: 24\tFidelity = 0.504798\tKL_Divergence = 2.731927\n",
      "Epoch: 25\tFidelity = 0.504383\tKL_Divergence = 2.782337\n",
      "Epoch: 26\tFidelity = 0.503974\tKL_Divergence = 2.836929\n",
      "Epoch: 27\tFidelity = 0.503621\tKL_Divergence = 2.888638\n",
      "Epoch: 28\tFidelity = 0.503828\tKL_Divergence = 2.857675\n",
      "Epoch: 29\tFidelity = 0.504793\tKL_Divergence = 2.732557\n",
      "Epoch: 30\tFidelity = 0.504041\tKL_Divergence = 2.827528\n",
      "Epoch: 31\tFidelity = 0.504273\tKL_Divergence = 2.796540\n",
      "Epoch: 32\tFidelity = 0.504140\tKL_Divergence = 2.814153\n",
      "Epoch: 33\tFidelity = 0.504109\tKL_Divergence = 2.818319\n",
      "Epoch: 34\tFidelity = 0.503788\tKL_Divergence = 2.863472\n",
      "Epoch: 35\tFidelity = 0.504224\tKL_Divergence = 2.802895\n",
      "Epoch: 36\tFidelity = 0.504336\tKL_Divergence = 2.788387\n",
      "Epoch: 37\tFidelity = 0.504172\tKL_Divergence = 2.809841\n",
      "Epoch: 38\tFidelity = 0.504051\tKL_Divergence = 2.826161\n",
      "Epoch: 39\tFidelity = 0.504535\tKL_Divergence = 2.763358\n",
      "Epoch: 40\tFidelity = 0.504095\tKL_Divergence = 2.820121\n",
      "Epoch: 41\tFidelity = 0.504266\tKL_Divergence = 2.797365\n",
      "Epoch: 42\tFidelity = 0.503943\tKL_Divergence = 2.841197\n",
      "Epoch: 43\tFidelity = 0.504044\tKL_Divergence = 2.827095\n",
      "Epoch: 44\tFidelity = 0.504292\tKL_Divergence = 2.794062\n",
      "Epoch: 45\tFidelity = 0.503825\tKL_Divergence = 2.858192\n",
      "Epoch: 46\tFidelity = 0.504005\tKL_Divergence = 2.832492\n",
      "Epoch: 47\tFidelity = 0.503855\tKL_Divergence = 2.853754\n",
      "Epoch: 48\tFidelity = 0.504397\tKL_Divergence = 2.780554\n",
      "Epoch: 49\tFidelity = 0.504032\tKL_Divergence = 2.828746\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:53:07,864] Trial 252 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.504453\tKL_Divergence = 2.773439\n",
      "Total time elapsed during training: 43.543 s\n",
      "Trial 252 pruned. \n",
      "Epoch: 1\tFidelity = 0.504929\tKL_Divergence = 2.716975\n",
      "Epoch: 2\tFidelity = 0.503825\tKL_Divergence = 2.858171\n",
      "Epoch: 3\tFidelity = 0.503579\tKL_Divergence = 2.895147\n",
      "Epoch: 4\tFidelity = 0.504603\tKL_Divergence = 2.755006\n",
      "Epoch: 5\tFidelity = 0.504152\tKL_Divergence = 2.812325\n",
      "Epoch: 6\tFidelity = 0.504232\tKL_Divergence = 2.801717\n",
      "Epoch: 7\tFidelity = 0.503772\tKL_Divergence = 2.865905\n",
      "Epoch: 8\tFidelity = 0.503841\tKL_Divergence = 2.855795\n",
      "Epoch: 9\tFidelity = 0.504715\tKL_Divergence = 2.741664\n",
      "Epoch: 10\tFidelity = 0.503979\tKL_Divergence = 2.836116\n",
      "Epoch: 11\tFidelity = 0.503752\tKL_Divergence = 2.868843\n",
      "Epoch: 12\tFidelity = 0.505094\tKL_Divergence = 2.698611\n",
      "Epoch: 13\tFidelity = 0.503711\tKL_Divergence = 2.875037\n",
      "Epoch: 14\tFidelity = 0.504287\tKL_Divergence = 2.794603\n",
      "Epoch: 15\tFidelity = 0.504861\tKL_Divergence = 2.724685\n",
      "Epoch: 16\tFidelity = 0.505193\tKL_Divergence = 2.687904\n",
      "Epoch: 17\tFidelity = 0.503933\tKL_Divergence = 2.842636\n",
      "Epoch: 18\tFidelity = 0.504265\tKL_Divergence = 2.797527\n",
      "Epoch: 19\tFidelity = 0.503842\tKL_Divergence = 2.855578\n",
      "Epoch: 20\tFidelity = 0.505161\tKL_Divergence = 2.691142\n",
      "Epoch: 21\tFidelity = 0.504067\tKL_Divergence = 2.823879\n",
      "Epoch: 22\tFidelity = 0.504728\tKL_Divergence = 2.740056\n",
      "Epoch: 23\tFidelity = 0.504591\tKL_Divergence = 2.756358\n",
      "Epoch: 24\tFidelity = 0.504120\tKL_Divergence = 2.816634\n",
      "Epoch: 25\tFidelity = 0.504902\tKL_Divergence = 2.719867\n",
      "Epoch: 26\tFidelity = 0.504162\tKL_Divergence = 2.811085\n",
      "Epoch: 27\tFidelity = 0.504515\tKL_Divergence = 2.765734\n",
      "Epoch: 28\tFidelity = 0.503615\tKL_Divergence = 2.889469\n",
      "Epoch: 29\tFidelity = 0.503453\tKL_Divergence = 2.914876\n",
      "Epoch: 30\tFidelity = 0.504171\tKL_Divergence = 2.809850\n",
      "Epoch: 31\tFidelity = 0.504339\tKL_Divergence = 2.787931\n",
      "Epoch: 32\tFidelity = 0.504391\tKL_Divergence = 2.781311\n",
      "Epoch: 33\tFidelity = 0.503730\tKL_Divergence = 2.871999\n",
      "Epoch: 34\tFidelity = 0.504138\tKL_Divergence = 2.814273\n",
      "Epoch: 35\tFidelity = 0.503639\tKL_Divergence = 2.885853\n",
      "Epoch: 36\tFidelity = 0.504372\tKL_Divergence = 2.783627\n",
      "Epoch: 37\tFidelity = 0.505071\tKL_Divergence = 2.701125\n",
      "Epoch: 38\tFidelity = 0.504701\tKL_Divergence = 2.743341\n",
      "Epoch: 39\tFidelity = 0.504156\tKL_Divergence = 2.811963\n",
      "Epoch: 40\tFidelity = 0.503825\tKL_Divergence = 2.858114\n",
      "Epoch: 41\tFidelity = 0.504320\tKL_Divergence = 2.790466\n",
      "Epoch: 42\tFidelity = 0.504491\tKL_Divergence = 2.768771\n",
      "Epoch: 43\tFidelity = 0.504182\tKL_Divergence = 2.808488\n",
      "Epoch: 44\tFidelity = 0.504167\tKL_Divergence = 2.810393\n",
      "Epoch: 45\tFidelity = 0.503996\tKL_Divergence = 2.833748\n",
      "Epoch: 46\tFidelity = 0.504367\tKL_Divergence = 2.784310\n",
      "Epoch: 47\tFidelity = 0.504178\tKL_Divergence = 2.808966\n",
      "Epoch: 48\tFidelity = 0.504233\tKL_Divergence = 2.801615\n",
      "Epoch: 49\tFidelity = 0.505206\tKL_Divergence = 2.686435\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:54:25,320] Trial 253 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.504597\tKL_Divergence = 2.755672\n",
      "Total time elapsed during training: 77.292 s\n",
      "Trial 253 pruned. \n",
      "Epoch: 1\tFidelity = 0.503050\tKL_Divergence = 2.983963\n",
      "Epoch: 2\tFidelity = 0.504453\tKL_Divergence = 2.773371\n",
      "Epoch: 3\tFidelity = 0.503823\tKL_Divergence = 2.858299\n",
      "Epoch: 4\tFidelity = 0.504018\tKL_Divergence = 2.830558\n",
      "Epoch: 5\tFidelity = 0.504852\tKL_Divergence = 2.725562\n",
      "Epoch: 6\tFidelity = 0.505168\tKL_Divergence = 2.690323\n",
      "Epoch: 7\tFidelity = 0.505107\tKL_Divergence = 2.696912\n",
      "Epoch: 8\tFidelity = 0.504381\tKL_Divergence = 2.781867\n",
      "Epoch: 9\tFidelity = 0.505048\tKL_Divergence = 2.702021\n",
      "Epoch: 10\tFidelity = 0.504689\tKL_Divergence = 2.743760\n",
      "Epoch: 11\tFidelity = 0.504416\tKL_Divergence = 2.776592\n",
      "Epoch: 12\tFidelity = 0.504019\tKL_Divergence = 2.829881\n",
      "Epoch: 13\tFidelity = 0.504577\tKL_Divergence = 2.757627\n",
      "Epoch: 14\tFidelity = 0.504829\tKL_Divergence = 2.728069\n",
      "Epoch: 15\tFidelity = 0.504631\tKL_Divergence = 2.751542\n",
      "Epoch: 16\tFidelity = 0.503764\tKL_Divergence = 2.866905\n",
      "Epoch: 17\tFidelity = 0.503644\tKL_Divergence = 2.884961\n",
      "Epoch: 18\tFidelity = 0.504593\tKL_Divergence = 2.756250\n",
      "Epoch: 19\tFidelity = 0.504539\tKL_Divergence = 2.762715\n",
      "Epoch: 20\tFidelity = 0.505267\tKL_Divergence = 2.679434\n",
      "Epoch: 21\tFidelity = 0.503858\tKL_Divergence = 2.852550\n",
      "Epoch: 22\tFidelity = 0.503406\tKL_Divergence = 2.922060\n",
      "Epoch: 23\tFidelity = 0.503986\tKL_Divergence = 2.834730\n",
      "Epoch: 24\tFidelity = 0.503867\tKL_Divergence = 2.851613\n",
      "Epoch: 25\tFidelity = 0.505735\tKL_Divergence = 2.632246\n",
      "Epoch: 26\tFidelity = 0.503766\tKL_Divergence = 2.866794\n",
      "Epoch: 27\tFidelity = 0.504062\tKL_Divergence = 2.824626\n",
      "Epoch: 28\tFidelity = 0.503676\tKL_Divergence = 2.880180\n",
      "Epoch: 29\tFidelity = 0.503591\tKL_Divergence = 2.893213\n",
      "Epoch: 30\tFidelity = 0.504116\tKL_Divergence = 2.817092\n",
      "Epoch: 31\tFidelity = 0.505552\tKL_Divergence = 2.650428\n",
      "Epoch: 32\tFidelity = 0.504175\tKL_Divergence = 2.809367\n",
      "Epoch: 33\tFidelity = 0.505445\tKL_Divergence = 2.661124\n",
      "Epoch: 34\tFidelity = 0.505824\tKL_Divergence = 2.623783\n",
      "Epoch: 35\tFidelity = 0.503975\tKL_Divergence = 2.836461\n",
      "Epoch: 36\tFidelity = 0.504891\tKL_Divergence = 2.720692\n",
      "Epoch: 37\tFidelity = 0.503732\tKL_Divergence = 2.871067\n",
      "Epoch: 38\tFidelity = 0.504919\tKL_Divergence = 2.717138\n",
      "Epoch: 39\tFidelity = 0.503558\tKL_Divergence = 2.897424\n",
      "Epoch: 40\tFidelity = 0.503678\tKL_Divergence = 2.879569\n",
      "Epoch: 41\tFidelity = 0.504425\tKL_Divergence = 2.776851\n",
      "Epoch: 42\tFidelity = 0.505226\tKL_Divergence = 2.684271\n",
      "Epoch: 43\tFidelity = 0.505598\tKL_Divergence = 2.645443\n",
      "Epoch: 44\tFidelity = 0.504375\tKL_Divergence = 2.783056\n",
      "Epoch: 45\tFidelity = 0.505639\tKL_Divergence = 2.641904\n",
      "Epoch: 46\tFidelity = 0.504437\tKL_Divergence = 2.775437\n",
      "Epoch: 47\tFidelity = 0.504966\tKL_Divergence = 2.712512\n",
      "Epoch: 48\tFidelity = 0.503877\tKL_Divergence = 2.850051\n",
      "Epoch: 49\tFidelity = 0.503423\tKL_Divergence = 2.919442\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:55:02,851] Trial 254 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.503116\tKL_Divergence = 2.971996\n",
      "Total time elapsed during training: 37.359 s\n",
      "Trial 254 pruned. \n",
      "Epoch: 1\tFidelity = 0.503481\tKL_Divergence = 2.910313\n",
      "Epoch: 2\tFidelity = 0.503839\tKL_Divergence = 2.855870\n",
      "Epoch: 3\tFidelity = 0.504051\tKL_Divergence = 2.825999\n",
      "Epoch: 4\tFidelity = 0.504281\tKL_Divergence = 2.795278\n",
      "Epoch: 5\tFidelity = 0.504278\tKL_Divergence = 2.795667\n",
      "Epoch: 6\tFidelity = 0.504400\tKL_Divergence = 2.779938\n",
      "Epoch: 7\tFidelity = 0.504373\tKL_Divergence = 2.783337\n",
      "Epoch: 8\tFidelity = 0.504458\tKL_Divergence = 2.772680\n",
      "Epoch: 9\tFidelity = 0.504512\tKL_Divergence = 2.766001\n",
      "Epoch: 10\tFidelity = 0.504449\tKL_Divergence = 2.773742\n",
      "Epoch: 11\tFidelity = 0.504484\tKL_Divergence = 2.769424\n",
      "Epoch: 12\tFidelity = 0.504386\tKL_Divergence = 2.781735\n",
      "Epoch: 13\tFidelity = 0.504468\tKL_Divergence = 2.771422\n",
      "Epoch: 14\tFidelity = 0.504571\tKL_Divergence = 2.758776\n",
      "Epoch: 15\tFidelity = 0.504624\tKL_Divergence = 2.752355\n",
      "Epoch: 16\tFidelity = 0.504664\tKL_Divergence = 2.747554\n",
      "Epoch: 17\tFidelity = 0.504529\tKL_Divergence = 2.763866\n",
      "Epoch: 18\tFidelity = 0.504600\tKL_Divergence = 2.755199\n",
      "Epoch: 19\tFidelity = 0.504563\tKL_Divergence = 2.759709\n",
      "Epoch: 20\tFidelity = 0.504572\tKL_Divergence = 2.758554\n",
      "Epoch: 21\tFidelity = 0.504541\tKL_Divergence = 2.762344\n",
      "Epoch: 22\tFidelity = 0.504373\tKL_Divergence = 2.783393\n",
      "Epoch: 23\tFidelity = 0.504632\tKL_Divergence = 2.751337\n",
      "Epoch: 24\tFidelity = 0.504566\tKL_Divergence = 2.759353\n",
      "Epoch: 25\tFidelity = 0.504528\tKL_Divergence = 2.764022\n",
      "Epoch: 26\tFidelity = 0.504629\tKL_Divergence = 2.751721\n",
      "Epoch: 27\tFidelity = 0.504698\tKL_Divergence = 2.743502\n",
      "Epoch: 28\tFidelity = 0.504693\tKL_Divergence = 2.744077\n",
      "Epoch: 29\tFidelity = 0.504585\tKL_Divergence = 2.757045\n",
      "Epoch: 30\tFidelity = 0.504344\tKL_Divergence = 2.787085\n",
      "Epoch: 31\tFidelity = 0.504612\tKL_Divergence = 2.753703\n",
      "Epoch: 32\tFidelity = 0.504548\tKL_Divergence = 2.761475\n",
      "Epoch: 33\tFidelity = 0.504559\tKL_Divergence = 2.760151\n",
      "Epoch: 34\tFidelity = 0.504477\tKL_Divergence = 2.770356\n",
      "Epoch: 35\tFidelity = 0.504630\tKL_Divergence = 2.751594\n",
      "Epoch: 36\tFidelity = 0.504625\tKL_Divergence = 2.752185\n",
      "Epoch: 37\tFidelity = 0.504733\tKL_Divergence = 2.739397\n",
      "Epoch: 38\tFidelity = 0.504592\tKL_Divergence = 2.756207\n",
      "Epoch: 39\tFidelity = 0.504280\tKL_Divergence = 2.795338\n",
      "Epoch: 40\tFidelity = 0.504495\tKL_Divergence = 2.768065\n",
      "Epoch: 41\tFidelity = 0.504475\tKL_Divergence = 2.770611\n",
      "Epoch: 42\tFidelity = 0.504105\tKL_Divergence = 2.818535\n",
      "Epoch: 43\tFidelity = 0.504388\tKL_Divergence = 2.781463\n",
      "Epoch: 44\tFidelity = 0.504815\tKL_Divergence = 2.729791\n",
      "Epoch: 45\tFidelity = 0.504479\tKL_Divergence = 2.770113\n",
      "Epoch: 46\tFidelity = 0.504561\tKL_Divergence = 2.759991\n",
      "Epoch: 47\tFidelity = 0.504187\tKL_Divergence = 2.807652\n",
      "Epoch: 48\tFidelity = 0.504661\tKL_Divergence = 2.747952\n",
      "Epoch: 49\tFidelity = 0.504525\tKL_Divergence = 2.764347\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:55:34,122] Trial 255 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.504439\tKL_Divergence = 2.775089\n",
      "Total time elapsed during training: 31.118 s\n",
      "Trial 255 pruned. \n",
      "Epoch: 1\tFidelity = 0.504308\tKL_Divergence = 2.791748\n",
      "Epoch: 2\tFidelity = 0.503713\tKL_Divergence = 2.874507\n",
      "Epoch: 3\tFidelity = 0.504847\tKL_Divergence = 2.726105\n",
      "Epoch: 4\tFidelity = 0.504098\tKL_Divergence = 2.819551\n",
      "Epoch: 5\tFidelity = 0.505052\tKL_Divergence = 2.703044\n",
      "Epoch: 6\tFidelity = 0.503929\tKL_Divergence = 2.843093\n",
      "Epoch: 7\tFidelity = 0.504475\tKL_Divergence = 2.770533\n",
      "Epoch: 8\tFidelity = 0.504265\tKL_Divergence = 2.797405\n",
      "Epoch: 9\tFidelity = 0.504916\tKL_Divergence = 2.718318\n",
      "Epoch: 10\tFidelity = 0.503982\tKL_Divergence = 2.835582\n",
      "Epoch: 11\tFidelity = 0.505064\tKL_Divergence = 2.701743\n",
      "Epoch: 12\tFidelity = 0.504017\tKL_Divergence = 2.830746\n",
      "Epoch: 13\tFidelity = 0.505390\tKL_Divergence = 2.667022\n",
      "Epoch: 14\tFidelity = 0.503831\tKL_Divergence = 2.857025\n",
      "Epoch: 15\tFidelity = 0.505389\tKL_Divergence = 2.667042\n",
      "Epoch: 16\tFidelity = 0.504071\tKL_Divergence = 2.823259\n",
      "Epoch: 17\tFidelity = 0.505176\tKL_Divergence = 2.689519\n",
      "Epoch: 18\tFidelity = 0.503784\tKL_Divergence = 2.863973\n",
      "Epoch: 19\tFidelity = 0.505265\tKL_Divergence = 2.680109\n",
      "Epoch: 20\tFidelity = 0.504058\tKL_Divergence = 2.825008\n",
      "Epoch: 21\tFidelity = 0.504625\tKL_Divergence = 2.752245\n",
      "Epoch: 22\tFidelity = 0.504004\tKL_Divergence = 2.832446\n",
      "Epoch: 23\tFidelity = 0.505518\tKL_Divergence = 2.653956\n",
      "Epoch: 24\tFidelity = 0.503712\tKL_Divergence = 2.874735\n",
      "Epoch: 25\tFidelity = 0.504905\tKL_Divergence = 2.719523\n",
      "Epoch: 26\tFidelity = 0.504195\tKL_Divergence = 2.806606\n",
      "Epoch: 27\tFidelity = 0.504917\tKL_Divergence = 2.718223\n",
      "Epoch: 28\tFidelity = 0.504053\tKL_Divergence = 2.825735\n",
      "Epoch: 29\tFidelity = 0.504471\tKL_Divergence = 2.771180\n",
      "Epoch: 30\tFidelity = 0.503686\tKL_Divergence = 2.878559\n",
      "Epoch: 31\tFidelity = 0.505589\tKL_Divergence = 2.646779\n",
      "Epoch: 32\tFidelity = 0.503571\tKL_Divergence = 2.896161\n",
      "Epoch: 33\tFidelity = 0.505615\tKL_Divergence = 2.644204\n",
      "Epoch: 34\tFidelity = 0.503727\tKL_Divergence = 2.872482\n",
      "Epoch: 35\tFidelity = 0.505569\tKL_Divergence = 2.648777\n",
      "Epoch: 36\tFidelity = 0.503507\tKL_Divergence = 2.906284\n",
      "Epoch: 37\tFidelity = 0.505700\tKL_Divergence = 2.635856\n",
      "Epoch: 38\tFidelity = 0.503538\tKL_Divergence = 2.901402\n",
      "Epoch: 39\tFidelity = 0.505626\tKL_Divergence = 2.643123\n",
      "Epoch: 40\tFidelity = 0.503442\tKL_Divergence = 2.916776\n",
      "Epoch: 41\tFidelity = 0.505469\tKL_Divergence = 2.658939\n",
      "Epoch: 42\tFidelity = 0.503693\tKL_Divergence = 2.877487\n",
      "Epoch: 43\tFidelity = 0.505879\tKL_Divergence = 2.618618\n",
      "Epoch: 44\tFidelity = 0.503502\tKL_Divergence = 2.907105\n",
      "Epoch: 45\tFidelity = 0.505160\tKL_Divergence = 2.691290\n",
      "Epoch: 46\tFidelity = 0.503644\tKL_Divergence = 2.885035\n",
      "Epoch: 47\tFidelity = 0.505526\tKL_Divergence = 2.653065\n",
      "Epoch: 48\tFidelity = 0.503905\tKL_Divergence = 2.846394\n",
      "Epoch: 49\tFidelity = 0.505568\tKL_Divergence = 2.648918\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:56:05,151] Trial 256 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.503530\tKL_Divergence = 2.902594\n",
      "Total time elapsed during training: 30.879 s\n",
      "Trial 256 pruned. \n",
      "Epoch: 1\tFidelity = 0.504243\tKL_Divergence = 2.800211\n",
      "Epoch: 2\tFidelity = 0.504165\tKL_Divergence = 2.810590\n",
      "Epoch: 3\tFidelity = 0.504576\tKL_Divergence = 2.758221\n",
      "Epoch: 4\tFidelity = 0.504219\tKL_Divergence = 2.803448\n",
      "Epoch: 5\tFidelity = 0.504612\tKL_Divergence = 2.753871\n",
      "Epoch: 6\tFidelity = 0.504423\tKL_Divergence = 2.777153\n",
      "Epoch: 7\tFidelity = 0.504249\tKL_Divergence = 2.799415\n",
      "Epoch: 8\tFidelity = 0.504478\tKL_Divergence = 2.770235\n",
      "Epoch: 9\tFidelity = 0.504682\tKL_Divergence = 2.745387\n",
      "Epoch: 10\tFidelity = 0.504328\tKL_Divergence = 2.789202\n",
      "Epoch: 11\tFidelity = 0.504664\tKL_Divergence = 2.747555\n",
      "Epoch: 12\tFidelity = 0.504870\tKL_Divergence = 2.723503\n",
      "Epoch: 13\tFidelity = 0.504426\tKL_Divergence = 2.776751\n",
      "Epoch: 14\tFidelity = 0.504232\tKL_Divergence = 2.801648\n",
      "Epoch: 15\tFidelity = 0.504622\tKL_Divergence = 2.752579\n",
      "Epoch: 16\tFidelity = 0.504674\tKL_Divergence = 2.746340\n",
      "Epoch: 17\tFidelity = 0.504442\tKL_Divergence = 2.774688\n",
      "Epoch: 18\tFidelity = 0.504233\tKL_Divergence = 2.801503\n",
      "Epoch: 19\tFidelity = 0.504462\tKL_Divergence = 2.772107\n",
      "Epoch: 20\tFidelity = 0.504415\tKL_Divergence = 2.778043\n",
      "Epoch: 21\tFidelity = 0.504453\tKL_Divergence = 2.773284\n",
      "Epoch: 22\tFidelity = 0.504623\tKL_Divergence = 2.752394\n",
      "Epoch: 23\tFidelity = 0.504936\tKL_Divergence = 2.715874\n",
      "Epoch: 24\tFidelity = 0.504296\tKL_Divergence = 2.793321\n",
      "Epoch: 25\tFidelity = 0.504559\tKL_Divergence = 2.760120\n",
      "Epoch: 26\tFidelity = 0.504560\tKL_Divergence = 2.760041\n",
      "Epoch: 27\tFidelity = 0.504776\tKL_Divergence = 2.734298\n",
      "Epoch: 28\tFidelity = 0.504148\tKL_Divergence = 2.812790\n",
      "Epoch: 29\tFidelity = 0.504288\tKL_Divergence = 2.794328\n",
      "Epoch: 30\tFidelity = 0.504341\tKL_Divergence = 2.787394\n",
      "Epoch: 31\tFidelity = 0.504352\tKL_Divergence = 2.786051\n",
      "Epoch: 32\tFidelity = 0.504456\tKL_Divergence = 2.772886\n",
      "Epoch: 33\tFidelity = 0.504647\tKL_Divergence = 2.749569\n",
      "Epoch: 34\tFidelity = 0.504724\tKL_Divergence = 2.740374\n",
      "Epoch: 35\tFidelity = 0.504288\tKL_Divergence = 2.794209\n",
      "Epoch: 36\tFidelity = 0.504634\tKL_Divergence = 2.751077\n",
      "Epoch: 37\tFidelity = 0.504797\tKL_Divergence = 2.731847\n",
      "Epoch: 38\tFidelity = 0.504260\tKL_Divergence = 2.797967\n",
      "Epoch: 39\tFidelity = 0.504303\tKL_Divergence = 2.792375\n",
      "Epoch: 40\tFidelity = 0.504508\tKL_Divergence = 2.766408\n",
      "Epoch: 41\tFidelity = 0.504579\tKL_Divergence = 2.757658\n",
      "Epoch: 42\tFidelity = 0.504392\tKL_Divergence = 2.781020\n",
      "Epoch: 43\tFidelity = 0.504515\tKL_Divergence = 2.765549\n",
      "Epoch: 44\tFidelity = 0.504096\tKL_Divergence = 2.819730\n",
      "Epoch: 45\tFidelity = 0.504276\tKL_Divergence = 2.795832\n",
      "Epoch: 46\tFidelity = 0.504483\tKL_Divergence = 2.769566\n",
      "Epoch: 47\tFidelity = 0.504324\tKL_Divergence = 2.789666\n",
      "Epoch: 48\tFidelity = 0.504141\tKL_Divergence = 2.813783\n",
      "Epoch: 49\tFidelity = 0.504030\tKL_Divergence = 2.828811\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:56:42,337] Trial 257 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.504262\tKL_Divergence = 2.797662\n",
      "Total time elapsed during training: 37.029 s\n",
      "Trial 257 pruned. \n",
      "Epoch: 1\tFidelity = 0.503923\tKL_Divergence = 2.843809\n",
      "Epoch: 2\tFidelity = 0.504787\tKL_Divergence = 2.732958\n",
      "Epoch: 3\tFidelity = 0.504567\tKL_Divergence = 2.759176\n",
      "Epoch: 4\tFidelity = 0.504820\tKL_Divergence = 2.729099\n",
      "Epoch: 5\tFidelity = 0.504137\tKL_Divergence = 2.814164\n",
      "Epoch: 6\tFidelity = 0.504963\tKL_Divergence = 2.712885\n",
      "Epoch: 7\tFidelity = 0.504269\tKL_Divergence = 2.796727\n",
      "Epoch: 8\tFidelity = 0.504574\tKL_Divergence = 2.758325\n",
      "Epoch: 9\tFidelity = 0.504690\tKL_Divergence = 2.744363\n",
      "Epoch: 10\tFidelity = 0.504433\tKL_Divergence = 2.775674\n",
      "Epoch: 11\tFidelity = 0.504447\tKL_Divergence = 2.774105\n",
      "Epoch: 12\tFidelity = 0.504792\tKL_Divergence = 2.732425\n",
      "Epoch: 13\tFidelity = 0.504813\tKL_Divergence = 2.729965\n",
      "Epoch: 14\tFidelity = 0.505112\tKL_Divergence = 2.696403\n",
      "Epoch: 15\tFidelity = 0.504591\tKL_Divergence = 2.756408\n",
      "Epoch: 16\tFidelity = 0.504218\tKL_Divergence = 2.803560\n",
      "Epoch: 17\tFidelity = 0.504281\tKL_Divergence = 2.795368\n",
      "Epoch: 18\tFidelity = 0.504015\tKL_Divergence = 2.831014\n",
      "Epoch: 19\tFidelity = 0.504392\tKL_Divergence = 2.781092\n",
      "Epoch: 20\tFidelity = 0.504204\tKL_Divergence = 2.805390\n",
      "Epoch: 21\tFidelity = 0.503832\tKL_Divergence = 2.856902\n",
      "Epoch: 22\tFidelity = 0.504944\tKL_Divergence = 2.715004\n",
      "Epoch: 23\tFidelity = 0.504903\tKL_Divergence = 2.719707\n",
      "Epoch: 24\tFidelity = 0.504296\tKL_Divergence = 2.793320\n",
      "Epoch: 25\tFidelity = 0.504720\tKL_Divergence = 2.740908\n",
      "Epoch: 26\tFidelity = 0.503972\tKL_Divergence = 2.837085\n",
      "Epoch: 27\tFidelity = 0.504735\tKL_Divergence = 2.739237\n",
      "Epoch: 28\tFidelity = 0.504047\tKL_Divergence = 2.826624\n",
      "Epoch: 29\tFidelity = 0.504677\tKL_Divergence = 2.746112\n",
      "Epoch: 30\tFidelity = 0.503879\tKL_Divergence = 2.850254\n",
      "Epoch: 31\tFidelity = 0.504364\tKL_Divergence = 2.784709\n",
      "Epoch: 32\tFidelity = 0.504221\tKL_Divergence = 2.803215\n",
      "Epoch: 33\tFidelity = 0.503840\tKL_Divergence = 2.855882\n",
      "Epoch: 34\tFidelity = 0.504062\tKL_Divergence = 2.824644\n",
      "Epoch: 35\tFidelity = 0.504754\tKL_Divergence = 2.737095\n",
      "Epoch: 36\tFidelity = 0.503628\tKL_Divergence = 2.887555\n",
      "Epoch: 37\tFidelity = 0.503962\tKL_Divergence = 2.838537\n",
      "Epoch: 38\tFidelity = 0.504157\tKL_Divergence = 2.811614\n",
      "Epoch: 39\tFidelity = 0.504714\tKL_Divergence = 2.741795\n",
      "Epoch: 40\tFidelity = 0.503565\tKL_Divergence = 2.897224\n",
      "Epoch: 41\tFidelity = 0.503646\tKL_Divergence = 2.884618\n",
      "Epoch: 42\tFidelity = 0.503448\tKL_Divergence = 2.915672\n",
      "Epoch: 43\tFidelity = 0.504799\tKL_Divergence = 2.731703\n",
      "Epoch: 44\tFidelity = 0.503984\tKL_Divergence = 2.835272\n",
      "Epoch: 45\tFidelity = 0.504694\tKL_Divergence = 2.743961\n",
      "Epoch: 46\tFidelity = 0.505369\tKL_Divergence = 2.669074\n",
      "Epoch: 47\tFidelity = 0.504599\tKL_Divergence = 2.755503\n",
      "Epoch: 48\tFidelity = 0.504598\tKL_Divergence = 2.755615\n",
      "Epoch: 49\tFidelity = 0.504539\tKL_Divergence = 2.762775\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:57:25,656] Trial 258 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.503663\tKL_Divergence = 2.882190\n",
      "Total time elapsed during training: 43.172 s\n",
      "Trial 258 pruned. \n",
      "Epoch: 1\tFidelity = 0.504516\tKL_Divergence = 2.765675\n",
      "Epoch: 2\tFidelity = 0.504448\tKL_Divergence = 2.774070\n",
      "Epoch: 3\tFidelity = 0.504320\tKL_Divergence = 2.790384\n",
      "Epoch: 4\tFidelity = 0.504393\tKL_Divergence = 2.780981\n",
      "Epoch: 5\tFidelity = 0.504507\tKL_Divergence = 2.766719\n",
      "Epoch: 6\tFidelity = 0.504032\tKL_Divergence = 2.828745\n",
      "Epoch: 7\tFidelity = 0.504515\tKL_Divergence = 2.765757\n",
      "Epoch: 8\tFidelity = 0.504233\tKL_Divergence = 2.801703\n",
      "Epoch: 9\tFidelity = 0.503818\tKL_Divergence = 2.859113\n",
      "Epoch: 10\tFidelity = 0.504344\tKL_Divergence = 2.787319\n",
      "Epoch: 11\tFidelity = 0.504165\tKL_Divergence = 2.810708\n",
      "Epoch: 12\tFidelity = 0.504364\tKL_Divergence = 2.784757\n",
      "Epoch: 13\tFidelity = 0.503987\tKL_Divergence = 2.835075\n",
      "Epoch: 14\tFidelity = 0.503885\tKL_Divergence = 2.849490\n",
      "Epoch: 15\tFidelity = 0.504466\tKL_Divergence = 2.771852\n",
      "Epoch: 16\tFidelity = 0.504473\tKL_Divergence = 2.771034\n",
      "Epoch: 17\tFidelity = 0.504002\tKL_Divergence = 2.832902\n",
      "Epoch: 18\tFidelity = 0.504018\tKL_Divergence = 2.830670\n",
      "Epoch: 19\tFidelity = 0.503963\tKL_Divergence = 2.838344\n",
      "Epoch: 20\tFidelity = 0.504320\tKL_Divergence = 2.790342\n",
      "Epoch: 21\tFidelity = 0.504613\tKL_Divergence = 2.753803\n",
      "Epoch: 22\tFidelity = 0.504101\tKL_Divergence = 2.819329\n",
      "Epoch: 23\tFidelity = 0.504346\tKL_Divergence = 2.787093\n",
      "Epoch: 24\tFidelity = 0.504514\tKL_Divergence = 2.765976\n",
      "Epoch: 25\tFidelity = 0.504087\tKL_Divergence = 2.821271\n",
      "Epoch: 26\tFidelity = 0.504087\tKL_Divergence = 2.821196\n",
      "Epoch: 27\tFidelity = 0.503871\tKL_Divergence = 2.851508\n",
      "Epoch: 28\tFidelity = 0.503759\tKL_Divergence = 2.867787\n",
      "Epoch: 29\tFidelity = 0.504345\tKL_Divergence = 2.787108\n",
      "Epoch: 30\tFidelity = 0.504293\tKL_Divergence = 2.793845\n",
      "Epoch: 31\tFidelity = 0.504360\tKL_Divergence = 2.785186\n",
      "Epoch: 32\tFidelity = 0.504291\tKL_Divergence = 2.794115\n",
      "Epoch: 33\tFidelity = 0.504033\tKL_Divergence = 2.828699\n",
      "Epoch: 34\tFidelity = 0.504464\tKL_Divergence = 2.772112\n",
      "Epoch: 35\tFidelity = 0.504008\tKL_Divergence = 2.832148\n",
      "Epoch: 36\tFidelity = 0.504284\tKL_Divergence = 2.795011\n",
      "Epoch: 37\tFidelity = 0.503953\tKL_Divergence = 2.839744\n",
      "Epoch: 38\tFidelity = 0.504248\tKL_Divergence = 2.799801\n",
      "Epoch: 39\tFidelity = 0.503931\tKL_Divergence = 2.842899\n",
      "Epoch: 40\tFidelity = 0.503819\tKL_Divergence = 2.858941\n",
      "Epoch: 41\tFidelity = 0.504157\tKL_Divergence = 2.811723\n",
      "Epoch: 42\tFidelity = 0.503905\tKL_Divergence = 2.846571\n",
      "Epoch: 43\tFidelity = 0.504385\tKL_Divergence = 2.782031\n",
      "Epoch: 44\tFidelity = 0.503569\tKL_Divergence = 2.896670\n",
      "Epoch: 45\tFidelity = 0.504110\tKL_Divergence = 2.818040\n",
      "Epoch: 46\tFidelity = 0.504041\tKL_Divergence = 2.827437\n",
      "Epoch: 47\tFidelity = 0.504127\tKL_Divergence = 2.815818\n",
      "Epoch: 48\tFidelity = 0.503823\tKL_Divergence = 2.858421\n",
      "Epoch: 49\tFidelity = 0.503707\tKL_Divergence = 2.875462\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:58:03,138] Trial 259 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.504405\tKL_Divergence = 2.779524\n",
      "Total time elapsed during training: 37.321 s\n",
      "Trial 259 pruned. \n",
      "Epoch: 1\tFidelity = 0.504702\tKL_Divergence = 2.743100\n",
      "Epoch: 2\tFidelity = 0.504378\tKL_Divergence = 2.782799\n",
      "Epoch: 3\tFidelity = 0.504121\tKL_Divergence = 2.816563\n",
      "Epoch: 4\tFidelity = 0.504369\tKL_Divergence = 2.783901\n",
      "Epoch: 5\tFidelity = 0.504032\tKL_Divergence = 2.828746\n",
      "Epoch: 6\tFidelity = 0.504087\tKL_Divergence = 2.821235\n",
      "Epoch: 7\tFidelity = 0.502972\tKL_Divergence = 2.998414\n",
      "Epoch: 8\tFidelity = 0.503688\tKL_Divergence = 2.878504\n",
      "Epoch: 9\tFidelity = 0.503416\tKL_Divergence = 2.921105\n",
      "Epoch: 10\tFidelity = 0.505326\tKL_Divergence = 2.673694\n",
      "Epoch: 11\tFidelity = 0.503162\tKL_Divergence = 2.964021\n",
      "Epoch: 12\tFidelity = 0.504417\tKL_Divergence = 2.778092\n",
      "Epoch: 13\tFidelity = 0.503088\tKL_Divergence = 2.977072\n",
      "Epoch: 14\tFidelity = 0.504031\tKL_Divergence = 2.828803\n",
      "Epoch: 15\tFidelity = 0.503415\tKL_Divergence = 2.921127\n",
      "Epoch: 16\tFidelity = 0.503869\tKL_Divergence = 2.851705\n",
      "Epoch: 17\tFidelity = 0.503848\tKL_Divergence = 2.854732\n",
      "Epoch: 18\tFidelity = 0.504683\tKL_Divergence = 2.745488\n",
      "Epoch: 19\tFidelity = 0.504756\tKL_Divergence = 2.736808\n",
      "Epoch: 20\tFidelity = 0.504027\tKL_Divergence = 2.829507\n",
      "Epoch: 21\tFidelity = 0.504320\tKL_Divergence = 2.790383\n",
      "Epoch: 22\tFidelity = 0.503785\tKL_Divergence = 2.863752\n",
      "Epoch: 23\tFidelity = 0.504308\tKL_Divergence = 2.792009\n",
      "Epoch: 24\tFidelity = 0.504080\tKL_Divergence = 2.822227\n",
      "Epoch: 25\tFidelity = 0.503998\tKL_Divergence = 2.833378\n",
      "Epoch: 26\tFidelity = 0.503575\tKL_Divergence = 2.895658\n",
      "Epoch: 27\tFidelity = 0.503002\tKL_Divergence = 2.992897\n",
      "Epoch: 28\tFidelity = 0.504314\tKL_Divergence = 2.791258\n",
      "Epoch: 29\tFidelity = 0.503613\tKL_Divergence = 2.890011\n",
      "Epoch: 30\tFidelity = 0.503931\tKL_Divergence = 2.843027\n",
      "Epoch: 31\tFidelity = 0.503438\tKL_Divergence = 2.917368\n",
      "Epoch: 32\tFidelity = 0.504415\tKL_Divergence = 2.778221\n",
      "Epoch: 33\tFidelity = 0.504412\tKL_Divergence = 2.778474\n",
      "Epoch: 34\tFidelity = 0.505512\tKL_Divergence = 2.654666\n",
      "Epoch: 35\tFidelity = 0.504646\tKL_Divergence = 2.749738\n",
      "Epoch: 36\tFidelity = 0.503767\tKL_Divergence = 2.866729\n",
      "Epoch: 37\tFidelity = 0.503734\tKL_Divergence = 2.871576\n",
      "Epoch: 38\tFidelity = 0.504070\tKL_Divergence = 2.823575\n",
      "Epoch: 39\tFidelity = 0.504766\tKL_Divergence = 2.735637\n",
      "Epoch: 40\tFidelity = 0.503423\tKL_Divergence = 2.919942\n",
      "Epoch: 41\tFidelity = 0.503504\tKL_Divergence = 2.906917\n",
      "Epoch: 42\tFidelity = 0.503472\tKL_Divergence = 2.912020\n",
      "Epoch: 43\tFidelity = 0.504715\tKL_Divergence = 2.741731\n",
      "Epoch: 44\tFidelity = 0.503888\tKL_Divergence = 2.849055\n",
      "Epoch: 45\tFidelity = 0.504677\tKL_Divergence = 2.746206\n",
      "Epoch: 46\tFidelity = 0.503853\tKL_Divergence = 2.853960\n",
      "Epoch: 47\tFidelity = 0.503343\tKL_Divergence = 2.932908\n",
      "Epoch: 48\tFidelity = 0.503999\tKL_Divergence = 2.833203\n",
      "Epoch: 49\tFidelity = 0.503310\tKL_Divergence = 2.938534\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:59:21,313] Trial 260 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.504873\tKL_Divergence = 2.723263\n",
      "Total time elapsed during training: 78.015 s\n",
      "Trial 260 pruned. \n",
      "Epoch: 1\tFidelity = 0.503566\tKL_Divergence = 2.896821\n",
      "Epoch: 2\tFidelity = 0.503831\tKL_Divergence = 2.856697\n",
      "Epoch: 3\tFidelity = 0.503895\tKL_Divergence = 2.847376\n",
      "Epoch: 4\tFidelity = 0.504056\tKL_Divergence = 2.825164\n",
      "Epoch: 5\tFidelity = 0.503537\tKL_Divergence = 2.901383\n",
      "Epoch: 6\tFidelity = 0.504466\tKL_Divergence = 2.771503\n",
      "Epoch: 7\tFidelity = 0.504374\tKL_Divergence = 2.783305\n",
      "Epoch: 8\tFidelity = 0.504226\tKL_Divergence = 2.802566\n",
      "Epoch: 9\tFidelity = 0.504442\tKL_Divergence = 2.774782\n",
      "Epoch: 10\tFidelity = 0.504500\tKL_Divergence = 2.767469\n",
      "Epoch: 11\tFidelity = 0.504282\tKL_Divergence = 2.794699\n",
      "Epoch: 12\tFidelity = 0.503838\tKL_Divergence = 2.855819\n",
      "Epoch: 13\tFidelity = 0.504325\tKL_Divergence = 2.789359\n",
      "Epoch: 14\tFidelity = 0.504592\tKL_Divergence = 2.756214\n",
      "Epoch: 15\tFidelity = 0.504307\tKL_Divergence = 2.791924\n",
      "Epoch: 16\tFidelity = 0.503974\tKL_Divergence = 2.836725\n",
      "Epoch: 17\tFidelity = 0.504184\tKL_Divergence = 2.808175\n",
      "Epoch: 18\tFidelity = 0.504176\tKL_Divergence = 2.809202\n",
      "Epoch: 19\tFidelity = 0.504039\tKL_Divergence = 2.827635\n",
      "Epoch: 20\tFidelity = 0.504165\tKL_Divergence = 2.810443\n",
      "Epoch: 21\tFidelity = 0.504157\tKL_Divergence = 2.811658\n",
      "Epoch: 22\tFidelity = 0.504023\tKL_Divergence = 2.830021\n",
      "Epoch: 23\tFidelity = 0.504846\tKL_Divergence = 2.726333\n",
      "Epoch: 24\tFidelity = 0.504582\tKL_Divergence = 2.757571\n",
      "Epoch: 25\tFidelity = 0.503959\tKL_Divergence = 2.838731\n",
      "Epoch: 26\tFidelity = 0.504036\tKL_Divergence = 2.827960\n",
      "Epoch: 27\tFidelity = 0.503727\tKL_Divergence = 2.872079\n",
      "Epoch: 28\tFidelity = 0.504786\tKL_Divergence = 2.732847\n",
      "Epoch: 29\tFidelity = 0.503931\tKL_Divergence = 2.842434\n",
      "Epoch: 30\tFidelity = 0.504689\tKL_Divergence = 2.744589\n",
      "Epoch: 31\tFidelity = 0.504033\tKL_Divergence = 2.828500\n",
      "Epoch: 32\tFidelity = 0.504406\tKL_Divergence = 2.779397\n",
      "Epoch: 33\tFidelity = 0.504491\tKL_Divergence = 2.768660\n",
      "Epoch: 34\tFidelity = 0.504494\tKL_Divergence = 2.768401\n",
      "Epoch: 35\tFidelity = 0.504027\tKL_Divergence = 2.829381\n",
      "Epoch: 36\tFidelity = 0.504526\tKL_Divergence = 2.764376\n",
      "Epoch: 37\tFidelity = 0.503746\tKL_Divergence = 2.869541\n",
      "Epoch: 38\tFidelity = 0.504842\tKL_Divergence = 2.726554\n",
      "Epoch: 39\tFidelity = 0.504401\tKL_Divergence = 2.779937\n",
      "Epoch: 40\tFidelity = 0.503857\tKL_Divergence = 2.853412\n",
      "Epoch: 41\tFidelity = 0.504640\tKL_Divergence = 2.750514\n",
      "Epoch: 42\tFidelity = 0.503775\tKL_Divergence = 2.865309\n",
      "Epoch: 43\tFidelity = 0.503642\tKL_Divergence = 2.885182\n",
      "Epoch: 44\tFidelity = 0.504056\tKL_Divergence = 2.825324\n",
      "Epoch: 45\tFidelity = 0.503583\tKL_Divergence = 2.894332\n",
      "Epoch: 46\tFidelity = 0.503567\tKL_Divergence = 2.896827\n",
      "Epoch: 47\tFidelity = 0.504082\tKL_Divergence = 2.821782\n",
      "Epoch: 48\tFidelity = 0.504348\tKL_Divergence = 2.786614\n",
      "Epoch: 49\tFidelity = 0.503968\tKL_Divergence = 2.837500\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 06:59:58,156] Trial 261 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.504574\tKL_Divergence = 2.758464\n",
      "Total time elapsed during training: 36.688 s\n",
      "Trial 261 pruned. \n",
      "Epoch: 1\tFidelity = 0.504493\tKL_Divergence = 2.768456\n",
      "Epoch: 2\tFidelity = 0.503511\tKL_Divergence = 2.905642\n",
      "Epoch: 3\tFidelity = 0.504987\tKL_Divergence = 2.710353\n",
      "Epoch: 4\tFidelity = 0.503321\tKL_Divergence = 2.936696\n",
      "Epoch: 5\tFidelity = 0.502913\tKL_Divergence = 3.009451\n",
      "Epoch: 6\tFidelity = 0.504773\tKL_Divergence = 2.734747\n",
      "Epoch: 7\tFidelity = 0.504099\tKL_Divergence = 2.819486\n",
      "Epoch: 8\tFidelity = 0.504292\tKL_Divergence = 2.793842\n",
      "Epoch: 9\tFidelity = 0.503390\tKL_Divergence = 2.925209\n",
      "Epoch: 10\tFidelity = 0.504243\tKL_Divergence = 2.800255\n",
      "Epoch: 11\tFidelity = 0.504067\tKL_Divergence = 2.823923\n",
      "Epoch: 12\tFidelity = 0.504549\tKL_Divergence = 2.761495\n",
      "Epoch: 13\tFidelity = 0.503576\tKL_Divergence = 2.895560\n",
      "Epoch: 14\tFidelity = 0.503357\tKL_Divergence = 2.930578\n",
      "Epoch: 15\tFidelity = 0.504630\tKL_Divergence = 2.751663\n",
      "Epoch: 16\tFidelity = 0.503667\tKL_Divergence = 2.881500\n",
      "Epoch: 17\tFidelity = 0.504558\tKL_Divergence = 2.760456\n",
      "Epoch: 18\tFidelity = 0.503326\tKL_Divergence = 2.935736\n",
      "Epoch: 19\tFidelity = 0.504634\tKL_Divergence = 2.751283\n",
      "Epoch: 20\tFidelity = 0.503783\tKL_Divergence = 2.864280\n",
      "Epoch: 21\tFidelity = 0.503902\tKL_Divergence = 2.846912\n",
      "Epoch: 22\tFidelity = 0.504625\tKL_Divergence = 2.752335\n",
      "Epoch: 23\tFidelity = 0.503214\tKL_Divergence = 2.954916\n",
      "Epoch: 24\tFidelity = 0.504389\tKL_Divergence = 2.781574\n",
      "Epoch: 25\tFidelity = 0.503860\tKL_Divergence = 2.852938\n",
      "Epoch: 26\tFidelity = 0.504280\tKL_Divergence = 2.795541\n",
      "Epoch: 27\tFidelity = 0.504488\tKL_Divergence = 2.769069\n",
      "Epoch: 28\tFidelity = 0.503086\tKL_Divergence = 2.977473\n",
      "Epoch: 29\tFidelity = 0.505053\tKL_Divergence = 2.703134\n",
      "Epoch: 30\tFidelity = 0.504320\tKL_Divergence = 2.790405\n",
      "Epoch: 31\tFidelity = 0.503986\tKL_Divergence = 2.835206\n",
      "Epoch: 32\tFidelity = 0.504489\tKL_Divergence = 2.769028\n",
      "Epoch: 33\tFidelity = 0.503573\tKL_Divergence = 2.896009\n",
      "Epoch: 34\tFidelity = 0.505174\tKL_Divergence = 2.689948\n",
      "Epoch: 35\tFidelity = 0.504943\tKL_Divergence = 2.715381\n",
      "Epoch: 36\tFidelity = 0.504011\tKL_Divergence = 2.831731\n",
      "Epoch: 37\tFidelity = 0.504088\tKL_Divergence = 2.821060\n",
      "Epoch: 38\tFidelity = 0.504665\tKL_Divergence = 2.747554\n",
      "Epoch: 39\tFidelity = 0.504415\tKL_Divergence = 2.778309\n",
      "Epoch: 40\tFidelity = 0.504826\tKL_Divergence = 2.728776\n",
      "Epoch: 41\tFidelity = 0.503751\tKL_Divergence = 2.869039\n",
      "Epoch: 42\tFidelity = 0.503505\tKL_Divergence = 2.906672\n",
      "Epoch: 43\tFidelity = 0.503196\tKL_Divergence = 2.958127\n",
      "Epoch: 44\tFidelity = 0.504523\tKL_Divergence = 2.764817\n",
      "Epoch: 45\tFidelity = 0.503518\tKL_Divergence = 2.904685\n",
      "Epoch: 46\tFidelity = 0.503831\tKL_Divergence = 2.857239\n",
      "Epoch: 47\tFidelity = 0.504224\tKL_Divergence = 2.802946\n",
      "Epoch: 48\tFidelity = 0.504194\tKL_Divergence = 2.806935\n",
      "Epoch: 49\tFidelity = 0.503329\tKL_Divergence = 2.935367\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:00:41,613] Trial 262 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.503400\tKL_Divergence = 2.923651\n",
      "Total time elapsed during training: 43.306 s\n",
      "Trial 262 pruned. \n",
      "Epoch: 1\tFidelity = 0.504127\tKL_Divergence = 2.815771\n",
      "Epoch: 2\tFidelity = 0.503909\tKL_Divergence = 2.845903\n",
      "Epoch: 3\tFidelity = 0.504466\tKL_Divergence = 2.771892\n",
      "Epoch: 4\tFidelity = 0.504604\tKL_Divergence = 2.754831\n",
      "Epoch: 5\tFidelity = 0.504324\tKL_Divergence = 2.789989\n",
      "Epoch: 6\tFidelity = 0.504209\tKL_Divergence = 2.804883\n",
      "Epoch: 7\tFidelity = 0.503652\tKL_Divergence = 2.883490\n",
      "Epoch: 8\tFidelity = 0.504455\tKL_Divergence = 2.773344\n",
      "Epoch: 9\tFidelity = 0.504313\tKL_Divergence = 2.791159\n",
      "Epoch: 10\tFidelity = 0.505058\tKL_Divergence = 2.702495\n",
      "Epoch: 11\tFidelity = 0.503692\tKL_Divergence = 2.877765\n",
      "Epoch: 12\tFidelity = 0.504351\tKL_Divergence = 2.786506\n",
      "Epoch: 13\tFidelity = 0.504308\tKL_Divergence = 2.791697\n",
      "Epoch: 14\tFidelity = 0.504597\tKL_Divergence = 2.755436\n",
      "Epoch: 15\tFidelity = 0.503799\tKL_Divergence = 2.861715\n",
      "Epoch: 16\tFidelity = 0.503920\tKL_Divergence = 2.844434\n",
      "Epoch: 17\tFidelity = 0.503014\tKL_Divergence = 2.990626\n",
      "Epoch: 18\tFidelity = 0.503786\tKL_Divergence = 2.863716\n",
      "Epoch: 19\tFidelity = 0.503259\tKL_Divergence = 2.947085\n",
      "Epoch: 20\tFidelity = 0.505098\tKL_Divergence = 2.698068\n",
      "Epoch: 21\tFidelity = 0.504137\tKL_Divergence = 2.814338\n",
      "Epoch: 22\tFidelity = 0.504510\tKL_Divergence = 2.766402\n",
      "Epoch: 23\tFidelity = 0.504349\tKL_Divergence = 2.786633\n",
      "Epoch: 24\tFidelity = 0.504746\tKL_Divergence = 2.737967\n",
      "Epoch: 25\tFidelity = 0.504734\tKL_Divergence = 2.739237\n",
      "Epoch: 26\tFidelity = 0.504154\tKL_Divergence = 2.812019\n",
      "Epoch: 27\tFidelity = 0.504683\tKL_Divergence = 2.745502\n",
      "Epoch: 28\tFidelity = 0.504100\tKL_Divergence = 2.819408\n",
      "Epoch: 29\tFidelity = 0.504231\tKL_Divergence = 2.801900\n",
      "Epoch: 30\tFidelity = 0.503882\tKL_Divergence = 2.849368\n",
      "Epoch: 31\tFidelity = 0.505527\tKL_Divergence = 2.652941\n",
      "Epoch: 32\tFidelity = 0.503363\tKL_Divergence = 2.929685\n",
      "Epoch: 33\tFidelity = 0.503586\tKL_Divergence = 2.893910\n",
      "Epoch: 34\tFidelity = 0.504219\tKL_Divergence = 2.803552\n",
      "Epoch: 35\tFidelity = 0.504312\tKL_Divergence = 2.791092\n",
      "Epoch: 36\tFidelity = 0.503150\tKL_Divergence = 2.965933\n",
      "Epoch: 37\tFidelity = 0.504324\tKL_Divergence = 2.789684\n",
      "Epoch: 38\tFidelity = 0.504716\tKL_Divergence = 2.741216\n",
      "Epoch: 39\tFidelity = 0.505242\tKL_Divergence = 2.682382\n",
      "Epoch: 40\tFidelity = 0.504029\tKL_Divergence = 2.828345\n",
      "Epoch: 41\tFidelity = 0.503682\tKL_Divergence = 2.878902\n",
      "Epoch: 42\tFidelity = 0.504821\tKL_Divergence = 2.728969\n",
      "Epoch: 43\tFidelity = 0.503631\tKL_Divergence = 2.886961\n",
      "Epoch: 44\tFidelity = 0.503714\tKL_Divergence = 2.873996\n",
      "Epoch: 45\tFidelity = 0.502609\tKL_Divergence = 3.070659\n",
      "Epoch: 46\tFidelity = 0.505289\tKL_Divergence = 2.677678\n",
      "Epoch: 47\tFidelity = 0.503233\tKL_Divergence = 2.951728\n",
      "Epoch: 48\tFidelity = 0.503114\tKL_Divergence = 2.972628\n",
      "Epoch: 49\tFidelity = 0.503677\tKL_Divergence = 2.880005\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:01:41,049] Trial 263 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.502835\tKL_Divergence = 3.024709\n",
      "Total time elapsed during training: 59.291 s\n",
      "Trial 263 pruned. \n",
      "Epoch: 1\tFidelity = 0.504096\tKL_Divergence = 2.820036\n",
      "Epoch: 2\tFidelity = 0.504194\tKL_Divergence = 2.807013\n",
      "Epoch: 3\tFidelity = 0.504146\tKL_Divergence = 2.813298\n",
      "Epoch: 4\tFidelity = 0.503719\tKL_Divergence = 2.873829\n",
      "Epoch: 5\tFidelity = 0.503479\tKL_Divergence = 2.910970\n",
      "Epoch: 6\tFidelity = 0.503612\tKL_Divergence = 2.890088\n",
      "Epoch: 7\tFidelity = 0.504003\tKL_Divergence = 2.832942\n",
      "Epoch: 8\tFidelity = 0.503740\tKL_Divergence = 2.870768\n",
      "Epoch: 9\tFidelity = 0.503441\tKL_Divergence = 2.917062\n",
      "Epoch: 10\tFidelity = 0.503709\tKL_Divergence = 2.875354\n",
      "Epoch: 11\tFidelity = 0.504000\tKL_Divergence = 2.833356\n",
      "Epoch: 12\tFidelity = 0.503764\tKL_Divergence = 2.867114\n",
      "Epoch: 13\tFidelity = 0.503582\tKL_Divergence = 2.894609\n",
      "Epoch: 14\tFidelity = 0.503847\tKL_Divergence = 2.854928\n",
      "Epoch: 15\tFidelity = 0.504140\tKL_Divergence = 2.814188\n",
      "Epoch: 16\tFidelity = 0.503643\tKL_Divergence = 2.885315\n",
      "Epoch: 17\tFidelity = 0.504006\tKL_Divergence = 2.832444\n",
      "Epoch: 18\tFidelity = 0.504205\tKL_Divergence = 2.805397\n",
      "Epoch: 19\tFidelity = 0.503641\tKL_Divergence = 2.885615\n",
      "Epoch: 20\tFidelity = 0.503742\tKL_Divergence = 2.870450\n",
      "Epoch: 21\tFidelity = 0.504103\tKL_Divergence = 2.819123\n",
      "Epoch: 22\tFidelity = 0.503327\tKL_Divergence = 2.935778\n",
      "Epoch: 23\tFidelity = 0.504206\tKL_Divergence = 2.805271\n",
      "Epoch: 24\tFidelity = 0.503825\tKL_Divergence = 2.858157\n",
      "Epoch: 25\tFidelity = 0.504040\tKL_Divergence = 2.827824\n",
      "Epoch: 26\tFidelity = 0.503693\tKL_Divergence = 2.877779\n",
      "Epoch: 27\tFidelity = 0.503955\tKL_Divergence = 2.839651\n",
      "Epoch: 28\tFidelity = 0.503214\tKL_Divergence = 2.954940\n",
      "Epoch: 29\tFidelity = 0.503285\tKL_Divergence = 2.942949\n",
      "Epoch: 30\tFidelity = 0.503669\tKL_Divergence = 2.881298\n",
      "Epoch: 31\tFidelity = 0.503614\tKL_Divergence = 2.889699\n",
      "Epoch: 32\tFidelity = 0.503634\tKL_Divergence = 2.886671\n",
      "Epoch: 33\tFidelity = 0.503263\tKL_Divergence = 2.946519\n",
      "Epoch: 34\tFidelity = 0.503804\tKL_Divergence = 2.861213\n",
      "Epoch: 35\tFidelity = 0.503929\tKL_Divergence = 2.843234\n",
      "Epoch: 36\tFidelity = 0.503137\tKL_Divergence = 2.968521\n",
      "Epoch: 37\tFidelity = 0.503251\tKL_Divergence = 2.948723\n",
      "Epoch: 38\tFidelity = 0.503820\tKL_Divergence = 2.858998\n",
      "Epoch: 39\tFidelity = 0.503564\tKL_Divergence = 2.897456\n",
      "Epoch: 40\tFidelity = 0.503598\tKL_Divergence = 2.892221\n",
      "Epoch: 41\tFidelity = 0.503788\tKL_Divergence = 2.863701\n",
      "Epoch: 42\tFidelity = 0.503431\tKL_Divergence = 2.918706\n",
      "Epoch: 43\tFidelity = 0.503429\tKL_Divergence = 2.918939\n",
      "Epoch: 44\tFidelity = 0.503925\tKL_Divergence = 2.843779\n",
      "Epoch: 45\tFidelity = 0.503108\tKL_Divergence = 2.973661\n",
      "Epoch: 46\tFidelity = 0.503831\tKL_Divergence = 2.857386\n",
      "Epoch: 47\tFidelity = 0.504166\tKL_Divergence = 2.810726\n",
      "Epoch: 48\tFidelity = 0.503447\tKL_Divergence = 2.916089\n",
      "Epoch: 49\tFidelity = 0.503552\tKL_Divergence = 2.899444\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:03:03,103] Trial 264 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.503978\tKL_Divergence = 2.836382\n",
      "Total time elapsed during training: 81.895 s\n",
      "Trial 264 pruned. \n",
      "Epoch: 1\tFidelity = 0.503683\tKL_Divergence = 2.879268\n",
      "Epoch: 2\tFidelity = 0.503395\tKL_Divergence = 2.924632\n",
      "Epoch: 3\tFidelity = 0.503454\tKL_Divergence = 2.914941\n",
      "Epoch: 4\tFidelity = 0.503701\tKL_Divergence = 2.876602\n",
      "Epoch: 5\tFidelity = 0.503367\tKL_Divergence = 2.929172\n",
      "Epoch: 6\tFidelity = 0.503415\tKL_Divergence = 2.921338\n",
      "Epoch: 7\tFidelity = 0.503541\tKL_Divergence = 2.901097\n",
      "Epoch: 8\tFidelity = 0.503763\tKL_Divergence = 2.867225\n",
      "Epoch: 9\tFidelity = 0.503846\tKL_Divergence = 2.855163\n",
      "Epoch: 10\tFidelity = 0.503679\tKL_Divergence = 2.879925\n",
      "Epoch: 11\tFidelity = 0.503848\tKL_Divergence = 2.854845\n",
      "Epoch: 12\tFidelity = 0.503653\tKL_Divergence = 2.883799\n",
      "Epoch: 13\tFidelity = 0.503483\tKL_Divergence = 2.910394\n",
      "Epoch: 14\tFidelity = 0.503521\tKL_Divergence = 2.904330\n",
      "Epoch: 15\tFidelity = 0.503627\tKL_Divergence = 2.887796\n",
      "Epoch: 16\tFidelity = 0.503382\tKL_Divergence = 2.926680\n",
      "Epoch: 17\tFidelity = 0.503499\tKL_Divergence = 2.907738\n",
      "Epoch: 18\tFidelity = 0.503739\tKL_Divergence = 2.870804\n",
      "Epoch: 19\tFidelity = 0.503903\tKL_Divergence = 2.847000\n",
      "Epoch: 20\tFidelity = 0.503826\tKL_Divergence = 2.858116\n",
      "Epoch: 21\tFidelity = 0.503650\tKL_Divergence = 2.884364\n",
      "Epoch: 22\tFidelity = 0.503331\tKL_Divergence = 2.935155\n",
      "Epoch: 23\tFidelity = 0.503315\tKL_Divergence = 2.937831\n",
      "Epoch: 24\tFidelity = 0.503358\tKL_Divergence = 2.930670\n",
      "Epoch: 25\tFidelity = 0.503484\tKL_Divergence = 2.910209\n",
      "Epoch: 26\tFidelity = 0.503484\tKL_Divergence = 2.910153\n",
      "Epoch: 27\tFidelity = 0.503357\tKL_Divergence = 2.930874\n",
      "Epoch: 28\tFidelity = 0.503765\tKL_Divergence = 2.866970\n",
      "Epoch: 29\tFidelity = 0.503861\tKL_Divergence = 2.852978\n",
      "Epoch: 30\tFidelity = 0.503400\tKL_Divergence = 2.923826\n",
      "Epoch: 31\tFidelity = 0.503458\tKL_Divergence = 2.914401\n",
      "Epoch: 32\tFidelity = 0.503239\tKL_Divergence = 2.950778\n",
      "Epoch: 33\tFidelity = 0.503740\tKL_Divergence = 2.870716\n",
      "Epoch: 34\tFidelity = 0.503508\tKL_Divergence = 2.906419\n",
      "Epoch: 35\tFidelity = 0.503609\tKL_Divergence = 2.890640\n",
      "Epoch: 36\tFidelity = 0.503583\tKL_Divergence = 2.894627\n",
      "Epoch: 37\tFidelity = 0.503199\tKL_Divergence = 2.957738\n",
      "Epoch: 38\tFidelity = 0.503229\tKL_Divergence = 2.952549\n",
      "Epoch: 39\tFidelity = 0.503362\tKL_Divergence = 2.929968\n",
      "Epoch: 40\tFidelity = 0.503273\tKL_Divergence = 2.944888\n",
      "Epoch: 41\tFidelity = 0.503733\tKL_Divergence = 2.871852\n",
      "Epoch: 42\tFidelity = 0.503402\tKL_Divergence = 2.923517\n",
      "Epoch: 43\tFidelity = 0.503874\tKL_Divergence = 2.851249\n",
      "Epoch: 44\tFidelity = 0.503639\tKL_Divergence = 2.886002\n",
      "Epoch: 45\tFidelity = 0.503216\tKL_Divergence = 2.954693\n",
      "Epoch: 46\tFidelity = 0.503487\tKL_Divergence = 2.909727\n",
      "Epoch: 47\tFidelity = 0.503181\tKL_Divergence = 2.960782\n",
      "Epoch: 48\tFidelity = 0.503122\tKL_Divergence = 2.971157\n",
      "Epoch: 49\tFidelity = 0.503385\tKL_Divergence = 2.926213\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:03:42,382] Trial 265 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.503715\tKL_Divergence = 2.874581\n",
      "Total time elapsed during training: 39.116 s\n",
      "Trial 265 pruned. \n",
      "Epoch: 1\tFidelity = 0.503656\tKL_Divergence = 2.883411\n",
      "Epoch: 2\tFidelity = 0.503735\tKL_Divergence = 2.871561\n",
      "Epoch: 3\tFidelity = 0.503675\tKL_Divergence = 2.880544\n",
      "Epoch: 4\tFidelity = 0.503525\tKL_Divergence = 2.903776\n",
      "Epoch: 5\tFidelity = 0.503289\tKL_Divergence = 2.942290\n",
      "Epoch: 6\tFidelity = 0.503390\tKL_Divergence = 2.925396\n",
      "Epoch: 7\tFidelity = 0.503394\tKL_Divergence = 2.924738\n",
      "Epoch: 8\tFidelity = 0.503309\tKL_Divergence = 2.938834\n",
      "Epoch: 9\tFidelity = 0.503759\tKL_Divergence = 2.867883\n",
      "Epoch: 10\tFidelity = 0.503406\tKL_Divergence = 2.922876\n",
      "Epoch: 11\tFidelity = 0.503549\tKL_Divergence = 2.899958\n",
      "Epoch: 12\tFidelity = 0.503631\tKL_Divergence = 2.887253\n",
      "Epoch: 13\tFidelity = 0.503374\tKL_Divergence = 2.928103\n",
      "Epoch: 14\tFidelity = 0.503963\tKL_Divergence = 2.838602\n",
      "Epoch: 15\tFidelity = 0.503206\tKL_Divergence = 2.956521\n",
      "Epoch: 16\tFidelity = 0.503419\tKL_Divergence = 2.920748\n",
      "Epoch: 17\tFidelity = 0.503651\tKL_Divergence = 2.884202\n",
      "Epoch: 18\tFidelity = 0.503501\tKL_Divergence = 2.907521\n",
      "Epoch: 19\tFidelity = 0.503349\tKL_Divergence = 2.932224\n",
      "Epoch: 20\tFidelity = 0.503689\tKL_Divergence = 2.878349\n",
      "Epoch: 21\tFidelity = 0.503433\tKL_Divergence = 2.918445\n",
      "Epoch: 22\tFidelity = 0.503392\tKL_Divergence = 2.925065\n",
      "Epoch: 23\tFidelity = 0.503455\tKL_Divergence = 2.914900\n",
      "Epoch: 24\tFidelity = 0.503240\tKL_Divergence = 2.950623\n",
      "Epoch: 25\tFidelity = 0.503258\tKL_Divergence = 2.947433\n",
      "Epoch: 26\tFidelity = 0.503321\tKL_Divergence = 2.936849\n",
      "Epoch: 27\tFidelity = 0.503543\tKL_Divergence = 2.900863\n",
      "Epoch: 28\tFidelity = 0.503336\tKL_Divergence = 2.934391\n",
      "Epoch: 29\tFidelity = 0.503523\tKL_Divergence = 2.904050\n",
      "Epoch: 30\tFidelity = 0.503446\tKL_Divergence = 2.916211\n",
      "Epoch: 31\tFidelity = 0.503424\tKL_Divergence = 2.919899\n",
      "Epoch: 32\tFidelity = 0.503614\tKL_Divergence = 2.889867\n",
      "Epoch: 33\tFidelity = 0.503328\tKL_Divergence = 2.935647\n",
      "Epoch: 34\tFidelity = 0.503333\tKL_Divergence = 2.934888\n",
      "Epoch: 35\tFidelity = 0.503546\tKL_Divergence = 2.900379\n",
      "Epoch: 36\tFidelity = 0.503527\tKL_Divergence = 2.903333\n",
      "Epoch: 37\tFidelity = 0.503397\tKL_Divergence = 2.924287\n",
      "Epoch: 38\tFidelity = 0.503227\tKL_Divergence = 2.952848\n",
      "Epoch: 39\tFidelity = 0.503822\tKL_Divergence = 2.858727\n",
      "Epoch: 40\tFidelity = 0.503124\tKL_Divergence = 2.970856\n",
      "Epoch: 41\tFidelity = 0.503308\tKL_Divergence = 2.939104\n",
      "Epoch: 42\tFidelity = 0.503368\tKL_Divergence = 2.929030\n",
      "Epoch: 43\tFidelity = 0.503436\tKL_Divergence = 2.917898\n",
      "Epoch: 44\tFidelity = 0.503283\tKL_Divergence = 2.943315\n",
      "Epoch: 45\tFidelity = 0.503706\tKL_Divergence = 2.875908\n",
      "Epoch: 46\tFidelity = 0.503644\tKL_Divergence = 2.885178\n",
      "Epoch: 47\tFidelity = 0.503318\tKL_Divergence = 2.937373\n",
      "Epoch: 48\tFidelity = 0.503227\tKL_Divergence = 2.952916\n",
      "Epoch: 49\tFidelity = 0.503394\tKL_Divergence = 2.924862\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:04:21,964] Trial 266 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.503841\tKL_Divergence = 2.855876\n",
      "Total time elapsed during training: 39.407 s\n",
      "Trial 266 pruned. \n",
      "Epoch: 1\tFidelity = 0.503805\tKL_Divergence = 2.861220\n",
      "Epoch: 2\tFidelity = 0.503765\tKL_Divergence = 2.867091\n",
      "Epoch: 3\tFidelity = 0.503194\tKL_Divergence = 2.958134\n",
      "Epoch: 4\tFidelity = 0.503542\tKL_Divergence = 2.900924\n",
      "Epoch: 5\tFidelity = 0.503875\tKL_Divergence = 2.850876\n",
      "Epoch: 6\tFidelity = 0.503946\tKL_Divergence = 2.840574\n",
      "Epoch: 7\tFidelity = 0.502869\tKL_Divergence = 3.017719\n",
      "Epoch: 8\tFidelity = 0.502729\tKL_Divergence = 3.045407\n",
      "Epoch: 9\tFidelity = 0.503379\tKL_Divergence = 2.926291\n",
      "Epoch: 10\tFidelity = 0.502759\tKL_Divergence = 3.039462\n",
      "Epoch: 11\tFidelity = 0.502908\tKL_Divergence = 3.010251\n",
      "Epoch: 12\tFidelity = 0.503549\tKL_Divergence = 2.899248\n",
      "Epoch: 13\tFidelity = 0.502949\tKL_Divergence = 3.002460\n",
      "Epoch: 14\tFidelity = 0.502783\tKL_Divergence = 3.034787\n",
      "Epoch: 15\tFidelity = 0.504120\tKL_Divergence = 2.816765\n",
      "Epoch: 16\tFidelity = 0.504146\tKL_Divergence = 2.813383\n",
      "Epoch: 17\tFidelity = 0.503378\tKL_Divergence = 2.927270\n",
      "Epoch: 18\tFidelity = 0.503034\tKL_Divergence = 2.986962\n",
      "Epoch: 19\tFidelity = 0.503187\tKL_Divergence = 2.959631\n",
      "Epoch: 20\tFidelity = 0.503318\tKL_Divergence = 2.937342\n",
      "Epoch: 21\tFidelity = 0.502919\tKL_Divergence = 3.008367\n",
      "Epoch: 22\tFidelity = 0.503086\tKL_Divergence = 2.977573\n",
      "Epoch: 23\tFidelity = 0.503794\tKL_Divergence = 2.862770\n",
      "Epoch: 24\tFidelity = 0.503262\tKL_Divergence = 2.946674\n",
      "Epoch: 25\tFidelity = 0.503600\tKL_Divergence = 2.891886\n",
      "Epoch: 26\tFidelity = 0.504040\tKL_Divergence = 2.827648\n",
      "Epoch: 27\tFidelity = 0.503796\tKL_Divergence = 2.862269\n",
      "Epoch: 28\tFidelity = 0.503048\tKL_Divergence = 2.984162\n",
      "Epoch: 29\tFidelity = 0.503501\tKL_Divergence = 2.907207\n",
      "Epoch: 30\tFidelity = 0.504219\tKL_Divergence = 2.803626\n",
      "Epoch: 31\tFidelity = 0.502923\tKL_Divergence = 3.007870\n",
      "Epoch: 32\tFidelity = 0.503502\tKL_Divergence = 2.907257\n",
      "Epoch: 33\tFidelity = 0.503452\tKL_Divergence = 2.915220\n",
      "Epoch: 34\tFidelity = 0.503680\tKL_Divergence = 2.879752\n",
      "Epoch: 35\tFidelity = 0.503768\tKL_Divergence = 2.866514\n",
      "Epoch: 36\tFidelity = 0.503024\tKL_Divergence = 2.988763\n",
      "Epoch: 37\tFidelity = 0.503604\tKL_Divergence = 2.891102\n",
      "Epoch: 38\tFidelity = 0.503106\tKL_Divergence = 2.973832\n",
      "Epoch: 39\tFidelity = 0.503646\tKL_Divergence = 2.884941\n",
      "Epoch: 40\tFidelity = 0.503041\tKL_Divergence = 2.985737\n",
      "Epoch: 41\tFidelity = 0.503847\tKL_Divergence = 2.854775\n",
      "Epoch: 42\tFidelity = 0.503507\tKL_Divergence = 2.906318\n",
      "Epoch: 43\tFidelity = 0.503080\tKL_Divergence = 2.978510\n",
      "Epoch: 44\tFidelity = 0.503215\tKL_Divergence = 2.954706\n",
      "Epoch: 45\tFidelity = 0.504354\tKL_Divergence = 2.785827\n",
      "Epoch: 46\tFidelity = 0.503693\tKL_Divergence = 2.877577\n",
      "Epoch: 47\tFidelity = 0.502832\tKL_Divergence = 3.025240\n",
      "Epoch: 48\tFidelity = 0.503677\tKL_Divergence = 2.880197\n",
      "Epoch: 49\tFidelity = 0.502791\tKL_Divergence = 3.033427\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:05:01,572] Trial 267 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.503135\tKL_Divergence = 2.968886\n",
      "Total time elapsed during training: 39.422 s\n",
      "Trial 267 pruned. \n",
      "Epoch: 1\tFidelity = 0.503734\tKL_Divergence = 2.871535\n",
      "Epoch: 2\tFidelity = 0.503657\tKL_Divergence = 2.883155\n",
      "Epoch: 3\tFidelity = 0.503258\tKL_Divergence = 2.947539\n",
      "Epoch: 4\tFidelity = 0.503531\tKL_Divergence = 2.902625\n",
      "Epoch: 5\tFidelity = 0.504067\tKL_Divergence = 2.823989\n",
      "Epoch: 6\tFidelity = 0.503277\tKL_Divergence = 2.944317\n",
      "Epoch: 7\tFidelity = 0.503292\tKL_Divergence = 2.941715\n",
      "Epoch: 8\tFidelity = 0.503412\tKL_Divergence = 2.921777\n",
      "Epoch: 9\tFidelity = 0.503478\tKL_Divergence = 2.911113\n",
      "Epoch: 10\tFidelity = 0.503740\tKL_Divergence = 2.870683\n",
      "Epoch: 11\tFidelity = 0.503545\tKL_Divergence = 2.900432\n",
      "Epoch: 12\tFidelity = 0.503161\tKL_Divergence = 2.964310\n",
      "Epoch: 13\tFidelity = 0.503750\tKL_Divergence = 2.869182\n",
      "Epoch: 14\tFidelity = 0.503159\tKL_Divergence = 2.964684\n",
      "Epoch: 15\tFidelity = 0.503966\tKL_Divergence = 2.838008\n",
      "Epoch: 16\tFidelity = 0.503210\tKL_Divergence = 2.955791\n",
      "Epoch: 17\tFidelity = 0.503373\tKL_Divergence = 2.928120\n",
      "Epoch: 18\tFidelity = 0.503435\tKL_Divergence = 2.918116\n",
      "Epoch: 19\tFidelity = 0.503811\tKL_Divergence = 2.860205\n",
      "Epoch: 20\tFidelity = 0.503458\tKL_Divergence = 2.914292\n",
      "Epoch: 21\tFidelity = 0.503663\tKL_Divergence = 2.882269\n",
      "Epoch: 22\tFidelity = 0.503471\tKL_Divergence = 2.912279\n",
      "Epoch: 23\tFidelity = 0.503293\tKL_Divergence = 2.941511\n",
      "Epoch: 24\tFidelity = 0.503307\tKL_Divergence = 2.939138\n",
      "Epoch: 25\tFidelity = 0.503997\tKL_Divergence = 2.833792\n",
      "Epoch: 26\tFidelity = 0.503002\tKL_Divergence = 2.993096\n",
      "Epoch: 27\tFidelity = 0.502982\tKL_Divergence = 2.996800\n",
      "Epoch: 28\tFidelity = 0.503722\tKL_Divergence = 2.873510\n",
      "Epoch: 29\tFidelity = 0.503641\tKL_Divergence = 2.885618\n",
      "Epoch: 30\tFidelity = 0.502936\tKL_Divergence = 3.005436\n",
      "Epoch: 31\tFidelity = 0.503176\tKL_Divergence = 2.961682\n",
      "Epoch: 32\tFidelity = 0.503657\tKL_Divergence = 2.883190\n",
      "Epoch: 33\tFidelity = 0.503283\tKL_Divergence = 2.943229\n",
      "Epoch: 34\tFidelity = 0.503918\tKL_Divergence = 2.844868\n",
      "Epoch: 35\tFidelity = 0.503101\tKL_Divergence = 2.974955\n",
      "Epoch: 36\tFidelity = 0.503327\tKL_Divergence = 2.935882\n",
      "Epoch: 37\tFidelity = 0.503634\tKL_Divergence = 2.886804\n",
      "Epoch: 38\tFidelity = 0.503179\tKL_Divergence = 2.961257\n",
      "Epoch: 39\tFidelity = 0.503397\tKL_Divergence = 2.924246\n",
      "Epoch: 40\tFidelity = 0.503679\tKL_Divergence = 2.879914\n",
      "Epoch: 41\tFidelity = 0.503801\tKL_Divergence = 2.861787\n",
      "Epoch: 42\tFidelity = 0.503081\tKL_Divergence = 2.978642\n",
      "Epoch: 43\tFidelity = 0.503436\tKL_Divergence = 2.917979\n",
      "Epoch: 44\tFidelity = 0.503317\tKL_Divergence = 2.937582\n",
      "Epoch: 45\tFidelity = 0.503273\tKL_Divergence = 2.944999\n",
      "Epoch: 46\tFidelity = 0.503449\tKL_Divergence = 2.915799\n",
      "Epoch: 47\tFidelity = 0.503209\tKL_Divergence = 2.955949\n",
      "Epoch: 48\tFidelity = 0.503884\tKL_Divergence = 2.849704\n",
      "Epoch: 49\tFidelity = 0.503309\tKL_Divergence = 2.938783\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:05:34,704] Trial 268 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.502966\tKL_Divergence = 2.999715\n",
      "Total time elapsed during training: 32.883 s\n",
      "Trial 268 pruned. \n",
      "Epoch: 1\tFidelity = 0.503774\tKL_Divergence = 2.865623\n",
      "Epoch: 2\tFidelity = 0.503259\tKL_Divergence = 2.947355\n",
      "Epoch: 3\tFidelity = 0.502830\tKL_Divergence = 3.025788\n",
      "Epoch: 4\tFidelity = 0.503910\tKL_Divergence = 2.845917\n",
      "Epoch: 5\tFidelity = 0.503593\tKL_Divergence = 2.892978\n",
      "Epoch: 6\tFidelity = 0.503724\tKL_Divergence = 2.873026\n",
      "Epoch: 7\tFidelity = 0.503115\tKL_Divergence = 2.972379\n",
      "Epoch: 8\tFidelity = 0.503154\tKL_Divergence = 2.965435\n",
      "Epoch: 9\tFidelity = 0.503486\tKL_Divergence = 2.909780\n",
      "Epoch: 10\tFidelity = 0.503455\tKL_Divergence = 2.914724\n",
      "Epoch: 11\tFidelity = 0.503551\tKL_Divergence = 2.899496\n",
      "Epoch: 12\tFidelity = 0.504320\tKL_Divergence = 2.790448\n",
      "Epoch: 13\tFidelity = 0.503053\tKL_Divergence = 2.983612\n",
      "Epoch: 14\tFidelity = 0.503457\tKL_Divergence = 2.914450\n",
      "Epoch: 15\tFidelity = 0.503925\tKL_Divergence = 2.843809\n",
      "Epoch: 16\tFidelity = 0.504077\tKL_Divergence = 2.822603\n",
      "Epoch: 17\tFidelity = 0.503547\tKL_Divergence = 2.900107\n",
      "Epoch: 18\tFidelity = 0.503933\tKL_Divergence = 2.842660\n",
      "Epoch: 19\tFidelity = 0.504076\tKL_Divergence = 2.822746\n",
      "Epoch: 20\tFidelity = 0.503220\tKL_Divergence = 2.953942\n",
      "Epoch: 21\tFidelity = 0.503826\tKL_Divergence = 2.857976\n",
      "Epoch: 22\tFidelity = 0.503135\tKL_Divergence = 2.968786\n",
      "Epoch: 23\tFidelity = 0.503961\tKL_Divergence = 2.838799\n",
      "Epoch: 24\tFidelity = 0.503141\tKL_Divergence = 2.967731\n",
      "Epoch: 25\tFidelity = 0.503452\tKL_Divergence = 2.915262\n",
      "Epoch: 26\tFidelity = 0.504501\tKL_Divergence = 2.767531\n",
      "Epoch: 27\tFidelity = 0.503134\tKL_Divergence = 2.969016\n",
      "Epoch: 28\tFidelity = 0.503805\tKL_Divergence = 2.861005\n",
      "Epoch: 29\tFidelity = 0.503144\tKL_Divergence = 2.967282\n",
      "Epoch: 30\tFidelity = 0.503672\tKL_Divergence = 2.880858\n",
      "Epoch: 31\tFidelity = 0.502556\tKL_Divergence = 3.082209\n",
      "Epoch: 32\tFidelity = 0.503521\tKL_Divergence = 2.904215\n",
      "Epoch: 33\tFidelity = 0.502663\tKL_Divergence = 3.059461\n",
      "Epoch: 34\tFidelity = 0.503389\tKL_Divergence = 2.925460\n",
      "Epoch: 35\tFidelity = 0.504369\tKL_Divergence = 2.784167\n",
      "Epoch: 36\tFidelity = 0.503389\tKL_Divergence = 2.925552\n",
      "Epoch: 37\tFidelity = 0.503863\tKL_Divergence = 2.852598\n",
      "Epoch: 38\tFidelity = 0.503426\tKL_Divergence = 2.919485\n",
      "Epoch: 39\tFidelity = 0.504297\tKL_Divergence = 2.793416\n",
      "Epoch: 40\tFidelity = 0.503240\tKL_Divergence = 2.950593\n",
      "Epoch: 41\tFidelity = 0.502968\tKL_Divergence = 2.999337\n",
      "Epoch: 42\tFidelity = 0.504116\tKL_Divergence = 2.817390\n",
      "Epoch: 43\tFidelity = 0.503584\tKL_Divergence = 2.894466\n",
      "Epoch: 44\tFidelity = 0.503357\tKL_Divergence = 2.930875\n",
      "Epoch: 45\tFidelity = 0.502946\tKL_Divergence = 3.003346\n",
      "Epoch: 46\tFidelity = 0.503961\tKL_Divergence = 2.838744\n",
      "Epoch: 47\tFidelity = 0.503315\tKL_Divergence = 2.937889\n",
      "Epoch: 48\tFidelity = 0.503166\tKL_Divergence = 2.963333\n",
      "Epoch: 49\tFidelity = 0.502604\tKL_Divergence = 3.072033\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:06:07,705] Trial 269 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.503881\tKL_Divergence = 2.850161\n",
      "Total time elapsed during training: 32.832 s\n",
      "Trial 269 pruned. \n",
      "Epoch: 1\tFidelity = 0.503395\tKL_Divergence = 2.924491\n",
      "Epoch: 2\tFidelity = 0.503281\tKL_Divergence = 2.943599\n",
      "Epoch: 3\tFidelity = 0.503727\tKL_Divergence = 2.872666\n",
      "Epoch: 4\tFidelity = 0.503131\tKL_Divergence = 2.969619\n",
      "Epoch: 5\tFidelity = 0.503431\tKL_Divergence = 2.918673\n",
      "Epoch: 6\tFidelity = 0.503069\tKL_Divergence = 2.980741\n",
      "Epoch: 7\tFidelity = 0.503917\tKL_Divergence = 2.844945\n",
      "Epoch: 8\tFidelity = 0.503355\tKL_Divergence = 2.931051\n",
      "Epoch: 9\tFidelity = 0.503373\tKL_Divergence = 2.928158\n",
      "Epoch: 10\tFidelity = 0.503267\tKL_Divergence = 2.945841\n",
      "Epoch: 11\tFidelity = 0.503272\tKL_Divergence = 2.945113\n",
      "Epoch: 12\tFidelity = 0.503394\tKL_Divergence = 2.924655\n",
      "Epoch: 13\tFidelity = 0.503810\tKL_Divergence = 2.860468\n",
      "Epoch: 14\tFidelity = 0.503020\tKL_Divergence = 2.989749\n",
      "Epoch: 15\tFidelity = 0.503594\tKL_Divergence = 2.892836\n",
      "Epoch: 16\tFidelity = 0.503355\tKL_Divergence = 2.931090\n",
      "Epoch: 17\tFidelity = 0.503734\tKL_Divergence = 2.871537\n",
      "Epoch: 18\tFidelity = 0.503634\tKL_Divergence = 2.886684\n",
      "Epoch: 19\tFidelity = 0.503343\tKL_Divergence = 2.933079\n",
      "Epoch: 20\tFidelity = 0.503756\tKL_Divergence = 2.868367\n",
      "Epoch: 21\tFidelity = 0.503508\tKL_Divergence = 2.906347\n",
      "Epoch: 22\tFidelity = 0.503784\tKL_Divergence = 2.864226\n",
      "Epoch: 23\tFidelity = 0.503344\tKL_Divergence = 2.932927\n",
      "Epoch: 24\tFidelity = 0.503276\tKL_Divergence = 2.944477\n",
      "Epoch: 25\tFidelity = 0.503148\tKL_Divergence = 2.966533\n",
      "Epoch: 26\tFidelity = 0.503046\tKL_Divergence = 2.984877\n",
      "Epoch: 27\tFidelity = 0.503640\tKL_Divergence = 2.885819\n",
      "Epoch: 28\tFidelity = 0.503207\tKL_Divergence = 2.956171\n",
      "Epoch: 29\tFidelity = 0.503286\tKL_Divergence = 2.942673\n",
      "Epoch: 30\tFidelity = 0.503274\tKL_Divergence = 2.944812\n",
      "Epoch: 31\tFidelity = 0.503352\tKL_Divergence = 2.931596\n",
      "Epoch: 32\tFidelity = 0.503534\tKL_Divergence = 2.902294\n",
      "Epoch: 33\tFidelity = 0.503032\tKL_Divergence = 2.987393\n",
      "Epoch: 34\tFidelity = 0.502973\tKL_Divergence = 2.998446\n",
      "Epoch: 35\tFidelity = 0.502875\tKL_Divergence = 3.017029\n",
      "Epoch: 36\tFidelity = 0.503129\tKL_Divergence = 2.969900\n",
      "Epoch: 37\tFidelity = 0.503505\tKL_Divergence = 2.906756\n",
      "Epoch: 38\tFidelity = 0.503111\tKL_Divergence = 2.973073\n",
      "Epoch: 39\tFidelity = 0.503353\tKL_Divergence = 2.931517\n",
      "Epoch: 40\tFidelity = 0.503298\tKL_Divergence = 2.940700\n",
      "Epoch: 41\tFidelity = 0.503653\tKL_Divergence = 2.883808\n",
      "Epoch: 42\tFidelity = 0.503406\tKL_Divergence = 2.922770\n",
      "Epoch: 43\tFidelity = 0.503057\tKL_Divergence = 2.982880\n",
      "Epoch: 44\tFidelity = 0.503562\tKL_Divergence = 2.897796\n",
      "Epoch: 45\tFidelity = 0.503618\tKL_Divergence = 2.889201\n",
      "Epoch: 46\tFidelity = 0.503367\tKL_Divergence = 2.929122\n",
      "Epoch: 47\tFidelity = 0.503101\tKL_Divergence = 2.975023\n",
      "Epoch: 48\tFidelity = 0.503227\tKL_Divergence = 2.952814\n",
      "Epoch: 49\tFidelity = 0.503293\tKL_Divergence = 2.941584\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:07:30,937] Trial 270 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.503293\tKL_Divergence = 2.941555\n",
      "Total time elapsed during training: 83.072 s\n",
      "Trial 270 pruned. \n",
      "Epoch: 1\tFidelity = 0.503678\tKL_Divergence = 2.879913\n",
      "Epoch: 2\tFidelity = 0.502931\tKL_Divergence = 3.006213\n",
      "Epoch: 3\tFidelity = 0.504201\tKL_Divergence = 2.805977\n",
      "Epoch: 4\tFidelity = 0.503933\tKL_Divergence = 2.842705\n",
      "Epoch: 5\tFidelity = 0.502859\tKL_Divergence = 3.020072\n",
      "Epoch: 6\tFidelity = 0.503410\tKL_Divergence = 2.922045\n",
      "Epoch: 7\tFidelity = 0.502721\tKL_Divergence = 3.047525\n",
      "Epoch: 8\tFidelity = 0.504288\tKL_Divergence = 2.794562\n",
      "Epoch: 9\tFidelity = 0.502491\tKL_Divergence = 3.096743\n",
      "Epoch: 10\tFidelity = 0.503917\tKL_Divergence = 2.844882\n",
      "Epoch: 11\tFidelity = 0.502728\tKL_Divergence = 3.046092\n",
      "Epoch: 12\tFidelity = 0.504098\tKL_Divergence = 2.819802\n",
      "Epoch: 13\tFidelity = 0.503843\tKL_Divergence = 2.855597\n",
      "Epoch: 14\tFidelity = 0.503459\tKL_Divergence = 2.914117\n",
      "Epoch: 15\tFidelity = 0.503802\tKL_Divergence = 2.861460\n",
      "Epoch: 16\tFidelity = 0.503408\tKL_Divergence = 2.922388\n",
      "Epoch: 17\tFidelity = 0.503259\tKL_Divergence = 2.947265\n",
      "Epoch: 18\tFidelity = 0.503075\tKL_Divergence = 2.979508\n",
      "Epoch: 19\tFidelity = 0.503389\tKL_Divergence = 2.925392\n",
      "Epoch: 20\tFidelity = 0.504091\tKL_Divergence = 2.820559\n",
      "Epoch: 21\tFidelity = 0.503447\tKL_Divergence = 2.916026\n",
      "Epoch: 22\tFidelity = 0.503749\tKL_Divergence = 2.869173\n",
      "Epoch: 23\tFidelity = 0.503909\tKL_Divergence = 2.845983\n",
      "Epoch: 24\tFidelity = 0.503711\tKL_Divergence = 2.874961\n",
      "Epoch: 25\tFidelity = 0.504378\tKL_Divergence = 2.782909\n",
      "Epoch: 26\tFidelity = 0.503437\tKL_Divergence = 2.917721\n",
      "Epoch: 27\tFidelity = 0.504029\tKL_Divergence = 2.829215\n",
      "Epoch: 28\tFidelity = 0.502992\tKL_Divergence = 2.994816\n",
      "Epoch: 29\tFidelity = 0.503274\tKL_Divergence = 2.944588\n",
      "Epoch: 30\tFidelity = 0.504458\tKL_Divergence = 2.772949\n",
      "Epoch: 31\tFidelity = 0.504458\tKL_Divergence = 2.772884\n",
      "Epoch: 32\tFidelity = 0.504215\tKL_Divergence = 2.804096\n",
      "Epoch: 33\tFidelity = 0.502710\tKL_Divergence = 3.049856\n",
      "Epoch: 34\tFidelity = 0.504439\tKL_Divergence = 2.775377\n",
      "Epoch: 35\tFidelity = 0.502913\tKL_Divergence = 3.009779\n",
      "Epoch: 36\tFidelity = 0.503876\tKL_Divergence = 2.850998\n",
      "Epoch: 37\tFidelity = 0.503727\tKL_Divergence = 2.872671\n",
      "Epoch: 38\tFidelity = 0.504257\tKL_Divergence = 2.798659\n",
      "Epoch: 39\tFidelity = 0.503960\tKL_Divergence = 2.838957\n",
      "Epoch: 40\tFidelity = 0.502771\tKL_Divergence = 3.037574\n",
      "Epoch: 41\tFidelity = 0.503039\tKL_Divergence = 2.986246\n",
      "Epoch: 42\tFidelity = 0.502932\tKL_Divergence = 3.006217\n",
      "Epoch: 43\tFidelity = 0.502866\tKL_Divergence = 3.018823\n",
      "Epoch: 44\tFidelity = 0.503275\tKL_Divergence = 2.944651\n",
      "Epoch: 45\tFidelity = 0.503360\tKL_Divergence = 2.930319\n",
      "Epoch: 46\tFidelity = 0.502924\tKL_Divergence = 3.007585\n",
      "Epoch: 47\tFidelity = 0.504033\tKL_Divergence = 2.828802\n",
      "Epoch: 48\tFidelity = 0.502632\tKL_Divergence = 3.066209\n",
      "Epoch: 49\tFidelity = 0.504164\tKL_Divergence = 2.811061\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:08:17,326] Trial 271 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.503565\tKL_Divergence = 2.897452\n",
      "Total time elapsed during training: 46.231 s\n",
      "Trial 271 pruned. \n",
      "Epoch: 1\tFidelity = 0.504359\tKL_Divergence = 2.785457\n",
      "Epoch: 2\tFidelity = 0.503871\tKL_Divergence = 2.851544\n",
      "Epoch: 3\tFidelity = 0.503828\tKL_Divergence = 2.857690\n",
      "Epoch: 4\tFidelity = 0.503737\tKL_Divergence = 2.871215\n",
      "Epoch: 5\tFidelity = 0.503682\tKL_Divergence = 2.879384\n",
      "Epoch: 6\tFidelity = 0.503629\tKL_Divergence = 2.887363\n",
      "Epoch: 7\tFidelity = 0.503794\tKL_Divergence = 2.862828\n",
      "Epoch: 8\tFidelity = 0.503216\tKL_Divergence = 2.954776\n",
      "Epoch: 9\tFidelity = 0.503813\tKL_Divergence = 2.859929\n",
      "Epoch: 10\tFidelity = 0.503635\tKL_Divergence = 2.886546\n",
      "Epoch: 11\tFidelity = 0.504003\tKL_Divergence = 2.832932\n",
      "Epoch: 12\tFidelity = 0.503141\tKL_Divergence = 2.967758\n",
      "Epoch: 13\tFidelity = 0.503281\tKL_Divergence = 2.943548\n",
      "Epoch: 14\tFidelity = 0.503092\tKL_Divergence = 2.976552\n",
      "Epoch: 15\tFidelity = 0.503347\tKL_Divergence = 2.932585\n",
      "Epoch: 16\tFidelity = 0.503901\tKL_Divergence = 2.847316\n",
      "Epoch: 17\tFidelity = 0.503487\tKL_Divergence = 2.909719\n",
      "Epoch: 18\tFidelity = 0.503679\tKL_Divergence = 2.879914\n",
      "Epoch: 19\tFidelity = 0.503342\tKL_Divergence = 2.933332\n",
      "Epoch: 20\tFidelity = 0.503572\tKL_Divergence = 2.896372\n",
      "Epoch: 21\tFidelity = 0.503590\tKL_Divergence = 2.893529\n",
      "Epoch: 22\tFidelity = 0.503802\tKL_Divergence = 2.861583\n",
      "Epoch: 23\tFidelity = 0.503414\tKL_Divergence = 2.921541\n",
      "Epoch: 24\tFidelity = 0.503847\tKL_Divergence = 2.854950\n",
      "Epoch: 25\tFidelity = 0.503527\tKL_Divergence = 2.903176\n",
      "Epoch: 26\tFidelity = 0.503122\tKL_Divergence = 2.971272\n",
      "Epoch: 27\tFidelity = 0.503747\tKL_Divergence = 2.869702\n",
      "Epoch: 28\tFidelity = 0.503610\tKL_Divergence = 2.890426\n",
      "Epoch: 29\tFidelity = 0.503753\tKL_Divergence = 2.868891\n",
      "Epoch: 30\tFidelity = 0.503479\tKL_Divergence = 2.911029\n",
      "Epoch: 31\tFidelity = 0.503487\tKL_Divergence = 2.909789\n",
      "Epoch: 32\tFidelity = 0.503011\tKL_Divergence = 2.991270\n",
      "Epoch: 33\tFidelity = 0.503524\tKL_Divergence = 2.903752\n",
      "Epoch: 34\tFidelity = 0.503781\tKL_Divergence = 2.864557\n",
      "Epoch: 35\tFidelity = 0.503237\tKL_Divergence = 2.951024\n",
      "Epoch: 36\tFidelity = 0.503666\tKL_Divergence = 2.881816\n",
      "Epoch: 37\tFidelity = 0.503568\tKL_Divergence = 2.897000\n",
      "Epoch: 38\tFidelity = 0.503327\tKL_Divergence = 2.935847\n",
      "Epoch: 39\tFidelity = 0.503388\tKL_Divergence = 2.925681\n",
      "Epoch: 40\tFidelity = 0.503824\tKL_Divergence = 2.858221\n",
      "Epoch: 41\tFidelity = 0.503572\tKL_Divergence = 2.896393\n",
      "Epoch: 42\tFidelity = 0.503611\tKL_Divergence = 2.890301\n",
      "Epoch: 43\tFidelity = 0.503023\tKL_Divergence = 2.989186\n",
      "Epoch: 44\tFidelity = 0.503257\tKL_Divergence = 2.947646\n",
      "Epoch: 45\tFidelity = 0.503892\tKL_Divergence = 2.848649\n",
      "Epoch: 46\tFidelity = 0.503536\tKL_Divergence = 2.901998\n",
      "Epoch: 47\tFidelity = 0.503747\tKL_Divergence = 2.869675\n",
      "Epoch: 48\tFidelity = 0.503677\tKL_Divergence = 2.880139\n",
      "Epoch: 49\tFidelity = 0.503446\tKL_Divergence = 2.916037\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:08:57,344] Trial 272 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.503456\tKL_Divergence = 2.914531\n",
      "Total time elapsed during training: 39.847 s\n",
      "Trial 272 pruned. \n",
      "Epoch: 1\tFidelity = 0.503303\tKL_Divergence = 2.939912\n",
      "Epoch: 2\tFidelity = 0.503202\tKL_Divergence = 2.957116\n",
      "Epoch: 3\tFidelity = 0.504779\tKL_Divergence = 2.734234\n",
      "Epoch: 4\tFidelity = 0.503480\tKL_Divergence = 2.910878\n",
      "Epoch: 5\tFidelity = 0.503120\tKL_Divergence = 2.971545\n",
      "Epoch: 6\tFidelity = 0.502948\tKL_Divergence = 3.003064\n",
      "Epoch: 7\tFidelity = 0.504028\tKL_Divergence = 2.829499\n",
      "Epoch: 8\tFidelity = 0.503189\tKL_Divergence = 2.959489\n",
      "Epoch: 9\tFidelity = 0.503258\tKL_Divergence = 2.947488\n",
      "Epoch: 10\tFidelity = 0.503433\tKL_Divergence = 2.918430\n",
      "Epoch: 11\tFidelity = 0.503597\tKL_Divergence = 2.892573\n",
      "Epoch: 12\tFidelity = 0.503212\tKL_Divergence = 2.955360\n",
      "Epoch: 13\tFidelity = 0.502981\tKL_Divergence = 2.996254\n",
      "Epoch: 14\tFidelity = 0.502850\tKL_Divergence = 3.021061\n",
      "Epoch: 15\tFidelity = 0.502936\tKL_Divergence = 3.004923\n",
      "Epoch: 16\tFidelity = 0.502924\tKL_Divergence = 3.007237\n",
      "Epoch: 17\tFidelity = 0.503364\tKL_Divergence = 2.929750\n",
      "Epoch: 18\tFidelity = 0.502864\tKL_Divergence = 3.019046\n",
      "Epoch: 19\tFidelity = 0.502723\tKL_Divergence = 3.047048\n",
      "Epoch: 20\tFidelity = 0.502910\tKL_Divergence = 3.009496\n",
      "Epoch: 21\tFidelity = 0.502987\tKL_Divergence = 2.995632\n",
      "Epoch: 22\tFidelity = 0.504140\tKL_Divergence = 2.814281\n",
      "Epoch: 23\tFidelity = 0.503879\tKL_Divergence = 2.850445\n",
      "Epoch: 24\tFidelity = 0.503631\tKL_Divergence = 2.887208\n",
      "Epoch: 25\tFidelity = 0.503892\tKL_Divergence = 2.848598\n",
      "Epoch: 26\tFidelity = 0.504146\tKL_Divergence = 2.813344\n",
      "Epoch: 27\tFidelity = 0.503039\tKL_Divergence = 2.986067\n",
      "Epoch: 28\tFidelity = 0.503413\tKL_Divergence = 2.921521\n",
      "Epoch: 29\tFidelity = 0.503380\tKL_Divergence = 2.927115\n",
      "Epoch: 30\tFidelity = 0.502847\tKL_Divergence = 3.022452\n",
      "Epoch: 31\tFidelity = 0.503832\tKL_Divergence = 2.857288\n",
      "Epoch: 32\tFidelity = 0.503207\tKL_Divergence = 2.956311\n",
      "Epoch: 33\tFidelity = 0.503682\tKL_Divergence = 2.879290\n",
      "Epoch: 34\tFidelity = 0.504149\tKL_Divergence = 2.812902\n",
      "Epoch: 35\tFidelity = 0.503519\tKL_Divergence = 2.904447\n",
      "Epoch: 36\tFidelity = 0.503425\tKL_Divergence = 2.919319\n",
      "Epoch: 37\tFidelity = 0.502586\tKL_Divergence = 3.075597\n",
      "Epoch: 38\tFidelity = 0.503570\tKL_Divergence = 2.896513\n",
      "Epoch: 39\tFidelity = 0.503141\tKL_Divergence = 2.967848\n",
      "Epoch: 40\tFidelity = 0.503209\tKL_Divergence = 2.955900\n",
      "Epoch: 41\tFidelity = 0.503595\tKL_Divergence = 2.892767\n",
      "Epoch: 42\tFidelity = 0.502829\tKL_Divergence = 3.026108\n",
      "Epoch: 43\tFidelity = 0.504206\tKL_Divergence = 2.805405\n",
      "Epoch: 44\tFidelity = 0.504299\tKL_Divergence = 2.793197\n",
      "Epoch: 45\tFidelity = 0.503649\tKL_Divergence = 2.883570\n",
      "Epoch: 46\tFidelity = 0.504024\tKL_Divergence = 2.829453\n",
      "Epoch: 47\tFidelity = 0.502731\tKL_Divergence = 3.045161\n",
      "Epoch: 48\tFidelity = 0.502898\tKL_Divergence = 3.011269\n",
      "Epoch: 49\tFidelity = 0.502932\tKL_Divergence = 3.004264\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:09:36,606] Trial 273 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.502964\tKL_Divergence = 2.998838\n",
      "Total time elapsed during training: 39.091 s\n",
      "Trial 273 pruned. \n",
      "Epoch: 1\tFidelity = 0.503399\tKL_Divergence = 2.922868\n",
      "Epoch: 2\tFidelity = 0.503437\tKL_Divergence = 2.916813\n",
      "Epoch: 3\tFidelity = 0.503166\tKL_Divergence = 2.962654\n",
      "Epoch: 4\tFidelity = 0.502964\tKL_Divergence = 2.999664\n",
      "Epoch: 5\tFidelity = 0.503005\tKL_Divergence = 2.992265\n",
      "Epoch: 6\tFidelity = 0.502839\tKL_Divergence = 3.023930\n",
      "Epoch: 7\tFidelity = 0.503097\tKL_Divergence = 2.975717\n",
      "Epoch: 8\tFidelity = 0.503312\tKL_Divergence = 2.938225\n",
      "Epoch: 9\tFidelity = 0.503605\tKL_Divergence = 2.891057\n",
      "Epoch: 10\tFidelity = 0.503371\tKL_Divergence = 2.928366\n",
      "Epoch: 11\tFidelity = 0.502984\tKL_Divergence = 2.996153\n",
      "Epoch: 12\tFidelity = 0.503505\tKL_Divergence = 2.906769\n",
      "Epoch: 13\tFidelity = 0.503593\tKL_Divergence = 2.892955\n",
      "Epoch: 14\tFidelity = 0.503671\tKL_Divergence = 2.881106\n",
      "Epoch: 15\tFidelity = 0.503628\tKL_Divergence = 2.887686\n",
      "Epoch: 16\tFidelity = 0.503306\tKL_Divergence = 2.939429\n",
      "Epoch: 17\tFidelity = 0.503369\tKL_Divergence = 2.928981\n",
      "Epoch: 18\tFidelity = 0.503651\tKL_Divergence = 2.884189\n",
      "Epoch: 19\tFidelity = 0.503457\tKL_Divergence = 2.914655\n",
      "Epoch: 20\tFidelity = 0.503450\tKL_Divergence = 2.915773\n",
      "Epoch: 21\tFidelity = 0.503785\tKL_Divergence = 2.864231\n",
      "Epoch: 22\tFidelity = 0.504075\tKL_Divergence = 2.823097\n",
      "Epoch: 23\tFidelity = 0.503569\tKL_Divergence = 2.896905\n",
      "Epoch: 24\tFidelity = 0.502935\tKL_Divergence = 3.005704\n",
      "Epoch: 25\tFidelity = 0.503084\tKL_Divergence = 2.977981\n",
      "Epoch: 26\tFidelity = 0.503340\tKL_Divergence = 2.933776\n",
      "Epoch: 27\tFidelity = 0.503158\tKL_Divergence = 2.964982\n",
      "Epoch: 28\tFidelity = 0.503065\tKL_Divergence = 2.981577\n",
      "Epoch: 29\tFidelity = 0.503602\tKL_Divergence = 2.891746\n",
      "Epoch: 30\tFidelity = 0.503075\tKL_Divergence = 2.979656\n",
      "Epoch: 31\tFidelity = 0.502742\tKL_Divergence = 3.043394\n",
      "Epoch: 32\tFidelity = 0.503224\tKL_Divergence = 2.953294\n",
      "Epoch: 33\tFidelity = 0.503351\tKL_Divergence = 2.931827\n",
      "Epoch: 34\tFidelity = 0.503246\tKL_Divergence = 2.949635\n",
      "Epoch: 35\tFidelity = 0.503542\tKL_Divergence = 2.901105\n",
      "Epoch: 36\tFidelity = 0.503122\tKL_Divergence = 2.971305\n",
      "Epoch: 37\tFidelity = 0.503391\tKL_Divergence = 2.925307\n",
      "Epoch: 38\tFidelity = 0.502776\tKL_Divergence = 3.036693\n",
      "Epoch: 39\tFidelity = 0.502844\tKL_Divergence = 3.023244\n",
      "Epoch: 40\tFidelity = 0.503084\tKL_Divergence = 2.978067\n",
      "Epoch: 41\tFidelity = 0.503140\tKL_Divergence = 2.968129\n",
      "Epoch: 42\tFidelity = 0.503065\tKL_Divergence = 2.981577\n",
      "Epoch: 43\tFidelity = 0.502922\tKL_Divergence = 3.008142\n",
      "Epoch: 44\tFidelity = 0.503623\tKL_Divergence = 2.888434\n",
      "Epoch: 45\tFidelity = 0.503561\tKL_Divergence = 2.898169\n",
      "Epoch: 46\tFidelity = 0.502947\tKL_Divergence = 3.003326\n",
      "Epoch: 47\tFidelity = 0.503372\tKL_Divergence = 2.928528\n",
      "Epoch: 48\tFidelity = 0.503475\tKL_Divergence = 2.911755\n",
      "Epoch: 49\tFidelity = 0.502786\tKL_Divergence = 3.034667\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:10:16,953] Trial 274 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.503092\tKL_Divergence = 2.976696\n",
      "Total time elapsed during training: 40.184 s\n",
      "Trial 274 pruned. \n",
      "Epoch: 1\tFidelity = 0.503247\tKL_Divergence = 2.949510\n",
      "Epoch: 2\tFidelity = 0.503924\tKL_Divergence = 2.844083\n",
      "Epoch: 3\tFidelity = 0.502694\tKL_Divergence = 3.053340\n",
      "Epoch: 4\tFidelity = 0.503071\tKL_Divergence = 2.980275\n",
      "Epoch: 5\tFidelity = 0.503518\tKL_Divergence = 2.904881\n",
      "Epoch: 6\tFidelity = 0.503248\tKL_Divergence = 2.949329\n",
      "Epoch: 7\tFidelity = 0.502852\tKL_Divergence = 3.021634\n",
      "Epoch: 8\tFidelity = 0.503090\tKL_Divergence = 2.977074\n",
      "Epoch: 9\tFidelity = 0.504323\tKL_Divergence = 2.790192\n",
      "Epoch: 10\tFidelity = 0.503243\tKL_Divergence = 2.950232\n",
      "Epoch: 11\tFidelity = 0.503441\tKL_Divergence = 2.917179\n",
      "Epoch: 12\tFidelity = 0.502788\tKL_Divergence = 3.034251\n",
      "Epoch: 13\tFidelity = 0.503463\tKL_Divergence = 2.913573\n",
      "Epoch: 14\tFidelity = 0.503327\tKL_Divergence = 2.935832\n",
      "Epoch: 15\tFidelity = 0.503475\tKL_Divergence = 2.911697\n",
      "Epoch: 16\tFidelity = 0.502839\tKL_Divergence = 3.024172\n",
      "Epoch: 17\tFidelity = 0.502696\tKL_Divergence = 3.052714\n",
      "Epoch: 18\tFidelity = 0.502924\tKL_Divergence = 3.007126\n",
      "Epoch: 19\tFidelity = 0.502760\tKL_Divergence = 3.039534\n",
      "Epoch: 20\tFidelity = 0.502951\tKL_Divergence = 3.002578\n",
      "Epoch: 21\tFidelity = 0.503035\tKL_Divergence = 2.987052\n",
      "Epoch: 22\tFidelity = 0.503428\tKL_Divergence = 2.919162\n",
      "Epoch: 23\tFidelity = 0.503534\tKL_Divergence = 2.902357\n",
      "Epoch: 24\tFidelity = 0.503699\tKL_Divergence = 2.877033\n",
      "Epoch: 25\tFidelity = 0.502997\tKL_Divergence = 2.994010\n",
      "Epoch: 26\tFidelity = 0.503442\tKL_Divergence = 2.917029\n",
      "Epoch: 27\tFidelity = 0.503175\tKL_Divergence = 2.961738\n",
      "Epoch: 28\tFidelity = 0.503281\tKL_Divergence = 2.943555\n",
      "Epoch: 29\tFidelity = 0.502619\tKL_Divergence = 3.068546\n",
      "Epoch: 30\tFidelity = 0.503560\tKL_Divergence = 2.897983\n",
      "Epoch: 31\tFidelity = 0.503400\tKL_Divergence = 2.923888\n",
      "Epoch: 32\tFidelity = 0.503691\tKL_Divergence = 2.878049\n",
      "Epoch: 33\tFidelity = 0.503475\tKL_Divergence = 2.911635\n",
      "Epoch: 34\tFidelity = 0.503641\tKL_Divergence = 2.885721\n",
      "Epoch: 35\tFidelity = 0.504089\tKL_Divergence = 2.821157\n",
      "Epoch: 36\tFidelity = 0.503948\tKL_Divergence = 2.840586\n",
      "Epoch: 37\tFidelity = 0.502699\tKL_Divergence = 3.051974\n",
      "Epoch: 38\tFidelity = 0.503026\tKL_Divergence = 2.988402\n",
      "Epoch: 39\tFidelity = 0.503483\tKL_Divergence = 2.910166\n",
      "Epoch: 40\tFidelity = 0.503180\tKL_Divergence = 2.960461\n",
      "Epoch: 41\tFidelity = 0.503074\tKL_Divergence = 2.979583\n",
      "Epoch: 42\tFidelity = 0.503270\tKL_Divergence = 2.945138\n",
      "Epoch: 43\tFidelity = 0.503461\tKL_Divergence = 2.913429\n",
      "Epoch: 44\tFidelity = 0.503931\tKL_Divergence = 2.842825\n",
      "Epoch: 45\tFidelity = 0.503701\tKL_Divergence = 2.876374\n",
      "Epoch: 46\tFidelity = 0.503198\tKL_Divergence = 2.957516\n",
      "Epoch: 47\tFidelity = 0.503180\tKL_Divergence = 2.960693\n",
      "Epoch: 48\tFidelity = 0.503078\tKL_Divergence = 2.979126\n",
      "Epoch: 49\tFidelity = 0.502722\tKL_Divergence = 3.047370\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:11:03,767] Trial 275 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.503580\tKL_Divergence = 2.894939\n",
      "Total time elapsed during training: 46.647 s\n",
      "Trial 275 pruned. \n",
      "Epoch: 1\tFidelity = 0.503812\tKL_Divergence = 2.859992\n",
      "Epoch: 2\tFidelity = 0.503425\tKL_Divergence = 2.919638\n",
      "Epoch: 3\tFidelity = 0.503185\tKL_Divergence = 2.960080\n",
      "Epoch: 4\tFidelity = 0.503190\tKL_Divergence = 2.959159\n",
      "Epoch: 5\tFidelity = 0.503116\tKL_Divergence = 2.972266\n",
      "Epoch: 6\tFidelity = 0.502604\tKL_Divergence = 3.072080\n",
      "Epoch: 7\tFidelity = 0.503529\tKL_Divergence = 2.903048\n",
      "Epoch: 8\tFidelity = 0.503810\tKL_Divergence = 2.860370\n",
      "Epoch: 9\tFidelity = 0.503257\tKL_Divergence = 2.947615\n",
      "Epoch: 10\tFidelity = 0.503315\tKL_Divergence = 2.937771\n",
      "Epoch: 11\tFidelity = 0.503581\tKL_Divergence = 2.894888\n",
      "Epoch: 12\tFidelity = 0.503230\tKL_Divergence = 2.952249\n",
      "Epoch: 13\tFidelity = 0.503186\tKL_Divergence = 2.959955\n",
      "Epoch: 14\tFidelity = 0.502917\tKL_Divergence = 3.008951\n",
      "Epoch: 15\tFidelity = 0.503773\tKL_Divergence = 2.865933\n",
      "Epoch: 16\tFidelity = 0.504191\tKL_Divergence = 2.807320\n",
      "Epoch: 17\tFidelity = 0.503971\tKL_Divergence = 2.837401\n",
      "Epoch: 18\tFidelity = 0.503460\tKL_Divergence = 2.913988\n",
      "Epoch: 19\tFidelity = 0.503266\tKL_Divergence = 2.946011\n",
      "Epoch: 20\tFidelity = 0.503043\tKL_Divergence = 2.985402\n",
      "Epoch: 21\tFidelity = 0.503404\tKL_Divergence = 2.923033\n",
      "Epoch: 22\tFidelity = 0.503138\tKL_Divergence = 2.968315\n",
      "Epoch: 23\tFidelity = 0.503390\tKL_Divergence = 2.925390\n",
      "Epoch: 24\tFidelity = 0.503239\tKL_Divergence = 2.950651\n",
      "Epoch: 25\tFidelity = 0.502740\tKL_Divergence = 3.043740\n",
      "Epoch: 26\tFidelity = 0.502698\tKL_Divergence = 3.052379\n",
      "Epoch: 27\tFidelity = 0.502684\tKL_Divergence = 3.055232\n",
      "Epoch: 28\tFidelity = 0.502455\tKL_Divergence = 3.104872\n",
      "Epoch: 29\tFidelity = 0.503372\tKL_Divergence = 2.928370\n",
      "Epoch: 30\tFidelity = 0.502910\tKL_Divergence = 3.010415\n",
      "Epoch: 31\tFidelity = 0.502993\tKL_Divergence = 2.994633\n",
      "Epoch: 32\tFidelity = 0.503478\tKL_Divergence = 2.911189\n",
      "Epoch: 33\tFidelity = 0.502822\tKL_Divergence = 3.027337\n",
      "Epoch: 34\tFidelity = 0.503839\tKL_Divergence = 2.856166\n",
      "Epoch: 35\tFidelity = 0.503868\tKL_Divergence = 2.852015\n",
      "Epoch: 36\tFidelity = 0.502913\tKL_Divergence = 3.009767\n",
      "Epoch: 37\tFidelity = 0.502907\tKL_Divergence = 3.010861\n",
      "Epoch: 38\tFidelity = 0.502655\tKL_Divergence = 3.061285\n",
      "Epoch: 39\tFidelity = 0.503316\tKL_Divergence = 2.937772\n",
      "Epoch: 40\tFidelity = 0.503275\tKL_Divergence = 2.944596\n",
      "Epoch: 41\tFidelity = 0.503264\tKL_Divergence = 2.946577\n",
      "Epoch: 42\tFidelity = 0.503842\tKL_Divergence = 2.855847\n",
      "Epoch: 43\tFidelity = 0.502755\tKL_Divergence = 3.040771\n",
      "Epoch: 44\tFidelity = 0.503233\tKL_Divergence = 2.951715\n",
      "Epoch: 45\tFidelity = 0.503220\tKL_Divergence = 2.954055\n",
      "Epoch: 46\tFidelity = 0.503830\tKL_Divergence = 2.857481\n",
      "Epoch: 47\tFidelity = 0.503410\tKL_Divergence = 2.922069\n",
      "Epoch: 48\tFidelity = 0.503482\tKL_Divergence = 2.910537\n",
      "Epoch: 49\tFidelity = 0.503005\tKL_Divergence = 2.992364\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:11:43,816] Trial 276 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.503031\tKL_Divergence = 2.987660\n",
      "Total time elapsed during training: 39.885 s\n",
      "Trial 276 pruned. \n",
      "Epoch: 1\tFidelity = 0.503551\tKL_Divergence = 2.899496\n",
      "Epoch: 2\tFidelity = 0.503350\tKL_Divergence = 2.931949\n",
      "Epoch: 3\tFidelity = 0.503678\tKL_Divergence = 2.879931\n",
      "Epoch: 4\tFidelity = 0.503704\tKL_Divergence = 2.876047\n",
      "Epoch: 5\tFidelity = 0.503545\tKL_Divergence = 2.900516\n",
      "Epoch: 6\tFidelity = 0.503304\tKL_Divergence = 2.939601\n",
      "Epoch: 7\tFidelity = 0.503514\tKL_Divergence = 2.905349\n",
      "Epoch: 8\tFidelity = 0.503177\tKL_Divergence = 2.961470\n",
      "Epoch: 9\tFidelity = 0.503723\tKL_Divergence = 2.873284\n",
      "Epoch: 10\tFidelity = 0.503558\tKL_Divergence = 2.898551\n",
      "Epoch: 11\tFidelity = 0.503225\tKL_Divergence = 2.953055\n",
      "Epoch: 12\tFidelity = 0.503147\tKL_Divergence = 2.966804\n",
      "Epoch: 13\tFidelity = 0.503451\tKL_Divergence = 2.915417\n",
      "Epoch: 14\tFidelity = 0.503891\tKL_Divergence = 2.848706\n",
      "Epoch: 15\tFidelity = 0.503197\tKL_Divergence = 2.958046\n",
      "Epoch: 16\tFidelity = 0.503396\tKL_Divergence = 2.924441\n",
      "Epoch: 17\tFidelity = 0.503169\tKL_Divergence = 2.962899\n",
      "Epoch: 18\tFidelity = 0.503167\tKL_Divergence = 2.963221\n",
      "Epoch: 19\tFidelity = 0.503667\tKL_Divergence = 2.881635\n",
      "Epoch: 20\tFidelity = 0.503417\tKL_Divergence = 2.921056\n",
      "Epoch: 21\tFidelity = 0.503455\tKL_Divergence = 2.914881\n",
      "Epoch: 22\tFidelity = 0.503175\tKL_Divergence = 2.961868\n",
      "Epoch: 23\tFidelity = 0.503527\tKL_Divergence = 2.903362\n",
      "Epoch: 24\tFidelity = 0.503715\tKL_Divergence = 2.874524\n",
      "Epoch: 25\tFidelity = 0.503259\tKL_Divergence = 2.947290\n",
      "Epoch: 26\tFidelity = 0.503039\tKL_Divergence = 2.986215\n",
      "Epoch: 27\tFidelity = 0.503004\tKL_Divergence = 2.992697\n",
      "Epoch: 28\tFidelity = 0.502916\tKL_Divergence = 3.009212\n",
      "Epoch: 29\tFidelity = 0.503286\tKL_Divergence = 2.942782\n",
      "Epoch: 30\tFidelity = 0.503251\tKL_Divergence = 2.948730\n",
      "Epoch: 31\tFidelity = 0.502919\tKL_Divergence = 3.008449\n",
      "Epoch: 32\tFidelity = 0.503790\tKL_Divergence = 2.863291\n",
      "Epoch: 33\tFidelity = 0.503481\tKL_Divergence = 2.910576\n",
      "Epoch: 34\tFidelity = 0.503448\tKL_Divergence = 2.915887\n",
      "Epoch: 35\tFidelity = 0.503246\tKL_Divergence = 2.949439\n",
      "Epoch: 36\tFidelity = 0.503236\tKL_Divergence = 2.951186\n",
      "Epoch: 37\tFidelity = 0.503632\tKL_Divergence = 2.887029\n",
      "Epoch: 38\tFidelity = 0.503034\tKL_Divergence = 2.987043\n",
      "Epoch: 39\tFidelity = 0.503106\tKL_Divergence = 2.973958\n",
      "Epoch: 40\tFidelity = 0.502964\tKL_Divergence = 3.000025\n",
      "Epoch: 41\tFidelity = 0.503483\tKL_Divergence = 2.910252\n",
      "Epoch: 42\tFidelity = 0.503634\tKL_Divergence = 2.886674\n",
      "Epoch: 43\tFidelity = 0.503384\tKL_Divergence = 2.926256\n",
      "Epoch: 44\tFidelity = 0.503153\tKL_Divergence = 2.965679\n",
      "Epoch: 45\tFidelity = 0.503241\tKL_Divergence = 2.950413\n",
      "Epoch: 46\tFidelity = 0.503648\tKL_Divergence = 2.884527\n",
      "Epoch: 47\tFidelity = 0.502804\tKL_Divergence = 3.030858\n",
      "Epoch: 48\tFidelity = 0.503261\tKL_Divergence = 2.947000\n",
      "Epoch: 49\tFidelity = 0.502868\tKL_Divergence = 3.018286\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:13:08,746] Trial 277 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.503022\tKL_Divergence = 2.989348\n",
      "Total time elapsed during training: 84.763 s\n",
      "Trial 277 pruned. \n",
      "Epoch: 1\tFidelity = 0.503301\tKL_Divergence = 2.940217\n",
      "Epoch: 2\tFidelity = 0.503203\tKL_Divergence = 2.957006\n",
      "Epoch: 3\tFidelity = 0.503237\tKL_Divergence = 2.950992\n",
      "Epoch: 4\tFidelity = 0.503237\tKL_Divergence = 2.951082\n",
      "Epoch: 5\tFidelity = 0.503304\tKL_Divergence = 2.939608\n",
      "Epoch: 6\tFidelity = 0.503224\tKL_Divergence = 2.953216\n",
      "Epoch: 7\tFidelity = 0.503486\tKL_Divergence = 2.909875\n",
      "Epoch: 8\tFidelity = 0.503336\tKL_Divergence = 2.934387\n",
      "Epoch: 9\tFidelity = 0.503118\tKL_Divergence = 2.971873\n",
      "Epoch: 10\tFidelity = 0.503312\tKL_Divergence = 2.938331\n",
      "Epoch: 11\tFidelity = 0.503211\tKL_Divergence = 2.955510\n",
      "Epoch: 12\tFidelity = 0.503034\tKL_Divergence = 2.987100\n",
      "Epoch: 13\tFidelity = 0.503260\tKL_Divergence = 2.947183\n",
      "Epoch: 14\tFidelity = 0.503341\tKL_Divergence = 2.933469\n",
      "Epoch: 15\tFidelity = 0.503196\tKL_Divergence = 2.958109\n",
      "Epoch: 16\tFidelity = 0.503457\tKL_Divergence = 2.914542\n",
      "Epoch: 17\tFidelity = 0.503419\tKL_Divergence = 2.920619\n",
      "Epoch: 18\tFidelity = 0.503314\tKL_Divergence = 2.938050\n",
      "Epoch: 19\tFidelity = 0.503087\tKL_Divergence = 2.977406\n",
      "Epoch: 20\tFidelity = 0.503320\tKL_Divergence = 2.937046\n",
      "Epoch: 21\tFidelity = 0.503291\tKL_Divergence = 2.941921\n",
      "Epoch: 22\tFidelity = 0.503514\tKL_Divergence = 2.905425\n",
      "Epoch: 23\tFidelity = 0.503354\tKL_Divergence = 2.931262\n",
      "Epoch: 24\tFidelity = 0.503095\tKL_Divergence = 2.976102\n",
      "Epoch: 25\tFidelity = 0.503223\tKL_Divergence = 2.953449\n",
      "Epoch: 26\tFidelity = 0.503433\tKL_Divergence = 2.918452\n",
      "Epoch: 27\tFidelity = 0.503344\tKL_Divergence = 2.932969\n",
      "Epoch: 28\tFidelity = 0.503257\tKL_Divergence = 2.947620\n",
      "Epoch: 29\tFidelity = 0.503436\tKL_Divergence = 2.917954\n",
      "Epoch: 30\tFidelity = 0.503161\tKL_Divergence = 2.964275\n",
      "Epoch: 31\tFidelity = 0.503458\tKL_Divergence = 2.914417\n",
      "Epoch: 32\tFidelity = 0.503225\tKL_Divergence = 2.953243\n",
      "Epoch: 33\tFidelity = 0.503295\tKL_Divergence = 2.941284\n",
      "Epoch: 34\tFidelity = 0.503514\tKL_Divergence = 2.905496\n",
      "Epoch: 35\tFidelity = 0.503181\tKL_Divergence = 2.960830\n",
      "Epoch: 36\tFidelity = 0.503413\tKL_Divergence = 2.921591\n",
      "Epoch: 37\tFidelity = 0.503402\tKL_Divergence = 2.923416\n",
      "Epoch: 38\tFidelity = 0.503319\tKL_Divergence = 2.937170\n",
      "Epoch: 39\tFidelity = 0.503267\tKL_Divergence = 2.945945\n",
      "Epoch: 40\tFidelity = 0.503299\tKL_Divergence = 2.940478\n",
      "Epoch: 41\tFidelity = 0.503193\tKL_Divergence = 2.958732\n",
      "Epoch: 42\tFidelity = 0.503034\tKL_Divergence = 2.987030\n",
      "Epoch: 43\tFidelity = 0.503192\tKL_Divergence = 2.958918\n",
      "Epoch: 44\tFidelity = 0.503240\tKL_Divergence = 2.950560\n",
      "Epoch: 45\tFidelity = 0.503331\tKL_Divergence = 2.935172\n",
      "Epoch: 46\tFidelity = 0.503210\tKL_Divergence = 2.955834\n",
      "Epoch: 47\tFidelity = 0.503178\tKL_Divergence = 2.961318\n",
      "Epoch: 48\tFidelity = 0.503389\tKL_Divergence = 2.925522\n",
      "Epoch: 49\tFidelity = 0.503057\tKL_Divergence = 2.982939\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:13:41,584] Trial 278 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.503175\tKL_Divergence = 2.961877\n",
      "Total time elapsed during training: 32.666 s\n",
      "Trial 278 pruned. \n",
      "Epoch: 1\tFidelity = 0.503463\tKL_Divergence = 2.913097\n",
      "Epoch: 2\tFidelity = 0.503277\tKL_Divergence = 2.944085\n",
      "Epoch: 3\tFidelity = 0.503090\tKL_Divergence = 2.976502\n",
      "Epoch: 4\tFidelity = 0.502690\tKL_Divergence = 3.053733\n",
      "Epoch: 5\tFidelity = 0.502926\tKL_Divergence = 3.006701\n",
      "Epoch: 6\tFidelity = 0.503528\tKL_Divergence = 2.902848\n",
      "Epoch: 7\tFidelity = 0.503479\tKL_Divergence = 2.910146\n",
      "Epoch: 8\tFidelity = 0.503526\tKL_Divergence = 2.902828\n",
      "Epoch: 9\tFidelity = 0.503337\tKL_Divergence = 2.933837\n",
      "Epoch: 10\tFidelity = 0.503246\tKL_Divergence = 2.948959\n",
      "Epoch: 11\tFidelity = 0.503634\tKL_Divergence = 2.886658\n",
      "Epoch: 12\tFidelity = 0.503073\tKL_Divergence = 2.979903\n",
      "Epoch: 13\tFidelity = 0.503158\tKL_Divergence = 2.964848\n",
      "Epoch: 14\tFidelity = 0.502653\tKL_Divergence = 3.061656\n",
      "Epoch: 15\tFidelity = 0.503087\tKL_Divergence = 2.977416\n",
      "Epoch: 16\tFidelity = 0.503506\tKL_Divergence = 2.906655\n",
      "Epoch: 17\tFidelity = 0.503476\tKL_Divergence = 2.911263\n",
      "Epoch: 18\tFidelity = 0.502752\tKL_Divergence = 3.040678\n",
      "Epoch: 19\tFidelity = 0.503251\tKL_Divergence = 2.948245\n",
      "Epoch: 20\tFidelity = 0.503215\tKL_Divergence = 2.954217\n",
      "Epoch: 21\tFidelity = 0.503666\tKL_Divergence = 2.881298\n",
      "Epoch: 22\tFidelity = 0.504052\tKL_Divergence = 2.825929\n",
      "Epoch: 23\tFidelity = 0.502911\tKL_Divergence = 3.010001\n",
      "Epoch: 24\tFidelity = 0.503206\tKL_Divergence = 2.956005\n",
      "Epoch: 25\tFidelity = 0.503010\tKL_Divergence = 2.990483\n",
      "Epoch: 26\tFidelity = 0.502834\tKL_Divergence = 3.024128\n",
      "Epoch: 27\tFidelity = 0.502989\tKL_Divergence = 2.995212\n",
      "Epoch: 28\tFidelity = 0.503652\tKL_Divergence = 2.883962\n",
      "Epoch: 29\tFidelity = 0.503307\tKL_Divergence = 2.939167\n",
      "Epoch: 30\tFidelity = 0.503761\tKL_Divergence = 2.867334\n",
      "Epoch: 31\tFidelity = 0.504016\tKL_Divergence = 2.830513\n",
      "Epoch: 32\tFidelity = 0.503052\tKL_Divergence = 2.983229\n",
      "Epoch: 33\tFidelity = 0.503176\tKL_Divergence = 2.960801\n",
      "Epoch: 34\tFidelity = 0.503598\tKL_Divergence = 2.891991\n",
      "Epoch: 35\tFidelity = 0.502980\tKL_Divergence = 2.997127\n",
      "Epoch: 36\tFidelity = 0.502664\tKL_Divergence = 3.059538\n",
      "Epoch: 37\tFidelity = 0.502568\tKL_Divergence = 3.079774\n",
      "Epoch: 38\tFidelity = 0.503511\tKL_Divergence = 2.905594\n",
      "Epoch: 39\tFidelity = 0.503571\tKL_Divergence = 2.895641\n",
      "Epoch: 40\tFidelity = 0.502917\tKL_Divergence = 3.008395\n",
      "Epoch: 41\tFidelity = 0.503349\tKL_Divergence = 2.931542\n",
      "Epoch: 42\tFidelity = 0.503628\tKL_Divergence = 2.886338\n",
      "Epoch: 43\tFidelity = 0.502860\tKL_Divergence = 3.018963\n",
      "Epoch: 44\tFidelity = 0.502624\tKL_Divergence = 3.067011\n",
      "Epoch: 45\tFidelity = 0.503130\tKL_Divergence = 2.968444\n",
      "Epoch: 46\tFidelity = 0.503088\tKL_Divergence = 2.974810\n",
      "Epoch: 47\tFidelity = 0.503470\tKL_Divergence = 2.911546\n",
      "Epoch: 48\tFidelity = 0.503754\tKL_Divergence = 2.867648\n",
      "Epoch: 49\tFidelity = 0.503605\tKL_Divergence = 2.890656\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:14:21,034] Trial 279 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.503753\tKL_Divergence = 2.867883\n",
      "Total time elapsed during training: 39.288 s\n",
      "Trial 279 pruned. \n",
      "Epoch: 1\tFidelity = 0.502989\tKL_Divergence = 2.994666\n",
      "Epoch: 2\tFidelity = 0.503150\tKL_Divergence = 2.965546\n",
      "Epoch: 3\tFidelity = 0.502929\tKL_Divergence = 3.006202\n",
      "Epoch: 4\tFidelity = 0.503199\tKL_Divergence = 2.957171\n",
      "Epoch: 5\tFidelity = 0.502936\tKL_Divergence = 3.004869\n",
      "Epoch: 6\tFidelity = 0.503388\tKL_Divergence = 2.925446\n",
      "Epoch: 7\tFidelity = 0.503005\tKL_Divergence = 2.992084\n",
      "Epoch: 8\tFidelity = 0.503380\tKL_Divergence = 2.926806\n",
      "Epoch: 9\tFidelity = 0.502830\tKL_Divergence = 3.025507\n",
      "Epoch: 10\tFidelity = 0.503429\tKL_Divergence = 2.918790\n",
      "Epoch: 11\tFidelity = 0.502995\tKL_Divergence = 2.994107\n",
      "Epoch: 12\tFidelity = 0.503461\tKL_Divergence = 2.913692\n",
      "Epoch: 13\tFidelity = 0.503030\tKL_Divergence = 2.987696\n",
      "Epoch: 14\tFidelity = 0.503402\tKL_Divergence = 2.923352\n",
      "Epoch: 15\tFidelity = 0.502883\tKL_Divergence = 3.015410\n",
      "Epoch: 16\tFidelity = 0.503437\tKL_Divergence = 2.917751\n",
      "Epoch: 17\tFidelity = 0.502744\tKL_Divergence = 3.042908\n",
      "Epoch: 18\tFidelity = 0.503706\tKL_Divergence = 2.875732\n",
      "Epoch: 19\tFidelity = 0.502799\tKL_Divergence = 3.031875\n",
      "Epoch: 20\tFidelity = 0.503239\tKL_Divergence = 2.950835\n",
      "Epoch: 21\tFidelity = 0.502870\tKL_Divergence = 3.017961\n",
      "Epoch: 22\tFidelity = 0.503425\tKL_Divergence = 2.919748\n",
      "Epoch: 23\tFidelity = 0.502807\tKL_Divergence = 3.030420\n",
      "Epoch: 24\tFidelity = 0.503432\tKL_Divergence = 2.918513\n",
      "Epoch: 25\tFidelity = 0.502814\tKL_Divergence = 3.028951\n",
      "Epoch: 26\tFidelity = 0.503500\tKL_Divergence = 2.907644\n",
      "Epoch: 27\tFidelity = 0.502794\tKL_Divergence = 3.033068\n",
      "Epoch: 28\tFidelity = 0.503377\tKL_Divergence = 2.927560\n",
      "Epoch: 29\tFidelity = 0.502773\tKL_Divergence = 3.037085\n",
      "Epoch: 30\tFidelity = 0.503457\tKL_Divergence = 2.914593\n",
      "Epoch: 31\tFidelity = 0.502838\tKL_Divergence = 3.024359\n",
      "Epoch: 32\tFidelity = 0.503601\tKL_Divergence = 2.891870\n",
      "Epoch: 33\tFidelity = 0.503001\tKL_Divergence = 2.993193\n",
      "Epoch: 34\tFidelity = 0.503167\tKL_Divergence = 2.963269\n",
      "Epoch: 35\tFidelity = 0.503065\tKL_Divergence = 2.981609\n",
      "Epoch: 36\tFidelity = 0.503214\tKL_Divergence = 2.955073\n",
      "Epoch: 37\tFidelity = 0.503089\tKL_Divergence = 2.977292\n",
      "Epoch: 38\tFidelity = 0.503129\tKL_Divergence = 2.969975\n",
      "Epoch: 39\tFidelity = 0.503159\tKL_Divergence = 2.964794\n",
      "Epoch: 40\tFidelity = 0.503176\tKL_Divergence = 2.961778\n",
      "Epoch: 41\tFidelity = 0.503001\tKL_Divergence = 2.993335\n",
      "Epoch: 42\tFidelity = 0.502966\tKL_Divergence = 2.999740\n",
      "Epoch: 43\tFidelity = 0.503121\tKL_Divergence = 2.971430\n",
      "Epoch: 44\tFidelity = 0.502940\tKL_Divergence = 3.004641\n",
      "Epoch: 45\tFidelity = 0.503309\tKL_Divergence = 2.938910\n",
      "Epoch: 46\tFidelity = 0.502890\tKL_Divergence = 3.014236\n",
      "Epoch: 47\tFidelity = 0.502886\tKL_Divergence = 3.015012\n",
      "Epoch: 48\tFidelity = 0.503323\tKL_Divergence = 2.936574\n",
      "Epoch: 49\tFidelity = 0.502941\tKL_Divergence = 3.004617\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:14:53,528] Trial 280 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.503525\tKL_Divergence = 2.903876\n",
      "Total time elapsed during training: 32.324 s\n",
      "Trial 280 pruned. \n",
      "Epoch: 1\tFidelity = 0.502926\tKL_Divergence = 3.007342\n",
      "Epoch: 2\tFidelity = 0.503197\tKL_Divergence = 2.958131\n",
      "Epoch: 3\tFidelity = 0.502894\tKL_Divergence = 3.013562\n",
      "Epoch: 4\tFidelity = 0.503197\tKL_Divergence = 2.958132\n",
      "Epoch: 5\tFidelity = 0.502718\tKL_Divergence = 3.048383\n",
      "Epoch: 6\tFidelity = 0.503208\tKL_Divergence = 2.956234\n",
      "Epoch: 7\tFidelity = 0.502654\tKL_Divergence = 3.061503\n",
      "Epoch: 8\tFidelity = 0.502307\tKL_Divergence = 3.139314\n",
      "Epoch: 9\tFidelity = 0.503053\tKL_Divergence = 2.983714\n",
      "Epoch: 10\tFidelity = 0.503303\tKL_Divergence = 2.939912\n",
      "Epoch: 11\tFidelity = 0.503146\tKL_Divergence = 2.967049\n",
      "Epoch: 12\tFidelity = 0.503003\tKL_Divergence = 2.992937\n",
      "Epoch: 13\tFidelity = 0.503147\tKL_Divergence = 2.966772\n",
      "Epoch: 14\tFidelity = 0.502792\tKL_Divergence = 3.033286\n",
      "Epoch: 15\tFidelity = 0.503048\tKL_Divergence = 2.984567\n",
      "Epoch: 16\tFidelity = 0.503164\tKL_Divergence = 2.963811\n",
      "Epoch: 17\tFidelity = 0.502959\tKL_Divergence = 3.001074\n",
      "Epoch: 18\tFidelity = 0.503118\tKL_Divergence = 2.971923\n",
      "Epoch: 19\tFidelity = 0.503506\tKL_Divergence = 2.906705\n",
      "Epoch: 20\tFidelity = 0.503168\tKL_Divergence = 2.963192\n",
      "Epoch: 21\tFidelity = 0.503505\tKL_Divergence = 2.907031\n",
      "Epoch: 22\tFidelity = 0.503783\tKL_Divergence = 2.864486\n",
      "Epoch: 23\tFidelity = 0.503523\tKL_Divergence = 2.904056\n",
      "Epoch: 24\tFidelity = 0.503783\tKL_Divergence = 2.864483\n",
      "Epoch: 25\tFidelity = 0.503405\tKL_Divergence = 2.923017\n",
      "Epoch: 26\tFidelity = 0.503433\tKL_Divergence = 2.918575\n",
      "Epoch: 27\tFidelity = 0.503094\tKL_Divergence = 2.976312\n",
      "Epoch: 28\tFidelity = 0.503276\tKL_Divergence = 2.944617\n",
      "Epoch: 29\tFidelity = 0.503128\tKL_Divergence = 2.970271\n",
      "Epoch: 30\tFidelity = 0.503398\tKL_Divergence = 2.924179\n",
      "Epoch: 31\tFidelity = 0.502909\tKL_Divergence = 3.010688\n",
      "Epoch: 32\tFidelity = 0.502984\tKL_Divergence = 2.996530\n",
      "Epoch: 33\tFidelity = 0.503735\tKL_Divergence = 2.871693\n",
      "Epoch: 34\tFidelity = 0.502971\tKL_Divergence = 2.998902\n",
      "Epoch: 35\tFidelity = 0.503369\tKL_Divergence = 2.929137\n",
      "Epoch: 36\tFidelity = 0.503480\tKL_Divergence = 2.911045\n",
      "Epoch: 37\tFidelity = 0.502673\tKL_Divergence = 3.057810\n",
      "Epoch: 38\tFidelity = 0.502618\tKL_Divergence = 3.069172\n",
      "Epoch: 39\tFidelity = 0.503145\tKL_Divergence = 2.967242\n",
      "Epoch: 40\tFidelity = 0.502764\tKL_Divergence = 3.039153\n",
      "Epoch: 41\tFidelity = 0.503131\tKL_Divergence = 2.969700\n",
      "Epoch: 42\tFidelity = 0.502873\tKL_Divergence = 3.017539\n",
      "Epoch: 43\tFidelity = 0.503381\tKL_Divergence = 2.927147\n",
      "Epoch: 44\tFidelity = 0.502869\tKL_Divergence = 3.018412\n",
      "Epoch: 45\tFidelity = 0.503031\tKL_Divergence = 2.987953\n",
      "Epoch: 46\tFidelity = 0.503171\tKL_Divergence = 2.962853\n",
      "Epoch: 47\tFidelity = 0.503118\tKL_Divergence = 2.972051\n",
      "Epoch: 48\tFidelity = 0.503071\tKL_Divergence = 2.980627\n",
      "Epoch: 49\tFidelity = 0.502666\tKL_Divergence = 3.059267\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:15:41,193] Trial 281 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.503033\tKL_Divergence = 2.987500\n",
      "Total time elapsed during training: 47.497 s\n",
      "Trial 281 pruned. \n",
      "Epoch: 1\tFidelity = 0.503038\tKL_Divergence = 2.986701\n",
      "Epoch: 2\tFidelity = 0.502861\tKL_Divergence = 3.019986\n",
      "Epoch: 3\tFidelity = 0.502399\tKL_Divergence = 3.117789\n",
      "Epoch: 4\tFidelity = 0.502700\tKL_Divergence = 3.052301\n",
      "Epoch: 5\tFidelity = 0.502814\tKL_Divergence = 3.029175\n",
      "Epoch: 6\tFidelity = 0.503134\tKL_Divergence = 2.969217\n",
      "Epoch: 7\tFidelity = 0.502719\tKL_Divergence = 3.048217\n",
      "Epoch: 8\tFidelity = 0.503376\tKL_Divergence = 2.927983\n",
      "Epoch: 9\tFidelity = 0.503045\tKL_Divergence = 2.985358\n",
      "Epoch: 10\tFidelity = 0.503170\tKL_Divergence = 2.962882\n",
      "Epoch: 11\tFidelity = 0.503115\tKL_Divergence = 2.972576\n",
      "Epoch: 12\tFidelity = 0.502813\tKL_Divergence = 3.029287\n",
      "Epoch: 13\tFidelity = 0.502662\tKL_Divergence = 3.060093\n",
      "Epoch: 14\tFidelity = 0.503132\tKL_Divergence = 2.969667\n",
      "Epoch: 15\tFidelity = 0.502691\tKL_Divergence = 3.053969\n",
      "Epoch: 16\tFidelity = 0.503007\tKL_Divergence = 2.992225\n",
      "Epoch: 17\tFidelity = 0.503025\tKL_Divergence = 2.988777\n",
      "Epoch: 18\tFidelity = 0.503229\tKL_Divergence = 2.952600\n",
      "Epoch: 19\tFidelity = 0.503011\tKL_Divergence = 2.991597\n",
      "Epoch: 20\tFidelity = 0.502594\tKL_Divergence = 3.074393\n",
      "Epoch: 21\tFidelity = 0.502886\tKL_Divergence = 3.015044\n",
      "Epoch: 22\tFidelity = 0.503122\tKL_Divergence = 2.971330\n",
      "Epoch: 23\tFidelity = 0.503348\tKL_Divergence = 2.932486\n",
      "Epoch: 24\tFidelity = 0.503262\tKL_Divergence = 2.946943\n",
      "Epoch: 25\tFidelity = 0.503030\tKL_Divergence = 2.987955\n",
      "Epoch: 26\tFidelity = 0.502760\tKL_Divergence = 3.039784\n",
      "Epoch: 27\tFidelity = 0.502613\tKL_Divergence = 3.070252\n",
      "Epoch: 28\tFidelity = 0.502728\tKL_Divergence = 3.046423\n",
      "Epoch: 29\tFidelity = 0.503302\tKL_Divergence = 2.940224\n",
      "Epoch: 30\tFidelity = 0.503033\tKL_Divergence = 2.987412\n",
      "Epoch: 31\tFidelity = 0.502484\tKL_Divergence = 3.098507\n",
      "Epoch: 32\tFidelity = 0.502280\tKL_Divergence = 3.146096\n",
      "Epoch: 33\tFidelity = 0.503045\tKL_Divergence = 2.985207\n",
      "Epoch: 34\tFidelity = 0.502673\tKL_Divergence = 3.057789\n",
      "Epoch: 35\tFidelity = 0.502887\tKL_Divergence = 3.014870\n",
      "Epoch: 36\tFidelity = 0.502768\tKL_Divergence = 3.038310\n",
      "Epoch: 37\tFidelity = 0.503139\tKL_Divergence = 2.968314\n",
      "Epoch: 38\tFidelity = 0.502751\tKL_Divergence = 3.041693\n",
      "Epoch: 39\tFidelity = 0.502761\tKL_Divergence = 3.039785\n",
      "Epoch: 40\tFidelity = 0.502570\tKL_Divergence = 3.079642\n",
      "Epoch: 41\tFidelity = 0.503075\tKL_Divergence = 2.979827\n",
      "Epoch: 42\tFidelity = 0.502949\tKL_Divergence = 3.002985\n",
      "Epoch: 43\tFidelity = 0.503192\tKL_Divergence = 2.959078\n",
      "Epoch: 44\tFidelity = 0.503065\tKL_Divergence = 2.981571\n",
      "Epoch: 45\tFidelity = 0.502826\tKL_Divergence = 3.026691\n",
      "Epoch: 46\tFidelity = 0.502904\tKL_Divergence = 3.011668\n",
      "Epoch: 47\tFidelity = 0.502954\tKL_Divergence = 3.002201\n",
      "Epoch: 48\tFidelity = 0.503211\tKL_Divergence = 2.955795\n",
      "Epoch: 49\tFidelity = 0.502609\tKL_Divergence = 3.071170\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:16:42,511] Trial 282 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.502750\tKL_Divergence = 3.041850\n",
      "Total time elapsed during training: 61.158 s\n",
      "Trial 282 pruned. \n",
      "Epoch: 1\tFidelity = 0.502651\tKL_Divergence = 3.062334\n",
      "Epoch: 2\tFidelity = 0.502911\tKL_Divergence = 3.010210\n",
      "Epoch: 3\tFidelity = 0.503259\tKL_Divergence = 2.947515\n",
      "Epoch: 4\tFidelity = 0.502857\tKL_Divergence = 3.020750\n",
      "Epoch: 5\tFidelity = 0.502766\tKL_Divergence = 3.038646\n",
      "Epoch: 6\tFidelity = 0.503066\tKL_Divergence = 2.981441\n",
      "Epoch: 7\tFidelity = 0.502700\tKL_Divergence = 3.052211\n",
      "Epoch: 8\tFidelity = 0.502624\tKL_Divergence = 3.068077\n",
      "Epoch: 9\tFidelity = 0.502815\tKL_Divergence = 3.028891\n",
      "Epoch: 10\tFidelity = 0.502601\tKL_Divergence = 3.072917\n",
      "Epoch: 11\tFidelity = 0.502424\tKL_Divergence = 3.111979\n",
      "Epoch: 12\tFidelity = 0.502877\tKL_Divergence = 3.016816\n",
      "Epoch: 13\tFidelity = 0.502950\tKL_Divergence = 3.002969\n",
      "Epoch: 14\tFidelity = 0.502862\tKL_Divergence = 3.019722\n",
      "Epoch: 15\tFidelity = 0.502782\tKL_Divergence = 3.035517\n",
      "Epoch: 16\tFidelity = 0.502673\tKL_Divergence = 3.057778\n",
      "Epoch: 17\tFidelity = 0.503029\tKL_Divergence = 2.988121\n",
      "Epoch: 18\tFidelity = 0.502750\tKL_Divergence = 3.041900\n",
      "Epoch: 19\tFidelity = 0.502715\tKL_Divergence = 3.049139\n",
      "Epoch: 20\tFidelity = 0.502760\tKL_Divergence = 3.039901\n",
      "Epoch: 21\tFidelity = 0.502561\tKL_Divergence = 3.081588\n",
      "Epoch: 22\tFidelity = 0.502581\tKL_Divergence = 3.077152\n",
      "Epoch: 23\tFidelity = 0.503093\tKL_Divergence = 2.976570\n",
      "Epoch: 24\tFidelity = 0.503034\tKL_Divergence = 2.987281\n",
      "Epoch: 25\tFidelity = 0.502571\tKL_Divergence = 3.079353\n",
      "Epoch: 26\tFidelity = 0.502717\tKL_Divergence = 3.048709\n",
      "Epoch: 27\tFidelity = 0.503125\tKL_Divergence = 2.970761\n",
      "Epoch: 28\tFidelity = 0.502689\tKL_Divergence = 3.054343\n",
      "Epoch: 29\tFidelity = 0.502730\tKL_Divergence = 3.046094\n",
      "Epoch: 30\tFidelity = 0.502739\tKL_Divergence = 3.044081\n",
      "Epoch: 31\tFidelity = 0.502762\tKL_Divergence = 3.039610\n",
      "Epoch: 32\tFidelity = 0.503176\tKL_Divergence = 2.961780\n",
      "Epoch: 33\tFidelity = 0.502776\tKL_Divergence = 3.036606\n",
      "Epoch: 34\tFidelity = 0.502452\tKL_Divergence = 3.105628\n",
      "Epoch: 35\tFidelity = 0.502770\tKL_Divergence = 3.037793\n",
      "Epoch: 36\tFidelity = 0.502856\tKL_Divergence = 3.020885\n",
      "Epoch: 37\tFidelity = 0.502884\tKL_Divergence = 3.015420\n",
      "Epoch: 38\tFidelity = 0.502932\tKL_Divergence = 3.006338\n",
      "Epoch: 39\tFidelity = 0.502728\tKL_Divergence = 3.046382\n",
      "Epoch: 40\tFidelity = 0.503000\tKL_Divergence = 2.993616\n",
      "Epoch: 41\tFidelity = 0.502514\tKL_Divergence = 3.091775\n",
      "Epoch: 42\tFidelity = 0.502949\tKL_Divergence = 3.003065\n",
      "Epoch: 43\tFidelity = 0.502612\tKL_Divergence = 3.070481\n",
      "Epoch: 44\tFidelity = 0.502698\tKL_Divergence = 3.052445\n",
      "Epoch: 45\tFidelity = 0.502721\tKL_Divergence = 3.047728\n",
      "Epoch: 46\tFidelity = 0.502720\tKL_Divergence = 3.047981\n",
      "Epoch: 47\tFidelity = 0.502748\tKL_Divergence = 3.042229\n",
      "Epoch: 48\tFidelity = 0.502788\tKL_Divergence = 3.034284\n",
      "Epoch: 49\tFidelity = 0.502788\tKL_Divergence = 3.034333\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:18:07,570] Trial 283 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.502745\tKL_Divergence = 3.042931\n",
      "Total time elapsed during training: 84.893 s\n",
      "Trial 283 pruned. \n",
      "Epoch: 1\tFidelity = 0.503161\tKL_Divergence = 2.964491\n",
      "Epoch: 2\tFidelity = 0.502971\tKL_Divergence = 2.998990\n",
      "Epoch: 3\tFidelity = 0.503252\tKL_Divergence = 2.948775\n",
      "Epoch: 4\tFidelity = 0.502664\tKL_Divergence = 3.059599\n",
      "Epoch: 5\tFidelity = 0.502889\tKL_Divergence = 3.014465\n",
      "Epoch: 6\tFidelity = 0.502330\tKL_Divergence = 3.133921\n",
      "Epoch: 7\tFidelity = 0.502588\tKL_Divergence = 3.075784\n",
      "Epoch: 8\tFidelity = 0.503240\tKL_Divergence = 2.950786\n",
      "Epoch: 9\tFidelity = 0.502688\tKL_Divergence = 3.054591\n",
      "Epoch: 10\tFidelity = 0.502647\tKL_Divergence = 3.063152\n",
      "Epoch: 11\tFidelity = 0.503574\tKL_Divergence = 2.896090\n",
      "Epoch: 12\tFidelity = 0.502478\tKL_Divergence = 3.099730\n",
      "Epoch: 13\tFidelity = 0.502500\tKL_Divergence = 3.094950\n",
      "Epoch: 14\tFidelity = 0.503329\tKL_Divergence = 2.935643\n",
      "Epoch: 15\tFidelity = 0.502524\tKL_Divergence = 3.089550\n",
      "Epoch: 16\tFidelity = 0.502785\tKL_Divergence = 3.034908\n",
      "Epoch: 17\tFidelity = 0.502734\tKL_Divergence = 3.045211\n",
      "Epoch: 18\tFidelity = 0.503524\tKL_Divergence = 2.903989\n",
      "Epoch: 19\tFidelity = 0.502747\tKL_Divergence = 3.042402\n",
      "Epoch: 20\tFidelity = 0.502813\tKL_Divergence = 3.029140\n",
      "Epoch: 21\tFidelity = 0.502727\tKL_Divergence = 3.046411\n",
      "Epoch: 22\tFidelity = 0.502311\tKL_Divergence = 3.138423\n",
      "Epoch: 23\tFidelity = 0.503011\tKL_Divergence = 2.991485\n",
      "Epoch: 24\tFidelity = 0.502753\tKL_Divergence = 3.041358\n",
      "Epoch: 25\tFidelity = 0.502592\tKL_Divergence = 3.074857\n",
      "Epoch: 26\tFidelity = 0.502909\tKL_Divergence = 3.010741\n",
      "Epoch: 27\tFidelity = 0.502697\tKL_Divergence = 3.052819\n",
      "Epoch: 28\tFidelity = 0.502455\tKL_Divergence = 3.105094\n",
      "Epoch: 29\tFidelity = 0.502299\tKL_Divergence = 3.141512\n",
      "Epoch: 30\tFidelity = 0.503180\tKL_Divergence = 2.961144\n",
      "Epoch: 31\tFidelity = 0.502778\tKL_Divergence = 3.036348\n",
      "Epoch: 32\tFidelity = 0.503229\tKL_Divergence = 2.952644\n",
      "Epoch: 33\tFidelity = 0.503158\tKL_Divergence = 2.964992\n",
      "Epoch: 34\tFidelity = 0.503462\tKL_Divergence = 2.913773\n",
      "Epoch: 35\tFidelity = 0.503431\tKL_Divergence = 2.918833\n",
      "Epoch: 36\tFidelity = 0.503270\tKL_Divergence = 2.945706\n",
      "Epoch: 37\tFidelity = 0.502392\tKL_Divergence = 3.119551\n",
      "Epoch: 38\tFidelity = 0.502862\tKL_Divergence = 3.019775\n",
      "Epoch: 39\tFidelity = 0.502400\tKL_Divergence = 3.117664\n",
      "Epoch: 40\tFidelity = 0.503311\tKL_Divergence = 2.938648\n",
      "Epoch: 41\tFidelity = 0.502760\tKL_Divergence = 3.039926\n",
      "Epoch: 42\tFidelity = 0.502693\tKL_Divergence = 3.053656\n",
      "Epoch: 43\tFidelity = 0.503520\tKL_Divergence = 2.904532\n",
      "Epoch: 44\tFidelity = 0.503259\tKL_Divergence = 2.947376\n",
      "Epoch: 45\tFidelity = 0.502920\tKL_Divergence = 3.008567\n",
      "Epoch: 46\tFidelity = 0.502406\tKL_Divergence = 3.116224\n",
      "Epoch: 47\tFidelity = 0.502531\tKL_Divergence = 3.088081\n",
      "Epoch: 48\tFidelity = 0.502380\tKL_Divergence = 3.122261\n",
      "Epoch: 49\tFidelity = 0.502516\tKL_Divergence = 3.091289\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:18:47,277] Trial 284 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.503092\tKL_Divergence = 2.976664\n",
      "Total time elapsed during training: 39.524 s\n",
      "Trial 284 pruned. \n",
      "Epoch: 1\tFidelity = 0.502929\tKL_Divergence = 3.006801\n",
      "Epoch: 2\tFidelity = 0.502904\tKL_Divergence = 3.011516\n",
      "Epoch: 3\tFidelity = 0.502869\tKL_Divergence = 3.018239\n",
      "Epoch: 4\tFidelity = 0.502793\tKL_Divergence = 3.033194\n",
      "Epoch: 5\tFidelity = 0.502839\tKL_Divergence = 3.024131\n",
      "Epoch: 6\tFidelity = 0.502773\tKL_Divergence = 3.037255\n",
      "Epoch: 7\tFidelity = 0.502578\tKL_Divergence = 3.077683\n",
      "Epoch: 8\tFidelity = 0.502761\tKL_Divergence = 3.039559\n",
      "Epoch: 9\tFidelity = 0.502841\tKL_Divergence = 3.023791\n",
      "Epoch: 10\tFidelity = 0.502507\tKL_Divergence = 3.093273\n",
      "Epoch: 11\tFidelity = 0.502865\tKL_Divergence = 3.019036\n",
      "Epoch: 12\tFidelity = 0.502841\tKL_Divergence = 3.023842\n",
      "Epoch: 13\tFidelity = 0.502663\tKL_Divergence = 3.059670\n",
      "Epoch: 14\tFidelity = 0.502739\tKL_Divergence = 3.044135\n",
      "Epoch: 15\tFidelity = 0.502822\tKL_Divergence = 3.027460\n",
      "Epoch: 16\tFidelity = 0.502721\tKL_Divergence = 3.047691\n",
      "Epoch: 17\tFidelity = 0.502906\tKL_Divergence = 3.011161\n",
      "Epoch: 18\tFidelity = 0.502783\tKL_Divergence = 3.035205\n",
      "Epoch: 19\tFidelity = 0.502618\tKL_Divergence = 3.069259\n",
      "Epoch: 20\tFidelity = 0.502925\tKL_Divergence = 3.007564\n",
      "Epoch: 21\tFidelity = 0.502648\tKL_Divergence = 3.062859\n",
      "Epoch: 22\tFidelity = 0.502722\tKL_Divergence = 3.047673\n",
      "Epoch: 23\tFidelity = 0.502649\tKL_Divergence = 3.062761\n",
      "Epoch: 24\tFidelity = 0.502906\tKL_Divergence = 3.011170\n",
      "Epoch: 25\tFidelity = 0.502584\tKL_Divergence = 3.076534\n",
      "Epoch: 26\tFidelity = 0.502788\tKL_Divergence = 3.034276\n",
      "Epoch: 27\tFidelity = 0.502781\tKL_Divergence = 3.035573\n",
      "Epoch: 28\tFidelity = 0.502701\tKL_Divergence = 3.051925\n",
      "Epoch: 29\tFidelity = 0.502624\tKL_Divergence = 3.067858\n",
      "Epoch: 30\tFidelity = 0.502628\tKL_Divergence = 3.067021\n",
      "Epoch: 31\tFidelity = 0.502811\tKL_Divergence = 3.029730\n",
      "Epoch: 32\tFidelity = 0.502740\tKL_Divergence = 3.043886\n",
      "Epoch: 33\tFidelity = 0.502819\tKL_Divergence = 3.028149\n",
      "Epoch: 34\tFidelity = 0.502830\tKL_Divergence = 3.025860\n",
      "Epoch: 35\tFidelity = 0.502955\tKL_Divergence = 3.001818\n",
      "Epoch: 36\tFidelity = 0.502892\tKL_Divergence = 3.013845\n",
      "Epoch: 37\tFidelity = 0.502862\tKL_Divergence = 3.019610\n",
      "Epoch: 38\tFidelity = 0.502854\tKL_Divergence = 3.021168\n",
      "Epoch: 39\tFidelity = 0.502689\tKL_Divergence = 3.054316\n",
      "Epoch: 40\tFidelity = 0.502591\tKL_Divergence = 3.074896\n",
      "Epoch: 41\tFidelity = 0.502740\tKL_Divergence = 3.043805\n",
      "Epoch: 42\tFidelity = 0.502764\tKL_Divergence = 3.039062\n",
      "Epoch: 43\tFidelity = 0.502864\tKL_Divergence = 3.019292\n",
      "Epoch: 44\tFidelity = 0.502676\tKL_Divergence = 3.057028\n",
      "Epoch: 45\tFidelity = 0.502755\tKL_Divergence = 3.040930\n",
      "Epoch: 46\tFidelity = 0.502635\tKL_Divergence = 3.065573\n",
      "Epoch: 47\tFidelity = 0.502883\tKL_Divergence = 3.015581\n",
      "Epoch: 48\tFidelity = 0.502882\tKL_Divergence = 3.015818\n",
      "Epoch: 49\tFidelity = 0.502791\tKL_Divergence = 3.033558\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:19:27,085] Trial 285 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.502940\tKL_Divergence = 3.004785\n",
      "Total time elapsed during training: 39.639 s\n",
      "Trial 285 pruned. \n",
      "Epoch: 1\tFidelity = 0.502814\tKL_Divergence = 3.029080\n",
      "Epoch: 2\tFidelity = 0.503276\tKL_Divergence = 2.944527\n",
      "Epoch: 3\tFidelity = 0.503172\tKL_Divergence = 2.962438\n",
      "Epoch: 4\tFidelity = 0.502404\tKL_Divergence = 3.116573\n",
      "Epoch: 5\tFidelity = 0.502758\tKL_Divergence = 3.040081\n",
      "Epoch: 6\tFidelity = 0.503517\tKL_Divergence = 2.904917\n",
      "Epoch: 7\tFidelity = 0.502840\tKL_Divergence = 3.023828\n",
      "Epoch: 8\tFidelity = 0.502994\tKL_Divergence = 2.994589\n",
      "Epoch: 9\tFidelity = 0.503357\tKL_Divergence = 2.930868\n",
      "Epoch: 10\tFidelity = 0.503759\tKL_Divergence = 2.867946\n",
      "Epoch: 11\tFidelity = 0.502829\tKL_Divergence = 3.026062\n",
      "Epoch: 12\tFidelity = 0.502482\tKL_Divergence = 3.098668\n",
      "Epoch: 13\tFidelity = 0.502370\tKL_Divergence = 3.124307\n",
      "Epoch: 14\tFidelity = 0.502142\tKL_Divergence = 3.180324\n",
      "Epoch: 15\tFidelity = 0.502241\tKL_Divergence = 3.154701\n",
      "Epoch: 16\tFidelity = 0.502266\tKL_Divergence = 3.148891\n",
      "Epoch: 17\tFidelity = 0.502968\tKL_Divergence = 2.999183\n",
      "Epoch: 18\tFidelity = 0.502289\tKL_Divergence = 3.143294\n",
      "Epoch: 19\tFidelity = 0.502720\tKL_Divergence = 3.046148\n",
      "Epoch: 20\tFidelity = 0.502659\tKL_Divergence = 3.059150\n",
      "Epoch: 21\tFidelity = 0.503139\tKL_Divergence = 2.966785\n",
      "Epoch: 22\tFidelity = 0.502821\tKL_Divergence = 3.026834\n",
      "Epoch: 23\tFidelity = 0.502448\tKL_Divergence = 3.105390\n",
      "Epoch: 24\tFidelity = 0.503337\tKL_Divergence = 2.932994\n",
      "Epoch: 25\tFidelity = 0.503535\tKL_Divergence = 2.901725\n",
      "Epoch: 26\tFidelity = 0.502443\tKL_Divergence = 3.107395\n",
      "Epoch: 27\tFidelity = 0.502691\tKL_Divergence = 3.053696\n",
      "Epoch: 28\tFidelity = 0.502521\tKL_Divergence = 3.090215\n",
      "Epoch: 29\tFidelity = 0.503350\tKL_Divergence = 2.931952\n",
      "Epoch: 30\tFidelity = 0.503193\tKL_Divergence = 2.958647\n",
      "Epoch: 31\tFidelity = 0.502686\tKL_Divergence = 3.054753\n",
      "Epoch: 32\tFidelity = 0.503136\tKL_Divergence = 2.968650\n",
      "Epoch: 33\tFidelity = 0.502771\tKL_Divergence = 3.037513\n",
      "Epoch: 34\tFidelity = 0.502595\tKL_Divergence = 3.073911\n",
      "Epoch: 35\tFidelity = 0.503123\tKL_Divergence = 2.970751\n",
      "Epoch: 36\tFidelity = 0.502366\tKL_Divergence = 3.124984\n",
      "Epoch: 37\tFidelity = 0.502519\tKL_Divergence = 3.090523\n",
      "Epoch: 38\tFidelity = 0.502888\tKL_Divergence = 3.014497\n",
      "Epoch: 39\tFidelity = 0.503006\tKL_Divergence = 2.992246\n",
      "Epoch: 40\tFidelity = 0.502415\tKL_Divergence = 3.114084\n",
      "Epoch: 41\tFidelity = 0.502548\tKL_Divergence = 3.084222\n",
      "Epoch: 42\tFidelity = 0.502867\tKL_Divergence = 3.018488\n",
      "Epoch: 43\tFidelity = 0.502860\tKL_Divergence = 3.019966\n",
      "Epoch: 44\tFidelity = 0.502927\tKL_Divergence = 3.006703\n",
      "Epoch: 45\tFidelity = 0.503164\tKL_Divergence = 2.963846\n",
      "Epoch: 46\tFidelity = 0.502464\tKL_Divergence = 3.102865\n",
      "Epoch: 47\tFidelity = 0.502124\tKL_Divergence = 3.185502\n",
      "Epoch: 48\tFidelity = 0.502802\tKL_Divergence = 3.031168\n",
      "Epoch: 49\tFidelity = 0.502383\tKL_Divergence = 3.121265\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:20:06,864] Trial 286 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.503762\tKL_Divergence = 2.867361\n",
      "Total time elapsed during training: 39.608 s\n",
      "Trial 286 pruned. \n",
      "Epoch: 1\tFidelity = 0.502857\tKL_Divergence = 3.020586\n",
      "Epoch: 2\tFidelity = 0.502520\tKL_Divergence = 3.090476\n",
      "Epoch: 3\tFidelity = 0.502807\tKL_Divergence = 3.030563\n",
      "Epoch: 4\tFidelity = 0.502791\tKL_Divergence = 3.033629\n",
      "Epoch: 5\tFidelity = 0.502672\tKL_Divergence = 3.057924\n",
      "Epoch: 6\tFidelity = 0.502758\tKL_Divergence = 3.040301\n",
      "Epoch: 7\tFidelity = 0.502893\tKL_Divergence = 3.013659\n",
      "Epoch: 8\tFidelity = 0.502774\tKL_Divergence = 3.037063\n",
      "Epoch: 9\tFidelity = 0.503064\tKL_Divergence = 2.981671\n",
      "Epoch: 10\tFidelity = 0.502719\tKL_Divergence = 3.048162\n",
      "Epoch: 11\tFidelity = 0.502514\tKL_Divergence = 3.091653\n",
      "Epoch: 12\tFidelity = 0.502943\tKL_Divergence = 3.004234\n",
      "Epoch: 13\tFidelity = 0.503129\tKL_Divergence = 2.969994\n",
      "Epoch: 14\tFidelity = 0.503060\tKL_Divergence = 2.982471\n",
      "Epoch: 15\tFidelity = 0.503094\tKL_Divergence = 2.976348\n",
      "Epoch: 16\tFidelity = 0.502700\tKL_Divergence = 3.052008\n",
      "Epoch: 17\tFidelity = 0.503014\tKL_Divergence = 2.990860\n",
      "Epoch: 18\tFidelity = 0.502658\tKL_Divergence = 3.060718\n",
      "Epoch: 19\tFidelity = 0.502736\tKL_Divergence = 3.044673\n",
      "Epoch: 20\tFidelity = 0.502884\tKL_Divergence = 3.015489\n",
      "Epoch: 21\tFidelity = 0.502994\tKL_Divergence = 2.994519\n",
      "Epoch: 22\tFidelity = 0.502847\tKL_Divergence = 3.022618\n",
      "Epoch: 23\tFidelity = 0.502867\tKL_Divergence = 3.018586\n",
      "Epoch: 24\tFidelity = 0.503011\tKL_Divergence = 2.991464\n",
      "Epoch: 25\tFidelity = 0.503094\tKL_Divergence = 2.976313\n",
      "Epoch: 26\tFidelity = 0.502807\tKL_Divergence = 3.030342\n",
      "Epoch: 27\tFidelity = 0.502516\tKL_Divergence = 3.091175\n",
      "Epoch: 28\tFidelity = 0.502875\tKL_Divergence = 3.016992\n",
      "Epoch: 29\tFidelity = 0.503040\tKL_Divergence = 2.986003\n",
      "Epoch: 30\tFidelity = 0.502784\tKL_Divergence = 3.034880\n",
      "Epoch: 31\tFidelity = 0.502904\tKL_Divergence = 3.011534\n",
      "Epoch: 32\tFidelity = 0.502893\tKL_Divergence = 3.013549\n",
      "Epoch: 33\tFidelity = 0.502559\tKL_Divergence = 3.081750\n",
      "Epoch: 34\tFidelity = 0.502598\tKL_Divergence = 3.073410\n",
      "Epoch: 35\tFidelity = 0.503117\tKL_Divergence = 2.972113\n",
      "Epoch: 36\tFidelity = 0.502779\tKL_Divergence = 3.035906\n",
      "Epoch: 37\tFidelity = 0.502770\tKL_Divergence = 3.037631\n",
      "Epoch: 38\tFidelity = 0.502906\tKL_Divergence = 3.011101\n",
      "Epoch: 39\tFidelity = 0.502842\tKL_Divergence = 3.023508\n",
      "Epoch: 40\tFidelity = 0.502853\tKL_Divergence = 3.021216\n",
      "Epoch: 41\tFidelity = 0.502548\tKL_Divergence = 3.084158\n",
      "Epoch: 42\tFidelity = 0.502980\tKL_Divergence = 2.997115\n",
      "Epoch: 43\tFidelity = 0.502464\tKL_Divergence = 3.102759\n",
      "Epoch: 44\tFidelity = 0.502879\tKL_Divergence = 3.016217\n",
      "Epoch: 45\tFidelity = 0.502598\tKL_Divergence = 3.073425\n",
      "Epoch: 46\tFidelity = 0.502752\tKL_Divergence = 3.041282\n",
      "Epoch: 47\tFidelity = 0.503007\tKL_Divergence = 2.992003\n",
      "Epoch: 48\tFidelity = 0.502614\tKL_Divergence = 3.069863\n",
      "Epoch: 49\tFidelity = 0.502852\tKL_Divergence = 3.021539\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:21:30,330] Trial 287 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.502829\tKL_Divergence = 3.026050\n",
      "Total time elapsed during training: 83.290 s\n",
      "Trial 287 pruned. \n",
      "Epoch: 1\tFidelity = 0.503158\tKL_Divergence = 2.964792\n",
      "Epoch: 2\tFidelity = 0.502834\tKL_Divergence = 3.025077\n",
      "Epoch: 3\tFidelity = 0.502855\tKL_Divergence = 3.020900\n",
      "Epoch: 4\tFidelity = 0.502688\tKL_Divergence = 3.054520\n",
      "Epoch: 5\tFidelity = 0.503047\tKL_Divergence = 2.984794\n",
      "Epoch: 6\tFidelity = 0.502489\tKL_Divergence = 3.097283\n",
      "Epoch: 7\tFidelity = 0.502855\tKL_Divergence = 3.021090\n",
      "Epoch: 8\tFidelity = 0.502839\tKL_Divergence = 3.024112\n",
      "Epoch: 9\tFidelity = 0.502935\tKL_Divergence = 3.005638\n",
      "Epoch: 10\tFidelity = 0.502845\tKL_Divergence = 3.022940\n",
      "Epoch: 11\tFidelity = 0.502797\tKL_Divergence = 3.032494\n",
      "Epoch: 12\tFidelity = 0.502944\tKL_Divergence = 3.003955\n",
      "Epoch: 13\tFidelity = 0.502780\tKL_Divergence = 3.035720\n",
      "Epoch: 14\tFidelity = 0.502968\tKL_Divergence = 2.999311\n",
      "Epoch: 15\tFidelity = 0.503078\tKL_Divergence = 2.979152\n",
      "Epoch: 16\tFidelity = 0.502872\tKL_Divergence = 3.017640\n",
      "Epoch: 17\tFidelity = 0.502480\tKL_Divergence = 3.099229\n",
      "Epoch: 18\tFidelity = 0.502547\tKL_Divergence = 3.084380\n",
      "Epoch: 19\tFidelity = 0.502906\tKL_Divergence = 3.011119\n",
      "Epoch: 20\tFidelity = 0.502939\tKL_Divergence = 3.004860\n",
      "Epoch: 21\tFidelity = 0.502855\tKL_Divergence = 3.020950\n",
      "Epoch: 22\tFidelity = 0.503064\tKL_Divergence = 2.981765\n",
      "Epoch: 23\tFidelity = 0.502812\tKL_Divergence = 3.029518\n",
      "Epoch: 24\tFidelity = 0.503205\tKL_Divergence = 2.956612\n",
      "Epoch: 25\tFidelity = 0.502926\tKL_Divergence = 3.007360\n",
      "Epoch: 26\tFidelity = 0.502899\tKL_Divergence = 3.012552\n",
      "Epoch: 27\tFidelity = 0.502674\tKL_Divergence = 3.057498\n",
      "Epoch: 28\tFidelity = 0.502917\tKL_Divergence = 3.009103\n",
      "Epoch: 29\tFidelity = 0.503013\tKL_Divergence = 2.991049\n",
      "Epoch: 30\tFidelity = 0.502518\tKL_Divergence = 3.090945\n",
      "Epoch: 31\tFidelity = 0.502610\tKL_Divergence = 3.070972\n",
      "Epoch: 32\tFidelity = 0.503199\tKL_Divergence = 2.957690\n",
      "Epoch: 33\tFidelity = 0.502936\tKL_Divergence = 3.005478\n",
      "Epoch: 34\tFidelity = 0.502645\tKL_Divergence = 3.063565\n",
      "Epoch: 35\tFidelity = 0.502637\tKL_Divergence = 3.065249\n",
      "Epoch: 36\tFidelity = 0.502922\tKL_Divergence = 3.008111\n",
      "Epoch: 37\tFidelity = 0.502687\tKL_Divergence = 3.054786\n",
      "Epoch: 38\tFidelity = 0.502796\tKL_Divergence = 3.032526\n",
      "Epoch: 39\tFidelity = 0.502728\tKL_Divergence = 3.046184\n",
      "Epoch: 40\tFidelity = 0.502837\tKL_Divergence = 3.024562\n",
      "Epoch: 41\tFidelity = 0.503290\tKL_Divergence = 2.942117\n",
      "Epoch: 42\tFidelity = 0.502807\tKL_Divergence = 3.030329\n",
      "Epoch: 43\tFidelity = 0.503175\tKL_Divergence = 2.961861\n",
      "Epoch: 44\tFidelity = 0.502699\tKL_Divergence = 3.052224\n",
      "Epoch: 45\tFidelity = 0.502972\tKL_Divergence = 2.998689\n",
      "Epoch: 46\tFidelity = 0.502980\tKL_Divergence = 2.997191\n",
      "Epoch: 47\tFidelity = 0.502626\tKL_Divergence = 3.067386\n",
      "Epoch: 48\tFidelity = 0.502810\tKL_Divergence = 3.029731\n",
      "Epoch: 49\tFidelity = 0.502993\tKL_Divergence = 2.994725\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:22:14,797] Trial 288 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.502925\tKL_Divergence = 3.007455\n",
      "Total time elapsed during training: 44.304 s\n",
      "Trial 288 pruned. \n",
      "Epoch: 1\tFidelity = 0.503146\tKL_Divergence = 2.966938\n",
      "Epoch: 2\tFidelity = 0.502667\tKL_Divergence = 3.058809\n",
      "Epoch: 3\tFidelity = 0.502656\tKL_Divergence = 3.061129\n",
      "Epoch: 4\tFidelity = 0.503243\tKL_Divergence = 2.949949\n",
      "Epoch: 5\tFidelity = 0.502753\tKL_Divergence = 3.041165\n",
      "Epoch: 6\tFidelity = 0.503152\tKL_Divergence = 2.965805\n",
      "Epoch: 7\tFidelity = 0.502753\tKL_Divergence = 3.041090\n",
      "Epoch: 8\tFidelity = 0.502979\tKL_Divergence = 2.997259\n",
      "Epoch: 9\tFidelity = 0.503564\tKL_Divergence = 2.897451\n",
      "Epoch: 10\tFidelity = 0.502854\tKL_Divergence = 3.021027\n",
      "Epoch: 11\tFidelity = 0.503211\tKL_Divergence = 2.955602\n",
      "Epoch: 12\tFidelity = 0.503105\tKL_Divergence = 2.974201\n",
      "Epoch: 13\tFidelity = 0.503149\tKL_Divergence = 2.966437\n",
      "Epoch: 14\tFidelity = 0.502733\tKL_Divergence = 3.045243\n",
      "Epoch: 15\tFidelity = 0.503440\tKL_Divergence = 2.917198\n",
      "Epoch: 16\tFidelity = 0.502553\tKL_Divergence = 3.083028\n",
      "Epoch: 17\tFidelity = 0.503217\tKL_Divergence = 2.954542\n",
      "Epoch: 18\tFidelity = 0.502647\tKL_Divergence = 3.063021\n",
      "Epoch: 19\tFidelity = 0.503051\tKL_Divergence = 2.984016\n",
      "Epoch: 20\tFidelity = 0.503243\tKL_Divergence = 2.950079\n",
      "Epoch: 21\tFidelity = 0.502693\tKL_Divergence = 3.053313\n",
      "Epoch: 22\tFidelity = 0.503070\tKL_Divergence = 2.980506\n",
      "Epoch: 23\tFidelity = 0.502749\tKL_Divergence = 3.041936\n",
      "Epoch: 24\tFidelity = 0.502989\tKL_Divergence = 2.995344\n",
      "Epoch: 25\tFidelity = 0.502783\tKL_Divergence = 3.035081\n",
      "Epoch: 26\tFidelity = 0.502912\tKL_Divergence = 3.009863\n",
      "Epoch: 27\tFidelity = 0.502851\tKL_Divergence = 3.021795\n",
      "Epoch: 28\tFidelity = 0.502895\tKL_Divergence = 3.013280\n",
      "Epoch: 29\tFidelity = 0.502848\tKL_Divergence = 3.022308\n",
      "Epoch: 30\tFidelity = 0.503106\tKL_Divergence = 2.974139\n",
      "Epoch: 31\tFidelity = 0.502390\tKL_Divergence = 3.119721\n",
      "Epoch: 32\tFidelity = 0.503090\tKL_Divergence = 2.976878\n",
      "Epoch: 33\tFidelity = 0.502633\tKL_Divergence = 3.065901\n",
      "Epoch: 34\tFidelity = 0.502992\tKL_Divergence = 2.994963\n",
      "Epoch: 35\tFidelity = 0.502911\tKL_Divergence = 3.010109\n",
      "Epoch: 36\tFidelity = 0.502827\tKL_Divergence = 3.026446\n",
      "Epoch: 37\tFidelity = 0.503058\tKL_Divergence = 2.982803\n",
      "Epoch: 38\tFidelity = 0.503005\tKL_Divergence = 2.992481\n",
      "Epoch: 39\tFidelity = 0.502529\tKL_Divergence = 3.088255\n",
      "Epoch: 40\tFidelity = 0.503147\tKL_Divergence = 2.966850\n",
      "Epoch: 41\tFidelity = 0.502770\tKL_Divergence = 3.037679\n",
      "Epoch: 42\tFidelity = 0.503035\tKL_Divergence = 2.987028\n",
      "Epoch: 43\tFidelity = 0.502877\tKL_Divergence = 3.016682\n",
      "Epoch: 44\tFidelity = 0.502797\tKL_Divergence = 3.032414\n",
      "Epoch: 45\tFidelity = 0.502783\tKL_Divergence = 3.035089\n",
      "Epoch: 46\tFidelity = 0.503142\tKL_Divergence = 2.967739\n",
      "Epoch: 47\tFidelity = 0.502716\tKL_Divergence = 3.048595\n",
      "Epoch: 48\tFidelity = 0.503056\tKL_Divergence = 2.983139\n",
      "Epoch: 49\tFidelity = 0.502598\tKL_Divergence = 3.073446\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:22:46,413] Trial 289 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.503335\tKL_Divergence = 2.934427\n",
      "Total time elapsed during training: 31.454 s\n",
      "Trial 289 pruned. \n",
      "Epoch: 1\tFidelity = 0.503309\tKL_Divergence = 2.938870\n",
      "Epoch: 2\tFidelity = 0.502950\tKL_Divergence = 3.002677\n",
      "Epoch: 3\tFidelity = 0.502762\tKL_Divergence = 3.039314\n",
      "Epoch: 4\tFidelity = 0.503017\tKL_Divergence = 2.990299\n",
      "Epoch: 5\tFidelity = 0.502792\tKL_Divergence = 3.033188\n",
      "Epoch: 6\tFidelity = 0.502977\tKL_Divergence = 2.997453\n",
      "Epoch: 7\tFidelity = 0.503000\tKL_Divergence = 2.993231\n",
      "Epoch: 8\tFidelity = 0.503438\tKL_Divergence = 2.917447\n",
      "Epoch: 9\tFidelity = 0.502953\tKL_Divergence = 3.002083\n",
      "Epoch: 10\tFidelity = 0.502910\tKL_Divergence = 3.010208\n",
      "Epoch: 11\tFidelity = 0.502947\tKL_Divergence = 3.003061\n",
      "Epoch: 12\tFidelity = 0.502899\tKL_Divergence = 3.012168\n",
      "Epoch: 13\tFidelity = 0.502825\tKL_Divergence = 3.026566\n",
      "Epoch: 14\tFidelity = 0.502750\tKL_Divergence = 3.041619\n",
      "Epoch: 15\tFidelity = 0.503035\tKL_Divergence = 2.986626\n",
      "Epoch: 16\tFidelity = 0.503230\tKL_Divergence = 2.951694\n",
      "Epoch: 17\tFidelity = 0.503263\tKL_Divergence = 2.946054\n",
      "Epoch: 18\tFidelity = 0.503471\tKL_Divergence = 2.911796\n",
      "Epoch: 19\tFidelity = 0.502818\tKL_Divergence = 3.027561\n",
      "Epoch: 20\tFidelity = 0.503134\tKL_Divergence = 2.968457\n",
      "Epoch: 21\tFidelity = 0.502777\tKL_Divergence = 3.035577\n",
      "Epoch: 22\tFidelity = 0.502907\tKL_Divergence = 3.010270\n",
      "Epoch: 23\tFidelity = 0.502878\tKL_Divergence = 3.015775\n",
      "Epoch: 24\tFidelity = 0.503139\tKL_Divergence = 2.967456\n",
      "Epoch: 25\tFidelity = 0.502983\tKL_Divergence = 2.995665\n",
      "Epoch: 26\tFidelity = 0.502867\tKL_Divergence = 3.017605\n",
      "Epoch: 27\tFidelity = 0.502705\tKL_Divergence = 3.049881\n",
      "Epoch: 28\tFidelity = 0.502539\tKL_Divergence = 3.084700\n",
      "Epoch: 29\tFidelity = 0.503011\tKL_Divergence = 2.990175\n",
      "Epoch: 30\tFidelity = 0.502829\tKL_Divergence = 3.024583\n",
      "Epoch: 31\tFidelity = 0.502753\tKL_Divergence = 3.039904\n",
      "Epoch: 32\tFidelity = 0.502809\tKL_Divergence = 3.028975\n",
      "Epoch: 33\tFidelity = 0.502594\tKL_Divergence = 3.073392\n",
      "Epoch: 34\tFidelity = 0.502821\tKL_Divergence = 3.026716\n",
      "Epoch: 35\tFidelity = 0.502747\tKL_Divergence = 3.041292\n",
      "Epoch: 36\tFidelity = 0.502866\tKL_Divergence = 3.018306\n",
      "Epoch: 37\tFidelity = 0.503055\tKL_Divergence = 2.982630\n",
      "Epoch: 38\tFidelity = 0.502801\tKL_Divergence = 3.031287\n",
      "Epoch: 39\tFidelity = 0.502790\tKL_Divergence = 3.033295\n",
      "Epoch: 40\tFidelity = 0.503117\tKL_Divergence = 2.971702\n",
      "Epoch: 41\tFidelity = 0.503181\tKL_Divergence = 2.960405\n",
      "Epoch: 42\tFidelity = 0.502814\tKL_Divergence = 3.028526\n",
      "Epoch: 43\tFidelity = 0.502868\tKL_Divergence = 3.018116\n",
      "Epoch: 44\tFidelity = 0.502724\tKL_Divergence = 3.046815\n",
      "Epoch: 45\tFidelity = 0.502637\tKL_Divergence = 3.064730\n",
      "Epoch: 46\tFidelity = 0.503200\tKL_Divergence = 2.957143\n",
      "Epoch: 47\tFidelity = 0.502798\tKL_Divergence = 3.031795\n",
      "Epoch: 48\tFidelity = 0.503009\tKL_Divergence = 2.991732\n",
      "Epoch: 49\tFidelity = 0.503230\tKL_Divergence = 2.952165\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:23:23,656] Trial 290 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.502994\tKL_Divergence = 2.994531\n",
      "Total time elapsed during training: 37.087 s\n",
      "Trial 290 pruned. \n",
      "Epoch: 1\tFidelity = 0.502701\tKL_Divergence = 3.051598\n",
      "Epoch: 2\tFidelity = 0.502626\tKL_Divergence = 3.067189\n",
      "Epoch: 3\tFidelity = 0.502515\tKL_Divergence = 3.091268\n",
      "Epoch: 4\tFidelity = 0.502722\tKL_Divergence = 3.047111\n",
      "Epoch: 5\tFidelity = 0.502886\tKL_Divergence = 3.014616\n",
      "Epoch: 6\tFidelity = 0.502886\tKL_Divergence = 3.014626\n",
      "Epoch: 7\tFidelity = 0.503509\tKL_Divergence = 2.906122\n",
      "Epoch: 8\tFidelity = 0.502868\tKL_Divergence = 3.018389\n",
      "Epoch: 9\tFidelity = 0.503197\tKL_Divergence = 2.958041\n",
      "Epoch: 10\tFidelity = 0.503142\tKL_Divergence = 2.967377\n",
      "Epoch: 11\tFidelity = 0.503012\tKL_Divergence = 2.991135\n",
      "Epoch: 12\tFidelity = 0.502549\tKL_Divergence = 3.083947\n",
      "Epoch: 13\tFidelity = 0.502428\tKL_Divergence = 3.111039\n",
      "Epoch: 14\tFidelity = 0.502453\tKL_Divergence = 3.105346\n",
      "Epoch: 15\tFidelity = 0.502888\tKL_Divergence = 3.014734\n",
      "Epoch: 16\tFidelity = 0.502756\tKL_Divergence = 3.040699\n",
      "Epoch: 17\tFidelity = 0.503144\tKL_Divergence = 2.967432\n",
      "Epoch: 18\tFidelity = 0.502542\tKL_Divergence = 3.085589\n",
      "Epoch: 19\tFidelity = 0.503024\tKL_Divergence = 2.989069\n",
      "Epoch: 20\tFidelity = 0.502855\tKL_Divergence = 3.021004\n",
      "Epoch: 21\tFidelity = 0.502657\tKL_Divergence = 3.060975\n",
      "Epoch: 22\tFidelity = 0.502949\tKL_Divergence = 3.002945\n",
      "Epoch: 23\tFidelity = 0.502492\tKL_Divergence = 3.096538\n",
      "Epoch: 24\tFidelity = 0.502782\tKL_Divergence = 3.035418\n",
      "Epoch: 25\tFidelity = 0.502744\tKL_Divergence = 3.042905\n",
      "Epoch: 26\tFidelity = 0.503277\tKL_Divergence = 2.944345\n",
      "Epoch: 27\tFidelity = 0.502844\tKL_Divergence = 3.023160\n",
      "Epoch: 28\tFidelity = 0.502885\tKL_Divergence = 3.015238\n",
      "Epoch: 29\tFidelity = 0.502343\tKL_Divergence = 3.130925\n",
      "Epoch: 30\tFidelity = 0.502665\tKL_Divergence = 3.059195\n",
      "Epoch: 31\tFidelity = 0.502432\tKL_Divergence = 3.109970\n",
      "Epoch: 32\tFidelity = 0.503056\tKL_Divergence = 2.983110\n",
      "Epoch: 33\tFidelity = 0.503307\tKL_Divergence = 2.939371\n",
      "Epoch: 34\tFidelity = 0.502423\tKL_Divergence = 3.112215\n",
      "Epoch: 35\tFidelity = 0.503349\tKL_Divergence = 2.932310\n",
      "Epoch: 36\tFidelity = 0.502624\tKL_Divergence = 3.067892\n",
      "Epoch: 37\tFidelity = 0.503051\tKL_Divergence = 2.984029\n",
      "Epoch: 38\tFidelity = 0.503028\tKL_Divergence = 2.988268\n",
      "Epoch: 39\tFidelity = 0.502372\tKL_Divergence = 3.123919\n",
      "Epoch: 40\tFidelity = 0.502401\tKL_Divergence = 3.117154\n",
      "Epoch: 41\tFidelity = 0.502546\tKL_Divergence = 3.084610\n",
      "Epoch: 42\tFidelity = 0.503235\tKL_Divergence = 2.951335\n",
      "Epoch: 43\tFidelity = 0.503018\tKL_Divergence = 2.989976\n",
      "Epoch: 44\tFidelity = 0.503102\tKL_Divergence = 2.974737\n",
      "Epoch: 45\tFidelity = 0.502444\tKL_Divergence = 3.107230\n",
      "Epoch: 46\tFidelity = 0.503365\tKL_Divergence = 2.929372\n",
      "Epoch: 47\tFidelity = 0.502953\tKL_Divergence = 3.002077\n",
      "Epoch: 48\tFidelity = 0.502846\tKL_Divergence = 3.022659\n",
      "Epoch: 49\tFidelity = 0.503048\tKL_Divergence = 2.984540\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:24:07,465] Trial 291 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.503104\tKL_Divergence = 2.974422\n",
      "Total time elapsed during training: 43.580 s\n",
      "Trial 291 pruned. \n",
      "Epoch: 1\tFidelity = 0.502742\tKL_Divergence = 3.043463\n",
      "Epoch: 2\tFidelity = 0.502712\tKL_Divergence = 3.049421\n",
      "Epoch: 3\tFidelity = 0.502897\tKL_Divergence = 3.012918\n",
      "Epoch: 4\tFidelity = 0.502629\tKL_Divergence = 3.066787\n",
      "Epoch: 5\tFidelity = 0.502860\tKL_Divergence = 3.020010\n",
      "Epoch: 6\tFidelity = 0.502760\tKL_Divergence = 3.039799\n",
      "Epoch: 7\tFidelity = 0.502728\tKL_Divergence = 3.046263\n",
      "Epoch: 8\tFidelity = 0.503034\tKL_Divergence = 2.987227\n",
      "Epoch: 9\tFidelity = 0.502742\tKL_Divergence = 3.043408\n",
      "Epoch: 10\tFidelity = 0.502895\tKL_Divergence = 3.013245\n",
      "Epoch: 11\tFidelity = 0.502898\tKL_Divergence = 3.012713\n",
      "Epoch: 12\tFidelity = 0.502769\tKL_Divergence = 3.037924\n",
      "Epoch: 13\tFidelity = 0.502966\tKL_Divergence = 2.999844\n",
      "Epoch: 14\tFidelity = 0.502836\tKL_Divergence = 3.024780\n",
      "Epoch: 15\tFidelity = 0.503025\tKL_Divergence = 2.988914\n",
      "Epoch: 16\tFidelity = 0.502823\tKL_Divergence = 3.027340\n",
      "Epoch: 17\tFidelity = 0.502631\tKL_Divergence = 3.066504\n",
      "Epoch: 18\tFidelity = 0.503122\tKL_Divergence = 2.971371\n",
      "Epoch: 19\tFidelity = 0.502659\tKL_Divergence = 3.060607\n",
      "Epoch: 20\tFidelity = 0.502769\tKL_Divergence = 3.038102\n",
      "Epoch: 21\tFidelity = 0.502972\tKL_Divergence = 2.998676\n",
      "Epoch: 22\tFidelity = 0.502916\tKL_Divergence = 3.009355\n",
      "Epoch: 23\tFidelity = 0.502765\tKL_Divergence = 3.038874\n",
      "Epoch: 24\tFidelity = 0.502536\tKL_Divergence = 3.086890\n",
      "Epoch: 25\tFidelity = 0.503064\tKL_Divergence = 2.981732\n",
      "Epoch: 26\tFidelity = 0.503144\tKL_Divergence = 2.967332\n",
      "Epoch: 27\tFidelity = 0.502672\tKL_Divergence = 3.057935\n",
      "Epoch: 28\tFidelity = 0.502832\tKL_Divergence = 3.025603\n",
      "Epoch: 29\tFidelity = 0.502901\tKL_Divergence = 3.012120\n",
      "Epoch: 30\tFidelity = 0.502744\tKL_Divergence = 3.043120\n",
      "Epoch: 31\tFidelity = 0.502732\tKL_Divergence = 3.045572\n",
      "Epoch: 32\tFidelity = 0.502955\tKL_Divergence = 3.001950\n",
      "Epoch: 33\tFidelity = 0.503045\tKL_Divergence = 2.985219\n",
      "Epoch: 34\tFidelity = 0.502671\tKL_Divergence = 3.058081\n",
      "Epoch: 35\tFidelity = 0.502685\tKL_Divergence = 3.055104\n",
      "Epoch: 36\tFidelity = 0.502909\tKL_Divergence = 3.010535\n",
      "Epoch: 37\tFidelity = 0.502584\tKL_Divergence = 3.076521\n",
      "Epoch: 38\tFidelity = 0.502794\tKL_Divergence = 3.033114\n",
      "Epoch: 39\tFidelity = 0.502949\tKL_Divergence = 3.002971\n",
      "Epoch: 40\tFidelity = 0.503092\tKL_Divergence = 2.976772\n",
      "Epoch: 41\tFidelity = 0.502787\tKL_Divergence = 3.034435\n",
      "Epoch: 42\tFidelity = 0.503068\tKL_Divergence = 2.981102\n",
      "Epoch: 43\tFidelity = 0.502930\tKL_Divergence = 3.006650\n",
      "Epoch: 44\tFidelity = 0.502901\tKL_Divergence = 3.012237\n",
      "Epoch: 45\tFidelity = 0.502492\tKL_Divergence = 3.096707\n",
      "Epoch: 46\tFidelity = 0.502957\tKL_Divergence = 3.001523\n",
      "Epoch: 47\tFidelity = 0.502725\tKL_Divergence = 3.046955\n",
      "Epoch: 48\tFidelity = 0.502926\tKL_Divergence = 3.007311\n",
      "Epoch: 49\tFidelity = 0.502810\tKL_Divergence = 3.029921\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:24:38,484] Trial 292 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.502882\tKL_Divergence = 3.015812\n",
      "Total time elapsed during training: 30.863 s\n",
      "Trial 292 pruned. \n",
      "Epoch: 1\tFidelity = 0.503281\tKL_Divergence = 2.943642\n",
      "Epoch: 2\tFidelity = 0.503409\tKL_Divergence = 2.922443\n",
      "Epoch: 3\tFidelity = 0.502722\tKL_Divergence = 3.047468\n",
      "Epoch: 4\tFidelity = 0.502366\tKL_Divergence = 3.125475\n",
      "Epoch: 5\tFidelity = 0.502242\tKL_Divergence = 3.155381\n",
      "Epoch: 6\tFidelity = 0.502324\tKL_Divergence = 3.135253\n",
      "Epoch: 7\tFidelity = 0.502476\tKL_Divergence = 3.100168\n",
      "Epoch: 8\tFidelity = 0.502444\tKL_Divergence = 3.107282\n",
      "Epoch: 9\tFidelity = 0.502517\tKL_Divergence = 3.090920\n",
      "Epoch: 10\tFidelity = 0.502026\tKL_Divergence = 3.211642\n",
      "Epoch: 11\tFidelity = 0.502715\tKL_Divergence = 3.048826\n",
      "Epoch: 12\tFidelity = 0.502345\tKL_Divergence = 3.130352\n",
      "Epoch: 13\tFidelity = 0.502562\tKL_Divergence = 3.081026\n",
      "Epoch: 14\tFidelity = 0.502540\tKL_Divergence = 3.085774\n",
      "Epoch: 15\tFidelity = 0.502969\tKL_Divergence = 2.998963\n",
      "Epoch: 16\tFidelity = 0.502588\tKL_Divergence = 3.075469\n",
      "Epoch: 17\tFidelity = 0.502770\tKL_Divergence = 3.037752\n",
      "Epoch: 18\tFidelity = 0.502664\tKL_Divergence = 3.059462\n",
      "Epoch: 19\tFidelity = 0.502763\tKL_Divergence = 3.039258\n",
      "Epoch: 20\tFidelity = 0.502267\tKL_Divergence = 3.149152\n",
      "Epoch: 21\tFidelity = 0.502194\tKL_Divergence = 3.167469\n",
      "Epoch: 22\tFidelity = 0.502640\tKL_Divergence = 3.064565\n",
      "Epoch: 23\tFidelity = 0.502401\tKL_Divergence = 3.117291\n",
      "Epoch: 24\tFidelity = 0.502979\tKL_Divergence = 2.997436\n",
      "Epoch: 25\tFidelity = 0.502996\tKL_Divergence = 2.994121\n",
      "Epoch: 26\tFidelity = 0.502281\tKL_Divergence = 3.145862\n",
      "Epoch: 27\tFidelity = 0.502194\tKL_Divergence = 3.167337\n",
      "Epoch: 28\tFidelity = 0.502424\tKL_Divergence = 3.112105\n",
      "Epoch: 29\tFidelity = 0.503228\tKL_Divergence = 2.952755\n",
      "Epoch: 30\tFidelity = 0.503091\tKL_Divergence = 2.976742\n",
      "Epoch: 31\tFidelity = 0.502750\tKL_Divergence = 3.041755\n",
      "Epoch: 32\tFidelity = 0.502534\tKL_Divergence = 3.087250\n",
      "Epoch: 33\tFidelity = 0.502247\tKL_Divergence = 3.154064\n",
      "Epoch: 34\tFidelity = 0.502175\tKL_Divergence = 3.172121\n",
      "Epoch: 35\tFidelity = 0.502555\tKL_Divergence = 3.082586\n",
      "Epoch: 36\tFidelity = 0.502618\tKL_Divergence = 3.069156\n",
      "Epoch: 37\tFidelity = 0.502348\tKL_Divergence = 3.129610\n",
      "Epoch: 38\tFidelity = 0.502339\tKL_Divergence = 3.131703\n",
      "Epoch: 39\tFidelity = 0.502525\tKL_Divergence = 3.089250\n",
      "Epoch: 40\tFidelity = 0.502206\tKL_Divergence = 3.164320\n",
      "Epoch: 41\tFidelity = 0.502383\tKL_Divergence = 3.121438\n",
      "Epoch: 42\tFidelity = 0.502407\tKL_Divergence = 3.115803\n",
      "Epoch: 43\tFidelity = 0.502687\tKL_Divergence = 3.054701\n",
      "Epoch: 44\tFidelity = 0.502361\tKL_Divergence = 3.126589\n",
      "Epoch: 45\tFidelity = 0.502124\tKL_Divergence = 3.185345\n",
      "Epoch: 46\tFidelity = 0.502238\tKL_Divergence = 3.156406\n",
      "Epoch: 47\tFidelity = 0.502422\tKL_Divergence = 3.112371\n",
      "Epoch: 48\tFidelity = 0.502579\tKL_Divergence = 3.077579\n",
      "Epoch: 49\tFidelity = 0.502832\tKL_Divergence = 3.025562\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:25:15,804] Trial 293 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.502961\tKL_Divergence = 3.000686\n",
      "Total time elapsed during training: 37.164 s\n",
      "Trial 293 pruned. \n",
      "Epoch: 1\tFidelity = 0.502717\tKL_Divergence = 3.048531\n",
      "Epoch: 2\tFidelity = 0.502779\tKL_Divergence = 3.035922\n",
      "Epoch: 3\tFidelity = 0.502771\tKL_Divergence = 3.037631\n",
      "Epoch: 4\tFidelity = 0.502769\tKL_Divergence = 3.038051\n",
      "Epoch: 5\tFidelity = 0.502691\tKL_Divergence = 3.053751\n",
      "Epoch: 6\tFidelity = 0.502824\tKL_Divergence = 3.027009\n",
      "Epoch: 7\tFidelity = 0.502876\tKL_Divergence = 3.016841\n",
      "Epoch: 8\tFidelity = 0.503147\tKL_Divergence = 2.966867\n",
      "Epoch: 9\tFidelity = 0.502912\tKL_Divergence = 3.009921\n",
      "Epoch: 10\tFidelity = 0.502783\tKL_Divergence = 3.035209\n",
      "Epoch: 11\tFidelity = 0.503034\tKL_Divergence = 2.987169\n",
      "Epoch: 12\tFidelity = 0.502874\tKL_Divergence = 3.017327\n",
      "Epoch: 13\tFidelity = 0.502596\tKL_Divergence = 3.073819\n",
      "Epoch: 14\tFidelity = 0.502825\tKL_Divergence = 3.026805\n",
      "Epoch: 15\tFidelity = 0.502585\tKL_Divergence = 3.076252\n",
      "Epoch: 16\tFidelity = 0.502722\tKL_Divergence = 3.047468\n",
      "Epoch: 17\tFidelity = 0.503164\tKL_Divergence = 2.963805\n",
      "Epoch: 18\tFidelity = 0.502723\tKL_Divergence = 3.047347\n",
      "Epoch: 19\tFidelity = 0.502709\tKL_Divergence = 3.050117\n",
      "Epoch: 20\tFidelity = 0.502721\tKL_Divergence = 3.047670\n",
      "Epoch: 21\tFidelity = 0.503015\tKL_Divergence = 2.990688\n",
      "Epoch: 22\tFidelity = 0.502810\tKL_Divergence = 3.029819\n",
      "Epoch: 23\tFidelity = 0.502684\tKL_Divergence = 3.055332\n",
      "Epoch: 24\tFidelity = 0.502830\tKL_Divergence = 3.025944\n",
      "Epoch: 25\tFidelity = 0.502694\tKL_Divergence = 3.053185\n",
      "Epoch: 26\tFidelity = 0.502643\tKL_Divergence = 3.063986\n",
      "Epoch: 27\tFidelity = 0.502726\tKL_Divergence = 3.046811\n",
      "Epoch: 28\tFidelity = 0.503190\tKL_Divergence = 2.959391\n",
      "Epoch: 29\tFidelity = 0.502454\tKL_Divergence = 3.105099\n",
      "Epoch: 30\tFidelity = 0.502846\tKL_Divergence = 3.022776\n",
      "Epoch: 31\tFidelity = 0.503121\tKL_Divergence = 2.971514\n",
      "Epoch: 32\tFidelity = 0.502952\tKL_Divergence = 3.002456\n",
      "Epoch: 33\tFidelity = 0.502897\tKL_Divergence = 3.012953\n",
      "Epoch: 34\tFidelity = 0.503207\tKL_Divergence = 2.956308\n",
      "Epoch: 35\tFidelity = 0.502913\tKL_Divergence = 3.009916\n",
      "Epoch: 36\tFidelity = 0.503220\tKL_Divergence = 2.954052\n",
      "Epoch: 37\tFidelity = 0.502841\tKL_Divergence = 3.023661\n",
      "Epoch: 38\tFidelity = 0.502832\tKL_Divergence = 3.025535\n",
      "Epoch: 39\tFidelity = 0.502607\tKL_Divergence = 3.071517\n",
      "Epoch: 40\tFidelity = 0.503055\tKL_Divergence = 2.983296\n",
      "Epoch: 41\tFidelity = 0.502868\tKL_Divergence = 3.018415\n",
      "Epoch: 42\tFidelity = 0.503023\tKL_Divergence = 2.989143\n",
      "Epoch: 43\tFidelity = 0.502845\tKL_Divergence = 3.022992\n",
      "Epoch: 44\tFidelity = 0.502539\tKL_Divergence = 3.086079\n",
      "Epoch: 45\tFidelity = 0.502889\tKL_Divergence = 3.014441\n",
      "Epoch: 46\tFidelity = 0.502808\tKL_Divergence = 3.030165\n",
      "Epoch: 47\tFidelity = 0.502802\tKL_Divergence = 3.031404\n",
      "Epoch: 48\tFidelity = 0.503038\tKL_Divergence = 2.986471\n",
      "Epoch: 49\tFidelity = 0.502835\tKL_Divergence = 3.025022\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:25:53,273] Trial 294 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.502580\tKL_Divergence = 3.077422\n",
      "Total time elapsed during training: 37.317 s\n",
      "Trial 294 pruned. \n",
      "Epoch: 1\tFidelity = 0.502762\tKL_Divergence = 3.039339\n",
      "Epoch: 2\tFidelity = 0.502538\tKL_Divergence = 3.086441\n",
      "Epoch: 3\tFidelity = 0.502791\tKL_Divergence = 3.033549\n",
      "Epoch: 4\tFidelity = 0.503032\tKL_Divergence = 2.987486\n",
      "Epoch: 5\tFidelity = 0.502610\tKL_Divergence = 3.070975\n",
      "Epoch: 6\tFidelity = 0.503091\tKL_Divergence = 2.976868\n",
      "Epoch: 7\tFidelity = 0.502895\tKL_Divergence = 3.013222\n",
      "Epoch: 8\tFidelity = 0.502970\tKL_Divergence = 2.999059\n",
      "Epoch: 9\tFidelity = 0.502938\tKL_Divergence = 3.005038\n",
      "Epoch: 10\tFidelity = 0.502901\tKL_Divergence = 3.012124\n",
      "Epoch: 11\tFidelity = 0.502641\tKL_Divergence = 3.064425\n",
      "Epoch: 12\tFidelity = 0.502943\tKL_Divergence = 3.004094\n",
      "Epoch: 13\tFidelity = 0.502581\tKL_Divergence = 3.077142\n",
      "Epoch: 14\tFidelity = 0.502646\tKL_Divergence = 3.063328\n",
      "Epoch: 15\tFidelity = 0.502668\tKL_Divergence = 3.058751\n",
      "Epoch: 16\tFidelity = 0.502727\tKL_Divergence = 3.046484\n",
      "Epoch: 17\tFidelity = 0.502829\tKL_Divergence = 3.026147\n",
      "Epoch: 18\tFidelity = 0.502897\tKL_Divergence = 3.012824\n",
      "Epoch: 19\tFidelity = 0.502904\tKL_Divergence = 3.011629\n",
      "Epoch: 20\tFidelity = 0.502659\tKL_Divergence = 3.060620\n",
      "Epoch: 21\tFidelity = 0.503030\tKL_Divergence = 2.987905\n",
      "Epoch: 22\tFidelity = 0.502934\tKL_Divergence = 3.005751\n",
      "Epoch: 23\tFidelity = 0.502544\tKL_Divergence = 3.085032\n",
      "Epoch: 24\tFidelity = 0.503162\tKL_Divergence = 2.964214\n",
      "Epoch: 25\tFidelity = 0.503032\tKL_Divergence = 2.987550\n",
      "Epoch: 26\tFidelity = 0.503034\tKL_Divergence = 2.987139\n",
      "Epoch: 27\tFidelity = 0.502842\tKL_Divergence = 3.023638\n",
      "Epoch: 28\tFidelity = 0.502742\tKL_Divergence = 3.043519\n",
      "Epoch: 29\tFidelity = 0.502964\tKL_Divergence = 3.000182\n",
      "Epoch: 30\tFidelity = 0.503158\tKL_Divergence = 2.964951\n",
      "Epoch: 31\tFidelity = 0.502811\tKL_Divergence = 3.029587\n",
      "Epoch: 32\tFidelity = 0.503100\tKL_Divergence = 2.975270\n",
      "Epoch: 33\tFidelity = 0.502755\tKL_Divergence = 3.040903\n",
      "Epoch: 34\tFidelity = 0.503008\tKL_Divergence = 2.991974\n",
      "Epoch: 35\tFidelity = 0.502670\tKL_Divergence = 3.058297\n",
      "Epoch: 36\tFidelity = 0.502955\tKL_Divergence = 3.001778\n",
      "Epoch: 37\tFidelity = 0.503035\tKL_Divergence = 2.986993\n",
      "Epoch: 38\tFidelity = 0.502692\tKL_Divergence = 3.053611\n",
      "Epoch: 39\tFidelity = 0.502921\tKL_Divergence = 3.008279\n",
      "Epoch: 40\tFidelity = 0.502679\tKL_Divergence = 3.056339\n",
      "Epoch: 41\tFidelity = 0.503428\tKL_Divergence = 2.919231\n",
      "Epoch: 42\tFidelity = 0.502760\tKL_Divergence = 3.039857\n",
      "Epoch: 43\tFidelity = 0.502657\tKL_Divergence = 3.060973\n",
      "Epoch: 44\tFidelity = 0.502986\tKL_Divergence = 2.996006\n",
      "Epoch: 45\tFidelity = 0.503250\tKL_Divergence = 2.948963\n",
      "Epoch: 46\tFidelity = 0.503062\tKL_Divergence = 2.982006\n",
      "Epoch: 47\tFidelity = 0.502998\tKL_Divergence = 2.993780\n",
      "Epoch: 48\tFidelity = 0.502811\tKL_Divergence = 3.029585\n",
      "Epoch: 49\tFidelity = 0.502928\tKL_Divergence = 3.007064\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:27:11,161] Trial 295 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.502897\tKL_Divergence = 3.013004\n",
      "Total time elapsed during training: 77.738 s\n",
      "Trial 295 pruned. \n",
      "Epoch: 1\tFidelity = 0.502322\tKL_Divergence = 3.135876\n",
      "Epoch: 2\tFidelity = 0.502931\tKL_Divergence = 3.006480\n",
      "Epoch: 3\tFidelity = 0.502980\tKL_Divergence = 2.997307\n",
      "Epoch: 4\tFidelity = 0.502755\tKL_Divergence = 3.040832\n",
      "Epoch: 5\tFidelity = 0.502698\tKL_Divergence = 3.052567\n",
      "Epoch: 6\tFidelity = 0.502661\tKL_Divergence = 3.060184\n",
      "Epoch: 7\tFidelity = 0.502882\tKL_Divergence = 3.015763\n",
      "Epoch: 8\tFidelity = 0.502910\tKL_Divergence = 3.010403\n",
      "Epoch: 9\tFidelity = 0.502941\tKL_Divergence = 3.004589\n",
      "Epoch: 10\tFidelity = 0.502899\tKL_Divergence = 3.012550\n",
      "Epoch: 11\tFidelity = 0.502628\tKL_Divergence = 3.067084\n",
      "Epoch: 12\tFidelity = 0.502813\tKL_Divergence = 3.029398\n",
      "Epoch: 13\tFidelity = 0.503016\tKL_Divergence = 2.990642\n",
      "Epoch: 14\tFidelity = 0.502918\tKL_Divergence = 3.009020\n",
      "Epoch: 15\tFidelity = 0.502647\tKL_Divergence = 3.063123\n",
      "Epoch: 16\tFidelity = 0.502511\tKL_Divergence = 3.092559\n",
      "Epoch: 17\tFidelity = 0.502938\tKL_Divergence = 3.005152\n",
      "Epoch: 18\tFidelity = 0.502341\tKL_Divergence = 3.131372\n",
      "Epoch: 19\tFidelity = 0.502956\tKL_Divergence = 3.001838\n",
      "Epoch: 20\tFidelity = 0.502499\tKL_Divergence = 3.095074\n",
      "Epoch: 21\tFidelity = 0.502541\tKL_Divergence = 3.085816\n",
      "Epoch: 22\tFidelity = 0.502791\tKL_Divergence = 3.033529\n",
      "Epoch: 23\tFidelity = 0.502904\tKL_Divergence = 3.011469\n",
      "Epoch: 24\tFidelity = 0.502759\tKL_Divergence = 3.039953\n",
      "Epoch: 25\tFidelity = 0.502856\tKL_Divergence = 3.020759\n",
      "Epoch: 26\tFidelity = 0.502962\tKL_Divergence = 3.000667\n",
      "Epoch: 27\tFidelity = 0.503159\tKL_Divergence = 2.964854\n",
      "Epoch: 28\tFidelity = 0.502537\tKL_Divergence = 3.086599\n",
      "Epoch: 29\tFidelity = 0.502878\tKL_Divergence = 3.016512\n",
      "Epoch: 30\tFidelity = 0.502657\tKL_Divergence = 3.060964\n",
      "Epoch: 31\tFidelity = 0.502842\tKL_Divergence = 3.023544\n",
      "Epoch: 32\tFidelity = 0.503041\tKL_Divergence = 2.985882\n",
      "Epoch: 33\tFidelity = 0.502902\tKL_Divergence = 3.011899\n",
      "Epoch: 34\tFidelity = 0.502937\tKL_Divergence = 3.005262\n",
      "Epoch: 35\tFidelity = 0.502918\tKL_Divergence = 3.008903\n",
      "Epoch: 36\tFidelity = 0.502546\tKL_Divergence = 3.084632\n",
      "Epoch: 37\tFidelity = 0.502572\tKL_Divergence = 3.079026\n",
      "Epoch: 38\tFidelity = 0.502931\tKL_Divergence = 3.006398\n",
      "Epoch: 39\tFidelity = 0.502967\tKL_Divergence = 2.999608\n",
      "Epoch: 40\tFidelity = 0.502816\tKL_Divergence = 3.028740\n",
      "Epoch: 41\tFidelity = 0.502432\tKL_Divergence = 3.110220\n",
      "Epoch: 42\tFidelity = 0.503212\tKL_Divergence = 2.955467\n",
      "Epoch: 43\tFidelity = 0.502808\tKL_Divergence = 3.030088\n",
      "Epoch: 44\tFidelity = 0.502477\tKL_Divergence = 3.099923\n",
      "Epoch: 45\tFidelity = 0.503060\tKL_Divergence = 2.982200\n",
      "Epoch: 46\tFidelity = 0.502438\tKL_Divergence = 3.108731\n",
      "Epoch: 47\tFidelity = 0.502930\tKL_Divergence = 3.006551\n",
      "Epoch: 48\tFidelity = 0.502833\tKL_Divergence = 3.025232\n",
      "Epoch: 49\tFidelity = 0.502642\tKL_Divergence = 3.063848\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:27:48,227] Trial 296 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.502824\tKL_Divergence = 3.026725\n",
      "Total time elapsed during training: 36.904 s\n",
      "Trial 296 pruned. \n",
      "Epoch: 1\tFidelity = 0.502943\tKL_Divergence = 3.003892\n",
      "Epoch: 2\tFidelity = 0.502921\tKL_Divergence = 3.008059\n",
      "Epoch: 3\tFidelity = 0.502746\tKL_Divergence = 3.042462\n",
      "Epoch: 4\tFidelity = 0.502973\tKL_Divergence = 2.998432\n",
      "Epoch: 5\tFidelity = 0.502461\tKL_Divergence = 3.103618\n",
      "Epoch: 6\tFidelity = 0.502853\tKL_Divergence = 3.021383\n",
      "Epoch: 7\tFidelity = 0.502455\tKL_Divergence = 3.105042\n",
      "Epoch: 8\tFidelity = 0.503058\tKL_Divergence = 2.982819\n",
      "Epoch: 9\tFidelity = 0.502768\tKL_Divergence = 3.038349\n",
      "Epoch: 10\tFidelity = 0.502696\tKL_Divergence = 3.052899\n",
      "Epoch: 11\tFidelity = 0.502453\tKL_Divergence = 3.105420\n",
      "Epoch: 12\tFidelity = 0.502573\tKL_Divergence = 3.078888\n",
      "Epoch: 13\tFidelity = 0.502879\tKL_Divergence = 3.016399\n",
      "Epoch: 14\tFidelity = 0.502622\tKL_Divergence = 3.068392\n",
      "Epoch: 15\tFidelity = 0.502903\tKL_Divergence = 3.011797\n",
      "Epoch: 16\tFidelity = 0.502498\tKL_Divergence = 3.095381\n",
      "Epoch: 17\tFidelity = 0.502580\tKL_Divergence = 3.077472\n",
      "Epoch: 18\tFidelity = 0.502484\tKL_Divergence = 3.098439\n",
      "Epoch: 19\tFidelity = 0.503398\tKL_Divergence = 2.924304\n",
      "Epoch: 20\tFidelity = 0.502351\tKL_Divergence = 3.129165\n",
      "Epoch: 21\tFidelity = 0.502783\tKL_Divergence = 3.035234\n",
      "Epoch: 22\tFidelity = 0.502205\tKL_Divergence = 3.164634\n",
      "Epoch: 23\tFidelity = 0.503078\tKL_Divergence = 2.979318\n",
      "Epoch: 24\tFidelity = 0.502446\tKL_Divergence = 3.107057\n",
      "Epoch: 25\tFidelity = 0.502644\tKL_Divergence = 3.063883\n",
      "Epoch: 26\tFidelity = 0.502816\tKL_Divergence = 3.028730\n",
      "Epoch: 27\tFidelity = 0.502507\tKL_Divergence = 3.093341\n",
      "Epoch: 28\tFidelity = 0.502522\tKL_Divergence = 3.090104\n",
      "Epoch: 29\tFidelity = 0.502593\tKL_Divergence = 3.074503\n",
      "Epoch: 30\tFidelity = 0.502769\tKL_Divergence = 3.038083\n",
      "Epoch: 31\tFidelity = 0.502614\tKL_Divergence = 3.070201\n",
      "Epoch: 32\tFidelity = 0.502791\tKL_Divergence = 3.033693\n",
      "Epoch: 33\tFidelity = 0.502891\tKL_Divergence = 3.014216\n",
      "Epoch: 34\tFidelity = 0.502472\tKL_Divergence = 3.101178\n",
      "Epoch: 35\tFidelity = 0.502827\tKL_Divergence = 3.026689\n",
      "Epoch: 36\tFidelity = 0.503350\tKL_Divergence = 2.932122\n",
      "Epoch: 37\tFidelity = 0.502652\tKL_Divergence = 3.062079\n",
      "Epoch: 38\tFidelity = 0.502685\tKL_Divergence = 3.055131\n",
      "Epoch: 39\tFidelity = 0.503057\tKL_Divergence = 2.983113\n",
      "Epoch: 40\tFidelity = 0.502547\tKL_Divergence = 3.084528\n",
      "Epoch: 41\tFidelity = 0.502863\tKL_Divergence = 3.019475\n",
      "Epoch: 42\tFidelity = 0.502358\tKL_Divergence = 3.127490\n",
      "Epoch: 43\tFidelity = 0.502891\tKL_Divergence = 3.014094\n",
      "Epoch: 44\tFidelity = 0.502509\tKL_Divergence = 3.092887\n",
      "Epoch: 45\tFidelity = 0.502906\tKL_Divergence = 3.011164\n",
      "Epoch: 46\tFidelity = 0.502428\tKL_Divergence = 3.110989\n",
      "Epoch: 47\tFidelity = 0.503081\tKL_Divergence = 2.978664\n",
      "Epoch: 48\tFidelity = 0.502686\tKL_Divergence = 3.054972\n",
      "Epoch: 49\tFidelity = 0.502819\tKL_Divergence = 3.028039\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:28:31,992] Trial 297 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.502822\tKL_Divergence = 3.027545\n",
      "Total time elapsed during training: 43.610 s\n",
      "Trial 297 pruned. \n",
      "Epoch: 1\tFidelity = 0.502677\tKL_Divergence = 3.056928\n",
      "Epoch: 2\tFidelity = 0.503124\tKL_Divergence = 2.971003\n",
      "Epoch: 3\tFidelity = 0.502352\tKL_Divergence = 3.128775\n",
      "Epoch: 4\tFidelity = 0.502592\tKL_Divergence = 3.074790\n",
      "Epoch: 5\tFidelity = 0.502802\tKL_Divergence = 3.031413\n",
      "Epoch: 6\tFidelity = 0.502525\tKL_Divergence = 3.089422\n",
      "Epoch: 7\tFidelity = 0.502637\tKL_Divergence = 3.065151\n",
      "Epoch: 8\tFidelity = 0.502640\tKL_Divergence = 3.064568\n",
      "Epoch: 9\tFidelity = 0.502759\tKL_Divergence = 3.040046\n",
      "Epoch: 10\tFidelity = 0.502946\tKL_Divergence = 3.003641\n",
      "Epoch: 11\tFidelity = 0.502905\tKL_Divergence = 3.011435\n",
      "Epoch: 12\tFidelity = 0.502678\tKL_Divergence = 3.056578\n",
      "Epoch: 13\tFidelity = 0.502671\tKL_Divergence = 3.058041\n",
      "Epoch: 14\tFidelity = 0.502496\tKL_Divergence = 3.095855\n",
      "Epoch: 15\tFidelity = 0.502516\tKL_Divergence = 3.091271\n",
      "Epoch: 16\tFidelity = 0.502648\tKL_Divergence = 3.062855\n",
      "Epoch: 17\tFidelity = 0.502702\tKL_Divergence = 3.051673\n",
      "Epoch: 18\tFidelity = 0.503044\tKL_Divergence = 2.985319\n",
      "Epoch: 19\tFidelity = 0.502899\tKL_Divergence = 3.012511\n",
      "Epoch: 20\tFidelity = 0.502787\tKL_Divergence = 3.034471\n",
      "Epoch: 21\tFidelity = 0.502505\tKL_Divergence = 3.093782\n",
      "Epoch: 22\tFidelity = 0.502727\tKL_Divergence = 3.046520\n",
      "Epoch: 23\tFidelity = 0.502606\tKL_Divergence = 3.071847\n",
      "Epoch: 24\tFidelity = 0.502834\tKL_Divergence = 3.025068\n",
      "Epoch: 25\tFidelity = 0.502901\tKL_Divergence = 3.012200\n",
      "Epoch: 26\tFidelity = 0.502456\tKL_Divergence = 3.104689\n",
      "Epoch: 27\tFidelity = 0.502854\tKL_Divergence = 3.021219\n",
      "Epoch: 28\tFidelity = 0.502730\tKL_Divergence = 3.045861\n",
      "Epoch: 29\tFidelity = 0.502706\tKL_Divergence = 3.050838\n",
      "Epoch: 30\tFidelity = 0.502727\tKL_Divergence = 3.046595\n",
      "Epoch: 31\tFidelity = 0.502577\tKL_Divergence = 3.077958\n",
      "Epoch: 32\tFidelity = 0.502750\tKL_Divergence = 3.041806\n",
      "Epoch: 33\tFidelity = 0.502943\tKL_Divergence = 3.004141\n",
      "Epoch: 34\tFidelity = 0.502676\tKL_Divergence = 3.057063\n",
      "Epoch: 35\tFidelity = 0.502794\tKL_Divergence = 3.033057\n",
      "Epoch: 36\tFidelity = 0.502968\tKL_Divergence = 2.999410\n",
      "Epoch: 37\tFidelity = 0.502791\tKL_Divergence = 3.033663\n",
      "Epoch: 38\tFidelity = 0.502979\tKL_Divergence = 2.997492\n",
      "Epoch: 39\tFidelity = 0.502679\tKL_Divergence = 3.056508\n",
      "Epoch: 40\tFidelity = 0.502538\tKL_Divergence = 3.086490\n",
      "Epoch: 41\tFidelity = 0.502755\tKL_Divergence = 3.040946\n",
      "Epoch: 42\tFidelity = 0.502942\tKL_Divergence = 3.004350\n",
      "Epoch: 43\tFidelity = 0.502968\tKL_Divergence = 2.999463\n",
      "Epoch: 44\tFidelity = 0.503068\tKL_Divergence = 2.981072\n",
      "Epoch: 45\tFidelity = 0.502588\tKL_Divergence = 3.075566\n",
      "Epoch: 46\tFidelity = 0.502812\tKL_Divergence = 3.029501\n",
      "Epoch: 47\tFidelity = 0.502366\tKL_Divergence = 3.125496\n",
      "Epoch: 48\tFidelity = 0.502653\tKL_Divergence = 3.061878\n",
      "Epoch: 49\tFidelity = 0.502361\tKL_Divergence = 3.126826\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:29:09,395] Trial 298 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.502472\tKL_Divergence = 3.101161\n",
      "Total time elapsed during training: 37.244 s\n",
      "Trial 298 pruned. \n",
      "Epoch: 1\tFidelity = 0.503025\tKL_Divergence = 2.988955\n",
      "Epoch: 2\tFidelity = 0.502736\tKL_Divergence = 3.044685\n",
      "Epoch: 3\tFidelity = 0.502506\tKL_Divergence = 3.093485\n",
      "Epoch: 4\tFidelity = 0.502901\tKL_Divergence = 3.012174\n",
      "Epoch: 5\tFidelity = 0.502587\tKL_Divergence = 3.075957\n",
      "Epoch: 6\tFidelity = 0.502999\tKL_Divergence = 2.993802\n",
      "Epoch: 7\tFidelity = 0.502637\tKL_Divergence = 3.065350\n",
      "Epoch: 8\tFidelity = 0.502563\tKL_Divergence = 3.081005\n",
      "Epoch: 9\tFidelity = 0.502439\tKL_Divergence = 3.108675\n",
      "Epoch: 10\tFidelity = 0.503086\tKL_Divergence = 2.977780\n",
      "Epoch: 11\tFidelity = 0.502802\tKL_Divergence = 3.031533\n",
      "Epoch: 12\tFidelity = 0.502359\tKL_Divergence = 3.127146\n",
      "Epoch: 13\tFidelity = 0.502801\tKL_Divergence = 3.031800\n",
      "Epoch: 14\tFidelity = 0.502661\tKL_Divergence = 3.060265\n",
      "Epoch: 15\tFidelity = 0.502693\tKL_Divergence = 3.053650\n",
      "Epoch: 16\tFidelity = 0.502568\tKL_Divergence = 3.080006\n",
      "Epoch: 17\tFidelity = 0.502480\tKL_Divergence = 3.099365\n",
      "Epoch: 18\tFidelity = 0.502802\tKL_Divergence = 3.031613\n",
      "Epoch: 19\tFidelity = 0.503029\tKL_Divergence = 2.988292\n",
      "Epoch: 20\tFidelity = 0.502935\tKL_Divergence = 3.005799\n",
      "Epoch: 21\tFidelity = 0.502322\tKL_Divergence = 3.136003\n",
      "Epoch: 22\tFidelity = 0.502377\tKL_Divergence = 3.122969\n",
      "Epoch: 23\tFidelity = 0.502601\tKL_Divergence = 3.073028\n",
      "Epoch: 24\tFidelity = 0.502452\tKL_Divergence = 3.105699\n",
      "Epoch: 25\tFidelity = 0.502671\tKL_Divergence = 3.058023\n",
      "Epoch: 26\tFidelity = 0.502850\tKL_Divergence = 3.022121\n",
      "Epoch: 27\tFidelity = 0.502690\tKL_Divergence = 3.054105\n",
      "Epoch: 28\tFidelity = 0.502535\tKL_Divergence = 3.087156\n",
      "Epoch: 29\tFidelity = 0.502318\tKL_Divergence = 3.137007\n",
      "Epoch: 30\tFidelity = 0.502516\tKL_Divergence = 3.091267\n",
      "Epoch: 31\tFidelity = 0.502670\tKL_Divergence = 3.058202\n",
      "Epoch: 32\tFidelity = 0.502930\tKL_Divergence = 3.006610\n",
      "Epoch: 33\tFidelity = 0.502494\tKL_Divergence = 3.096124\n",
      "Epoch: 34\tFidelity = 0.502725\tKL_Divergence = 3.046839\n",
      "Epoch: 35\tFidelity = 0.502485\tKL_Divergence = 3.098125\n",
      "Epoch: 36\tFidelity = 0.502530\tKL_Divergence = 3.088271\n",
      "Epoch: 37\tFidelity = 0.502569\tKL_Divergence = 3.079823\n",
      "Epoch: 38\tFidelity = 0.502418\tKL_Divergence = 3.113428\n",
      "Epoch: 39\tFidelity = 0.502640\tKL_Divergence = 3.064472\n",
      "Epoch: 40\tFidelity = 0.502517\tKL_Divergence = 3.091068\n",
      "Epoch: 41\tFidelity = 0.502809\tKL_Divergence = 3.029888\n",
      "Epoch: 42\tFidelity = 0.502935\tKL_Divergence = 3.005687\n",
      "Epoch: 43\tFidelity = 0.502613\tKL_Divergence = 3.070113\n",
      "Epoch: 44\tFidelity = 0.502975\tKL_Divergence = 2.998023\n",
      "Epoch: 45\tFidelity = 0.502733\tKL_Divergence = 3.045179\n",
      "Epoch: 46\tFidelity = 0.503137\tKL_Divergence = 2.968542\n",
      "Epoch: 47\tFidelity = 0.502861\tKL_Divergence = 3.019826\n",
      "Epoch: 48\tFidelity = 0.502470\tKL_Divergence = 3.101570\n",
      "Epoch: 49\tFidelity = 0.502471\tKL_Divergence = 3.101399\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:30:06,087] Trial 299 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.502568\tKL_Divergence = 3.079879\n",
      "Total time elapsed during training: 56.538 s\n",
      "Trial 299 pruned. \n",
      "Epoch: 1\tFidelity = 0.502164\tKL_Divergence = 3.175159\n",
      "Epoch: 2\tFidelity = 0.502381\tKL_Divergence = 3.122076\n",
      "Epoch: 3\tFidelity = 0.502720\tKL_Divergence = 3.048027\n",
      "Epoch: 4\tFidelity = 0.502758\tKL_Divergence = 3.040230\n",
      "Epoch: 5\tFidelity = 0.502554\tKL_Divergence = 3.082912\n",
      "Epoch: 6\tFidelity = 0.502404\tKL_Divergence = 3.116639\n",
      "Epoch: 7\tFidelity = 0.502827\tKL_Divergence = 3.026559\n",
      "Epoch: 8\tFidelity = 0.502419\tKL_Divergence = 3.113168\n",
      "Epoch: 9\tFidelity = 0.502334\tKL_Divergence = 3.132955\n",
      "Epoch: 10\tFidelity = 0.503013\tKL_Divergence = 2.990946\n",
      "Epoch: 11\tFidelity = 0.503124\tKL_Divergence = 2.970913\n",
      "Epoch: 12\tFidelity = 0.502585\tKL_Divergence = 3.076373\n",
      "Epoch: 13\tFidelity = 0.502782\tKL_Divergence = 3.035436\n",
      "Epoch: 14\tFidelity = 0.502369\tKL_Divergence = 3.124678\n",
      "Epoch: 15\tFidelity = 0.502618\tKL_Divergence = 3.069224\n",
      "Epoch: 16\tFidelity = 0.502473\tKL_Divergence = 3.100714\n",
      "Epoch: 17\tFidelity = 0.502653\tKL_Divergence = 3.061796\n",
      "Epoch: 18\tFidelity = 0.502764\tKL_Divergence = 3.038981\n",
      "Epoch: 19\tFidelity = 0.502210\tKL_Divergence = 3.163413\n",
      "Epoch: 20\tFidelity = 0.502468\tKL_Divergence = 3.101975\n",
      "Epoch: 21\tFidelity = 0.502316\tKL_Divergence = 3.137279\n",
      "Epoch: 22\tFidelity = 0.502261\tKL_Divergence = 3.150725\n",
      "Epoch: 23\tFidelity = 0.503056\tKL_Divergence = 2.983182\n",
      "Epoch: 24\tFidelity = 0.503038\tKL_Divergence = 2.986406\n",
      "Epoch: 25\tFidelity = 0.502735\tKL_Divergence = 3.044843\n",
      "Epoch: 26\tFidelity = 0.502539\tKL_Divergence = 3.086042\n",
      "Epoch: 27\tFidelity = 0.502453\tKL_Divergence = 3.105194\n",
      "Epoch: 28\tFidelity = 0.503023\tKL_Divergence = 2.989140\n",
      "Epoch: 29\tFidelity = 0.503069\tKL_Divergence = 2.980833\n",
      "Epoch: 30\tFidelity = 0.502592\tKL_Divergence = 3.074626\n",
      "Epoch: 31\tFidelity = 0.502696\tKL_Divergence = 3.052857\n",
      "Epoch: 32\tFidelity = 0.502897\tKL_Divergence = 3.012936\n",
      "Epoch: 33\tFidelity = 0.502530\tKL_Divergence = 3.088035\n",
      "Epoch: 34\tFidelity = 0.502587\tKL_Divergence = 3.075709\n",
      "Epoch: 35\tFidelity = 0.502447\tKL_Divergence = 3.106834\n",
      "Epoch: 36\tFidelity = 0.502584\tKL_Divergence = 3.076553\n",
      "Epoch: 37\tFidelity = 0.502393\tKL_Divergence = 3.119200\n",
      "Epoch: 38\tFidelity = 0.502611\tKL_Divergence = 3.070619\n",
      "Epoch: 39\tFidelity = 0.502995\tKL_Divergence = 2.994280\n",
      "Epoch: 40\tFidelity = 0.502959\tKL_Divergence = 3.001126\n",
      "Epoch: 41\tFidelity = 0.502995\tKL_Divergence = 2.994336\n",
      "Epoch: 42\tFidelity = 0.502775\tKL_Divergence = 3.036816\n",
      "Epoch: 43\tFidelity = 0.503019\tKL_Divergence = 2.989801\n",
      "Epoch: 44\tFidelity = 0.502539\tKL_Divergence = 3.086122\n",
      "Epoch: 45\tFidelity = 0.502845\tKL_Divergence = 3.023010\n",
      "Epoch: 46\tFidelity = 0.502642\tKL_Divergence = 3.063988\n",
      "Epoch: 47\tFidelity = 0.503173\tKL_Divergence = 2.962290\n",
      "Epoch: 48\tFidelity = 0.502653\tKL_Divergence = 3.061867\n",
      "Epoch: 49\tFidelity = 0.502757\tKL_Divergence = 3.040244\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:31:25,137] Trial 300 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.502788\tKL_Divergence = 3.034046\n",
      "Total time elapsed during training: 78.862 s\n",
      "Trial 300 pruned. \n",
      "Epoch: 1\tFidelity = 0.502873\tKL_Divergence = 3.017319\n",
      "Epoch: 2\tFidelity = 0.503117\tKL_Divergence = 2.971877\n",
      "Epoch: 3\tFidelity = 0.502789\tKL_Divergence = 3.033679\n",
      "Epoch: 4\tFidelity = 0.502889\tKL_Divergence = 3.014163\n",
      "Epoch: 5\tFidelity = 0.502729\tKL_Divergence = 3.045982\n",
      "Epoch: 6\tFidelity = 0.502853\tKL_Divergence = 3.021236\n",
      "Epoch: 7\tFidelity = 0.502823\tKL_Divergence = 3.027147\n",
      "Epoch: 8\tFidelity = 0.502850\tKL_Divergence = 3.021883\n",
      "Epoch: 9\tFidelity = 0.502553\tKL_Divergence = 3.082924\n",
      "Epoch: 10\tFidelity = 0.502662\tKL_Divergence = 3.059711\n",
      "Epoch: 11\tFidelity = 0.502504\tKL_Divergence = 3.093837\n",
      "Epoch: 12\tFidelity = 0.502754\tKL_Divergence = 3.040773\n",
      "Epoch: 13\tFidelity = 0.502759\tKL_Divergence = 3.039853\n",
      "Epoch: 14\tFidelity = 0.502620\tKL_Divergence = 3.068644\n",
      "Epoch: 15\tFidelity = 0.502790\tKL_Divergence = 3.033655\n",
      "Epoch: 16\tFidelity = 0.502925\tKL_Divergence = 3.007462\n",
      "Epoch: 17\tFidelity = 0.502552\tKL_Divergence = 3.083305\n",
      "Epoch: 18\tFidelity = 0.502912\tKL_Divergence = 3.009945\n",
      "Epoch: 19\tFidelity = 0.502889\tKL_Divergence = 3.014400\n",
      "Epoch: 20\tFidelity = 0.502944\tKL_Divergence = 3.003839\n",
      "Epoch: 21\tFidelity = 0.502621\tKL_Divergence = 3.068367\n",
      "Epoch: 22\tFidelity = 0.502852\tKL_Divergence = 3.021581\n",
      "Epoch: 23\tFidelity = 0.502914\tKL_Divergence = 3.009464\n",
      "Epoch: 24\tFidelity = 0.502704\tKL_Divergence = 3.051206\n",
      "Epoch: 25\tFidelity = 0.502772\tKL_Divergence = 3.037367\n",
      "Epoch: 26\tFidelity = 0.502841\tKL_Divergence = 3.023576\n",
      "Epoch: 27\tFidelity = 0.502732\tKL_Divergence = 3.045357\n",
      "Epoch: 28\tFidelity = 0.502560\tKL_Divergence = 3.081579\n",
      "Epoch: 29\tFidelity = 0.502809\tKL_Divergence = 3.029892\n",
      "Epoch: 30\tFidelity = 0.502508\tKL_Divergence = 3.093047\n",
      "Epoch: 31\tFidelity = 0.502781\tKL_Divergence = 3.035497\n",
      "Epoch: 32\tFidelity = 0.502807\tKL_Divergence = 3.030385\n",
      "Epoch: 33\tFidelity = 0.502848\tKL_Divergence = 3.022391\n",
      "Epoch: 34\tFidelity = 0.502902\tKL_Divergence = 3.011971\n",
      "Epoch: 35\tFidelity = 0.502715\tKL_Divergence = 3.048996\n",
      "Epoch: 36\tFidelity = 0.502773\tKL_Divergence = 3.037232\n",
      "Epoch: 37\tFidelity = 0.502890\tKL_Divergence = 3.014215\n",
      "Epoch: 38\tFidelity = 0.502740\tKL_Divergence = 3.043921\n",
      "Epoch: 39\tFidelity = 0.502858\tKL_Divergence = 3.020399\n",
      "Epoch: 40\tFidelity = 0.502516\tKL_Divergence = 3.091178\n",
      "Epoch: 41\tFidelity = 0.502886\tKL_Divergence = 3.014956\n",
      "Epoch: 42\tFidelity = 0.502665\tKL_Divergence = 3.059152\n",
      "Epoch: 43\tFidelity = 0.502773\tKL_Divergence = 3.037119\n",
      "Epoch: 44\tFidelity = 0.502735\tKL_Divergence = 3.044907\n",
      "Epoch: 45\tFidelity = 0.502688\tKL_Divergence = 3.054408\n",
      "Epoch: 46\tFidelity = 0.502975\tKL_Divergence = 2.998048\n",
      "Epoch: 47\tFidelity = 0.502570\tKL_Divergence = 3.079477\n",
      "Epoch: 48\tFidelity = 0.502971\tKL_Divergence = 2.998766\n",
      "Epoch: 49\tFidelity = 0.502848\tKL_Divergence = 3.022399\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:31:56,647] Trial 301 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.502743\tKL_Divergence = 3.043349\n",
      "Total time elapsed during training: 31.348 s\n",
      "Trial 301 pruned. \n",
      "Epoch: 1\tFidelity = 0.503040\tKL_Divergence = 2.986061\n",
      "Epoch: 2\tFidelity = 0.503094\tKL_Divergence = 2.976215\n",
      "Epoch: 3\tFidelity = 0.503091\tKL_Divergence = 2.976842\n",
      "Epoch: 4\tFidelity = 0.503170\tKL_Divergence = 2.962840\n",
      "Epoch: 5\tFidelity = 0.502754\tKL_Divergence = 3.041136\n",
      "Epoch: 6\tFidelity = 0.502470\tKL_Divergence = 3.101438\n",
      "Epoch: 7\tFidelity = 0.502900\tKL_Divergence = 3.012260\n",
      "Epoch: 8\tFidelity = 0.502959\tKL_Divergence = 3.001115\n",
      "Epoch: 9\tFidelity = 0.502827\tKL_Divergence = 3.026477\n",
      "Epoch: 10\tFidelity = 0.502914\tKL_Divergence = 3.009621\n",
      "Epoch: 11\tFidelity = 0.502608\tKL_Divergence = 3.071374\n",
      "Epoch: 12\tFidelity = 0.502450\tKL_Divergence = 3.106134\n",
      "Epoch: 13\tFidelity = 0.502452\tKL_Divergence = 3.105684\n",
      "Epoch: 14\tFidelity = 0.502403\tKL_Divergence = 3.116868\n",
      "Epoch: 15\tFidelity = 0.502447\tKL_Divergence = 3.106837\n",
      "Epoch: 16\tFidelity = 0.502240\tKL_Divergence = 3.155767\n",
      "Epoch: 17\tFidelity = 0.502318\tKL_Divergence = 3.136766\n",
      "Epoch: 18\tFidelity = 0.502777\tKL_Divergence = 3.036463\n",
      "Epoch: 19\tFidelity = 0.502513\tKL_Divergence = 3.091943\n",
      "Epoch: 20\tFidelity = 0.502287\tKL_Divergence = 3.144399\n",
      "Epoch: 21\tFidelity = 0.502546\tKL_Divergence = 3.084639\n",
      "Epoch: 22\tFidelity = 0.502465\tKL_Divergence = 3.102620\n",
      "Epoch: 23\tFidelity = 0.502740\tKL_Divergence = 3.043828\n",
      "Epoch: 24\tFidelity = 0.502867\tKL_Divergence = 3.018642\n",
      "Epoch: 25\tFidelity = 0.502967\tKL_Divergence = 2.999603\n",
      "Epoch: 26\tFidelity = 0.503145\tKL_Divergence = 2.967203\n",
      "Epoch: 27\tFidelity = 0.502584\tKL_Divergence = 3.076452\n",
      "Epoch: 28\tFidelity = 0.502546\tKL_Divergence = 3.084752\n",
      "Epoch: 29\tFidelity = 0.502807\tKL_Divergence = 3.030520\n",
      "Epoch: 30\tFidelity = 0.502733\tKL_Divergence = 3.045396\n",
      "Epoch: 31\tFidelity = 0.503054\tKL_Divergence = 2.983649\n",
      "Epoch: 32\tFidelity = 0.502895\tKL_Divergence = 3.013315\n",
      "Epoch: 33\tFidelity = 0.502876\tKL_Divergence = 3.016926\n",
      "Epoch: 34\tFidelity = 0.502941\tKL_Divergence = 3.004575\n",
      "Epoch: 35\tFidelity = 0.503183\tKL_Divergence = 2.960571\n",
      "Epoch: 36\tFidelity = 0.503153\tKL_Divergence = 2.965886\n",
      "Epoch: 37\tFidelity = 0.503205\tKL_Divergence = 2.956700\n",
      "Epoch: 38\tFidelity = 0.503149\tKL_Divergence = 2.966487\n",
      "Epoch: 39\tFidelity = 0.502671\tKL_Divergence = 3.058123\n",
      "Epoch: 40\tFidelity = 0.503059\tKL_Divergence = 2.982692\n",
      "Epoch: 41\tFidelity = 0.503189\tKL_Divergence = 2.959512\n",
      "Epoch: 42\tFidelity = 0.503250\tKL_Divergence = 2.949022\n",
      "Epoch: 43\tFidelity = 0.503100\tKL_Divergence = 2.975306\n",
      "Epoch: 44\tFidelity = 0.502965\tKL_Divergence = 3.000094\n",
      "Epoch: 45\tFidelity = 0.503013\tKL_Divergence = 2.991149\n",
      "Epoch: 46\tFidelity = 0.503226\tKL_Divergence = 2.953155\n",
      "Epoch: 47\tFidelity = 0.503142\tKL_Divergence = 2.967784\n",
      "Epoch: 48\tFidelity = 0.503023\tKL_Divergence = 2.989259\n",
      "Epoch: 49\tFidelity = 0.502713\tKL_Divergence = 3.049392\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:32:34,954] Trial 302 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.502510\tKL_Divergence = 3.092731\n",
      "Total time elapsed during training: 38.150 s\n",
      "Trial 302 pruned. \n",
      "Epoch: 1\tFidelity = 0.502897\tKL_Divergence = 3.013059\n",
      "Epoch: 2\tFidelity = 0.502878\tKL_Divergence = 3.016579\n",
      "Epoch: 3\tFidelity = 0.502931\tKL_Divergence = 3.006458\n",
      "Epoch: 4\tFidelity = 0.502437\tKL_Divergence = 3.109100\n",
      "Epoch: 5\tFidelity = 0.502814\tKL_Divergence = 3.029035\n",
      "Epoch: 6\tFidelity = 0.502413\tKL_Divergence = 3.114578\n",
      "Epoch: 7\tFidelity = 0.502939\tKL_Divergence = 3.004998\n",
      "Epoch: 8\tFidelity = 0.502266\tKL_Divergence = 3.149406\n",
      "Epoch: 9\tFidelity = 0.503062\tKL_Divergence = 2.982252\n",
      "Epoch: 10\tFidelity = 0.502467\tKL_Divergence = 3.102248\n",
      "Epoch: 11\tFidelity = 0.502994\tKL_Divergence = 2.994732\n",
      "Epoch: 12\tFidelity = 0.502407\tKL_Divergence = 3.116028\n",
      "Epoch: 13\tFidelity = 0.503098\tKL_Divergence = 2.975719\n",
      "Epoch: 14\tFidelity = 0.502420\tKL_Divergence = 3.113006\n",
      "Epoch: 15\tFidelity = 0.503049\tKL_Divergence = 2.984592\n",
      "Epoch: 16\tFidelity = 0.502322\tKL_Divergence = 3.136007\n",
      "Epoch: 17\tFidelity = 0.503146\tKL_Divergence = 2.967101\n",
      "Epoch: 18\tFidelity = 0.502278\tKL_Divergence = 3.146583\n",
      "Epoch: 19\tFidelity = 0.503136\tKL_Divergence = 2.968855\n",
      "Epoch: 20\tFidelity = 0.502224\tKL_Divergence = 3.159781\n",
      "Epoch: 21\tFidelity = 0.503178\tKL_Divergence = 2.961551\n",
      "Epoch: 22\tFidelity = 0.502407\tKL_Divergence = 3.115984\n",
      "Epoch: 23\tFidelity = 0.502841\tKL_Divergence = 3.023761\n",
      "Epoch: 24\tFidelity = 0.502646\tKL_Divergence = 3.063239\n",
      "Epoch: 25\tFidelity = 0.502743\tKL_Divergence = 3.043414\n",
      "Epoch: 26\tFidelity = 0.502493\tKL_Divergence = 3.096362\n",
      "Epoch: 27\tFidelity = 0.502807\tKL_Divergence = 3.030548\n",
      "Epoch: 28\tFidelity = 0.502532\tKL_Divergence = 3.087779\n",
      "Epoch: 29\tFidelity = 0.502808\tKL_Divergence = 3.030334\n",
      "Epoch: 30\tFidelity = 0.502442\tKL_Divergence = 3.107986\n",
      "Epoch: 31\tFidelity = 0.503050\tKL_Divergence = 2.984390\n",
      "Epoch: 32\tFidelity = 0.502490\tKL_Divergence = 3.097010\n",
      "Epoch: 33\tFidelity = 0.502955\tKL_Divergence = 3.002017\n",
      "Epoch: 34\tFidelity = 0.502451\tKL_Divergence = 3.105929\n",
      "Epoch: 35\tFidelity = 0.502852\tKL_Divergence = 3.021610\n",
      "Epoch: 36\tFidelity = 0.502868\tKL_Divergence = 3.018617\n",
      "Epoch: 37\tFidelity = 0.502724\tKL_Divergence = 3.047263\n",
      "Epoch: 38\tFidelity = 0.502649\tKL_Divergence = 3.062635\n",
      "Epoch: 39\tFidelity = 0.502658\tKL_Divergence = 3.060713\n",
      "Epoch: 40\tFidelity = 0.502756\tKL_Divergence = 3.040625\n",
      "Epoch: 41\tFidelity = 0.502602\tKL_Divergence = 3.072641\n",
      "Epoch: 42\tFidelity = 0.502988\tKL_Divergence = 2.995657\n",
      "Epoch: 43\tFidelity = 0.502504\tKL_Divergence = 3.094028\n",
      "Epoch: 44\tFidelity = 0.502748\tKL_Divergence = 3.042206\n",
      "Epoch: 45\tFidelity = 0.503241\tKL_Divergence = 2.950551\n",
      "Epoch: 46\tFidelity = 0.502438\tKL_Divergence = 3.108791\n",
      "Epoch: 47\tFidelity = 0.502915\tKL_Divergence = 3.009511\n",
      "Epoch: 48\tFidelity = 0.502645\tKL_Divergence = 3.063453\n",
      "Epoch: 49\tFidelity = 0.502997\tKL_Divergence = 2.993976\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:33:06,843] Trial 303 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.502825\tKL_Divergence = 3.026906\n",
      "Total time elapsed during training: 31.725 s\n",
      "Trial 303 pruned. \n",
      "Epoch: 1\tFidelity = 0.503086\tKL_Divergence = 2.977583\n",
      "Epoch: 2\tFidelity = 0.503149\tKL_Divergence = 2.965943\n",
      "Epoch: 3\tFidelity = 0.502446\tKL_Divergence = 3.106727\n",
      "Epoch: 4\tFidelity = 0.502598\tKL_Divergence = 3.072774\n",
      "Epoch: 5\tFidelity = 0.502528\tKL_Divergence = 3.088339\n",
      "Epoch: 6\tFidelity = 0.502331\tKL_Divergence = 3.133120\n",
      "Epoch: 7\tFidelity = 0.502414\tKL_Divergence = 3.113522\n",
      "Epoch: 8\tFidelity = 0.503782\tKL_Divergence = 2.864174\n",
      "Epoch: 9\tFidelity = 0.503068\tKL_Divergence = 2.980570\n",
      "Epoch: 10\tFidelity = 0.502114\tKL_Divergence = 3.187379\n",
      "Epoch: 11\tFidelity = 0.502920\tKL_Divergence = 3.008030\n",
      "Epoch: 12\tFidelity = 0.502789\tKL_Divergence = 3.034059\n",
      "Epoch: 13\tFidelity = 0.502993\tKL_Divergence = 2.994740\n",
      "Epoch: 14\tFidelity = 0.502494\tKL_Divergence = 3.095664\n",
      "Epoch: 15\tFidelity = 0.502378\tKL_Divergence = 3.122460\n",
      "Epoch: 16\tFidelity = 0.502584\tKL_Divergence = 3.076078\n",
      "Epoch: 17\tFidelity = 0.502807\tKL_Divergence = 3.029842\n",
      "Epoch: 18\tFidelity = 0.502362\tKL_Divergence = 3.126107\n",
      "Epoch: 19\tFidelity = 0.502966\tKL_Divergence = 2.999274\n",
      "Epoch: 20\tFidelity = 0.503139\tKL_Divergence = 2.967675\n",
      "Epoch: 21\tFidelity = 0.502679\tKL_Divergence = 3.055749\n",
      "Epoch: 22\tFidelity = 0.503547\tKL_Divergence = 2.900189\n",
      "Epoch: 23\tFidelity = 0.502157\tKL_Divergence = 3.176743\n",
      "Epoch: 24\tFidelity = 0.502663\tKL_Divergence = 3.059511\n",
      "Epoch: 25\tFidelity = 0.502404\tKL_Divergence = 3.116601\n",
      "Epoch: 26\tFidelity = 0.502705\tKL_Divergence = 3.051043\n",
      "Epoch: 27\tFidelity = 0.502231\tKL_Divergence = 3.158218\n",
      "Epoch: 28\tFidelity = 0.502521\tKL_Divergence = 3.090313\n",
      "Epoch: 29\tFidelity = 0.502209\tKL_Divergence = 3.163572\n",
      "Epoch: 30\tFidelity = 0.502518\tKL_Divergence = 3.090790\n",
      "Epoch: 31\tFidelity = 0.503136\tKL_Divergence = 2.968791\n",
      "Epoch: 32\tFidelity = 0.503520\tKL_Divergence = 2.904551\n",
      "Epoch: 33\tFidelity = 0.502398\tKL_Divergence = 3.117741\n",
      "Epoch: 34\tFidelity = 0.502525\tKL_Divergence = 3.089280\n",
      "Epoch: 35\tFidelity = 0.503099\tKL_Divergence = 2.975508\n",
      "Epoch: 36\tFidelity = 0.502789\tKL_Divergence = 3.033957\n",
      "Epoch: 37\tFidelity = 0.502823\tKL_Divergence = 3.027236\n",
      "Epoch: 38\tFidelity = 0.502609\tKL_Divergence = 3.071114\n",
      "Epoch: 39\tFidelity = 0.503869\tKL_Divergence = 2.851977\n",
      "Epoch: 40\tFidelity = 0.503767\tKL_Divergence = 2.866832\n",
      "Epoch: 41\tFidelity = 0.502745\tKL_Divergence = 3.042597\n",
      "Epoch: 42\tFidelity = 0.503444\tKL_Divergence = 2.915659\n",
      "Epoch: 43\tFidelity = 0.503123\tKL_Divergence = 2.970657\n",
      "Epoch: 44\tFidelity = 0.503074\tKL_Divergence = 2.979724\n",
      "Epoch: 45\tFidelity = 0.502920\tKL_Divergence = 3.007917\n",
      "Epoch: 46\tFidelity = 0.502354\tKL_Divergence = 3.126986\n",
      "Epoch: 47\tFidelity = 0.502810\tKL_Divergence = 3.028694\n",
      "Epoch: 48\tFidelity = 0.502793\tKL_Divergence = 3.032574\n",
      "Epoch: 49\tFidelity = 0.502956\tKL_Divergence = 3.001111\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:33:44,693] Trial 304 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.502361\tKL_Divergence = 3.126057\n",
      "Total time elapsed during training: 37.681 s\n",
      "Trial 304 pruned. \n",
      "Epoch: 1\tFidelity = 0.502351\tKL_Divergence = 3.128999\n",
      "Epoch: 2\tFidelity = 0.502149\tKL_Divergence = 3.178818\n",
      "Epoch: 3\tFidelity = 0.502577\tKL_Divergence = 3.077779\n",
      "Epoch: 4\tFidelity = 0.503045\tKL_Divergence = 2.984853\n",
      "Epoch: 5\tFidelity = 0.502796\tKL_Divergence = 3.032417\n",
      "Epoch: 6\tFidelity = 0.502358\tKL_Divergence = 3.127376\n",
      "Epoch: 7\tFidelity = 0.503372\tKL_Divergence = 2.928501\n",
      "Epoch: 8\tFidelity = 0.502528\tKL_Divergence = 3.088557\n",
      "Epoch: 9\tFidelity = 0.502352\tKL_Divergence = 3.128800\n",
      "Epoch: 10\tFidelity = 0.501993\tKL_Divergence = 3.220754\n",
      "Epoch: 11\tFidelity = 0.502591\tKL_Divergence = 3.075023\n",
      "Epoch: 12\tFidelity = 0.501728\tKL_Divergence = 3.299921\n",
      "Epoch: 13\tFidelity = 0.502450\tKL_Divergence = 3.106012\n",
      "Epoch: 14\tFidelity = 0.502596\tKL_Divergence = 3.073846\n",
      "Epoch: 15\tFidelity = 0.502822\tKL_Divergence = 3.027337\n",
      "Epoch: 16\tFidelity = 0.502754\tKL_Divergence = 3.041035\n",
      "Epoch: 17\tFidelity = 0.503584\tKL_Divergence = 2.894558\n",
      "Epoch: 18\tFidelity = 0.503595\tKL_Divergence = 2.892778\n",
      "Epoch: 19\tFidelity = 0.502899\tKL_Divergence = 3.012566\n",
      "Epoch: 20\tFidelity = 0.502948\tKL_Divergence = 3.003254\n",
      "Epoch: 21\tFidelity = 0.503728\tKL_Divergence = 2.872587\n",
      "Epoch: 22\tFidelity = 0.503565\tKL_Divergence = 2.897519\n",
      "Epoch: 23\tFidelity = 0.502738\tKL_Divergence = 3.044323\n",
      "Epoch: 24\tFidelity = 0.503010\tKL_Divergence = 2.991789\n",
      "Epoch: 25\tFidelity = 0.502698\tKL_Divergence = 3.052512\n",
      "Epoch: 26\tFidelity = 0.502729\tKL_Divergence = 3.046033\n",
      "Epoch: 27\tFidelity = 0.502603\tKL_Divergence = 3.072474\n",
      "Epoch: 28\tFidelity = 0.503046\tKL_Divergence = 2.984892\n",
      "Epoch: 29\tFidelity = 0.504196\tKL_Divergence = 2.806639\n",
      "Epoch: 30\tFidelity = 0.502007\tKL_Divergence = 3.216893\n",
      "Epoch: 31\tFidelity = 0.502137\tKL_Divergence = 3.182058\n",
      "Epoch: 32\tFidelity = 0.502750\tKL_Divergence = 3.041831\n",
      "Epoch: 33\tFidelity = 0.502860\tKL_Divergence = 3.019824\n",
      "Epoch: 34\tFidelity = 0.503133\tKL_Divergence = 2.968795\n",
      "Epoch: 35\tFidelity = 0.502889\tKL_Divergence = 3.013985\n",
      "Epoch: 36\tFidelity = 0.502560\tKL_Divergence = 3.081306\n",
      "Epoch: 37\tFidelity = 0.503413\tKL_Divergence = 2.921858\n",
      "Epoch: 38\tFidelity = 0.502822\tKL_Divergence = 3.027647\n",
      "Epoch: 39\tFidelity = 0.502840\tKL_Divergence = 3.023971\n",
      "Epoch: 40\tFidelity = 0.502663\tKL_Divergence = 3.059799\n",
      "Epoch: 41\tFidelity = 0.502441\tKL_Divergence = 3.108213\n",
      "Epoch: 42\tFidelity = 0.503067\tKL_Divergence = 2.981379\n",
      "Epoch: 43\tFidelity = 0.502610\tKL_Divergence = 3.071027\n",
      "Epoch: 44\tFidelity = 0.502190\tKL_Divergence = 3.168653\n",
      "Epoch: 45\tFidelity = 0.502430\tKL_Divergence = 3.110814\n",
      "Epoch: 46\tFidelity = 0.502309\tKL_Divergence = 3.139134\n",
      "Epoch: 47\tFidelity = 0.502270\tKL_Divergence = 3.148351\n",
      "Epoch: 48\tFidelity = 0.502247\tKL_Divergence = 3.154227\n",
      "Epoch: 49\tFidelity = 0.502833\tKL_Divergence = 3.025414\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:34:23,167] Trial 305 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.503118\tKL_Divergence = 2.972263\n",
      "Total time elapsed during training: 38.313 s\n",
      "Trial 305 pruned. \n",
      "Epoch: 1\tFidelity = 0.502116\tKL_Divergence = 3.187620\n",
      "Epoch: 2\tFidelity = 0.504179\tKL_Divergence = 2.809207\n",
      "Epoch: 3\tFidelity = 0.503531\tKL_Divergence = 2.902541\n",
      "Epoch: 4\tFidelity = 0.503893\tKL_Divergence = 2.848685\n",
      "Epoch: 5\tFidelity = 0.502696\tKL_Divergence = 3.053090\n",
      "Epoch: 6\tFidelity = 0.502942\tKL_Divergence = 3.004484\n",
      "Epoch: 7\tFidelity = 0.502194\tKL_Divergence = 3.167545\n",
      "Epoch: 8\tFidelity = 0.502279\tKL_Divergence = 3.146383\n",
      "Epoch: 9\tFidelity = 0.502655\tKL_Divergence = 3.061450\n",
      "Epoch: 10\tFidelity = 0.502469\tKL_Divergence = 3.101916\n",
      "Epoch: 11\tFidelity = 0.502136\tKL_Divergence = 3.182325\n",
      "Epoch: 12\tFidelity = 0.503506\tKL_Divergence = 2.906919\n",
      "Epoch: 13\tFidelity = 0.502524\tKL_Divergence = 3.089271\n",
      "Epoch: 14\tFidelity = 0.502161\tKL_Divergence = 3.175704\n",
      "Epoch: 15\tFidelity = 0.502544\tKL_Divergence = 3.085146\n",
      "Epoch: 16\tFidelity = 0.502773\tKL_Divergence = 3.037393\n",
      "Epoch: 17\tFidelity = 0.502396\tKL_Divergence = 3.118538\n",
      "Epoch: 18\tFidelity = 0.503546\tKL_Divergence = 2.899969\n",
      "Epoch: 19\tFidelity = 0.502339\tKL_Divergence = 3.131819\n",
      "Epoch: 20\tFidelity = 0.502592\tKL_Divergence = 3.074775\n",
      "Epoch: 21\tFidelity = 0.502636\tKL_Divergence = 3.065504\n",
      "Epoch: 22\tFidelity = 0.503046\tKL_Divergence = 2.984962\n",
      "Epoch: 23\tFidelity = 0.502963\tKL_Divergence = 3.000481\n",
      "Epoch: 24\tFidelity = 0.502888\tKL_Divergence = 3.014560\n",
      "Epoch: 25\tFidelity = 0.502991\tKL_Divergence = 2.995125\n",
      "Epoch: 26\tFidelity = 0.503399\tKL_Divergence = 2.923799\n",
      "Epoch: 27\tFidelity = 0.502558\tKL_Divergence = 3.081934\n",
      "Epoch: 28\tFidelity = 0.502767\tKL_Divergence = 3.038397\n",
      "Epoch: 29\tFidelity = 0.502354\tKL_Divergence = 3.128324\n",
      "Epoch: 30\tFidelity = 0.502814\tKL_Divergence = 3.029014\n",
      "Epoch: 31\tFidelity = 0.502666\tKL_Divergence = 3.059057\n",
      "Epoch: 32\tFidelity = 0.503306\tKL_Divergence = 2.939106\n",
      "Epoch: 33\tFidelity = 0.502593\tKL_Divergence = 3.074539\n",
      "Epoch: 34\tFidelity = 0.502352\tKL_Divergence = 3.128864\n",
      "Epoch: 35\tFidelity = 0.502418\tKL_Divergence = 3.113475\n",
      "Epoch: 36\tFidelity = 0.503264\tKL_Divergence = 2.946610\n",
      "Epoch: 37\tFidelity = 0.503745\tKL_Divergence = 2.869973\n",
      "Epoch: 38\tFidelity = 0.503452\tKL_Divergence = 2.915498\n",
      "Epoch: 39\tFidelity = 0.502199\tKL_Divergence = 3.166046\n",
      "Epoch: 40\tFidelity = 0.503156\tKL_Divergence = 2.965408\n",
      "Epoch: 41\tFidelity = 0.502732\tKL_Divergence = 3.045418\n",
      "Epoch: 42\tFidelity = 0.503091\tKL_Divergence = 2.976842\n",
      "Epoch: 43\tFidelity = 0.502178\tKL_Divergence = 3.171484\n",
      "Epoch: 44\tFidelity = 0.502653\tKL_Divergence = 3.061924\n",
      "Epoch: 45\tFidelity = 0.502133\tKL_Divergence = 3.183059\n",
      "Epoch: 46\tFidelity = 0.502078\tKL_Divergence = 3.197147\n",
      "Epoch: 47\tFidelity = 0.503888\tKL_Divergence = 2.849129\n",
      "Epoch: 48\tFidelity = 0.503159\tKL_Divergence = 2.964673\n",
      "Epoch: 49\tFidelity = 0.503659\tKL_Divergence = 2.883041\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:35:42,567] Trial 306 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.503277\tKL_Divergence = 2.944344\n",
      "Total time elapsed during training: 79.230 s\n",
      "Trial 306 pruned. \n",
      "Epoch: 1\tFidelity = 0.502757\tKL_Divergence = 3.040321\n",
      "Epoch: 2\tFidelity = 0.502859\tKL_Divergence = 3.020214\n",
      "Epoch: 3\tFidelity = 0.502678\tKL_Divergence = 3.056628\n",
      "Epoch: 4\tFidelity = 0.503013\tKL_Divergence = 2.990968\n",
      "Epoch: 5\tFidelity = 0.503238\tKL_Divergence = 2.950916\n",
      "Epoch: 6\tFidelity = 0.502881\tKL_Divergence = 3.016025\n",
      "Epoch: 7\tFidelity = 0.502767\tKL_Divergence = 3.038314\n",
      "Epoch: 8\tFidelity = 0.502866\tKL_Divergence = 3.018925\n",
      "Epoch: 9\tFidelity = 0.502901\tKL_Divergence = 3.012063\n",
      "Epoch: 10\tFidelity = 0.502635\tKL_Divergence = 3.065473\n",
      "Epoch: 11\tFidelity = 0.502796\tKL_Divergence = 3.032545\n",
      "Epoch: 12\tFidelity = 0.503017\tKL_Divergence = 2.990247\n",
      "Epoch: 13\tFidelity = 0.503029\tKL_Divergence = 2.988001\n",
      "Epoch: 14\tFidelity = 0.502823\tKL_Divergence = 3.027216\n",
      "Epoch: 15\tFidelity = 0.502745\tKL_Divergence = 3.042763\n",
      "Epoch: 16\tFidelity = 0.503120\tKL_Divergence = 2.971644\n",
      "Epoch: 17\tFidelity = 0.502787\tKL_Divergence = 3.034336\n",
      "Epoch: 18\tFidelity = 0.503004\tKL_Divergence = 2.992696\n",
      "Epoch: 19\tFidelity = 0.502729\tKL_Divergence = 3.046034\n",
      "Epoch: 20\tFidelity = 0.502556\tKL_Divergence = 3.082428\n",
      "Epoch: 21\tFidelity = 0.502806\tKL_Divergence = 3.030555\n",
      "Epoch: 22\tFidelity = 0.502705\tKL_Divergence = 3.050895\n",
      "Epoch: 23\tFidelity = 0.502748\tKL_Divergence = 3.042263\n",
      "Epoch: 24\tFidelity = 0.503055\tKL_Divergence = 2.983263\n",
      "Epoch: 25\tFidelity = 0.502994\tKL_Divergence = 2.994446\n",
      "Epoch: 26\tFidelity = 0.503061\tKL_Divergence = 2.982252\n",
      "Epoch: 27\tFidelity = 0.502966\tKL_Divergence = 2.999729\n",
      "Epoch: 28\tFidelity = 0.503133\tKL_Divergence = 2.969210\n",
      "Epoch: 29\tFidelity = 0.502744\tKL_Divergence = 3.043076\n",
      "Epoch: 30\tFidelity = 0.502961\tKL_Divergence = 3.000705\n",
      "Epoch: 31\tFidelity = 0.502871\tKL_Divergence = 3.017865\n",
      "Epoch: 32\tFidelity = 0.502929\tKL_Divergence = 3.006681\n",
      "Epoch: 33\tFidelity = 0.503114\tKL_Divergence = 2.972724\n",
      "Epoch: 34\tFidelity = 0.502910\tKL_Divergence = 3.010380\n",
      "Epoch: 35\tFidelity = 0.502802\tKL_Divergence = 3.031431\n",
      "Epoch: 36\tFidelity = 0.502859\tKL_Divergence = 3.020092\n",
      "Epoch: 37\tFidelity = 0.503086\tKL_Divergence = 2.977672\n",
      "Epoch: 38\tFidelity = 0.502842\tKL_Divergence = 3.023574\n",
      "Epoch: 39\tFidelity = 0.503080\tKL_Divergence = 2.978811\n",
      "Epoch: 40\tFidelity = 0.502870\tKL_Divergence = 3.018062\n",
      "Epoch: 41\tFidelity = 0.502664\tKL_Divergence = 3.059494\n",
      "Epoch: 42\tFidelity = 0.502619\tKL_Divergence = 3.068935\n",
      "Epoch: 43\tFidelity = 0.502770\tKL_Divergence = 3.037743\n",
      "Epoch: 44\tFidelity = 0.502815\tKL_Divergence = 3.028820\n",
      "Epoch: 45\tFidelity = 0.502703\tKL_Divergence = 3.051506\n",
      "Epoch: 46\tFidelity = 0.502711\tKL_Divergence = 3.049760\n",
      "Epoch: 47\tFidelity = 0.502437\tKL_Divergence = 3.108916\n",
      "Epoch: 48\tFidelity = 0.502739\tKL_Divergence = 3.044058\n",
      "Epoch: 49\tFidelity = 0.502736\tKL_Divergence = 3.044653\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:36:27,405] Trial 307 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.502658\tKL_Divergence = 3.060827\n",
      "Total time elapsed during training: 44.661 s\n",
      "Trial 307 pruned. \n",
      "Epoch: 1\tFidelity = 0.502452\tKL_Divergence = 3.105537\n",
      "Epoch: 2\tFidelity = 0.502706\tKL_Divergence = 3.050672\n",
      "Epoch: 3\tFidelity = 0.502754\tKL_Divergence = 3.040949\n",
      "Epoch: 4\tFidelity = 0.503064\tKL_Divergence = 2.981665\n",
      "Epoch: 5\tFidelity = 0.503017\tKL_Divergence = 2.990201\n",
      "Epoch: 6\tFidelity = 0.503295\tKL_Divergence = 2.941248\n",
      "Epoch: 7\tFidelity = 0.502819\tKL_Divergence = 3.028086\n",
      "Epoch: 8\tFidelity = 0.502455\tKL_Divergence = 3.104733\n",
      "Epoch: 9\tFidelity = 0.503141\tKL_Divergence = 2.967720\n",
      "Epoch: 10\tFidelity = 0.502424\tKL_Divergence = 3.111455\n",
      "Epoch: 11\tFidelity = 0.503238\tKL_Divergence = 2.950669\n",
      "Epoch: 12\tFidelity = 0.503163\tKL_Divergence = 2.963642\n",
      "Epoch: 13\tFidelity = 0.502079\tKL_Divergence = 3.197011\n",
      "Epoch: 14\tFidelity = 0.502986\tKL_Divergence = 2.995569\n",
      "Epoch: 15\tFidelity = 0.503150\tKL_Divergence = 2.965963\n",
      "Epoch: 16\tFidelity = 0.503407\tKL_Divergence = 2.922345\n",
      "Epoch: 17\tFidelity = 0.503263\tKL_Divergence = 2.946247\n",
      "Epoch: 18\tFidelity = 0.502895\tKL_Divergence = 3.012767\n",
      "Epoch: 19\tFidelity = 0.502343\tKL_Divergence = 3.130626\n",
      "Epoch: 20\tFidelity = 0.502799\tKL_Divergence = 3.031696\n",
      "Epoch: 21\tFidelity = 0.502872\tKL_Divergence = 3.017213\n",
      "Epoch: 22\tFidelity = 0.503373\tKL_Divergence = 2.927526\n",
      "Epoch: 23\tFidelity = 0.502771\tKL_Divergence = 3.037136\n",
      "Epoch: 24\tFidelity = 0.503060\tKL_Divergence = 2.982096\n",
      "Epoch: 25\tFidelity = 0.502783\tKL_Divergence = 3.034892\n",
      "Epoch: 26\tFidelity = 0.503050\tKL_Divergence = 2.984249\n",
      "Epoch: 27\tFidelity = 0.502815\tKL_Divergence = 3.028880\n",
      "Epoch: 28\tFidelity = 0.502850\tKL_Divergence = 3.021892\n",
      "Epoch: 29\tFidelity = 0.502929\tKL_Divergence = 3.006545\n",
      "Epoch: 30\tFidelity = 0.502796\tKL_Divergence = 3.032582\n",
      "Epoch: 31\tFidelity = 0.503027\tKL_Divergence = 2.988339\n",
      "Epoch: 32\tFidelity = 0.502246\tKL_Divergence = 3.154356\n",
      "Epoch: 33\tFidelity = 0.502919\tKL_Divergence = 3.008575\n",
      "Epoch: 34\tFidelity = 0.502939\tKL_Divergence = 3.004824\n",
      "Epoch: 35\tFidelity = 0.502908\tKL_Divergence = 3.010427\n",
      "Epoch: 36\tFidelity = 0.503202\tKL_Divergence = 2.957158\n",
      "Epoch: 37\tFidelity = 0.502487\tKL_Divergence = 3.097744\n",
      "Epoch: 38\tFidelity = 0.503486\tKL_Divergence = 2.909886\n",
      "Epoch: 39\tFidelity = 0.502974\tKL_Divergence = 2.998260\n",
      "Epoch: 40\tFidelity = 0.503144\tKL_Divergence = 2.967269\n",
      "Epoch: 41\tFidelity = 0.502469\tKL_Divergence = 3.101555\n",
      "Epoch: 42\tFidelity = 0.502047\tKL_Divergence = 3.205631\n",
      "Epoch: 43\tFidelity = 0.502722\tKL_Divergence = 3.047333\n",
      "Epoch: 44\tFidelity = 0.503195\tKL_Divergence = 2.958052\n",
      "Epoch: 45\tFidelity = 0.502945\tKL_Divergence = 3.003554\n",
      "Epoch: 46\tFidelity = 0.502990\tKL_Divergence = 2.994899\n",
      "Epoch: 47\tFidelity = 0.503028\tKL_Divergence = 2.988272\n",
      "Epoch: 48\tFidelity = 0.503002\tKL_Divergence = 2.993048\n",
      "Epoch: 49\tFidelity = 0.502172\tKL_Divergence = 3.172782\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:37:12,210] Trial 308 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.502783\tKL_Divergence = 3.035110\n",
      "Total time elapsed during training: 44.647 s\n",
      "Trial 308 pruned. \n",
      "Epoch: 1\tFidelity = 0.502738\tKL_Divergence = 3.044056\n",
      "Epoch: 2\tFidelity = 0.502593\tKL_Divergence = 3.074258\n",
      "Epoch: 3\tFidelity = 0.502779\tKL_Divergence = 3.035697\n",
      "Epoch: 4\tFidelity = 0.502939\tKL_Divergence = 3.004794\n",
      "Epoch: 5\tFidelity = 0.502711\tKL_Divergence = 3.049666\n",
      "Epoch: 6\tFidelity = 0.502602\tKL_Divergence = 3.072468\n",
      "Epoch: 7\tFidelity = 0.502886\tKL_Divergence = 3.014643\n",
      "Epoch: 8\tFidelity = 0.502550\tKL_Divergence = 3.083433\n",
      "Epoch: 9\tFidelity = 0.503588\tKL_Divergence = 2.893322\n",
      "Epoch: 10\tFidelity = 0.502857\tKL_Divergence = 3.019243\n",
      "Epoch: 11\tFidelity = 0.502676\tKL_Divergence = 3.054932\n",
      "Epoch: 12\tFidelity = 0.502913\tKL_Divergence = 3.008217\n",
      "Epoch: 13\tFidelity = 0.502766\tKL_Divergence = 3.036694\n",
      "Epoch: 14\tFidelity = 0.502911\tKL_Divergence = 3.009037\n",
      "Epoch: 15\tFidelity = 0.502494\tKL_Divergence = 3.095055\n",
      "Epoch: 16\tFidelity = 0.503003\tKL_Divergence = 2.991456\n",
      "Epoch: 17\tFidelity = 0.503524\tKL_Divergence = 2.902625\n",
      "Epoch: 18\tFidelity = 0.502525\tKL_Divergence = 3.088555\n",
      "Epoch: 19\tFidelity = 0.502219\tKL_Divergence = 3.160639\n",
      "Epoch: 20\tFidelity = 0.502478\tKL_Divergence = 3.099464\n",
      "Epoch: 21\tFidelity = 0.502761\tKL_Divergence = 3.039534\n",
      "Epoch: 22\tFidelity = 0.502784\tKL_Divergence = 3.034935\n",
      "Epoch: 23\tFidelity = 0.502877\tKL_Divergence = 3.016621\n",
      "Epoch: 24\tFidelity = 0.503056\tKL_Divergence = 2.983054\n",
      "Epoch: 25\tFidelity = 0.503288\tKL_Divergence = 2.942365\n",
      "Epoch: 26\tFidelity = 0.502352\tKL_Divergence = 3.128615\n",
      "Epoch: 27\tFidelity = 0.502732\tKL_Divergence = 3.045389\n",
      "Epoch: 28\tFidelity = 0.503271\tKL_Divergence = 2.945305\n",
      "Epoch: 29\tFidelity = 0.502522\tKL_Divergence = 3.089987\n",
      "Epoch: 30\tFidelity = 0.502182\tKL_Divergence = 3.170419\n",
      "Epoch: 31\tFidelity = 0.502735\tKL_Divergence = 3.044846\n",
      "Epoch: 32\tFidelity = 0.503020\tKL_Divergence = 2.989733\n",
      "Epoch: 33\tFidelity = 0.502670\tKL_Divergence = 3.058117\n",
      "Epoch: 34\tFidelity = 0.502450\tKL_Divergence = 3.105603\n",
      "Epoch: 35\tFidelity = 0.502373\tKL_Divergence = 3.123457\n",
      "Epoch: 36\tFidelity = 0.503136\tKL_Divergence = 2.968783\n",
      "Epoch: 37\tFidelity = 0.502553\tKL_Divergence = 3.083012\n",
      "Epoch: 38\tFidelity = 0.502461\tKL_Divergence = 3.103524\n",
      "Epoch: 39\tFidelity = 0.502644\tKL_Divergence = 3.063554\n",
      "Epoch: 40\tFidelity = 0.503171\tKL_Divergence = 2.962591\n",
      "Epoch: 41\tFidelity = 0.502397\tKL_Divergence = 3.118138\n",
      "Epoch: 42\tFidelity = 0.503134\tKL_Divergence = 2.969070\n",
      "Epoch: 43\tFidelity = 0.502280\tKL_Divergence = 3.145943\n",
      "Epoch: 44\tFidelity = 0.503137\tKL_Divergence = 2.968503\n",
      "Epoch: 45\tFidelity = 0.502927\tKL_Divergence = 3.006920\n",
      "Epoch: 46\tFidelity = 0.502390\tKL_Divergence = 3.119583\n",
      "Epoch: 47\tFidelity = 0.502572\tKL_Divergence = 3.078739\n",
      "Epoch: 48\tFidelity = 0.503010\tKL_Divergence = 2.991467\n",
      "Epoch: 49\tFidelity = 0.502650\tKL_Divergence = 3.062294\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:37:50,538] Trial 309 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.502321\tKL_Divergence = 3.135838\n",
      "Total time elapsed during training: 38.138 s\n",
      "Trial 309 pruned. \n",
      "Epoch: 1\tFidelity = 0.503047\tKL_Divergence = 2.984647\n",
      "Epoch: 2\tFidelity = 0.502857\tKL_Divergence = 3.020571\n",
      "Epoch: 3\tFidelity = 0.502856\tKL_Divergence = 3.020808\n",
      "Epoch: 4\tFidelity = 0.502757\tKL_Divergence = 3.040288\n",
      "Epoch: 5\tFidelity = 0.502637\tKL_Divergence = 3.065086\n",
      "Epoch: 6\tFidelity = 0.502644\tKL_Divergence = 3.063733\n",
      "Epoch: 7\tFidelity = 0.503157\tKL_Divergence = 2.965105\n",
      "Epoch: 8\tFidelity = 0.502474\tKL_Divergence = 3.100669\n",
      "Epoch: 9\tFidelity = 0.502599\tKL_Divergence = 3.073178\n",
      "Epoch: 10\tFidelity = 0.502659\tKL_Divergence = 3.060508\n",
      "Epoch: 11\tFidelity = 0.502861\tKL_Divergence = 3.019811\n",
      "Epoch: 12\tFidelity = 0.502584\tKL_Divergence = 3.076375\n",
      "Epoch: 13\tFidelity = 0.502711\tKL_Divergence = 3.049768\n",
      "Epoch: 14\tFidelity = 0.502516\tKL_Divergence = 3.091197\n",
      "Epoch: 15\tFidelity = 0.502634\tKL_Divergence = 3.065755\n",
      "Epoch: 16\tFidelity = 0.502911\tKL_Divergence = 3.010135\n",
      "Epoch: 17\tFidelity = 0.502859\tKL_Divergence = 3.020124\n",
      "Epoch: 18\tFidelity = 0.502572\tKL_Divergence = 3.079069\n",
      "Epoch: 19\tFidelity = 0.502511\tKL_Divergence = 3.092420\n",
      "Epoch: 20\tFidelity = 0.502739\tKL_Divergence = 3.043963\n",
      "Epoch: 21\tFidelity = 0.502712\tKL_Divergence = 3.049460\n",
      "Epoch: 22\tFidelity = 0.502829\tKL_Divergence = 3.026123\n",
      "Epoch: 23\tFidelity = 0.502607\tKL_Divergence = 3.071396\n",
      "Epoch: 24\tFidelity = 0.502848\tKL_Divergence = 3.022209\n",
      "Epoch: 25\tFidelity = 0.502950\tKL_Divergence = 3.002745\n",
      "Epoch: 26\tFidelity = 0.502363\tKL_Divergence = 3.125950\n",
      "Epoch: 27\tFidelity = 0.503085\tKL_Divergence = 2.977808\n",
      "Epoch: 28\tFidelity = 0.502959\tKL_Divergence = 3.001087\n",
      "Epoch: 29\tFidelity = 0.502529\tKL_Divergence = 3.088344\n",
      "Epoch: 30\tFidelity = 0.503017\tKL_Divergence = 2.990322\n",
      "Epoch: 31\tFidelity = 0.502432\tKL_Divergence = 3.110171\n",
      "Epoch: 32\tFidelity = 0.503171\tKL_Divergence = 2.962594\n",
      "Epoch: 33\tFidelity = 0.502628\tKL_Divergence = 3.067033\n",
      "Epoch: 34\tFidelity = 0.503023\tKL_Divergence = 2.989193\n",
      "Epoch: 35\tFidelity = 0.502519\tKL_Divergence = 3.090673\n",
      "Epoch: 36\tFidelity = 0.502517\tKL_Divergence = 3.090923\n",
      "Epoch: 37\tFidelity = 0.503018\tKL_Divergence = 2.990092\n",
      "Epoch: 38\tFidelity = 0.502784\tKL_Divergence = 3.034981\n",
      "Epoch: 39\tFidelity = 0.503256\tKL_Divergence = 2.947840\n",
      "Epoch: 40\tFidelity = 0.502730\tKL_Divergence = 3.045861\n",
      "Epoch: 41\tFidelity = 0.502789\tKL_Divergence = 3.034039\n",
      "Epoch: 42\tFidelity = 0.502801\tKL_Divergence = 3.031550\n",
      "Epoch: 43\tFidelity = 0.502758\tKL_Divergence = 3.040131\n",
      "Epoch: 44\tFidelity = 0.503006\tKL_Divergence = 2.992356\n",
      "Epoch: 45\tFidelity = 0.502832\tKL_Divergence = 3.025372\n",
      "Epoch: 46\tFidelity = 0.502995\tKL_Divergence = 2.994139\n",
      "Epoch: 47\tFidelity = 0.502595\tKL_Divergence = 3.073892\n",
      "Epoch: 48\tFidelity = 0.502803\tKL_Divergence = 3.031012\n",
      "Epoch: 49\tFidelity = 0.502533\tKL_Divergence = 3.087417\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:38:28,325] Trial 310 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.502391\tKL_Divergence = 3.119518\n",
      "Total time elapsed during training: 37.632 s\n",
      "Trial 310 pruned. \n",
      "Epoch: 1\tFidelity = 0.502815\tKL_Divergence = 3.028705\n",
      "Epoch: 2\tFidelity = 0.502802\tKL_Divergence = 3.031287\n",
      "Epoch: 3\tFidelity = 0.502722\tKL_Divergence = 3.047367\n",
      "Epoch: 4\tFidelity = 0.502665\tKL_Divergence = 3.059209\n",
      "Epoch: 5\tFidelity = 0.502562\tKL_Divergence = 3.081130\n",
      "Epoch: 6\tFidelity = 0.502650\tKL_Divergence = 3.062357\n",
      "Epoch: 7\tFidelity = 0.502952\tKL_Divergence = 3.002315\n",
      "Epoch: 8\tFidelity = 0.502754\tKL_Divergence = 3.040960\n",
      "Epoch: 9\tFidelity = 0.502737\tKL_Divergence = 3.044338\n",
      "Epoch: 10\tFidelity = 0.502795\tKL_Divergence = 3.032657\n",
      "Epoch: 11\tFidelity = 0.502645\tKL_Divergence = 3.063507\n",
      "Epoch: 12\tFidelity = 0.502763\tKL_Divergence = 3.039068\n",
      "Epoch: 13\tFidelity = 0.502961\tKL_Divergence = 3.000708\n",
      "Epoch: 14\tFidelity = 0.502806\tKL_Divergence = 3.030571\n",
      "Epoch: 15\tFidelity = 0.502626\tKL_Divergence = 3.067503\n",
      "Epoch: 16\tFidelity = 0.502648\tKL_Divergence = 3.062726\n",
      "Epoch: 17\tFidelity = 0.502824\tKL_Divergence = 3.027037\n",
      "Epoch: 18\tFidelity = 0.502794\tKL_Divergence = 3.032998\n",
      "Epoch: 19\tFidelity = 0.502715\tKL_Divergence = 3.048806\n",
      "Epoch: 20\tFidelity = 0.502715\tKL_Divergence = 3.048899\n",
      "Epoch: 21\tFidelity = 0.502738\tKL_Divergence = 3.044123\n",
      "Epoch: 22\tFidelity = 0.502633\tKL_Divergence = 3.065878\n",
      "Epoch: 23\tFidelity = 0.502601\tKL_Divergence = 3.072818\n",
      "Epoch: 24\tFidelity = 0.502644\tKL_Divergence = 3.063580\n",
      "Epoch: 25\tFidelity = 0.502833\tKL_Divergence = 3.025318\n",
      "Epoch: 26\tFidelity = 0.502706\tKL_Divergence = 3.050732\n",
      "Epoch: 27\tFidelity = 0.502951\tKL_Divergence = 3.002596\n",
      "Epoch: 28\tFidelity = 0.502522\tKL_Divergence = 3.089930\n",
      "Epoch: 29\tFidelity = 0.502842\tKL_Divergence = 3.023538\n",
      "Epoch: 30\tFidelity = 0.502711\tKL_Divergence = 3.049704\n",
      "Epoch: 31\tFidelity = 0.502681\tKL_Divergence = 3.055941\n",
      "Epoch: 32\tFidelity = 0.502479\tKL_Divergence = 3.099344\n",
      "Epoch: 33\tFidelity = 0.502886\tKL_Divergence = 3.014990\n",
      "Epoch: 34\tFidelity = 0.502704\tKL_Divergence = 3.051252\n",
      "Epoch: 35\tFidelity = 0.502585\tKL_Divergence = 3.076099\n",
      "Epoch: 36\tFidelity = 0.502594\tKL_Divergence = 3.074306\n",
      "Epoch: 37\tFidelity = 0.502717\tKL_Divergence = 3.048550\n",
      "Epoch: 38\tFidelity = 0.502817\tKL_Divergence = 3.028477\n",
      "Epoch: 39\tFidelity = 0.502849\tKL_Divergence = 3.022212\n",
      "Epoch: 40\tFidelity = 0.502676\tKL_Divergence = 3.056987\n",
      "Epoch: 41\tFidelity = 0.502659\tKL_Divergence = 3.060511\n",
      "Epoch: 42\tFidelity = 0.502717\tKL_Divergence = 3.048540\n",
      "Epoch: 43\tFidelity = 0.502895\tKL_Divergence = 3.013193\n",
      "Epoch: 44\tFidelity = 0.502448\tKL_Divergence = 3.106436\n",
      "Epoch: 45\tFidelity = 0.502642\tKL_Divergence = 3.064070\n",
      "Epoch: 46\tFidelity = 0.502553\tKL_Divergence = 3.083133\n",
      "Epoch: 47\tFidelity = 0.502764\tKL_Divergence = 3.038929\n",
      "Epoch: 48\tFidelity = 0.502765\tKL_Divergence = 3.038896\n",
      "Epoch: 49\tFidelity = 0.502571\tKL_Divergence = 3.079146\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:39:06,405] Trial 311 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.502619\tKL_Divergence = 3.068860\n",
      "Total time elapsed during training: 37.920 s\n",
      "Trial 311 pruned. \n",
      "Epoch: 1\tFidelity = 0.502472\tKL_Divergence = 3.101088\n",
      "Epoch: 2\tFidelity = 0.502295\tKL_Divergence = 3.142423\n",
      "Epoch: 3\tFidelity = 0.502413\tKL_Divergence = 3.114534\n",
      "Epoch: 4\tFidelity = 0.502725\tKL_Divergence = 3.046723\n",
      "Epoch: 5\tFidelity = 0.502667\tKL_Divergence = 3.058959\n",
      "Epoch: 6\tFidelity = 0.502643\tKL_Divergence = 3.063838\n",
      "Epoch: 7\tFidelity = 0.503093\tKL_Divergence = 2.976345\n",
      "Epoch: 8\tFidelity = 0.502475\tKL_Divergence = 3.100245\n",
      "Epoch: 9\tFidelity = 0.502912\tKL_Divergence = 3.009859\n",
      "Epoch: 10\tFidelity = 0.502418\tKL_Divergence = 3.113469\n",
      "Epoch: 11\tFidelity = 0.502711\tKL_Divergence = 3.049735\n",
      "Epoch: 12\tFidelity = 0.502511\tKL_Divergence = 3.092304\n",
      "Epoch: 13\tFidelity = 0.502721\tKL_Divergence = 3.047640\n",
      "Epoch: 14\tFidelity = 0.502321\tKL_Divergence = 3.136079\n",
      "Epoch: 15\tFidelity = 0.502241\tKL_Divergence = 3.155437\n",
      "Epoch: 16\tFidelity = 0.502413\tKL_Divergence = 3.114545\n",
      "Epoch: 17\tFidelity = 0.503052\tKL_Divergence = 2.983886\n",
      "Epoch: 18\tFidelity = 0.502965\tKL_Divergence = 3.000032\n",
      "Epoch: 19\tFidelity = 0.502222\tKL_Divergence = 3.160377\n",
      "Epoch: 20\tFidelity = 0.502138\tKL_Divergence = 3.181738\n",
      "Epoch: 21\tFidelity = 0.502447\tKL_Divergence = 3.106622\n",
      "Epoch: 22\tFidelity = 0.502475\tKL_Divergence = 3.100438\n",
      "Epoch: 23\tFidelity = 0.502909\tKL_Divergence = 3.010505\n",
      "Epoch: 24\tFidelity = 0.502081\tKL_Divergence = 3.196705\n",
      "Epoch: 25\tFidelity = 0.503256\tKL_Divergence = 2.947705\n",
      "Epoch: 26\tFidelity = 0.502599\tKL_Divergence = 3.073140\n",
      "Epoch: 27\tFidelity = 0.503101\tKL_Divergence = 2.975028\n",
      "Epoch: 28\tFidelity = 0.502424\tKL_Divergence = 3.112010\n",
      "Epoch: 29\tFidelity = 0.502325\tKL_Divergence = 3.135112\n",
      "Epoch: 30\tFidelity = 0.502815\tKL_Divergence = 3.028849\n",
      "Epoch: 31\tFidelity = 0.502592\tKL_Divergence = 3.074560\n",
      "Epoch: 32\tFidelity = 0.502715\tKL_Divergence = 3.048818\n",
      "Epoch: 33\tFidelity = 0.502998\tKL_Divergence = 2.993825\n",
      "Epoch: 34\tFidelity = 0.502783\tKL_Divergence = 3.035059\n",
      "Epoch: 35\tFidelity = 0.503139\tKL_Divergence = 2.968013\n",
      "Epoch: 36\tFidelity = 0.502892\tKL_Divergence = 3.013776\n",
      "Epoch: 37\tFidelity = 0.502871\tKL_Divergence = 3.017496\n",
      "Epoch: 38\tFidelity = 0.502256\tKL_Divergence = 3.151754\n",
      "Epoch: 39\tFidelity = 0.503011\tKL_Divergence = 2.991371\n",
      "Epoch: 40\tFidelity = 0.502055\tKL_Divergence = 3.203640\n",
      "Epoch: 41\tFidelity = 0.502962\tKL_Divergence = 3.000537\n",
      "Epoch: 42\tFidelity = 0.502986\tKL_Divergence = 2.996091\n",
      "Epoch: 43\tFidelity = 0.502817\tKL_Divergence = 3.028412\n",
      "Epoch: 44\tFidelity = 0.503002\tKL_Divergence = 2.993159\n",
      "Epoch: 45\tFidelity = 0.502226\tKL_Divergence = 3.159211\n",
      "Epoch: 46\tFidelity = 0.502143\tKL_Divergence = 3.180380\n",
      "Epoch: 47\tFidelity = 0.502559\tKL_Divergence = 3.081820\n",
      "Epoch: 48\tFidelity = 0.503180\tKL_Divergence = 2.960973\n",
      "Epoch: 49\tFidelity = 0.502755\tKL_Divergence = 3.040874\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:40:25,290] Trial 312 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.502697\tKL_Divergence = 3.052704\n",
      "Total time elapsed during training: 78.721 s\n",
      "Trial 312 pruned. \n",
      "Epoch: 1\tFidelity = 0.502391\tKL_Divergence = 3.119560\n",
      "Epoch: 2\tFidelity = 0.502777\tKL_Divergence = 3.036430\n",
      "Epoch: 3\tFidelity = 0.502537\tKL_Divergence = 3.086627\n",
      "Epoch: 4\tFidelity = 0.502882\tKL_Divergence = 3.015857\n",
      "Epoch: 5\tFidelity = 0.502487\tKL_Divergence = 3.097588\n",
      "Epoch: 6\tFidelity = 0.502647\tKL_Divergence = 3.063087\n",
      "Epoch: 7\tFidelity = 0.502808\tKL_Divergence = 3.030258\n",
      "Epoch: 8\tFidelity = 0.502324\tKL_Divergence = 3.135255\n",
      "Epoch: 9\tFidelity = 0.502704\tKL_Divergence = 3.051123\n",
      "Epoch: 10\tFidelity = 0.502609\tKL_Divergence = 3.071154\n",
      "Epoch: 11\tFidelity = 0.502702\tKL_Divergence = 3.051656\n",
      "Epoch: 12\tFidelity = 0.502617\tKL_Divergence = 3.069445\n",
      "Epoch: 13\tFidelity = 0.502599\tKL_Divergence = 3.073314\n",
      "Epoch: 14\tFidelity = 0.502611\tKL_Divergence = 3.070741\n",
      "Epoch: 15\tFidelity = 0.502373\tKL_Divergence = 3.123744\n",
      "Epoch: 16\tFidelity = 0.502432\tKL_Divergence = 3.110082\n",
      "Epoch: 17\tFidelity = 0.502412\tKL_Divergence = 3.114628\n",
      "Epoch: 18\tFidelity = 0.502653\tKL_Divergence = 3.061704\n",
      "Epoch: 19\tFidelity = 0.502583\tKL_Divergence = 3.076579\n",
      "Epoch: 20\tFidelity = 0.502632\tKL_Divergence = 3.066193\n",
      "Epoch: 21\tFidelity = 0.502831\tKL_Divergence = 3.025710\n",
      "Epoch: 22\tFidelity = 0.502418\tKL_Divergence = 3.113327\n",
      "Epoch: 23\tFidelity = 0.502823\tKL_Divergence = 3.027328\n",
      "Epoch: 24\tFidelity = 0.502747\tKL_Divergence = 3.042460\n",
      "Epoch: 25\tFidelity = 0.502502\tKL_Divergence = 3.094304\n",
      "Epoch: 26\tFidelity = 0.502615\tKL_Divergence = 3.069900\n",
      "Epoch: 27\tFidelity = 0.502578\tKL_Divergence = 3.077735\n",
      "Epoch: 28\tFidelity = 0.502743\tKL_Divergence = 3.043333\n",
      "Epoch: 29\tFidelity = 0.502714\tKL_Divergence = 3.049191\n",
      "Epoch: 30\tFidelity = 0.502305\tKL_Divergence = 3.140014\n",
      "Epoch: 31\tFidelity = 0.502349\tKL_Divergence = 3.129450\n",
      "Epoch: 32\tFidelity = 0.502555\tKL_Divergence = 3.082672\n",
      "Epoch: 33\tFidelity = 0.502397\tKL_Divergence = 3.118203\n",
      "Epoch: 34\tFidelity = 0.502285\tKL_Divergence = 3.144844\n",
      "Epoch: 35\tFidelity = 0.502502\tKL_Divergence = 3.094464\n",
      "Epoch: 36\tFidelity = 0.502793\tKL_Divergence = 3.033185\n",
      "Epoch: 37\tFidelity = 0.502648\tKL_Divergence = 3.062936\n",
      "Epoch: 38\tFidelity = 0.502819\tKL_Divergence = 3.028013\n",
      "Epoch: 39\tFidelity = 0.502548\tKL_Divergence = 3.084321\n",
      "Epoch: 40\tFidelity = 0.502756\tKL_Divergence = 3.040602\n",
      "Epoch: 41\tFidelity = 0.502791\tKL_Divergence = 3.033538\n",
      "Epoch: 42\tFidelity = 0.502395\tKL_Divergence = 3.118676\n",
      "Epoch: 43\tFidelity = 0.502600\tKL_Divergence = 3.073045\n",
      "Epoch: 44\tFidelity = 0.503173\tKL_Divergence = 2.962326\n",
      "Epoch: 45\tFidelity = 0.502714\tKL_Divergence = 3.049227\n",
      "Epoch: 46\tFidelity = 0.502551\tKL_Divergence = 3.083567\n",
      "Epoch: 47\tFidelity = 0.502900\tKL_Divergence = 3.012200\n",
      "Epoch: 48\tFidelity = 0.502413\tKL_Divergence = 3.114392\n",
      "Epoch: 49\tFidelity = 0.502569\tKL_Divergence = 3.079587\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:40:56,641] Trial 313 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.502587\tKL_Divergence = 3.075858\n",
      "Total time elapsed during training: 31.188 s\n",
      "Trial 313 pruned. \n",
      "Epoch: 1\tFidelity = 0.503016\tKL_Divergence = 2.990443\n",
      "Epoch: 2\tFidelity = 0.502362\tKL_Divergence = 3.126271\n",
      "Epoch: 3\tFidelity = 0.502476\tKL_Divergence = 3.100110\n",
      "Epoch: 4\tFidelity = 0.502482\tKL_Divergence = 3.098760\n",
      "Epoch: 5\tFidelity = 0.502848\tKL_Divergence = 3.022389\n",
      "Epoch: 6\tFidelity = 0.502314\tKL_Divergence = 3.137739\n",
      "Epoch: 7\tFidelity = 0.502705\tKL_Divergence = 3.050988\n",
      "Epoch: 8\tFidelity = 0.502182\tKL_Divergence = 3.170370\n",
      "Epoch: 9\tFidelity = 0.502726\tKL_Divergence = 3.046784\n",
      "Epoch: 10\tFidelity = 0.502214\tKL_Divergence = 3.162333\n",
      "Epoch: 11\tFidelity = 0.503051\tKL_Divergence = 2.984053\n",
      "Epoch: 12\tFidelity = 0.502275\tKL_Divergence = 3.147162\n",
      "Epoch: 13\tFidelity = 0.502850\tKL_Divergence = 3.022043\n",
      "Epoch: 14\tFidelity = 0.502370\tKL_Divergence = 3.124480\n",
      "Epoch: 15\tFidelity = 0.502452\tKL_Divergence = 3.105709\n",
      "Epoch: 16\tFidelity = 0.502448\tKL_Divergence = 3.106431\n",
      "Epoch: 17\tFidelity = 0.502869\tKL_Divergence = 3.018351\n",
      "Epoch: 18\tFidelity = 0.502262\tKL_Divergence = 3.150450\n",
      "Epoch: 19\tFidelity = 0.502687\tKL_Divergence = 3.054728\n",
      "Epoch: 20\tFidelity = 0.502193\tKL_Divergence = 3.167635\n",
      "Epoch: 21\tFidelity = 0.502882\tKL_Divergence = 3.015824\n",
      "Epoch: 22\tFidelity = 0.502324\tKL_Divergence = 3.135281\n",
      "Epoch: 23\tFidelity = 0.502662\tKL_Divergence = 3.059947\n",
      "Epoch: 24\tFidelity = 0.502496\tKL_Divergence = 3.095649\n",
      "Epoch: 25\tFidelity = 0.502637\tKL_Divergence = 3.065172\n",
      "Epoch: 26\tFidelity = 0.502478\tKL_Divergence = 3.099823\n",
      "Epoch: 27\tFidelity = 0.502638\tKL_Divergence = 3.065049\n",
      "Epoch: 28\tFidelity = 0.502280\tKL_Divergence = 3.145910\n",
      "Epoch: 29\tFidelity = 0.502349\tKL_Divergence = 3.129345\n",
      "Epoch: 30\tFidelity = 0.502800\tKL_Divergence = 3.031769\n",
      "Epoch: 31\tFidelity = 0.502147\tKL_Divergence = 3.179359\n",
      "Epoch: 32\tFidelity = 0.502905\tKL_Divergence = 3.011391\n",
      "Epoch: 33\tFidelity = 0.502193\tKL_Divergence = 3.167610\n",
      "Epoch: 34\tFidelity = 0.503146\tKL_Divergence = 2.967019\n",
      "Epoch: 35\tFidelity = 0.502128\tKL_Divergence = 3.184336\n",
      "Epoch: 36\tFidelity = 0.502757\tKL_Divergence = 3.040423\n",
      "Epoch: 37\tFidelity = 0.502423\tKL_Divergence = 3.112188\n",
      "Epoch: 38\tFidelity = 0.502495\tKL_Divergence = 3.095935\n",
      "Epoch: 39\tFidelity = 0.502775\tKL_Divergence = 3.036866\n",
      "Epoch: 40\tFidelity = 0.502384\tKL_Divergence = 3.121317\n",
      "Epoch: 41\tFidelity = 0.502477\tKL_Divergence = 3.099966\n",
      "Epoch: 42\tFidelity = 0.502124\tKL_Divergence = 3.185336\n",
      "Epoch: 43\tFidelity = 0.502770\tKL_Divergence = 3.037749\n",
      "Epoch: 44\tFidelity = 0.502433\tKL_Divergence = 3.109988\n",
      "Epoch: 45\tFidelity = 0.502748\tKL_Divergence = 3.042253\n",
      "Epoch: 46\tFidelity = 0.502475\tKL_Divergence = 3.100464\n",
      "Epoch: 47\tFidelity = 0.502201\tKL_Divergence = 3.165503\n",
      "Epoch: 48\tFidelity = 0.502622\tKL_Divergence = 3.068347\n",
      "Epoch: 49\tFidelity = 0.502441\tKL_Divergence = 3.108223\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:41:28,135] Trial 314 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.502478\tKL_Divergence = 3.099815\n",
      "Total time elapsed during training: 31.337 s\n",
      "Trial 314 pruned. \n",
      "Epoch: 1\tFidelity = 0.502493\tKL_Divergence = 3.096459\n",
      "Epoch: 2\tFidelity = 0.502674\tKL_Divergence = 3.057357\n",
      "Epoch: 3\tFidelity = 0.502326\tKL_Divergence = 3.135038\n",
      "Epoch: 4\tFidelity = 0.502745\tKL_Divergence = 3.042981\n",
      "Epoch: 5\tFidelity = 0.502401\tKL_Divergence = 3.117258\n",
      "Epoch: 6\tFidelity = 0.502562\tKL_Divergence = 3.081167\n",
      "Epoch: 7\tFidelity = 0.502334\tKL_Divergence = 3.132904\n",
      "Epoch: 8\tFidelity = 0.502773\tKL_Divergence = 3.037247\n",
      "Epoch: 9\tFidelity = 0.502770\tKL_Divergence = 3.037841\n",
      "Epoch: 10\tFidelity = 0.502775\tKL_Divergence = 3.036797\n",
      "Epoch: 11\tFidelity = 0.502789\tKL_Divergence = 3.033835\n",
      "Epoch: 12\tFidelity = 0.502524\tKL_Divergence = 3.089390\n",
      "Epoch: 13\tFidelity = 0.502341\tKL_Divergence = 3.131113\n",
      "Epoch: 14\tFidelity = 0.502710\tKL_Divergence = 3.049777\n",
      "Epoch: 15\tFidelity = 0.502375\tKL_Divergence = 3.123182\n",
      "Epoch: 16\tFidelity = 0.502564\tKL_Divergence = 3.080471\n",
      "Epoch: 17\tFidelity = 0.502392\tKL_Divergence = 3.119161\n",
      "Epoch: 18\tFidelity = 0.502392\tKL_Divergence = 3.119256\n",
      "Epoch: 19\tFidelity = 0.502283\tKL_Divergence = 3.145026\n",
      "Epoch: 20\tFidelity = 0.502337\tKL_Divergence = 3.132056\n",
      "Epoch: 21\tFidelity = 0.502442\tKL_Divergence = 3.107531\n",
      "Epoch: 22\tFidelity = 0.502705\tKL_Divergence = 3.050757\n",
      "Epoch: 23\tFidelity = 0.502175\tKL_Divergence = 3.171695\n",
      "Epoch: 24\tFidelity = 0.502022\tKL_Divergence = 3.212512\n",
      "Epoch: 25\tFidelity = 0.502254\tKL_Divergence = 3.152024\n",
      "Epoch: 26\tFidelity = 0.502268\tKL_Divergence = 3.148786\n",
      "Epoch: 27\tFidelity = 0.502411\tKL_Divergence = 3.114877\n",
      "Epoch: 28\tFidelity = 0.502226\tKL_Divergence = 3.159284\n",
      "Epoch: 29\tFidelity = 0.502773\tKL_Divergence = 3.037224\n",
      "Epoch: 30\tFidelity = 0.502294\tKL_Divergence = 3.142548\n",
      "Epoch: 31\tFidelity = 0.502683\tKL_Divergence = 3.055673\n",
      "Epoch: 32\tFidelity = 0.502642\tKL_Divergence = 3.064070\n",
      "Epoch: 33\tFidelity = 0.502228\tKL_Divergence = 3.158734\n",
      "Epoch: 34\tFidelity = 0.502590\tKL_Divergence = 3.075204\n",
      "Epoch: 35\tFidelity = 0.502143\tKL_Divergence = 3.180457\n",
      "Epoch: 36\tFidelity = 0.502440\tKL_Divergence = 3.108243\n",
      "Epoch: 37\tFidelity = 0.502304\tKL_Divergence = 3.140287\n",
      "Epoch: 38\tFidelity = 0.502720\tKL_Divergence = 3.048010\n",
      "Epoch: 39\tFidelity = 0.502370\tKL_Divergence = 3.124585\n",
      "Epoch: 40\tFidelity = 0.502326\tKL_Divergence = 3.134860\n",
      "Epoch: 41\tFidelity = 0.502211\tKL_Divergence = 3.163124\n",
      "Epoch: 42\tFidelity = 0.502600\tKL_Divergence = 3.073052\n",
      "Epoch: 43\tFidelity = 0.502907\tKL_Divergence = 3.010943\n",
      "Epoch: 44\tFidelity = 0.502235\tKL_Divergence = 3.157134\n",
      "Epoch: 45\tFidelity = 0.503075\tKL_Divergence = 2.979608\n",
      "Epoch: 46\tFidelity = 0.502730\tKL_Divergence = 3.045792\n",
      "Epoch: 47\tFidelity = 0.502303\tKL_Divergence = 3.140055\n",
      "Epoch: 48\tFidelity = 0.502370\tKL_Divergence = 3.124407\n",
      "Epoch: 49\tFidelity = 0.502315\tKL_Divergence = 3.137653\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:42:05,562] Trial 315 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.502188\tKL_Divergence = 3.168890\n",
      "Total time elapsed during training: 37.271 s\n",
      "Trial 315 pruned. \n",
      "Epoch: 1\tFidelity = 0.502311\tKL_Divergence = 3.138598\n",
      "Epoch: 2\tFidelity = 0.502769\tKL_Divergence = 3.038066\n",
      "Epoch: 3\tFidelity = 0.502381\tKL_Divergence = 3.122005\n",
      "Epoch: 4\tFidelity = 0.502665\tKL_Divergence = 3.059275\n",
      "Epoch: 5\tFidelity = 0.502255\tKL_Divergence = 3.152026\n",
      "Epoch: 6\tFidelity = 0.502590\tKL_Divergence = 3.075048\n",
      "Epoch: 7\tFidelity = 0.502486\tKL_Divergence = 3.097854\n",
      "Epoch: 8\tFidelity = 0.502576\tKL_Divergence = 3.078144\n",
      "Epoch: 9\tFidelity = 0.502391\tKL_Divergence = 3.119628\n",
      "Epoch: 10\tFidelity = 0.502734\tKL_Divergence = 3.045032\n",
      "Epoch: 11\tFidelity = 0.502428\tKL_Divergence = 3.111117\n",
      "Epoch: 12\tFidelity = 0.502475\tKL_Divergence = 3.100465\n",
      "Epoch: 13\tFidelity = 0.502280\tKL_Divergence = 3.145944\n",
      "Epoch: 14\tFidelity = 0.502440\tKL_Divergence = 3.108411\n",
      "Epoch: 15\tFidelity = 0.502694\tKL_Divergence = 3.053344\n",
      "Epoch: 16\tFidelity = 0.502382\tKL_Divergence = 3.121772\n",
      "Epoch: 17\tFidelity = 0.502441\tKL_Divergence = 3.108073\n",
      "Epoch: 18\tFidelity = 0.502209\tKL_Divergence = 3.163532\n",
      "Epoch: 19\tFidelity = 0.502711\tKL_Divergence = 3.049864\n",
      "Epoch: 20\tFidelity = 0.502095\tKL_Divergence = 3.193093\n",
      "Epoch: 21\tFidelity = 0.502325\tKL_Divergence = 3.135305\n",
      "Epoch: 22\tFidelity = 0.502194\tKL_Divergence = 3.167490\n",
      "Epoch: 23\tFidelity = 0.502550\tKL_Divergence = 3.083872\n",
      "Epoch: 24\tFidelity = 0.502647\tKL_Divergence = 3.063231\n",
      "Epoch: 25\tFidelity = 0.502012\tKL_Divergence = 3.215529\n",
      "Epoch: 26\tFidelity = 0.502176\tKL_Divergence = 3.172145\n",
      "Epoch: 27\tFidelity = 0.502346\tKL_Divergence = 3.130300\n",
      "Epoch: 28\tFidelity = 0.502455\tKL_Divergence = 3.105032\n",
      "Epoch: 29\tFidelity = 0.502512\tKL_Divergence = 3.092218\n",
      "Epoch: 30\tFidelity = 0.502577\tKL_Divergence = 3.078112\n",
      "Epoch: 31\tFidelity = 0.502259\tKL_Divergence = 3.151335\n",
      "Epoch: 32\tFidelity = 0.502522\tKL_Divergence = 3.090022\n",
      "Epoch: 33\tFidelity = 0.502410\tKL_Divergence = 3.115165\n",
      "Epoch: 34\tFidelity = 0.502210\tKL_Divergence = 3.163520\n",
      "Epoch: 35\tFidelity = 0.502404\tKL_Divergence = 3.116725\n",
      "Epoch: 36\tFidelity = 0.502290\tKL_Divergence = 3.143752\n",
      "Epoch: 37\tFidelity = 0.502178\tKL_Divergence = 3.171438\n",
      "Epoch: 38\tFidelity = 0.502337\tKL_Divergence = 3.132433\n",
      "Epoch: 39\tFidelity = 0.502557\tKL_Divergence = 3.082336\n",
      "Epoch: 40\tFidelity = 0.502505\tKL_Divergence = 3.093812\n",
      "Epoch: 41\tFidelity = 0.502524\tKL_Divergence = 3.089644\n",
      "Epoch: 42\tFidelity = 0.502381\tKL_Divergence = 3.121961\n",
      "Epoch: 43\tFidelity = 0.502723\tKL_Divergence = 3.047403\n",
      "Epoch: 44\tFidelity = 0.502569\tKL_Divergence = 3.079812\n",
      "Epoch: 45\tFidelity = 0.502359\tKL_Divergence = 3.127240\n",
      "Epoch: 46\tFidelity = 0.502377\tKL_Divergence = 3.123023\n",
      "Epoch: 47\tFidelity = 0.502230\tKL_Divergence = 3.158452\n",
      "Epoch: 48\tFidelity = 0.502014\tKL_Divergence = 3.214923\n",
      "Epoch: 49\tFidelity = 0.502157\tKL_Divergence = 3.176843\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:42:50,137] Trial 316 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.502669\tKL_Divergence = 3.058560\n",
      "Total time elapsed during training: 44.413 s\n",
      "Trial 316 pruned. \n",
      "Epoch: 1\tFidelity = 0.502488\tKL_Divergence = 3.097558\n",
      "Epoch: 2\tFidelity = 0.502637\tKL_Divergence = 3.065151\n",
      "Epoch: 3\tFidelity = 0.502373\tKL_Divergence = 3.123692\n",
      "Epoch: 4\tFidelity = 0.502295\tKL_Divergence = 3.142311\n",
      "Epoch: 5\tFidelity = 0.502007\tKL_Divergence = 3.216804\n",
      "Epoch: 6\tFidelity = 0.502742\tKL_Divergence = 3.043392\n",
      "Epoch: 7\tFidelity = 0.502050\tKL_Divergence = 3.205002\n",
      "Epoch: 8\tFidelity = 0.502482\tKL_Divergence = 3.098912\n",
      "Epoch: 9\tFidelity = 0.502104\tKL_Divergence = 3.190641\n",
      "Epoch: 10\tFidelity = 0.502055\tKL_Divergence = 3.203764\n",
      "Epoch: 11\tFidelity = 0.502377\tKL_Divergence = 3.122940\n",
      "Epoch: 12\tFidelity = 0.502217\tKL_Divergence = 3.161683\n",
      "Epoch: 13\tFidelity = 0.502544\tKL_Divergence = 3.085113\n",
      "Epoch: 14\tFidelity = 0.502314\tKL_Divergence = 3.137861\n",
      "Epoch: 15\tFidelity = 0.502334\tKL_Divergence = 3.133056\n",
      "Epoch: 16\tFidelity = 0.502051\tKL_Divergence = 3.204899\n",
      "Epoch: 17\tFidelity = 0.502374\tKL_Divergence = 3.123483\n",
      "Epoch: 18\tFidelity = 0.502354\tKL_Divergence = 3.128201\n",
      "Epoch: 19\tFidelity = 0.502366\tKL_Divergence = 3.125335\n",
      "Epoch: 20\tFidelity = 0.502153\tKL_Divergence = 3.177734\n",
      "Epoch: 21\tFidelity = 0.502529\tKL_Divergence = 3.088320\n",
      "Epoch: 22\tFidelity = 0.502643\tKL_Divergence = 3.063847\n",
      "Epoch: 23\tFidelity = 0.502212\tKL_Divergence = 3.162828\n",
      "Epoch: 24\tFidelity = 0.502129\tKL_Divergence = 3.184077\n",
      "Epoch: 25\tFidelity = 0.502606\tKL_Divergence = 3.071740\n",
      "Epoch: 26\tFidelity = 0.501993\tKL_Divergence = 3.220683\n",
      "Epoch: 27\tFidelity = 0.502051\tKL_Divergence = 3.204751\n",
      "Epoch: 28\tFidelity = 0.502053\tKL_Divergence = 3.204318\n",
      "Epoch: 29\tFidelity = 0.502583\tKL_Divergence = 3.076685\n",
      "Epoch: 30\tFidelity = 0.502330\tKL_Divergence = 3.133807\n",
      "Epoch: 31\tFidelity = 0.502333\tKL_Divergence = 3.133154\n",
      "Epoch: 32\tFidelity = 0.502450\tKL_Divergence = 3.106015\n",
      "Epoch: 33\tFidelity = 0.502568\tKL_Divergence = 3.079958\n",
      "Epoch: 34\tFidelity = 0.502164\tKL_Divergence = 3.175020\n",
      "Epoch: 35\tFidelity = 0.502417\tKL_Divergence = 3.113732\n",
      "Epoch: 36\tFidelity = 0.502529\tKL_Divergence = 3.088486\n",
      "Epoch: 37\tFidelity = 0.502099\tKL_Divergence = 3.192095\n",
      "Epoch: 38\tFidelity = 0.502133\tKL_Divergence = 3.183220\n",
      "Epoch: 39\tFidelity = 0.502343\tKL_Divergence = 3.130835\n",
      "Epoch: 40\tFidelity = 0.502219\tKL_Divergence = 3.161203\n",
      "Epoch: 41\tFidelity = 0.502645\tKL_Divergence = 3.063653\n",
      "Epoch: 42\tFidelity = 0.502303\tKL_Divergence = 3.140578\n",
      "Epoch: 43\tFidelity = 0.502094\tKL_Divergence = 3.193367\n",
      "Epoch: 44\tFidelity = 0.502137\tKL_Divergence = 3.182087\n",
      "Epoch: 45\tFidelity = 0.502440\tKL_Divergence = 3.108344\n",
      "Epoch: 46\tFidelity = 0.502086\tKL_Divergence = 3.195553\n",
      "Epoch: 47\tFidelity = 0.502539\tKL_Divergence = 3.086388\n",
      "Epoch: 48\tFidelity = 0.502064\tKL_Divergence = 3.201492\n",
      "Epoch: 49\tFidelity = 0.502708\tKL_Divergence = 3.050491\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:43:47,257] Trial 317 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.502241\tKL_Divergence = 3.155565\n",
      "Total time elapsed during training: 56.965 s\n",
      "Trial 317 pruned. \n",
      "Epoch: 1\tFidelity = 0.502359\tKL_Divergence = 3.127216\n",
      "Epoch: 2\tFidelity = 0.501924\tKL_Divergence = 3.240289\n",
      "Epoch: 3\tFidelity = 0.502270\tKL_Divergence = 3.148445\n",
      "Epoch: 4\tFidelity = 0.502204\tKL_Divergence = 3.164772\n",
      "Epoch: 5\tFidelity = 0.502282\tKL_Divergence = 3.145503\n",
      "Epoch: 6\tFidelity = 0.502228\tKL_Divergence = 3.158690\n",
      "Epoch: 7\tFidelity = 0.501934\tKL_Divergence = 3.237475\n",
      "Epoch: 8\tFidelity = 0.502442\tKL_Divergence = 3.107866\n",
      "Epoch: 9\tFidelity = 0.502184\tKL_Divergence = 3.170052\n",
      "Epoch: 10\tFidelity = 0.502505\tKL_Divergence = 3.093687\n",
      "Epoch: 11\tFidelity = 0.502345\tKL_Divergence = 3.130387\n",
      "Epoch: 12\tFidelity = 0.502259\tKL_Divergence = 3.151179\n",
      "Epoch: 13\tFidelity = 0.501918\tKL_Divergence = 3.241965\n",
      "Epoch: 14\tFidelity = 0.502450\tKL_Divergence = 3.105955\n",
      "Epoch: 15\tFidelity = 0.502435\tKL_Divergence = 3.109578\n",
      "Epoch: 16\tFidelity = 0.502266\tKL_Divergence = 3.149586\n",
      "Epoch: 17\tFidelity = 0.502213\tKL_Divergence = 3.162685\n",
      "Epoch: 18\tFidelity = 0.502421\tKL_Divergence = 3.112828\n",
      "Epoch: 19\tFidelity = 0.502407\tKL_Divergence = 3.116041\n",
      "Epoch: 20\tFidelity = 0.502306\tKL_Divergence = 3.139718\n",
      "Epoch: 21\tFidelity = 0.502416\tKL_Divergence = 3.113917\n",
      "Epoch: 22\tFidelity = 0.501984\tKL_Divergence = 3.223189\n",
      "Epoch: 23\tFidelity = 0.502300\tKL_Divergence = 3.141149\n",
      "Epoch: 24\tFidelity = 0.502250\tKL_Divergence = 3.153476\n",
      "Epoch: 25\tFidelity = 0.502437\tKL_Divergence = 3.108983\n",
      "Epoch: 26\tFidelity = 0.502014\tKL_Divergence = 3.214987\n",
      "Epoch: 27\tFidelity = 0.502047\tKL_Divergence = 3.206078\n",
      "Epoch: 28\tFidelity = 0.502347\tKL_Divergence = 3.129978\n",
      "Epoch: 29\tFidelity = 0.502102\tKL_Divergence = 3.191275\n",
      "Epoch: 30\tFidelity = 0.502199\tKL_Divergence = 3.166264\n",
      "Epoch: 31\tFidelity = 0.502165\tKL_Divergence = 3.174680\n",
      "Epoch: 32\tFidelity = 0.502230\tKL_Divergence = 3.158304\n",
      "Epoch: 33\tFidelity = 0.502308\tKL_Divergence = 3.139187\n",
      "Epoch: 34\tFidelity = 0.502165\tKL_Divergence = 3.174736\n",
      "Epoch: 35\tFidelity = 0.502276\tKL_Divergence = 3.147093\n",
      "Epoch: 36\tFidelity = 0.502422\tKL_Divergence = 3.112490\n",
      "Epoch: 37\tFidelity = 0.502281\tKL_Divergence = 3.145700\n",
      "Epoch: 38\tFidelity = 0.502395\tKL_Divergence = 3.118639\n",
      "Epoch: 39\tFidelity = 0.501892\tKL_Divergence = 3.249780\n",
      "Epoch: 40\tFidelity = 0.502346\tKL_Divergence = 3.130308\n",
      "Epoch: 41\tFidelity = 0.501964\tKL_Divergence = 3.228858\n",
      "Epoch: 42\tFidelity = 0.502193\tKL_Divergence = 3.167587\n",
      "Epoch: 43\tFidelity = 0.502466\tKL_Divergence = 3.102366\n",
      "Epoch: 44\tFidelity = 0.502233\tKL_Divergence = 3.157585\n",
      "Epoch: 45\tFidelity = 0.502078\tKL_Divergence = 3.197548\n",
      "Epoch: 46\tFidelity = 0.502051\tKL_Divergence = 3.204966\n",
      "Epoch: 47\tFidelity = 0.501998\tKL_Divergence = 3.219474\n",
      "Epoch: 48\tFidelity = 0.502152\tKL_Divergence = 3.178251\n",
      "Epoch: 49\tFidelity = 0.502330\tKL_Divergence = 3.133916\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:44:27,106] Trial 318 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.502025\tKL_Divergence = 3.211871\n",
      "Total time elapsed during training: 39.679 s\n",
      "Trial 318 pruned. \n",
      "Epoch: 1\tFidelity = 0.502496\tKL_Divergence = 3.095715\n",
      "Epoch: 2\tFidelity = 0.501999\tKL_Divergence = 3.219217\n",
      "Epoch: 3\tFidelity = 0.502360\tKL_Divergence = 3.126782\n",
      "Epoch: 4\tFidelity = 0.501970\tKL_Divergence = 3.227266\n",
      "Epoch: 5\tFidelity = 0.502221\tKL_Divergence = 3.160669\n",
      "Epoch: 6\tFidelity = 0.502332\tKL_Divergence = 3.133617\n",
      "Epoch: 7\tFidelity = 0.502056\tKL_Divergence = 3.203638\n",
      "Epoch: 8\tFidelity = 0.502039\tKL_Divergence = 3.208095\n",
      "Epoch: 9\tFidelity = 0.502421\tKL_Divergence = 3.112710\n",
      "Epoch: 10\tFidelity = 0.502516\tKL_Divergence = 3.091266\n",
      "Epoch: 11\tFidelity = 0.502568\tKL_Divergence = 3.079954\n",
      "Epoch: 12\tFidelity = 0.502477\tKL_Divergence = 3.099782\n",
      "Epoch: 13\tFidelity = 0.502088\tKL_Divergence = 3.195003\n",
      "Epoch: 14\tFidelity = 0.502383\tKL_Divergence = 3.121612\n",
      "Epoch: 15\tFidelity = 0.501867\tKL_Divergence = 3.257206\n",
      "Epoch: 16\tFidelity = 0.501705\tKL_Divergence = 3.307667\n",
      "Epoch: 17\tFidelity = 0.502337\tKL_Divergence = 3.132516\n",
      "Epoch: 18\tFidelity = 0.502261\tKL_Divergence = 3.150930\n",
      "Epoch: 19\tFidelity = 0.502267\tKL_Divergence = 3.149434\n",
      "Epoch: 20\tFidelity = 0.501735\tKL_Divergence = 3.298047\n",
      "Epoch: 21\tFidelity = 0.501991\tKL_Divergence = 3.221360\n",
      "Epoch: 22\tFidelity = 0.501787\tKL_Divergence = 3.281497\n",
      "Epoch: 23\tFidelity = 0.501913\tKL_Divergence = 3.243583\n",
      "Epoch: 24\tFidelity = 0.502121\tKL_Divergence = 3.186342\n",
      "Epoch: 25\tFidelity = 0.502250\tKL_Divergence = 3.153537\n",
      "Epoch: 26\tFidelity = 0.502344\tKL_Divergence = 3.130712\n",
      "Epoch: 27\tFidelity = 0.502364\tKL_Divergence = 3.126120\n",
      "Epoch: 28\tFidelity = 0.502148\tKL_Divergence = 3.179305\n",
      "Epoch: 29\tFidelity = 0.501810\tKL_Divergence = 3.274420\n",
      "Epoch: 30\tFidelity = 0.501797\tKL_Divergence = 3.278569\n",
      "Epoch: 31\tFidelity = 0.502090\tKL_Divergence = 3.194426\n",
      "Epoch: 32\tFidelity = 0.502345\tKL_Divergence = 3.130660\n",
      "Epoch: 33\tFidelity = 0.501929\tKL_Divergence = 3.239131\n",
      "Epoch: 34\tFidelity = 0.501753\tKL_Divergence = 3.292117\n",
      "Epoch: 35\tFidelity = 0.502534\tKL_Divergence = 3.087626\n",
      "Epoch: 36\tFidelity = 0.502234\tKL_Divergence = 3.157651\n",
      "Epoch: 37\tFidelity = 0.501891\tKL_Divergence = 3.250247\n",
      "Epoch: 38\tFidelity = 0.501943\tKL_Divergence = 3.235040\n",
      "Epoch: 39\tFidelity = 0.501772\tKL_Divergence = 3.286295\n",
      "Epoch: 40\tFidelity = 0.501795\tKL_Divergence = 3.278999\n",
      "Epoch: 41\tFidelity = 0.502504\tKL_Divergence = 3.094041\n",
      "Epoch: 42\tFidelity = 0.502320\tKL_Divergence = 3.136681\n",
      "Epoch: 43\tFidelity = 0.502279\tKL_Divergence = 3.146585\n",
      "Epoch: 44\tFidelity = 0.502270\tKL_Divergence = 3.148619\n",
      "Epoch: 45\tFidelity = 0.501661\tKL_Divergence = 3.321959\n",
      "Epoch: 46\tFidelity = 0.502050\tKL_Divergence = 3.205317\n",
      "Epoch: 47\tFidelity = 0.501695\tKL_Divergence = 3.311106\n",
      "Epoch: 48\tFidelity = 0.501575\tKL_Divergence = 3.351587\n",
      "Epoch: 49\tFidelity = 0.502178\tKL_Divergence = 3.171653\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:45:52,320] Trial 319 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.502009\tKL_Divergence = 3.216408\n",
      "Total time elapsed during training: 85.039 s\n",
      "Trial 319 pruned. \n",
      "Epoch: 1\tFidelity = 0.501943\tKL_Divergence = 3.235029\n",
      "Epoch: 2\tFidelity = 0.501947\tKL_Divergence = 3.233873\n",
      "Epoch: 3\tFidelity = 0.501948\tKL_Divergence = 3.233597\n",
      "Epoch: 4\tFidelity = 0.502134\tKL_Divergence = 3.182895\n",
      "Epoch: 5\tFidelity = 0.502202\tKL_Divergence = 3.165558\n",
      "Epoch: 6\tFidelity = 0.502118\tKL_Divergence = 3.187096\n",
      "Epoch: 7\tFidelity = 0.501892\tKL_Divergence = 3.249799\n",
      "Epoch: 8\tFidelity = 0.501815\tKL_Divergence = 3.273049\n",
      "Epoch: 9\tFidelity = 0.502058\tKL_Divergence = 3.203206\n",
      "Epoch: 10\tFidelity = 0.501868\tKL_Divergence = 3.256949\n",
      "Epoch: 11\tFidelity = 0.502216\tKL_Divergence = 3.162029\n",
      "Epoch: 12\tFidelity = 0.502085\tKL_Divergence = 3.195853\n",
      "Epoch: 13\tFidelity = 0.501938\tKL_Divergence = 3.236453\n",
      "Epoch: 14\tFidelity = 0.501922\tKL_Divergence = 3.241049\n",
      "Epoch: 15\tFidelity = 0.501869\tKL_Divergence = 3.256641\n",
      "Epoch: 16\tFidelity = 0.501744\tKL_Divergence = 3.295102\n",
      "Epoch: 17\tFidelity = 0.501811\tKL_Divergence = 3.274197\n",
      "Epoch: 18\tFidelity = 0.501956\tKL_Divergence = 3.231320\n",
      "Epoch: 19\tFidelity = 0.502015\tKL_Divergence = 3.214934\n",
      "Epoch: 20\tFidelity = 0.501926\tKL_Divergence = 3.239883\n",
      "Epoch: 21\tFidelity = 0.501870\tKL_Divergence = 3.256364\n",
      "Epoch: 22\tFidelity = 0.501801\tKL_Divergence = 3.277176\n",
      "Epoch: 23\tFidelity = 0.501832\tKL_Divergence = 3.267774\n",
      "Epoch: 24\tFidelity = 0.501861\tKL_Divergence = 3.259117\n",
      "Epoch: 25\tFidelity = 0.502077\tKL_Divergence = 3.198104\n",
      "Epoch: 26\tFidelity = 0.501960\tKL_Divergence = 3.230279\n",
      "Epoch: 27\tFidelity = 0.501874\tKL_Divergence = 3.255358\n",
      "Epoch: 28\tFidelity = 0.501920\tKL_Divergence = 3.241816\n",
      "Epoch: 29\tFidelity = 0.501864\tKL_Divergence = 3.258318\n",
      "Epoch: 30\tFidelity = 0.502051\tKL_Divergence = 3.205083\n",
      "Epoch: 31\tFidelity = 0.501934\tKL_Divergence = 3.237742\n",
      "Epoch: 32\tFidelity = 0.501912\tKL_Divergence = 3.244154\n",
      "Epoch: 33\tFidelity = 0.501873\tKL_Divergence = 3.255662\n",
      "Epoch: 34\tFidelity = 0.502081\tKL_Divergence = 3.196988\n",
      "Epoch: 35\tFidelity = 0.502008\tKL_Divergence = 3.216997\n",
      "Epoch: 36\tFidelity = 0.501999\tKL_Divergence = 3.219449\n",
      "Epoch: 37\tFidelity = 0.501873\tKL_Divergence = 3.255563\n",
      "Epoch: 38\tFidelity = 0.502034\tKL_Divergence = 3.209651\n",
      "Epoch: 39\tFidelity = 0.502062\tKL_Divergence = 3.202035\n",
      "Epoch: 40\tFidelity = 0.501660\tKL_Divergence = 3.322698\n",
      "Epoch: 41\tFidelity = 0.501950\tKL_Divergence = 3.233080\n",
      "Epoch: 42\tFidelity = 0.502112\tKL_Divergence = 3.188870\n",
      "Epoch: 43\tFidelity = 0.501968\tKL_Divergence = 3.228129\n",
      "Epoch: 44\tFidelity = 0.501959\tKL_Divergence = 3.230709\n",
      "Epoch: 45\tFidelity = 0.501863\tKL_Divergence = 3.258498\n",
      "Epoch: 46\tFidelity = 0.501976\tKL_Divergence = 3.225882\n",
      "Epoch: 47\tFidelity = 0.501873\tKL_Divergence = 3.255401\n",
      "Epoch: 48\tFidelity = 0.501741\tKL_Divergence = 3.296064\n",
      "Epoch: 49\tFidelity = 0.501854\tKL_Divergence = 3.261138\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:46:32,795] Trial 320 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.502136\tKL_Divergence = 3.182629\n",
      "Total time elapsed during training: 40.309 s\n",
      "Trial 320 pruned. \n",
      "Epoch: 1\tFidelity = 0.501890\tKL_Divergence = 3.250532\n",
      "Epoch: 2\tFidelity = 0.501850\tKL_Divergence = 3.262333\n",
      "Epoch: 3\tFidelity = 0.502052\tKL_Divergence = 3.204750\n",
      "Epoch: 4\tFidelity = 0.501743\tKL_Divergence = 3.295560\n",
      "Epoch: 5\tFidelity = 0.501991\tKL_Divergence = 3.221657\n",
      "Epoch: 6\tFidelity = 0.501981\tKL_Divergence = 3.224198\n",
      "Epoch: 7\tFidelity = 0.502013\tKL_Divergence = 3.215337\n",
      "Epoch: 8\tFidelity = 0.501735\tKL_Divergence = 3.298032\n",
      "Epoch: 9\tFidelity = 0.501763\tKL_Divergence = 3.289234\n",
      "Epoch: 10\tFidelity = 0.501935\tKL_Divergence = 3.237419\n",
      "Epoch: 11\tFidelity = 0.501755\tKL_Divergence = 3.291629\n",
      "Epoch: 12\tFidelity = 0.502038\tKL_Divergence = 3.208540\n",
      "Epoch: 13\tFidelity = 0.501898\tKL_Divergence = 3.247838\n",
      "Epoch: 14\tFidelity = 0.502129\tKL_Divergence = 3.183821\n",
      "Epoch: 15\tFidelity = 0.501889\tKL_Divergence = 3.250432\n",
      "Epoch: 16\tFidelity = 0.501899\tKL_Divergence = 3.247643\n",
      "Epoch: 17\tFidelity = 0.501837\tKL_Divergence = 3.265908\n",
      "Epoch: 18\tFidelity = 0.501841\tKL_Divergence = 3.264812\n",
      "Epoch: 19\tFidelity = 0.501914\tKL_Divergence = 3.243223\n",
      "Epoch: 20\tFidelity = 0.501867\tKL_Divergence = 3.256750\n",
      "Epoch: 21\tFidelity = 0.502140\tKL_Divergence = 3.181292\n",
      "Epoch: 22\tFidelity = 0.501907\tKL_Divergence = 3.245249\n",
      "Epoch: 23\tFidelity = 0.501880\tKL_Divergence = 3.253135\n",
      "Epoch: 24\tFidelity = 0.501750\tKL_Divergence = 3.292880\n",
      "Epoch: 25\tFidelity = 0.502133\tKL_Divergence = 3.183184\n",
      "Epoch: 26\tFidelity = 0.501799\tKL_Divergence = 3.277537\n",
      "Epoch: 27\tFidelity = 0.501709\tKL_Divergence = 3.305930\n",
      "Epoch: 28\tFidelity = 0.502056\tKL_Divergence = 3.203303\n",
      "Epoch: 29\tFidelity = 0.501698\tKL_Divergence = 3.309552\n",
      "Epoch: 30\tFidelity = 0.501848\tKL_Divergence = 3.262629\n",
      "Epoch: 31\tFidelity = 0.501999\tKL_Divergence = 3.219206\n",
      "Epoch: 32\tFidelity = 0.501733\tKL_Divergence = 3.298332\n",
      "Epoch: 33\tFidelity = 0.502126\tKL_Divergence = 3.184972\n",
      "Epoch: 34\tFidelity = 0.501978\tKL_Divergence = 3.224949\n",
      "Epoch: 35\tFidelity = 0.502007\tKL_Divergence = 3.216747\n",
      "Epoch: 36\tFidelity = 0.501852\tKL_Divergence = 3.261434\n",
      "Epoch: 37\tFidelity = 0.501917\tKL_Divergence = 3.242364\n",
      "Epoch: 38\tFidelity = 0.502157\tKL_Divergence = 3.176876\n",
      "Epoch: 39\tFidelity = 0.502083\tKL_Divergence = 3.196509\n",
      "Epoch: 40\tFidelity = 0.501877\tKL_Divergence = 3.254260\n",
      "Epoch: 41\tFidelity = 0.501838\tKL_Divergence = 3.266036\n",
      "Epoch: 42\tFidelity = 0.502059\tKL_Divergence = 3.202954\n",
      "Epoch: 43\tFidelity = 0.501932\tKL_Divergence = 3.238244\n",
      "Epoch: 44\tFidelity = 0.502087\tKL_Divergence = 3.195399\n",
      "Epoch: 45\tFidelity = 0.501729\tKL_Divergence = 3.299944\n",
      "Epoch: 46\tFidelity = 0.501919\tKL_Divergence = 3.241967\n",
      "Epoch: 47\tFidelity = 0.501838\tKL_Divergence = 3.265934\n",
      "Epoch: 48\tFidelity = 0.502256\tKL_Divergence = 3.152182\n",
      "Epoch: 49\tFidelity = 0.501986\tKL_Divergence = 3.222808\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:47:12,728] Trial 321 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.501847\tKL_Divergence = 3.262932\n",
      "Total time elapsed during training: 39.766 s\n",
      "Trial 321 pruned. \n",
      "Epoch: 1\tFidelity = 0.501938\tKL_Divergence = 3.236347\n",
      "Epoch: 2\tFidelity = 0.502028\tKL_Divergence = 3.211269\n",
      "Epoch: 3\tFidelity = 0.502102\tKL_Divergence = 3.191447\n",
      "Epoch: 4\tFidelity = 0.501817\tKL_Divergence = 3.272368\n",
      "Epoch: 5\tFidelity = 0.502104\tKL_Divergence = 3.190873\n",
      "Epoch: 6\tFidelity = 0.502131\tKL_Divergence = 3.183873\n",
      "Epoch: 7\tFidelity = 0.501767\tKL_Divergence = 3.287972\n",
      "Epoch: 8\tFidelity = 0.502103\tKL_Divergence = 3.191130\n",
      "Epoch: 9\tFidelity = 0.501906\tKL_Divergence = 3.245907\n",
      "Epoch: 10\tFidelity = 0.502033\tKL_Divergence = 3.210049\n",
      "Epoch: 11\tFidelity = 0.502040\tKL_Divergence = 3.207908\n",
      "Epoch: 12\tFidelity = 0.502184\tKL_Divergence = 3.170238\n",
      "Epoch: 13\tFidelity = 0.502105\tKL_Divergence = 3.190670\n",
      "Epoch: 14\tFidelity = 0.501809\tKL_Divergence = 3.274898\n",
      "Epoch: 15\tFidelity = 0.502016\tKL_Divergence = 3.214474\n",
      "Epoch: 16\tFidelity = 0.501751\tKL_Divergence = 3.292739\n",
      "Epoch: 17\tFidelity = 0.501720\tKL_Divergence = 3.302962\n",
      "Epoch: 18\tFidelity = 0.501668\tKL_Divergence = 3.320008\n",
      "Epoch: 19\tFidelity = 0.502325\tKL_Divergence = 3.135366\n",
      "Epoch: 20\tFidelity = 0.501753\tKL_Divergence = 3.292219\n",
      "Epoch: 21\tFidelity = 0.501932\tKL_Divergence = 3.238221\n",
      "Epoch: 22\tFidelity = 0.501848\tKL_Divergence = 3.262983\n",
      "Epoch: 23\tFidelity = 0.501783\tKL_Divergence = 3.282750\n",
      "Epoch: 24\tFidelity = 0.502187\tKL_Divergence = 3.169289\n",
      "Epoch: 25\tFidelity = 0.502071\tKL_Divergence = 3.199561\n",
      "Epoch: 26\tFidelity = 0.501777\tKL_Divergence = 3.284546\n",
      "Epoch: 27\tFidelity = 0.501772\tKL_Divergence = 3.286383\n",
      "Epoch: 28\tFidelity = 0.502138\tKL_Divergence = 3.182024\n",
      "Epoch: 29\tFidelity = 0.502078\tKL_Divergence = 3.197812\n",
      "Epoch: 30\tFidelity = 0.502005\tKL_Divergence = 3.217517\n",
      "Epoch: 31\tFidelity = 0.501674\tKL_Divergence = 3.317696\n",
      "Epoch: 32\tFidelity = 0.501783\tKL_Divergence = 3.282832\n",
      "Epoch: 33\tFidelity = 0.501760\tKL_Divergence = 3.289876\n",
      "Epoch: 34\tFidelity = 0.501984\tKL_Divergence = 3.223338\n",
      "Epoch: 35\tFidelity = 0.501817\tKL_Divergence = 3.272227\n",
      "Epoch: 36\tFidelity = 0.502057\tKL_Divergence = 3.203404\n",
      "Epoch: 37\tFidelity = 0.502007\tKL_Divergence = 3.216913\n",
      "Epoch: 38\tFidelity = 0.501864\tKL_Divergence = 3.258069\n",
      "Epoch: 39\tFidelity = 0.501886\tKL_Divergence = 3.251669\n",
      "Epoch: 40\tFidelity = 0.501808\tKL_Divergence = 3.275165\n",
      "Epoch: 41\tFidelity = 0.501806\tKL_Divergence = 3.275577\n",
      "Epoch: 42\tFidelity = 0.501777\tKL_Divergence = 3.284572\n",
      "Epoch: 43\tFidelity = 0.501817\tKL_Divergence = 3.272369\n",
      "Epoch: 44\tFidelity = 0.501607\tKL_Divergence = 3.340421\n",
      "Epoch: 45\tFidelity = 0.502084\tKL_Divergence = 3.196130\n",
      "Epoch: 46\tFidelity = 0.502069\tKL_Divergence = 3.200245\n",
      "Epoch: 47\tFidelity = 0.502092\tKL_Divergence = 3.194138\n",
      "Epoch: 48\tFidelity = 0.501910\tKL_Divergence = 3.244685\n",
      "Epoch: 49\tFidelity = 0.501683\tKL_Divergence = 3.314941\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:48:38,855] Trial 322 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.501775\tKL_Divergence = 3.285373\n",
      "Total time elapsed during training: 85.964 s\n",
      "Trial 322 pruned. \n",
      "Epoch: 1\tFidelity = 0.501959\tKL_Divergence = 3.230467\n",
      "Epoch: 2\tFidelity = 0.501668\tKL_Divergence = 3.319946\n",
      "Epoch: 3\tFidelity = 0.501584\tKL_Divergence = 3.348339\n",
      "Epoch: 4\tFidelity = 0.501883\tKL_Divergence = 3.252549\n",
      "Epoch: 5\tFidelity = 0.501942\tKL_Divergence = 3.235279\n",
      "Epoch: 6\tFidelity = 0.502046\tKL_Divergence = 3.206310\n",
      "Epoch: 7\tFidelity = 0.502062\tKL_Divergence = 3.202048\n",
      "Epoch: 8\tFidelity = 0.502025\tKL_Divergence = 3.212106\n",
      "Epoch: 9\tFidelity = 0.501722\tKL_Divergence = 3.302032\n",
      "Epoch: 10\tFidelity = 0.501903\tKL_Divergence = 3.246587\n",
      "Epoch: 11\tFidelity = 0.501770\tKL_Divergence = 3.286861\n",
      "Epoch: 12\tFidelity = 0.501641\tKL_Divergence = 3.329070\n",
      "Epoch: 13\tFidelity = 0.501813\tKL_Divergence = 3.273627\n",
      "Epoch: 14\tFidelity = 0.501912\tKL_Divergence = 3.243972\n",
      "Epoch: 15\tFidelity = 0.501858\tKL_Divergence = 3.259834\n",
      "Epoch: 16\tFidelity = 0.501924\tKL_Divergence = 3.240592\n",
      "Epoch: 17\tFidelity = 0.501644\tKL_Divergence = 3.328041\n",
      "Epoch: 18\tFidelity = 0.502015\tKL_Divergence = 3.215005\n",
      "Epoch: 19\tFidelity = 0.501716\tKL_Divergence = 3.304175\n",
      "Epoch: 20\tFidelity = 0.501772\tKL_Divergence = 3.286420\n",
      "Epoch: 21\tFidelity = 0.501807\tKL_Divergence = 3.275286\n",
      "Epoch: 22\tFidelity = 0.501960\tKL_Divergence = 3.230259\n",
      "Epoch: 23\tFidelity = 0.501872\tKL_Divergence = 3.255933\n",
      "Epoch: 24\tFidelity = 0.501738\tKL_Divergence = 3.296998\n",
      "Epoch: 25\tFidelity = 0.501651\tKL_Divergence = 3.325632\n",
      "Epoch: 26\tFidelity = 0.501785\tKL_Divergence = 3.282239\n",
      "Epoch: 27\tFidelity = 0.502153\tKL_Divergence = 3.178174\n",
      "Epoch: 28\tFidelity = 0.501924\tKL_Divergence = 3.240640\n",
      "Epoch: 29\tFidelity = 0.501744\tKL_Divergence = 3.295256\n",
      "Epoch: 30\tFidelity = 0.501837\tKL_Divergence = 3.266422\n",
      "Epoch: 31\tFidelity = 0.501818\tKL_Divergence = 3.272146\n",
      "Epoch: 32\tFidelity = 0.501676\tKL_Divergence = 3.317306\n",
      "Epoch: 33\tFidelity = 0.501823\tKL_Divergence = 3.270441\n",
      "Epoch: 34\tFidelity = 0.501894\tKL_Divergence = 3.249263\n",
      "Epoch: 35\tFidelity = 0.501773\tKL_Divergence = 3.285897\n",
      "Epoch: 36\tFidelity = 0.501828\tKL_Divergence = 3.269141\n",
      "Epoch: 37\tFidelity = 0.501649\tKL_Divergence = 3.326290\n",
      "Epoch: 38\tFidelity = 0.501750\tKL_Divergence = 3.293339\n",
      "Epoch: 39\tFidelity = 0.501933\tKL_Divergence = 3.237896\n",
      "Epoch: 40\tFidelity = 0.501861\tKL_Divergence = 3.258991\n",
      "Epoch: 41\tFidelity = 0.501733\tKL_Divergence = 3.298764\n",
      "Epoch: 42\tFidelity = 0.502133\tKL_Divergence = 3.183402\n",
      "Epoch: 43\tFidelity = 0.501993\tKL_Divergence = 3.221138\n",
      "Epoch: 44\tFidelity = 0.501675\tKL_Divergence = 3.317719\n",
      "Epoch: 45\tFidelity = 0.501835\tKL_Divergence = 3.267010\n",
      "Epoch: 46\tFidelity = 0.501744\tKL_Divergence = 3.295231\n",
      "Epoch: 47\tFidelity = 0.501681\tKL_Divergence = 3.315744\n",
      "Epoch: 48\tFidelity = 0.501925\tKL_Divergence = 3.240431\n",
      "Epoch: 49\tFidelity = 0.501843\tKL_Divergence = 3.264367\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:49:27,188] Trial 323 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.501956\tKL_Divergence = 3.231513\n",
      "Total time elapsed during training: 48.160 s\n",
      "Trial 323 pruned. \n",
      "Epoch: 1\tFidelity = 0.501813\tKL_Divergence = 3.273613\n",
      "Epoch: 2\tFidelity = 0.501954\tKL_Divergence = 3.231996\n",
      "Epoch: 3\tFidelity = 0.501717\tKL_Divergence = 3.303762\n",
      "Epoch: 4\tFidelity = 0.501812\tKL_Divergence = 3.273858\n",
      "Epoch: 5\tFidelity = 0.501825\tKL_Divergence = 3.269921\n",
      "Epoch: 6\tFidelity = 0.501814\tKL_Divergence = 3.273436\n",
      "Epoch: 7\tFidelity = 0.501814\tKL_Divergence = 3.273207\n",
      "Epoch: 8\tFidelity = 0.501871\tKL_Divergence = 3.256252\n",
      "Epoch: 9\tFidelity = 0.501892\tKL_Divergence = 3.249716\n",
      "Epoch: 10\tFidelity = 0.501698\tKL_Divergence = 3.309899\n",
      "Epoch: 11\tFidelity = 0.501795\tKL_Divergence = 3.279139\n",
      "Epoch: 12\tFidelity = 0.501854\tKL_Divergence = 3.261119\n",
      "Epoch: 13\tFidelity = 0.501622\tKL_Divergence = 3.335378\n",
      "Epoch: 14\tFidelity = 0.501755\tKL_Divergence = 3.291569\n",
      "Epoch: 15\tFidelity = 0.501655\tKL_Divergence = 3.324248\n",
      "Epoch: 16\tFidelity = 0.501621\tKL_Divergence = 3.335675\n",
      "Epoch: 17\tFidelity = 0.501781\tKL_Divergence = 3.283547\n",
      "Epoch: 18\tFidelity = 0.501920\tKL_Divergence = 3.241820\n",
      "Epoch: 19\tFidelity = 0.501720\tKL_Divergence = 3.302914\n",
      "Epoch: 20\tFidelity = 0.501624\tKL_Divergence = 3.334804\n",
      "Epoch: 21\tFidelity = 0.501926\tKL_Divergence = 3.239918\n",
      "Epoch: 22\tFidelity = 0.501585\tKL_Divergence = 3.348206\n",
      "Epoch: 23\tFidelity = 0.502027\tKL_Divergence = 3.211412\n",
      "Epoch: 24\tFidelity = 0.501894\tKL_Divergence = 3.249260\n",
      "Epoch: 25\tFidelity = 0.501784\tKL_Divergence = 3.282717\n",
      "Epoch: 26\tFidelity = 0.501596\tKL_Divergence = 3.344476\n",
      "Epoch: 27\tFidelity = 0.501689\tKL_Divergence = 3.313030\n",
      "Epoch: 28\tFidelity = 0.501517\tKL_Divergence = 3.372679\n",
      "Epoch: 29\tFidelity = 0.501748\tKL_Divergence = 3.293860\n",
      "Epoch: 30\tFidelity = 0.501732\tKL_Divergence = 3.298952\n",
      "Epoch: 31\tFidelity = 0.501980\tKL_Divergence = 3.224528\n",
      "Epoch: 32\tFidelity = 0.501836\tKL_Divergence = 3.266447\n",
      "Epoch: 33\tFidelity = 0.501928\tKL_Divergence = 3.239406\n",
      "Epoch: 34\tFidelity = 0.501810\tKL_Divergence = 3.274473\n",
      "Epoch: 35\tFidelity = 0.501644\tKL_Divergence = 3.327911\n",
      "Epoch: 36\tFidelity = 0.501941\tKL_Divergence = 3.235684\n",
      "Epoch: 37\tFidelity = 0.501971\tKL_Divergence = 3.226973\n",
      "Epoch: 38\tFidelity = 0.501652\tKL_Divergence = 3.324962\n",
      "Epoch: 39\tFidelity = 0.501900\tKL_Divergence = 3.247451\n",
      "Epoch: 40\tFidelity = 0.501503\tKL_Divergence = 3.377559\n",
      "Epoch: 41\tFidelity = 0.501797\tKL_Divergence = 3.278266\n",
      "Epoch: 42\tFidelity = 0.501979\tKL_Divergence = 3.224540\n",
      "Epoch: 43\tFidelity = 0.501967\tKL_Divergence = 3.228223\n",
      "Epoch: 44\tFidelity = 0.501823\tKL_Divergence = 3.270481\n",
      "Epoch: 45\tFidelity = 0.501693\tKL_Divergence = 3.311416\n",
      "Epoch: 46\tFidelity = 0.501724\tKL_Divergence = 3.301489\n",
      "Epoch: 47\tFidelity = 0.501821\tKL_Divergence = 3.270932\n",
      "Epoch: 48\tFidelity = 0.501777\tKL_Divergence = 3.284648\n",
      "Epoch: 49\tFidelity = 0.501708\tKL_Divergence = 3.306488\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:50:13,348] Trial 324 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.501632\tKL_Divergence = 3.331667\n",
      "Total time elapsed during training: 45.993 s\n",
      "Trial 324 pruned. \n",
      "Epoch: 1\tFidelity = 0.502057\tKL_Divergence = 3.203378\n",
      "Epoch: 2\tFidelity = 0.501552\tKL_Divergence = 3.359712\n",
      "Epoch: 3\tFidelity = 0.502253\tKL_Divergence = 3.152754\n",
      "Epoch: 4\tFidelity = 0.501454\tKL_Divergence = 3.395927\n",
      "Epoch: 5\tFidelity = 0.502215\tKL_Divergence = 3.162192\n",
      "Epoch: 6\tFidelity = 0.501403\tKL_Divergence = 3.415752\n",
      "Epoch: 7\tFidelity = 0.502394\tKL_Divergence = 3.119107\n",
      "Epoch: 8\tFidelity = 0.501491\tKL_Divergence = 3.382269\n",
      "Epoch: 9\tFidelity = 0.502025\tKL_Divergence = 3.212118\n",
      "Epoch: 10\tFidelity = 0.501343\tKL_Divergence = 3.440252\n",
      "Epoch: 11\tFidelity = 0.502287\tKL_Divergence = 3.144653\n",
      "Epoch: 12\tFidelity = 0.501433\tKL_Divergence = 3.404088\n",
      "Epoch: 13\tFidelity = 0.502286\tKL_Divergence = 3.144902\n",
      "Epoch: 14\tFidelity = 0.501650\tKL_Divergence = 3.326030\n",
      "Epoch: 15\tFidelity = 0.501829\tKL_Divergence = 3.268571\n",
      "Epoch: 16\tFidelity = 0.502007\tKL_Divergence = 3.217146\n",
      "Epoch: 17\tFidelity = 0.501437\tKL_Divergence = 3.402604\n",
      "Epoch: 18\tFidelity = 0.502241\tKL_Divergence = 3.155756\n",
      "Epoch: 19\tFidelity = 0.501608\tKL_Divergence = 3.340212\n",
      "Epoch: 20\tFidelity = 0.502379\tKL_Divergence = 3.122647\n",
      "Epoch: 21\tFidelity = 0.501233\tKL_Divergence = 3.487498\n",
      "Epoch: 22\tFidelity = 0.502248\tKL_Divergence = 3.154027\n",
      "Epoch: 23\tFidelity = 0.501519\tKL_Divergence = 3.371763\n",
      "Epoch: 24\tFidelity = 0.501697\tKL_Divergence = 3.310418\n",
      "Epoch: 25\tFidelity = 0.501928\tKL_Divergence = 3.239357\n",
      "Epoch: 26\tFidelity = 0.501714\tKL_Divergence = 3.304901\n",
      "Epoch: 27\tFidelity = 0.501770\tKL_Divergence = 3.287098\n",
      "Epoch: 28\tFidelity = 0.501758\tKL_Divergence = 3.290774\n",
      "Epoch: 29\tFidelity = 0.501611\tKL_Divergence = 3.339341\n",
      "Epoch: 30\tFidelity = 0.501783\tKL_Divergence = 3.282886\n",
      "Epoch: 31\tFidelity = 0.501895\tKL_Divergence = 3.248969\n",
      "Epoch: 32\tFidelity = 0.501646\tKL_Divergence = 3.327206\n",
      "Epoch: 33\tFidelity = 0.501912\tKL_Divergence = 3.244095\n",
      "Epoch: 34\tFidelity = 0.501532\tKL_Divergence = 3.367349\n",
      "Epoch: 35\tFidelity = 0.501767\tKL_Divergence = 3.287889\n",
      "Epoch: 36\tFidelity = 0.502246\tKL_Divergence = 3.154679\n",
      "Epoch: 37\tFidelity = 0.501519\tKL_Divergence = 3.371749\n",
      "Epoch: 38\tFidelity = 0.501979\tKL_Divergence = 3.224841\n",
      "Epoch: 39\tFidelity = 0.501444\tKL_Divergence = 3.399943\n",
      "Epoch: 40\tFidelity = 0.502120\tKL_Divergence = 3.186718\n",
      "Epoch: 41\tFidelity = 0.501517\tKL_Divergence = 3.372657\n",
      "Epoch: 42\tFidelity = 0.501965\tKL_Divergence = 3.229006\n",
      "Epoch: 43\tFidelity = 0.501438\tKL_Divergence = 3.402166\n",
      "Epoch: 44\tFidelity = 0.501865\tKL_Divergence = 3.258054\n",
      "Epoch: 45\tFidelity = 0.501547\tKL_Divergence = 3.361825\n",
      "Epoch: 46\tFidelity = 0.501542\tKL_Divergence = 3.363476\n",
      "Epoch: 47\tFidelity = 0.501752\tKL_Divergence = 3.292578\n",
      "Epoch: 48\tFidelity = 0.501661\tKL_Divergence = 3.322343\n",
      "Epoch: 49\tFidelity = 0.502109\tKL_Divergence = 3.189528\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:50:45,840] Trial 325 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.501429\tKL_Divergence = 3.405944\n",
      "Total time elapsed during training: 32.298 s\n",
      "Trial 325 pruned. \n",
      "Epoch: 1\tFidelity = 0.501555\tKL_Divergence = 3.358908\n",
      "Epoch: 2\tFidelity = 0.501640\tKL_Divergence = 3.329270\n",
      "Epoch: 3\tFidelity = 0.501679\tKL_Divergence = 3.316315\n",
      "Epoch: 4\tFidelity = 0.501692\tKL_Divergence = 3.311937\n",
      "Epoch: 5\tFidelity = 0.501713\tKL_Divergence = 3.305058\n",
      "Epoch: 6\tFidelity = 0.501749\tKL_Divergence = 3.293583\n",
      "Epoch: 7\tFidelity = 0.501706\tKL_Divergence = 3.307445\n",
      "Epoch: 8\tFidelity = 0.501751\tKL_Divergence = 3.293025\n",
      "Epoch: 9\tFidelity = 0.501786\tKL_Divergence = 3.282054\n",
      "Epoch: 10\tFidelity = 0.501790\tKL_Divergence = 3.280719\n",
      "Epoch: 11\tFidelity = 0.501760\tKL_Divergence = 3.290153\n",
      "Epoch: 12\tFidelity = 0.501726\tKL_Divergence = 3.300825\n",
      "Epoch: 13\tFidelity = 0.501754\tKL_Divergence = 3.292137\n",
      "Epoch: 14\tFidelity = 0.501811\tKL_Divergence = 3.274386\n",
      "Epoch: 15\tFidelity = 0.501774\tKL_Divergence = 3.285673\n",
      "Epoch: 16\tFidelity = 0.501820\tKL_Divergence = 3.271445\n",
      "Epoch: 17\tFidelity = 0.501761\tKL_Divergence = 3.289801\n",
      "Epoch: 18\tFidelity = 0.501742\tKL_Divergence = 3.295995\n",
      "Epoch: 19\tFidelity = 0.501763\tKL_Divergence = 3.289251\n",
      "Epoch: 20\tFidelity = 0.501794\tKL_Divergence = 3.279450\n",
      "Epoch: 21\tFidelity = 0.501695\tKL_Divergence = 3.310891\n",
      "Epoch: 22\tFidelity = 0.501803\tKL_Divergence = 3.276843\n",
      "Epoch: 23\tFidelity = 0.501771\tKL_Divergence = 3.286596\n",
      "Epoch: 24\tFidelity = 0.501792\tKL_Divergence = 3.280144\n",
      "Epoch: 25\tFidelity = 0.501806\tKL_Divergence = 3.275667\n",
      "Epoch: 26\tFidelity = 0.501755\tKL_Divergence = 3.291651\n",
      "Epoch: 27\tFidelity = 0.501720\tKL_Divergence = 3.302951\n",
      "Epoch: 28\tFidelity = 0.501728\tKL_Divergence = 3.300348\n",
      "Epoch: 29\tFidelity = 0.501731\tKL_Divergence = 3.299431\n",
      "Epoch: 30\tFidelity = 0.501695\tKL_Divergence = 3.310938\n",
      "Epoch: 31\tFidelity = 0.501744\tKL_Divergence = 3.295265\n",
      "Epoch: 32\tFidelity = 0.501872\tKL_Divergence = 3.255742\n",
      "Epoch: 33\tFidelity = 0.501859\tKL_Divergence = 3.259692\n",
      "Epoch: 34\tFidelity = 0.501766\tKL_Divergence = 3.288348\n",
      "Epoch: 35\tFidelity = 0.501739\tKL_Divergence = 3.296937\n",
      "Epoch: 36\tFidelity = 0.501850\tKL_Divergence = 3.262498\n",
      "Epoch: 37\tFidelity = 0.501796\tKL_Divergence = 3.278769\n",
      "Epoch: 38\tFidelity = 0.501681\tKL_Divergence = 3.315721\n",
      "Epoch: 39\tFidelity = 0.501775\tKL_Divergence = 3.285469\n",
      "Epoch: 40\tFidelity = 0.501769\tKL_Divergence = 3.287275\n",
      "Epoch: 41\tFidelity = 0.501745\tKL_Divergence = 3.294828\n",
      "Epoch: 42\tFidelity = 0.501628\tKL_Divergence = 3.333280\n",
      "Epoch: 43\tFidelity = 0.501765\tKL_Divergence = 3.288411\n",
      "Epoch: 44\tFidelity = 0.501852\tKL_Divergence = 3.261866\n",
      "Epoch: 45\tFidelity = 0.501710\tKL_Divergence = 3.306174\n",
      "Epoch: 46\tFidelity = 0.501844\tKL_Divergence = 3.264238\n",
      "Epoch: 47\tFidelity = 0.501734\tKL_Divergence = 3.298274\n",
      "Epoch: 48\tFidelity = 0.501751\tKL_Divergence = 3.292919\n",
      "Epoch: 49\tFidelity = 0.501845\tKL_Divergence = 3.263807\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:51:18,846] Trial 326 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.501869\tKL_Divergence = 3.256641\n",
      "Total time elapsed during training: 32.838 s\n",
      "Trial 326 pruned. \n",
      "Epoch: 1\tFidelity = 0.502036\tKL_Divergence = 3.209190\n",
      "Epoch: 2\tFidelity = 0.501623\tKL_Divergence = 3.335075\n",
      "Epoch: 3\tFidelity = 0.501769\tKL_Divergence = 3.287427\n",
      "Epoch: 4\tFidelity = 0.501605\tKL_Divergence = 3.341517\n",
      "Epoch: 5\tFidelity = 0.501909\tKL_Divergence = 3.244863\n",
      "Epoch: 6\tFidelity = 0.501796\tKL_Divergence = 3.278833\n",
      "Epoch: 7\tFidelity = 0.501969\tKL_Divergence = 3.227790\n",
      "Epoch: 8\tFidelity = 0.501606\tKL_Divergence = 3.341037\n",
      "Epoch: 9\tFidelity = 0.501830\tKL_Divergence = 3.268503\n",
      "Epoch: 10\tFidelity = 0.502108\tKL_Divergence = 3.189837\n",
      "Epoch: 11\tFidelity = 0.501753\tKL_Divergence = 3.292425\n",
      "Epoch: 12\tFidelity = 0.501886\tKL_Divergence = 3.251671\n",
      "Epoch: 13\tFidelity = 0.501912\tKL_Divergence = 3.243786\n",
      "Epoch: 14\tFidelity = 0.501814\tKL_Divergence = 3.273125\n",
      "Epoch: 15\tFidelity = 0.501626\tKL_Divergence = 3.334172\n",
      "Epoch: 16\tFidelity = 0.501927\tKL_Divergence = 3.239526\n",
      "Epoch: 17\tFidelity = 0.501716\tKL_Divergence = 3.303982\n",
      "Epoch: 18\tFidelity = 0.501986\tKL_Divergence = 3.222922\n",
      "Epoch: 19\tFidelity = 0.501764\tKL_Divergence = 3.288753\n",
      "Epoch: 20\tFidelity = 0.502046\tKL_Divergence = 3.206412\n",
      "Epoch: 21\tFidelity = 0.501779\tKL_Divergence = 3.283963\n",
      "Epoch: 22\tFidelity = 0.501840\tKL_Divergence = 3.265413\n",
      "Epoch: 23\tFidelity = 0.501951\tKL_Divergence = 3.232883\n",
      "Epoch: 24\tFidelity = 0.501792\tKL_Divergence = 3.280119\n",
      "Epoch: 25\tFidelity = 0.501831\tKL_Divergence = 3.268093\n",
      "Epoch: 26\tFidelity = 0.501637\tKL_Divergence = 3.330229\n",
      "Epoch: 27\tFidelity = 0.501769\tKL_Divergence = 3.287315\n",
      "Epoch: 28\tFidelity = 0.501712\tKL_Divergence = 3.305501\n",
      "Epoch: 29\tFidelity = 0.501982\tKL_Divergence = 3.224250\n",
      "Epoch: 30\tFidelity = 0.501803\tKL_Divergence = 3.276681\n",
      "Epoch: 31\tFidelity = 0.501881\tKL_Divergence = 3.253290\n",
      "Epoch: 32\tFidelity = 0.501876\tKL_Divergence = 3.254660\n",
      "Epoch: 33\tFidelity = 0.501978\tKL_Divergence = 3.225180\n",
      "Epoch: 34\tFidelity = 0.501913\tKL_Divergence = 3.243717\n",
      "Epoch: 35\tFidelity = 0.501840\tKL_Divergence = 3.265298\n",
      "Epoch: 36\tFidelity = 0.501689\tKL_Divergence = 3.312989\n",
      "Epoch: 37\tFidelity = 0.501634\tKL_Divergence = 3.331116\n",
      "Epoch: 38\tFidelity = 0.501851\tKL_Divergence = 3.261598\n",
      "Epoch: 39\tFidelity = 0.501886\tKL_Divergence = 3.251345\n",
      "Epoch: 40\tFidelity = 0.501814\tKL_Divergence = 3.272706\n",
      "Epoch: 41\tFidelity = 0.501859\tKL_Divergence = 3.259220\n",
      "Epoch: 42\tFidelity = 0.502011\tKL_Divergence = 3.215430\n",
      "Epoch: 43\tFidelity = 0.501629\tKL_Divergence = 3.332339\n",
      "Epoch: 44\tFidelity = 0.501774\tKL_Divergence = 3.284695\n",
      "Epoch: 45\tFidelity = 0.501692\tKL_Divergence = 3.311588\n",
      "Epoch: 46\tFidelity = 0.501857\tKL_Divergence = 3.259824\n",
      "Epoch: 47\tFidelity = 0.501877\tKL_Divergence = 3.254015\n",
      "Epoch: 48\tFidelity = 0.502040\tKL_Divergence = 3.207930\n",
      "Epoch: 49\tFidelity = 0.501919\tKL_Divergence = 3.241868\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:51:58,433] Trial 327 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.501702\tKL_Divergence = 3.308816\n",
      "Total time elapsed during training: 39.429 s\n",
      "Trial 327 pruned. \n",
      "Epoch: 1\tFidelity = 0.501676\tKL_Divergence = 3.317123\n",
      "Epoch: 2\tFidelity = 0.501732\tKL_Divergence = 3.298962\n",
      "Epoch: 3\tFidelity = 0.502054\tKL_Divergence = 3.204275\n",
      "Epoch: 4\tFidelity = 0.501972\tKL_Divergence = 3.226971\n",
      "Epoch: 5\tFidelity = 0.501880\tKL_Divergence = 3.253573\n",
      "Epoch: 6\tFidelity = 0.501728\tKL_Divergence = 3.300268\n",
      "Epoch: 7\tFidelity = 0.501765\tKL_Divergence = 3.288510\n",
      "Epoch: 8\tFidelity = 0.501906\tKL_Divergence = 3.245746\n",
      "Epoch: 9\tFidelity = 0.501571\tKL_Divergence = 3.353312\n",
      "Epoch: 10\tFidelity = 0.501799\tKL_Divergence = 3.278009\n",
      "Epoch: 11\tFidelity = 0.501833\tKL_Divergence = 3.267517\n",
      "Epoch: 12\tFidelity = 0.501675\tKL_Divergence = 3.317627\n",
      "Epoch: 13\tFidelity = 0.501841\tKL_Divergence = 3.265165\n",
      "Epoch: 14\tFidelity = 0.501968\tKL_Divergence = 3.228109\n",
      "Epoch: 15\tFidelity = 0.501622\tKL_Divergence = 3.335566\n",
      "Epoch: 16\tFidelity = 0.501771\tKL_Divergence = 3.286754\n",
      "Epoch: 17\tFidelity = 0.501866\tKL_Divergence = 3.257522\n",
      "Epoch: 18\tFidelity = 0.501765\tKL_Divergence = 3.288429\n",
      "Epoch: 19\tFidelity = 0.501685\tKL_Divergence = 3.314304\n",
      "Epoch: 20\tFidelity = 0.501823\tKL_Divergence = 3.270691\n",
      "Epoch: 21\tFidelity = 0.501599\tKL_Divergence = 3.343202\n",
      "Epoch: 22\tFidelity = 0.501626\tKL_Divergence = 3.334224\n",
      "Epoch: 23\tFidelity = 0.501725\tKL_Divergence = 3.301202\n",
      "Epoch: 24\tFidelity = 0.501661\tKL_Divergence = 3.322281\n",
      "Epoch: 25\tFidelity = 0.501949\tKL_Divergence = 3.233406\n",
      "Epoch: 26\tFidelity = 0.501724\tKL_Divergence = 3.301719\n",
      "Epoch: 27\tFidelity = 0.501736\tKL_Divergence = 3.297650\n",
      "Epoch: 28\tFidelity = 0.501996\tKL_Divergence = 3.220088\n",
      "Epoch: 29\tFidelity = 0.501900\tKL_Divergence = 3.247547\n",
      "Epoch: 30\tFidelity = 0.502056\tKL_Divergence = 3.203706\n",
      "Epoch: 31\tFidelity = 0.501702\tKL_Divergence = 3.308568\n",
      "Epoch: 32\tFidelity = 0.501837\tKL_Divergence = 3.266312\n",
      "Epoch: 33\tFidelity = 0.501891\tKL_Divergence = 3.250211\n",
      "Epoch: 34\tFidelity = 0.501939\tKL_Divergence = 3.236383\n",
      "Epoch: 35\tFidelity = 0.501893\tKL_Divergence = 3.249665\n",
      "Epoch: 36\tFidelity = 0.501767\tKL_Divergence = 3.287800\n",
      "Epoch: 37\tFidelity = 0.501652\tKL_Divergence = 3.325354\n",
      "Epoch: 38\tFidelity = 0.501854\tKL_Divergence = 3.261172\n",
      "Epoch: 39\tFidelity = 0.501834\tKL_Divergence = 3.267294\n",
      "Epoch: 40\tFidelity = 0.501802\tKL_Divergence = 3.277156\n",
      "Epoch: 41\tFidelity = 0.501616\tKL_Divergence = 3.337617\n",
      "Epoch: 42\tFidelity = 0.501729\tKL_Divergence = 3.300015\n",
      "Epoch: 43\tFidelity = 0.501823\tKL_Divergence = 3.270571\n",
      "Epoch: 44\tFidelity = 0.501746\tKL_Divergence = 3.294559\n",
      "Epoch: 45\tFidelity = 0.501667\tKL_Divergence = 3.320396\n",
      "Epoch: 46\tFidelity = 0.501669\tKL_Divergence = 3.319557\n",
      "Epoch: 47\tFidelity = 0.501663\tKL_Divergence = 3.321572\n",
      "Epoch: 48\tFidelity = 0.501660\tKL_Divergence = 3.322695\n",
      "Epoch: 49\tFidelity = 0.501742\tKL_Divergence = 3.295728\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:52:38,280] Trial 328 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.501662\tKL_Divergence = 3.321779\n",
      "Total time elapsed during training: 39.679 s\n",
      "Trial 328 pruned. \n",
      "Epoch: 1\tFidelity = 0.501474\tKL_Divergence = 3.388546\n",
      "Epoch: 2\tFidelity = 0.501566\tKL_Divergence = 3.355023\n",
      "Epoch: 3\tFidelity = 0.501376\tKL_Divergence = 3.426942\n",
      "Epoch: 4\tFidelity = 0.501757\tKL_Divergence = 3.291028\n",
      "Epoch: 5\tFidelity = 0.501551\tKL_Divergence = 3.360395\n",
      "Epoch: 6\tFidelity = 0.501938\tKL_Divergence = 3.236461\n",
      "Epoch: 7\tFidelity = 0.501910\tKL_Divergence = 3.244604\n",
      "Epoch: 8\tFidelity = 0.502141\tKL_Divergence = 3.181199\n",
      "Epoch: 9\tFidelity = 0.501808\tKL_Divergence = 3.275006\n",
      "Epoch: 10\tFidelity = 0.501621\tKL_Divergence = 3.335775\n",
      "Epoch: 11\tFidelity = 0.501601\tKL_Divergence = 3.342650\n",
      "Epoch: 12\tFidelity = 0.501825\tKL_Divergence = 3.269955\n",
      "Epoch: 13\tFidelity = 0.501529\tKL_Divergence = 3.368071\n",
      "Epoch: 14\tFidelity = 0.501560\tKL_Divergence = 3.356826\n",
      "Epoch: 15\tFidelity = 0.501705\tKL_Divergence = 3.307577\n",
      "Epoch: 16\tFidelity = 0.501559\tKL_Divergence = 3.357266\n",
      "Epoch: 17\tFidelity = 0.501851\tKL_Divergence = 3.262000\n",
      "Epoch: 18\tFidelity = 0.501729\tKL_Divergence = 3.299998\n",
      "Epoch: 19\tFidelity = 0.501836\tKL_Divergence = 3.266474\n",
      "Epoch: 20\tFidelity = 0.502268\tKL_Divergence = 3.148992\n",
      "Epoch: 21\tFidelity = 0.502083\tKL_Divergence = 3.196433\n",
      "Epoch: 22\tFidelity = 0.502183\tKL_Divergence = 3.170163\n",
      "Epoch: 23\tFidelity = 0.501920\tKL_Divergence = 3.241689\n",
      "Epoch: 24\tFidelity = 0.502180\tKL_Divergence = 3.171030\n",
      "Epoch: 25\tFidelity = 0.501848\tKL_Divergence = 3.262757\n",
      "Epoch: 26\tFidelity = 0.502175\tKL_Divergence = 3.172267\n",
      "Epoch: 27\tFidelity = 0.501780\tKL_Divergence = 3.283778\n",
      "Epoch: 28\tFidelity = 0.501444\tKL_Divergence = 3.399934\n",
      "Epoch: 29\tFidelity = 0.501551\tKL_Divergence = 3.360211\n",
      "Epoch: 30\tFidelity = 0.501379\tKL_Divergence = 3.425551\n",
      "Epoch: 31\tFidelity = 0.502005\tKL_Divergence = 3.217597\n",
      "Epoch: 32\tFidelity = 0.502308\tKL_Divergence = 3.139322\n",
      "Epoch: 33\tFidelity = 0.502025\tKL_Divergence = 3.211955\n",
      "Epoch: 34\tFidelity = 0.501628\tKL_Divergence = 3.333195\n",
      "Epoch: 35\tFidelity = 0.501560\tKL_Divergence = 3.357142\n",
      "Epoch: 36\tFidelity = 0.501286\tKL_Divergence = 3.464328\n",
      "Epoch: 37\tFidelity = 0.501702\tKL_Divergence = 3.308515\n",
      "Epoch: 38\tFidelity = 0.501786\tKL_Divergence = 3.281848\n",
      "Epoch: 39\tFidelity = 0.501789\tKL_Divergence = 3.280895\n",
      "Epoch: 40\tFidelity = 0.502242\tKL_Divergence = 3.155664\n",
      "Epoch: 41\tFidelity = 0.501716\tKL_Divergence = 3.304042\n",
      "Epoch: 42\tFidelity = 0.501668\tKL_Divergence = 3.319766\n",
      "Epoch: 43\tFidelity = 0.502134\tKL_Divergence = 3.182965\n",
      "Epoch: 44\tFidelity = 0.501790\tKL_Divergence = 3.280648\n",
      "Epoch: 45\tFidelity = 0.501487\tKL_Divergence = 3.383544\n",
      "Epoch: 46\tFidelity = 0.501572\tKL_Divergence = 3.352733\n",
      "Epoch: 47\tFidelity = 0.501517\tKL_Divergence = 3.372390\n",
      "Epoch: 48\tFidelity = 0.501671\tKL_Divergence = 3.318717\n",
      "Epoch: 49\tFidelity = 0.501463\tKL_Divergence = 3.392507\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:53:18,903] Trial 329 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.501629\tKL_Divergence = 3.332871\n",
      "Total time elapsed during training: 40.431 s\n",
      "Trial 329 pruned. \n",
      "Epoch: 1\tFidelity = 0.502025\tKL_Divergence = 3.212253\n",
      "Epoch: 2\tFidelity = 0.501652\tKL_Divergence = 3.325259\n",
      "Epoch: 3\tFidelity = 0.501910\tKL_Divergence = 3.244539\n",
      "Epoch: 4\tFidelity = 0.501641\tKL_Divergence = 3.328816\n",
      "Epoch: 5\tFidelity = 0.501674\tKL_Divergence = 3.317908\n",
      "Epoch: 6\tFidelity = 0.501509\tKL_Divergence = 3.375333\n",
      "Epoch: 7\tFidelity = 0.501610\tKL_Divergence = 3.339424\n",
      "Epoch: 8\tFidelity = 0.501713\tKL_Divergence = 3.305111\n",
      "Epoch: 9\tFidelity = 0.502249\tKL_Divergence = 3.153933\n",
      "Epoch: 10\tFidelity = 0.501688\tKL_Divergence = 3.313184\n",
      "Epoch: 11\tFidelity = 0.501549\tKL_Divergence = 3.360974\n",
      "Epoch: 12\tFidelity = 0.502265\tKL_Divergence = 3.149875\n",
      "Epoch: 13\tFidelity = 0.501969\tKL_Divergence = 3.227785\n",
      "Epoch: 14\tFidelity = 0.501788\tKL_Divergence = 3.281362\n",
      "Epoch: 15\tFidelity = 0.501661\tKL_Divergence = 3.322067\n",
      "Epoch: 16\tFidelity = 0.501680\tKL_Divergence = 3.315943\n",
      "Epoch: 17\tFidelity = 0.501928\tKL_Divergence = 3.239395\n",
      "Epoch: 18\tFidelity = 0.501740\tKL_Divergence = 3.296383\n",
      "Epoch: 19\tFidelity = 0.501589\tKL_Divergence = 3.346989\n",
      "Epoch: 20\tFidelity = 0.502081\tKL_Divergence = 3.197046\n",
      "Epoch: 21\tFidelity = 0.501788\tKL_Divergence = 3.281355\n",
      "Epoch: 22\tFidelity = 0.501846\tKL_Divergence = 3.263464\n",
      "Epoch: 23\tFidelity = 0.501366\tKL_Divergence = 3.430707\n",
      "Epoch: 24\tFidelity = 0.501494\tKL_Divergence = 3.381052\n",
      "Epoch: 25\tFidelity = 0.501938\tKL_Divergence = 3.236467\n",
      "Epoch: 26\tFidelity = 0.501552\tKL_Divergence = 3.360052\n",
      "Epoch: 27\tFidelity = 0.501899\tKL_Divergence = 3.247839\n",
      "Epoch: 28\tFidelity = 0.501572\tKL_Divergence = 3.352924\n",
      "Epoch: 29\tFidelity = 0.501675\tKL_Divergence = 3.317673\n",
      "Epoch: 30\tFidelity = 0.501548\tKL_Divergence = 3.361484\n",
      "Epoch: 31\tFidelity = 0.501748\tKL_Divergence = 3.293921\n",
      "Epoch: 32\tFidelity = 0.501589\tKL_Divergence = 3.346890\n",
      "Epoch: 33\tFidelity = 0.501825\tKL_Divergence = 3.270041\n",
      "Epoch: 34\tFidelity = 0.502077\tKL_Divergence = 3.197937\n",
      "Epoch: 35\tFidelity = 0.501654\tKL_Divergence = 3.324590\n",
      "Epoch: 36\tFidelity = 0.501696\tKL_Divergence = 3.310643\n",
      "Epoch: 37\tFidelity = 0.501817\tKL_Divergence = 3.272326\n",
      "Epoch: 38\tFidelity = 0.502226\tKL_Divergence = 3.159519\n",
      "Epoch: 39\tFidelity = 0.501748\tKL_Divergence = 3.293857\n",
      "Epoch: 40\tFidelity = 0.501702\tKL_Divergence = 3.308811\n",
      "Epoch: 41\tFidelity = 0.501985\tKL_Divergence = 3.223325\n",
      "Epoch: 42\tFidelity = 0.502127\tKL_Divergence = 3.184981\n",
      "Epoch: 43\tFidelity = 0.502043\tKL_Divergence = 3.207105\n",
      "Epoch: 44\tFidelity = 0.501810\tKL_Divergence = 3.274397\n",
      "Epoch: 45\tFidelity = 0.501949\tKL_Divergence = 3.233243\n",
      "Epoch: 46\tFidelity = 0.502008\tKL_Divergence = 3.216780\n",
      "Epoch: 47\tFidelity = 0.501886\tKL_Divergence = 3.251596\n",
      "Epoch: 48\tFidelity = 0.501673\tKL_Divergence = 3.318382\n",
      "Epoch: 49\tFidelity = 0.502160\tKL_Divergence = 3.176439\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:54:47,947] Trial 330 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.501700\tKL_Divergence = 3.309207\n",
      "Total time elapsed during training: 88.884 s\n",
      "Trial 330 pruned. \n",
      "Epoch: 1\tFidelity = 0.501837\tKL_Divergence = 3.266300\n",
      "Epoch: 2\tFidelity = 0.501605\tKL_Divergence = 3.341391\n",
      "Epoch: 3\tFidelity = 0.502132\tKL_Divergence = 3.183594\n",
      "Epoch: 4\tFidelity = 0.501957\tKL_Divergence = 3.231026\n",
      "Epoch: 5\tFidelity = 0.501744\tKL_Divergence = 3.295012\n",
      "Epoch: 6\tFidelity = 0.501554\tKL_Divergence = 3.359036\n",
      "Epoch: 7\tFidelity = 0.501570\tKL_Divergence = 3.352807\n",
      "Epoch: 8\tFidelity = 0.501509\tKL_Divergence = 3.374753\n",
      "Epoch: 9\tFidelity = 0.501586\tKL_Divergence = 3.347207\n",
      "Epoch: 10\tFidelity = 0.501494\tKL_Divergence = 3.380520\n",
      "Epoch: 11\tFidelity = 0.501731\tKL_Divergence = 3.299144\n",
      "Epoch: 12\tFidelity = 0.501947\tKL_Divergence = 3.233887\n",
      "Epoch: 13\tFidelity = 0.501658\tKL_Divergence = 3.323141\n",
      "Epoch: 14\tFidelity = 0.501890\tKL_Divergence = 3.250545\n",
      "Epoch: 15\tFidelity = 0.501972\tKL_Divergence = 3.227037\n",
      "Epoch: 16\tFidelity = 0.501952\tKL_Divergence = 3.232688\n",
      "Epoch: 17\tFidelity = 0.501318\tKL_Divergence = 3.450788\n",
      "Epoch: 18\tFidelity = 0.501481\tKL_Divergence = 3.386061\n",
      "Epoch: 19\tFidelity = 0.501439\tKL_Divergence = 3.401725\n",
      "Epoch: 20\tFidelity = 0.501431\tKL_Divergence = 3.404958\n",
      "Epoch: 21\tFidelity = 0.501598\tKL_Divergence = 3.343733\n",
      "Epoch: 22\tFidelity = 0.501450\tKL_Divergence = 3.397956\n",
      "Epoch: 23\tFidelity = 0.501972\tKL_Divergence = 3.226994\n",
      "Epoch: 24\tFidelity = 0.501901\tKL_Divergence = 3.247257\n",
      "Epoch: 25\tFidelity = 0.501666\tKL_Divergence = 3.320583\n",
      "Epoch: 26\tFidelity = 0.501649\tKL_Divergence = 3.326053\n",
      "Epoch: 27\tFidelity = 0.502294\tKL_Divergence = 3.142515\n",
      "Epoch: 28\tFidelity = 0.501779\tKL_Divergence = 3.284103\n",
      "Epoch: 29\tFidelity = 0.501692\tKL_Divergence = 3.311942\n",
      "Epoch: 30\tFidelity = 0.501477\tKL_Divergence = 3.387396\n",
      "Epoch: 31\tFidelity = 0.501615\tKL_Divergence = 3.337856\n",
      "Epoch: 32\tFidelity = 0.501729\tKL_Divergence = 3.300067\n",
      "Epoch: 33\tFidelity = 0.501558\tKL_Divergence = 3.357649\n",
      "Epoch: 34\tFidelity = 0.501852\tKL_Divergence = 3.261846\n",
      "Epoch: 35\tFidelity = 0.501713\tKL_Divergence = 3.304213\n",
      "Epoch: 36\tFidelity = 0.501764\tKL_Divergence = 3.287732\n",
      "Epoch: 37\tFidelity = 0.501561\tKL_Divergence = 3.355812\n",
      "Epoch: 38\tFidelity = 0.502101\tKL_Divergence = 3.191000\n",
      "Epoch: 39\tFidelity = 0.501256\tKL_Divergence = 3.477545\n",
      "Epoch: 40\tFidelity = 0.501657\tKL_Divergence = 3.323489\n",
      "Epoch: 41\tFidelity = 0.501422\tKL_Divergence = 3.408785\n",
      "Epoch: 42\tFidelity = 0.501416\tKL_Divergence = 3.411052\n",
      "Epoch: 43\tFidelity = 0.501641\tKL_Divergence = 3.328895\n",
      "Epoch: 44\tFidelity = 0.501778\tKL_Divergence = 3.284476\n",
      "Epoch: 45\tFidelity = 0.501838\tKL_Divergence = 3.265818\n",
      "Epoch: 46\tFidelity = 0.501632\tKL_Divergence = 3.331614\n",
      "Epoch: 47\tFidelity = 0.501268\tKL_Divergence = 3.472027\n",
      "Epoch: 48\tFidelity = 0.501468\tKL_Divergence = 3.390982\n",
      "Epoch: 49\tFidelity = 0.501716\tKL_Divergence = 3.303899\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:55:28,201] Trial 331 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.501836\tKL_Divergence = 3.265703\n",
      "Total time elapsed during training: 40.073 s\n",
      "Trial 331 pruned. \n",
      "Epoch: 1\tFidelity = 0.501592\tKL_Divergence = 3.345272\n",
      "Epoch: 2\tFidelity = 0.501518\tKL_Divergence = 3.371696\n",
      "Epoch: 3\tFidelity = 0.501602\tKL_Divergence = 3.341938\n",
      "Epoch: 4\tFidelity = 0.501729\tKL_Divergence = 3.299704\n",
      "Epoch: 5\tFidelity = 0.501578\tKL_Divergence = 3.350327\n",
      "Epoch: 6\tFidelity = 0.501520\tKL_Divergence = 3.371419\n",
      "Epoch: 7\tFidelity = 0.501511\tKL_Divergence = 3.374775\n",
      "Epoch: 8\tFidelity = 0.501659\tKL_Divergence = 3.322793\n",
      "Epoch: 9\tFidelity = 0.501664\tKL_Divergence = 3.321294\n",
      "Epoch: 10\tFidelity = 0.501723\tKL_Divergence = 3.301750\n",
      "Epoch: 11\tFidelity = 0.501490\tKL_Divergence = 3.382417\n",
      "Epoch: 12\tFidelity = 0.501899\tKL_Divergence = 3.247802\n",
      "Epoch: 13\tFidelity = 0.501445\tKL_Divergence = 3.399563\n",
      "Epoch: 14\tFidelity = 0.501611\tKL_Divergence = 3.339083\n",
      "Epoch: 15\tFidelity = 0.501744\tKL_Divergence = 3.295154\n",
      "Epoch: 16\tFidelity = 0.501490\tKL_Divergence = 3.382670\n",
      "Epoch: 17\tFidelity = 0.501587\tKL_Divergence = 3.347447\n",
      "Epoch: 18\tFidelity = 0.501660\tKL_Divergence = 3.322478\n",
      "Epoch: 19\tFidelity = 0.501549\tKL_Divergence = 3.361142\n",
      "Epoch: 20\tFidelity = 0.501647\tKL_Divergence = 3.327185\n",
      "Epoch: 21\tFidelity = 0.501630\tKL_Divergence = 3.332945\n",
      "Epoch: 22\tFidelity = 0.501757\tKL_Divergence = 3.291222\n",
      "Epoch: 23\tFidelity = 0.501660\tKL_Divergence = 3.322707\n",
      "Epoch: 24\tFidelity = 0.501853\tKL_Divergence = 3.261662\n",
      "Epoch: 25\tFidelity = 0.501647\tKL_Divergence = 3.327072\n",
      "Epoch: 26\tFidelity = 0.501878\tKL_Divergence = 3.254131\n",
      "Epoch: 27\tFidelity = 0.501474\tKL_Divergence = 3.388599\n",
      "Epoch: 28\tFidelity = 0.501612\tKL_Divergence = 3.339151\n",
      "Epoch: 29\tFidelity = 0.501860\tKL_Divergence = 3.259408\n",
      "Epoch: 30\tFidelity = 0.501429\tKL_Divergence = 3.405778\n",
      "Epoch: 31\tFidelity = 0.501587\tKL_Divergence = 3.347612\n",
      "Epoch: 32\tFidelity = 0.501643\tKL_Divergence = 3.328529\n",
      "Epoch: 33\tFidelity = 0.501646\tKL_Divergence = 3.327359\n",
      "Epoch: 34\tFidelity = 0.501433\tKL_Divergence = 3.404220\n",
      "Epoch: 35\tFidelity = 0.501490\tKL_Divergence = 3.382562\n",
      "Epoch: 36\tFidelity = 0.501678\tKL_Divergence = 3.316833\n",
      "Epoch: 37\tFidelity = 0.501748\tKL_Divergence = 3.293859\n",
      "Epoch: 38\tFidelity = 0.501381\tKL_Divergence = 3.424717\n",
      "Epoch: 39\tFidelity = 0.501742\tKL_Divergence = 3.296013\n",
      "Epoch: 40\tFidelity = 0.501677\tKL_Divergence = 3.317090\n",
      "Epoch: 41\tFidelity = 0.501493\tKL_Divergence = 3.381462\n",
      "Epoch: 42\tFidelity = 0.501669\tKL_Divergence = 3.319711\n",
      "Epoch: 43\tFidelity = 0.501589\tKL_Divergence = 3.347024\n",
      "Epoch: 44\tFidelity = 0.501726\tKL_Divergence = 3.301206\n",
      "Epoch: 45\tFidelity = 0.501445\tKL_Divergence = 3.399646\n",
      "Epoch: 46\tFidelity = 0.501621\tKL_Divergence = 3.336068\n",
      "Epoch: 47\tFidelity = 0.501719\tKL_Divergence = 3.303266\n",
      "Epoch: 48\tFidelity = 0.501623\tKL_Divergence = 3.335203\n",
      "Epoch: 49\tFidelity = 0.501564\tKL_Divergence = 3.355967\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:56:15,353] Trial 332 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.501516\tKL_Divergence = 3.373300\n",
      "Total time elapsed during training: 46.990 s\n",
      "Trial 332 pruned. \n",
      "Epoch: 1\tFidelity = 0.501575\tKL_Divergence = 3.351947\n",
      "Epoch: 2\tFidelity = 0.501435\tKL_Divergence = 3.403445\n",
      "Epoch: 3\tFidelity = 0.501648\tKL_Divergence = 3.326684\n",
      "Epoch: 4\tFidelity = 0.501454\tKL_Divergence = 3.396462\n",
      "Epoch: 5\tFidelity = 0.501599\tKL_Divergence = 3.343585\n",
      "Epoch: 6\tFidelity = 0.501546\tKL_Divergence = 3.362267\n",
      "Epoch: 7\tFidelity = 0.501823\tKL_Divergence = 3.270499\n",
      "Epoch: 8\tFidelity = 0.501490\tKL_Divergence = 3.382775\n",
      "Epoch: 9\tFidelity = 0.501703\tKL_Divergence = 3.308593\n",
      "Epoch: 10\tFidelity = 0.501717\tKL_Divergence = 3.303771\n",
      "Epoch: 11\tFidelity = 0.501739\tKL_Divergence = 3.296910\n",
      "Epoch: 12\tFidelity = 0.501671\tKL_Divergence = 3.318954\n",
      "Epoch: 13\tFidelity = 0.501591\tKL_Divergence = 3.346344\n",
      "Epoch: 14\tFidelity = 0.501503\tKL_Divergence = 3.377794\n",
      "Epoch: 15\tFidelity = 0.501578\tKL_Divergence = 3.350624\n",
      "Epoch: 16\tFidelity = 0.501692\tKL_Divergence = 3.312080\n",
      "Epoch: 17\tFidelity = 0.501337\tKL_Divergence = 3.442851\n",
      "Epoch: 18\tFidelity = 0.501448\tKL_Divergence = 3.398648\n",
      "Epoch: 19\tFidelity = 0.501612\tKL_Divergence = 3.339006\n",
      "Epoch: 20\tFidelity = 0.501504\tKL_Divergence = 3.377347\n",
      "Epoch: 21\tFidelity = 0.501740\tKL_Divergence = 3.296506\n",
      "Epoch: 22\tFidelity = 0.501771\tKL_Divergence = 3.286642\n",
      "Epoch: 23\tFidelity = 0.501551\tKL_Divergence = 3.360148\n",
      "Epoch: 24\tFidelity = 0.501793\tKL_Divergence = 3.279743\n",
      "Epoch: 25\tFidelity = 0.501405\tKL_Divergence = 3.415273\n",
      "Epoch: 26\tFidelity = 0.501575\tKL_Divergence = 3.351768\n",
      "Epoch: 27\tFidelity = 0.501599\tKL_Divergence = 3.343427\n",
      "Epoch: 28\tFidelity = 0.501754\tKL_Divergence = 3.292209\n",
      "Epoch: 29\tFidelity = 0.501757\tKL_Divergence = 3.291267\n",
      "Epoch: 30\tFidelity = 0.501492\tKL_Divergence = 3.381901\n",
      "Epoch: 31\tFidelity = 0.501674\tKL_Divergence = 3.318091\n",
      "Epoch: 32\tFidelity = 0.501517\tKL_Divergence = 3.372768\n",
      "Epoch: 33\tFidelity = 0.501701\tKL_Divergence = 3.309246\n",
      "Epoch: 34\tFidelity = 0.501632\tKL_Divergence = 3.332259\n",
      "Epoch: 35\tFidelity = 0.501425\tKL_Divergence = 3.407383\n",
      "Epoch: 36\tFidelity = 0.501690\tKL_Divergence = 3.312700\n",
      "Epoch: 37\tFidelity = 0.501711\tKL_Divergence = 3.305833\n",
      "Epoch: 38\tFidelity = 0.501409\tKL_Divergence = 3.413497\n",
      "Epoch: 39\tFidelity = 0.501877\tKL_Divergence = 3.254392\n",
      "Epoch: 40\tFidelity = 0.501429\tKL_Divergence = 3.405937\n",
      "Epoch: 41\tFidelity = 0.501743\tKL_Divergence = 3.295542\n",
      "Epoch: 42\tFidelity = 0.501890\tKL_Divergence = 3.250670\n",
      "Epoch: 43\tFidelity = 0.501465\tKL_Divergence = 3.392068\n",
      "Epoch: 44\tFidelity = 0.501358\tKL_Divergence = 3.433970\n",
      "Epoch: 45\tFidelity = 0.501718\tKL_Divergence = 3.303548\n",
      "Epoch: 46\tFidelity = 0.501758\tKL_Divergence = 3.290968\n",
      "Epoch: 47\tFidelity = 0.501620\tKL_Divergence = 3.336349\n",
      "Epoch: 48\tFidelity = 0.501408\tKL_Divergence = 3.414022\n",
      "Epoch: 49\tFidelity = 0.501415\tKL_Divergence = 3.411458\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:57:13,384] Trial 333 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.501487\tKL_Divergence = 3.383953\n",
      "Total time elapsed during training: 57.866 s\n",
      "Trial 333 pruned. \n",
      "Epoch: 1\tFidelity = 0.501359\tKL_Divergence = 3.433877\n",
      "Epoch: 2\tFidelity = 0.501623\tKL_Divergence = 3.335180\n",
      "Epoch: 3\tFidelity = 0.501696\tKL_Divergence = 3.310671\n",
      "Epoch: 4\tFidelity = 0.501476\tKL_Divergence = 3.387722\n",
      "Epoch: 5\tFidelity = 0.501789\tKL_Divergence = 3.280974\n",
      "Epoch: 6\tFidelity = 0.501776\tKL_Divergence = 3.285129\n",
      "Epoch: 7\tFidelity = 0.501725\tKL_Divergence = 3.301427\n",
      "Epoch: 8\tFidelity = 0.501542\tKL_Divergence = 3.363664\n",
      "Epoch: 9\tFidelity = 0.501425\tKL_Divergence = 3.407427\n",
      "Epoch: 10\tFidelity = 0.501383\tKL_Divergence = 3.423870\n",
      "Epoch: 11\tFidelity = 0.501125\tKL_Divergence = 3.538901\n",
      "Epoch: 12\tFidelity = 0.501459\tKL_Divergence = 3.394406\n",
      "Epoch: 13\tFidelity = 0.501825\tKL_Divergence = 3.270156\n",
      "Epoch: 14\tFidelity = 0.501178\tKL_Divergence = 3.513354\n",
      "Epoch: 15\tFidelity = 0.501382\tKL_Divergence = 3.424549\n",
      "Epoch: 16\tFidelity = 0.501571\tKL_Divergence = 3.353404\n",
      "Epoch: 17\tFidelity = 0.501591\tKL_Divergence = 3.346490\n",
      "Epoch: 18\tFidelity = 0.501402\tKL_Divergence = 3.416537\n",
      "Epoch: 19\tFidelity = 0.501476\tKL_Divergence = 3.388155\n",
      "Epoch: 20\tFidelity = 0.501431\tKL_Divergence = 3.405076\n",
      "Epoch: 21\tFidelity = 0.501432\tKL_Divergence = 3.404821\n",
      "Epoch: 22\tFidelity = 0.501707\tKL_Divergence = 3.307179\n",
      "Epoch: 23\tFidelity = 0.501580\tKL_Divergence = 3.350080\n",
      "Epoch: 24\tFidelity = 0.501710\tKL_Divergence = 3.306160\n",
      "Epoch: 25\tFidelity = 0.501323\tKL_Divergence = 3.448829\n",
      "Epoch: 26\tFidelity = 0.501393\tKL_Divergence = 3.420376\n",
      "Epoch: 27\tFidelity = 0.501770\tKL_Divergence = 3.287270\n",
      "Epoch: 28\tFidelity = 0.501489\tKL_Divergence = 3.383088\n",
      "Epoch: 29\tFidelity = 0.501638\tKL_Divergence = 3.330311\n",
      "Epoch: 30\tFidelity = 0.501440\tKL_Divergence = 3.401753\n",
      "Epoch: 31\tFidelity = 0.501605\tKL_Divergence = 3.341214\n",
      "Epoch: 32\tFidelity = 0.501594\tKL_Divergence = 3.345303\n",
      "Epoch: 33\tFidelity = 0.501572\tKL_Divergence = 3.353039\n",
      "Epoch: 34\tFidelity = 0.501296\tKL_Divergence = 3.460205\n",
      "Epoch: 35\tFidelity = 0.501296\tKL_Divergence = 3.460271\n",
      "Epoch: 36\tFidelity = 0.501245\tKL_Divergence = 3.482243\n",
      "Epoch: 37\tFidelity = 0.501315\tKL_Divergence = 3.451954\n",
      "Epoch: 38\tFidelity = 0.501233\tKL_Divergence = 3.488147\n",
      "Epoch: 39\tFidelity = 0.501476\tKL_Divergence = 3.387880\n",
      "Epoch: 40\tFidelity = 0.501316\tKL_Divergence = 3.451730\n",
      "Epoch: 41\tFidelity = 0.501398\tKL_Divergence = 3.418214\n",
      "Epoch: 42\tFidelity = 0.501505\tKL_Divergence = 3.377185\n",
      "Epoch: 43\tFidelity = 0.501657\tKL_Divergence = 3.323811\n",
      "Epoch: 44\tFidelity = 0.501656\tKL_Divergence = 3.323993\n",
      "Epoch: 45\tFidelity = 0.501562\tKL_Divergence = 3.356575\n",
      "Epoch: 46\tFidelity = 0.501397\tKL_Divergence = 3.418888\n",
      "Epoch: 47\tFidelity = 0.501500\tKL_Divergence = 3.379466\n",
      "Epoch: 48\tFidelity = 0.501573\tKL_Divergence = 3.352749\n",
      "Epoch: 49\tFidelity = 0.501356\tKL_Divergence = 3.435119\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:57:51,967] Trial 334 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500991\tKL_Divergence = 3.609108\n",
      "Total time elapsed during training: 38.412 s\n",
      "Trial 334 pruned. \n",
      "Epoch: 1\tFidelity = 0.501219\tKL_Divergence = 3.494422\n",
      "Epoch: 2\tFidelity = 0.501170\tKL_Divergence = 3.517242\n",
      "Epoch: 3\tFidelity = 0.501297\tKL_Divergence = 3.460109\n",
      "Epoch: 4\tFidelity = 0.501350\tKL_Divergence = 3.437574\n",
      "Epoch: 5\tFidelity = 0.501447\tKL_Divergence = 3.399289\n",
      "Epoch: 6\tFidelity = 0.501325\tKL_Divergence = 3.447940\n",
      "Epoch: 7\tFidelity = 0.501400\tKL_Divergence = 3.417645\n",
      "Epoch: 8\tFidelity = 0.501458\tKL_Divergence = 3.394735\n",
      "Epoch: 9\tFidelity = 0.501315\tKL_Divergence = 3.452401\n",
      "Epoch: 10\tFidelity = 0.501269\tKL_Divergence = 3.471918\n",
      "Epoch: 11\tFidelity = 0.501488\tKL_Divergence = 3.383444\n",
      "Epoch: 12\tFidelity = 0.501408\tKL_Divergence = 3.414365\n",
      "Epoch: 13\tFidelity = 0.501125\tKL_Divergence = 3.538772\n",
      "Epoch: 14\tFidelity = 0.501776\tKL_Divergence = 3.285213\n",
      "Epoch: 15\tFidelity = 0.501210\tKL_Divergence = 3.498261\n",
      "Epoch: 16\tFidelity = 0.501249\tKL_Divergence = 3.480907\n",
      "Epoch: 17\tFidelity = 0.501202\tKL_Divergence = 3.501935\n",
      "Epoch: 18\tFidelity = 0.501178\tKL_Divergence = 3.513101\n",
      "Epoch: 19\tFidelity = 0.501546\tKL_Divergence = 3.362296\n",
      "Epoch: 20\tFidelity = 0.501250\tKL_Divergence = 3.480460\n",
      "Epoch: 21\tFidelity = 0.501374\tKL_Divergence = 3.427865\n",
      "Epoch: 22\tFidelity = 0.501286\tKL_Divergence = 3.464578\n",
      "Epoch: 23\tFidelity = 0.501333\tKL_Divergence = 3.444771\n",
      "Epoch: 24\tFidelity = 0.501439\tKL_Divergence = 3.402201\n",
      "Epoch: 25\tFidelity = 0.501160\tKL_Divergence = 3.521908\n",
      "Epoch: 26\tFidelity = 0.501227\tKL_Divergence = 3.490492\n",
      "Epoch: 27\tFidelity = 0.501335\tKL_Divergence = 3.443999\n",
      "Epoch: 28\tFidelity = 0.501137\tKL_Divergence = 3.532761\n",
      "Epoch: 29\tFidelity = 0.501529\tKL_Divergence = 3.368442\n",
      "Epoch: 30\tFidelity = 0.501081\tKL_Divergence = 3.560819\n",
      "Epoch: 31\tFidelity = 0.501442\tKL_Divergence = 3.401164\n",
      "Epoch: 32\tFidelity = 0.501406\tKL_Divergence = 3.415043\n",
      "Epoch: 33\tFidelity = 0.501499\tKL_Divergence = 3.379529\n",
      "Epoch: 34\tFidelity = 0.501526\tKL_Divergence = 3.369667\n",
      "Epoch: 35\tFidelity = 0.501427\tKL_Divergence = 3.406697\n",
      "Epoch: 36\tFidelity = 0.501453\tKL_Divergence = 3.396669\n",
      "Epoch: 37\tFidelity = 0.501722\tKL_Divergence = 3.302502\n",
      "Epoch: 38\tFidelity = 0.501296\tKL_Divergence = 3.460255\n",
      "Epoch: 39\tFidelity = 0.501418\tKL_Divergence = 3.410431\n",
      "Epoch: 40\tFidelity = 0.501222\tKL_Divergence = 3.492760\n",
      "Epoch: 41\tFidelity = 0.501473\tKL_Divergence = 3.389369\n",
      "Epoch: 42\tFidelity = 0.501382\tKL_Divergence = 3.424472\n",
      "Epoch: 43\tFidelity = 0.501552\tKL_Divergence = 3.360152\n",
      "Epoch: 44\tFidelity = 0.501547\tKL_Divergence = 3.362062\n",
      "Epoch: 45\tFidelity = 0.501531\tKL_Divergence = 3.367642\n",
      "Epoch: 46\tFidelity = 0.501418\tKL_Divergence = 3.410182\n",
      "Epoch: 47\tFidelity = 0.501229\tKL_Divergence = 3.489642\n",
      "Epoch: 48\tFidelity = 0.501139\tKL_Divergence = 3.532030\n",
      "Epoch: 49\tFidelity = 0.501430\tKL_Divergence = 3.405564\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:59:12,563] Trial 335 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.501199\tKL_Divergence = 3.503630\n",
      "Total time elapsed during training: 80.428 s\n",
      "Trial 335 pruned. \n",
      "Epoch: 1\tFidelity = 0.501502\tKL_Divergence = 3.378511\n",
      "Epoch: 2\tFidelity = 0.501255\tKL_Divergence = 3.477913\n",
      "Epoch: 3\tFidelity = 0.501333\tKL_Divergence = 3.444574\n",
      "Epoch: 4\tFidelity = 0.501260\tKL_Divergence = 3.475915\n",
      "Epoch: 5\tFidelity = 0.501252\tKL_Divergence = 3.479577\n",
      "Epoch: 6\tFidelity = 0.501519\tKL_Divergence = 3.372020\n",
      "Epoch: 7\tFidelity = 0.501206\tKL_Divergence = 3.500391\n",
      "Epoch: 8\tFidelity = 0.501645\tKL_Divergence = 3.327941\n",
      "Epoch: 9\tFidelity = 0.501170\tKL_Divergence = 3.517087\n",
      "Epoch: 10\tFidelity = 0.501455\tKL_Divergence = 3.396040\n",
      "Epoch: 11\tFidelity = 0.501285\tKL_Divergence = 3.464799\n",
      "Epoch: 12\tFidelity = 0.501545\tKL_Divergence = 3.362547\n",
      "Epoch: 13\tFidelity = 0.501307\tKL_Divergence = 3.455586\n",
      "Epoch: 14\tFidelity = 0.501385\tKL_Divergence = 3.423545\n",
      "Epoch: 15\tFidelity = 0.501335\tKL_Divergence = 3.443644\n",
      "Epoch: 16\tFidelity = 0.501508\tKL_Divergence = 3.376276\n",
      "Epoch: 17\tFidelity = 0.501304\tKL_Divergence = 3.456952\n",
      "Epoch: 18\tFidelity = 0.501521\tKL_Divergence = 3.371371\n",
      "Epoch: 19\tFidelity = 0.501422\tKL_Divergence = 3.408849\n",
      "Epoch: 20\tFidelity = 0.501342\tKL_Divergence = 3.441015\n",
      "Epoch: 21\tFidelity = 0.501726\tKL_Divergence = 3.301053\n",
      "Epoch: 22\tFidelity = 0.501233\tKL_Divergence = 3.487748\n",
      "Epoch: 23\tFidelity = 0.501637\tKL_Divergence = 3.330468\n",
      "Epoch: 24\tFidelity = 0.501280\tKL_Divergence = 3.467123\n",
      "Epoch: 25\tFidelity = 0.501599\tKL_Divergence = 3.343447\n",
      "Epoch: 26\tFidelity = 0.501219\tKL_Divergence = 3.494342\n",
      "Epoch: 27\tFidelity = 0.501576\tKL_Divergence = 3.351431\n",
      "Epoch: 28\tFidelity = 0.501431\tKL_Divergence = 3.405128\n",
      "Epoch: 29\tFidelity = 0.501275\tKL_Divergence = 3.469279\n",
      "Epoch: 30\tFidelity = 0.501450\tKL_Divergence = 3.397660\n",
      "Epoch: 31\tFidelity = 0.501477\tKL_Divergence = 3.387658\n",
      "Epoch: 32\tFidelity = 0.501480\tKL_Divergence = 3.386511\n",
      "Epoch: 33\tFidelity = 0.501447\tKL_Divergence = 3.398956\n",
      "Epoch: 34\tFidelity = 0.501460\tKL_Divergence = 3.394201\n",
      "Epoch: 35\tFidelity = 0.501217\tKL_Divergence = 3.495226\n",
      "Epoch: 36\tFidelity = 0.501474\tKL_Divergence = 3.388809\n",
      "Epoch: 37\tFidelity = 0.501173\tKL_Divergence = 3.515527\n",
      "Epoch: 38\tFidelity = 0.501688\tKL_Divergence = 3.313588\n",
      "Epoch: 39\tFidelity = 0.501208\tKL_Divergence = 3.499389\n",
      "Epoch: 40\tFidelity = 0.501426\tKL_Divergence = 3.406961\n",
      "Epoch: 41\tFidelity = 0.501369\tKL_Divergence = 3.429859\n",
      "Epoch: 42\tFidelity = 0.501302\tKL_Divergence = 3.457644\n",
      "Epoch: 43\tFidelity = 0.501447\tKL_Divergence = 3.399029\n",
      "Epoch: 44\tFidelity = 0.501393\tKL_Divergence = 3.420121\n",
      "Epoch: 45\tFidelity = 0.501455\tKL_Divergence = 3.395795\n",
      "Epoch: 46\tFidelity = 0.501467\tKL_Divergence = 3.391416\n",
      "Epoch: 47\tFidelity = 0.501331\tKL_Divergence = 3.445412\n",
      "Epoch: 48\tFidelity = 0.501563\tKL_Divergence = 3.356180\n",
      "Epoch: 49\tFidelity = 0.501362\tKL_Divergence = 3.432473\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 07:59:44,314] Trial 336 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.501272\tKL_Divergence = 3.470687\n",
      "Total time elapsed during training: 31.518 s\n",
      "Trial 336 pruned. \n",
      "Epoch: 1\tFidelity = 0.501312\tKL_Divergence = 3.453438\n",
      "Epoch: 2\tFidelity = 0.501187\tKL_Divergence = 3.509226\n",
      "Epoch: 3\tFidelity = 0.501165\tKL_Divergence = 3.519377\n",
      "Epoch: 4\tFidelity = 0.501200\tKL_Divergence = 3.502939\n",
      "Epoch: 5\tFidelity = 0.501290\tKL_Divergence = 3.462822\n",
      "Epoch: 6\tFidelity = 0.501464\tKL_Divergence = 3.392603\n",
      "Epoch: 7\tFidelity = 0.501240\tKL_Divergence = 3.484595\n",
      "Epoch: 8\tFidelity = 0.501222\tKL_Divergence = 3.492844\n",
      "Epoch: 9\tFidelity = 0.501333\tKL_Divergence = 3.444491\n",
      "Epoch: 10\tFidelity = 0.501261\tKL_Divergence = 3.475632\n",
      "Epoch: 11\tFidelity = 0.501257\tKL_Divergence = 3.477234\n",
      "Epoch: 12\tFidelity = 0.501227\tKL_Divergence = 3.490440\n",
      "Epoch: 13\tFidelity = 0.501354\tKL_Divergence = 3.435799\n",
      "Epoch: 14\tFidelity = 0.501227\tKL_Divergence = 3.490642\n",
      "Epoch: 15\tFidelity = 0.501194\tKL_Divergence = 3.505892\n",
      "Epoch: 16\tFidelity = 0.501120\tKL_Divergence = 3.541342\n",
      "Epoch: 17\tFidelity = 0.501196\tKL_Divergence = 3.504964\n",
      "Epoch: 18\tFidelity = 0.501317\tKL_Divergence = 3.451227\n",
      "Epoch: 19\tFidelity = 0.501405\tKL_Divergence = 3.415499\n",
      "Epoch: 20\tFidelity = 0.501142\tKL_Divergence = 3.530664\n",
      "Epoch: 21\tFidelity = 0.501592\tKL_Divergence = 3.345925\n",
      "Epoch: 22\tFidelity = 0.501554\tKL_Divergence = 3.359327\n",
      "Epoch: 23\tFidelity = 0.501493\tKL_Divergence = 3.381656\n",
      "Epoch: 24\tFidelity = 0.501340\tKL_Divergence = 3.441821\n",
      "Epoch: 25\tFidelity = 0.501317\tKL_Divergence = 3.451488\n",
      "Epoch: 26\tFidelity = 0.501600\tKL_Divergence = 3.343235\n",
      "Epoch: 27\tFidelity = 0.501295\tKL_Divergence = 3.460632\n",
      "Epoch: 28\tFidelity = 0.501203\tKL_Divergence = 3.501745\n",
      "Epoch: 29\tFidelity = 0.501524\tKL_Divergence = 3.370356\n",
      "Epoch: 30\tFidelity = 0.501561\tKL_Divergence = 3.356842\n",
      "Epoch: 31\tFidelity = 0.501680\tKL_Divergence = 3.316207\n",
      "Epoch: 32\tFidelity = 0.501391\tKL_Divergence = 3.421069\n",
      "Epoch: 33\tFidelity = 0.501365\tKL_Divergence = 3.431491\n",
      "Epoch: 34\tFidelity = 0.501533\tKL_Divergence = 3.366858\n",
      "Epoch: 35\tFidelity = 0.501535\tKL_Divergence = 3.366236\n",
      "Epoch: 36\tFidelity = 0.501661\tKL_Divergence = 3.322365\n",
      "Epoch: 37\tFidelity = 0.501422\tKL_Divergence = 3.408619\n",
      "Epoch: 38\tFidelity = 0.501290\tKL_Divergence = 3.463035\n",
      "Epoch: 39\tFidelity = 0.501333\tKL_Divergence = 3.444516\n",
      "Epoch: 40\tFidelity = 0.501204\tKL_Divergence = 3.500942\n",
      "Epoch: 41\tFidelity = 0.501201\tKL_Divergence = 3.502428\n",
      "Epoch: 42\tFidelity = 0.501378\tKL_Divergence = 3.426116\n",
      "Epoch: 43\tFidelity = 0.501489\tKL_Divergence = 3.383188\n",
      "Epoch: 44\tFidelity = 0.501484\tKL_Divergence = 3.385070\n",
      "Epoch: 45\tFidelity = 0.501607\tKL_Divergence = 3.340727\n",
      "Epoch: 46\tFidelity = 0.501529\tKL_Divergence = 3.368379\n",
      "Epoch: 47\tFidelity = 0.501448\tKL_Divergence = 3.398635\n",
      "Epoch: 48\tFidelity = 0.501384\tKL_Divergence = 3.423861\n",
      "Epoch: 49\tFidelity = 0.501180\tKL_Divergence = 3.512303\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:00:22,301] Trial 337 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.501175\tKL_Divergence = 3.514761\n",
      "Total time elapsed during training: 37.823 s\n",
      "Trial 337 pruned. \n",
      "Epoch: 1\tFidelity = 0.501378\tKL_Divergence = 3.426086\n",
      "Epoch: 2\tFidelity = 0.501372\tKL_Divergence = 3.428800\n",
      "Epoch: 3\tFidelity = 0.501236\tKL_Divergence = 3.486482\n",
      "Epoch: 4\tFidelity = 0.501352\tKL_Divergence = 3.436669\n",
      "Epoch: 5\tFidelity = 0.501438\tKL_Divergence = 3.402414\n",
      "Epoch: 6\tFidelity = 0.501213\tKL_Divergence = 3.497158\n",
      "Epoch: 7\tFidelity = 0.501514\tKL_Divergence = 3.373868\n",
      "Epoch: 8\tFidelity = 0.501166\tKL_Divergence = 3.518856\n",
      "Epoch: 9\tFidelity = 0.501382\tKL_Divergence = 3.424475\n",
      "Epoch: 10\tFidelity = 0.501403\tKL_Divergence = 3.416050\n",
      "Epoch: 11\tFidelity = 0.501234\tKL_Divergence = 3.487731\n",
      "Epoch: 12\tFidelity = 0.501311\tKL_Divergence = 3.454050\n",
      "Epoch: 13\tFidelity = 0.501361\tKL_Divergence = 3.433331\n",
      "Epoch: 14\tFidelity = 0.501321\tKL_Divergence = 3.449513\n",
      "Epoch: 15\tFidelity = 0.501424\tKL_Divergence = 3.407999\n",
      "Epoch: 16\tFidelity = 0.501336\tKL_Divergence = 3.443461\n",
      "Epoch: 17\tFidelity = 0.501433\tKL_Divergence = 3.404571\n",
      "Epoch: 18\tFidelity = 0.501258\tKL_Divergence = 3.476668\n",
      "Epoch: 19\tFidelity = 0.501371\tKL_Divergence = 3.428865\n",
      "Epoch: 20\tFidelity = 0.501174\tKL_Divergence = 3.515230\n",
      "Epoch: 21\tFidelity = 0.501332\tKL_Divergence = 3.445124\n",
      "Epoch: 22\tFidelity = 0.501383\tKL_Divergence = 3.424094\n",
      "Epoch: 23\tFidelity = 0.501310\tKL_Divergence = 3.454202\n",
      "Epoch: 24\tFidelity = 0.501402\tKL_Divergence = 3.416714\n",
      "Epoch: 25\tFidelity = 0.501313\tKL_Divergence = 3.453267\n",
      "Epoch: 26\tFidelity = 0.501474\tKL_Divergence = 3.388835\n",
      "Epoch: 27\tFidelity = 0.501276\tKL_Divergence = 3.468972\n",
      "Epoch: 28\tFidelity = 0.501202\tKL_Divergence = 3.502187\n",
      "Epoch: 29\tFidelity = 0.501436\tKL_Divergence = 3.403321\n",
      "Epoch: 30\tFidelity = 0.501163\tKL_Divergence = 3.520586\n",
      "Epoch: 31\tFidelity = 0.501377\tKL_Divergence = 3.426618\n",
      "Epoch: 32\tFidelity = 0.501253\tKL_Divergence = 3.479229\n",
      "Epoch: 33\tFidelity = 0.501333\tKL_Divergence = 3.444895\n",
      "Epoch: 34\tFidelity = 0.501201\tKL_Divergence = 3.502825\n",
      "Epoch: 35\tFidelity = 0.501462\tKL_Divergence = 3.393430\n",
      "Epoch: 36\tFidelity = 0.501345\tKL_Divergence = 3.439916\n",
      "Epoch: 37\tFidelity = 0.501181\tKL_Divergence = 3.512024\n",
      "Epoch: 38\tFidelity = 0.501423\tKL_Divergence = 3.408414\n",
      "Epoch: 39\tFidelity = 0.501326\tKL_Divergence = 3.447796\n",
      "Epoch: 40\tFidelity = 0.501254\tKL_Divergence = 3.478634\n",
      "Epoch: 41\tFidelity = 0.501387\tKL_Divergence = 3.422603\n",
      "Epoch: 42\tFidelity = 0.501313\tKL_Divergence = 3.452949\n",
      "Epoch: 43\tFidelity = 0.501388\tKL_Divergence = 3.422443\n",
      "Epoch: 44\tFidelity = 0.501175\tKL_Divergence = 3.514783\n",
      "Epoch: 45\tFidelity = 0.501446\tKL_Divergence = 3.399405\n",
      "Epoch: 46\tFidelity = 0.501249\tKL_Divergence = 3.480741\n",
      "Epoch: 47\tFidelity = 0.501273\tKL_Divergence = 3.470222\n",
      "Epoch: 48\tFidelity = 0.501336\tKL_Divergence = 3.443363\n",
      "Epoch: 49\tFidelity = 0.501334\tKL_Divergence = 3.444457\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:00:53,907] Trial 338 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.501228\tKL_Divergence = 3.490465\n",
      "Total time elapsed during training: 31.438 s\n",
      "Trial 338 pruned. \n",
      "Epoch: 1\tFidelity = 0.501269\tKL_Divergence = 3.471995\n",
      "Epoch: 2\tFidelity = 0.501460\tKL_Divergence = 3.393976\n",
      "Epoch: 3\tFidelity = 0.501422\tKL_Divergence = 3.408905\n",
      "Epoch: 4\tFidelity = 0.501441\tKL_Divergence = 3.401244\n",
      "Epoch: 5\tFidelity = 0.501104\tKL_Divergence = 3.549443\n",
      "Epoch: 6\tFidelity = 0.501117\tKL_Divergence = 3.542761\n",
      "Epoch: 7\tFidelity = 0.501207\tKL_Divergence = 3.499948\n",
      "Epoch: 8\tFidelity = 0.501269\tKL_Divergence = 3.472144\n",
      "Epoch: 9\tFidelity = 0.501298\tKL_Divergence = 3.459653\n",
      "Epoch: 10\tFidelity = 0.501302\tKL_Divergence = 3.457633\n",
      "Epoch: 11\tFidelity = 0.501414\tKL_Divergence = 3.411864\n",
      "Epoch: 12\tFidelity = 0.501407\tKL_Divergence = 3.414578\n",
      "Epoch: 13\tFidelity = 0.501337\tKL_Divergence = 3.442881\n",
      "Epoch: 14\tFidelity = 0.501568\tKL_Divergence = 3.354692\n",
      "Epoch: 15\tFidelity = 0.501196\tKL_Divergence = 3.504935\n",
      "Epoch: 16\tFidelity = 0.501341\tKL_Divergence = 3.441446\n",
      "Epoch: 17\tFidelity = 0.501379\tKL_Divergence = 3.425957\n",
      "Epoch: 18\tFidelity = 0.501385\tKL_Divergence = 3.423427\n",
      "Epoch: 19\tFidelity = 0.501447\tKL_Divergence = 3.399043\n",
      "Epoch: 20\tFidelity = 0.501448\tKL_Divergence = 3.398651\n",
      "Epoch: 21\tFidelity = 0.501253\tKL_Divergence = 3.479339\n",
      "Epoch: 22\tFidelity = 0.501174\tKL_Divergence = 3.515331\n",
      "Epoch: 23\tFidelity = 0.501178\tKL_Divergence = 3.513367\n",
      "Epoch: 24\tFidelity = 0.501232\tKL_Divergence = 3.488346\n",
      "Epoch: 25\tFidelity = 0.501289\tKL_Divergence = 3.463371\n",
      "Epoch: 26\tFidelity = 0.501449\tKL_Divergence = 3.398362\n",
      "Epoch: 27\tFidelity = 0.501375\tKL_Divergence = 3.427485\n",
      "Epoch: 28\tFidelity = 0.501504\tKL_Divergence = 3.377712\n",
      "Epoch: 29\tFidelity = 0.501394\tKL_Divergence = 3.419920\n",
      "Epoch: 30\tFidelity = 0.501295\tKL_Divergence = 3.460772\n",
      "Epoch: 31\tFidelity = 0.501385\tKL_Divergence = 3.423523\n",
      "Epoch: 32\tFidelity = 0.501200\tKL_Divergence = 3.503163\n",
      "Epoch: 33\tFidelity = 0.501197\tKL_Divergence = 3.504376\n",
      "Epoch: 34\tFidelity = 0.501424\tKL_Divergence = 3.408156\n",
      "Epoch: 35\tFidelity = 0.501277\tKL_Divergence = 3.468383\n",
      "Epoch: 36\tFidelity = 0.501416\tKL_Divergence = 3.411206\n",
      "Epoch: 37\tFidelity = 0.501319\tKL_Divergence = 3.450642\n",
      "Epoch: 38\tFidelity = 0.501268\tKL_Divergence = 3.472506\n",
      "Epoch: 39\tFidelity = 0.501326\tKL_Divergence = 3.447530\n",
      "Epoch: 40\tFidelity = 0.501459\tKL_Divergence = 3.394578\n",
      "Epoch: 41\tFidelity = 0.501203\tKL_Divergence = 3.501723\n",
      "Epoch: 42\tFidelity = 0.501254\tKL_Divergence = 3.478617\n",
      "Epoch: 43\tFidelity = 0.501280\tKL_Divergence = 3.467100\n",
      "Epoch: 44\tFidelity = 0.501384\tKL_Divergence = 3.423833\n",
      "Epoch: 45\tFidelity = 0.501364\tKL_Divergence = 3.431893\n",
      "Epoch: 46\tFidelity = 0.501411\tKL_Divergence = 3.413233\n",
      "Epoch: 47\tFidelity = 0.501292\tKL_Divergence = 3.462278\n",
      "Epoch: 48\tFidelity = 0.501144\tKL_Divergence = 3.529797\n",
      "Epoch: 49\tFidelity = 0.501208\tKL_Divergence = 3.499285\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:01:31,552] Trial 339 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.501355\tKL_Divergence = 3.435858\n",
      "Total time elapsed during training: 37.482 s\n",
      "Trial 339 pruned. \n",
      "Epoch: 1\tFidelity = 0.501224\tKL_Divergence = 3.492028\n",
      "Epoch: 2\tFidelity = 0.501059\tKL_Divergence = 3.572396\n",
      "Epoch: 3\tFidelity = 0.501766\tKL_Divergence = 3.288511\n",
      "Epoch: 4\tFidelity = 0.501743\tKL_Divergence = 3.295402\n",
      "Epoch: 5\tFidelity = 0.501165\tKL_Divergence = 3.519869\n",
      "Epoch: 6\tFidelity = 0.501318\tKL_Divergence = 3.450546\n",
      "Epoch: 7\tFidelity = 0.501489\tKL_Divergence = 3.382937\n",
      "Epoch: 8\tFidelity = 0.501359\tKL_Divergence = 3.433865\n",
      "Epoch: 9\tFidelity = 0.501467\tKL_Divergence = 3.391690\n",
      "Epoch: 10\tFidelity = 0.501401\tKL_Divergence = 3.417152\n",
      "Epoch: 11\tFidelity = 0.501041\tKL_Divergence = 3.581414\n",
      "Epoch: 12\tFidelity = 0.501514\tKL_Divergence = 3.374028\n",
      "Epoch: 13\tFidelity = 0.501408\tKL_Divergence = 3.414138\n",
      "Epoch: 14\tFidelity = 0.501313\tKL_Divergence = 3.453212\n",
      "Epoch: 15\tFidelity = 0.501633\tKL_Divergence = 3.331981\n",
      "Epoch: 16\tFidelity = 0.501050\tKL_Divergence = 3.577219\n",
      "Epoch: 17\tFidelity = 0.501264\tKL_Divergence = 3.474223\n",
      "Epoch: 18\tFidelity = 0.501336\tKL_Divergence = 3.443188\n",
      "Epoch: 19\tFidelity = 0.501451\tKL_Divergence = 3.397054\n",
      "Epoch: 20\tFidelity = 0.501213\tKL_Divergence = 3.496910\n",
      "Epoch: 21\tFidelity = 0.501479\tKL_Divergence = 3.386524\n",
      "Epoch: 22\tFidelity = 0.501075\tKL_Divergence = 3.563295\n",
      "Epoch: 23\tFidelity = 0.501120\tKL_Divergence = 3.540924\n",
      "Epoch: 24\tFidelity = 0.501014\tKL_Divergence = 3.596612\n",
      "Epoch: 25\tFidelity = 0.501301\tKL_Divergence = 3.457766\n",
      "Epoch: 26\tFidelity = 0.501288\tKL_Divergence = 3.463362\n",
      "Epoch: 27\tFidelity = 0.501271\tKL_Divergence = 3.470555\n",
      "Epoch: 28\tFidelity = 0.501433\tKL_Divergence = 3.403832\n",
      "Epoch: 29\tFidelity = 0.501183\tKL_Divergence = 3.510570\n",
      "Epoch: 30\tFidelity = 0.501227\tKL_Divergence = 3.489426\n",
      "Epoch: 31\tFidelity = 0.501215\tKL_Divergence = 3.494854\n",
      "Epoch: 32\tFidelity = 0.501240\tKL_Divergence = 3.483703\n",
      "Epoch: 33\tFidelity = 0.501214\tKL_Divergence = 3.495586\n",
      "Epoch: 34\tFidelity = 0.501336\tKL_Divergence = 3.441783\n",
      "Epoch: 35\tFidelity = 0.501245\tKL_Divergence = 3.480725\n",
      "Epoch: 36\tFidelity = 0.501152\tKL_Divergence = 3.524554\n",
      "Epoch: 37\tFidelity = 0.501435\tKL_Divergence = 3.402335\n",
      "Epoch: 38\tFidelity = 0.501239\tKL_Divergence = 3.483792\n",
      "Epoch: 39\tFidelity = 0.501365\tKL_Divergence = 3.429312\n",
      "Epoch: 40\tFidelity = 0.501408\tKL_Divergence = 3.411191\n",
      "Epoch: 41\tFidelity = 0.501493\tKL_Divergence = 3.379505\n",
      "Epoch: 42\tFidelity = 0.501584\tKL_Divergence = 3.346467\n",
      "Epoch: 43\tFidelity = 0.501043\tKL_Divergence = 3.577970\n",
      "Epoch: 44\tFidelity = 0.501245\tKL_Divergence = 3.478909\n",
      "Epoch: 45\tFidelity = 0.501403\tKL_Divergence = 3.412023\n",
      "Epoch: 46\tFidelity = 0.501268\tKL_Divergence = 3.469060\n",
      "Epoch: 47\tFidelity = 0.501660\tKL_Divergence = 3.318980\n",
      "Epoch: 48\tFidelity = 0.501385\tKL_Divergence = 3.419688\n",
      "Epoch: 49\tFidelity = 0.501460\tKL_Divergence = 3.390325\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:02:09,772] Trial 340 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.501469\tKL_Divergence = 3.386125\n",
      "Total time elapsed during training: 38.057 s\n",
      "Trial 340 pruned. \n",
      "Epoch: 1\tFidelity = 0.501305\tKL_Divergence = 3.452549\n",
      "Epoch: 2\tFidelity = 0.501150\tKL_Divergence = 3.523579\n",
      "Epoch: 3\tFidelity = 0.501179\tKL_Divergence = 3.510495\n",
      "Epoch: 4\tFidelity = 0.501457\tKL_Divergence = 3.393332\n",
      "Epoch: 5\tFidelity = 0.501208\tKL_Divergence = 3.497812\n",
      "Epoch: 6\tFidelity = 0.501200\tKL_Divergence = 3.501785\n",
      "Epoch: 7\tFidelity = 0.501327\tKL_Divergence = 3.446344\n",
      "Epoch: 8\tFidelity = 0.501072\tKL_Divergence = 3.564549\n",
      "Epoch: 9\tFidelity = 0.501170\tKL_Divergence = 3.516158\n",
      "Epoch: 10\tFidelity = 0.501075\tKL_Divergence = 3.563748\n",
      "Epoch: 11\tFidelity = 0.501373\tKL_Divergence = 3.427877\n",
      "Epoch: 12\tFidelity = 0.501269\tKL_Divergence = 3.471401\n",
      "Epoch: 13\tFidelity = 0.501246\tKL_Divergence = 3.481957\n",
      "Epoch: 14\tFidelity = 0.501403\tKL_Divergence = 3.416161\n",
      "Epoch: 15\tFidelity = 0.501209\tKL_Divergence = 3.498853\n",
      "Epoch: 16\tFidelity = 0.501390\tKL_Divergence = 3.421299\n",
      "Epoch: 17\tFidelity = 0.501212\tKL_Divergence = 3.497583\n",
      "Epoch: 18\tFidelity = 0.501233\tKL_Divergence = 3.487703\n",
      "Epoch: 19\tFidelity = 0.501145\tKL_Divergence = 3.529240\n",
      "Epoch: 20\tFidelity = 0.501373\tKL_Divergence = 3.428224\n",
      "Epoch: 21\tFidelity = 0.501159\tKL_Divergence = 3.522472\n",
      "Epoch: 22\tFidelity = 0.501263\tKL_Divergence = 3.474676\n",
      "Epoch: 23\tFidelity = 0.501141\tKL_Divergence = 3.531070\n",
      "Epoch: 24\tFidelity = 0.501287\tKL_Divergence = 3.464276\n",
      "Epoch: 25\tFidelity = 0.501285\tKL_Divergence = 3.465077\n",
      "Epoch: 26\tFidelity = 0.501353\tKL_Divergence = 3.436669\n",
      "Epoch: 27\tFidelity = 0.501360\tKL_Divergence = 3.433579\n",
      "Epoch: 28\tFidelity = 0.501213\tKL_Divergence = 3.497205\n",
      "Epoch: 29\tFidelity = 0.501386\tKL_Divergence = 3.423167\n",
      "Epoch: 30\tFidelity = 0.501166\tKL_Divergence = 3.519236\n",
      "Epoch: 31\tFidelity = 0.501237\tKL_Divergence = 3.486233\n",
      "Epoch: 32\tFidelity = 0.501274\tKL_Divergence = 3.469714\n",
      "Epoch: 33\tFidelity = 0.501222\tKL_Divergence = 3.492904\n",
      "Epoch: 34\tFidelity = 0.501310\tKL_Divergence = 3.454226\n",
      "Epoch: 35\tFidelity = 0.501144\tKL_Divergence = 3.529417\n",
      "Epoch: 36\tFidelity = 0.501213\tKL_Divergence = 3.497254\n",
      "Epoch: 37\tFidelity = 0.501183\tKL_Divergence = 3.511048\n",
      "Epoch: 38\tFidelity = 0.501343\tKL_Divergence = 3.440471\n",
      "Epoch: 39\tFidelity = 0.501370\tKL_Divergence = 3.429741\n",
      "Epoch: 40\tFidelity = 0.501148\tKL_Divergence = 3.527706\n",
      "Epoch: 41\tFidelity = 0.501096\tKL_Divergence = 3.553404\n",
      "Epoch: 42\tFidelity = 0.501333\tKL_Divergence = 3.444897\n",
      "Epoch: 43\tFidelity = 0.501118\tKL_Divergence = 3.542182\n",
      "Epoch: 44\tFidelity = 0.501255\tKL_Divergence = 3.478123\n",
      "Epoch: 45\tFidelity = 0.501211\tKL_Divergence = 3.498072\n",
      "Epoch: 46\tFidelity = 0.501237\tKL_Divergence = 3.486127\n",
      "Epoch: 47\tFidelity = 0.501071\tKL_Divergence = 3.566135\n",
      "Epoch: 48\tFidelity = 0.501534\tKL_Divergence = 3.366555\n",
      "Epoch: 49\tFidelity = 0.501200\tKL_Divergence = 3.503229\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:02:54,373] Trial 341 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.501258\tKL_Divergence = 3.476954\n",
      "Total time elapsed during training: 44.434 s\n",
      "Trial 341 pruned. \n",
      "Epoch: 1\tFidelity = 0.501151\tKL_Divergence = 3.526158\n",
      "Epoch: 2\tFidelity = 0.501350\tKL_Divergence = 3.437607\n",
      "Epoch: 3\tFidelity = 0.501317\tKL_Divergence = 3.451239\n",
      "Epoch: 4\tFidelity = 0.501260\tKL_Divergence = 3.475897\n",
      "Epoch: 5\tFidelity = 0.501355\tKL_Divergence = 3.435576\n",
      "Epoch: 6\tFidelity = 0.501175\tKL_Divergence = 3.514867\n",
      "Epoch: 7\tFidelity = 0.501361\tKL_Divergence = 3.433027\n",
      "Epoch: 8\tFidelity = 0.501134\tKL_Divergence = 3.534730\n",
      "Epoch: 9\tFidelity = 0.501238\tKL_Divergence = 3.485553\n",
      "Epoch: 10\tFidelity = 0.501392\tKL_Divergence = 3.420566\n",
      "Epoch: 11\tFidelity = 0.501354\tKL_Divergence = 3.436115\n",
      "Epoch: 12\tFidelity = 0.501137\tKL_Divergence = 3.533046\n",
      "Epoch: 13\tFidelity = 0.501098\tKL_Divergence = 3.552611\n",
      "Epoch: 14\tFidelity = 0.501127\tKL_Divergence = 3.537706\n",
      "Epoch: 15\tFidelity = 0.501202\tKL_Divergence = 3.501989\n",
      "Epoch: 16\tFidelity = 0.501339\tKL_Divergence = 3.442285\n",
      "Epoch: 17\tFidelity = 0.501317\tKL_Divergence = 3.451441\n",
      "Epoch: 18\tFidelity = 0.501278\tKL_Divergence = 3.468231\n",
      "Epoch: 19\tFidelity = 0.501141\tKL_Divergence = 3.531112\n",
      "Epoch: 20\tFidelity = 0.501312\tKL_Divergence = 3.453574\n",
      "Epoch: 21\tFidelity = 0.501196\tKL_Divergence = 3.504815\n",
      "Epoch: 22\tFidelity = 0.501211\tKL_Divergence = 3.497880\n",
      "Epoch: 23\tFidelity = 0.501145\tKL_Divergence = 3.529259\n",
      "Epoch: 24\tFidelity = 0.501217\tKL_Divergence = 3.495479\n",
      "Epoch: 25\tFidelity = 0.501055\tKL_Divergence = 3.574882\n",
      "Epoch: 26\tFidelity = 0.501162\tKL_Divergence = 3.521194\n",
      "Epoch: 27\tFidelity = 0.501289\tKL_Divergence = 3.463517\n",
      "Epoch: 28\tFidelity = 0.501216\tKL_Divergence = 3.495650\n",
      "Epoch: 29\tFidelity = 0.501151\tKL_Divergence = 3.526237\n",
      "Epoch: 30\tFidelity = 0.501152\tKL_Divergence = 3.525849\n",
      "Epoch: 31\tFidelity = 0.501238\tKL_Divergence = 3.485656\n",
      "Epoch: 32\tFidelity = 0.501462\tKL_Divergence = 3.393235\n",
      "Epoch: 33\tFidelity = 0.501258\tKL_Divergence = 3.476675\n",
      "Epoch: 34\tFidelity = 0.501256\tKL_Divergence = 3.477851\n",
      "Epoch: 35\tFidelity = 0.501256\tKL_Divergence = 3.477792\n",
      "Epoch: 36\tFidelity = 0.501173\tKL_Divergence = 3.515649\n",
      "Epoch: 37\tFidelity = 0.501342\tKL_Divergence = 3.441078\n",
      "Epoch: 38\tFidelity = 0.501257\tKL_Divergence = 3.477395\n",
      "Epoch: 39\tFidelity = 0.501362\tKL_Divergence = 3.432925\n",
      "Epoch: 40\tFidelity = 0.501322\tKL_Divergence = 3.449320\n",
      "Epoch: 41\tFidelity = 0.501009\tKL_Divergence = 3.599498\n",
      "Epoch: 42\tFidelity = 0.501254\tKL_Divergence = 3.478598\n",
      "Epoch: 43\tFidelity = 0.501169\tKL_Divergence = 3.517634\n",
      "Epoch: 44\tFidelity = 0.501188\tKL_Divergence = 3.508665\n",
      "Epoch: 45\tFidelity = 0.501193\tKL_Divergence = 3.506430\n",
      "Epoch: 46\tFidelity = 0.501272\tKL_Divergence = 3.470518\n",
      "Epoch: 47\tFidelity = 0.501142\tKL_Divergence = 3.530678\n",
      "Epoch: 48\tFidelity = 0.501136\tKL_Divergence = 3.533338\n",
      "Epoch: 49\tFidelity = 0.501225\tKL_Divergence = 3.491685\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:04:13,223] Trial 342 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.501265\tKL_Divergence = 3.473518\n",
      "Total time elapsed during training: 78.662 s\n",
      "Trial 342 pruned. \n",
      "Epoch: 1\tFidelity = 0.501271\tKL_Divergence = 3.470730\n",
      "Epoch: 2\tFidelity = 0.501083\tKL_Divergence = 3.559861\n",
      "Epoch: 3\tFidelity = 0.501078\tKL_Divergence = 3.562414\n",
      "Epoch: 4\tFidelity = 0.501001\tKL_Divergence = 3.603659\n",
      "Epoch: 5\tFidelity = 0.501349\tKL_Divergence = 3.437885\n",
      "Epoch: 6\tFidelity = 0.501201\tKL_Divergence = 3.502372\n",
      "Epoch: 7\tFidelity = 0.501095\tKL_Divergence = 3.553468\n",
      "Epoch: 8\tFidelity = 0.501260\tKL_Divergence = 3.475540\n",
      "Epoch: 9\tFidelity = 0.501372\tKL_Divergence = 3.428438\n",
      "Epoch: 10\tFidelity = 0.501071\tKL_Divergence = 3.566288\n",
      "Epoch: 11\tFidelity = 0.501002\tKL_Divergence = 3.602895\n",
      "Epoch: 12\tFidelity = 0.501112\tKL_Divergence = 3.545429\n",
      "Epoch: 13\tFidelity = 0.501117\tKL_Divergence = 3.542703\n",
      "Epoch: 14\tFidelity = 0.501246\tKL_Divergence = 3.482028\n",
      "Epoch: 15\tFidelity = 0.501027\tKL_Divergence = 3.589289\n",
      "Epoch: 16\tFidelity = 0.501330\tKL_Divergence = 3.445857\n",
      "Epoch: 17\tFidelity = 0.501302\tKL_Divergence = 3.457633\n",
      "Epoch: 18\tFidelity = 0.501449\tKL_Divergence = 3.398232\n",
      "Epoch: 19\tFidelity = 0.501305\tKL_Divergence = 3.456126\n",
      "Epoch: 20\tFidelity = 0.501017\tKL_Divergence = 3.594782\n",
      "Epoch: 21\tFidelity = 0.501226\tKL_Divergence = 3.490869\n",
      "Epoch: 22\tFidelity = 0.501507\tKL_Divergence = 3.376265\n",
      "Epoch: 23\tFidelity = 0.501213\tKL_Divergence = 3.496772\n",
      "Epoch: 24\tFidelity = 0.501293\tKL_Divergence = 3.461365\n",
      "Epoch: 25\tFidelity = 0.501064\tKL_Divergence = 3.569528\n",
      "Epoch: 26\tFidelity = 0.501539\tKL_Divergence = 3.364714\n",
      "Epoch: 27\tFidelity = 0.500994\tKL_Divergence = 3.607690\n",
      "Epoch: 28\tFidelity = 0.501192\tKL_Divergence = 3.506753\n",
      "Epoch: 29\tFidelity = 0.501287\tKL_Divergence = 3.464072\n",
      "Epoch: 30\tFidelity = 0.501302\tKL_Divergence = 3.457560\n",
      "Epoch: 31\tFidelity = 0.501257\tKL_Divergence = 3.476999\n",
      "Epoch: 32\tFidelity = 0.501433\tKL_Divergence = 3.404539\n",
      "Epoch: 33\tFidelity = 0.501073\tKL_Divergence = 3.565086\n",
      "Epoch: 34\tFidelity = 0.501078\tKL_Divergence = 3.562631\n",
      "Epoch: 35\tFidelity = 0.501271\tKL_Divergence = 3.470895\n",
      "Epoch: 36\tFidelity = 0.501270\tKL_Divergence = 3.471059\n",
      "Epoch: 37\tFidelity = 0.501080\tKL_Divergence = 3.561360\n",
      "Epoch: 38\tFidelity = 0.501243\tKL_Divergence = 3.483403\n",
      "Epoch: 39\tFidelity = 0.501147\tKL_Divergence = 3.527630\n",
      "Epoch: 40\tFidelity = 0.501239\tKL_Divergence = 3.485151\n",
      "Epoch: 41\tFidelity = 0.501287\tKL_Divergence = 3.464140\n",
      "Epoch: 42\tFidelity = 0.501210\tKL_Divergence = 3.498283\n",
      "Epoch: 43\tFidelity = 0.501104\tKL_Divergence = 3.549446\n",
      "Epoch: 44\tFidelity = 0.501120\tKL_Divergence = 3.541335\n",
      "Epoch: 45\tFidelity = 0.500980\tKL_Divergence = 3.615614\n",
      "Epoch: 46\tFidelity = 0.501261\tKL_Divergence = 3.475683\n",
      "Epoch: 47\tFidelity = 0.501215\tKL_Divergence = 3.495922\n",
      "Epoch: 48\tFidelity = 0.501186\tKL_Divergence = 3.509480\n",
      "Epoch: 49\tFidelity = 0.501283\tKL_Divergence = 3.465862\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:04:57,545] Trial 343 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.501079\tKL_Divergence = 3.562100\n",
      "Total time elapsed during training: 44.159 s\n",
      "Trial 343 pruned. \n",
      "Epoch: 1\tFidelity = 0.501107\tKL_Divergence = 3.547677\n",
      "Epoch: 2\tFidelity = 0.501169\tKL_Divergence = 3.517624\n",
      "Epoch: 3\tFidelity = 0.501412\tKL_Divergence = 3.412692\n",
      "Epoch: 4\tFidelity = 0.501103\tKL_Divergence = 3.549864\n",
      "Epoch: 5\tFidelity = 0.501134\tKL_Divergence = 3.534406\n",
      "Epoch: 6\tFidelity = 0.501475\tKL_Divergence = 3.388154\n",
      "Epoch: 7\tFidelity = 0.501163\tKL_Divergence = 3.520581\n",
      "Epoch: 8\tFidelity = 0.501376\tKL_Divergence = 3.426920\n",
      "Epoch: 9\tFidelity = 0.501019\tKL_Divergence = 3.593926\n",
      "Epoch: 10\tFidelity = 0.501052\tKL_Divergence = 3.575606\n",
      "Epoch: 11\tFidelity = 0.501230\tKL_Divergence = 3.489284\n",
      "Epoch: 12\tFidelity = 0.500940\tKL_Divergence = 3.638795\n",
      "Epoch: 13\tFidelity = 0.501152\tKL_Divergence = 3.525678\n",
      "Epoch: 14\tFidelity = 0.501327\tKL_Divergence = 3.446893\n",
      "Epoch: 15\tFidelity = 0.501146\tKL_Divergence = 3.528172\n",
      "Epoch: 16\tFidelity = 0.501003\tKL_Divergence = 3.602412\n",
      "Epoch: 17\tFidelity = 0.501288\tKL_Divergence = 3.462387\n",
      "Epoch: 18\tFidelity = 0.500931\tKL_Divergence = 3.643919\n",
      "Epoch: 19\tFidelity = 0.501145\tKL_Divergence = 3.528834\n",
      "Epoch: 20\tFidelity = 0.500914\tKL_Divergence = 3.653524\n",
      "Epoch: 21\tFidelity = 0.501014\tKL_Divergence = 3.595994\n",
      "Epoch: 22\tFidelity = 0.501145\tKL_Divergence = 3.527756\n",
      "Epoch: 23\tFidelity = 0.501334\tKL_Divergence = 3.442730\n",
      "Epoch: 24\tFidelity = 0.500841\tKL_Divergence = 3.698598\n",
      "Epoch: 25\tFidelity = 0.501058\tKL_Divergence = 3.571820\n",
      "Epoch: 26\tFidelity = 0.501430\tKL_Divergence = 3.404918\n",
      "Epoch: 27\tFidelity = 0.501463\tKL_Divergence = 3.392738\n",
      "Epoch: 28\tFidelity = 0.501084\tKL_Divergence = 3.559565\n",
      "Epoch: 29\tFidelity = 0.501159\tKL_Divergence = 3.522181\n",
      "Epoch: 30\tFidelity = 0.501085\tKL_Divergence = 3.558819\n",
      "Epoch: 31\tFidelity = 0.501125\tKL_Divergence = 3.538585\n",
      "Epoch: 32\tFidelity = 0.500928\tKL_Divergence = 3.645524\n",
      "Epoch: 33\tFidelity = 0.500954\tKL_Divergence = 3.630335\n",
      "Epoch: 34\tFidelity = 0.501192\tKL_Divergence = 3.506794\n",
      "Epoch: 35\tFidelity = 0.501235\tKL_Divergence = 3.486924\n",
      "Epoch: 36\tFidelity = 0.501017\tKL_Divergence = 3.594972\n",
      "Epoch: 37\tFidelity = 0.501135\tKL_Divergence = 3.533661\n",
      "Epoch: 38\tFidelity = 0.500930\tKL_Divergence = 3.644543\n",
      "Epoch: 39\tFidelity = 0.500921\tKL_Divergence = 3.649996\n",
      "Epoch: 40\tFidelity = 0.501114\tKL_Divergence = 3.544124\n",
      "Epoch: 41\tFidelity = 0.501408\tKL_Divergence = 3.413828\n",
      "Epoch: 42\tFidelity = 0.501128\tKL_Divergence = 3.537098\n",
      "Epoch: 43\tFidelity = 0.501308\tKL_Divergence = 3.455154\n",
      "Epoch: 44\tFidelity = 0.501043\tKL_Divergence = 3.581125\n",
      "Epoch: 45\tFidelity = 0.501211\tKL_Divergence = 3.497359\n",
      "Epoch: 46\tFidelity = 0.501346\tKL_Divergence = 3.439205\n",
      "Epoch: 47\tFidelity = 0.501299\tKL_Divergence = 3.458715\n",
      "Epoch: 48\tFidelity = 0.501101\tKL_Divergence = 3.550809\n",
      "Epoch: 49\tFidelity = 0.501342\tKL_Divergence = 3.440276\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:05:35,133] Trial 344 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.501173\tKL_Divergence = 3.515522\n",
      "Total time elapsed during training: 37.426 s\n",
      "Trial 344 pruned. \n",
      "Epoch: 1\tFidelity = 0.501102\tKL_Divergence = 3.550017\n",
      "Epoch: 2\tFidelity = 0.501070\tKL_Divergence = 3.566320\n",
      "Epoch: 3\tFidelity = 0.501052\tKL_Divergence = 3.575720\n",
      "Epoch: 4\tFidelity = 0.501063\tKL_Divergence = 3.570096\n",
      "Epoch: 5\tFidelity = 0.501130\tKL_Divergence = 3.536489\n",
      "Epoch: 6\tFidelity = 0.501157\tKL_Divergence = 3.523100\n",
      "Epoch: 7\tFidelity = 0.501165\tKL_Divergence = 3.519351\n",
      "Epoch: 8\tFidelity = 0.501098\tKL_Divergence = 3.552160\n",
      "Epoch: 9\tFidelity = 0.501099\tKL_Divergence = 3.551637\n",
      "Epoch: 10\tFidelity = 0.501161\tKL_Divergence = 3.521285\n",
      "Epoch: 11\tFidelity = 0.501148\tKL_Divergence = 3.527418\n",
      "Epoch: 12\tFidelity = 0.501075\tKL_Divergence = 3.564289\n",
      "Epoch: 13\tFidelity = 0.501136\tKL_Divergence = 3.533657\n",
      "Epoch: 14\tFidelity = 0.501160\tKL_Divergence = 3.521912\n",
      "Epoch: 15\tFidelity = 0.501051\tKL_Divergence = 3.576481\n",
      "Epoch: 16\tFidelity = 0.501072\tKL_Divergence = 3.565831\n",
      "Epoch: 17\tFidelity = 0.501232\tKL_Divergence = 3.488508\n",
      "Epoch: 18\tFidelity = 0.501128\tKL_Divergence = 3.537326\n",
      "Epoch: 19\tFidelity = 0.501141\tKL_Divergence = 3.530868\n",
      "Epoch: 20\tFidelity = 0.501104\tKL_Divergence = 3.549254\n",
      "Epoch: 21\tFidelity = 0.501170\tKL_Divergence = 3.517141\n",
      "Epoch: 22\tFidelity = 0.501213\tKL_Divergence = 3.497042\n",
      "Epoch: 23\tFidelity = 0.501255\tKL_Divergence = 3.478183\n",
      "Epoch: 24\tFidelity = 0.501097\tKL_Divergence = 3.553010\n",
      "Epoch: 25\tFidelity = 0.501108\tKL_Divergence = 3.547185\n",
      "Epoch: 26\tFidelity = 0.501121\tKL_Divergence = 3.540883\n",
      "Epoch: 27\tFidelity = 0.501209\tKL_Divergence = 3.498874\n",
      "Epoch: 28\tFidelity = 0.501109\tKL_Divergence = 3.546685\n",
      "Epoch: 29\tFidelity = 0.501110\tKL_Divergence = 3.546201\n",
      "Epoch: 30\tFidelity = 0.501204\tKL_Divergence = 3.501131\n",
      "Epoch: 31\tFidelity = 0.501189\tKL_Divergence = 3.508168\n",
      "Epoch: 32\tFidelity = 0.501144\tKL_Divergence = 3.529403\n",
      "Epoch: 33\tFidelity = 0.501092\tKL_Divergence = 3.555266\n",
      "Epoch: 34\tFidelity = 0.501145\tKL_Divergence = 3.528909\n",
      "Epoch: 35\tFidelity = 0.501186\tKL_Divergence = 3.509408\n",
      "Epoch: 36\tFidelity = 0.501211\tKL_Divergence = 3.498084\n",
      "Epoch: 37\tFidelity = 0.501174\tKL_Divergence = 3.514913\n",
      "Epoch: 38\tFidelity = 0.501204\tKL_Divergence = 3.500917\n",
      "Epoch: 39\tFidelity = 0.501143\tKL_Divergence = 3.529892\n",
      "Epoch: 40\tFidelity = 0.501095\tKL_Divergence = 3.553714\n",
      "Epoch: 41\tFidelity = 0.501136\tKL_Divergence = 3.533628\n",
      "Epoch: 42\tFidelity = 0.501156\tKL_Divergence = 3.523853\n",
      "Epoch: 43\tFidelity = 0.501078\tKL_Divergence = 3.562713\n",
      "Epoch: 44\tFidelity = 0.501188\tKL_Divergence = 3.508648\n",
      "Epoch: 45\tFidelity = 0.501216\tKL_Divergence = 3.495712\n",
      "Epoch: 46\tFidelity = 0.501071\tKL_Divergence = 3.566250\n",
      "Epoch: 47\tFidelity = 0.501207\tKL_Divergence = 3.499973\n",
      "Epoch: 48\tFidelity = 0.501235\tKL_Divergence = 3.487203\n",
      "Epoch: 49\tFidelity = 0.501108\tKL_Divergence = 3.547416\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:06:12,599] Trial 345 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.501072\tKL_Divergence = 3.565594\n",
      "Total time elapsed during training: 37.304 s\n",
      "Trial 345 pruned. \n",
      "Epoch: 1\tFidelity = 0.501117\tKL_Divergence = 3.542851\n",
      "Epoch: 2\tFidelity = 0.501014\tKL_Divergence = 3.596394\n",
      "Epoch: 3\tFidelity = 0.501079\tKL_Divergence = 3.562091\n",
      "Epoch: 4\tFidelity = 0.501058\tKL_Divergence = 3.573107\n",
      "Epoch: 5\tFidelity = 0.501157\tKL_Divergence = 3.523509\n",
      "Epoch: 6\tFidelity = 0.501016\tKL_Divergence = 3.595576\n",
      "Epoch: 7\tFidelity = 0.501111\tKL_Divergence = 3.545901\n",
      "Epoch: 8\tFidelity = 0.501115\tKL_Divergence = 3.543734\n",
      "Epoch: 9\tFidelity = 0.500947\tKL_Divergence = 3.634811\n",
      "Epoch: 10\tFidelity = 0.501099\tKL_Divergence = 3.552027\n",
      "Epoch: 11\tFidelity = 0.501172\tKL_Divergence = 3.516390\n",
      "Epoch: 12\tFidelity = 0.501115\tKL_Divergence = 3.543762\n",
      "Epoch: 13\tFidelity = 0.501167\tKL_Divergence = 3.518503\n",
      "Epoch: 14\tFidelity = 0.501169\tKL_Divergence = 3.517811\n",
      "Epoch: 15\tFidelity = 0.501175\tKL_Divergence = 3.514734\n",
      "Epoch: 16\tFidelity = 0.501343\tKL_Divergence = 3.440557\n",
      "Epoch: 17\tFidelity = 0.501082\tKL_Divergence = 3.560806\n",
      "Epoch: 18\tFidelity = 0.501086\tKL_Divergence = 3.558816\n",
      "Epoch: 19\tFidelity = 0.501174\tKL_Divergence = 3.515211\n",
      "Epoch: 20\tFidelity = 0.501059\tKL_Divergence = 3.572594\n",
      "Epoch: 21\tFidelity = 0.501018\tKL_Divergence = 3.594583\n",
      "Epoch: 22\tFidelity = 0.501111\tKL_Divergence = 3.545781\n",
      "Epoch: 23\tFidelity = 0.500991\tKL_Divergence = 3.609608\n",
      "Epoch: 24\tFidelity = 0.501165\tKL_Divergence = 3.519749\n",
      "Epoch: 25\tFidelity = 0.501159\tKL_Divergence = 3.522285\n",
      "Epoch: 26\tFidelity = 0.501236\tKL_Divergence = 3.486774\n",
      "Epoch: 27\tFidelity = 0.501268\tKL_Divergence = 3.472502\n",
      "Epoch: 28\tFidelity = 0.501134\tKL_Divergence = 3.534548\n",
      "Epoch: 29\tFidelity = 0.501183\tKL_Divergence = 3.510950\n",
      "Epoch: 30\tFidelity = 0.501098\tKL_Divergence = 3.552544\n",
      "Epoch: 31\tFidelity = 0.501277\tKL_Divergence = 3.468425\n",
      "Epoch: 32\tFidelity = 0.501124\tKL_Divergence = 3.539549\n",
      "Epoch: 33\tFidelity = 0.501110\tKL_Divergence = 3.546416\n",
      "Epoch: 34\tFidelity = 0.500947\tKL_Divergence = 3.634715\n",
      "Epoch: 35\tFidelity = 0.501028\tKL_Divergence = 3.589169\n",
      "Epoch: 36\tFidelity = 0.501080\tKL_Divergence = 3.561424\n",
      "Epoch: 37\tFidelity = 0.501085\tKL_Divergence = 3.558942\n",
      "Epoch: 38\tFidelity = 0.501148\tKL_Divergence = 3.527585\n",
      "Epoch: 39\tFidelity = 0.501187\tKL_Divergence = 3.509411\n",
      "Epoch: 40\tFidelity = 0.501152\tKL_Divergence = 3.525853\n",
      "Epoch: 41\tFidelity = 0.501137\tKL_Divergence = 3.532890\n",
      "Epoch: 42\tFidelity = 0.500991\tKL_Divergence = 3.609387\n",
      "Epoch: 43\tFidelity = 0.501054\tKL_Divergence = 3.575045\n",
      "Epoch: 44\tFidelity = 0.500986\tKL_Divergence = 3.611943\n",
      "Epoch: 45\tFidelity = 0.501249\tKL_Divergence = 3.481053\n",
      "Epoch: 46\tFidelity = 0.501169\tKL_Divergence = 3.517510\n",
      "Epoch: 47\tFidelity = 0.501059\tKL_Divergence = 3.572641\n",
      "Epoch: 48\tFidelity = 0.501277\tKL_Divergence = 3.468552\n",
      "Epoch: 49\tFidelity = 0.501052\tKL_Divergence = 3.576075\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:06:50,385] Trial 346 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500981\tKL_Divergence = 3.615119\n",
      "Total time elapsed during training: 37.627 s\n",
      "Trial 346 pruned. \n",
      "Epoch: 1\tFidelity = 0.501182\tKL_Divergence = 3.511334\n",
      "Epoch: 2\tFidelity = 0.501125\tKL_Divergence = 3.538786\n",
      "Epoch: 3\tFidelity = 0.501240\tKL_Divergence = 3.484861\n",
      "Epoch: 4\tFidelity = 0.501105\tKL_Divergence = 3.548788\n",
      "Epoch: 5\tFidelity = 0.501226\tKL_Divergence = 3.491324\n",
      "Epoch: 6\tFidelity = 0.501223\tKL_Divergence = 3.492537\n",
      "Epoch: 7\tFidelity = 0.500974\tKL_Divergence = 3.619046\n",
      "Epoch: 8\tFidelity = 0.501053\tKL_Divergence = 3.575552\n",
      "Epoch: 9\tFidelity = 0.501182\tKL_Divergence = 3.511604\n",
      "Epoch: 10\tFidelity = 0.501136\tKL_Divergence = 3.533538\n",
      "Epoch: 11\tFidelity = 0.501093\tKL_Divergence = 3.554725\n",
      "Epoch: 12\tFidelity = 0.501079\tKL_Divergence = 3.562320\n",
      "Epoch: 13\tFidelity = 0.501036\tKL_Divergence = 3.584481\n",
      "Epoch: 14\tFidelity = 0.500949\tKL_Divergence = 3.633363\n",
      "Epoch: 15\tFidelity = 0.501051\tKL_Divergence = 3.576822\n",
      "Epoch: 16\tFidelity = 0.501154\tKL_Divergence = 3.524831\n",
      "Epoch: 17\tFidelity = 0.501082\tKL_Divergence = 3.560736\n",
      "Epoch: 18\tFidelity = 0.501081\tKL_Divergence = 3.561130\n",
      "Epoch: 19\tFidelity = 0.501102\tKL_Divergence = 3.550417\n",
      "Epoch: 20\tFidelity = 0.501106\tKL_Divergence = 3.548193\n",
      "Epoch: 21\tFidelity = 0.501017\tKL_Divergence = 3.595048\n",
      "Epoch: 22\tFidelity = 0.501130\tKL_Divergence = 3.536301\n",
      "Epoch: 23\tFidelity = 0.501126\tKL_Divergence = 3.538521\n",
      "Epoch: 24\tFidelity = 0.501080\tKL_Divergence = 3.561427\n",
      "Epoch: 25\tFidelity = 0.501077\tKL_Divergence = 3.563049\n",
      "Epoch: 26\tFidelity = 0.501131\tKL_Divergence = 3.536256\n",
      "Epoch: 27\tFidelity = 0.501059\tKL_Divergence = 3.572366\n",
      "Epoch: 28\tFidelity = 0.501121\tKL_Divergence = 3.540982\n",
      "Epoch: 29\tFidelity = 0.501107\tKL_Divergence = 3.547797\n",
      "Epoch: 30\tFidelity = 0.501169\tKL_Divergence = 3.517508\n",
      "Epoch: 31\tFidelity = 0.501070\tKL_Divergence = 3.566761\n",
      "Epoch: 32\tFidelity = 0.501023\tKL_Divergence = 3.591529\n",
      "Epoch: 33\tFidelity = 0.501124\tKL_Divergence = 3.539260\n",
      "Epoch: 34\tFidelity = 0.501208\tKL_Divergence = 3.499513\n",
      "Epoch: 35\tFidelity = 0.501083\tKL_Divergence = 3.560265\n",
      "Epoch: 36\tFidelity = 0.501087\tKL_Divergence = 3.558123\n",
      "Epoch: 37\tFidelity = 0.501071\tKL_Divergence = 3.566119\n",
      "Epoch: 38\tFidelity = 0.501016\tKL_Divergence = 3.595284\n",
      "Epoch: 39\tFidelity = 0.501112\tKL_Divergence = 3.545390\n",
      "Epoch: 40\tFidelity = 0.501058\tKL_Divergence = 3.573080\n",
      "Epoch: 41\tFidelity = 0.501081\tKL_Divergence = 3.560928\n",
      "Epoch: 42\tFidelity = 0.501112\tKL_Divergence = 3.545192\n",
      "Epoch: 43\tFidelity = 0.501098\tKL_Divergence = 3.552259\n",
      "Epoch: 44\tFidelity = 0.501134\tKL_Divergence = 3.534286\n",
      "Epoch: 45\tFidelity = 0.501130\tKL_Divergence = 3.536243\n",
      "Epoch: 46\tFidelity = 0.501110\tKL_Divergence = 3.546612\n",
      "Epoch: 47\tFidelity = 0.501014\tKL_Divergence = 3.596696\n",
      "Epoch: 48\tFidelity = 0.501116\tKL_Divergence = 3.543236\n",
      "Epoch: 49\tFidelity = 0.501079\tKL_Divergence = 3.561965\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:08:10,046] Trial 347 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.501011\tKL_Divergence = 3.598005\n",
      "Total time elapsed during training: 79.482 s\n",
      "Trial 347 pruned. \n",
      "Epoch: 1\tFidelity = 0.501098\tKL_Divergence = 3.552317\n",
      "Epoch: 2\tFidelity = 0.501009\tKL_Divergence = 3.599549\n",
      "Epoch: 3\tFidelity = 0.501044\tKL_Divergence = 3.580640\n",
      "Epoch: 4\tFidelity = 0.501012\tKL_Divergence = 3.597608\n",
      "Epoch: 5\tFidelity = 0.501103\tKL_Divergence = 3.549886\n",
      "Epoch: 6\tFidelity = 0.500974\tKL_Divergence = 3.618889\n",
      "Epoch: 7\tFidelity = 0.501126\tKL_Divergence = 3.538400\n",
      "Epoch: 8\tFidelity = 0.501037\tKL_Divergence = 3.584017\n",
      "Epoch: 9\tFidelity = 0.501034\tKL_Divergence = 3.585981\n",
      "Epoch: 10\tFidelity = 0.501081\tKL_Divergence = 3.561280\n",
      "Epoch: 11\tFidelity = 0.501023\tKL_Divergence = 3.591784\n",
      "Epoch: 12\tFidelity = 0.501040\tKL_Divergence = 3.582720\n",
      "Epoch: 13\tFidelity = 0.501010\tKL_Divergence = 3.598586\n",
      "Epoch: 14\tFidelity = 0.501140\tKL_Divergence = 3.531782\n",
      "Epoch: 15\tFidelity = 0.500976\tKL_Divergence = 3.618073\n",
      "Epoch: 16\tFidelity = 0.500955\tKL_Divergence = 3.629876\n",
      "Epoch: 17\tFidelity = 0.501056\tKL_Divergence = 3.574217\n",
      "Epoch: 18\tFidelity = 0.501027\tKL_Divergence = 3.589564\n",
      "Epoch: 19\tFidelity = 0.501048\tKL_Divergence = 3.578151\n",
      "Epoch: 20\tFidelity = 0.501047\tKL_Divergence = 3.579113\n",
      "Epoch: 21\tFidelity = 0.500970\tKL_Divergence = 3.621362\n",
      "Epoch: 22\tFidelity = 0.501060\tKL_Divergence = 3.571935\n",
      "Epoch: 23\tFidelity = 0.501014\tKL_Divergence = 3.596604\n",
      "Epoch: 24\tFidelity = 0.501135\tKL_Divergence = 3.534182\n",
      "Epoch: 25\tFidelity = 0.501039\tKL_Divergence = 3.583337\n",
      "Epoch: 26\tFidelity = 0.501096\tKL_Divergence = 3.553306\n",
      "Epoch: 27\tFidelity = 0.501056\tKL_Divergence = 3.574345\n",
      "Epoch: 28\tFidelity = 0.500963\tKL_Divergence = 3.625516\n",
      "Epoch: 29\tFidelity = 0.501023\tKL_Divergence = 3.591525\n",
      "Epoch: 30\tFidelity = 0.501059\tKL_Divergence = 3.572359\n",
      "Epoch: 31\tFidelity = 0.501123\tKL_Divergence = 3.539839\n",
      "Epoch: 32\tFidelity = 0.501061\tKL_Divergence = 3.571382\n",
      "Epoch: 33\tFidelity = 0.501113\tKL_Divergence = 3.544890\n",
      "Epoch: 34\tFidelity = 0.501076\tKL_Divergence = 3.563894\n",
      "Epoch: 35\tFidelity = 0.500999\tKL_Divergence = 3.605013\n",
      "Epoch: 36\tFidelity = 0.501147\tKL_Divergence = 3.528027\n",
      "Epoch: 37\tFidelity = 0.501114\tKL_Divergence = 3.544188\n",
      "Epoch: 38\tFidelity = 0.501108\tKL_Divergence = 3.547400\n",
      "Epoch: 39\tFidelity = 0.501002\tKL_Divergence = 3.603387\n",
      "Epoch: 40\tFidelity = 0.500984\tKL_Divergence = 3.613266\n",
      "Epoch: 41\tFidelity = 0.501113\tKL_Divergence = 3.544819\n",
      "Epoch: 42\tFidelity = 0.501015\tKL_Divergence = 3.595865\n",
      "Epoch: 43\tFidelity = 0.501039\tKL_Divergence = 3.582861\n",
      "Epoch: 44\tFidelity = 0.501015\tKL_Divergence = 3.596255\n",
      "Epoch: 45\tFidelity = 0.501148\tKL_Divergence = 3.527602\n",
      "Epoch: 46\tFidelity = 0.500995\tKL_Divergence = 3.607093\n",
      "Epoch: 47\tFidelity = 0.501044\tKL_Divergence = 3.580301\n",
      "Epoch: 48\tFidelity = 0.501075\tKL_Divergence = 3.564233\n",
      "Epoch: 49\tFidelity = 0.501005\tKL_Divergence = 3.601388\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:08:41,817] Trial 348 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500974\tKL_Divergence = 3.618875\n",
      "Total time elapsed during training: 31.610 s\n",
      "Trial 348 pruned. \n",
      "Epoch: 1\tFidelity = 0.501207\tKL_Divergence = 3.499691\n",
      "Epoch: 2\tFidelity = 0.500966\tKL_Divergence = 3.623480\n",
      "Epoch: 3\tFidelity = 0.501250\tKL_Divergence = 3.480398\n",
      "Epoch: 4\tFidelity = 0.500913\tKL_Divergence = 3.654933\n",
      "Epoch: 5\tFidelity = 0.501225\tKL_Divergence = 3.491855\n",
      "Epoch: 6\tFidelity = 0.500926\tKL_Divergence = 3.647085\n",
      "Epoch: 7\tFidelity = 0.501227\tKL_Divergence = 3.490531\n",
      "Epoch: 8\tFidelity = 0.500935\tKL_Divergence = 3.641460\n",
      "Epoch: 9\tFidelity = 0.501203\tKL_Divergence = 3.501499\n",
      "Epoch: 10\tFidelity = 0.500812\tKL_Divergence = 3.719850\n",
      "Epoch: 11\tFidelity = 0.501322\tKL_Divergence = 3.449476\n",
      "Epoch: 12\tFidelity = 0.500799\tKL_Divergence = 3.729161\n",
      "Epoch: 13\tFidelity = 0.501374\tKL_Divergence = 3.427812\n",
      "Epoch: 14\tFidelity = 0.500819\tKL_Divergence = 3.715080\n",
      "Epoch: 15\tFidelity = 0.501292\tKL_Divergence = 3.462019\n",
      "Epoch: 16\tFidelity = 0.500830\tKL_Divergence = 3.707820\n",
      "Epoch: 17\tFidelity = 0.501478\tKL_Divergence = 3.387235\n",
      "Epoch: 18\tFidelity = 0.500834\tKL_Divergence = 3.705381\n",
      "Epoch: 19\tFidelity = 0.501402\tKL_Divergence = 3.416636\n",
      "Epoch: 20\tFidelity = 0.500834\tKL_Divergence = 3.705023\n",
      "Epoch: 21\tFidelity = 0.501432\tKL_Divergence = 3.405067\n",
      "Epoch: 22\tFidelity = 0.500786\tKL_Divergence = 3.737895\n",
      "Epoch: 23\tFidelity = 0.501494\tKL_Divergence = 3.381322\n",
      "Epoch: 24\tFidelity = 0.500835\tKL_Divergence = 3.704435\n",
      "Epoch: 25\tFidelity = 0.501308\tKL_Divergence = 3.455424\n",
      "Epoch: 26\tFidelity = 0.500844\tKL_Divergence = 3.698292\n",
      "Epoch: 27\tFidelity = 0.501334\tKL_Divergence = 3.444319\n",
      "Epoch: 28\tFidelity = 0.500891\tKL_Divergence = 3.668686\n",
      "Epoch: 29\tFidelity = 0.501359\tKL_Divergence = 3.433942\n",
      "Epoch: 30\tFidelity = 0.500910\tKL_Divergence = 3.656741\n",
      "Epoch: 31\tFidelity = 0.501169\tKL_Divergence = 3.517820\n",
      "Epoch: 32\tFidelity = 0.501066\tKL_Divergence = 3.568762\n",
      "Epoch: 33\tFidelity = 0.501059\tKL_Divergence = 3.572648\n",
      "Epoch: 34\tFidelity = 0.501111\tKL_Divergence = 3.546055\n",
      "Epoch: 35\tFidelity = 0.501060\tKL_Divergence = 3.572123\n",
      "Epoch: 36\tFidelity = 0.501151\tKL_Divergence = 3.526430\n",
      "Epoch: 37\tFidelity = 0.501027\tKL_Divergence = 3.589687\n",
      "Epoch: 38\tFidelity = 0.501183\tKL_Divergence = 3.511103\n",
      "Epoch: 39\tFidelity = 0.500977\tKL_Divergence = 3.617046\n",
      "Epoch: 40\tFidelity = 0.501098\tKL_Divergence = 3.552243\n",
      "Epoch: 41\tFidelity = 0.501117\tKL_Divergence = 3.542870\n",
      "Epoch: 42\tFidelity = 0.501033\tKL_Divergence = 3.586598\n",
      "Epoch: 43\tFidelity = 0.501055\tKL_Divergence = 3.574757\n",
      "Epoch: 44\tFidelity = 0.501034\tKL_Divergence = 3.585749\n",
      "Epoch: 45\tFidelity = 0.500996\tKL_Divergence = 3.606885\n",
      "Epoch: 46\tFidelity = 0.501138\tKL_Divergence = 3.532614\n",
      "Epoch: 47\tFidelity = 0.500880\tKL_Divergence = 3.675185\n",
      "Epoch: 48\tFidelity = 0.501215\tKL_Divergence = 3.496450\n",
      "Epoch: 49\tFidelity = 0.500921\tKL_Divergence = 3.650135\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:09:13,722] Trial 349 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.501161\tKL_Divergence = 3.521556\n",
      "Total time elapsed during training: 31.749 s\n",
      "Trial 349 pruned. \n",
      "Epoch: 1\tFidelity = 0.500947\tKL_Divergence = 3.634654\n",
      "Epoch: 2\tFidelity = 0.500977\tKL_Divergence = 3.617064\n",
      "Epoch: 3\tFidelity = 0.500927\tKL_Divergence = 3.646375\n",
      "Epoch: 4\tFidelity = 0.501135\tKL_Divergence = 3.534190\n",
      "Epoch: 5\tFidelity = 0.501040\tKL_Divergence = 3.582369\n",
      "Epoch: 6\tFidelity = 0.501058\tKL_Divergence = 3.573290\n",
      "Epoch: 7\tFidelity = 0.501094\tKL_Divergence = 3.554475\n",
      "Epoch: 8\tFidelity = 0.500988\tKL_Divergence = 3.611352\n",
      "Epoch: 9\tFidelity = 0.501080\tKL_Divergence = 3.561740\n",
      "Epoch: 10\tFidelity = 0.501075\tKL_Divergence = 3.564180\n",
      "Epoch: 11\tFidelity = 0.501159\tKL_Divergence = 3.522422\n",
      "Epoch: 12\tFidelity = 0.501060\tKL_Divergence = 3.571865\n",
      "Epoch: 13\tFidelity = 0.501074\tKL_Divergence = 3.564611\n",
      "Epoch: 14\tFidelity = 0.501095\tKL_Divergence = 3.553786\n",
      "Epoch: 15\tFidelity = 0.500986\tKL_Divergence = 3.612430\n",
      "Epoch: 16\tFidelity = 0.500932\tKL_Divergence = 3.643245\n",
      "Epoch: 17\tFidelity = 0.501089\tKL_Divergence = 3.557151\n",
      "Epoch: 18\tFidelity = 0.501234\tKL_Divergence = 3.487668\n",
      "Epoch: 19\tFidelity = 0.500974\tKL_Divergence = 3.618840\n",
      "Epoch: 20\tFidelity = 0.501120\tKL_Divergence = 3.541626\n",
      "Epoch: 21\tFidelity = 0.500990\tKL_Divergence = 3.610123\n",
      "Epoch: 22\tFidelity = 0.500945\tKL_Divergence = 3.635940\n",
      "Epoch: 23\tFidelity = 0.501137\tKL_Divergence = 3.533074\n",
      "Epoch: 24\tFidelity = 0.500970\tKL_Divergence = 3.621289\n",
      "Epoch: 25\tFidelity = 0.501019\tKL_Divergence = 3.593820\n",
      "Epoch: 26\tFidelity = 0.501058\tKL_Divergence = 3.573271\n",
      "Epoch: 27\tFidelity = 0.501062\tKL_Divergence = 3.570852\n",
      "Epoch: 28\tFidelity = 0.501083\tKL_Divergence = 3.560219\n",
      "Epoch: 29\tFidelity = 0.500953\tKL_Divergence = 3.630973\n",
      "Epoch: 30\tFidelity = 0.501032\tKL_Divergence = 3.587006\n",
      "Epoch: 31\tFidelity = 0.500986\tKL_Divergence = 3.612258\n",
      "Epoch: 32\tFidelity = 0.501116\tKL_Divergence = 3.543387\n",
      "Epoch: 33\tFidelity = 0.501118\tKL_Divergence = 3.542403\n",
      "Epoch: 34\tFidelity = 0.500930\tKL_Divergence = 3.644457\n",
      "Epoch: 35\tFidelity = 0.500988\tKL_Divergence = 3.610908\n",
      "Epoch: 36\tFidelity = 0.501021\tKL_Divergence = 3.592450\n",
      "Epoch: 37\tFidelity = 0.501091\tKL_Divergence = 3.555435\n",
      "Epoch: 38\tFidelity = 0.501041\tKL_Divergence = 3.581819\n",
      "Epoch: 39\tFidelity = 0.501139\tKL_Divergence = 3.531893\n",
      "Epoch: 40\tFidelity = 0.501097\tKL_Divergence = 3.552854\n",
      "Epoch: 41\tFidelity = 0.501075\tKL_Divergence = 3.563950\n",
      "Epoch: 42\tFidelity = 0.501056\tKL_Divergence = 3.573875\n",
      "Epoch: 43\tFidelity = 0.500916\tKL_Divergence = 3.652852\n",
      "Epoch: 44\tFidelity = 0.500908\tKL_Divergence = 3.657697\n",
      "Epoch: 45\tFidelity = 0.500930\tKL_Divergence = 3.644690\n",
      "Epoch: 46\tFidelity = 0.500925\tKL_Divergence = 3.647714\n",
      "Epoch: 47\tFidelity = 0.500944\tKL_Divergence = 3.636294\n",
      "Epoch: 48\tFidelity = 0.501155\tKL_Divergence = 3.524170\n",
      "Epoch: 49\tFidelity = 0.501027\tKL_Divergence = 3.589806\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:09:51,963] Trial 350 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.501028\tKL_Divergence = 3.589282\n",
      "Total time elapsed during training: 38.078 s\n",
      "Trial 350 pruned. \n",
      "Epoch: 1\tFidelity = 0.501016\tKL_Divergence = 3.595488\n",
      "Epoch: 2\tFidelity = 0.500957\tKL_Divergence = 3.628627\n",
      "Epoch: 3\tFidelity = 0.501069\tKL_Divergence = 3.567175\n",
      "Epoch: 4\tFidelity = 0.501003\tKL_Divergence = 3.602699\n",
      "Epoch: 5\tFidelity = 0.501077\tKL_Divergence = 3.563283\n",
      "Epoch: 6\tFidelity = 0.501016\tKL_Divergence = 3.595787\n",
      "Epoch: 7\tFidelity = 0.501000\tKL_Divergence = 3.604454\n",
      "Epoch: 8\tFidelity = 0.501054\tKL_Divergence = 3.575350\n",
      "Epoch: 9\tFidelity = 0.500965\tKL_Divergence = 3.624409\n",
      "Epoch: 10\tFidelity = 0.501026\tKL_Divergence = 3.590365\n",
      "Epoch: 11\tFidelity = 0.500925\tKL_Divergence = 3.647885\n",
      "Epoch: 12\tFidelity = 0.501125\tKL_Divergence = 3.539013\n",
      "Epoch: 13\tFidelity = 0.500956\tKL_Divergence = 3.629229\n",
      "Epoch: 14\tFidelity = 0.501074\tKL_Divergence = 3.564535\n",
      "Epoch: 15\tFidelity = 0.501050\tKL_Divergence = 3.577064\n",
      "Epoch: 16\tFidelity = 0.501048\tKL_Divergence = 3.578669\n",
      "Epoch: 17\tFidelity = 0.501004\tKL_Divergence = 3.602192\n",
      "Epoch: 18\tFidelity = 0.501116\tKL_Divergence = 3.543299\n",
      "Epoch: 19\tFidelity = 0.501001\tKL_Divergence = 3.604029\n",
      "Epoch: 20\tFidelity = 0.500991\tKL_Divergence = 3.609448\n",
      "Epoch: 21\tFidelity = 0.501015\tKL_Divergence = 3.596345\n",
      "Epoch: 22\tFidelity = 0.501108\tKL_Divergence = 3.547378\n",
      "Epoch: 23\tFidelity = 0.501096\tKL_Divergence = 3.553451\n",
      "Epoch: 24\tFidelity = 0.501013\tKL_Divergence = 3.596966\n",
      "Epoch: 25\tFidelity = 0.501159\tKL_Divergence = 3.522430\n",
      "Epoch: 26\tFidelity = 0.501119\tKL_Divergence = 3.541759\n",
      "Epoch: 27\tFidelity = 0.501129\tKL_Divergence = 3.537230\n",
      "Epoch: 28\tFidelity = 0.501040\tKL_Divergence = 3.582829\n",
      "Epoch: 29\tFidelity = 0.501156\tKL_Divergence = 3.523958\n",
      "Epoch: 30\tFidelity = 0.501088\tKL_Divergence = 3.557424\n",
      "Epoch: 31\tFidelity = 0.500908\tKL_Divergence = 3.657942\n",
      "Epoch: 32\tFidelity = 0.500919\tKL_Divergence = 3.651243\n",
      "Epoch: 33\tFidelity = 0.501024\tKL_Divergence = 3.591286\n",
      "Epoch: 34\tFidelity = 0.501021\tKL_Divergence = 3.592711\n",
      "Epoch: 35\tFidelity = 0.500986\tKL_Divergence = 3.612205\n",
      "Epoch: 36\tFidelity = 0.501050\tKL_Divergence = 3.577386\n",
      "Epoch: 37\tFidelity = 0.501022\tKL_Divergence = 3.592159\n",
      "Epoch: 38\tFidelity = 0.501010\tKL_Divergence = 3.598828\n",
      "Epoch: 39\tFidelity = 0.501184\tKL_Divergence = 3.510333\n",
      "Epoch: 40\tFidelity = 0.501007\tKL_Divergence = 3.600350\n",
      "Epoch: 41\tFidelity = 0.501157\tKL_Divergence = 3.523184\n",
      "Epoch: 42\tFidelity = 0.501079\tKL_Divergence = 3.562340\n",
      "Epoch: 43\tFidelity = 0.501040\tKL_Divergence = 3.582787\n",
      "Epoch: 44\tFidelity = 0.501127\tKL_Divergence = 3.537902\n",
      "Epoch: 45\tFidelity = 0.501100\tKL_Divergence = 3.551672\n",
      "Epoch: 46\tFidelity = 0.501044\tKL_Divergence = 3.580236\n",
      "Epoch: 47\tFidelity = 0.501011\tKL_Divergence = 3.598343\n",
      "Epoch: 48\tFidelity = 0.501111\tKL_Divergence = 3.545872\n",
      "Epoch: 49\tFidelity = 0.501097\tKL_Divergence = 3.553229\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:10:37,537] Trial 351 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.501155\tKL_Divergence = 3.524174\n",
      "Total time elapsed during training: 45.376 s\n",
      "Trial 351 pruned. \n",
      "Epoch: 1\tFidelity = 0.500877\tKL_Divergence = 3.677291\n",
      "Epoch: 2\tFidelity = 0.500936\tKL_Divergence = 3.640652\n",
      "Epoch: 3\tFidelity = 0.501055\tKL_Divergence = 3.574145\n",
      "Epoch: 4\tFidelity = 0.501125\tKL_Divergence = 3.538594\n",
      "Epoch: 5\tFidelity = 0.501203\tKL_Divergence = 3.501385\n",
      "Epoch: 6\tFidelity = 0.500908\tKL_Divergence = 3.657220\n",
      "Epoch: 7\tFidelity = 0.500812\tKL_Divergence = 3.719928\n",
      "Epoch: 8\tFidelity = 0.500959\tKL_Divergence = 3.627510\n",
      "Epoch: 9\tFidelity = 0.500972\tKL_Divergence = 3.620085\n",
      "Epoch: 10\tFidelity = 0.501167\tKL_Divergence = 3.518869\n",
      "Epoch: 11\tFidelity = 0.500831\tKL_Divergence = 3.707496\n",
      "Epoch: 12\tFidelity = 0.500992\tKL_Divergence = 3.608931\n",
      "Epoch: 13\tFidelity = 0.501024\tKL_Divergence = 3.591275\n",
      "Epoch: 14\tFidelity = 0.501215\tKL_Divergence = 3.496101\n",
      "Epoch: 15\tFidelity = 0.501024\tKL_Divergence = 3.591121\n",
      "Epoch: 16\tFidelity = 0.500939\tKL_Divergence = 3.639370\n",
      "Epoch: 17\tFidelity = 0.500953\tKL_Divergence = 3.631232\n",
      "Epoch: 18\tFidelity = 0.501162\tKL_Divergence = 3.521051\n",
      "Epoch: 19\tFidelity = 0.501196\tKL_Divergence = 3.505125\n",
      "Epoch: 20\tFidelity = 0.501141\tKL_Divergence = 3.531217\n",
      "Epoch: 21\tFidelity = 0.500949\tKL_Divergence = 3.633693\n",
      "Epoch: 22\tFidelity = 0.501078\tKL_Divergence = 3.562840\n",
      "Epoch: 23\tFidelity = 0.500942\tKL_Divergence = 3.637448\n",
      "Epoch: 24\tFidelity = 0.500843\tKL_Divergence = 3.698916\n",
      "Epoch: 25\tFidelity = 0.500864\tKL_Divergence = 3.685486\n",
      "Epoch: 26\tFidelity = 0.501162\tKL_Divergence = 3.520909\n",
      "Epoch: 27\tFidelity = 0.500990\tKL_Divergence = 3.610123\n",
      "Epoch: 28\tFidelity = 0.500838\tKL_Divergence = 3.702252\n",
      "Epoch: 29\tFidelity = 0.501126\tKL_Divergence = 3.538486\n",
      "Epoch: 30\tFidelity = 0.501099\tKL_Divergence = 3.551859\n",
      "Epoch: 31\tFidelity = 0.501316\tKL_Divergence = 3.451807\n",
      "Epoch: 32\tFidelity = 0.501074\tKL_Divergence = 3.564565\n",
      "Epoch: 33\tFidelity = 0.501009\tKL_Divergence = 3.599470\n",
      "Epoch: 34\tFidelity = 0.501068\tKL_Divergence = 3.567489\n",
      "Epoch: 35\tFidelity = 0.500896\tKL_Divergence = 3.665410\n",
      "Epoch: 36\tFidelity = 0.501256\tKL_Divergence = 3.477544\n",
      "Epoch: 37\tFidelity = 0.501082\tKL_Divergence = 3.560566\n",
      "Epoch: 38\tFidelity = 0.500941\tKL_Divergence = 3.638252\n",
      "Epoch: 39\tFidelity = 0.501032\tKL_Divergence = 3.586986\n",
      "Epoch: 40\tFidelity = 0.500976\tKL_Divergence = 3.618123\n",
      "Epoch: 41\tFidelity = 0.500922\tKL_Divergence = 3.649618\n",
      "Epoch: 42\tFidelity = 0.501096\tKL_Divergence = 3.553140\n",
      "Epoch: 43\tFidelity = 0.500967\tKL_Divergence = 3.622938\n",
      "Epoch: 44\tFidelity = 0.500901\tKL_Divergence = 3.662327\n",
      "Epoch: 45\tFidelity = 0.500889\tKL_Divergence = 3.669514\n",
      "Epoch: 46\tFidelity = 0.501020\tKL_Divergence = 3.593216\n",
      "Epoch: 47\tFidelity = 0.500906\tKL_Divergence = 3.658762\n",
      "Epoch: 48\tFidelity = 0.500930\tKL_Divergence = 3.644267\n",
      "Epoch: 49\tFidelity = 0.501135\tKL_Divergence = 3.533298\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:11:34,999] Trial 352 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500890\tKL_Divergence = 3.668478\n",
      "Total time elapsed during training: 57.291 s\n",
      "Trial 352 pruned. \n",
      "Epoch: 1\tFidelity = 0.500891\tKL_Divergence = 3.668097\n",
      "Epoch: 2\tFidelity = 0.501020\tKL_Divergence = 3.593193\n",
      "Epoch: 3\tFidelity = 0.500979\tKL_Divergence = 3.615798\n",
      "Epoch: 4\tFidelity = 0.501011\tKL_Divergence = 3.597920\n",
      "Epoch: 5\tFidelity = 0.501062\tKL_Divergence = 3.570645\n",
      "Epoch: 6\tFidelity = 0.500987\tKL_Divergence = 3.611559\n",
      "Epoch: 7\tFidelity = 0.501051\tKL_Divergence = 3.576233\n",
      "Epoch: 8\tFidelity = 0.501119\tKL_Divergence = 3.541529\n",
      "Epoch: 9\tFidelity = 0.501072\tKL_Divergence = 3.565807\n",
      "Epoch: 10\tFidelity = 0.501083\tKL_Divergence = 3.560058\n",
      "Epoch: 11\tFidelity = 0.501122\tKL_Divergence = 3.540300\n",
      "Epoch: 12\tFidelity = 0.501067\tKL_Divergence = 3.568186\n",
      "Epoch: 13\tFidelity = 0.501068\tKL_Divergence = 3.567773\n",
      "Epoch: 14\tFidelity = 0.501039\tKL_Divergence = 3.583123\n",
      "Epoch: 15\tFidelity = 0.501025\tKL_Divergence = 3.590471\n",
      "Epoch: 16\tFidelity = 0.500900\tKL_Divergence = 3.662823\n",
      "Epoch: 17\tFidelity = 0.501106\tKL_Divergence = 3.548348\n",
      "Epoch: 18\tFidelity = 0.501028\tKL_Divergence = 3.588965\n",
      "Epoch: 19\tFidelity = 0.501018\tKL_Divergence = 3.594514\n",
      "Epoch: 20\tFidelity = 0.501147\tKL_Divergence = 3.528255\n",
      "Epoch: 21\tFidelity = 0.500966\tKL_Divergence = 3.623686\n",
      "Epoch: 22\tFidelity = 0.501011\tKL_Divergence = 3.598204\n",
      "Epoch: 23\tFidelity = 0.500962\tKL_Divergence = 3.625618\n",
      "Epoch: 24\tFidelity = 0.500888\tKL_Divergence = 3.670393\n",
      "Epoch: 25\tFidelity = 0.501058\tKL_Divergence = 3.573051\n",
      "Epoch: 26\tFidelity = 0.500990\tKL_Divergence = 3.609862\n",
      "Epoch: 27\tFidelity = 0.501075\tKL_Divergence = 3.563997\n",
      "Epoch: 28\tFidelity = 0.500946\tKL_Divergence = 3.635140\n",
      "Epoch: 29\tFidelity = 0.501082\tKL_Divergence = 3.560231\n",
      "Epoch: 30\tFidelity = 0.501142\tKL_Divergence = 3.530274\n",
      "Epoch: 31\tFidelity = 0.501048\tKL_Divergence = 3.578078\n",
      "Epoch: 32\tFidelity = 0.500920\tKL_Divergence = 3.650680\n",
      "Epoch: 33\tFidelity = 0.501076\tKL_Divergence = 3.563280\n",
      "Epoch: 34\tFidelity = 0.501022\tKL_Divergence = 3.592108\n",
      "Epoch: 35\tFidelity = 0.501050\tKL_Divergence = 3.577139\n",
      "Epoch: 36\tFidelity = 0.500982\tKL_Divergence = 3.614041\n",
      "Epoch: 37\tFidelity = 0.501101\tKL_Divergence = 3.550804\n",
      "Epoch: 38\tFidelity = 0.501062\tKL_Divergence = 3.570597\n",
      "Epoch: 39\tFidelity = 0.501157\tKL_Divergence = 3.523229\n",
      "Epoch: 40\tFidelity = 0.501034\tKL_Divergence = 3.585391\n",
      "Epoch: 41\tFidelity = 0.500988\tKL_Divergence = 3.610789\n",
      "Epoch: 42\tFidelity = 0.500973\tKL_Divergence = 3.619354\n",
      "Epoch: 43\tFidelity = 0.501093\tKL_Divergence = 3.554853\n",
      "Epoch: 44\tFidelity = 0.501049\tKL_Divergence = 3.577682\n",
      "Epoch: 45\tFidelity = 0.500972\tKL_Divergence = 3.619832\n",
      "Epoch: 46\tFidelity = 0.501023\tKL_Divergence = 3.591554\n",
      "Epoch: 47\tFidelity = 0.501059\tKL_Divergence = 3.572288\n",
      "Epoch: 48\tFidelity = 0.500978\tKL_Divergence = 3.616481\n",
      "Epoch: 49\tFidelity = 0.501046\tKL_Divergence = 3.579410\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:12:12,843] Trial 353 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.501130\tKL_Divergence = 3.536320\n",
      "Total time elapsed during training: 37.681 s\n",
      "Trial 353 pruned. \n",
      "Epoch: 1\tFidelity = 0.500837\tKL_Divergence = 3.703367\n",
      "Epoch: 2\tFidelity = 0.500891\tKL_Divergence = 3.668501\n",
      "Epoch: 3\tFidelity = 0.500804\tKL_Divergence = 3.725107\n",
      "Epoch: 4\tFidelity = 0.500805\tKL_Divergence = 3.725143\n",
      "Epoch: 5\tFidelity = 0.501255\tKL_Divergence = 3.478244\n",
      "Epoch: 6\tFidelity = 0.501048\tKL_Divergence = 3.577903\n",
      "Epoch: 7\tFidelity = 0.500853\tKL_Divergence = 3.692644\n",
      "Epoch: 8\tFidelity = 0.500864\tKL_Divergence = 3.685196\n",
      "Epoch: 9\tFidelity = 0.500883\tKL_Divergence = 3.673659\n",
      "Epoch: 10\tFidelity = 0.500857\tKL_Divergence = 3.690177\n",
      "Epoch: 11\tFidelity = 0.500934\tKL_Divergence = 3.642007\n",
      "Epoch: 12\tFidelity = 0.501341\tKL_Divergence = 3.441327\n",
      "Epoch: 13\tFidelity = 0.500899\tKL_Divergence = 3.663207\n",
      "Epoch: 14\tFidelity = 0.500839\tKL_Divergence = 3.701722\n",
      "Epoch: 15\tFidelity = 0.500946\tKL_Divergence = 3.635083\n",
      "Epoch: 16\tFidelity = 0.501014\tKL_Divergence = 3.596963\n",
      "Epoch: 17\tFidelity = 0.501043\tKL_Divergence = 3.581267\n",
      "Epoch: 18\tFidelity = 0.501178\tKL_Divergence = 3.513266\n",
      "Epoch: 19\tFidelity = 0.501072\tKL_Divergence = 3.565694\n",
      "Epoch: 20\tFidelity = 0.500875\tKL_Divergence = 3.678884\n",
      "Epoch: 21\tFidelity = 0.500963\tKL_Divergence = 3.625370\n",
      "Epoch: 22\tFidelity = 0.500935\tKL_Divergence = 3.641506\n",
      "Epoch: 23\tFidelity = 0.501013\tKL_Divergence = 3.597575\n",
      "Epoch: 24\tFidelity = 0.501015\tKL_Divergence = 3.596443\n",
      "Epoch: 25\tFidelity = 0.501093\tKL_Divergence = 3.554819\n",
      "Epoch: 26\tFidelity = 0.500800\tKL_Divergence = 3.728126\n",
      "Epoch: 27\tFidelity = 0.500999\tKL_Divergence = 3.604649\n",
      "Epoch: 28\tFidelity = 0.500823\tKL_Divergence = 3.712313\n",
      "Epoch: 29\tFidelity = 0.500938\tKL_Divergence = 3.640021\n",
      "Epoch: 30\tFidelity = 0.500983\tKL_Divergence = 3.613697\n",
      "Epoch: 31\tFidelity = 0.500883\tKL_Divergence = 3.673726\n",
      "Epoch: 32\tFidelity = 0.500994\tKL_Divergence = 3.607663\n",
      "Epoch: 33\tFidelity = 0.501143\tKL_Divergence = 3.530101\n",
      "Epoch: 34\tFidelity = 0.501159\tKL_Divergence = 3.522633\n",
      "Epoch: 35\tFidelity = 0.500876\tKL_Divergence = 3.677973\n",
      "Epoch: 36\tFidelity = 0.500945\tKL_Divergence = 3.635712\n",
      "Epoch: 37\tFidelity = 0.500901\tKL_Divergence = 3.662196\n",
      "Epoch: 38\tFidelity = 0.500876\tKL_Divergence = 3.678263\n",
      "Epoch: 39\tFidelity = 0.500892\tKL_Divergence = 3.667781\n",
      "Epoch: 40\tFidelity = 0.500827\tKL_Divergence = 3.709860\n",
      "Epoch: 41\tFidelity = 0.500863\tKL_Divergence = 3.686204\n",
      "Epoch: 42\tFidelity = 0.500935\tKL_Divergence = 3.641968\n",
      "Epoch: 43\tFidelity = 0.501038\tKL_Divergence = 3.583635\n",
      "Epoch: 44\tFidelity = 0.500752\tKL_Divergence = 3.762397\n",
      "Epoch: 45\tFidelity = 0.500844\tKL_Divergence = 3.698421\n",
      "Epoch: 46\tFidelity = 0.500885\tKL_Divergence = 3.672492\n",
      "Epoch: 47\tFidelity = 0.500802\tKL_Divergence = 3.726707\n",
      "Epoch: 48\tFidelity = 0.500952\tKL_Divergence = 3.631747\n",
      "Epoch: 49\tFidelity = 0.500922\tKL_Divergence = 3.649203\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:13:32,826] Trial 354 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.501043\tKL_Divergence = 3.580762\n",
      "Total time elapsed during training: 79.824 s\n",
      "Trial 354 pruned. \n",
      "Epoch: 1\tFidelity = 0.500915\tKL_Divergence = 3.653666\n",
      "Epoch: 2\tFidelity = 0.500909\tKL_Divergence = 3.657530\n",
      "Epoch: 3\tFidelity = 0.500884\tKL_Divergence = 3.672913\n",
      "Epoch: 4\tFidelity = 0.500859\tKL_Divergence = 3.688837\n",
      "Epoch: 5\tFidelity = 0.500875\tKL_Divergence = 3.678524\n",
      "Epoch: 6\tFidelity = 0.500853\tKL_Divergence = 3.693014\n",
      "Epoch: 7\tFidelity = 0.500840\tKL_Divergence = 3.701209\n",
      "Epoch: 8\tFidelity = 0.500862\tKL_Divergence = 3.686934\n",
      "Epoch: 9\tFidelity = 0.500808\tKL_Divergence = 3.722695\n",
      "Epoch: 10\tFidelity = 0.500863\tKL_Divergence = 3.686420\n",
      "Epoch: 11\tFidelity = 0.500826\tKL_Divergence = 3.710814\n",
      "Epoch: 12\tFidelity = 0.500787\tKL_Divergence = 3.737152\n",
      "Epoch: 13\tFidelity = 0.500841\tKL_Divergence = 3.700908\n",
      "Epoch: 14\tFidelity = 0.500834\tKL_Divergence = 3.704930\n",
      "Epoch: 15\tFidelity = 0.500830\tKL_Divergence = 3.707609\n",
      "Epoch: 16\tFidelity = 0.500826\tKL_Divergence = 3.710332\n",
      "Epoch: 17\tFidelity = 0.500824\tKL_Divergence = 3.711884\n",
      "Epoch: 18\tFidelity = 0.500802\tKL_Divergence = 3.726968\n",
      "Epoch: 19\tFidelity = 0.500845\tKL_Divergence = 3.697903\n",
      "Epoch: 20\tFidelity = 0.500814\tKL_Divergence = 3.718729\n",
      "Epoch: 21\tFidelity = 0.500817\tKL_Divergence = 3.716845\n",
      "Epoch: 22\tFidelity = 0.500801\tKL_Divergence = 3.727622\n",
      "Epoch: 23\tFidelity = 0.500849\tKL_Divergence = 3.695228\n",
      "Epoch: 24\tFidelity = 0.500816\tKL_Divergence = 3.717644\n",
      "Epoch: 25\tFidelity = 0.500825\tKL_Divergence = 3.711086\n",
      "Epoch: 26\tFidelity = 0.500845\tKL_Divergence = 3.698125\n",
      "Epoch: 27\tFidelity = 0.500779\tKL_Divergence = 3.743178\n",
      "Epoch: 28\tFidelity = 0.500808\tKL_Divergence = 3.722668\n",
      "Epoch: 29\tFidelity = 0.500814\tKL_Divergence = 3.718923\n",
      "Epoch: 30\tFidelity = 0.500778\tKL_Divergence = 3.744143\n",
      "Epoch: 31\tFidelity = 0.500824\tKL_Divergence = 3.711759\n",
      "Epoch: 32\tFidelity = 0.500808\tKL_Divergence = 3.722708\n",
      "Epoch: 33\tFidelity = 0.500824\tKL_Divergence = 3.712187\n",
      "Epoch: 34\tFidelity = 0.500825\tKL_Divergence = 3.711484\n",
      "Epoch: 35\tFidelity = 0.500864\tKL_Divergence = 3.685756\n",
      "Epoch: 36\tFidelity = 0.500834\tKL_Divergence = 3.705369\n",
      "Epoch: 37\tFidelity = 0.500832\tKL_Divergence = 3.706471\n",
      "Epoch: 38\tFidelity = 0.500792\tKL_Divergence = 3.733865\n",
      "Epoch: 39\tFidelity = 0.500846\tKL_Divergence = 3.697567\n",
      "Epoch: 40\tFidelity = 0.500751\tKL_Divergence = 3.763694\n",
      "Epoch: 41\tFidelity = 0.500774\tKL_Divergence = 3.747074\n",
      "Epoch: 42\tFidelity = 0.500787\tKL_Divergence = 3.737230\n",
      "Epoch: 43\tFidelity = 0.500787\tKL_Divergence = 3.737499\n",
      "Epoch: 44\tFidelity = 0.500789\tKL_Divergence = 3.736059\n",
      "Epoch: 45\tFidelity = 0.500821\tKL_Divergence = 3.714036\n",
      "Epoch: 46\tFidelity = 0.500855\tKL_Divergence = 3.691486\n",
      "Epoch: 47\tFidelity = 0.500864\tKL_Divergence = 3.685616\n",
      "Epoch: 48\tFidelity = 0.500784\tKL_Divergence = 3.739453\n",
      "Epoch: 49\tFidelity = 0.500840\tKL_Divergence = 3.701239\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:14:10,326] Trial 355 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500814\tKL_Divergence = 3.719002\n",
      "Total time elapsed during training: 37.321 s\n",
      "Trial 355 pruned. \n",
      "Epoch: 1\tFidelity = 0.500965\tKL_Divergence = 3.624060\n",
      "Epoch: 2\tFidelity = 0.500739\tKL_Divergence = 3.772304\n",
      "Epoch: 3\tFidelity = 0.500712\tKL_Divergence = 3.792763\n",
      "Epoch: 4\tFidelity = 0.500689\tKL_Divergence = 3.811606\n",
      "Epoch: 5\tFidelity = 0.500738\tKL_Divergence = 3.773573\n",
      "Epoch: 6\tFidelity = 0.500863\tKL_Divergence = 3.686014\n",
      "Epoch: 7\tFidelity = 0.500769\tKL_Divergence = 3.750510\n",
      "Epoch: 8\tFidelity = 0.500847\tKL_Divergence = 3.696679\n",
      "Epoch: 9\tFidelity = 0.500714\tKL_Divergence = 3.791569\n",
      "Epoch: 10\tFidelity = 0.500886\tKL_Divergence = 3.671022\n",
      "Epoch: 11\tFidelity = 0.500756\tKL_Divergence = 3.759118\n",
      "Epoch: 12\tFidelity = 0.500725\tKL_Divergence = 3.782383\n",
      "Epoch: 13\tFidelity = 0.500747\tKL_Divergence = 3.765440\n",
      "Epoch: 14\tFidelity = 0.500765\tKL_Divergence = 3.752863\n",
      "Epoch: 15\tFidelity = 0.500766\tKL_Divergence = 3.751990\n",
      "Epoch: 16\tFidelity = 0.500876\tKL_Divergence = 3.677630\n",
      "Epoch: 17\tFidelity = 0.500792\tKL_Divergence = 3.733694\n",
      "Epoch: 18\tFidelity = 0.500694\tKL_Divergence = 3.806569\n",
      "Epoch: 19\tFidelity = 0.500725\tKL_Divergence = 3.782680\n",
      "Epoch: 20\tFidelity = 0.500840\tKL_Divergence = 3.700710\n",
      "Epoch: 21\tFidelity = 0.500744\tKL_Divergence = 3.768270\n",
      "Epoch: 22\tFidelity = 0.500853\tKL_Divergence = 3.692694\n",
      "Epoch: 23\tFidelity = 0.500677\tKL_Divergence = 3.821402\n",
      "Epoch: 24\tFidelity = 0.500765\tKL_Divergence = 3.752802\n",
      "Epoch: 25\tFidelity = 0.500712\tKL_Divergence = 3.793188\n",
      "Epoch: 26\tFidelity = 0.500696\tKL_Divergence = 3.805486\n",
      "Epoch: 27\tFidelity = 0.500831\tKL_Divergence = 3.707292\n",
      "Epoch: 28\tFidelity = 0.500797\tKL_Divergence = 3.730368\n",
      "Epoch: 29\tFidelity = 0.500809\tKL_Divergence = 3.721649\n",
      "Epoch: 30\tFidelity = 0.500703\tKL_Divergence = 3.799474\n",
      "Epoch: 31\tFidelity = 0.500783\tKL_Divergence = 3.740289\n",
      "Epoch: 32\tFidelity = 0.500743\tKL_Divergence = 3.769404\n",
      "Epoch: 33\tFidelity = 0.500779\tKL_Divergence = 3.743333\n",
      "Epoch: 34\tFidelity = 0.500857\tKL_Divergence = 3.690087\n",
      "Epoch: 35\tFidelity = 0.500849\tKL_Divergence = 3.695052\n",
      "Epoch: 36\tFidelity = 0.500790\tKL_Divergence = 3.735582\n",
      "Epoch: 37\tFidelity = 0.500763\tKL_Divergence = 3.754757\n",
      "Epoch: 38\tFidelity = 0.500717\tKL_Divergence = 3.788892\n",
      "Epoch: 39\tFidelity = 0.500892\tKL_Divergence = 3.668097\n",
      "Epoch: 40\tFidelity = 0.500789\tKL_Divergence = 3.735874\n",
      "Epoch: 41\tFidelity = 0.500689\tKL_Divergence = 3.811474\n",
      "Epoch: 42\tFidelity = 0.500684\tKL_Divergence = 3.815141\n",
      "Epoch: 43\tFidelity = 0.500635\tKL_Divergence = 3.855859\n",
      "Epoch: 44\tFidelity = 0.500798\tKL_Divergence = 3.729269\n",
      "Epoch: 45\tFidelity = 0.500889\tKL_Divergence = 3.669297\n",
      "Epoch: 46\tFidelity = 0.500794\tKL_Divergence = 3.732191\n",
      "Epoch: 47\tFidelity = 0.500661\tKL_Divergence = 3.833562\n",
      "Epoch: 48\tFidelity = 0.500759\tKL_Divergence = 3.757389\n",
      "Epoch: 49\tFidelity = 0.500861\tKL_Divergence = 3.687059\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:14:48,038] Trial 356 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500889\tKL_Divergence = 3.669411\n",
      "Total time elapsed during training: 37.545 s\n",
      "Trial 356 pruned. \n",
      "Epoch: 1\tFidelity = 0.500763\tKL_Divergence = 3.754137\n",
      "Epoch: 2\tFidelity = 0.500864\tKL_Divergence = 3.685540\n",
      "Epoch: 3\tFidelity = 0.500786\tKL_Divergence = 3.738032\n",
      "Epoch: 4\tFidelity = 0.500728\tKL_Divergence = 3.780642\n",
      "Epoch: 5\tFidelity = 0.500732\tKL_Divergence = 3.777674\n",
      "Epoch: 6\tFidelity = 0.500746\tKL_Divergence = 3.766820\n",
      "Epoch: 7\tFidelity = 0.500760\tKL_Divergence = 3.756544\n",
      "Epoch: 8\tFidelity = 0.500824\tKL_Divergence = 3.711738\n",
      "Epoch: 9\tFidelity = 0.500689\tKL_Divergence = 3.811009\n",
      "Epoch: 10\tFidelity = 0.500774\tKL_Divergence = 3.746622\n",
      "Epoch: 11\tFidelity = 0.500824\tKL_Divergence = 3.711963\n",
      "Epoch: 12\tFidelity = 0.500676\tKL_Divergence = 3.821570\n",
      "Epoch: 13\tFidelity = 0.500808\tKL_Divergence = 3.722860\n",
      "Epoch: 14\tFidelity = 0.500745\tKL_Divergence = 3.768148\n",
      "Epoch: 15\tFidelity = 0.500786\tKL_Divergence = 3.738259\n",
      "Epoch: 16\tFidelity = 0.500717\tKL_Divergence = 3.789282\n",
      "Epoch: 17\tFidelity = 0.500815\tKL_Divergence = 3.717843\n",
      "Epoch: 18\tFidelity = 0.500818\tKL_Divergence = 3.715775\n",
      "Epoch: 19\tFidelity = 0.500750\tKL_Divergence = 3.764475\n",
      "Epoch: 20\tFidelity = 0.500765\tKL_Divergence = 3.753430\n",
      "Epoch: 21\tFidelity = 0.500764\tKL_Divergence = 3.753724\n",
      "Epoch: 22\tFidelity = 0.500763\tKL_Divergence = 3.754585\n",
      "Epoch: 23\tFidelity = 0.500743\tKL_Divergence = 3.769500\n",
      "Epoch: 24\tFidelity = 0.500787\tKL_Divergence = 3.737181\n",
      "Epoch: 25\tFidelity = 0.500769\tKL_Divergence = 3.749947\n",
      "Epoch: 26\tFidelity = 0.500751\tKL_Divergence = 3.763218\n",
      "Epoch: 27\tFidelity = 0.500725\tKL_Divergence = 3.782755\n",
      "Epoch: 28\tFidelity = 0.500721\tKL_Divergence = 3.785874\n",
      "Epoch: 29\tFidelity = 0.500713\tKL_Divergence = 3.792352\n",
      "Epoch: 30\tFidelity = 0.500819\tKL_Divergence = 3.714990\n",
      "Epoch: 31\tFidelity = 0.500682\tKL_Divergence = 3.816864\n",
      "Epoch: 32\tFidelity = 0.500799\tKL_Divergence = 3.729171\n",
      "Epoch: 33\tFidelity = 0.500767\tKL_Divergence = 3.751764\n",
      "Epoch: 34\tFidelity = 0.500810\tKL_Divergence = 3.721078\n",
      "Epoch: 35\tFidelity = 0.500697\tKL_Divergence = 3.805007\n",
      "Epoch: 36\tFidelity = 0.500747\tKL_Divergence = 3.766725\n",
      "Epoch: 37\tFidelity = 0.500756\tKL_Divergence = 3.760066\n",
      "Epoch: 38\tFidelity = 0.500723\tKL_Divergence = 3.784771\n",
      "Epoch: 39\tFidelity = 0.500723\tKL_Divergence = 3.784451\n",
      "Epoch: 40\tFidelity = 0.500710\tKL_Divergence = 3.794570\n",
      "Epoch: 41\tFidelity = 0.500711\tKL_Divergence = 3.793788\n",
      "Epoch: 42\tFidelity = 0.500816\tKL_Divergence = 3.717616\n",
      "Epoch: 43\tFidelity = 0.500747\tKL_Divergence = 3.766253\n",
      "Epoch: 44\tFidelity = 0.500688\tKL_Divergence = 3.812386\n",
      "Epoch: 45\tFidelity = 0.500777\tKL_Divergence = 3.744281\n",
      "Epoch: 46\tFidelity = 0.500713\tKL_Divergence = 3.792566\n",
      "Epoch: 47\tFidelity = 0.500749\tKL_Divergence = 3.764688\n",
      "Epoch: 48\tFidelity = 0.500748\tKL_Divergence = 3.765783\n",
      "Epoch: 49\tFidelity = 0.500705\tKL_Divergence = 3.798534\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:15:34,224] Trial 357 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500722\tKL_Divergence = 3.785129\n",
      "Total time elapsed during training: 46.009 s\n",
      "Trial 357 pruned. \n",
      "Epoch: 1\tFidelity = 0.500692\tKL_Divergence = 3.808513\n",
      "Epoch: 2\tFidelity = 0.500831\tKL_Divergence = 3.707293\n",
      "Epoch: 3\tFidelity = 0.500728\tKL_Divergence = 3.780404\n",
      "Epoch: 4\tFidelity = 0.500723\tKL_Divergence = 3.784450\n",
      "Epoch: 5\tFidelity = 0.500671\tKL_Divergence = 3.825824\n",
      "Epoch: 6\tFidelity = 0.500892\tKL_Divergence = 3.667881\n",
      "Epoch: 7\tFidelity = 0.500844\tKL_Divergence = 3.698651\n",
      "Epoch: 8\tFidelity = 0.500836\tKL_Divergence = 3.703904\n",
      "Epoch: 9\tFidelity = 0.500859\tKL_Divergence = 3.688568\n",
      "Epoch: 10\tFidelity = 0.500731\tKL_Divergence = 3.778429\n",
      "Epoch: 11\tFidelity = 0.500600\tKL_Divergence = 3.887903\n",
      "Epoch: 12\tFidelity = 0.500837\tKL_Divergence = 3.703116\n",
      "Epoch: 13\tFidelity = 0.500761\tKL_Divergence = 3.755860\n",
      "Epoch: 14\tFidelity = 0.500798\tKL_Divergence = 3.729516\n",
      "Epoch: 15\tFidelity = 0.500706\tKL_Divergence = 3.797625\n",
      "Epoch: 16\tFidelity = 0.500658\tKL_Divergence = 3.836464\n",
      "Epoch: 17\tFidelity = 0.500689\tKL_Divergence = 3.811231\n",
      "Epoch: 18\tFidelity = 0.500729\tKL_Divergence = 3.779441\n",
      "Epoch: 19\tFidelity = 0.500750\tKL_Divergence = 3.764100\n",
      "Epoch: 20\tFidelity = 0.500667\tKL_Divergence = 3.828684\n",
      "Epoch: 21\tFidelity = 0.500643\tKL_Divergence = 3.849436\n",
      "Epoch: 22\tFidelity = 0.500637\tKL_Divergence = 3.854313\n",
      "Epoch: 23\tFidelity = 0.500804\tKL_Divergence = 3.725357\n",
      "Epoch: 24\tFidelity = 0.500606\tKL_Divergence = 3.882124\n",
      "Epoch: 25\tFidelity = 0.500673\tKL_Divergence = 3.823333\n",
      "Epoch: 26\tFidelity = 0.500630\tKL_Divergence = 3.860218\n",
      "Epoch: 27\tFidelity = 0.500714\tKL_Divergence = 3.790566\n",
      "Epoch: 28\tFidelity = 0.500650\tKL_Divergence = 3.843069\n",
      "Epoch: 29\tFidelity = 0.500729\tKL_Divergence = 3.779756\n",
      "Epoch: 30\tFidelity = 0.500803\tKL_Divergence = 3.725305\n",
      "Epoch: 31\tFidelity = 0.500746\tKL_Divergence = 3.766034\n",
      "Epoch: 32\tFidelity = 0.500798\tKL_Divergence = 3.728474\n",
      "Epoch: 33\tFidelity = 0.500716\tKL_Divergence = 3.789275\n",
      "Epoch: 34\tFidelity = 0.500706\tKL_Divergence = 3.797210\n",
      "Epoch: 35\tFidelity = 0.500710\tKL_Divergence = 3.794267\n",
      "Epoch: 36\tFidelity = 0.500794\tKL_Divergence = 3.732389\n",
      "Epoch: 37\tFidelity = 0.500576\tKL_Divergence = 3.911088\n",
      "Epoch: 38\tFidelity = 0.500709\tKL_Divergence = 3.795503\n",
      "Epoch: 39\tFidelity = 0.500604\tKL_Divergence = 3.884213\n",
      "Epoch: 40\tFidelity = 0.500749\tKL_Divergence = 3.764774\n",
      "Epoch: 41\tFidelity = 0.500676\tKL_Divergence = 3.821797\n",
      "Epoch: 42\tFidelity = 0.500662\tKL_Divergence = 3.833681\n",
      "Epoch: 43\tFidelity = 0.500830\tKL_Divergence = 3.707911\n",
      "Epoch: 44\tFidelity = 0.500746\tKL_Divergence = 3.767174\n",
      "Epoch: 45\tFidelity = 0.500606\tKL_Divergence = 3.882560\n",
      "Epoch: 46\tFidelity = 0.500609\tKL_Divergence = 3.879981\n",
      "Epoch: 47\tFidelity = 0.500674\tKL_Divergence = 3.823049\n",
      "Epoch: 48\tFidelity = 0.500761\tKL_Divergence = 3.755697\n",
      "Epoch: 49\tFidelity = 0.500709\tKL_Divergence = 3.795116\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:16:17,648] Trial 358 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500720\tKL_Divergence = 3.787123\n",
      "Total time elapsed during training: 43.254 s\n",
      "Trial 358 pruned. \n",
      "Epoch: 1\tFidelity = 0.500768\tKL_Divergence = 3.751173\n",
      "Epoch: 2\tFidelity = 0.500583\tKL_Divergence = 3.904456\n",
      "Epoch: 3\tFidelity = 0.500689\tKL_Divergence = 3.810902\n",
      "Epoch: 4\tFidelity = 0.500671\tKL_Divergence = 3.825973\n",
      "Epoch: 5\tFidelity = 0.500636\tKL_Divergence = 3.856083\n",
      "Epoch: 6\tFidelity = 0.500547\tKL_Divergence = 3.939968\n",
      "Epoch: 7\tFidelity = 0.500733\tKL_Divergence = 3.777074\n",
      "Epoch: 8\tFidelity = 0.500620\tKL_Divergence = 3.869793\n",
      "Epoch: 9\tFidelity = 0.500598\tKL_Divergence = 3.890374\n",
      "Epoch: 10\tFidelity = 0.500652\tKL_Divergence = 3.842019\n",
      "Epoch: 11\tFidelity = 0.500770\tKL_Divergence = 3.749144\n",
      "Epoch: 12\tFidelity = 0.500826\tKL_Divergence = 3.710690\n",
      "Epoch: 13\tFidelity = 0.500646\tKL_Divergence = 3.847253\n",
      "Epoch: 14\tFidelity = 0.500664\tKL_Divergence = 3.832052\n",
      "Epoch: 15\tFidelity = 0.500584\tKL_Divergence = 3.903199\n",
      "Epoch: 16\tFidelity = 0.500742\tKL_Divergence = 3.769785\n",
      "Epoch: 17\tFidelity = 0.500665\tKL_Divergence = 3.831026\n",
      "Epoch: 18\tFidelity = 0.500623\tKL_Divergence = 3.867594\n",
      "Epoch: 19\tFidelity = 0.500589\tKL_Divergence = 3.897981\n",
      "Epoch: 20\tFidelity = 0.500594\tKL_Divergence = 3.894102\n",
      "Epoch: 21\tFidelity = 0.500589\tKL_Divergence = 3.897985\n",
      "Epoch: 22\tFidelity = 0.500544\tKL_Divergence = 3.942902\n",
      "Epoch: 23\tFidelity = 0.500602\tKL_Divergence = 3.886541\n",
      "Epoch: 24\tFidelity = 0.500729\tKL_Divergence = 3.779630\n",
      "Epoch: 25\tFidelity = 0.500660\tKL_Divergence = 3.835454\n",
      "Epoch: 26\tFidelity = 0.500561\tKL_Divergence = 3.925597\n",
      "Epoch: 27\tFidelity = 0.500581\tKL_Divergence = 3.906100\n",
      "Epoch: 28\tFidelity = 0.500615\tKL_Divergence = 3.874193\n",
      "Epoch: 29\tFidelity = 0.500750\tKL_Divergence = 3.764388\n",
      "Epoch: 30\tFidelity = 0.500610\tKL_Divergence = 3.878931\n",
      "Epoch: 31\tFidelity = 0.500620\tKL_Divergence = 3.869657\n",
      "Epoch: 32\tFidelity = 0.500671\tKL_Divergence = 3.826310\n",
      "Epoch: 33\tFidelity = 0.500605\tKL_Divergence = 3.883980\n",
      "Epoch: 34\tFidelity = 0.500517\tKL_Divergence = 3.971069\n",
      "Epoch: 35\tFidelity = 0.500514\tKL_Divergence = 3.974398\n",
      "Epoch: 36\tFidelity = 0.500643\tKL_Divergence = 3.849329\n",
      "Epoch: 37\tFidelity = 0.500564\tKL_Divergence = 3.923026\n",
      "Epoch: 38\tFidelity = 0.500696\tKL_Divergence = 3.806026\n",
      "Epoch: 39\tFidelity = 0.500662\tKL_Divergence = 3.833762\n",
      "Epoch: 40\tFidelity = 0.500527\tKL_Divergence = 3.960163\n",
      "Epoch: 41\tFidelity = 0.500761\tKL_Divergence = 3.756403\n",
      "Epoch: 42\tFidelity = 0.500508\tKL_Divergence = 3.980749\n",
      "Epoch: 43\tFidelity = 0.500537\tKL_Divergence = 3.949544\n",
      "Epoch: 44\tFidelity = 0.500720\tKL_Divergence = 3.786659\n",
      "Epoch: 45\tFidelity = 0.500592\tKL_Divergence = 3.895414\n",
      "Epoch: 46\tFidelity = 0.500581\tKL_Divergence = 3.905670\n",
      "Epoch: 47\tFidelity = 0.500515\tKL_Divergence = 3.973192\n",
      "Epoch: 48\tFidelity = 0.500596\tKL_Divergence = 3.892190\n",
      "Epoch: 49\tFidelity = 0.500520\tKL_Divergence = 3.967331\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:17:37,357] Trial 359 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500606\tKL_Divergence = 3.882278\n",
      "Total time elapsed during training: 79.542 s\n",
      "Trial 359 pruned. \n",
      "Epoch: 1\tFidelity = 0.500561\tKL_Divergence = 3.926009\n",
      "Epoch: 2\tFidelity = 0.500600\tKL_Divergence = 3.888512\n",
      "Epoch: 3\tFidelity = 0.500573\tKL_Divergence = 3.914123\n",
      "Epoch: 4\tFidelity = 0.500615\tKL_Divergence = 3.874222\n",
      "Epoch: 5\tFidelity = 0.500648\tKL_Divergence = 3.845804\n",
      "Epoch: 6\tFidelity = 0.500637\tKL_Divergence = 3.854666\n",
      "Epoch: 7\tFidelity = 0.500671\tKL_Divergence = 3.826205\n",
      "Epoch: 8\tFidelity = 0.500711\tKL_Divergence = 3.793561\n",
      "Epoch: 9\tFidelity = 0.500646\tKL_Divergence = 3.847478\n",
      "Epoch: 10\tFidelity = 0.500589\tKL_Divergence = 3.898835\n",
      "Epoch: 11\tFidelity = 0.500542\tKL_Divergence = 3.945066\n",
      "Epoch: 12\tFidelity = 0.500595\tKL_Divergence = 3.893289\n",
      "Epoch: 13\tFidelity = 0.500551\tKL_Divergence = 3.935481\n",
      "Epoch: 14\tFidelity = 0.500562\tKL_Divergence = 3.924974\n",
      "Epoch: 15\tFidelity = 0.500619\tKL_Divergence = 3.871310\n",
      "Epoch: 16\tFidelity = 0.500610\tKL_Divergence = 3.878693\n",
      "Epoch: 17\tFidelity = 0.500649\tKL_Divergence = 3.844705\n",
      "Epoch: 18\tFidelity = 0.500583\tKL_Divergence = 3.904272\n",
      "Epoch: 19\tFidelity = 0.500569\tKL_Divergence = 3.917505\n",
      "Epoch: 20\tFidelity = 0.500519\tKL_Divergence = 3.968339\n",
      "Epoch: 21\tFidelity = 0.500559\tKL_Divergence = 3.927129\n",
      "Epoch: 22\tFidelity = 0.500599\tKL_Divergence = 3.888768\n",
      "Epoch: 23\tFidelity = 0.500622\tKL_Divergence = 3.868118\n",
      "Epoch: 24\tFidelity = 0.500605\tKL_Divergence = 3.883859\n",
      "Epoch: 25\tFidelity = 0.500649\tKL_Divergence = 3.844863\n",
      "Epoch: 26\tFidelity = 0.500585\tKL_Divergence = 3.902366\n",
      "Epoch: 27\tFidelity = 0.500629\tKL_Divergence = 3.862388\n",
      "Epoch: 28\tFidelity = 0.500585\tKL_Divergence = 3.902627\n",
      "Epoch: 29\tFidelity = 0.500640\tKL_Divergence = 3.852409\n",
      "Epoch: 30\tFidelity = 0.500569\tKL_Divergence = 3.917489\n",
      "Epoch: 31\tFidelity = 0.500539\tKL_Divergence = 3.948208\n",
      "Epoch: 32\tFidelity = 0.500519\tKL_Divergence = 3.968378\n",
      "Epoch: 33\tFidelity = 0.500586\tKL_Divergence = 3.900881\n",
      "Epoch: 34\tFidelity = 0.500629\tKL_Divergence = 3.862331\n",
      "Epoch: 35\tFidelity = 0.500643\tKL_Divergence = 3.849583\n",
      "Epoch: 36\tFidelity = 0.500616\tKL_Divergence = 3.873301\n",
      "Epoch: 37\tFidelity = 0.500623\tKL_Divergence = 3.866920\n",
      "Epoch: 38\tFidelity = 0.500587\tKL_Divergence = 3.900021\n",
      "Epoch: 39\tFidelity = 0.500606\tKL_Divergence = 3.882631\n",
      "Epoch: 40\tFidelity = 0.500552\tKL_Divergence = 3.934649\n",
      "Epoch: 41\tFidelity = 0.500572\tKL_Divergence = 3.914400\n",
      "Epoch: 42\tFidelity = 0.500634\tKL_Divergence = 3.857608\n",
      "Epoch: 43\tFidelity = 0.500585\tKL_Divergence = 3.902652\n",
      "Epoch: 44\tFidelity = 0.500514\tKL_Divergence = 3.974587\n",
      "Epoch: 45\tFidelity = 0.500578\tKL_Divergence = 3.908822\n",
      "Epoch: 46\tFidelity = 0.500552\tKL_Divergence = 3.934775\n",
      "Epoch: 47\tFidelity = 0.500540\tKL_Divergence = 3.946639\n",
      "Epoch: 48\tFidelity = 0.500579\tKL_Divergence = 3.908388\n",
      "Epoch: 49\tFidelity = 0.500591\tKL_Divergence = 3.896963\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:18:09,584] Trial 360 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500594\tKL_Divergence = 3.894087\n",
      "Total time elapsed during training: 32.066 s\n",
      "Trial 360 pruned. \n",
      "Epoch: 1\tFidelity = 0.500655\tKL_Divergence = 3.839773\n",
      "Epoch: 2\tFidelity = 0.500578\tKL_Divergence = 3.908604\n",
      "Epoch: 3\tFidelity = 0.500607\tKL_Divergence = 3.881648\n",
      "Epoch: 4\tFidelity = 0.500567\tKL_Divergence = 3.919212\n",
      "Epoch: 5\tFidelity = 0.500593\tKL_Divergence = 3.895148\n",
      "Epoch: 6\tFidelity = 0.500612\tKL_Divergence = 3.877110\n",
      "Epoch: 7\tFidelity = 0.500559\tKL_Divergence = 3.927077\n",
      "Epoch: 8\tFidelity = 0.500565\tKL_Divergence = 3.921369\n",
      "Epoch: 9\tFidelity = 0.500640\tKL_Divergence = 3.852353\n",
      "Epoch: 10\tFidelity = 0.500535\tKL_Divergence = 3.952009\n",
      "Epoch: 11\tFidelity = 0.500623\tKL_Divergence = 3.867310\n",
      "Epoch: 12\tFidelity = 0.500589\tKL_Divergence = 3.898398\n",
      "Epoch: 13\tFidelity = 0.500546\tKL_Divergence = 3.940359\n",
      "Epoch: 14\tFidelity = 0.500603\tKL_Divergence = 3.885650\n",
      "Epoch: 15\tFidelity = 0.500571\tKL_Divergence = 3.915437\n",
      "Epoch: 16\tFidelity = 0.500618\tKL_Divergence = 3.871939\n",
      "Epoch: 17\tFidelity = 0.500570\tKL_Divergence = 3.917035\n",
      "Epoch: 18\tFidelity = 0.500571\tKL_Divergence = 3.915683\n",
      "Epoch: 19\tFidelity = 0.500603\tKL_Divergence = 3.885376\n",
      "Epoch: 20\tFidelity = 0.500591\tKL_Divergence = 3.896334\n",
      "Epoch: 21\tFidelity = 0.500574\tKL_Divergence = 3.913148\n",
      "Epoch: 22\tFidelity = 0.500619\tKL_Divergence = 3.870739\n",
      "Epoch: 23\tFidelity = 0.500588\tKL_Divergence = 3.899211\n",
      "Epoch: 24\tFidelity = 0.500611\tKL_Divergence = 3.878200\n",
      "Epoch: 25\tFidelity = 0.500616\tKL_Divergence = 3.873194\n",
      "Epoch: 26\tFidelity = 0.500581\tKL_Divergence = 3.905697\n",
      "Epoch: 27\tFidelity = 0.500575\tKL_Divergence = 3.911953\n",
      "Epoch: 28\tFidelity = 0.500626\tKL_Divergence = 3.864654\n",
      "Epoch: 29\tFidelity = 0.500557\tKL_Divergence = 3.929085\n",
      "Epoch: 30\tFidelity = 0.500588\tKL_Divergence = 3.899461\n",
      "Epoch: 31\tFidelity = 0.500528\tKL_Divergence = 3.959217\n",
      "Epoch: 32\tFidelity = 0.500616\tKL_Divergence = 3.873376\n",
      "Epoch: 33\tFidelity = 0.500613\tKL_Divergence = 3.876225\n",
      "Epoch: 34\tFidelity = 0.500593\tKL_Divergence = 3.894839\n",
      "Epoch: 35\tFidelity = 0.500565\tKL_Divergence = 3.921372\n",
      "Epoch: 36\tFidelity = 0.500628\tKL_Divergence = 3.862982\n",
      "Epoch: 37\tFidelity = 0.500556\tKL_Divergence = 3.930877\n",
      "Epoch: 38\tFidelity = 0.500594\tKL_Divergence = 3.893568\n",
      "Epoch: 39\tFidelity = 0.500620\tKL_Divergence = 3.870299\n",
      "Epoch: 40\tFidelity = 0.500587\tKL_Divergence = 3.900543\n",
      "Epoch: 41\tFidelity = 0.500593\tKL_Divergence = 3.895120\n",
      "Epoch: 42\tFidelity = 0.500600\tKL_Divergence = 3.887753\n",
      "Epoch: 43\tFidelity = 0.500605\tKL_Divergence = 3.883738\n",
      "Epoch: 44\tFidelity = 0.500561\tKL_Divergence = 3.925105\n",
      "Epoch: 45\tFidelity = 0.500563\tKL_Divergence = 3.923384\n",
      "Epoch: 46\tFidelity = 0.500566\tKL_Divergence = 3.920438\n",
      "Epoch: 47\tFidelity = 0.500548\tKL_Divergence = 3.938724\n",
      "Epoch: 48\tFidelity = 0.500600\tKL_Divergence = 3.888398\n",
      "Epoch: 49\tFidelity = 0.500620\tKL_Divergence = 3.870137\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:18:40,890] Trial 361 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500549\tKL_Divergence = 3.937953\n",
      "Total time elapsed during training: 31.146 s\n",
      "Trial 361 pruned. \n",
      "Epoch: 1\tFidelity = 0.500627\tKL_Divergence = 3.863768\n",
      "Epoch: 2\tFidelity = 0.500492\tKL_Divergence = 3.998705\n",
      "Epoch: 3\tFidelity = 0.500581\tKL_Divergence = 3.905716\n",
      "Epoch: 4\tFidelity = 0.500537\tKL_Divergence = 3.949436\n",
      "Epoch: 5\tFidelity = 0.500556\tKL_Divergence = 3.930167\n",
      "Epoch: 6\tFidelity = 0.500568\tKL_Divergence = 3.918670\n",
      "Epoch: 7\tFidelity = 0.500580\tKL_Divergence = 3.907133\n",
      "Epoch: 8\tFidelity = 0.500535\tKL_Divergence = 3.951537\n",
      "Epoch: 9\tFidelity = 0.500514\tKL_Divergence = 3.973691\n",
      "Epoch: 10\tFidelity = 0.500622\tKL_Divergence = 3.868378\n",
      "Epoch: 11\tFidelity = 0.500499\tKL_Divergence = 3.989958\n",
      "Epoch: 12\tFidelity = 0.500510\tKL_Divergence = 3.978163\n",
      "Epoch: 13\tFidelity = 0.500606\tKL_Divergence = 3.882296\n",
      "Epoch: 14\tFidelity = 0.500669\tKL_Divergence = 3.827660\n",
      "Epoch: 15\tFidelity = 0.500515\tKL_Divergence = 3.972815\n",
      "Epoch: 16\tFidelity = 0.500542\tKL_Divergence = 3.944117\n",
      "Epoch: 17\tFidelity = 0.500670\tKL_Divergence = 3.826782\n",
      "Epoch: 18\tFidelity = 0.500539\tKL_Divergence = 3.948074\n",
      "Epoch: 19\tFidelity = 0.500558\tKL_Divergence = 3.928233\n",
      "Epoch: 20\tFidelity = 0.500553\tKL_Divergence = 3.933894\n",
      "Epoch: 21\tFidelity = 0.500562\tKL_Divergence = 3.924390\n",
      "Epoch: 22\tFidelity = 0.500548\tKL_Divergence = 3.937847\n",
      "Epoch: 23\tFidelity = 0.500515\tKL_Divergence = 3.972303\n",
      "Epoch: 24\tFidelity = 0.500545\tKL_Divergence = 3.941478\n",
      "Epoch: 25\tFidelity = 0.500568\tKL_Divergence = 3.918065\n",
      "Epoch: 26\tFidelity = 0.500627\tKL_Divergence = 3.863971\n",
      "Epoch: 27\tFidelity = 0.500637\tKL_Divergence = 3.854923\n",
      "Epoch: 28\tFidelity = 0.500676\tKL_Divergence = 3.821795\n",
      "Epoch: 29\tFidelity = 0.500599\tKL_Divergence = 3.888809\n",
      "Epoch: 30\tFidelity = 0.500640\tKL_Divergence = 3.852220\n",
      "Epoch: 31\tFidelity = 0.500666\tKL_Divergence = 3.830493\n",
      "Epoch: 32\tFidelity = 0.500642\tKL_Divergence = 3.850717\n",
      "Epoch: 33\tFidelity = 0.500579\tKL_Divergence = 3.908049\n",
      "Epoch: 34\tFidelity = 0.500532\tKL_Divergence = 3.955200\n",
      "Epoch: 35\tFidelity = 0.500708\tKL_Divergence = 3.795983\n",
      "Epoch: 36\tFidelity = 0.500621\tKL_Divergence = 3.868589\n",
      "Epoch: 37\tFidelity = 0.500544\tKL_Divergence = 3.942172\n",
      "Epoch: 38\tFidelity = 0.500576\tKL_Divergence = 3.910696\n",
      "Epoch: 39\tFidelity = 0.500611\tKL_Divergence = 3.877448\n",
      "Epoch: 40\tFidelity = 0.500527\tKL_Divergence = 3.960347\n",
      "Epoch: 41\tFidelity = 0.500537\tKL_Divergence = 3.949941\n",
      "Epoch: 42\tFidelity = 0.500565\tKL_Divergence = 3.921759\n",
      "Epoch: 43\tFidelity = 0.500526\tKL_Divergence = 3.961251\n",
      "Epoch: 44\tFidelity = 0.500596\tKL_Divergence = 3.892113\n",
      "Epoch: 45\tFidelity = 0.500587\tKL_Divergence = 3.899897\n",
      "Epoch: 46\tFidelity = 0.500556\tKL_Divergence = 3.930063\n",
      "Epoch: 47\tFidelity = 0.500513\tKL_Divergence = 3.975623\n",
      "Epoch: 48\tFidelity = 0.500608\tKL_Divergence = 3.881180\n",
      "Epoch: 49\tFidelity = 0.500537\tKL_Divergence = 3.949994\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:19:17,730] Trial 362 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500661\tKL_Divergence = 3.834371\n",
      "Total time elapsed during training: 36.673 s\n",
      "Trial 362 pruned. \n",
      "Epoch: 1\tFidelity = 0.500543\tKL_Divergence = 3.943547\n",
      "Epoch: 2\tFidelity = 0.500512\tKL_Divergence = 3.976141\n",
      "Epoch: 3\tFidelity = 0.500526\tKL_Divergence = 3.960924\n",
      "Epoch: 4\tFidelity = 0.500540\tKL_Divergence = 3.946300\n",
      "Epoch: 5\tFidelity = 0.500564\tKL_Divergence = 3.922631\n",
      "Epoch: 6\tFidelity = 0.500533\tKL_Divergence = 3.953885\n",
      "Epoch: 7\tFidelity = 0.500541\tKL_Divergence = 3.945731\n",
      "Epoch: 8\tFidelity = 0.500666\tKL_Divergence = 3.830178\n",
      "Epoch: 9\tFidelity = 0.500654\tKL_Divergence = 3.840285\n",
      "Epoch: 10\tFidelity = 0.500621\tKL_Divergence = 3.868723\n",
      "Epoch: 11\tFidelity = 0.500565\tKL_Divergence = 3.921797\n",
      "Epoch: 12\tFidelity = 0.500563\tKL_Divergence = 3.923905\n",
      "Epoch: 13\tFidelity = 0.500623\tKL_Divergence = 3.866854\n",
      "Epoch: 14\tFidelity = 0.500509\tKL_Divergence = 3.979079\n",
      "Epoch: 15\tFidelity = 0.500634\tKL_Divergence = 3.857476\n",
      "Epoch: 16\tFidelity = 0.500602\tKL_Divergence = 3.886204\n",
      "Epoch: 17\tFidelity = 0.500506\tKL_Divergence = 3.982214\n",
      "Epoch: 18\tFidelity = 0.500700\tKL_Divergence = 3.802208\n",
      "Epoch: 19\tFidelity = 0.500590\tKL_Divergence = 3.897826\n",
      "Epoch: 20\tFidelity = 0.500628\tKL_Divergence = 3.862390\n",
      "Epoch: 21\tFidelity = 0.500570\tKL_Divergence = 3.916696\n",
      "Epoch: 22\tFidelity = 0.500448\tKL_Divergence = 4.050622\n",
      "Epoch: 23\tFidelity = 0.500591\tKL_Divergence = 3.896084\n",
      "Epoch: 24\tFidelity = 0.500612\tKL_Divergence = 3.876773\n",
      "Epoch: 25\tFidelity = 0.500605\tKL_Divergence = 3.883041\n",
      "Epoch: 26\tFidelity = 0.500655\tKL_Divergence = 3.839204\n",
      "Epoch: 27\tFidelity = 0.500626\tKL_Divergence = 3.864438\n",
      "Epoch: 28\tFidelity = 0.500537\tKL_Divergence = 3.949620\n",
      "Epoch: 29\tFidelity = 0.500597\tKL_Divergence = 3.890707\n",
      "Epoch: 30\tFidelity = 0.500540\tKL_Divergence = 3.946194\n",
      "Epoch: 31\tFidelity = 0.500617\tKL_Divergence = 3.872196\n",
      "Epoch: 32\tFidelity = 0.500582\tKL_Divergence = 3.905318\n",
      "Epoch: 33\tFidelity = 0.500492\tKL_Divergence = 3.997894\n",
      "Epoch: 34\tFidelity = 0.500611\tKL_Divergence = 3.877562\n",
      "Epoch: 35\tFidelity = 0.500521\tKL_Divergence = 3.966153\n",
      "Epoch: 36\tFidelity = 0.500600\tKL_Divergence = 3.888314\n",
      "Epoch: 37\tFidelity = 0.500573\tKL_Divergence = 3.913372\n",
      "Epoch: 38\tFidelity = 0.500588\tKL_Divergence = 3.899241\n",
      "Epoch: 39\tFidelity = 0.500537\tKL_Divergence = 3.950141\n",
      "Epoch: 40\tFidelity = 0.500609\tKL_Divergence = 3.879465\n",
      "Epoch: 41\tFidelity = 0.500600\tKL_Divergence = 3.888345\n",
      "Epoch: 42\tFidelity = 0.500620\tKL_Divergence = 3.869426\n",
      "Epoch: 43\tFidelity = 0.500566\tKL_Divergence = 3.920166\n",
      "Epoch: 44\tFidelity = 0.500601\tKL_Divergence = 3.886981\n",
      "Epoch: 45\tFidelity = 0.500486\tKL_Divergence = 4.004842\n",
      "Epoch: 46\tFidelity = 0.500543\tKL_Divergence = 3.943890\n",
      "Epoch: 47\tFidelity = 0.500648\tKL_Divergence = 3.844853\n",
      "Epoch: 48\tFidelity = 0.500577\tKL_Divergence = 3.909814\n",
      "Epoch: 49\tFidelity = 0.500630\tKL_Divergence = 3.860451\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:19:54,554] Trial 363 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500560\tKL_Divergence = 3.925937\n",
      "Total time elapsed during training: 36.657 s\n",
      "Trial 363 pruned. \n",
      "Epoch: 1\tFidelity = 0.500529\tKL_Divergence = 3.958112\n",
      "Epoch: 2\tFidelity = 0.500512\tKL_Divergence = 3.976120\n",
      "Epoch: 3\tFidelity = 0.500610\tKL_Divergence = 3.878519\n",
      "Epoch: 4\tFidelity = 0.500726\tKL_Divergence = 3.782285\n",
      "Epoch: 5\tFidelity = 0.500700\tKL_Divergence = 3.802756\n",
      "Epoch: 6\tFidelity = 0.500581\tKL_Divergence = 3.906199\n",
      "Epoch: 7\tFidelity = 0.500580\tKL_Divergence = 3.906627\n",
      "Epoch: 8\tFidelity = 0.500726\tKL_Divergence = 3.782010\n",
      "Epoch: 9\tFidelity = 0.500788\tKL_Divergence = 3.736578\n",
      "Epoch: 10\tFidelity = 0.500618\tKL_Divergence = 3.871736\n",
      "Epoch: 11\tFidelity = 0.500722\tKL_Divergence = 3.785374\n",
      "Epoch: 12\tFidelity = 0.500743\tKL_Divergence = 3.768883\n",
      "Epoch: 13\tFidelity = 0.500656\tKL_Divergence = 3.838668\n",
      "Epoch: 14\tFidelity = 0.500658\tKL_Divergence = 3.837051\n",
      "Epoch: 15\tFidelity = 0.500760\tKL_Divergence = 3.756423\n",
      "Epoch: 16\tFidelity = 0.500672\tKL_Divergence = 3.824929\n",
      "Epoch: 17\tFidelity = 0.500501\tKL_Divergence = 3.987985\n",
      "Epoch: 18\tFidelity = 0.500437\tKL_Divergence = 4.064193\n",
      "Epoch: 19\tFidelity = 0.500391\tKL_Divergence = 4.125954\n",
      "Epoch: 20\tFidelity = 0.500535\tKL_Divergence = 3.952095\n",
      "Epoch: 21\tFidelity = 0.500555\tKL_Divergence = 3.931223\n",
      "Epoch: 22\tFidelity = 0.500579\tKL_Divergence = 3.907365\n",
      "Epoch: 23\tFidelity = 0.500627\tKL_Divergence = 3.863302\n",
      "Epoch: 24\tFidelity = 0.500632\tKL_Divergence = 3.859523\n",
      "Epoch: 25\tFidelity = 0.500565\tKL_Divergence = 3.920803\n",
      "Epoch: 26\tFidelity = 0.500591\tKL_Divergence = 3.896173\n",
      "Epoch: 27\tFidelity = 0.500638\tKL_Divergence = 3.853981\n",
      "Epoch: 28\tFidelity = 0.500656\tKL_Divergence = 3.838061\n",
      "Epoch: 29\tFidelity = 0.500617\tKL_Divergence = 3.872758\n",
      "Epoch: 30\tFidelity = 0.500599\tKL_Divergence = 3.888443\n",
      "Epoch: 31\tFidelity = 0.500738\tKL_Divergence = 3.772744\n",
      "Epoch: 32\tFidelity = 0.500468\tKL_Divergence = 4.025991\n",
      "Epoch: 33\tFidelity = 0.500469\tKL_Divergence = 4.025252\n",
      "Epoch: 34\tFidelity = 0.500683\tKL_Divergence = 3.815883\n",
      "Epoch: 35\tFidelity = 0.500513\tKL_Divergence = 3.975656\n",
      "Epoch: 36\tFidelity = 0.500529\tKL_Divergence = 3.957673\n",
      "Epoch: 37\tFidelity = 0.500599\tKL_Divergence = 3.889501\n",
      "Epoch: 38\tFidelity = 0.500721\tKL_Divergence = 3.786304\n",
      "Epoch: 39\tFidelity = 0.500650\tKL_Divergence = 3.843416\n",
      "Epoch: 40\tFidelity = 0.500544\tKL_Divergence = 3.942130\n",
      "Epoch: 41\tFidelity = 0.500546\tKL_Divergence = 3.940246\n",
      "Epoch: 42\tFidelity = 0.500573\tKL_Divergence = 3.913258\n",
      "Epoch: 43\tFidelity = 0.500660\tKL_Divergence = 3.835530\n",
      "Epoch: 44\tFidelity = 0.500658\tKL_Divergence = 3.836658\n",
      "Epoch: 45\tFidelity = 0.500621\tKL_Divergence = 3.868999\n",
      "Epoch: 46\tFidelity = 0.500532\tKL_Divergence = 3.954688\n",
      "Epoch: 47\tFidelity = 0.500579\tKL_Divergence = 3.908318\n",
      "Epoch: 48\tFidelity = 0.500627\tKL_Divergence = 3.863537\n",
      "Epoch: 49\tFidelity = 0.500595\tKL_Divergence = 3.892940\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:20:31,422] Trial 364 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500491\tKL_Divergence = 3.999272\n",
      "Total time elapsed during training: 36.700 s\n",
      "Trial 364 pruned. \n",
      "Epoch: 1\tFidelity = 0.500531\tKL_Divergence = 3.955871\n",
      "Epoch: 2\tFidelity = 0.500518\tKL_Divergence = 3.969661\n",
      "Epoch: 3\tFidelity = 0.500663\tKL_Divergence = 3.832677\n",
      "Epoch: 4\tFidelity = 0.500555\tKL_Divergence = 3.931893\n",
      "Epoch: 5\tFidelity = 0.500569\tKL_Divergence = 3.918125\n",
      "Epoch: 6\tFidelity = 0.500548\tKL_Divergence = 3.938257\n",
      "Epoch: 7\tFidelity = 0.500523\tKL_Divergence = 3.964246\n",
      "Epoch: 8\tFidelity = 0.500597\tKL_Divergence = 3.890604\n",
      "Epoch: 9\tFidelity = 0.500501\tKL_Divergence = 3.988236\n",
      "Epoch: 10\tFidelity = 0.500553\tKL_Divergence = 3.933024\n",
      "Epoch: 11\tFidelity = 0.500620\tKL_Divergence = 3.870057\n",
      "Epoch: 12\tFidelity = 0.500531\tKL_Divergence = 3.955660\n",
      "Epoch: 13\tFidelity = 0.500512\tKL_Divergence = 3.976791\n",
      "Epoch: 14\tFidelity = 0.500534\tKL_Divergence = 3.952381\n",
      "Epoch: 15\tFidelity = 0.500576\tKL_Divergence = 3.910731\n",
      "Epoch: 16\tFidelity = 0.500569\tKL_Divergence = 3.917136\n",
      "Epoch: 17\tFidelity = 0.500531\tKL_Divergence = 3.956447\n",
      "Epoch: 18\tFidelity = 0.500541\tKL_Divergence = 3.945450\n",
      "Epoch: 19\tFidelity = 0.500517\tKL_Divergence = 3.970733\n",
      "Epoch: 20\tFidelity = 0.500548\tKL_Divergence = 3.938787\n",
      "Epoch: 21\tFidelity = 0.500538\tKL_Divergence = 3.948232\n",
      "Epoch: 22\tFidelity = 0.500541\tKL_Divergence = 3.945599\n",
      "Epoch: 23\tFidelity = 0.500580\tKL_Divergence = 3.906928\n",
      "Epoch: 24\tFidelity = 0.500484\tKL_Divergence = 4.007979\n",
      "Epoch: 25\tFidelity = 0.500536\tKL_Divergence = 3.950362\n",
      "Epoch: 26\tFidelity = 0.500616\tKL_Divergence = 3.873862\n",
      "Epoch: 27\tFidelity = 0.500579\tKL_Divergence = 3.907806\n",
      "Epoch: 28\tFidelity = 0.500522\tKL_Divergence = 3.965922\n",
      "Epoch: 29\tFidelity = 0.500494\tKL_Divergence = 3.996681\n",
      "Epoch: 30\tFidelity = 0.500520\tKL_Divergence = 3.968067\n",
      "Epoch: 31\tFidelity = 0.500591\tKL_Divergence = 3.896240\n",
      "Epoch: 32\tFidelity = 0.500465\tKL_Divergence = 4.030211\n",
      "Epoch: 33\tFidelity = 0.500607\tKL_Divergence = 3.881735\n",
      "Epoch: 34\tFidelity = 0.500488\tKL_Divergence = 4.002858\n",
      "Epoch: 35\tFidelity = 0.500534\tKL_Divergence = 3.953334\n",
      "Epoch: 36\tFidelity = 0.500560\tKL_Divergence = 3.926357\n",
      "Epoch: 37\tFidelity = 0.500544\tKL_Divergence = 3.942328\n",
      "Epoch: 38\tFidelity = 0.500538\tKL_Divergence = 3.948395\n",
      "Epoch: 39\tFidelity = 0.500561\tKL_Divergence = 3.925695\n",
      "Epoch: 40\tFidelity = 0.500595\tKL_Divergence = 3.892963\n",
      "Epoch: 41\tFidelity = 0.500472\tKL_Divergence = 4.021674\n",
      "Epoch: 42\tFidelity = 0.500601\tKL_Divergence = 3.887561\n",
      "Epoch: 43\tFidelity = 0.500616\tKL_Divergence = 3.873226\n",
      "Epoch: 44\tFidelity = 0.500581\tKL_Divergence = 3.906379\n",
      "Epoch: 45\tFidelity = 0.500557\tKL_Divergence = 3.929231\n",
      "Epoch: 46\tFidelity = 0.500541\tKL_Divergence = 3.945759\n",
      "Epoch: 47\tFidelity = 0.500550\tKL_Divergence = 3.936758\n",
      "Epoch: 48\tFidelity = 0.500534\tKL_Divergence = 3.952554\n",
      "Epoch: 49\tFidelity = 0.500513\tKL_Divergence = 3.975342\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:21:48,550] Trial 365 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500527\tKL_Divergence = 3.960388\n",
      "Total time elapsed during training: 76.957 s\n",
      "Trial 365 pruned. \n",
      "Epoch: 1\tFidelity = 0.500531\tKL_Divergence = 3.956110\n",
      "Epoch: 2\tFidelity = 0.500557\tKL_Divergence = 3.929522\n",
      "Epoch: 3\tFidelity = 0.500536\tKL_Divergence = 3.951148\n",
      "Epoch: 4\tFidelity = 0.500484\tKL_Divergence = 4.006892\n",
      "Epoch: 5\tFidelity = 0.500561\tKL_Divergence = 3.925720\n",
      "Epoch: 6\tFidelity = 0.500514\tKL_Divergence = 3.974316\n",
      "Epoch: 7\tFidelity = 0.500536\tKL_Divergence = 3.950752\n",
      "Epoch: 8\tFidelity = 0.500589\tKL_Divergence = 3.898263\n",
      "Epoch: 9\tFidelity = 0.500526\tKL_Divergence = 3.960601\n",
      "Epoch: 10\tFidelity = 0.500536\tKL_Divergence = 3.950087\n",
      "Epoch: 11\tFidelity = 0.500596\tKL_Divergence = 3.890660\n",
      "Epoch: 12\tFidelity = 0.500583\tKL_Divergence = 3.903337\n",
      "Epoch: 13\tFidelity = 0.500612\tKL_Divergence = 3.876256\n",
      "Epoch: 14\tFidelity = 0.500587\tKL_Divergence = 3.899289\n",
      "Epoch: 15\tFidelity = 0.500633\tKL_Divergence = 3.857202\n",
      "Epoch: 16\tFidelity = 0.500610\tKL_Divergence = 3.878514\n",
      "Epoch: 17\tFidelity = 0.500581\tKL_Divergence = 3.905673\n",
      "Epoch: 18\tFidelity = 0.500549\tKL_Divergence = 3.937035\n",
      "Epoch: 19\tFidelity = 0.500598\tKL_Divergence = 3.889850\n",
      "Epoch: 20\tFidelity = 0.500539\tKL_Divergence = 3.946932\n",
      "Epoch: 21\tFidelity = 0.500566\tKL_Divergence = 3.919998\n",
      "Epoch: 22\tFidelity = 0.500489\tKL_Divergence = 4.001739\n",
      "Epoch: 23\tFidelity = 0.500509\tKL_Divergence = 3.979408\n",
      "Epoch: 24\tFidelity = 0.500577\tKL_Divergence = 3.909372\n",
      "Epoch: 25\tFidelity = 0.500499\tKL_Divergence = 3.990113\n",
      "Epoch: 26\tFidelity = 0.500532\tKL_Divergence = 3.954032\n",
      "Epoch: 27\tFidelity = 0.500450\tKL_Divergence = 4.046797\n",
      "Epoch: 28\tFidelity = 0.500533\tKL_Divergence = 3.953995\n",
      "Epoch: 29\tFidelity = 0.500539\tKL_Divergence = 3.947684\n",
      "Epoch: 30\tFidelity = 0.500584\tKL_Divergence = 3.902173\n",
      "Epoch: 31\tFidelity = 0.500559\tKL_Divergence = 3.927187\n",
      "Epoch: 32\tFidelity = 0.500573\tKL_Divergence = 3.912574\n",
      "Epoch: 33\tFidelity = 0.500541\tKL_Divergence = 3.944445\n",
      "Epoch: 34\tFidelity = 0.500528\tKL_Divergence = 3.958169\n",
      "Epoch: 35\tFidelity = 0.500521\tKL_Divergence = 3.965968\n",
      "Epoch: 36\tFidelity = 0.500592\tKL_Divergence = 3.894827\n",
      "Epoch: 37\tFidelity = 0.500577\tKL_Divergence = 3.909596\n",
      "Epoch: 38\tFidelity = 0.500595\tKL_Divergence = 3.892380\n",
      "Epoch: 39\tFidelity = 0.500576\tKL_Divergence = 3.909751\n",
      "Epoch: 40\tFidelity = 0.500586\tKL_Divergence = 3.900793\n",
      "Epoch: 41\tFidelity = 0.500573\tKL_Divergence = 3.912791\n",
      "Epoch: 42\tFidelity = 0.500533\tKL_Divergence = 3.952847\n",
      "Epoch: 43\tFidelity = 0.500493\tKL_Divergence = 3.996486\n",
      "Epoch: 44\tFidelity = 0.500502\tKL_Divergence = 3.986990\n",
      "Epoch: 45\tFidelity = 0.500562\tKL_Divergence = 3.924142\n",
      "Epoch: 46\tFidelity = 0.500535\tKL_Divergence = 3.951369\n",
      "Epoch: 47\tFidelity = 0.500572\tKL_Divergence = 3.914429\n",
      "Epoch: 48\tFidelity = 0.500530\tKL_Divergence = 3.956332\n",
      "Epoch: 49\tFidelity = 0.500487\tKL_Divergence = 4.003848\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:22:25,666] Trial 366 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500481\tKL_Divergence = 4.010773\n",
      "Total time elapsed during training: 36.952 s\n",
      "Trial 366 pruned. \n",
      "Epoch: 1\tFidelity = 0.500582\tKL_Divergence = 3.904839\n",
      "Epoch: 2\tFidelity = 0.500489\tKL_Divergence = 4.001549\n",
      "Epoch: 3\tFidelity = 0.500500\tKL_Divergence = 3.988878\n",
      "Epoch: 4\tFidelity = 0.500528\tKL_Divergence = 3.959145\n",
      "Epoch: 5\tFidelity = 0.500545\tKL_Divergence = 3.940752\n",
      "Epoch: 6\tFidelity = 0.500497\tKL_Divergence = 3.991982\n",
      "Epoch: 7\tFidelity = 0.500478\tKL_Divergence = 4.013454\n",
      "Epoch: 8\tFidelity = 0.500511\tKL_Divergence = 3.976390\n",
      "Epoch: 9\tFidelity = 0.500535\tKL_Divergence = 3.950508\n",
      "Epoch: 10\tFidelity = 0.500572\tKL_Divergence = 3.914188\n",
      "Epoch: 11\tFidelity = 0.500583\tKL_Divergence = 3.903437\n",
      "Epoch: 12\tFidelity = 0.500460\tKL_Divergence = 4.035564\n",
      "Epoch: 13\tFidelity = 0.500480\tKL_Divergence = 4.011330\n",
      "Epoch: 14\tFidelity = 0.500537\tKL_Divergence = 3.949300\n",
      "Epoch: 15\tFidelity = 0.500504\tKL_Divergence = 3.984869\n",
      "Epoch: 16\tFidelity = 0.500508\tKL_Divergence = 3.980521\n",
      "Epoch: 17\tFidelity = 0.500564\tKL_Divergence = 3.921868\n",
      "Epoch: 18\tFidelity = 0.500563\tKL_Divergence = 3.923832\n",
      "Epoch: 19\tFidelity = 0.500517\tKL_Divergence = 3.970885\n",
      "Epoch: 20\tFidelity = 0.500529\tKL_Divergence = 3.958036\n",
      "Epoch: 21\tFidelity = 0.500510\tKL_Divergence = 3.977986\n",
      "Epoch: 22\tFidelity = 0.500523\tKL_Divergence = 3.964077\n",
      "Epoch: 23\tFidelity = 0.500480\tKL_Divergence = 4.012062\n",
      "Epoch: 24\tFidelity = 0.500507\tKL_Divergence = 3.981093\n",
      "Epoch: 25\tFidelity = 0.500511\tKL_Divergence = 3.977127\n",
      "Epoch: 26\tFidelity = 0.500528\tKL_Divergence = 3.958997\n",
      "Epoch: 27\tFidelity = 0.500489\tKL_Divergence = 4.001142\n",
      "Epoch: 28\tFidelity = 0.500485\tKL_Divergence = 4.006777\n",
      "Epoch: 29\tFidelity = 0.500558\tKL_Divergence = 3.928519\n",
      "Epoch: 30\tFidelity = 0.500466\tKL_Divergence = 4.028762\n",
      "Epoch: 31\tFidelity = 0.500515\tKL_Divergence = 3.973374\n",
      "Epoch: 32\tFidelity = 0.500487\tKL_Divergence = 4.003496\n",
      "Epoch: 33\tFidelity = 0.500463\tKL_Divergence = 4.031488\n",
      "Epoch: 34\tFidelity = 0.500528\tKL_Divergence = 3.958756\n",
      "Epoch: 35\tFidelity = 0.500491\tKL_Divergence = 3.999284\n",
      "Epoch: 36\tFidelity = 0.500529\tKL_Divergence = 3.958153\n",
      "Epoch: 37\tFidelity = 0.500524\tKL_Divergence = 3.963394\n",
      "Epoch: 38\tFidelity = 0.500465\tKL_Divergence = 4.029075\n",
      "Epoch: 39\tFidelity = 0.500483\tKL_Divergence = 4.007913\n",
      "Epoch: 40\tFidelity = 0.500507\tKL_Divergence = 3.981018\n",
      "Epoch: 41\tFidelity = 0.500541\tKL_Divergence = 3.945575\n",
      "Epoch: 42\tFidelity = 0.500480\tKL_Divergence = 4.011559\n",
      "Epoch: 43\tFidelity = 0.500476\tKL_Divergence = 4.016666\n",
      "Epoch: 44\tFidelity = 0.500492\tKL_Divergence = 3.998674\n",
      "Epoch: 45\tFidelity = 0.500502\tKL_Divergence = 3.987316\n",
      "Epoch: 46\tFidelity = 0.500533\tKL_Divergence = 3.953509\n",
      "Epoch: 47\tFidelity = 0.500519\tKL_Divergence = 3.968088\n",
      "Epoch: 48\tFidelity = 0.500522\tKL_Divergence = 3.965669\n",
      "Epoch: 49\tFidelity = 0.500523\tKL_Divergence = 3.964529\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:23:22,455] Trial 367 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500487\tKL_Divergence = 4.003543\n",
      "Total time elapsed during training: 56.627 s\n",
      "Trial 367 pruned. \n",
      "Epoch: 1\tFidelity = 0.500520\tKL_Divergence = 3.966944\n",
      "Epoch: 2\tFidelity = 0.500506\tKL_Divergence = 3.982466\n",
      "Epoch: 3\tFidelity = 0.500498\tKL_Divergence = 3.991472\n",
      "Epoch: 4\tFidelity = 0.500518\tKL_Divergence = 3.969584\n",
      "Epoch: 5\tFidelity = 0.500473\tKL_Divergence = 4.019727\n",
      "Epoch: 6\tFidelity = 0.500499\tKL_Divergence = 3.990057\n",
      "Epoch: 7\tFidelity = 0.500507\tKL_Divergence = 3.981851\n",
      "Epoch: 8\tFidelity = 0.500540\tKL_Divergence = 3.946540\n",
      "Epoch: 9\tFidelity = 0.500537\tKL_Divergence = 3.949478\n",
      "Epoch: 10\tFidelity = 0.500483\tKL_Divergence = 4.008499\n",
      "Epoch: 11\tFidelity = 0.500490\tKL_Divergence = 4.000527\n",
      "Epoch: 12\tFidelity = 0.500489\tKL_Divergence = 4.001279\n",
      "Epoch: 13\tFidelity = 0.500503\tKL_Divergence = 3.985996\n",
      "Epoch: 14\tFidelity = 0.500510\tKL_Divergence = 3.978812\n",
      "Epoch: 15\tFidelity = 0.500556\tKL_Divergence = 3.930453\n",
      "Epoch: 16\tFidelity = 0.500494\tKL_Divergence = 3.996096\n",
      "Epoch: 17\tFidelity = 0.500481\tKL_Divergence = 4.010950\n",
      "Epoch: 18\tFidelity = 0.500513\tKL_Divergence = 3.974864\n",
      "Epoch: 19\tFidelity = 0.500522\tKL_Divergence = 3.965258\n",
      "Epoch: 20\tFidelity = 0.500512\tKL_Divergence = 3.975858\n",
      "Epoch: 21\tFidelity = 0.500539\tKL_Divergence = 3.947896\n",
      "Epoch: 22\tFidelity = 0.500493\tKL_Divergence = 3.997043\n",
      "Epoch: 23\tFidelity = 0.500526\tKL_Divergence = 3.961289\n",
      "Epoch: 24\tFidelity = 0.500506\tKL_Divergence = 3.983060\n",
      "Epoch: 25\tFidelity = 0.500472\tKL_Divergence = 4.021818\n",
      "Epoch: 26\tFidelity = 0.500506\tKL_Divergence = 3.982992\n",
      "Epoch: 27\tFidelity = 0.500458\tKL_Divergence = 4.037720\n",
      "Epoch: 28\tFidelity = 0.500518\tKL_Divergence = 3.969543\n",
      "Epoch: 29\tFidelity = 0.500568\tKL_Divergence = 3.918586\n",
      "Epoch: 30\tFidelity = 0.500489\tKL_Divergence = 4.001988\n",
      "Epoch: 31\tFidelity = 0.500495\tKL_Divergence = 3.994535\n",
      "Epoch: 32\tFidelity = 0.500508\tKL_Divergence = 3.980601\n",
      "Epoch: 33\tFidelity = 0.500480\tKL_Divergence = 4.011699\n",
      "Epoch: 34\tFidelity = 0.500508\tKL_Divergence = 3.980437\n",
      "Epoch: 35\tFidelity = 0.500529\tKL_Divergence = 3.957905\n",
      "Epoch: 36\tFidelity = 0.500509\tKL_Divergence = 3.979655\n",
      "Epoch: 37\tFidelity = 0.500479\tKL_Divergence = 4.012859\n",
      "Epoch: 38\tFidelity = 0.500533\tKL_Divergence = 3.954197\n",
      "Epoch: 39\tFidelity = 0.500506\tKL_Divergence = 3.982678\n",
      "Epoch: 40\tFidelity = 0.500550\tKL_Divergence = 3.936589\n",
      "Epoch: 41\tFidelity = 0.500488\tKL_Divergence = 4.002252\n",
      "Epoch: 42\tFidelity = 0.500480\tKL_Divergence = 4.011763\n",
      "Epoch: 43\tFidelity = 0.500523\tKL_Divergence = 3.964715\n",
      "Epoch: 44\tFidelity = 0.500500\tKL_Divergence = 3.989355\n",
      "Epoch: 45\tFidelity = 0.500484\tKL_Divergence = 4.006852\n",
      "Epoch: 46\tFidelity = 0.500504\tKL_Divergence = 3.985398\n",
      "Epoch: 47\tFidelity = 0.500498\tKL_Divergence = 3.991450\n",
      "Epoch: 48\tFidelity = 0.500540\tKL_Divergence = 3.946596\n",
      "Epoch: 49\tFidelity = 0.500505\tKL_Divergence = 3.984257\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:24:06,921] Trial 368 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500453\tKL_Divergence = 4.044359\n",
      "Total time elapsed during training: 44.292 s\n",
      "Trial 368 pruned. \n",
      "Epoch: 1\tFidelity = 0.500509\tKL_Divergence = 3.979187\n",
      "Epoch: 2\tFidelity = 0.500529\tKL_Divergence = 3.958028\n",
      "Epoch: 3\tFidelity = 0.500555\tKL_Divergence = 3.931187\n",
      "Epoch: 4\tFidelity = 0.500572\tKL_Divergence = 3.914454\n",
      "Epoch: 5\tFidelity = 0.500557\tKL_Divergence = 3.928900\n",
      "Epoch: 6\tFidelity = 0.500515\tKL_Divergence = 3.973176\n",
      "Epoch: 7\tFidelity = 0.500454\tKL_Divergence = 4.043089\n",
      "Epoch: 8\tFidelity = 0.500483\tKL_Divergence = 4.008214\n",
      "Epoch: 9\tFidelity = 0.500518\tKL_Divergence = 3.970089\n",
      "Epoch: 10\tFidelity = 0.500500\tKL_Divergence = 3.989693\n",
      "Epoch: 11\tFidelity = 0.500493\tKL_Divergence = 3.997474\n",
      "Epoch: 12\tFidelity = 0.500517\tKL_Divergence = 3.970912\n",
      "Epoch: 13\tFidelity = 0.500509\tKL_Divergence = 3.979749\n",
      "Epoch: 14\tFidelity = 0.500503\tKL_Divergence = 3.985539\n",
      "Epoch: 15\tFidelity = 0.500495\tKL_Divergence = 3.994601\n",
      "Epoch: 16\tFidelity = 0.500483\tKL_Divergence = 4.008762\n",
      "Epoch: 17\tFidelity = 0.500529\tKL_Divergence = 3.957751\n",
      "Epoch: 18\tFidelity = 0.500486\tKL_Divergence = 4.004851\n",
      "Epoch: 19\tFidelity = 0.500528\tKL_Divergence = 3.959046\n",
      "Epoch: 20\tFidelity = 0.500518\tKL_Divergence = 3.969569\n",
      "Epoch: 21\tFidelity = 0.500496\tKL_Divergence = 3.993247\n",
      "Epoch: 22\tFidelity = 0.500502\tKL_Divergence = 3.987102\n",
      "Epoch: 23\tFidelity = 0.500486\tKL_Divergence = 4.004619\n",
      "Epoch: 24\tFidelity = 0.500474\tKL_Divergence = 4.019026\n",
      "Epoch: 25\tFidelity = 0.500514\tKL_Divergence = 3.974047\n",
      "Epoch: 26\tFidelity = 0.500529\tKL_Divergence = 3.957514\n",
      "Epoch: 27\tFidelity = 0.500479\tKL_Divergence = 4.012670\n",
      "Epoch: 28\tFidelity = 0.500493\tKL_Divergence = 3.996900\n",
      "Epoch: 29\tFidelity = 0.500495\tKL_Divergence = 3.994767\n",
      "Epoch: 30\tFidelity = 0.500473\tKL_Divergence = 4.019677\n",
      "Epoch: 31\tFidelity = 0.500462\tKL_Divergence = 4.033737\n",
      "Epoch: 32\tFidelity = 0.500509\tKL_Divergence = 3.979818\n",
      "Epoch: 33\tFidelity = 0.500483\tKL_Divergence = 4.008300\n",
      "Epoch: 34\tFidelity = 0.500477\tKL_Divergence = 4.015845\n",
      "Epoch: 35\tFidelity = 0.500515\tKL_Divergence = 3.972914\n",
      "Epoch: 36\tFidelity = 0.500539\tKL_Divergence = 3.947101\n",
      "Epoch: 37\tFidelity = 0.500527\tKL_Divergence = 3.960236\n",
      "Epoch: 38\tFidelity = 0.500511\tKL_Divergence = 3.977052\n",
      "Epoch: 39\tFidelity = 0.500487\tKL_Divergence = 4.004422\n",
      "Epoch: 40\tFidelity = 0.500519\tKL_Divergence = 3.968646\n",
      "Epoch: 41\tFidelity = 0.500516\tKL_Divergence = 3.971881\n",
      "Epoch: 42\tFidelity = 0.500506\tKL_Divergence = 3.982414\n",
      "Epoch: 43\tFidelity = 0.500532\tKL_Divergence = 3.954642\n",
      "Epoch: 44\tFidelity = 0.500477\tKL_Divergence = 4.015211\n",
      "Epoch: 45\tFidelity = 0.500502\tKL_Divergence = 3.987569\n",
      "Epoch: 46\tFidelity = 0.500464\tKL_Divergence = 4.031377\n",
      "Epoch: 47\tFidelity = 0.500486\tKL_Divergence = 4.004556\n",
      "Epoch: 48\tFidelity = 0.500495\tKL_Divergence = 3.995143\n",
      "Epoch: 49\tFidelity = 0.500535\tKL_Divergence = 3.951322\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:24:44,631] Trial 369 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500543\tKL_Divergence = 3.943409\n",
      "Total time elapsed during training: 37.552 s\n",
      "Trial 369 pruned. \n",
      "Epoch: 1\tFidelity = 0.500570\tKL_Divergence = 3.916661\n",
      "Epoch: 2\tFidelity = 0.500539\tKL_Divergence = 3.947822\n",
      "Epoch: 3\tFidelity = 0.500498\tKL_Divergence = 3.991649\n",
      "Epoch: 4\tFidelity = 0.500528\tKL_Divergence = 3.959013\n",
      "Epoch: 5\tFidelity = 0.500520\tKL_Divergence = 3.968068\n",
      "Epoch: 6\tFidelity = 0.500534\tKL_Divergence = 3.952463\n",
      "Epoch: 7\tFidelity = 0.500462\tKL_Divergence = 4.033066\n",
      "Epoch: 8\tFidelity = 0.500448\tKL_Divergence = 4.050883\n",
      "Epoch: 9\tFidelity = 0.500542\tKL_Divergence = 3.944928\n",
      "Epoch: 10\tFidelity = 0.500537\tKL_Divergence = 3.949198\n",
      "Epoch: 11\tFidelity = 0.500458\tKL_Divergence = 4.037830\n",
      "Epoch: 12\tFidelity = 0.500522\tKL_Divergence = 3.965631\n",
      "Epoch: 13\tFidelity = 0.500501\tKL_Divergence = 3.987760\n",
      "Epoch: 14\tFidelity = 0.500479\tKL_Divergence = 4.013152\n",
      "Epoch: 15\tFidelity = 0.500487\tKL_Divergence = 4.003290\n",
      "Epoch: 16\tFidelity = 0.500531\tKL_Divergence = 3.955640\n",
      "Epoch: 17\tFidelity = 0.500509\tKL_Divergence = 3.978865\n",
      "Epoch: 18\tFidelity = 0.500483\tKL_Divergence = 4.008852\n",
      "Epoch: 19\tFidelity = 0.500563\tKL_Divergence = 3.923262\n",
      "Epoch: 20\tFidelity = 0.500525\tKL_Divergence = 3.962613\n",
      "Epoch: 21\tFidelity = 0.500494\tKL_Divergence = 3.996135\n",
      "Epoch: 22\tFidelity = 0.500635\tKL_Divergence = 3.856181\n",
      "Epoch: 23\tFidelity = 0.500580\tKL_Divergence = 3.907149\n",
      "Epoch: 24\tFidelity = 0.500488\tKL_Divergence = 4.003166\n",
      "Epoch: 25\tFidelity = 0.500521\tKL_Divergence = 3.966342\n",
      "Epoch: 26\tFidelity = 0.500483\tKL_Divergence = 4.008044\n",
      "Epoch: 27\tFidelity = 0.500467\tKL_Divergence = 4.027453\n",
      "Epoch: 28\tFidelity = 0.500471\tKL_Divergence = 4.022581\n",
      "Epoch: 29\tFidelity = 0.500497\tKL_Divergence = 3.992300\n",
      "Epoch: 30\tFidelity = 0.500558\tKL_Divergence = 3.928713\n",
      "Epoch: 31\tFidelity = 0.500485\tKL_Divergence = 4.006469\n",
      "Epoch: 32\tFidelity = 0.500535\tKL_Divergence = 3.951299\n",
      "Epoch: 33\tFidelity = 0.500490\tKL_Divergence = 4.000115\n",
      "Epoch: 34\tFidelity = 0.500490\tKL_Divergence = 4.000587\n",
      "Epoch: 35\tFidelity = 0.500452\tKL_Divergence = 4.045988\n",
      "Epoch: 36\tFidelity = 0.500512\tKL_Divergence = 3.976351\n",
      "Epoch: 37\tFidelity = 0.500451\tKL_Divergence = 4.047140\n",
      "Epoch: 38\tFidelity = 0.500433\tKL_Divergence = 4.069061\n",
      "Epoch: 39\tFidelity = 0.500420\tKL_Divergence = 4.086163\n",
      "Epoch: 40\tFidelity = 0.500435\tKL_Divergence = 4.066767\n",
      "Epoch: 41\tFidelity = 0.500545\tKL_Divergence = 3.941747\n",
      "Epoch: 42\tFidelity = 0.500460\tKL_Divergence = 4.035824\n",
      "Epoch: 43\tFidelity = 0.500498\tKL_Divergence = 3.991409\n",
      "Epoch: 44\tFidelity = 0.500489\tKL_Divergence = 4.001531\n",
      "Epoch: 45\tFidelity = 0.500536\tKL_Divergence = 3.951048\n",
      "Epoch: 46\tFidelity = 0.500488\tKL_Divergence = 4.002853\n",
      "Epoch: 47\tFidelity = 0.500514\tKL_Divergence = 3.974174\n",
      "Epoch: 48\tFidelity = 0.500495\tKL_Divergence = 3.995562\n",
      "Epoch: 49\tFidelity = 0.500373\tKL_Divergence = 4.151899\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:26:04,030] Trial 370 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500498\tKL_Divergence = 3.991178\n",
      "Total time elapsed during training: 79.237 s\n",
      "Trial 370 pruned. \n",
      "Epoch: 1\tFidelity = 0.500505\tKL_Divergence = 3.983741\n",
      "Epoch: 2\tFidelity = 0.500431\tKL_Divergence = 4.071319\n",
      "Epoch: 3\tFidelity = 0.500533\tKL_Divergence = 3.953817\n",
      "Epoch: 4\tFidelity = 0.500427\tKL_Divergence = 4.076400\n",
      "Epoch: 5\tFidelity = 0.500555\tKL_Divergence = 3.931195\n",
      "Epoch: 6\tFidelity = 0.500420\tKL_Divergence = 4.085774\n",
      "Epoch: 7\tFidelity = 0.500554\tKL_Divergence = 3.932754\n",
      "Epoch: 8\tFidelity = 0.500459\tKL_Divergence = 4.037163\n",
      "Epoch: 9\tFidelity = 0.500563\tKL_Divergence = 3.923427\n",
      "Epoch: 10\tFidelity = 0.500425\tKL_Divergence = 4.079542\n",
      "Epoch: 11\tFidelity = 0.500549\tKL_Divergence = 3.937187\n",
      "Epoch: 12\tFidelity = 0.500474\tKL_Divergence = 4.019546\n",
      "Epoch: 13\tFidelity = 0.500490\tKL_Divergence = 4.000942\n",
      "Epoch: 14\tFidelity = 0.500498\tKL_Divergence = 3.991594\n",
      "Epoch: 15\tFidelity = 0.500511\tKL_Divergence = 3.976775\n",
      "Epoch: 16\tFidelity = 0.500604\tKL_Divergence = 3.884616\n",
      "Epoch: 17\tFidelity = 0.500421\tKL_Divergence = 4.084202\n",
      "Epoch: 18\tFidelity = 0.500489\tKL_Divergence = 4.001379\n",
      "Epoch: 19\tFidelity = 0.500494\tKL_Divergence = 3.995557\n",
      "Epoch: 20\tFidelity = 0.500482\tKL_Divergence = 4.009803\n",
      "Epoch: 21\tFidelity = 0.500509\tKL_Divergence = 3.979996\n",
      "Epoch: 22\tFidelity = 0.500464\tKL_Divergence = 4.031079\n",
      "Epoch: 23\tFidelity = 0.500481\tKL_Divergence = 4.010321\n",
      "Epoch: 24\tFidelity = 0.500520\tKL_Divergence = 3.967346\n",
      "Epoch: 25\tFidelity = 0.500447\tKL_Divergence = 4.051399\n",
      "Epoch: 26\tFidelity = 0.500573\tKL_Divergence = 3.913331\n",
      "Epoch: 27\tFidelity = 0.500487\tKL_Divergence = 4.004274\n",
      "Epoch: 28\tFidelity = 0.500469\tKL_Divergence = 4.024934\n",
      "Epoch: 29\tFidelity = 0.500452\tKL_Divergence = 4.046061\n",
      "Epoch: 30\tFidelity = 0.500518\tKL_Divergence = 3.969741\n",
      "Epoch: 31\tFidelity = 0.500512\tKL_Divergence = 3.976356\n",
      "Epoch: 32\tFidelity = 0.500478\tKL_Divergence = 4.013917\n",
      "Epoch: 33\tFidelity = 0.500587\tKL_Divergence = 3.900490\n",
      "Epoch: 34\tFidelity = 0.500444\tKL_Divergence = 4.055572\n",
      "Epoch: 35\tFidelity = 0.500529\tKL_Divergence = 3.958631\n",
      "Epoch: 36\tFidelity = 0.500567\tKL_Divergence = 3.919816\n",
      "Epoch: 37\tFidelity = 0.500474\tKL_Divergence = 4.019638\n",
      "Epoch: 38\tFidelity = 0.500512\tKL_Divergence = 3.975952\n",
      "Epoch: 39\tFidelity = 0.500534\tKL_Divergence = 3.952567\n",
      "Epoch: 40\tFidelity = 0.500428\tKL_Divergence = 4.075872\n",
      "Epoch: 41\tFidelity = 0.500499\tKL_Divergence = 3.990868\n",
      "Epoch: 42\tFidelity = 0.500481\tKL_Divergence = 4.011435\n",
      "Epoch: 43\tFidelity = 0.500486\tKL_Divergence = 4.005798\n",
      "Epoch: 44\tFidelity = 0.500462\tKL_Divergence = 4.033296\n",
      "Epoch: 45\tFidelity = 0.500508\tKL_Divergence = 3.980421\n",
      "Epoch: 46\tFidelity = 0.500426\tKL_Divergence = 4.078141\n",
      "Epoch: 47\tFidelity = 0.500538\tKL_Divergence = 3.949022\n",
      "Epoch: 48\tFidelity = 0.500443\tKL_Divergence = 4.057261\n",
      "Epoch: 49\tFidelity = 0.500513\tKL_Divergence = 3.975630\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:26:35,462] Trial 371 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500443\tKL_Divergence = 4.056094\n",
      "Total time elapsed during training: 31.256 s\n",
      "Trial 371 pruned. \n",
      "Epoch: 1\tFidelity = 0.500450\tKL_Divergence = 4.047468\n",
      "Epoch: 2\tFidelity = 0.500418\tKL_Divergence = 4.089061\n",
      "Epoch: 3\tFidelity = 0.500476\tKL_Divergence = 4.016615\n",
      "Epoch: 4\tFidelity = 0.500452\tKL_Divergence = 4.046081\n",
      "Epoch: 5\tFidelity = 0.500411\tKL_Divergence = 4.098643\n",
      "Epoch: 6\tFidelity = 0.500544\tKL_Divergence = 3.942960\n",
      "Epoch: 7\tFidelity = 0.500449\tKL_Divergence = 4.048540\n",
      "Epoch: 8\tFidelity = 0.500545\tKL_Divergence = 3.941859\n",
      "Epoch: 9\tFidelity = 0.500388\tKL_Divergence = 4.129648\n",
      "Epoch: 10\tFidelity = 0.500497\tKL_Divergence = 3.992387\n",
      "Epoch: 11\tFidelity = 0.500496\tKL_Divergence = 3.993080\n",
      "Epoch: 12\tFidelity = 0.500432\tKL_Divergence = 4.070380\n",
      "Epoch: 13\tFidelity = 0.500460\tKL_Divergence = 4.035256\n",
      "Epoch: 14\tFidelity = 0.500516\tKL_Divergence = 3.972008\n",
      "Epoch: 15\tFidelity = 0.500445\tKL_Divergence = 4.053650\n",
      "Epoch: 16\tFidelity = 0.500545\tKL_Divergence = 3.941229\n",
      "Epoch: 17\tFidelity = 0.500383\tKL_Divergence = 4.137258\n",
      "Epoch: 18\tFidelity = 0.500487\tKL_Divergence = 4.004268\n",
      "Epoch: 19\tFidelity = 0.500458\tKL_Divergence = 4.037729\n",
      "Epoch: 20\tFidelity = 0.500457\tKL_Divergence = 4.038807\n",
      "Epoch: 21\tFidelity = 0.500474\tKL_Divergence = 4.018905\n",
      "Epoch: 22\tFidelity = 0.500533\tKL_Divergence = 3.954093\n",
      "Epoch: 23\tFidelity = 0.500444\tKL_Divergence = 4.055838\n",
      "Epoch: 24\tFidelity = 0.500514\tKL_Divergence = 3.973725\n",
      "Epoch: 25\tFidelity = 0.500501\tKL_Divergence = 3.988662\n",
      "Epoch: 26\tFidelity = 0.500511\tKL_Divergence = 3.977833\n",
      "Epoch: 27\tFidelity = 0.500497\tKL_Divergence = 3.992573\n",
      "Epoch: 28\tFidelity = 0.500524\tKL_Divergence = 3.963714\n",
      "Epoch: 29\tFidelity = 0.500506\tKL_Divergence = 3.983193\n",
      "Epoch: 30\tFidelity = 0.500455\tKL_Divergence = 4.041551\n",
      "Epoch: 31\tFidelity = 0.500478\tKL_Divergence = 4.014420\n",
      "Epoch: 32\tFidelity = 0.500433\tKL_Divergence = 4.069092\n",
      "Epoch: 33\tFidelity = 0.500469\tKL_Divergence = 4.025343\n",
      "Epoch: 34\tFidelity = 0.500526\tKL_Divergence = 3.961238\n",
      "Epoch: 35\tFidelity = 0.500416\tKL_Divergence = 4.091079\n",
      "Epoch: 36\tFidelity = 0.500389\tKL_Divergence = 4.128830\n",
      "Epoch: 37\tFidelity = 0.500425\tKL_Divergence = 4.079260\n",
      "Epoch: 38\tFidelity = 0.500433\tKL_Divergence = 4.068717\n",
      "Epoch: 39\tFidelity = 0.500431\tKL_Divergence = 4.071646\n",
      "Epoch: 40\tFidelity = 0.500480\tKL_Divergence = 4.011067\n",
      "Epoch: 41\tFidelity = 0.500412\tKL_Divergence = 4.096170\n",
      "Epoch: 42\tFidelity = 0.500457\tKL_Divergence = 4.039159\n",
      "Epoch: 43\tFidelity = 0.500503\tKL_Divergence = 3.985615\n",
      "Epoch: 44\tFidelity = 0.500529\tKL_Divergence = 3.957771\n",
      "Epoch: 45\tFidelity = 0.500428\tKL_Divergence = 4.075944\n",
      "Epoch: 46\tFidelity = 0.500422\tKL_Divergence = 4.083229\n",
      "Epoch: 47\tFidelity = 0.500464\tKL_Divergence = 4.030446\n",
      "Epoch: 48\tFidelity = 0.500456\tKL_Divergence = 4.040587\n",
      "Epoch: 49\tFidelity = 0.500537\tKL_Divergence = 3.949338\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:27:13,645] Trial 372 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500519\tKL_Divergence = 3.968364\n",
      "Total time elapsed during training: 38.011 s\n",
      "Trial 372 pruned. \n",
      "Epoch: 1\tFidelity = 0.500484\tKL_Divergence = 4.007783\n",
      "Epoch: 2\tFidelity = 0.500504\tKL_Divergence = 3.984888\n",
      "Epoch: 3\tFidelity = 0.500483\tKL_Divergence = 4.008797\n",
      "Epoch: 4\tFidelity = 0.500482\tKL_Divergence = 4.009947\n",
      "Epoch: 5\tFidelity = 0.500449\tKL_Divergence = 4.049463\n",
      "Epoch: 6\tFidelity = 0.500471\tKL_Divergence = 4.023086\n",
      "Epoch: 7\tFidelity = 0.500465\tKL_Divergence = 4.029867\n",
      "Epoch: 8\tFidelity = 0.500438\tKL_Divergence = 4.062499\n",
      "Epoch: 9\tFidelity = 0.500451\tKL_Divergence = 4.046162\n",
      "Epoch: 10\tFidelity = 0.500474\tKL_Divergence = 4.018850\n",
      "Epoch: 11\tFidelity = 0.500477\tKL_Divergence = 4.016048\n",
      "Epoch: 12\tFidelity = 0.500485\tKL_Divergence = 4.005836\n",
      "Epoch: 13\tFidelity = 0.500463\tKL_Divergence = 4.032430\n",
      "Epoch: 14\tFidelity = 0.500490\tKL_Divergence = 4.000398\n",
      "Epoch: 15\tFidelity = 0.500484\tKL_Divergence = 4.008059\n",
      "Epoch: 16\tFidelity = 0.500488\tKL_Divergence = 4.002610\n",
      "Epoch: 17\tFidelity = 0.500508\tKL_Divergence = 3.980113\n",
      "Epoch: 18\tFidelity = 0.500480\tKL_Divergence = 4.011825\n",
      "Epoch: 19\tFidelity = 0.500475\tKL_Divergence = 4.017480\n",
      "Epoch: 20\tFidelity = 0.500458\tKL_Divergence = 4.037783\n",
      "Epoch: 21\tFidelity = 0.500433\tKL_Divergence = 4.068829\n",
      "Epoch: 22\tFidelity = 0.500450\tKL_Divergence = 4.048523\n",
      "Epoch: 23\tFidelity = 0.500448\tKL_Divergence = 4.049938\n",
      "Epoch: 24\tFidelity = 0.500459\tKL_Divergence = 4.037058\n",
      "Epoch: 25\tFidelity = 0.500453\tKL_Divergence = 4.044286\n",
      "Epoch: 26\tFidelity = 0.500451\tKL_Divergence = 4.047243\n",
      "Epoch: 27\tFidelity = 0.500435\tKL_Divergence = 4.067228\n",
      "Epoch: 28\tFidelity = 0.500460\tKL_Divergence = 4.035195\n",
      "Epoch: 29\tFidelity = 0.500453\tKL_Divergence = 4.044331\n",
      "Epoch: 30\tFidelity = 0.500458\tKL_Divergence = 4.038018\n",
      "Epoch: 31\tFidelity = 0.500472\tKL_Divergence = 4.021829\n",
      "Epoch: 32\tFidelity = 0.500491\tKL_Divergence = 3.999121\n",
      "Epoch: 33\tFidelity = 0.500457\tKL_Divergence = 4.039019\n",
      "Epoch: 34\tFidelity = 0.500451\tKL_Divergence = 4.046716\n",
      "Epoch: 35\tFidelity = 0.500495\tKL_Divergence = 3.994882\n",
      "Epoch: 36\tFidelity = 0.500464\tKL_Divergence = 4.030480\n",
      "Epoch: 37\tFidelity = 0.500463\tKL_Divergence = 4.032762\n",
      "Epoch: 38\tFidelity = 0.500452\tKL_Divergence = 4.045771\n",
      "Epoch: 39\tFidelity = 0.500456\tKL_Divergence = 4.040981\n",
      "Epoch: 40\tFidelity = 0.500451\tKL_Divergence = 4.047170\n",
      "Epoch: 41\tFidelity = 0.500479\tKL_Divergence = 4.013845\n",
      "Epoch: 42\tFidelity = 0.500481\tKL_Divergence = 4.010429\n",
      "Epoch: 43\tFidelity = 0.500452\tKL_Divergence = 4.045014\n",
      "Epoch: 44\tFidelity = 0.500492\tKL_Divergence = 3.998472\n",
      "Epoch: 45\tFidelity = 0.500473\tKL_Divergence = 4.020521\n",
      "Epoch: 46\tFidelity = 0.500504\tKL_Divergence = 3.984702\n",
      "Epoch: 47\tFidelity = 0.500461\tKL_Divergence = 4.034989\n",
      "Epoch: 48\tFidelity = 0.500475\tKL_Divergence = 4.018107\n",
      "Epoch: 49\tFidelity = 0.500469\tKL_Divergence = 4.025300\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:27:45,106] Trial 373 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500436\tKL_Divergence = 4.065232\n",
      "Total time elapsed during training: 31.309 s\n",
      "Trial 373 pruned. \n",
      "Epoch: 1\tFidelity = 0.500418\tKL_Divergence = 4.089124\n",
      "Epoch: 2\tFidelity = 0.500366\tKL_Divergence = 4.162853\n",
      "Epoch: 3\tFidelity = 0.500414\tKL_Divergence = 4.094839\n",
      "Epoch: 4\tFidelity = 0.500374\tKL_Divergence = 4.150781\n",
      "Epoch: 5\tFidelity = 0.500457\tKL_Divergence = 4.039952\n",
      "Epoch: 6\tFidelity = 0.500466\tKL_Divergence = 4.028439\n",
      "Epoch: 7\tFidelity = 0.500465\tKL_Divergence = 4.029611\n",
      "Epoch: 8\tFidelity = 0.500371\tKL_Divergence = 4.155791\n",
      "Epoch: 9\tFidelity = 0.500545\tKL_Divergence = 3.941982\n",
      "Epoch: 10\tFidelity = 0.500618\tKL_Divergence = 3.871669\n",
      "Epoch: 11\tFidelity = 0.500602\tKL_Divergence = 3.886551\n",
      "Epoch: 12\tFidelity = 0.500530\tKL_Divergence = 3.957204\n",
      "Epoch: 13\tFidelity = 0.500366\tKL_Divergence = 4.163239\n",
      "Epoch: 14\tFidelity = 0.500583\tKL_Divergence = 3.904089\n",
      "Epoch: 15\tFidelity = 0.500340\tKL_Divergence = 4.203950\n",
      "Epoch: 16\tFidelity = 0.500488\tKL_Divergence = 4.003317\n",
      "Epoch: 17\tFidelity = 0.500521\tKL_Divergence = 3.966633\n",
      "Epoch: 18\tFidelity = 0.500418\tKL_Divergence = 4.089339\n",
      "Epoch: 19\tFidelity = 0.500413\tKL_Divergence = 4.095334\n",
      "Epoch: 20\tFidelity = 0.500623\tKL_Divergence = 3.867764\n",
      "Epoch: 21\tFidelity = 0.500547\tKL_Divergence = 3.939606\n",
      "Epoch: 22\tFidelity = 0.500397\tKL_Divergence = 4.118337\n",
      "Epoch: 23\tFidelity = 0.500538\tKL_Divergence = 3.949116\n",
      "Epoch: 24\tFidelity = 0.500439\tKL_Divergence = 4.061706\n",
      "Epoch: 25\tFidelity = 0.500355\tKL_Divergence = 4.180453\n",
      "Epoch: 26\tFidelity = 0.500513\tKL_Divergence = 3.975336\n",
      "Epoch: 27\tFidelity = 0.500560\tKL_Divergence = 3.926508\n",
      "Epoch: 28\tFidelity = 0.500545\tKL_Divergence = 3.941763\n",
      "Epoch: 29\tFidelity = 0.500454\tKL_Divergence = 4.043752\n",
      "Epoch: 30\tFidelity = 0.500410\tKL_Divergence = 4.099374\n",
      "Epoch: 31\tFidelity = 0.500365\tKL_Divergence = 4.163941\n",
      "Epoch: 32\tFidelity = 0.500553\tKL_Divergence = 3.933948\n",
      "Epoch: 33\tFidelity = 0.500470\tKL_Divergence = 4.024298\n",
      "Epoch: 34\tFidelity = 0.500462\tKL_Divergence = 4.033533\n",
      "Epoch: 35\tFidelity = 0.500549\tKL_Divergence = 3.938075\n",
      "Epoch: 36\tFidelity = 0.500541\tKL_Divergence = 3.945993\n",
      "Epoch: 37\tFidelity = 0.500578\tKL_Divergence = 3.908459\n",
      "Epoch: 38\tFidelity = 0.500480\tKL_Divergence = 4.012016\n",
      "Epoch: 39\tFidelity = 0.500498\tKL_Divergence = 3.991620\n",
      "Epoch: 40\tFidelity = 0.500465\tKL_Divergence = 4.030397\n",
      "Epoch: 41\tFidelity = 0.500524\tKL_Divergence = 3.963715\n",
      "Epoch: 42\tFidelity = 0.500322\tKL_Divergence = 4.233243\n",
      "Epoch: 43\tFidelity = 0.500515\tKL_Divergence = 3.973427\n",
      "Epoch: 44\tFidelity = 0.500510\tKL_Divergence = 3.978220\n",
      "Epoch: 45\tFidelity = 0.500510\tKL_Divergence = 3.978571\n",
      "Epoch: 46\tFidelity = 0.500457\tKL_Divergence = 4.039599\n",
      "Epoch: 47\tFidelity = 0.500486\tKL_Divergence = 4.005788\n",
      "Epoch: 48\tFidelity = 0.500548\tKL_Divergence = 3.938258\n",
      "Epoch: 49\tFidelity = 0.500383\tKL_Divergence = 4.137591\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:28:23,068] Trial 374 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500447\tKL_Divergence = 4.051557\n",
      "Total time elapsed during training: 37.795 s\n",
      "Trial 374 pruned. \n",
      "Epoch: 1\tFidelity = 0.500439\tKL_Divergence = 4.061577\n",
      "Epoch: 2\tFidelity = 0.500455\tKL_Divergence = 4.042295\n",
      "Epoch: 3\tFidelity = 0.500470\tKL_Divergence = 4.024098\n",
      "Epoch: 4\tFidelity = 0.500480\tKL_Divergence = 4.012668\n",
      "Epoch: 5\tFidelity = 0.500485\tKL_Divergence = 4.006849\n",
      "Epoch: 6\tFidelity = 0.500499\tKL_Divergence = 3.990519\n",
      "Epoch: 7\tFidelity = 0.500477\tKL_Divergence = 4.015710\n",
      "Epoch: 8\tFidelity = 0.500387\tKL_Divergence = 4.132015\n",
      "Epoch: 9\tFidelity = 0.500503\tKL_Divergence = 3.986363\n",
      "Epoch: 10\tFidelity = 0.500404\tKL_Divergence = 4.107298\n",
      "Epoch: 11\tFidelity = 0.500614\tKL_Divergence = 3.874806\n",
      "Epoch: 12\tFidelity = 0.500454\tKL_Divergence = 4.042842\n",
      "Epoch: 13\tFidelity = 0.500431\tKL_Divergence = 4.071260\n",
      "Epoch: 14\tFidelity = 0.500463\tKL_Divergence = 4.030873\n",
      "Epoch: 15\tFidelity = 0.500485\tKL_Divergence = 4.006137\n",
      "Epoch: 16\tFidelity = 0.500504\tKL_Divergence = 3.983915\n",
      "Epoch: 17\tFidelity = 0.500540\tKL_Divergence = 3.945785\n",
      "Epoch: 18\tFidelity = 0.500427\tKL_Divergence = 4.076827\n",
      "Epoch: 19\tFidelity = 0.500418\tKL_Divergence = 4.088501\n",
      "Epoch: 20\tFidelity = 0.500537\tKL_Divergence = 3.949923\n",
      "Epoch: 21\tFidelity = 0.500487\tKL_Divergence = 4.003922\n",
      "Epoch: 22\tFidelity = 0.500459\tKL_Divergence = 4.036614\n",
      "Epoch: 23\tFidelity = 0.500500\tKL_Divergence = 3.989914\n",
      "Epoch: 24\tFidelity = 0.500453\tKL_Divergence = 4.044713\n",
      "Epoch: 25\tFidelity = 0.500431\tKL_Divergence = 4.072387\n",
      "Epoch: 26\tFidelity = 0.500497\tKL_Divergence = 3.993244\n",
      "Epoch: 27\tFidelity = 0.500436\tKL_Divergence = 4.064920\n",
      "Epoch: 28\tFidelity = 0.500484\tKL_Divergence = 4.007724\n",
      "Epoch: 29\tFidelity = 0.500537\tKL_Divergence = 3.950229\n",
      "Epoch: 30\tFidelity = 0.500437\tKL_Divergence = 4.064600\n",
      "Epoch: 31\tFidelity = 0.500471\tKL_Divergence = 4.022530\n",
      "Epoch: 32\tFidelity = 0.500616\tKL_Divergence = 3.873808\n",
      "Epoch: 33\tFidelity = 0.500467\tKL_Divergence = 4.027384\n",
      "Epoch: 34\tFidelity = 0.500435\tKL_Divergence = 4.066264\n",
      "Epoch: 35\tFidelity = 0.500557\tKL_Divergence = 3.929510\n",
      "Epoch: 36\tFidelity = 0.500392\tKL_Divergence = 4.124799\n",
      "Epoch: 37\tFidelity = 0.500396\tKL_Divergence = 4.118099\n",
      "Epoch: 38\tFidelity = 0.500443\tKL_Divergence = 4.056877\n",
      "Epoch: 39\tFidelity = 0.500410\tKL_Divergence = 4.100236\n",
      "Epoch: 40\tFidelity = 0.500408\tKL_Divergence = 4.102585\n",
      "Epoch: 41\tFidelity = 0.500579\tKL_Divergence = 3.907985\n",
      "Epoch: 42\tFidelity = 0.500464\tKL_Divergence = 4.031147\n",
      "Epoch: 43\tFidelity = 0.500384\tKL_Divergence = 4.135993\n",
      "Epoch: 44\tFidelity = 0.500392\tKL_Divergence = 4.124302\n",
      "Epoch: 45\tFidelity = 0.500376\tKL_Divergence = 4.147817\n",
      "Epoch: 46\tFidelity = 0.500573\tKL_Divergence = 3.913237\n",
      "Epoch: 47\tFidelity = 0.500417\tKL_Divergence = 4.089847\n",
      "Epoch: 48\tFidelity = 0.500388\tKL_Divergence = 4.129660\n",
      "Epoch: 49\tFidelity = 0.500398\tKL_Divergence = 4.115682\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:29:00,788] Trial 375 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500448\tKL_Divergence = 4.050028\n",
      "Total time elapsed during training: 37.561 s\n",
      "Trial 375 pruned. \n",
      "Epoch: 1\tFidelity = 0.500534\tKL_Divergence = 3.952895\n",
      "Epoch: 2\tFidelity = 0.500461\tKL_Divergence = 4.035012\n",
      "Epoch: 3\tFidelity = 0.500412\tKL_Divergence = 4.097259\n",
      "Epoch: 4\tFidelity = 0.500580\tKL_Divergence = 3.907404\n",
      "Epoch: 5\tFidelity = 0.500472\tKL_Divergence = 4.021769\n",
      "Epoch: 6\tFidelity = 0.500333\tKL_Divergence = 4.215891\n",
      "Epoch: 7\tFidelity = 0.500517\tKL_Divergence = 3.970566\n",
      "Epoch: 8\tFidelity = 0.500485\tKL_Divergence = 4.005611\n",
      "Epoch: 9\tFidelity = 0.500499\tKL_Divergence = 3.990441\n",
      "Epoch: 10\tFidelity = 0.500361\tKL_Divergence = 4.169099\n",
      "Epoch: 11\tFidelity = 0.500621\tKL_Divergence = 3.869105\n",
      "Epoch: 12\tFidelity = 0.500466\tKL_Divergence = 4.027644\n",
      "Epoch: 13\tFidelity = 0.500399\tKL_Divergence = 4.114612\n",
      "Epoch: 14\tFidelity = 0.500403\tKL_Divergence = 4.108466\n",
      "Epoch: 15\tFidelity = 0.500570\tKL_Divergence = 3.916843\n",
      "Epoch: 16\tFidelity = 0.500389\tKL_Divergence = 4.128042\n",
      "Epoch: 17\tFidelity = 0.500492\tKL_Divergence = 3.998224\n",
      "Epoch: 18\tFidelity = 0.500494\tKL_Divergence = 3.995831\n",
      "Epoch: 19\tFidelity = 0.500334\tKL_Divergence = 4.213452\n",
      "Epoch: 20\tFidelity = 0.500366\tKL_Divergence = 4.163195\n",
      "Epoch: 21\tFidelity = 0.500344\tKL_Divergence = 4.197916\n",
      "Epoch: 22\tFidelity = 0.500421\tKL_Divergence = 4.085200\n",
      "Epoch: 23\tFidelity = 0.500613\tKL_Divergence = 3.876694\n",
      "Epoch: 24\tFidelity = 0.500316\tKL_Divergence = 4.244978\n",
      "Epoch: 25\tFidelity = 0.500532\tKL_Divergence = 3.954589\n",
      "Epoch: 26\tFidelity = 0.500382\tKL_Divergence = 4.138554\n",
      "Epoch: 27\tFidelity = 0.500417\tKL_Divergence = 4.090461\n",
      "Epoch: 28\tFidelity = 0.500525\tKL_Divergence = 3.962346\n",
      "Epoch: 29\tFidelity = 0.500371\tKL_Divergence = 4.154833\n",
      "Epoch: 30\tFidelity = 0.500433\tKL_Divergence = 4.068463\n",
      "Epoch: 31\tFidelity = 0.500391\tKL_Divergence = 4.126677\n",
      "Epoch: 32\tFidelity = 0.500551\tKL_Divergence = 3.934732\n",
      "Epoch: 33\tFidelity = 0.500469\tKL_Divergence = 4.025846\n",
      "Epoch: 34\tFidelity = 0.500512\tKL_Divergence = 3.976554\n",
      "Epoch: 35\tFidelity = 0.500305\tKL_Divergence = 4.264263\n",
      "Epoch: 36\tFidelity = 0.500474\tKL_Divergence = 4.019111\n",
      "Epoch: 37\tFidelity = 0.500343\tKL_Divergence = 4.198793\n",
      "Epoch: 38\tFidelity = 0.500647\tKL_Divergence = 3.846449\n",
      "Epoch: 39\tFidelity = 0.500476\tKL_Divergence = 4.016946\n",
      "Epoch: 40\tFidelity = 0.500370\tKL_Divergence = 4.155879\n",
      "Epoch: 41\tFidelity = 0.500359\tKL_Divergence = 4.172525\n",
      "Epoch: 42\tFidelity = 0.500538\tKL_Divergence = 3.948841\n",
      "Epoch: 43\tFidelity = 0.500386\tKL_Divergence = 4.133058\n",
      "Epoch: 44\tFidelity = 0.500316\tKL_Divergence = 4.244933\n",
      "Epoch: 45\tFidelity = 0.500426\tKL_Divergence = 4.077477\n",
      "Epoch: 46\tFidelity = 0.500415\tKL_Divergence = 4.092944\n",
      "Epoch: 47\tFidelity = 0.500455\tKL_Divergence = 4.042593\n",
      "Epoch: 48\tFidelity = 0.500341\tKL_Divergence = 4.201732\n",
      "Epoch: 49\tFidelity = 0.500479\tKL_Divergence = 4.013762\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:29:44,595] Trial 376 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500326\tKL_Divergence = 4.226262\n",
      "Total time elapsed during training: 43.642 s\n",
      "Trial 376 pruned. \n",
      "Epoch: 1\tFidelity = 0.500397\tKL_Divergence = 4.117117\n",
      "Epoch: 2\tFidelity = 0.500427\tKL_Divergence = 4.077077\n",
      "Epoch: 3\tFidelity = 0.500453\tKL_Divergence = 4.044522\n",
      "Epoch: 4\tFidelity = 0.500466\tKL_Divergence = 4.028908\n",
      "Epoch: 5\tFidelity = 0.500434\tKL_Divergence = 4.067664\n",
      "Epoch: 6\tFidelity = 0.500433\tKL_Divergence = 4.069701\n",
      "Epoch: 7\tFidelity = 0.500432\tKL_Divergence = 4.070840\n",
      "Epoch: 8\tFidelity = 0.500437\tKL_Divergence = 4.064222\n",
      "Epoch: 9\tFidelity = 0.500461\tKL_Divergence = 4.034157\n",
      "Epoch: 10\tFidelity = 0.500441\tKL_Divergence = 4.058740\n",
      "Epoch: 11\tFidelity = 0.500446\tKL_Divergence = 4.053300\n",
      "Epoch: 12\tFidelity = 0.500430\tKL_Divergence = 4.073491\n",
      "Epoch: 13\tFidelity = 0.500442\tKL_Divergence = 4.058114\n",
      "Epoch: 14\tFidelity = 0.500453\tKL_Divergence = 4.044806\n",
      "Epoch: 15\tFidelity = 0.500454\tKL_Divergence = 4.043158\n",
      "Epoch: 16\tFidelity = 0.500416\tKL_Divergence = 4.091345\n",
      "Epoch: 17\tFidelity = 0.500422\tKL_Divergence = 4.083546\n",
      "Epoch: 18\tFidelity = 0.500470\tKL_Divergence = 4.023551\n",
      "Epoch: 19\tFidelity = 0.500471\tKL_Divergence = 4.022793\n",
      "Epoch: 20\tFidelity = 0.500445\tKL_Divergence = 4.053685\n",
      "Epoch: 21\tFidelity = 0.500442\tKL_Divergence = 4.057768\n",
      "Epoch: 22\tFidelity = 0.500449\tKL_Divergence = 4.049618\n",
      "Epoch: 23\tFidelity = 0.500464\tKL_Divergence = 4.030685\n",
      "Epoch: 24\tFidelity = 0.500441\tKL_Divergence = 4.059303\n",
      "Epoch: 25\tFidelity = 0.500445\tKL_Divergence = 4.054884\n",
      "Epoch: 26\tFidelity = 0.500420\tKL_Divergence = 4.086012\n",
      "Epoch: 27\tFidelity = 0.500433\tKL_Divergence = 4.070080\n",
      "Epoch: 28\tFidelity = 0.500456\tKL_Divergence = 4.040890\n",
      "Epoch: 29\tFidelity = 0.500451\tKL_Divergence = 4.047208\n",
      "Epoch: 30\tFidelity = 0.500456\tKL_Divergence = 4.041094\n",
      "Epoch: 31\tFidelity = 0.500427\tKL_Divergence = 4.077601\n",
      "Epoch: 32\tFidelity = 0.500411\tKL_Divergence = 4.098513\n",
      "Epoch: 33\tFidelity = 0.500430\tKL_Divergence = 4.073869\n",
      "Epoch: 34\tFidelity = 0.500452\tKL_Divergence = 4.045913\n",
      "Epoch: 35\tFidelity = 0.500456\tKL_Divergence = 4.040562\n",
      "Epoch: 36\tFidelity = 0.500447\tKL_Divergence = 4.052176\n",
      "Epoch: 37\tFidelity = 0.500473\tKL_Divergence = 4.020843\n",
      "Epoch: 38\tFidelity = 0.500435\tKL_Divergence = 4.067315\n",
      "Epoch: 39\tFidelity = 0.500464\tKL_Divergence = 4.031447\n",
      "Epoch: 40\tFidelity = 0.500446\tKL_Divergence = 4.052406\n",
      "Epoch: 41\tFidelity = 0.500412\tKL_Divergence = 4.097377\n",
      "Epoch: 42\tFidelity = 0.500456\tKL_Divergence = 4.040162\n",
      "Epoch: 43\tFidelity = 0.500468\tKL_Divergence = 4.026597\n",
      "Epoch: 44\tFidelity = 0.500437\tKL_Divergence = 4.064253\n",
      "Epoch: 45\tFidelity = 0.500430\tKL_Divergence = 4.073231\n",
      "Epoch: 46\tFidelity = 0.500413\tKL_Divergence = 4.095768\n",
      "Epoch: 47\tFidelity = 0.500447\tKL_Divergence = 4.051667\n",
      "Epoch: 48\tFidelity = 0.500440\tKL_Divergence = 4.060161\n",
      "Epoch: 49\tFidelity = 0.500490\tKL_Divergence = 4.000700\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:30:30,959] Trial 377 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500446\tKL_Divergence = 4.053148\n",
      "Total time elapsed during training: 46.197 s\n",
      "Trial 377 pruned. \n",
      "Epoch: 1\tFidelity = 0.500359\tKL_Divergence = 4.172917\n",
      "Epoch: 2\tFidelity = 0.500489\tKL_Divergence = 4.001753\n",
      "Epoch: 3\tFidelity = 0.500479\tKL_Divergence = 4.013061\n",
      "Epoch: 4\tFidelity = 0.500457\tKL_Divergence = 4.039699\n",
      "Epoch: 5\tFidelity = 0.500460\tKL_Divergence = 4.035723\n",
      "Epoch: 6\tFidelity = 0.500544\tKL_Divergence = 3.943193\n",
      "Epoch: 7\tFidelity = 0.500447\tKL_Divergence = 4.051904\n",
      "Epoch: 8\tFidelity = 0.500414\tKL_Divergence = 4.093764\n",
      "Epoch: 9\tFidelity = 0.500384\tKL_Divergence = 4.136002\n",
      "Epoch: 10\tFidelity = 0.500516\tKL_Divergence = 3.972253\n",
      "Epoch: 11\tFidelity = 0.500430\tKL_Divergence = 4.073301\n",
      "Epoch: 12\tFidelity = 0.500496\tKL_Divergence = 3.993852\n",
      "Epoch: 13\tFidelity = 0.500380\tKL_Divergence = 4.141482\n",
      "Epoch: 14\tFidelity = 0.500487\tKL_Divergence = 4.004141\n",
      "Epoch: 15\tFidelity = 0.500404\tKL_Divergence = 4.108088\n",
      "Epoch: 16\tFidelity = 0.500461\tKL_Divergence = 4.034405\n",
      "Epoch: 17\tFidelity = 0.500495\tKL_Divergence = 3.995555\n",
      "Epoch: 18\tFidelity = 0.500523\tKL_Divergence = 3.964631\n",
      "Epoch: 19\tFidelity = 0.500471\tKL_Divergence = 4.022787\n",
      "Epoch: 20\tFidelity = 0.500432\tKL_Divergence = 4.071044\n",
      "Epoch: 21\tFidelity = 0.500471\tKL_Divergence = 4.022399\n",
      "Epoch: 22\tFidelity = 0.500399\tKL_Divergence = 4.114126\n",
      "Epoch: 23\tFidelity = 0.500470\tKL_Divergence = 4.023391\n",
      "Epoch: 24\tFidelity = 0.500511\tKL_Divergence = 3.977660\n",
      "Epoch: 25\tFidelity = 0.500521\tKL_Divergence = 3.966973\n",
      "Epoch: 26\tFidelity = 0.500481\tKL_Divergence = 4.010648\n",
      "Epoch: 27\tFidelity = 0.500623\tKL_Divergence = 3.867054\n",
      "Epoch: 28\tFidelity = 0.500515\tKL_Divergence = 3.973426\n",
      "Epoch: 29\tFidelity = 0.500492\tKL_Divergence = 3.997961\n",
      "Epoch: 30\tFidelity = 0.500464\tKL_Divergence = 4.030715\n",
      "Epoch: 31\tFidelity = 0.500547\tKL_Divergence = 3.939811\n",
      "Epoch: 32\tFidelity = 0.500462\tKL_Divergence = 4.033646\n",
      "Epoch: 33\tFidelity = 0.500516\tKL_Divergence = 3.972375\n",
      "Epoch: 34\tFidelity = 0.500452\tKL_Divergence = 4.045279\n",
      "Epoch: 35\tFidelity = 0.500403\tKL_Divergence = 4.108616\n",
      "Epoch: 36\tFidelity = 0.500539\tKL_Divergence = 3.948004\n",
      "Epoch: 37\tFidelity = 0.500499\tKL_Divergence = 3.990256\n",
      "Epoch: 38\tFidelity = 0.500533\tKL_Divergence = 3.953931\n",
      "Epoch: 39\tFidelity = 0.500540\tKL_Divergence = 3.946574\n",
      "Epoch: 40\tFidelity = 0.500413\tKL_Divergence = 4.095154\n",
      "Epoch: 41\tFidelity = 0.500537\tKL_Divergence = 3.949809\n",
      "Epoch: 42\tFidelity = 0.500509\tKL_Divergence = 3.980077\n",
      "Epoch: 43\tFidelity = 0.500470\tKL_Divergence = 4.023517\n",
      "Epoch: 44\tFidelity = 0.500461\tKL_Divergence = 4.035077\n",
      "Epoch: 45\tFidelity = 0.500483\tKL_Divergence = 4.008749\n",
      "Epoch: 46\tFidelity = 0.500428\tKL_Divergence = 4.075830\n",
      "Epoch: 47\tFidelity = 0.500518\tKL_Divergence = 3.969735\n",
      "Epoch: 48\tFidelity = 0.500507\tKL_Divergence = 3.981237\n",
      "Epoch: 49\tFidelity = 0.500446\tKL_Divergence = 4.052467\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:31:52,615] Trial 378 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500471\tKL_Divergence = 4.022872\n",
      "Total time elapsed during training: 81.486 s\n",
      "Trial 378 pruned. \n",
      "Epoch: 1\tFidelity = 0.500510\tKL_Divergence = 3.977963\n",
      "Epoch: 2\tFidelity = 0.500449\tKL_Divergence = 4.049307\n",
      "Epoch: 3\tFidelity = 0.500515\tKL_Divergence = 3.973520\n",
      "Epoch: 4\tFidelity = 0.500458\tKL_Divergence = 4.037500\n",
      "Epoch: 5\tFidelity = 0.500555\tKL_Divergence = 3.931610\n",
      "Epoch: 6\tFidelity = 0.500539\tKL_Divergence = 3.947067\n",
      "Epoch: 7\tFidelity = 0.500502\tKL_Divergence = 3.987008\n",
      "Epoch: 8\tFidelity = 0.500543\tKL_Divergence = 3.942978\n",
      "Epoch: 9\tFidelity = 0.500516\tKL_Divergence = 3.972258\n",
      "Epoch: 10\tFidelity = 0.500557\tKL_Divergence = 3.929284\n",
      "Epoch: 11\tFidelity = 0.500487\tKL_Divergence = 4.003884\n",
      "Epoch: 12\tFidelity = 0.500460\tKL_Divergence = 4.035946\n",
      "Epoch: 13\tFidelity = 0.500501\tKL_Divergence = 3.987696\n",
      "Epoch: 14\tFidelity = 0.500442\tKL_Divergence = 4.057701\n",
      "Epoch: 15\tFidelity = 0.500496\tKL_Divergence = 3.993656\n",
      "Epoch: 16\tFidelity = 0.500444\tKL_Divergence = 4.054558\n",
      "Epoch: 17\tFidelity = 0.500499\tKL_Divergence = 3.989503\n",
      "Epoch: 18\tFidelity = 0.500450\tKL_Divergence = 4.047621\n",
      "Epoch: 19\tFidelity = 0.500440\tKL_Divergence = 4.060522\n",
      "Epoch: 20\tFidelity = 0.500452\tKL_Divergence = 4.044726\n",
      "Epoch: 21\tFidelity = 0.500443\tKL_Divergence = 4.056847\n",
      "Epoch: 22\tFidelity = 0.500437\tKL_Divergence = 4.063847\n",
      "Epoch: 23\tFidelity = 0.500522\tKL_Divergence = 3.965548\n",
      "Epoch: 24\tFidelity = 0.500521\tKL_Divergence = 3.966300\n",
      "Epoch: 25\tFidelity = 0.500492\tKL_Divergence = 3.998391\n",
      "Epoch: 26\tFidelity = 0.500492\tKL_Divergence = 3.998687\n",
      "Epoch: 27\tFidelity = 0.500536\tKL_Divergence = 3.950535\n",
      "Epoch: 28\tFidelity = 0.500509\tKL_Divergence = 3.979373\n",
      "Epoch: 29\tFidelity = 0.500459\tKL_Divergence = 4.036422\n",
      "Epoch: 30\tFidelity = 0.500507\tKL_Divergence = 3.981272\n",
      "Epoch: 31\tFidelity = 0.500497\tKL_Divergence = 3.992307\n",
      "Epoch: 32\tFidelity = 0.500463\tKL_Divergence = 4.032378\n",
      "Epoch: 33\tFidelity = 0.500433\tKL_Divergence = 4.069207\n",
      "Epoch: 34\tFidelity = 0.500432\tKL_Divergence = 4.070970\n",
      "Epoch: 35\tFidelity = 0.500455\tKL_Divergence = 4.041559\n",
      "Epoch: 36\tFidelity = 0.500490\tKL_Divergence = 4.000323\n",
      "Epoch: 37\tFidelity = 0.500485\tKL_Divergence = 4.006566\n",
      "Epoch: 38\tFidelity = 0.500507\tKL_Divergence = 3.981365\n",
      "Epoch: 39\tFidelity = 0.500472\tKL_Divergence = 4.021112\n",
      "Epoch: 40\tFidelity = 0.500474\tKL_Divergence = 4.019016\n",
      "Epoch: 41\tFidelity = 0.500522\tKL_Divergence = 3.965881\n",
      "Epoch: 42\tFidelity = 0.500557\tKL_Divergence = 3.929103\n",
      "Epoch: 43\tFidelity = 0.500484\tKL_Divergence = 4.007305\n",
      "Epoch: 44\tFidelity = 0.500515\tKL_Divergence = 3.973317\n",
      "Epoch: 45\tFidelity = 0.500471\tKL_Divergence = 4.022011\n",
      "Epoch: 46\tFidelity = 0.500443\tKL_Divergence = 4.056285\n",
      "Epoch: 47\tFidelity = 0.500525\tKL_Divergence = 3.962161\n",
      "Epoch: 48\tFidelity = 0.500471\tKL_Divergence = 4.022917\n",
      "Epoch: 49\tFidelity = 0.500455\tKL_Divergence = 4.041591\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:32:31,229] Trial 379 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500475\tKL_Divergence = 4.017551\n",
      "Total time elapsed during training: 38.430 s\n",
      "Trial 379 pruned. \n",
      "Epoch: 1\tFidelity = 0.500443\tKL_Divergence = 4.056033\n",
      "Epoch: 2\tFidelity = 0.500463\tKL_Divergence = 4.032143\n",
      "Epoch: 3\tFidelity = 0.500531\tKL_Divergence = 3.956053\n",
      "Epoch: 4\tFidelity = 0.500517\tKL_Divergence = 3.970714\n",
      "Epoch: 5\tFidelity = 0.500442\tKL_Divergence = 4.057639\n",
      "Epoch: 6\tFidelity = 0.500537\tKL_Divergence = 3.950008\n",
      "Epoch: 7\tFidelity = 0.500474\tKL_Divergence = 4.019193\n",
      "Epoch: 8\tFidelity = 0.500466\tKL_Divergence = 4.028114\n",
      "Epoch: 9\tFidelity = 0.500548\tKL_Divergence = 3.938802\n",
      "Epoch: 10\tFidelity = 0.500575\tKL_Divergence = 3.911878\n",
      "Epoch: 11\tFidelity = 0.500437\tKL_Divergence = 4.064425\n",
      "Epoch: 12\tFidelity = 0.500432\tKL_Divergence = 4.070420\n",
      "Epoch: 13\tFidelity = 0.500477\tKL_Divergence = 4.015784\n",
      "Epoch: 14\tFidelity = 0.500447\tKL_Divergence = 4.051744\n",
      "Epoch: 15\tFidelity = 0.500482\tKL_Divergence = 4.009218\n",
      "Epoch: 16\tFidelity = 0.500532\tKL_Divergence = 3.954983\n",
      "Epoch: 17\tFidelity = 0.500518\tKL_Divergence = 3.969600\n",
      "Epoch: 18\tFidelity = 0.500482\tKL_Divergence = 4.009621\n",
      "Epoch: 19\tFidelity = 0.500446\tKL_Divergence = 4.053421\n",
      "Epoch: 20\tFidelity = 0.500580\tKL_Divergence = 3.907213\n",
      "Epoch: 21\tFidelity = 0.500433\tKL_Divergence = 4.068603\n",
      "Epoch: 22\tFidelity = 0.500480\tKL_Divergence = 4.011811\n",
      "Epoch: 23\tFidelity = 0.500556\tKL_Divergence = 3.930689\n",
      "Epoch: 24\tFidelity = 0.500499\tKL_Divergence = 3.990040\n",
      "Epoch: 25\tFidelity = 0.500465\tKL_Divergence = 4.029463\n",
      "Epoch: 26\tFidelity = 0.500473\tKL_Divergence = 4.019735\n",
      "Epoch: 27\tFidelity = 0.500442\tKL_Divergence = 4.057394\n",
      "Epoch: 28\tFidelity = 0.500542\tKL_Divergence = 3.944540\n",
      "Epoch: 29\tFidelity = 0.500553\tKL_Divergence = 3.933435\n",
      "Epoch: 30\tFidelity = 0.500545\tKL_Divergence = 3.941882\n",
      "Epoch: 31\tFidelity = 0.500561\tKL_Divergence = 3.925086\n",
      "Epoch: 32\tFidelity = 0.500490\tKL_Divergence = 4.000138\n",
      "Epoch: 33\tFidelity = 0.500532\tKL_Divergence = 3.955436\n",
      "Epoch: 34\tFidelity = 0.500597\tKL_Divergence = 3.890809\n",
      "Epoch: 35\tFidelity = 0.500498\tKL_Divergence = 3.991695\n",
      "Epoch: 36\tFidelity = 0.500418\tKL_Divergence = 4.088773\n",
      "Epoch: 37\tFidelity = 0.500421\tKL_Divergence = 4.085240\n",
      "Epoch: 38\tFidelity = 0.500430\tKL_Divergence = 4.073092\n",
      "Epoch: 39\tFidelity = 0.500456\tKL_Divergence = 4.039992\n",
      "Epoch: 40\tFidelity = 0.500505\tKL_Divergence = 3.983459\n",
      "Epoch: 41\tFidelity = 0.500527\tKL_Divergence = 3.960292\n",
      "Epoch: 42\tFidelity = 0.500587\tKL_Divergence = 3.900597\n",
      "Epoch: 43\tFidelity = 0.500518\tKL_Divergence = 3.969428\n",
      "Epoch: 44\tFidelity = 0.500486\tKL_Divergence = 4.005317\n",
      "Epoch: 45\tFidelity = 0.500459\tKL_Divergence = 4.036871\n",
      "Epoch: 46\tFidelity = 0.500418\tKL_Divergence = 4.088884\n",
      "Epoch: 47\tFidelity = 0.500518\tKL_Divergence = 3.969959\n",
      "Epoch: 48\tFidelity = 0.500504\tKL_Divergence = 3.985419\n",
      "Epoch: 49\tFidelity = 0.500432\tKL_Divergence = 4.070402\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:33:10,726] Trial 380 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500508\tKL_Divergence = 3.980720\n",
      "Total time elapsed during training: 39.310 s\n",
      "Trial 380 pruned. \n",
      "Epoch: 1\tFidelity = 0.500487\tKL_Divergence = 4.004196\n",
      "Epoch: 2\tFidelity = 0.500406\tKL_Divergence = 4.105337\n",
      "Epoch: 3\tFidelity = 0.500568\tKL_Divergence = 3.918136\n",
      "Epoch: 4\tFidelity = 0.500487\tKL_Divergence = 4.003846\n",
      "Epoch: 5\tFidelity = 0.500595\tKL_Divergence = 3.892933\n",
      "Epoch: 6\tFidelity = 0.500595\tKL_Divergence = 3.892372\n",
      "Epoch: 7\tFidelity = 0.500626\tKL_Divergence = 3.864986\n",
      "Epoch: 8\tFidelity = 0.500492\tKL_Divergence = 3.998554\n",
      "Epoch: 9\tFidelity = 0.500441\tKL_Divergence = 4.059396\n",
      "Epoch: 10\tFidelity = 0.500584\tKL_Divergence = 3.903005\n",
      "Epoch: 11\tFidelity = 0.500416\tKL_Divergence = 4.090880\n",
      "Epoch: 12\tFidelity = 0.500428\tKL_Divergence = 4.075170\n",
      "Epoch: 13\tFidelity = 0.500460\tKL_Divergence = 4.035325\n",
      "Epoch: 14\tFidelity = 0.500651\tKL_Divergence = 3.842437\n",
      "Epoch: 15\tFidelity = 0.500615\tKL_Divergence = 3.874569\n",
      "Epoch: 16\tFidelity = 0.500592\tKL_Divergence = 3.895632\n",
      "Epoch: 17\tFidelity = 0.500421\tKL_Divergence = 4.084455\n",
      "Epoch: 18\tFidelity = 0.500512\tKL_Divergence = 3.976065\n",
      "Epoch: 19\tFidelity = 0.500572\tKL_Divergence = 3.914166\n",
      "Epoch: 20\tFidelity = 0.500547\tKL_Divergence = 3.939267\n",
      "Epoch: 21\tFidelity = 0.500530\tKL_Divergence = 3.956766\n",
      "Epoch: 22\tFidelity = 0.500555\tKL_Divergence = 3.930972\n",
      "Epoch: 23\tFidelity = 0.500482\tKL_Divergence = 4.009195\n",
      "Epoch: 24\tFidelity = 0.500487\tKL_Divergence = 4.003676\n",
      "Epoch: 25\tFidelity = 0.500688\tKL_Divergence = 3.811797\n",
      "Epoch: 26\tFidelity = 0.500545\tKL_Divergence = 3.941947\n",
      "Epoch: 27\tFidelity = 0.500572\tKL_Divergence = 3.914760\n",
      "Epoch: 28\tFidelity = 0.500614\tKL_Divergence = 3.874763\n",
      "Epoch: 29\tFidelity = 0.500615\tKL_Divergence = 3.874061\n",
      "Epoch: 30\tFidelity = 0.500632\tKL_Divergence = 3.858724\n",
      "Epoch: 31\tFidelity = 0.500497\tKL_Divergence = 3.992352\n",
      "Epoch: 32\tFidelity = 0.500537\tKL_Divergence = 3.949356\n",
      "Epoch: 33\tFidelity = 0.500527\tKL_Divergence = 3.959499\n",
      "Epoch: 34\tFidelity = 0.500621\tKL_Divergence = 3.869070\n",
      "Epoch: 35\tFidelity = 0.500520\tKL_Divergence = 3.967519\n",
      "Epoch: 36\tFidelity = 0.500671\tKL_Divergence = 3.825338\n",
      "Epoch: 37\tFidelity = 0.500567\tKL_Divergence = 3.919539\n",
      "Epoch: 38\tFidelity = 0.500663\tKL_Divergence = 3.832162\n",
      "Epoch: 39\tFidelity = 0.500568\tKL_Divergence = 3.918015\n",
      "Epoch: 40\tFidelity = 0.500551\tKL_Divergence = 3.934870\n",
      "Epoch: 41\tFidelity = 0.500511\tKL_Divergence = 3.977417\n",
      "Epoch: 42\tFidelity = 0.500543\tKL_Divergence = 3.943805\n",
      "Epoch: 43\tFidelity = 0.500465\tKL_Divergence = 4.029659\n",
      "Epoch: 44\tFidelity = 0.500465\tKL_Divergence = 4.029856\n",
      "Epoch: 45\tFidelity = 0.500467\tKL_Divergence = 4.026643\n",
      "Epoch: 46\tFidelity = 0.500576\tKL_Divergence = 3.910146\n",
      "Epoch: 47\tFidelity = 0.500519\tKL_Divergence = 3.968224\n",
      "Epoch: 48\tFidelity = 0.500489\tKL_Divergence = 4.001741\n",
      "Epoch: 49\tFidelity = 0.500569\tKL_Divergence = 3.917649\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:34:33,348] Trial 381 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500607\tKL_Divergence = 3.881674\n",
      "Total time elapsed during training: 82.361 s\n",
      "Trial 381 pruned. \n",
      "Epoch: 1\tFidelity = 0.500601\tKL_Divergence = 3.886552\n",
      "Epoch: 2\tFidelity = 0.500561\tKL_Divergence = 3.925573\n",
      "Epoch: 3\tFidelity = 0.500550\tKL_Divergence = 3.936117\n",
      "Epoch: 4\tFidelity = 0.500537\tKL_Divergence = 3.949528\n",
      "Epoch: 5\tFidelity = 0.500531\tKL_Divergence = 3.956191\n",
      "Epoch: 6\tFidelity = 0.500523\tKL_Divergence = 3.963691\n",
      "Epoch: 7\tFidelity = 0.500575\tKL_Divergence = 3.911760\n",
      "Epoch: 8\tFidelity = 0.500546\tKL_Divergence = 3.940446\n",
      "Epoch: 9\tFidelity = 0.500527\tKL_Divergence = 3.959969\n",
      "Epoch: 10\tFidelity = 0.500539\tKL_Divergence = 3.947211\n",
      "Epoch: 11\tFidelity = 0.500583\tKL_Divergence = 3.904026\n",
      "Epoch: 12\tFidelity = 0.500530\tKL_Divergence = 3.956993\n",
      "Epoch: 13\tFidelity = 0.500532\tKL_Divergence = 3.954818\n",
      "Epoch: 14\tFidelity = 0.500555\tKL_Divergence = 3.931653\n",
      "Epoch: 15\tFidelity = 0.500576\tKL_Divergence = 3.911032\n",
      "Epoch: 16\tFidelity = 0.500520\tKL_Divergence = 3.967927\n",
      "Epoch: 17\tFidelity = 0.500522\tKL_Divergence = 3.965419\n",
      "Epoch: 18\tFidelity = 0.500506\tKL_Divergence = 3.983106\n",
      "Epoch: 19\tFidelity = 0.500544\tKL_Divergence = 3.942078\n",
      "Epoch: 20\tFidelity = 0.500548\tKL_Divergence = 3.938793\n",
      "Epoch: 21\tFidelity = 0.500522\tKL_Divergence = 3.965744\n",
      "Epoch: 22\tFidelity = 0.500529\tKL_Divergence = 3.958428\n",
      "Epoch: 23\tFidelity = 0.500556\tKL_Divergence = 3.929863\n",
      "Epoch: 24\tFidelity = 0.500564\tKL_Divergence = 3.922737\n",
      "Epoch: 25\tFidelity = 0.500512\tKL_Divergence = 3.975523\n",
      "Epoch: 26\tFidelity = 0.500542\tKL_Divergence = 3.944759\n",
      "Epoch: 27\tFidelity = 0.500548\tKL_Divergence = 3.938307\n",
      "Epoch: 28\tFidelity = 0.500516\tKL_Divergence = 3.971522\n",
      "Epoch: 29\tFidelity = 0.500522\tKL_Divergence = 3.965073\n",
      "Epoch: 30\tFidelity = 0.500519\tKL_Divergence = 3.968069\n",
      "Epoch: 31\tFidelity = 0.500517\tKL_Divergence = 3.970167\n",
      "Epoch: 32\tFidelity = 0.500533\tKL_Divergence = 3.954210\n",
      "Epoch: 33\tFidelity = 0.500556\tKL_Divergence = 3.930271\n",
      "Epoch: 34\tFidelity = 0.500555\tKL_Divergence = 3.931053\n",
      "Epoch: 35\tFidelity = 0.500571\tKL_Divergence = 3.915472\n",
      "Epoch: 36\tFidelity = 0.500550\tKL_Divergence = 3.936098\n",
      "Epoch: 37\tFidelity = 0.500562\tKL_Divergence = 3.923895\n",
      "Epoch: 38\tFidelity = 0.500539\tKL_Divergence = 3.947890\n",
      "Epoch: 39\tFidelity = 0.500515\tKL_Divergence = 3.972422\n",
      "Epoch: 40\tFidelity = 0.500582\tKL_Divergence = 3.904564\n",
      "Epoch: 41\tFidelity = 0.500540\tKL_Divergence = 3.946786\n",
      "Epoch: 42\tFidelity = 0.500565\tKL_Divergence = 3.921425\n",
      "Epoch: 43\tFidelity = 0.500558\tKL_Divergence = 3.928489\n",
      "Epoch: 44\tFidelity = 0.500547\tKL_Divergence = 3.938899\n",
      "Epoch: 45\tFidelity = 0.500541\tKL_Divergence = 3.945729\n",
      "Epoch: 46\tFidelity = 0.500547\tKL_Divergence = 3.939672\n",
      "Epoch: 47\tFidelity = 0.500532\tKL_Divergence = 3.955014\n",
      "Epoch: 48\tFidelity = 0.500543\tKL_Divergence = 3.943494\n",
      "Epoch: 49\tFidelity = 0.500537\tKL_Divergence = 3.949172\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:35:12,787] Trial 382 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500539\tKL_Divergence = 3.947412\n",
      "Total time elapsed during training: 39.269 s\n",
      "Trial 382 pruned. \n",
      "Epoch: 1\tFidelity = 0.500594\tKL_Divergence = 3.893628\n",
      "Epoch: 2\tFidelity = 0.500547\tKL_Divergence = 3.939664\n",
      "Epoch: 3\tFidelity = 0.500559\tKL_Divergence = 3.927572\n",
      "Epoch: 4\tFidelity = 0.500487\tKL_Divergence = 4.003603\n",
      "Epoch: 5\tFidelity = 0.500492\tKL_Divergence = 3.998237\n",
      "Epoch: 6\tFidelity = 0.500561\tKL_Divergence = 3.925139\n",
      "Epoch: 7\tFidelity = 0.500499\tKL_Divergence = 3.990688\n",
      "Epoch: 8\tFidelity = 0.500513\tKL_Divergence = 3.975263\n",
      "Epoch: 9\tFidelity = 0.500552\tKL_Divergence = 3.934674\n",
      "Epoch: 10\tFidelity = 0.500544\tKL_Divergence = 3.942746\n",
      "Epoch: 11\tFidelity = 0.500477\tKL_Divergence = 4.014800\n",
      "Epoch: 12\tFidelity = 0.500564\tKL_Divergence = 3.922624\n",
      "Epoch: 13\tFidelity = 0.500590\tKL_Divergence = 3.897393\n",
      "Epoch: 14\tFidelity = 0.500559\tKL_Divergence = 3.927323\n",
      "Epoch: 15\tFidelity = 0.500572\tKL_Divergence = 3.915050\n",
      "Epoch: 16\tFidelity = 0.500537\tKL_Divergence = 3.949391\n",
      "Epoch: 17\tFidelity = 0.500549\tKL_Divergence = 3.936997\n",
      "Epoch: 18\tFidelity = 0.500521\tKL_Divergence = 3.966464\n",
      "Epoch: 19\tFidelity = 0.500528\tKL_Divergence = 3.958478\n",
      "Epoch: 20\tFidelity = 0.500543\tKL_Divergence = 3.943381\n",
      "Epoch: 21\tFidelity = 0.500484\tKL_Divergence = 4.006985\n",
      "Epoch: 22\tFidelity = 0.500520\tKL_Divergence = 3.967448\n",
      "Epoch: 23\tFidelity = 0.500561\tKL_Divergence = 3.925704\n",
      "Epoch: 24\tFidelity = 0.500559\tKL_Divergence = 3.927039\n",
      "Epoch: 25\tFidelity = 0.500509\tKL_Divergence = 3.978890\n",
      "Epoch: 26\tFidelity = 0.500558\tKL_Divergence = 3.928614\n",
      "Epoch: 27\tFidelity = 0.500489\tKL_Divergence = 4.001104\n",
      "Epoch: 28\tFidelity = 0.500595\tKL_Divergence = 3.892703\n",
      "Epoch: 29\tFidelity = 0.500506\tKL_Divergence = 3.982495\n",
      "Epoch: 30\tFidelity = 0.500532\tKL_Divergence = 3.954830\n",
      "Epoch: 31\tFidelity = 0.500575\tKL_Divergence = 3.911480\n",
      "Epoch: 32\tFidelity = 0.500537\tKL_Divergence = 3.949405\n",
      "Epoch: 33\tFidelity = 0.500509\tKL_Divergence = 3.979825\n",
      "Epoch: 34\tFidelity = 0.500561\tKL_Divergence = 3.925722\n",
      "Epoch: 35\tFidelity = 0.500584\tKL_Divergence = 3.903191\n",
      "Epoch: 36\tFidelity = 0.500583\tKL_Divergence = 3.903602\n",
      "Epoch: 37\tFidelity = 0.500532\tKL_Divergence = 3.954676\n",
      "Epoch: 38\tFidelity = 0.500538\tKL_Divergence = 3.948402\n",
      "Epoch: 39\tFidelity = 0.500593\tKL_Divergence = 3.894982\n",
      "Epoch: 40\tFidelity = 0.500521\tKL_Divergence = 3.965940\n",
      "Epoch: 41\tFidelity = 0.500536\tKL_Divergence = 3.950472\n",
      "Epoch: 42\tFidelity = 0.500526\tKL_Divergence = 3.961051\n",
      "Epoch: 43\tFidelity = 0.500525\tKL_Divergence = 3.961932\n",
      "Epoch: 44\tFidelity = 0.500491\tKL_Divergence = 3.999595\n",
      "Epoch: 45\tFidelity = 0.500562\tKL_Divergence = 3.924401\n",
      "Epoch: 46\tFidelity = 0.500518\tKL_Divergence = 3.969255\n",
      "Epoch: 47\tFidelity = 0.500539\tKL_Divergence = 3.947354\n",
      "Epoch: 48\tFidelity = 0.500523\tKL_Divergence = 3.963818\n",
      "Epoch: 49\tFidelity = 0.500480\tKL_Divergence = 4.012071\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:35:45,732] Trial 383 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500520\tKL_Divergence = 3.967651\n",
      "Total time elapsed during training: 32.775 s\n",
      "Trial 383 pruned. \n",
      "Epoch: 1\tFidelity = 0.500570\tKL_Divergence = 3.916894\n",
      "Epoch: 2\tFidelity = 0.500529\tKL_Divergence = 3.957611\n",
      "Epoch: 3\tFidelity = 0.500565\tKL_Divergence = 3.921335\n",
      "Epoch: 4\tFidelity = 0.500547\tKL_Divergence = 3.939732\n",
      "Epoch: 5\tFidelity = 0.500511\tKL_Divergence = 3.977487\n",
      "Epoch: 6\tFidelity = 0.500552\tKL_Divergence = 3.933831\n",
      "Epoch: 7\tFidelity = 0.500531\tKL_Divergence = 3.956201\n",
      "Epoch: 8\tFidelity = 0.500522\tKL_Divergence = 3.965500\n",
      "Epoch: 9\tFidelity = 0.500515\tKL_Divergence = 3.973338\n",
      "Epoch: 10\tFidelity = 0.500499\tKL_Divergence = 3.990523\n",
      "Epoch: 11\tFidelity = 0.500523\tKL_Divergence = 3.964054\n",
      "Epoch: 12\tFidelity = 0.500500\tKL_Divergence = 3.989555\n",
      "Epoch: 13\tFidelity = 0.500549\tKL_Divergence = 3.937798\n",
      "Epoch: 14\tFidelity = 0.500498\tKL_Divergence = 3.991204\n",
      "Epoch: 15\tFidelity = 0.500534\tKL_Divergence = 3.952803\n",
      "Epoch: 16\tFidelity = 0.500502\tKL_Divergence = 3.986840\n",
      "Epoch: 17\tFidelity = 0.500527\tKL_Divergence = 3.959843\n",
      "Epoch: 18\tFidelity = 0.500560\tKL_Divergence = 3.926460\n",
      "Epoch: 19\tFidelity = 0.500516\tKL_Divergence = 3.971634\n",
      "Epoch: 20\tFidelity = 0.500520\tKL_Divergence = 3.967804\n",
      "Epoch: 21\tFidelity = 0.500585\tKL_Divergence = 3.902456\n",
      "Epoch: 22\tFidelity = 0.500531\tKL_Divergence = 3.955568\n",
      "Epoch: 23\tFidelity = 0.500501\tKL_Divergence = 3.987638\n",
      "Epoch: 24\tFidelity = 0.500557\tKL_Divergence = 3.928896\n",
      "Epoch: 25\tFidelity = 0.500490\tKL_Divergence = 4.000290\n",
      "Epoch: 26\tFidelity = 0.500520\tKL_Divergence = 3.967643\n",
      "Epoch: 27\tFidelity = 0.500504\tKL_Divergence = 3.985240\n",
      "Epoch: 28\tFidelity = 0.500491\tKL_Divergence = 3.998966\n",
      "Epoch: 29\tFidelity = 0.500554\tKL_Divergence = 3.932006\n",
      "Epoch: 30\tFidelity = 0.500512\tKL_Divergence = 3.976205\n",
      "Epoch: 31\tFidelity = 0.500502\tKL_Divergence = 3.987063\n",
      "Epoch: 32\tFidelity = 0.500549\tKL_Divergence = 3.937706\n",
      "Epoch: 33\tFidelity = 0.500490\tKL_Divergence = 4.000004\n",
      "Epoch: 34\tFidelity = 0.500536\tKL_Divergence = 3.950916\n",
      "Epoch: 35\tFidelity = 0.500513\tKL_Divergence = 3.975006\n",
      "Epoch: 36\tFidelity = 0.500589\tKL_Divergence = 3.898408\n",
      "Epoch: 37\tFidelity = 0.500485\tKL_Divergence = 4.005840\n",
      "Epoch: 38\tFidelity = 0.500571\tKL_Divergence = 3.915582\n",
      "Epoch: 39\tFidelity = 0.500554\tKL_Divergence = 3.932205\n",
      "Epoch: 40\tFidelity = 0.500497\tKL_Divergence = 3.992274\n",
      "Epoch: 41\tFidelity = 0.500574\tKL_Divergence = 3.912570\n",
      "Epoch: 42\tFidelity = 0.500479\tKL_Divergence = 4.013076\n",
      "Epoch: 43\tFidelity = 0.500546\tKL_Divergence = 3.940394\n",
      "Epoch: 44\tFidelity = 0.500516\tKL_Divergence = 3.971450\n",
      "Epoch: 45\tFidelity = 0.500500\tKL_Divergence = 3.988974\n",
      "Epoch: 46\tFidelity = 0.500505\tKL_Divergence = 3.983375\n",
      "Epoch: 47\tFidelity = 0.500536\tKL_Divergence = 3.950204\n",
      "Epoch: 48\tFidelity = 0.500515\tKL_Divergence = 3.972312\n",
      "Epoch: 49\tFidelity = 0.500543\tKL_Divergence = 3.943577\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:36:18,330] Trial 384 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500540\tKL_Divergence = 3.946538\n",
      "Total time elapsed during training: 32.420 s\n",
      "Trial 384 pruned. \n",
      "Epoch: 1\tFidelity = 0.500555\tKL_Divergence = 3.931161\n",
      "Epoch: 2\tFidelity = 0.500480\tKL_Divergence = 4.012369\n",
      "Epoch: 3\tFidelity = 0.500533\tKL_Divergence = 3.953419\n",
      "Epoch: 4\tFidelity = 0.500472\tKL_Divergence = 4.021370\n",
      "Epoch: 5\tFidelity = 0.500505\tKL_Divergence = 3.983767\n",
      "Epoch: 6\tFidelity = 0.500455\tKL_Divergence = 4.041356\n",
      "Epoch: 7\tFidelity = 0.500446\tKL_Divergence = 4.053048\n",
      "Epoch: 8\tFidelity = 0.500469\tKL_Divergence = 4.024092\n",
      "Epoch: 9\tFidelity = 0.500506\tKL_Divergence = 3.982457\n",
      "Epoch: 10\tFidelity = 0.500574\tKL_Divergence = 3.912930\n",
      "Epoch: 11\tFidelity = 0.500576\tKL_Divergence = 3.910674\n",
      "Epoch: 12\tFidelity = 0.500642\tKL_Divergence = 3.850322\n",
      "Epoch: 13\tFidelity = 0.500578\tKL_Divergence = 3.908611\n",
      "Epoch: 14\tFidelity = 0.500507\tKL_Divergence = 3.981054\n",
      "Epoch: 15\tFidelity = 0.500512\tKL_Divergence = 3.976589\n",
      "Epoch: 16\tFidelity = 0.500555\tKL_Divergence = 3.931479\n",
      "Epoch: 17\tFidelity = 0.500470\tKL_Divergence = 4.023254\n",
      "Epoch: 18\tFidelity = 0.500517\tKL_Divergence = 3.970352\n",
      "Epoch: 19\tFidelity = 0.500519\tKL_Divergence = 3.968266\n",
      "Epoch: 20\tFidelity = 0.500530\tKL_Divergence = 3.957257\n",
      "Epoch: 21\tFidelity = 0.500576\tKL_Divergence = 3.910942\n",
      "Epoch: 22\tFidelity = 0.500569\tKL_Divergence = 3.917771\n",
      "Epoch: 23\tFidelity = 0.500506\tKL_Divergence = 3.982206\n",
      "Epoch: 24\tFidelity = 0.500515\tKL_Divergence = 3.973116\n",
      "Epoch: 25\tFidelity = 0.500502\tKL_Divergence = 3.986785\n",
      "Epoch: 26\tFidelity = 0.500504\tKL_Divergence = 3.984725\n",
      "Epoch: 27\tFidelity = 0.500557\tKL_Divergence = 3.929080\n",
      "Epoch: 28\tFidelity = 0.500555\tKL_Divergence = 3.930859\n",
      "Epoch: 29\tFidelity = 0.500482\tKL_Divergence = 4.008158\n",
      "Epoch: 30\tFidelity = 0.500514\tKL_Divergence = 3.972955\n",
      "Epoch: 31\tFidelity = 0.500495\tKL_Divergence = 3.994330\n",
      "Epoch: 32\tFidelity = 0.500556\tKL_Divergence = 3.929430\n",
      "Epoch: 33\tFidelity = 0.500526\tKL_Divergence = 3.960594\n",
      "Epoch: 34\tFidelity = 0.500466\tKL_Divergence = 4.028206\n",
      "Epoch: 35\tFidelity = 0.500461\tKL_Divergence = 4.034448\n",
      "Epoch: 36\tFidelity = 0.500468\tKL_Divergence = 4.026235\n",
      "Epoch: 37\tFidelity = 0.500526\tKL_Divergence = 3.960887\n",
      "Epoch: 38\tFidelity = 0.500481\tKL_Divergence = 4.010408\n",
      "Epoch: 39\tFidelity = 0.500511\tKL_Divergence = 3.976407\n",
      "Epoch: 40\tFidelity = 0.500525\tKL_Divergence = 3.961235\n",
      "Epoch: 41\tFidelity = 0.500488\tKL_Divergence = 4.001159\n",
      "Epoch: 42\tFidelity = 0.500515\tKL_Divergence = 3.972303\n",
      "Epoch: 43\tFidelity = 0.500483\tKL_Divergence = 4.007378\n",
      "Epoch: 44\tFidelity = 0.500479\tKL_Divergence = 4.011246\n",
      "Epoch: 45\tFidelity = 0.500551\tKL_Divergence = 3.933624\n",
      "Epoch: 46\tFidelity = 0.500508\tKL_Divergence = 3.978495\n",
      "Epoch: 47\tFidelity = 0.500580\tKL_Divergence = 3.904562\n",
      "Epoch: 48\tFidelity = 0.500513\tKL_Divergence = 3.974225\n",
      "Epoch: 49\tFidelity = 0.500541\tKL_Divergence = 3.945003\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:36:57,665] Trial 385 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500549\tKL_Divergence = 3.937186\n",
      "Total time elapsed during training: 39.163 s\n",
      "Trial 385 pruned. \n",
      "Epoch: 1\tFidelity = 0.500611\tKL_Divergence = 3.877621\n",
      "Epoch: 2\tFidelity = 0.500477\tKL_Divergence = 4.015364\n",
      "Epoch: 3\tFidelity = 0.500474\tKL_Divergence = 4.018721\n",
      "Epoch: 4\tFidelity = 0.500569\tKL_Divergence = 3.917625\n",
      "Epoch: 5\tFidelity = 0.500467\tKL_Divergence = 4.026514\n",
      "Epoch: 6\tFidelity = 0.500475\tKL_Divergence = 4.018145\n",
      "Epoch: 7\tFidelity = 0.500474\tKL_Divergence = 4.018521\n",
      "Epoch: 8\tFidelity = 0.500548\tKL_Divergence = 3.938053\n",
      "Epoch: 9\tFidelity = 0.500508\tKL_Divergence = 3.980048\n",
      "Epoch: 10\tFidelity = 0.500514\tKL_Divergence = 3.973972\n",
      "Epoch: 11\tFidelity = 0.500607\tKL_Divergence = 3.881607\n",
      "Epoch: 12\tFidelity = 0.500527\tKL_Divergence = 3.959474\n",
      "Epoch: 13\tFidelity = 0.500502\tKL_Divergence = 3.986522\n",
      "Epoch: 14\tFidelity = 0.500542\tKL_Divergence = 3.943729\n",
      "Epoch: 15\tFidelity = 0.500571\tKL_Divergence = 3.915499\n",
      "Epoch: 16\tFidelity = 0.500634\tKL_Divergence = 3.857133\n",
      "Epoch: 17\tFidelity = 0.500499\tKL_Divergence = 3.989952\n",
      "Epoch: 18\tFidelity = 0.500601\tKL_Divergence = 3.886452\n",
      "Epoch: 19\tFidelity = 0.500643\tKL_Divergence = 3.849518\n",
      "Epoch: 20\tFidelity = 0.500574\tKL_Divergence = 3.911884\n",
      "Epoch: 21\tFidelity = 0.500619\tKL_Divergence = 3.870186\n",
      "Epoch: 22\tFidelity = 0.500526\tKL_Divergence = 3.960793\n",
      "Epoch: 23\tFidelity = 0.500626\tKL_Divergence = 3.864008\n",
      "Epoch: 24\tFidelity = 0.500503\tKL_Divergence = 3.985229\n",
      "Epoch: 25\tFidelity = 0.500480\tKL_Divergence = 4.011632\n",
      "Epoch: 26\tFidelity = 0.500428\tKL_Divergence = 4.075702\n",
      "Epoch: 27\tFidelity = 0.500518\tKL_Divergence = 3.969069\n",
      "Epoch: 28\tFidelity = 0.500554\tKL_Divergence = 3.931942\n",
      "Epoch: 29\tFidelity = 0.500502\tKL_Divergence = 3.986698\n",
      "Epoch: 30\tFidelity = 0.500554\tKL_Divergence = 3.932208\n",
      "Epoch: 31\tFidelity = 0.500582\tKL_Divergence = 3.904410\n",
      "Epoch: 32\tFidelity = 0.500522\tKL_Divergence = 3.965346\n",
      "Epoch: 33\tFidelity = 0.500425\tKL_Divergence = 4.079124\n",
      "Epoch: 34\tFidelity = 0.500532\tKL_Divergence = 3.955123\n",
      "Epoch: 35\tFidelity = 0.500511\tKL_Divergence = 3.976592\n",
      "Epoch: 36\tFidelity = 0.500584\tKL_Divergence = 3.902786\n",
      "Epoch: 37\tFidelity = 0.500630\tKL_Divergence = 3.861308\n",
      "Epoch: 38\tFidelity = 0.500646\tKL_Divergence = 3.847216\n",
      "Epoch: 39\tFidelity = 0.500607\tKL_Divergence = 3.881560\n",
      "Epoch: 40\tFidelity = 0.500570\tKL_Divergence = 3.916306\n",
      "Epoch: 41\tFidelity = 0.500598\tKL_Divergence = 3.890339\n",
      "Epoch: 42\tFidelity = 0.500558\tKL_Divergence = 3.927994\n",
      "Epoch: 43\tFidelity = 0.500507\tKL_Divergence = 3.980893\n",
      "Epoch: 44\tFidelity = 0.500527\tKL_Divergence = 3.960122\n",
      "Epoch: 45\tFidelity = 0.500517\tKL_Divergence = 3.970357\n",
      "Epoch: 46\tFidelity = 0.500626\tKL_Divergence = 3.864319\n",
      "Epoch: 47\tFidelity = 0.500470\tKL_Divergence = 4.023515\n",
      "Epoch: 48\tFidelity = 0.500460\tKL_Divergence = 4.035445\n",
      "Epoch: 49\tFidelity = 0.500512\tKL_Divergence = 3.976501\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:37:57,977] Trial 386 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500483\tKL_Divergence = 4.007996\n",
      "Total time elapsed during training: 60.119 s\n",
      "Trial 386 pruned. \n",
      "Epoch: 1\tFidelity = 0.500515\tKL_Divergence = 3.972468\n",
      "Epoch: 2\tFidelity = 0.500508\tKL_Divergence = 3.980608\n",
      "Epoch: 3\tFidelity = 0.500529\tKL_Divergence = 3.957633\n",
      "Epoch: 4\tFidelity = 0.500548\tKL_Divergence = 3.938041\n",
      "Epoch: 5\tFidelity = 0.500566\tKL_Divergence = 3.920600\n",
      "Epoch: 6\tFidelity = 0.500524\tKL_Divergence = 3.963275\n",
      "Epoch: 7\tFidelity = 0.500521\tKL_Divergence = 3.965874\n",
      "Epoch: 8\tFidelity = 0.500531\tKL_Divergence = 3.955758\n",
      "Epoch: 9\tFidelity = 0.500555\tKL_Divergence = 3.931467\n",
      "Epoch: 10\tFidelity = 0.500549\tKL_Divergence = 3.937298\n",
      "Epoch: 11\tFidelity = 0.500579\tKL_Divergence = 3.908065\n",
      "Epoch: 12\tFidelity = 0.500506\tKL_Divergence = 3.982840\n",
      "Epoch: 13\tFidelity = 0.500509\tKL_Divergence = 3.979137\n",
      "Epoch: 14\tFidelity = 0.500557\tKL_Divergence = 3.929106\n",
      "Epoch: 15\tFidelity = 0.500530\tKL_Divergence = 3.957369\n",
      "Epoch: 16\tFidelity = 0.500501\tKL_Divergence = 3.988404\n",
      "Epoch: 17\tFidelity = 0.500490\tKL_Divergence = 4.000811\n",
      "Epoch: 18\tFidelity = 0.500582\tKL_Divergence = 3.904828\n",
      "Epoch: 19\tFidelity = 0.500560\tKL_Divergence = 3.926449\n",
      "Epoch: 20\tFidelity = 0.500560\tKL_Divergence = 3.926691\n",
      "Epoch: 21\tFidelity = 0.500552\tKL_Divergence = 3.934011\n",
      "Epoch: 22\tFidelity = 0.500497\tKL_Divergence = 3.993071\n",
      "Epoch: 23\tFidelity = 0.500563\tKL_Divergence = 3.923829\n",
      "Epoch: 24\tFidelity = 0.500521\tKL_Divergence = 3.966493\n",
      "Epoch: 25\tFidelity = 0.500520\tKL_Divergence = 3.967503\n",
      "Epoch: 26\tFidelity = 0.500518\tKL_Divergence = 3.969660\n",
      "Epoch: 27\tFidelity = 0.500524\tKL_Divergence = 3.963329\n",
      "Epoch: 28\tFidelity = 0.500524\tKL_Divergence = 3.963079\n",
      "Epoch: 29\tFidelity = 0.500528\tKL_Divergence = 3.959063\n",
      "Epoch: 30\tFidelity = 0.500514\tKL_Divergence = 3.974265\n",
      "Epoch: 31\tFidelity = 0.500511\tKL_Divergence = 3.977058\n",
      "Epoch: 32\tFidelity = 0.500508\tKL_Divergence = 3.980045\n",
      "Epoch: 33\tFidelity = 0.500509\tKL_Divergence = 3.979772\n",
      "Epoch: 34\tFidelity = 0.500540\tKL_Divergence = 3.946541\n",
      "Epoch: 35\tFidelity = 0.500524\tKL_Divergence = 3.963118\n",
      "Epoch: 36\tFidelity = 0.500511\tKL_Divergence = 3.977718\n",
      "Epoch: 37\tFidelity = 0.500503\tKL_Divergence = 3.985609\n",
      "Epoch: 38\tFidelity = 0.500567\tKL_Divergence = 3.919933\n",
      "Epoch: 39\tFidelity = 0.500536\tKL_Divergence = 3.950716\n",
      "Epoch: 40\tFidelity = 0.500534\tKL_Divergence = 3.952866\n",
      "Epoch: 41\tFidelity = 0.500501\tKL_Divergence = 3.987885\n",
      "Epoch: 42\tFidelity = 0.500525\tKL_Divergence = 3.961741\n",
      "Epoch: 43\tFidelity = 0.500521\tKL_Divergence = 3.966120\n",
      "Epoch: 44\tFidelity = 0.500470\tKL_Divergence = 4.023825\n",
      "Epoch: 45\tFidelity = 0.500497\tKL_Divergence = 3.992806\n",
      "Epoch: 46\tFidelity = 0.500513\tKL_Divergence = 3.975054\n",
      "Epoch: 47\tFidelity = 0.500471\tKL_Divergence = 4.021892\n",
      "Epoch: 48\tFidelity = 0.500551\tKL_Divergence = 3.935852\n",
      "Epoch: 49\tFidelity = 0.500522\tKL_Divergence = 3.965432\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:38:44,005] Trial 387 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500543\tKL_Divergence = 3.943965\n",
      "Total time elapsed during training: 45.846 s\n",
      "Trial 387 pruned. \n",
      "Epoch: 1\tFidelity = 0.500453\tKL_Divergence = 4.044152\n",
      "Epoch: 2\tFidelity = 0.500480\tKL_Divergence = 4.012053\n",
      "Epoch: 3\tFidelity = 0.500431\tKL_Divergence = 4.071552\n",
      "Epoch: 4\tFidelity = 0.500449\tKL_Divergence = 4.048548\n",
      "Epoch: 5\tFidelity = 0.500540\tKL_Divergence = 3.945979\n",
      "Epoch: 6\tFidelity = 0.500582\tKL_Divergence = 3.904391\n",
      "Epoch: 7\tFidelity = 0.500591\tKL_Divergence = 3.896210\n",
      "Epoch: 8\tFidelity = 0.500558\tKL_Divergence = 3.928632\n",
      "Epoch: 9\tFidelity = 0.500430\tKL_Divergence = 4.072728\n",
      "Epoch: 10\tFidelity = 0.500490\tKL_Divergence = 3.999778\n",
      "Epoch: 11\tFidelity = 0.500555\tKL_Divergence = 3.930805\n",
      "Epoch: 12\tFidelity = 0.500537\tKL_Divergence = 3.949238\n",
      "Epoch: 13\tFidelity = 0.500483\tKL_Divergence = 4.008828\n",
      "Epoch: 14\tFidelity = 0.500442\tKL_Divergence = 4.057314\n",
      "Epoch: 15\tFidelity = 0.500573\tKL_Divergence = 3.913787\n",
      "Epoch: 16\tFidelity = 0.500560\tKL_Divergence = 3.926449\n",
      "Epoch: 17\tFidelity = 0.500483\tKL_Divergence = 4.008771\n",
      "Epoch: 18\tFidelity = 0.500403\tKL_Divergence = 4.108309\n",
      "Epoch: 19\tFidelity = 0.500568\tKL_Divergence = 3.918603\n",
      "Epoch: 20\tFidelity = 0.500513\tKL_Divergence = 3.975317\n",
      "Epoch: 21\tFidelity = 0.500615\tKL_Divergence = 3.874366\n",
      "Epoch: 22\tFidelity = 0.500638\tKL_Divergence = 3.853714\n",
      "Epoch: 23\tFidelity = 0.500576\tKL_Divergence = 3.910278\n",
      "Epoch: 24\tFidelity = 0.500601\tKL_Divergence = 3.887454\n",
      "Epoch: 25\tFidelity = 0.500581\tKL_Divergence = 3.905992\n",
      "Epoch: 26\tFidelity = 0.500406\tKL_Divergence = 4.104373\n",
      "Epoch: 27\tFidelity = 0.500553\tKL_Divergence = 3.932817\n",
      "Epoch: 28\tFidelity = 0.500579\tKL_Divergence = 3.907456\n",
      "Epoch: 29\tFidelity = 0.500528\tKL_Divergence = 3.959168\n",
      "Epoch: 30\tFidelity = 0.500432\tKL_Divergence = 4.070872\n",
      "Epoch: 31\tFidelity = 0.500639\tKL_Divergence = 3.852719\n",
      "Epoch: 32\tFidelity = 0.500515\tKL_Divergence = 3.972878\n",
      "Epoch: 33\tFidelity = 0.500604\tKL_Divergence = 3.884669\n",
      "Epoch: 34\tFidelity = 0.500566\tKL_Divergence = 3.920691\n",
      "Epoch: 35\tFidelity = 0.500557\tKL_Divergence = 3.929620\n",
      "Epoch: 36\tFidelity = 0.500577\tKL_Divergence = 3.909829\n",
      "Epoch: 37\tFidelity = 0.500614\tKL_Divergence = 3.874919\n",
      "Epoch: 38\tFidelity = 0.500459\tKL_Divergence = 4.036990\n",
      "Epoch: 39\tFidelity = 0.500586\tKL_Divergence = 3.901197\n",
      "Epoch: 40\tFidelity = 0.500549\tKL_Divergence = 3.936949\n",
      "Epoch: 41\tFidelity = 0.500557\tKL_Divergence = 3.929218\n",
      "Epoch: 42\tFidelity = 0.500470\tKL_Divergence = 4.023804\n",
      "Epoch: 43\tFidelity = 0.500631\tKL_Divergence = 3.859917\n",
      "Epoch: 44\tFidelity = 0.500603\tKL_Divergence = 3.885364\n",
      "Epoch: 45\tFidelity = 0.500556\tKL_Divergence = 3.930445\n",
      "Epoch: 46\tFidelity = 0.500577\tKL_Divergence = 3.910077\n",
      "Epoch: 47\tFidelity = 0.500508\tKL_Divergence = 3.980060\n",
      "Epoch: 48\tFidelity = 0.500513\tKL_Divergence = 3.974891\n",
      "Epoch: 49\tFidelity = 0.500462\tKL_Divergence = 4.032664\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:39:23,570] Trial 388 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500478\tKL_Divergence = 4.013758\n",
      "Total time elapsed during training: 39.388 s\n",
      "Trial 388 pruned. \n",
      "Epoch: 1\tFidelity = 0.500518\tKL_Divergence = 3.970159\n",
      "Epoch: 2\tFidelity = 0.500544\tKL_Divergence = 3.942663\n",
      "Epoch: 3\tFidelity = 0.500503\tKL_Divergence = 3.986071\n",
      "Epoch: 4\tFidelity = 0.500565\tKL_Divergence = 3.921349\n",
      "Epoch: 5\tFidelity = 0.500566\tKL_Divergence = 3.920004\n",
      "Epoch: 6\tFidelity = 0.500451\tKL_Divergence = 4.047114\n",
      "Epoch: 7\tFidelity = 0.500566\tKL_Divergence = 3.920544\n",
      "Epoch: 8\tFidelity = 0.500486\tKL_Divergence = 4.005062\n",
      "Epoch: 9\tFidelity = 0.500475\tKL_Divergence = 4.017375\n",
      "Epoch: 10\tFidelity = 0.500538\tKL_Divergence = 3.948572\n",
      "Epoch: 11\tFidelity = 0.500524\tKL_Divergence = 3.963150\n",
      "Epoch: 12\tFidelity = 0.500467\tKL_Divergence = 4.027391\n",
      "Epoch: 13\tFidelity = 0.500528\tKL_Divergence = 3.959193\n",
      "Epoch: 14\tFidelity = 0.500522\tKL_Divergence = 3.965184\n",
      "Epoch: 15\tFidelity = 0.500471\tKL_Divergence = 4.022452\n",
      "Epoch: 16\tFidelity = 0.500531\tKL_Divergence = 3.955936\n",
      "Epoch: 17\tFidelity = 0.500498\tKL_Divergence = 3.990922\n",
      "Epoch: 18\tFidelity = 0.500605\tKL_Divergence = 3.883093\n",
      "Epoch: 19\tFidelity = 0.500549\tKL_Divergence = 3.937603\n",
      "Epoch: 20\tFidelity = 0.500511\tKL_Divergence = 3.976923\n",
      "Epoch: 21\tFidelity = 0.500576\tKL_Divergence = 3.911186\n",
      "Epoch: 22\tFidelity = 0.500473\tKL_Divergence = 4.020607\n",
      "Epoch: 23\tFidelity = 0.500481\tKL_Divergence = 4.010571\n",
      "Epoch: 24\tFidelity = 0.500573\tKL_Divergence = 3.913534\n",
      "Epoch: 25\tFidelity = 0.500535\tKL_Divergence = 3.951233\n",
      "Epoch: 26\tFidelity = 0.500465\tKL_Divergence = 4.029030\n",
      "Epoch: 27\tFidelity = 0.500548\tKL_Divergence = 3.938045\n",
      "Epoch: 28\tFidelity = 0.500492\tKL_Divergence = 3.998175\n",
      "Epoch: 29\tFidelity = 0.500566\tKL_Divergence = 3.920949\n",
      "Epoch: 30\tFidelity = 0.500512\tKL_Divergence = 3.975631\n",
      "Epoch: 31\tFidelity = 0.500510\tKL_Divergence = 3.978424\n",
      "Epoch: 32\tFidelity = 0.500543\tKL_Divergence = 3.943450\n",
      "Epoch: 33\tFidelity = 0.500483\tKL_Divergence = 4.008696\n",
      "Epoch: 34\tFidelity = 0.500526\tKL_Divergence = 3.961671\n",
      "Epoch: 35\tFidelity = 0.500563\tKL_Divergence = 3.923446\n",
      "Epoch: 36\tFidelity = 0.500478\tKL_Divergence = 4.013937\n",
      "Epoch: 37\tFidelity = 0.500538\tKL_Divergence = 3.948743\n",
      "Epoch: 38\tFidelity = 0.500572\tKL_Divergence = 3.915121\n",
      "Epoch: 39\tFidelity = 0.500532\tKL_Divergence = 3.955234\n",
      "Epoch: 40\tFidelity = 0.500499\tKL_Divergence = 3.989869\n",
      "Epoch: 41\tFidelity = 0.500507\tKL_Divergence = 3.981411\n",
      "Epoch: 42\tFidelity = 0.500497\tKL_Divergence = 3.993191\n",
      "Epoch: 43\tFidelity = 0.500535\tKL_Divergence = 3.951585\n",
      "Epoch: 44\tFidelity = 0.500546\tKL_Divergence = 3.940003\n",
      "Epoch: 45\tFidelity = 0.500547\tKL_Divergence = 3.939481\n",
      "Epoch: 46\tFidelity = 0.500544\tKL_Divergence = 3.942745\n",
      "Epoch: 47\tFidelity = 0.500520\tKL_Divergence = 3.967147\n",
      "Epoch: 48\tFidelity = 0.500542\tKL_Divergence = 3.944365\n",
      "Epoch: 49\tFidelity = 0.500510\tKL_Divergence = 3.977863\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:40:48,121] Trial 389 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500473\tKL_Divergence = 4.020554\n",
      "Total time elapsed during training: 84.360 s\n",
      "Trial 389 pruned. \n",
      "Epoch: 1\tFidelity = 0.500533\tKL_Divergence = 3.953877\n",
      "Epoch: 2\tFidelity = 0.500557\tKL_Divergence = 3.929046\n",
      "Epoch: 3\tFidelity = 0.500537\tKL_Divergence = 3.949830\n",
      "Epoch: 4\tFidelity = 0.500561\tKL_Divergence = 3.925325\n",
      "Epoch: 5\tFidelity = 0.500459\tKL_Divergence = 4.036955\n",
      "Epoch: 6\tFidelity = 0.500508\tKL_Divergence = 3.979982\n",
      "Epoch: 7\tFidelity = 0.500560\tKL_Divergence = 3.926066\n",
      "Epoch: 8\tFidelity = 0.500483\tKL_Divergence = 4.008576\n",
      "Epoch: 9\tFidelity = 0.500449\tKL_Divergence = 4.048937\n",
      "Epoch: 10\tFidelity = 0.500483\tKL_Divergence = 4.007987\n",
      "Epoch: 11\tFidelity = 0.500585\tKL_Divergence = 3.901772\n",
      "Epoch: 12\tFidelity = 0.500531\tKL_Divergence = 3.955780\n",
      "Epoch: 13\tFidelity = 0.500473\tKL_Divergence = 4.019882\n",
      "Epoch: 14\tFidelity = 0.500481\tKL_Divergence = 4.010212\n",
      "Epoch: 15\tFidelity = 0.500558\tKL_Divergence = 3.928400\n",
      "Epoch: 16\tFidelity = 0.500512\tKL_Divergence = 3.976446\n",
      "Epoch: 17\tFidelity = 0.500471\tKL_Divergence = 4.022428\n",
      "Epoch: 18\tFidelity = 0.500528\tKL_Divergence = 3.959266\n",
      "Epoch: 19\tFidelity = 0.500545\tKL_Divergence = 3.940897\n",
      "Epoch: 20\tFidelity = 0.500568\tKL_Divergence = 3.918813\n",
      "Epoch: 21\tFidelity = 0.500505\tKL_Divergence = 3.983594\n",
      "Epoch: 22\tFidelity = 0.500516\tKL_Divergence = 3.972056\n",
      "Epoch: 23\tFidelity = 0.500507\tKL_Divergence = 3.981602\n",
      "Epoch: 24\tFidelity = 0.500486\tKL_Divergence = 4.004885\n",
      "Epoch: 25\tFidelity = 0.500497\tKL_Divergence = 3.992507\n",
      "Epoch: 26\tFidelity = 0.500530\tKL_Divergence = 3.956971\n",
      "Epoch: 27\tFidelity = 0.500571\tKL_Divergence = 3.915542\n",
      "Epoch: 28\tFidelity = 0.500487\tKL_Divergence = 4.004256\n",
      "Epoch: 29\tFidelity = 0.500476\tKL_Divergence = 4.016106\n",
      "Epoch: 30\tFidelity = 0.500503\tKL_Divergence = 3.985665\n",
      "Epoch: 31\tFidelity = 0.500496\tKL_Divergence = 3.993666\n",
      "Epoch: 32\tFidelity = 0.500576\tKL_Divergence = 3.910567\n",
      "Epoch: 33\tFidelity = 0.500567\tKL_Divergence = 3.918999\n",
      "Epoch: 34\tFidelity = 0.500470\tKL_Divergence = 4.023714\n",
      "Epoch: 35\tFidelity = 0.500574\tKL_Divergence = 3.912407\n",
      "Epoch: 36\tFidelity = 0.500580\tKL_Divergence = 3.906808\n",
      "Epoch: 37\tFidelity = 0.500582\tKL_Divergence = 3.904770\n",
      "Epoch: 38\tFidelity = 0.500449\tKL_Divergence = 4.048487\n",
      "Epoch: 39\tFidelity = 0.500507\tKL_Divergence = 3.981641\n",
      "Epoch: 40\tFidelity = 0.500465\tKL_Divergence = 4.029281\n",
      "Epoch: 41\tFidelity = 0.500509\tKL_Divergence = 3.979449\n",
      "Epoch: 42\tFidelity = 0.500454\tKL_Divergence = 4.042762\n",
      "Epoch: 43\tFidelity = 0.500487\tKL_Divergence = 4.003421\n",
      "Epoch: 44\tFidelity = 0.500517\tKL_Divergence = 3.970918\n",
      "Epoch: 45\tFidelity = 0.500511\tKL_Divergence = 3.977254\n",
      "Epoch: 46\tFidelity = 0.500538\tKL_Divergence = 3.949032\n",
      "Epoch: 47\tFidelity = 0.500560\tKL_Divergence = 3.926335\n",
      "Epoch: 48\tFidelity = 0.500514\tKL_Divergence = 3.973553\n",
      "Epoch: 49\tFidelity = 0.500506\tKL_Divergence = 3.982309\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:41:28,276] Trial 390 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500510\tKL_Divergence = 3.978366\n",
      "Total time elapsed during training: 39.982 s\n",
      "Trial 390 pruned. \n",
      "Epoch: 1\tFidelity = 0.500503\tKL_Divergence = 3.985258\n",
      "Epoch: 2\tFidelity = 0.500458\tKL_Divergence = 4.038248\n",
      "Epoch: 3\tFidelity = 0.500510\tKL_Divergence = 3.978501\n",
      "Epoch: 4\tFidelity = 0.500472\tKL_Divergence = 4.021121\n",
      "Epoch: 5\tFidelity = 0.500525\tKL_Divergence = 3.962076\n",
      "Epoch: 6\tFidelity = 0.500482\tKL_Divergence = 4.010002\n",
      "Epoch: 7\tFidelity = 0.500427\tKL_Divergence = 4.076583\n",
      "Epoch: 8\tFidelity = 0.500525\tKL_Divergence = 3.961411\n",
      "Epoch: 9\tFidelity = 0.500552\tKL_Divergence = 3.934083\n",
      "Epoch: 10\tFidelity = 0.500543\tKL_Divergence = 3.942868\n",
      "Epoch: 11\tFidelity = 0.500494\tKL_Divergence = 3.995511\n",
      "Epoch: 12\tFidelity = 0.500554\tKL_Divergence = 3.932057\n",
      "Epoch: 13\tFidelity = 0.500639\tKL_Divergence = 3.852866\n",
      "Epoch: 14\tFidelity = 0.500490\tKL_Divergence = 4.000344\n",
      "Epoch: 15\tFidelity = 0.500549\tKL_Divergence = 3.937761\n",
      "Epoch: 16\tFidelity = 0.500453\tKL_Divergence = 4.044103\n",
      "Epoch: 17\tFidelity = 0.500506\tKL_Divergence = 3.982459\n",
      "Epoch: 18\tFidelity = 0.500497\tKL_Divergence = 3.992537\n",
      "Epoch: 19\tFidelity = 0.500493\tKL_Divergence = 3.996828\n",
      "Epoch: 20\tFidelity = 0.500537\tKL_Divergence = 3.949210\n",
      "Epoch: 21\tFidelity = 0.500601\tKL_Divergence = 3.886585\n",
      "Epoch: 22\tFidelity = 0.500520\tKL_Divergence = 3.967361\n",
      "Epoch: 23\tFidelity = 0.500427\tKL_Divergence = 4.077294\n",
      "Epoch: 24\tFidelity = 0.500525\tKL_Divergence = 3.962026\n",
      "Epoch: 25\tFidelity = 0.500482\tKL_Divergence = 4.009016\n",
      "Epoch: 26\tFidelity = 0.500476\tKL_Divergence = 4.016650\n",
      "Epoch: 27\tFidelity = 0.500512\tKL_Divergence = 3.975475\n",
      "Epoch: 28\tFidelity = 0.500517\tKL_Divergence = 3.969354\n",
      "Epoch: 29\tFidelity = 0.500570\tKL_Divergence = 3.914960\n",
      "Epoch: 30\tFidelity = 0.500522\tKL_Divergence = 3.964228\n",
      "Epoch: 31\tFidelity = 0.500608\tKL_Divergence = 3.879731\n",
      "Epoch: 32\tFidelity = 0.500563\tKL_Divergence = 3.922727\n",
      "Epoch: 33\tFidelity = 0.500639\tKL_Divergence = 3.852083\n",
      "Epoch: 34\tFidelity = 0.500511\tKL_Divergence = 3.976173\n",
      "Epoch: 35\tFidelity = 0.500617\tKL_Divergence = 3.871895\n",
      "Epoch: 36\tFidelity = 0.500530\tKL_Divergence = 3.955854\n",
      "Epoch: 37\tFidelity = 0.500504\tKL_Divergence = 3.984717\n",
      "Epoch: 38\tFidelity = 0.500599\tKL_Divergence = 3.889167\n",
      "Epoch: 39\tFidelity = 0.500568\tKL_Divergence = 3.918333\n",
      "Epoch: 40\tFidelity = 0.500465\tKL_Divergence = 4.029294\n",
      "Epoch: 41\tFidelity = 0.500572\tKL_Divergence = 3.914557\n",
      "Epoch: 42\tFidelity = 0.500547\tKL_Divergence = 3.939475\n",
      "Epoch: 43\tFidelity = 0.500616\tKL_Divergence = 3.873318\n",
      "Epoch: 44\tFidelity = 0.500564\tKL_Divergence = 3.922041\n",
      "Epoch: 45\tFidelity = 0.500483\tKL_Divergence = 4.007816\n",
      "Epoch: 46\tFidelity = 0.500518\tKL_Divergence = 3.969257\n",
      "Epoch: 47\tFidelity = 0.500568\tKL_Divergence = 3.918674\n",
      "Epoch: 48\tFidelity = 0.500582\tKL_Divergence = 3.904887\n",
      "Epoch: 49\tFidelity = 0.500625\tKL_Divergence = 3.865195\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:42:06,994] Trial 391 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500566\tKL_Divergence = 3.919905\n",
      "Total time elapsed during training: 38.547 s\n",
      "Trial 391 pruned. \n",
      "Epoch: 1\tFidelity = 0.500521\tKL_Divergence = 3.966454\n",
      "Epoch: 2\tFidelity = 0.500553\tKL_Divergence = 3.933431\n",
      "Epoch: 3\tFidelity = 0.500503\tKL_Divergence = 3.985877\n",
      "Epoch: 4\tFidelity = 0.500534\tKL_Divergence = 3.952615\n",
      "Epoch: 5\tFidelity = 0.500565\tKL_Divergence = 3.920970\n",
      "Epoch: 6\tFidelity = 0.500531\tKL_Divergence = 3.955920\n",
      "Epoch: 7\tFidelity = 0.500584\tKL_Divergence = 3.902676\n",
      "Epoch: 8\tFidelity = 0.500544\tKL_Divergence = 3.942580\n",
      "Epoch: 9\tFidelity = 0.500540\tKL_Divergence = 3.946395\n",
      "Epoch: 10\tFidelity = 0.500549\tKL_Divergence = 3.937386\n",
      "Epoch: 11\tFidelity = 0.500529\tKL_Divergence = 3.957869\n",
      "Epoch: 12\tFidelity = 0.500520\tKL_Divergence = 3.967367\n",
      "Epoch: 13\tFidelity = 0.500543\tKL_Divergence = 3.943161\n",
      "Epoch: 14\tFidelity = 0.500565\tKL_Divergence = 3.920744\n",
      "Epoch: 15\tFidelity = 0.500525\tKL_Divergence = 3.961854\n",
      "Epoch: 16\tFidelity = 0.500498\tKL_Divergence = 3.990777\n",
      "Epoch: 17\tFidelity = 0.500478\tKL_Divergence = 4.013396\n",
      "Epoch: 18\tFidelity = 0.500518\tKL_Divergence = 3.969858\n",
      "Epoch: 19\tFidelity = 0.500526\tKL_Divergence = 3.961363\n",
      "Epoch: 20\tFidelity = 0.500558\tKL_Divergence = 3.927637\n",
      "Epoch: 21\tFidelity = 0.500544\tKL_Divergence = 3.942381\n",
      "Epoch: 22\tFidelity = 0.500511\tKL_Divergence = 3.977180\n",
      "Epoch: 23\tFidelity = 0.500524\tKL_Divergence = 3.963451\n",
      "Epoch: 24\tFidelity = 0.500553\tKL_Divergence = 3.933163\n",
      "Epoch: 25\tFidelity = 0.500529\tKL_Divergence = 3.958215\n",
      "Epoch: 26\tFidelity = 0.500573\tKL_Divergence = 3.913800\n",
      "Epoch: 27\tFidelity = 0.500548\tKL_Divergence = 3.938286\n",
      "Epoch: 28\tFidelity = 0.500509\tKL_Divergence = 3.979052\n",
      "Epoch: 29\tFidelity = 0.500555\tKL_Divergence = 3.930764\n",
      "Epoch: 30\tFidelity = 0.500561\tKL_Divergence = 3.925426\n",
      "Epoch: 31\tFidelity = 0.500555\tKL_Divergence = 3.931388\n",
      "Epoch: 32\tFidelity = 0.500543\tKL_Divergence = 3.943184\n",
      "Epoch: 33\tFidelity = 0.500562\tKL_Divergence = 3.924465\n",
      "Epoch: 34\tFidelity = 0.500513\tKL_Divergence = 3.974892\n",
      "Epoch: 35\tFidelity = 0.500543\tKL_Divergence = 3.943789\n",
      "Epoch: 36\tFidelity = 0.500510\tKL_Divergence = 3.978486\n",
      "Epoch: 37\tFidelity = 0.500470\tKL_Divergence = 4.023769\n",
      "Epoch: 38\tFidelity = 0.500489\tKL_Divergence = 4.000945\n",
      "Epoch: 39\tFidelity = 0.500533\tKL_Divergence = 3.953895\n",
      "Epoch: 40\tFidelity = 0.500555\tKL_Divergence = 3.931199\n",
      "Epoch: 41\tFidelity = 0.500507\tKL_Divergence = 3.981621\n",
      "Epoch: 42\tFidelity = 0.500536\tKL_Divergence = 3.950424\n",
      "Epoch: 43\tFidelity = 0.500543\tKL_Divergence = 3.943207\n",
      "Epoch: 44\tFidelity = 0.500506\tKL_Divergence = 3.982594\n",
      "Epoch: 45\tFidelity = 0.500542\tKL_Divergence = 3.944245\n",
      "Epoch: 46\tFidelity = 0.500514\tKL_Divergence = 3.973735\n",
      "Epoch: 47\tFidelity = 0.500504\tKL_Divergence = 3.984531\n",
      "Epoch: 48\tFidelity = 0.500556\tKL_Divergence = 3.930706\n",
      "Epoch: 49\tFidelity = 0.500522\tKL_Divergence = 3.965673\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:42:53,460] Trial 392 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500536\tKL_Divergence = 3.951083\n",
      "Total time elapsed during training: 46.282 s\n",
      "Trial 392 pruned. \n",
      "Epoch: 1\tFidelity = 0.500632\tKL_Divergence = 3.859226\n",
      "Epoch: 2\tFidelity = 0.500462\tKL_Divergence = 4.032704\n",
      "Epoch: 3\tFidelity = 0.500471\tKL_Divergence = 4.022761\n",
      "Epoch: 4\tFidelity = 0.500619\tKL_Divergence = 3.870353\n",
      "Epoch: 5\tFidelity = 0.500607\tKL_Divergence = 3.881857\n",
      "Epoch: 6\tFidelity = 0.500565\tKL_Divergence = 3.921349\n",
      "Epoch: 7\tFidelity = 0.500555\tKL_Divergence = 3.931528\n",
      "Epoch: 8\tFidelity = 0.500623\tKL_Divergence = 3.867145\n",
      "Epoch: 9\tFidelity = 0.500546\tKL_Divergence = 3.940687\n",
      "Epoch: 10\tFidelity = 0.500535\tKL_Divergence = 3.952004\n",
      "Epoch: 11\tFidelity = 0.500552\tKL_Divergence = 3.934234\n",
      "Epoch: 12\tFidelity = 0.500570\tKL_Divergence = 3.916424\n",
      "Epoch: 13\tFidelity = 0.500519\tKL_Divergence = 3.967991\n",
      "Epoch: 14\tFidelity = 0.500419\tKL_Divergence = 4.086839\n",
      "Epoch: 15\tFidelity = 0.500587\tKL_Divergence = 3.900447\n",
      "Epoch: 16\tFidelity = 0.500485\tKL_Divergence = 4.006524\n",
      "Epoch: 17\tFidelity = 0.500503\tKL_Divergence = 3.986130\n",
      "Epoch: 18\tFidelity = 0.500535\tKL_Divergence = 3.951570\n",
      "Epoch: 19\tFidelity = 0.500533\tKL_Divergence = 3.953718\n",
      "Epoch: 20\tFidelity = 0.500565\tKL_Divergence = 3.921666\n",
      "Epoch: 21\tFidelity = 0.500523\tKL_Divergence = 3.964448\n",
      "Epoch: 22\tFidelity = 0.500557\tKL_Divergence = 3.929453\n",
      "Epoch: 23\tFidelity = 0.500550\tKL_Divergence = 3.935806\n",
      "Epoch: 24\tFidelity = 0.500510\tKL_Divergence = 3.978274\n",
      "Epoch: 25\tFidelity = 0.500533\tKL_Divergence = 3.953250\n",
      "Epoch: 26\tFidelity = 0.500565\tKL_Divergence = 3.921349\n",
      "Epoch: 27\tFidelity = 0.500594\tKL_Divergence = 3.893941\n",
      "Epoch: 28\tFidelity = 0.500606\tKL_Divergence = 3.882363\n",
      "Epoch: 29\tFidelity = 0.500460\tKL_Divergence = 4.035065\n",
      "Epoch: 30\tFidelity = 0.500439\tKL_Divergence = 4.061888\n",
      "Epoch: 31\tFidelity = 0.500541\tKL_Divergence = 3.945302\n",
      "Epoch: 32\tFidelity = 0.500469\tKL_Divergence = 4.025377\n",
      "Epoch: 33\tFidelity = 0.500504\tKL_Divergence = 3.984488\n",
      "Epoch: 34\tFidelity = 0.500467\tKL_Divergence = 4.026997\n",
      "Epoch: 35\tFidelity = 0.500585\tKL_Divergence = 3.902292\n",
      "Epoch: 36\tFidelity = 0.500479\tKL_Divergence = 4.012807\n",
      "Epoch: 37\tFidelity = 0.500514\tKL_Divergence = 3.973487\n",
      "Epoch: 38\tFidelity = 0.500453\tKL_Divergence = 4.044663\n",
      "Epoch: 39\tFidelity = 0.500511\tKL_Divergence = 3.977532\n",
      "Epoch: 40\tFidelity = 0.500556\tKL_Divergence = 3.930473\n",
      "Epoch: 41\tFidelity = 0.500474\tKL_Divergence = 4.018276\n",
      "Epoch: 42\tFidelity = 0.500470\tKL_Divergence = 4.023426\n",
      "Epoch: 43\tFidelity = 0.500528\tKL_Divergence = 3.959145\n",
      "Epoch: 44\tFidelity = 0.500584\tKL_Divergence = 3.903347\n",
      "Epoch: 45\tFidelity = 0.500527\tKL_Divergence = 3.960449\n",
      "Epoch: 46\tFidelity = 0.500636\tKL_Divergence = 3.855734\n",
      "Epoch: 47\tFidelity = 0.500479\tKL_Divergence = 4.012862\n",
      "Epoch: 48\tFidelity = 0.500503\tKL_Divergence = 3.985702\n",
      "Epoch: 49\tFidelity = 0.500484\tKL_Divergence = 4.007219\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:44:16,801] Trial 393 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500547\tKL_Divergence = 3.939299\n",
      "Total time elapsed during training: 83.148 s\n",
      "Trial 393 pruned. \n",
      "Epoch: 1\tFidelity = 0.500486\tKL_Divergence = 4.004816\n",
      "Epoch: 2\tFidelity = 0.500626\tKL_Divergence = 3.864334\n",
      "Epoch: 3\tFidelity = 0.500491\tKL_Divergence = 3.999432\n",
      "Epoch: 4\tFidelity = 0.500383\tKL_Divergence = 4.137279\n",
      "Epoch: 5\tFidelity = 0.500345\tKL_Divergence = 4.195321\n",
      "Epoch: 6\tFidelity = 0.500615\tKL_Divergence = 3.874432\n",
      "Epoch: 7\tFidelity = 0.500508\tKL_Divergence = 3.980570\n",
      "Epoch: 8\tFidelity = 0.500474\tKL_Divergence = 4.018179\n",
      "Epoch: 9\tFidelity = 0.500499\tKL_Divergence = 3.990686\n",
      "Epoch: 10\tFidelity = 0.500473\tKL_Divergence = 4.019577\n",
      "Epoch: 11\tFidelity = 0.500519\tKL_Divergence = 3.968182\n",
      "Epoch: 12\tFidelity = 0.500559\tKL_Divergence = 3.927535\n",
      "Epoch: 13\tFidelity = 0.500504\tKL_Divergence = 3.984623\n",
      "Epoch: 14\tFidelity = 0.500451\tKL_Divergence = 4.046563\n",
      "Epoch: 15\tFidelity = 0.500445\tKL_Divergence = 4.054360\n",
      "Epoch: 16\tFidelity = 0.500434\tKL_Divergence = 4.067547\n",
      "Epoch: 17\tFidelity = 0.500450\tKL_Divergence = 4.048149\n",
      "Epoch: 18\tFidelity = 0.500625\tKL_Divergence = 3.865833\n",
      "Epoch: 19\tFidelity = 0.500611\tKL_Divergence = 3.878450\n",
      "Epoch: 20\tFidelity = 0.500475\tKL_Divergence = 4.017771\n",
      "Epoch: 21\tFidelity = 0.500572\tKL_Divergence = 3.914215\n",
      "Epoch: 22\tFidelity = 0.500487\tKL_Divergence = 4.003956\n",
      "Epoch: 23\tFidelity = 0.500461\tKL_Divergence = 4.033867\n",
      "Epoch: 24\tFidelity = 0.500491\tKL_Divergence = 3.998962\n",
      "Epoch: 25\tFidelity = 0.500490\tKL_Divergence = 4.001103\n",
      "Epoch: 26\tFidelity = 0.500505\tKL_Divergence = 3.984013\n",
      "Epoch: 27\tFidelity = 0.500549\tKL_Divergence = 3.937395\n",
      "Epoch: 28\tFidelity = 0.500490\tKL_Divergence = 4.000224\n",
      "Epoch: 29\tFidelity = 0.500454\tKL_Divergence = 4.042417\n",
      "Epoch: 30\tFidelity = 0.500481\tKL_Divergence = 4.010893\n",
      "Epoch: 31\tFidelity = 0.500578\tKL_Divergence = 3.908487\n",
      "Epoch: 32\tFidelity = 0.500444\tKL_Divergence = 4.054811\n",
      "Epoch: 33\tFidelity = 0.500617\tKL_Divergence = 3.872672\n",
      "Epoch: 34\tFidelity = 0.500487\tKL_Divergence = 4.003639\n",
      "Epoch: 35\tFidelity = 0.500499\tKL_Divergence = 3.990331\n",
      "Epoch: 36\tFidelity = 0.500528\tKL_Divergence = 3.959333\n",
      "Epoch: 37\tFidelity = 0.500505\tKL_Divergence = 3.983584\n",
      "Epoch: 38\tFidelity = 0.500570\tKL_Divergence = 3.915670\n",
      "Epoch: 39\tFidelity = 0.500454\tKL_Divergence = 4.042619\n",
      "Epoch: 40\tFidelity = 0.500593\tKL_Divergence = 3.894016\n",
      "Epoch: 41\tFidelity = 0.500514\tKL_Divergence = 3.974366\n",
      "Epoch: 42\tFidelity = 0.500629\tKL_Divergence = 3.862185\n",
      "Epoch: 43\tFidelity = 0.500416\tKL_Divergence = 4.090834\n",
      "Epoch: 44\tFidelity = 0.500371\tKL_Divergence = 4.155519\n",
      "Epoch: 45\tFidelity = 0.500456\tKL_Divergence = 4.040910\n",
      "Epoch: 46\tFidelity = 0.500393\tKL_Divergence = 4.123291\n",
      "Epoch: 47\tFidelity = 0.500609\tKL_Divergence = 3.879729\n",
      "Epoch: 48\tFidelity = 0.500478\tKL_Divergence = 4.014235\n",
      "Epoch: 49\tFidelity = 0.500480\tKL_Divergence = 4.011650\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:45:02,854] Trial 394 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500513\tKL_Divergence = 3.974186\n",
      "Total time elapsed during training: 45.881 s\n",
      "Trial 394 pruned. \n",
      "Epoch: 1\tFidelity = 0.500475\tKL_Divergence = 4.017258\n",
      "Epoch: 2\tFidelity = 0.500495\tKL_Divergence = 3.994535\n",
      "Epoch: 3\tFidelity = 0.500525\tKL_Divergence = 3.961759\n",
      "Epoch: 4\tFidelity = 0.500526\tKL_Divergence = 3.960429\n",
      "Epoch: 5\tFidelity = 0.500579\tKL_Divergence = 3.907504\n",
      "Epoch: 6\tFidelity = 0.500523\tKL_Divergence = 3.964135\n",
      "Epoch: 7\tFidelity = 0.500465\tKL_Divergence = 4.029481\n",
      "Epoch: 8\tFidelity = 0.500529\tKL_Divergence = 3.957893\n",
      "Epoch: 9\tFidelity = 0.500503\tKL_Divergence = 3.986135\n",
      "Epoch: 10\tFidelity = 0.500498\tKL_Divergence = 3.990719\n",
      "Epoch: 11\tFidelity = 0.500521\tKL_Divergence = 3.966515\n",
      "Epoch: 12\tFidelity = 0.500524\tKL_Divergence = 3.962950\n",
      "Epoch: 13\tFidelity = 0.500554\tKL_Divergence = 3.931659\n",
      "Epoch: 14\tFidelity = 0.500558\tKL_Divergence = 3.927842\n",
      "Epoch: 15\tFidelity = 0.500545\tKL_Divergence = 3.941206\n",
      "Epoch: 16\tFidelity = 0.500528\tKL_Divergence = 3.958894\n",
      "Epoch: 17\tFidelity = 0.500520\tKL_Divergence = 3.966729\n",
      "Epoch: 18\tFidelity = 0.500515\tKL_Divergence = 3.972464\n",
      "Epoch: 19\tFidelity = 0.500504\tKL_Divergence = 3.984960\n",
      "Epoch: 20\tFidelity = 0.500475\tKL_Divergence = 4.016977\n",
      "Epoch: 21\tFidelity = 0.500534\tKL_Divergence = 3.952293\n",
      "Epoch: 22\tFidelity = 0.500564\tKL_Divergence = 3.921736\n",
      "Epoch: 23\tFidelity = 0.500553\tKL_Divergence = 3.933178\n",
      "Epoch: 24\tFidelity = 0.500505\tKL_Divergence = 3.983781\n",
      "Epoch: 25\tFidelity = 0.500550\tKL_Divergence = 3.936397\n",
      "Epoch: 26\tFidelity = 0.500482\tKL_Divergence = 4.008875\n",
      "Epoch: 27\tFidelity = 0.500506\tKL_Divergence = 3.982032\n",
      "Epoch: 28\tFidelity = 0.500516\tKL_Divergence = 3.971949\n",
      "Epoch: 29\tFidelity = 0.500518\tKL_Divergence = 3.969690\n",
      "Epoch: 30\tFidelity = 0.500484\tKL_Divergence = 4.007347\n",
      "Epoch: 31\tFidelity = 0.500500\tKL_Divergence = 3.988729\n",
      "Epoch: 32\tFidelity = 0.500496\tKL_Divergence = 3.993956\n",
      "Epoch: 33\tFidelity = 0.500544\tKL_Divergence = 3.942420\n",
      "Epoch: 34\tFidelity = 0.500533\tKL_Divergence = 3.953745\n",
      "Epoch: 35\tFidelity = 0.500526\tKL_Divergence = 3.961097\n",
      "Epoch: 36\tFidelity = 0.500518\tKL_Divergence = 3.969687\n",
      "Epoch: 37\tFidelity = 0.500511\tKL_Divergence = 3.976981\n",
      "Epoch: 38\tFidelity = 0.500499\tKL_Divergence = 3.990469\n",
      "Epoch: 39\tFidelity = 0.500509\tKL_Divergence = 3.979352\n",
      "Epoch: 40\tFidelity = 0.500496\tKL_Divergence = 3.993153\n",
      "Epoch: 41\tFidelity = 0.500466\tKL_Divergence = 4.028567\n",
      "Epoch: 42\tFidelity = 0.500489\tKL_Divergence = 4.001449\n",
      "Epoch: 43\tFidelity = 0.500528\tKL_Divergence = 3.958664\n",
      "Epoch: 44\tFidelity = 0.500486\tKL_Divergence = 4.005327\n",
      "Epoch: 45\tFidelity = 0.500508\tKL_Divergence = 3.980179\n",
      "Epoch: 46\tFidelity = 0.500560\tKL_Divergence = 3.925981\n",
      "Epoch: 47\tFidelity = 0.500479\tKL_Divergence = 4.013454\n",
      "Epoch: 48\tFidelity = 0.500505\tKL_Divergence = 3.983855\n",
      "Epoch: 49\tFidelity = 0.500461\tKL_Divergence = 4.034736\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:45:35,656] Trial 395 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500477\tKL_Divergence = 4.015596\n",
      "Total time elapsed during training: 32.629 s\n",
      "Trial 395 pruned. \n",
      "Epoch: 1\tFidelity = 0.500560\tKL_Divergence = 3.926460\n",
      "Epoch: 2\tFidelity = 0.500545\tKL_Divergence = 3.941242\n",
      "Epoch: 3\tFidelity = 0.500517\tKL_Divergence = 3.970422\n",
      "Epoch: 4\tFidelity = 0.500574\tKL_Divergence = 3.912641\n",
      "Epoch: 5\tFidelity = 0.500477\tKL_Divergence = 4.015866\n",
      "Epoch: 6\tFidelity = 0.500513\tKL_Divergence = 3.974984\n",
      "Epoch: 7\tFidelity = 0.500506\tKL_Divergence = 3.982085\n",
      "Epoch: 8\tFidelity = 0.500491\tKL_Divergence = 3.998877\n",
      "Epoch: 9\tFidelity = 0.500512\tKL_Divergence = 3.976200\n",
      "Epoch: 10\tFidelity = 0.500532\tKL_Divergence = 3.954784\n",
      "Epoch: 11\tFidelity = 0.500473\tKL_Divergence = 4.020498\n",
      "Epoch: 12\tFidelity = 0.500570\tKL_Divergence = 3.916101\n",
      "Epoch: 13\tFidelity = 0.500485\tKL_Divergence = 4.005829\n",
      "Epoch: 14\tFidelity = 0.500582\tKL_Divergence = 3.905376\n",
      "Epoch: 15\tFidelity = 0.500489\tKL_Divergence = 4.002001\n",
      "Epoch: 16\tFidelity = 0.500555\tKL_Divergence = 3.931493\n",
      "Epoch: 17\tFidelity = 0.500486\tKL_Divergence = 4.004611\n",
      "Epoch: 18\tFidelity = 0.500543\tKL_Divergence = 3.943881\n",
      "Epoch: 19\tFidelity = 0.500549\tKL_Divergence = 3.937025\n",
      "Epoch: 20\tFidelity = 0.500486\tKL_Divergence = 4.005419\n",
      "Epoch: 21\tFidelity = 0.500514\tKL_Divergence = 3.974217\n",
      "Epoch: 22\tFidelity = 0.500484\tKL_Divergence = 4.007190\n",
      "Epoch: 23\tFidelity = 0.500579\tKL_Divergence = 3.907410\n",
      "Epoch: 24\tFidelity = 0.500466\tKL_Divergence = 4.028873\n",
      "Epoch: 25\tFidelity = 0.500537\tKL_Divergence = 3.950054\n",
      "Epoch: 26\tFidelity = 0.500477\tKL_Divergence = 4.014989\n",
      "Epoch: 27\tFidelity = 0.500585\tKL_Divergence = 3.901721\n",
      "Epoch: 28\tFidelity = 0.500494\tKL_Divergence = 3.995483\n",
      "Epoch: 29\tFidelity = 0.500522\tKL_Divergence = 3.965718\n",
      "Epoch: 30\tFidelity = 0.500483\tKL_Divergence = 4.008732\n",
      "Epoch: 31\tFidelity = 0.500508\tKL_Divergence = 3.980291\n",
      "Epoch: 32\tFidelity = 0.500479\tKL_Divergence = 4.012719\n",
      "Epoch: 33\tFidelity = 0.500534\tKL_Divergence = 3.952273\n",
      "Epoch: 34\tFidelity = 0.500544\tKL_Divergence = 3.942436\n",
      "Epoch: 35\tFidelity = 0.500557\tKL_Divergence = 3.929661\n",
      "Epoch: 36\tFidelity = 0.500476\tKL_Divergence = 4.016845\n",
      "Epoch: 37\tFidelity = 0.500474\tKL_Divergence = 4.018881\n",
      "Epoch: 38\tFidelity = 0.500563\tKL_Divergence = 3.923482\n",
      "Epoch: 39\tFidelity = 0.500541\tKL_Divergence = 3.945391\n",
      "Epoch: 40\tFidelity = 0.500496\tKL_Divergence = 3.993545\n",
      "Epoch: 41\tFidelity = 0.500506\tKL_Divergence = 3.982958\n",
      "Epoch: 42\tFidelity = 0.500524\tKL_Divergence = 3.962918\n",
      "Epoch: 43\tFidelity = 0.500509\tKL_Divergence = 3.979147\n",
      "Epoch: 44\tFidelity = 0.500498\tKL_Divergence = 3.991439\n",
      "Epoch: 45\tFidelity = 0.500526\tKL_Divergence = 3.960931\n",
      "Epoch: 46\tFidelity = 0.500526\tKL_Divergence = 3.960980\n",
      "Epoch: 47\tFidelity = 0.500554\tKL_Divergence = 3.932716\n",
      "Epoch: 48\tFidelity = 0.500501\tKL_Divergence = 3.987575\n",
      "Epoch: 49\tFidelity = 0.500578\tKL_Divergence = 3.908396\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:46:09,069] Trial 396 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500458\tKL_Divergence = 4.038032\n",
      "Total time elapsed during training: 33.244 s\n",
      "Trial 396 pruned. \n",
      "Epoch: 1\tFidelity = 0.500555\tKL_Divergence = 3.931748\n",
      "Epoch: 2\tFidelity = 0.500457\tKL_Divergence = 4.039419\n",
      "Epoch: 3\tFidelity = 0.500538\tKL_Divergence = 3.947931\n",
      "Epoch: 4\tFidelity = 0.500488\tKL_Divergence = 4.002512\n",
      "Epoch: 5\tFidelity = 0.500498\tKL_Divergence = 3.991288\n",
      "Epoch: 6\tFidelity = 0.500489\tKL_Divergence = 4.001599\n",
      "Epoch: 7\tFidelity = 0.500502\tKL_Divergence = 3.986798\n",
      "Epoch: 8\tFidelity = 0.500512\tKL_Divergence = 3.975786\n",
      "Epoch: 9\tFidelity = 0.500521\tKL_Divergence = 3.966073\n",
      "Epoch: 10\tFidelity = 0.500575\tKL_Divergence = 3.911255\n",
      "Epoch: 11\tFidelity = 0.500521\tKL_Divergence = 3.966140\n",
      "Epoch: 12\tFidelity = 0.500494\tKL_Divergence = 3.995405\n",
      "Epoch: 13\tFidelity = 0.500476\tKL_Divergence = 4.016710\n",
      "Epoch: 14\tFidelity = 0.500593\tKL_Divergence = 3.893852\n",
      "Epoch: 15\tFidelity = 0.500531\tKL_Divergence = 3.955427\n",
      "Epoch: 16\tFidelity = 0.500551\tKL_Divergence = 3.935315\n",
      "Epoch: 17\tFidelity = 0.500486\tKL_Divergence = 4.004822\n",
      "Epoch: 18\tFidelity = 0.500485\tKL_Divergence = 4.005683\n",
      "Epoch: 19\tFidelity = 0.500560\tKL_Divergence = 3.926197\n",
      "Epoch: 20\tFidelity = 0.500582\tKL_Divergence = 3.904597\n",
      "Epoch: 21\tFidelity = 0.500471\tKL_Divergence = 4.021359\n",
      "Epoch: 22\tFidelity = 0.500558\tKL_Divergence = 3.928081\n",
      "Epoch: 23\tFidelity = 0.500453\tKL_Divergence = 4.043331\n",
      "Epoch: 24\tFidelity = 0.500471\tKL_Divergence = 4.021081\n",
      "Epoch: 25\tFidelity = 0.500480\tKL_Divergence = 4.011684\n",
      "Epoch: 26\tFidelity = 0.500561\tKL_Divergence = 3.924603\n",
      "Epoch: 27\tFidelity = 0.500450\tKL_Divergence = 4.046735\n",
      "Epoch: 28\tFidelity = 0.500496\tKL_Divergence = 3.992846\n",
      "Epoch: 29\tFidelity = 0.500491\tKL_Divergence = 3.998380\n",
      "Epoch: 30\tFidelity = 0.500568\tKL_Divergence = 3.917796\n",
      "Epoch: 31\tFidelity = 0.500541\tKL_Divergence = 3.944869\n",
      "Epoch: 32\tFidelity = 0.500516\tKL_Divergence = 3.971028\n",
      "Epoch: 33\tFidelity = 0.500546\tKL_Divergence = 3.939279\n",
      "Epoch: 34\tFidelity = 0.500499\tKL_Divergence = 3.989795\n",
      "Epoch: 35\tFidelity = 0.500514\tKL_Divergence = 3.973453\n",
      "Epoch: 36\tFidelity = 0.500592\tKL_Divergence = 3.895674\n",
      "Epoch: 37\tFidelity = 0.500550\tKL_Divergence = 3.936032\n",
      "Epoch: 38\tFidelity = 0.500591\tKL_Divergence = 3.895901\n",
      "Epoch: 39\tFidelity = 0.500561\tKL_Divergence = 3.925330\n",
      "Epoch: 40\tFidelity = 0.500471\tKL_Divergence = 4.022332\n",
      "Epoch: 41\tFidelity = 0.500607\tKL_Divergence = 3.880974\n",
      "Epoch: 42\tFidelity = 0.500495\tKL_Divergence = 3.994366\n",
      "Epoch: 43\tFidelity = 0.500528\tKL_Divergence = 3.958591\n",
      "Epoch: 44\tFidelity = 0.500605\tKL_Divergence = 3.883381\n",
      "Epoch: 45\tFidelity = 0.500503\tKL_Divergence = 3.985562\n",
      "Epoch: 46\tFidelity = 0.500574\tKL_Divergence = 3.912242\n",
      "Epoch: 47\tFidelity = 0.500457\tKL_Divergence = 4.039012\n",
      "Epoch: 48\tFidelity = 0.500485\tKL_Divergence = 4.006151\n",
      "Epoch: 49\tFidelity = 0.500593\tKL_Divergence = 3.894665\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:46:48,693] Trial 397 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500442\tKL_Divergence = 4.057889\n",
      "Total time elapsed during training: 39.424 s\n",
      "Trial 397 pruned. \n",
      "Epoch: 1\tFidelity = 0.500545\tKL_Divergence = 3.941384\n",
      "Epoch: 2\tFidelity = 0.500553\tKL_Divergence = 3.933485\n",
      "Epoch: 3\tFidelity = 0.500499\tKL_Divergence = 3.989759\n",
      "Epoch: 4\tFidelity = 0.500499\tKL_Divergence = 3.990281\n",
      "Epoch: 5\tFidelity = 0.500529\tKL_Divergence = 3.958329\n",
      "Epoch: 6\tFidelity = 0.500491\tKL_Divergence = 3.999701\n",
      "Epoch: 7\tFidelity = 0.500486\tKL_Divergence = 4.005493\n",
      "Epoch: 8\tFidelity = 0.500510\tKL_Divergence = 3.978089\n",
      "Epoch: 9\tFidelity = 0.500447\tKL_Divergence = 4.051692\n",
      "Epoch: 10\tFidelity = 0.500485\tKL_Divergence = 4.006093\n",
      "Epoch: 11\tFidelity = 0.500468\tKL_Divergence = 4.025402\n",
      "Epoch: 12\tFidelity = 0.500533\tKL_Divergence = 3.953636\n",
      "Epoch: 13\tFidelity = 0.500524\tKL_Divergence = 3.963467\n",
      "Epoch: 14\tFidelity = 0.500490\tKL_Divergence = 3.999872\n",
      "Epoch: 15\tFidelity = 0.500532\tKL_Divergence = 3.954625\n",
      "Epoch: 16\tFidelity = 0.500536\tKL_Divergence = 3.950376\n",
      "Epoch: 17\tFidelity = 0.500456\tKL_Divergence = 4.040053\n",
      "Epoch: 18\tFidelity = 0.500508\tKL_Divergence = 3.980094\n",
      "Epoch: 19\tFidelity = 0.500486\tKL_Divergence = 4.004424\n",
      "Epoch: 20\tFidelity = 0.500509\tKL_Divergence = 3.979617\n",
      "Epoch: 21\tFidelity = 0.500480\tKL_Divergence = 4.011134\n",
      "Epoch: 22\tFidelity = 0.500499\tKL_Divergence = 3.990120\n",
      "Epoch: 23\tFidelity = 0.500520\tKL_Divergence = 3.967417\n",
      "Epoch: 24\tFidelity = 0.500561\tKL_Divergence = 3.924965\n",
      "Epoch: 25\tFidelity = 0.500556\tKL_Divergence = 3.930202\n",
      "Epoch: 26\tFidelity = 0.500493\tKL_Divergence = 3.996591\n",
      "Epoch: 27\tFidelity = 0.500519\tKL_Divergence = 3.968422\n",
      "Epoch: 28\tFidelity = 0.500500\tKL_Divergence = 3.988567\n",
      "Epoch: 29\tFidelity = 0.500523\tKL_Divergence = 3.964314\n",
      "Epoch: 30\tFidelity = 0.500527\tKL_Divergence = 3.959606\n",
      "Epoch: 31\tFidelity = 0.500535\tKL_Divergence = 3.951558\n",
      "Epoch: 32\tFidelity = 0.500511\tKL_Divergence = 3.976740\n",
      "Epoch: 33\tFidelity = 0.500578\tKL_Divergence = 3.909114\n",
      "Epoch: 34\tFidelity = 0.500500\tKL_Divergence = 3.989699\n",
      "Epoch: 35\tFidelity = 0.500520\tKL_Divergence = 3.967469\n",
      "Epoch: 36\tFidelity = 0.500531\tKL_Divergence = 3.955475\n",
      "Epoch: 37\tFidelity = 0.500492\tKL_Divergence = 3.998469\n",
      "Epoch: 38\tFidelity = 0.500527\tKL_Divergence = 3.959982\n",
      "Epoch: 39\tFidelity = 0.500567\tKL_Divergence = 3.918944\n",
      "Epoch: 40\tFidelity = 0.500534\tKL_Divergence = 3.952858\n",
      "Epoch: 41\tFidelity = 0.500518\tKL_Divergence = 3.969505\n",
      "Epoch: 42\tFidelity = 0.500503\tKL_Divergence = 3.986211\n",
      "Epoch: 43\tFidelity = 0.500499\tKL_Divergence = 3.990159\n",
      "Epoch: 44\tFidelity = 0.500492\tKL_Divergence = 3.998462\n",
      "Epoch: 45\tFidelity = 0.500530\tKL_Divergence = 3.956771\n",
      "Epoch: 46\tFidelity = 0.500532\tKL_Divergence = 3.954680\n",
      "Epoch: 47\tFidelity = 0.500557\tKL_Divergence = 3.928885\n",
      "Epoch: 48\tFidelity = 0.500584\tKL_Divergence = 3.903150\n",
      "Epoch: 49\tFidelity = 0.500510\tKL_Divergence = 3.978420\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:47:28,398] Trial 398 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500494\tKL_Divergence = 3.996113\n",
      "Total time elapsed during training: 39.532 s\n",
      "Trial 398 pruned. \n",
      "Epoch: 1\tFidelity = 0.500472\tKL_Divergence = 4.021312\n",
      "Epoch: 2\tFidelity = 0.500484\tKL_Divergence = 4.006633\n",
      "Epoch: 3\tFidelity = 0.500504\tKL_Divergence = 3.985144\n",
      "Epoch: 4\tFidelity = 0.500569\tKL_Divergence = 3.917284\n",
      "Epoch: 5\tFidelity = 0.500600\tKL_Divergence = 3.887698\n",
      "Epoch: 6\tFidelity = 0.500604\tKL_Divergence = 3.884152\n",
      "Epoch: 7\tFidelity = 0.500524\tKL_Divergence = 3.963187\n",
      "Epoch: 8\tFidelity = 0.500605\tKL_Divergence = 3.883033\n",
      "Epoch: 9\tFidelity = 0.500524\tKL_Divergence = 3.963114\n",
      "Epoch: 10\tFidelity = 0.500552\tKL_Divergence = 3.933724\n",
      "Epoch: 11\tFidelity = 0.500565\tKL_Divergence = 3.921246\n",
      "Epoch: 12\tFidelity = 0.500523\tKL_Divergence = 3.963727\n",
      "Epoch: 13\tFidelity = 0.500544\tKL_Divergence = 3.942656\n",
      "Epoch: 14\tFidelity = 0.500510\tKL_Divergence = 3.978122\n",
      "Epoch: 15\tFidelity = 0.500585\tKL_Divergence = 3.902294\n",
      "Epoch: 16\tFidelity = 0.500484\tKL_Divergence = 4.006841\n",
      "Epoch: 17\tFidelity = 0.500566\tKL_Divergence = 3.920405\n",
      "Epoch: 18\tFidelity = 0.500473\tKL_Divergence = 4.019672\n",
      "Epoch: 19\tFidelity = 0.500609\tKL_Divergence = 3.879702\n",
      "Epoch: 20\tFidelity = 0.500543\tKL_Divergence = 3.942863\n",
      "Epoch: 21\tFidelity = 0.500611\tKL_Divergence = 3.877555\n",
      "Epoch: 22\tFidelity = 0.500537\tKL_Divergence = 3.949285\n",
      "Epoch: 23\tFidelity = 0.500547\tKL_Divergence = 3.939124\n",
      "Epoch: 24\tFidelity = 0.500507\tKL_Divergence = 3.981202\n",
      "Epoch: 25\tFidelity = 0.500493\tKL_Divergence = 3.996422\n",
      "Epoch: 26\tFidelity = 0.500551\tKL_Divergence = 3.935510\n",
      "Epoch: 27\tFidelity = 0.500522\tKL_Divergence = 3.965693\n",
      "Epoch: 28\tFidelity = 0.500548\tKL_Divergence = 3.938471\n",
      "Epoch: 29\tFidelity = 0.500594\tKL_Divergence = 3.893825\n",
      "Epoch: 30\tFidelity = 0.500524\tKL_Divergence = 3.963184\n",
      "Epoch: 31\tFidelity = 0.500488\tKL_Divergence = 4.002662\n",
      "Epoch: 32\tFidelity = 0.500638\tKL_Divergence = 3.853835\n",
      "Epoch: 33\tFidelity = 0.500636\tKL_Divergence = 3.855385\n",
      "Epoch: 34\tFidelity = 0.500443\tKL_Divergence = 4.055691\n",
      "Epoch: 35\tFidelity = 0.500527\tKL_Divergence = 3.959444\n",
      "Epoch: 36\tFidelity = 0.500531\tKL_Divergence = 3.955844\n",
      "Epoch: 37\tFidelity = 0.500505\tKL_Divergence = 3.983528\n",
      "Epoch: 38\tFidelity = 0.500552\tKL_Divergence = 3.934183\n",
      "Epoch: 39\tFidelity = 0.500551\tKL_Divergence = 3.935590\n",
      "Epoch: 40\tFidelity = 0.500477\tKL_Divergence = 4.015297\n",
      "Epoch: 41\tFidelity = 0.500624\tKL_Divergence = 3.865869\n",
      "Epoch: 42\tFidelity = 0.500471\tKL_Divergence = 4.021929\n",
      "Epoch: 43\tFidelity = 0.500487\tKL_Divergence = 4.003889\n",
      "Epoch: 44\tFidelity = 0.500493\tKL_Divergence = 3.996344\n",
      "Epoch: 45\tFidelity = 0.500537\tKL_Divergence = 3.948951\n",
      "Epoch: 46\tFidelity = 0.500605\tKL_Divergence = 3.883015\n",
      "Epoch: 47\tFidelity = 0.500434\tKL_Divergence = 4.067803\n",
      "Epoch: 48\tFidelity = 0.500499\tKL_Divergence = 3.990575\n",
      "Epoch: 49\tFidelity = 0.500551\tKL_Divergence = 3.935066\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:48:07,782] Trial 399 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500597\tKL_Divergence = 3.890404\n",
      "Total time elapsed during training: 39.213 s\n",
      "Trial 399 pruned. \n",
      "Epoch: 1\tFidelity = 0.500566\tKL_Divergence = 3.920143\n",
      "Epoch: 2\tFidelity = 0.500511\tKL_Divergence = 3.976534\n",
      "Epoch: 3\tFidelity = 0.500512\tKL_Divergence = 3.976347\n",
      "Epoch: 4\tFidelity = 0.500493\tKL_Divergence = 3.997028\n",
      "Epoch: 5\tFidelity = 0.500514\tKL_Divergence = 3.973580\n",
      "Epoch: 6\tFidelity = 0.500610\tKL_Divergence = 3.878928\n",
      "Epoch: 7\tFidelity = 0.500553\tKL_Divergence = 3.933174\n",
      "Epoch: 8\tFidelity = 0.500503\tKL_Divergence = 3.985437\n",
      "Epoch: 9\tFidelity = 0.500518\tKL_Divergence = 3.969036\n",
      "Epoch: 10\tFidelity = 0.500569\tKL_Divergence = 3.917399\n",
      "Epoch: 11\tFidelity = 0.500556\tKL_Divergence = 3.930424\n",
      "Epoch: 12\tFidelity = 0.500461\tKL_Divergence = 4.033719\n",
      "Epoch: 13\tFidelity = 0.500464\tKL_Divergence = 4.030113\n",
      "Epoch: 14\tFidelity = 0.500490\tKL_Divergence = 4.000160\n",
      "Epoch: 15\tFidelity = 0.500614\tKL_Divergence = 3.875322\n",
      "Epoch: 16\tFidelity = 0.500470\tKL_Divergence = 4.024083\n",
      "Epoch: 17\tFidelity = 0.500498\tKL_Divergence = 3.991316\n",
      "Epoch: 18\tFidelity = 0.500549\tKL_Divergence = 3.936955\n",
      "Epoch: 19\tFidelity = 0.500515\tKL_Divergence = 3.972903\n",
      "Epoch: 20\tFidelity = 0.500552\tKL_Divergence = 3.934375\n",
      "Epoch: 21\tFidelity = 0.500520\tKL_Divergence = 3.966950\n",
      "Epoch: 22\tFidelity = 0.500513\tKL_Divergence = 3.975158\n",
      "Epoch: 23\tFidelity = 0.500555\tKL_Divergence = 3.930878\n",
      "Epoch: 24\tFidelity = 0.500493\tKL_Divergence = 3.996952\n",
      "Epoch: 25\tFidelity = 0.500523\tKL_Divergence = 3.964525\n",
      "Epoch: 26\tFidelity = 0.500538\tKL_Divergence = 3.948274\n",
      "Epoch: 27\tFidelity = 0.500588\tKL_Divergence = 3.898950\n",
      "Epoch: 28\tFidelity = 0.500526\tKL_Divergence = 3.961293\n",
      "Epoch: 29\tFidelity = 0.500570\tKL_Divergence = 3.916457\n",
      "Epoch: 30\tFidelity = 0.500567\tKL_Divergence = 3.919434\n",
      "Epoch: 31\tFidelity = 0.500506\tKL_Divergence = 3.981976\n",
      "Epoch: 32\tFidelity = 0.500532\tKL_Divergence = 3.955131\n",
      "Epoch: 33\tFidelity = 0.500389\tKL_Divergence = 4.128844\n",
      "Epoch: 34\tFidelity = 0.500471\tKL_Divergence = 4.022391\n",
      "Epoch: 35\tFidelity = 0.500559\tKL_Divergence = 3.927461\n",
      "Epoch: 36\tFidelity = 0.500545\tKL_Divergence = 3.941124\n",
      "Epoch: 37\tFidelity = 0.500583\tKL_Divergence = 3.903979\n",
      "Epoch: 38\tFidelity = 0.500508\tKL_Divergence = 3.979854\n",
      "Epoch: 39\tFidelity = 0.500567\tKL_Divergence = 3.919194\n",
      "Epoch: 40\tFidelity = 0.500522\tKL_Divergence = 3.965707\n",
      "Epoch: 41\tFidelity = 0.500539\tKL_Divergence = 3.947386\n",
      "Epoch: 42\tFidelity = 0.500601\tKL_Divergence = 3.886678\n",
      "Epoch: 43\tFidelity = 0.500562\tKL_Divergence = 3.924069\n",
      "Epoch: 44\tFidelity = 0.500533\tKL_Divergence = 3.953340\n",
      "Epoch: 45\tFidelity = 0.500595\tKL_Divergence = 3.892975\n",
      "Epoch: 46\tFidelity = 0.500457\tKL_Divergence = 4.039174\n",
      "Epoch: 47\tFidelity = 0.500516\tKL_Divergence = 3.972256\n",
      "Epoch: 48\tFidelity = 0.500583\tKL_Divergence = 3.903822\n",
      "Epoch: 49\tFidelity = 0.500523\tKL_Divergence = 3.964050\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:49:31,835] Trial 400 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500512\tKL_Divergence = 3.976575\n",
      "Total time elapsed during training: 83.878 s\n",
      "Trial 400 pruned. \n",
      "Epoch: 1\tFidelity = 0.500589\tKL_Divergence = 3.898659\n",
      "Epoch: 2\tFidelity = 0.500534\tKL_Divergence = 3.952427\n",
      "Epoch: 3\tFidelity = 0.500543\tKL_Divergence = 3.943146\n",
      "Epoch: 4\tFidelity = 0.500501\tKL_Divergence = 3.987801\n",
      "Epoch: 5\tFidelity = 0.500519\tKL_Divergence = 3.968597\n",
      "Epoch: 6\tFidelity = 0.500580\tKL_Divergence = 3.906525\n",
      "Epoch: 7\tFidelity = 0.500513\tKL_Divergence = 3.974516\n",
      "Epoch: 8\tFidelity = 0.500532\tKL_Divergence = 3.954692\n",
      "Epoch: 9\tFidelity = 0.500483\tKL_Divergence = 4.007928\n",
      "Epoch: 10\tFidelity = 0.500524\tKL_Divergence = 3.963062\n",
      "Epoch: 11\tFidelity = 0.500501\tKL_Divergence = 3.987535\n",
      "Epoch: 12\tFidelity = 0.500526\tKL_Divergence = 3.960407\n",
      "Epoch: 13\tFidelity = 0.500479\tKL_Divergence = 4.013333\n",
      "Epoch: 14\tFidelity = 0.500530\tKL_Divergence = 3.956761\n",
      "Epoch: 15\tFidelity = 0.500543\tKL_Divergence = 3.943378\n",
      "Epoch: 16\tFidelity = 0.500493\tKL_Divergence = 3.997104\n",
      "Epoch: 17\tFidelity = 0.500501\tKL_Divergence = 3.988498\n",
      "Epoch: 18\tFidelity = 0.500489\tKL_Divergence = 4.001219\n",
      "Epoch: 19\tFidelity = 0.500526\tKL_Divergence = 3.960674\n",
      "Epoch: 20\tFidelity = 0.500576\tKL_Divergence = 3.911108\n",
      "Epoch: 21\tFidelity = 0.500521\tKL_Divergence = 3.966216\n",
      "Epoch: 22\tFidelity = 0.500505\tKL_Divergence = 3.983171\n",
      "Epoch: 23\tFidelity = 0.500519\tKL_Divergence = 3.968339\n",
      "Epoch: 24\tFidelity = 0.500522\tKL_Divergence = 3.965153\n",
      "Epoch: 25\tFidelity = 0.500536\tKL_Divergence = 3.950153\n",
      "Epoch: 26\tFidelity = 0.500465\tKL_Divergence = 4.029477\n",
      "Epoch: 27\tFidelity = 0.500472\tKL_Divergence = 4.020648\n",
      "Epoch: 28\tFidelity = 0.500534\tKL_Divergence = 3.952399\n",
      "Epoch: 29\tFidelity = 0.500502\tKL_Divergence = 3.987295\n",
      "Epoch: 30\tFidelity = 0.500547\tKL_Divergence = 3.938726\n",
      "Epoch: 31\tFidelity = 0.500505\tKL_Divergence = 3.983491\n",
      "Epoch: 32\tFidelity = 0.500486\tKL_Divergence = 4.004473\n",
      "Epoch: 33\tFidelity = 0.500488\tKL_Divergence = 4.003224\n",
      "Epoch: 34\tFidelity = 0.500487\tKL_Divergence = 4.003870\n",
      "Epoch: 35\tFidelity = 0.500518\tKL_Divergence = 3.969344\n",
      "Epoch: 36\tFidelity = 0.500464\tKL_Divergence = 4.030386\n",
      "Epoch: 37\tFidelity = 0.500468\tKL_Divergence = 4.025769\n",
      "Epoch: 38\tFidelity = 0.500494\tKL_Divergence = 3.995581\n",
      "Epoch: 39\tFidelity = 0.500494\tKL_Divergence = 3.996030\n",
      "Epoch: 40\tFidelity = 0.500487\tKL_Divergence = 4.003816\n",
      "Epoch: 41\tFidelity = 0.500517\tKL_Divergence = 3.970779\n",
      "Epoch: 42\tFidelity = 0.500502\tKL_Divergence = 3.987434\n",
      "Epoch: 43\tFidelity = 0.500548\tKL_Divergence = 3.938332\n",
      "Epoch: 44\tFidelity = 0.500546\tKL_Divergence = 3.940283\n",
      "Epoch: 45\tFidelity = 0.500475\tKL_Divergence = 4.017692\n",
      "Epoch: 46\tFidelity = 0.500517\tKL_Divergence = 3.970703\n",
      "Epoch: 47\tFidelity = 0.500492\tKL_Divergence = 3.998454\n",
      "Epoch: 48\tFidelity = 0.500489\tKL_Divergence = 4.001686\n",
      "Epoch: 49\tFidelity = 0.500501\tKL_Divergence = 3.987885\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:50:31,647] Trial 401 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500503\tKL_Divergence = 3.986068\n",
      "Total time elapsed during training: 59.629 s\n",
      "Trial 401 pruned. \n",
      "Epoch: 1\tFidelity = 0.500556\tKL_Divergence = 3.930541\n",
      "Epoch: 2\tFidelity = 0.500563\tKL_Divergence = 3.923618\n",
      "Epoch: 3\tFidelity = 0.500561\tKL_Divergence = 3.925453\n",
      "Epoch: 4\tFidelity = 0.500474\tKL_Divergence = 4.018654\n",
      "Epoch: 5\tFidelity = 0.500545\tKL_Divergence = 3.940990\n",
      "Epoch: 6\tFidelity = 0.500456\tKL_Divergence = 4.040224\n",
      "Epoch: 7\tFidelity = 0.500466\tKL_Divergence = 4.029030\n",
      "Epoch: 8\tFidelity = 0.500627\tKL_Divergence = 3.863701\n",
      "Epoch: 9\tFidelity = 0.500599\tKL_Divergence = 3.887724\n",
      "Epoch: 10\tFidelity = 0.500477\tKL_Divergence = 4.013517\n",
      "Epoch: 11\tFidelity = 0.500508\tKL_Divergence = 3.980096\n",
      "Epoch: 12\tFidelity = 0.500500\tKL_Divergence = 3.988728\n",
      "Epoch: 13\tFidelity = 0.500433\tKL_Divergence = 4.069013\n",
      "Epoch: 14\tFidelity = 0.500489\tKL_Divergence = 4.001577\n",
      "Epoch: 15\tFidelity = 0.500550\tKL_Divergence = 3.935094\n",
      "Epoch: 16\tFidelity = 0.500486\tKL_Divergence = 4.004755\n",
      "Epoch: 17\tFidelity = 0.500442\tKL_Divergence = 4.055413\n",
      "Epoch: 18\tFidelity = 0.500601\tKL_Divergence = 3.885810\n",
      "Epoch: 19\tFidelity = 0.500536\tKL_Divergence = 3.948926\n",
      "Epoch: 20\tFidelity = 0.500616\tKL_Divergence = 3.872006\n",
      "Epoch: 21\tFidelity = 0.500463\tKL_Divergence = 4.029824\n",
      "Epoch: 22\tFidelity = 0.500440\tKL_Divergence = 4.059167\n",
      "Epoch: 23\tFidelity = 0.500389\tKL_Divergence = 4.127009\n",
      "Epoch: 24\tFidelity = 0.500476\tKL_Divergence = 4.015482\n",
      "Epoch: 25\tFidelity = 0.500496\tKL_Divergence = 3.991795\n",
      "Epoch: 26\tFidelity = 0.500460\tKL_Divergence = 4.035684\n",
      "Epoch: 27\tFidelity = 0.500420\tKL_Divergence = 4.084033\n",
      "Epoch: 28\tFidelity = 0.500565\tKL_Divergence = 3.920291\n",
      "Epoch: 29\tFidelity = 0.500388\tKL_Divergence = 4.129618\n",
      "Epoch: 30\tFidelity = 0.500396\tKL_Divergence = 4.117524\n",
      "Epoch: 31\tFidelity = 0.500598\tKL_Divergence = 3.888713\n",
      "Epoch: 32\tFidelity = 0.500586\tKL_Divergence = 3.899358\n",
      "Epoch: 33\tFidelity = 0.500567\tKL_Divergence = 3.914856\n",
      "Epoch: 34\tFidelity = 0.500419\tKL_Divergence = 4.085178\n",
      "Epoch: 35\tFidelity = 0.500642\tKL_Divergence = 3.846362\n",
      "Epoch: 36\tFidelity = 0.500445\tKL_Divergence = 4.049980\n",
      "Epoch: 37\tFidelity = 0.500461\tKL_Divergence = 4.029242\n",
      "Epoch: 38\tFidelity = 0.500451\tKL_Divergence = 4.040640\n",
      "Epoch: 39\tFidelity = 0.500447\tKL_Divergence = 4.048230\n",
      "Epoch: 40\tFidelity = 0.500510\tKL_Divergence = 3.975460\n",
      "Epoch: 41\tFidelity = 0.500473\tKL_Divergence = 4.019481\n",
      "Epoch: 42\tFidelity = 0.500559\tKL_Divergence = 3.925024\n",
      "Epoch: 43\tFidelity = 0.500478\tKL_Divergence = 4.012098\n",
      "Epoch: 44\tFidelity = 0.500523\tKL_Divergence = 3.963156\n",
      "Epoch: 45\tFidelity = 0.500420\tKL_Divergence = 4.084200\n",
      "Epoch: 46\tFidelity = 0.500522\tKL_Divergence = 3.961620\n",
      "Epoch: 47\tFidelity = 0.500559\tKL_Divergence = 3.924105\n",
      "Epoch: 48\tFidelity = 0.500626\tKL_Divergence = 3.863406\n",
      "Epoch: 49\tFidelity = 0.500487\tKL_Divergence = 4.002313\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:51:11,372] Trial 402 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500431\tKL_Divergence = 4.068417\n",
      "Total time elapsed during training: 39.553 s\n",
      "Trial 402 pruned. \n",
      "Epoch: 1\tFidelity = 0.500466\tKL_Divergence = 4.025871\n",
      "Epoch: 2\tFidelity = 0.500490\tKL_Divergence = 3.998303\n",
      "Epoch: 3\tFidelity = 0.500516\tKL_Divergence = 3.969312\n",
      "Epoch: 4\tFidelity = 0.500501\tKL_Divergence = 3.986411\n",
      "Epoch: 5\tFidelity = 0.500488\tKL_Divergence = 4.001398\n",
      "Epoch: 6\tFidelity = 0.500498\tKL_Divergence = 3.989278\n",
      "Epoch: 7\tFidelity = 0.500480\tKL_Divergence = 4.010490\n",
      "Epoch: 8\tFidelity = 0.500497\tKL_Divergence = 3.990920\n",
      "Epoch: 9\tFidelity = 0.500505\tKL_Divergence = 3.983017\n",
      "Epoch: 10\tFidelity = 0.500476\tKL_Divergence = 4.015051\n",
      "Epoch: 11\tFidelity = 0.500500\tKL_Divergence = 3.988524\n",
      "Epoch: 12\tFidelity = 0.500471\tKL_Divergence = 4.021094\n",
      "Epoch: 13\tFidelity = 0.500508\tKL_Divergence = 3.980152\n",
      "Epoch: 14\tFidelity = 0.500475\tKL_Divergence = 4.016724\n",
      "Epoch: 15\tFidelity = 0.500516\tKL_Divergence = 3.971191\n",
      "Epoch: 16\tFidelity = 0.500486\tKL_Divergence = 4.004717\n",
      "Epoch: 17\tFidelity = 0.500476\tKL_Divergence = 4.015829\n",
      "Epoch: 18\tFidelity = 0.500455\tKL_Divergence = 4.040509\n",
      "Epoch: 19\tFidelity = 0.500482\tKL_Divergence = 4.009037\n",
      "Epoch: 20\tFidelity = 0.500471\tKL_Divergence = 4.022471\n",
      "Epoch: 21\tFidelity = 0.500487\tKL_Divergence = 4.004014\n",
      "Epoch: 22\tFidelity = 0.500498\tKL_Divergence = 3.991183\n",
      "Epoch: 23\tFidelity = 0.500466\tKL_Divergence = 4.028498\n",
      "Epoch: 24\tFidelity = 0.500482\tKL_Divergence = 4.009355\n",
      "Epoch: 25\tFidelity = 0.500453\tKL_Divergence = 4.043704\n",
      "Epoch: 26\tFidelity = 0.500489\tKL_Divergence = 4.000872\n",
      "Epoch: 27\tFidelity = 0.500475\tKL_Divergence = 4.017131\n",
      "Epoch: 28\tFidelity = 0.500480\tKL_Divergence = 4.011387\n",
      "Epoch: 29\tFidelity = 0.500489\tKL_Divergence = 4.001888\n",
      "Epoch: 30\tFidelity = 0.500487\tKL_Divergence = 4.003320\n",
      "Epoch: 31\tFidelity = 0.500506\tKL_Divergence = 3.983084\n",
      "Epoch: 32\tFidelity = 0.500514\tKL_Divergence = 3.973785\n",
      "Epoch: 33\tFidelity = 0.500477\tKL_Divergence = 4.014911\n",
      "Epoch: 34\tFidelity = 0.500466\tKL_Divergence = 4.028218\n",
      "Epoch: 35\tFidelity = 0.500484\tKL_Divergence = 4.007339\n",
      "Epoch: 36\tFidelity = 0.500478\tKL_Divergence = 4.014128\n",
      "Epoch: 37\tFidelity = 0.500448\tKL_Divergence = 4.050731\n",
      "Epoch: 38\tFidelity = 0.500528\tKL_Divergence = 3.959328\n",
      "Epoch: 39\tFidelity = 0.500506\tKL_Divergence = 3.982767\n",
      "Epoch: 40\tFidelity = 0.500483\tKL_Divergence = 4.008258\n",
      "Epoch: 41\tFidelity = 0.500506\tKL_Divergence = 3.982847\n",
      "Epoch: 42\tFidelity = 0.500465\tKL_Divergence = 4.029618\n",
      "Epoch: 43\tFidelity = 0.500433\tKL_Divergence = 4.068873\n",
      "Epoch: 44\tFidelity = 0.500485\tKL_Divergence = 4.006348\n",
      "Epoch: 45\tFidelity = 0.500466\tKL_Divergence = 4.028246\n",
      "Epoch: 46\tFidelity = 0.500515\tKL_Divergence = 3.973404\n",
      "Epoch: 47\tFidelity = 0.500497\tKL_Divergence = 3.993151\n",
      "Epoch: 48\tFidelity = 0.500478\tKL_Divergence = 4.014763\n",
      "Epoch: 49\tFidelity = 0.500533\tKL_Divergence = 3.953727\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:51:57,929] Trial 403 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500498\tKL_Divergence = 3.991115\n",
      "Total time elapsed during training: 46.368 s\n",
      "Trial 403 pruned. \n",
      "Epoch: 1\tFidelity = 0.500490\tKL_Divergence = 4.000919\n",
      "Epoch: 2\tFidelity = 0.500489\tKL_Divergence = 4.001910\n",
      "Epoch: 3\tFidelity = 0.500446\tKL_Divergence = 4.052073\n",
      "Epoch: 4\tFidelity = 0.500467\tKL_Divergence = 4.027629\n",
      "Epoch: 5\tFidelity = 0.500519\tKL_Divergence = 3.968407\n",
      "Epoch: 6\tFidelity = 0.500488\tKL_Divergence = 4.002764\n",
      "Epoch: 7\tFidelity = 0.500440\tKL_Divergence = 4.059855\n",
      "Epoch: 8\tFidelity = 0.500460\tKL_Divergence = 4.035503\n",
      "Epoch: 9\tFidelity = 0.500531\tKL_Divergence = 3.955505\n",
      "Epoch: 10\tFidelity = 0.500518\tKL_Divergence = 3.969520\n",
      "Epoch: 11\tFidelity = 0.500532\tKL_Divergence = 3.955048\n",
      "Epoch: 12\tFidelity = 0.500550\tKL_Divergence = 3.936224\n",
      "Epoch: 13\tFidelity = 0.500520\tKL_Divergence = 3.967025\n",
      "Epoch: 14\tFidelity = 0.500503\tKL_Divergence = 3.985568\n",
      "Epoch: 15\tFidelity = 0.500461\tKL_Divergence = 4.034768\n",
      "Epoch: 16\tFidelity = 0.500459\tKL_Divergence = 4.036514\n",
      "Epoch: 17\tFidelity = 0.500495\tKL_Divergence = 3.994380\n",
      "Epoch: 18\tFidelity = 0.500463\tKL_Divergence = 4.032084\n",
      "Epoch: 19\tFidelity = 0.500468\tKL_Divergence = 4.026539\n",
      "Epoch: 20\tFidelity = 0.500506\tKL_Divergence = 3.982866\n",
      "Epoch: 21\tFidelity = 0.500428\tKL_Divergence = 4.075443\n",
      "Epoch: 22\tFidelity = 0.500441\tKL_Divergence = 4.058750\n",
      "Epoch: 23\tFidelity = 0.500503\tKL_Divergence = 3.985567\n",
      "Epoch: 24\tFidelity = 0.500451\tKL_Divergence = 4.046972\n",
      "Epoch: 25\tFidelity = 0.500452\tKL_Divergence = 4.045691\n",
      "Epoch: 26\tFidelity = 0.500501\tKL_Divergence = 3.988179\n",
      "Epoch: 27\tFidelity = 0.500508\tKL_Divergence = 3.979929\n",
      "Epoch: 28\tFidelity = 0.500475\tKL_Divergence = 4.017712\n",
      "Epoch: 29\tFidelity = 0.500442\tKL_Divergence = 4.058295\n",
      "Epoch: 30\tFidelity = 0.500475\tKL_Divergence = 4.018348\n",
      "Epoch: 31\tFidelity = 0.500443\tKL_Divergence = 4.056161\n",
      "Epoch: 32\tFidelity = 0.500419\tKL_Divergence = 4.087573\n",
      "Epoch: 33\tFidelity = 0.500527\tKL_Divergence = 3.960074\n",
      "Epoch: 34\tFidelity = 0.500506\tKL_Divergence = 3.982523\n",
      "Epoch: 35\tFidelity = 0.500509\tKL_Divergence = 3.979511\n",
      "Epoch: 36\tFidelity = 0.500496\tKL_Divergence = 3.993414\n",
      "Epoch: 37\tFidelity = 0.500448\tKL_Divergence = 4.050109\n",
      "Epoch: 38\tFidelity = 0.500477\tKL_Divergence = 4.014685\n",
      "Epoch: 39\tFidelity = 0.500478\tKL_Divergence = 4.014363\n",
      "Epoch: 40\tFidelity = 0.500487\tKL_Divergence = 4.004114\n",
      "Epoch: 41\tFidelity = 0.500463\tKL_Divergence = 4.031883\n",
      "Epoch: 42\tFidelity = 0.500534\tKL_Divergence = 3.953160\n",
      "Epoch: 43\tFidelity = 0.500568\tKL_Divergence = 3.918141\n",
      "Epoch: 44\tFidelity = 0.500534\tKL_Divergence = 3.952384\n",
      "Epoch: 45\tFidelity = 0.500433\tKL_Divergence = 4.069510\n",
      "Epoch: 46\tFidelity = 0.500478\tKL_Divergence = 4.014174\n",
      "Epoch: 47\tFidelity = 0.500537\tKL_Divergence = 3.949113\n",
      "Epoch: 48\tFidelity = 0.500510\tKL_Divergence = 3.977652\n",
      "Epoch: 49\tFidelity = 0.500446\tKL_Divergence = 4.051929\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:52:40,436] Trial 404 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500527\tKL_Divergence = 3.959719\n",
      "Total time elapsed during training: 42.325 s\n",
      "Trial 404 pruned. \n",
      "Epoch: 1\tFidelity = 0.500417\tKL_Divergence = 4.089811\n",
      "Epoch: 2\tFidelity = 0.500534\tKL_Divergence = 3.952087\n",
      "Epoch: 3\tFidelity = 0.500464\tKL_Divergence = 4.030183\n",
      "Epoch: 4\tFidelity = 0.500389\tKL_Divergence = 4.127324\n",
      "Epoch: 5\tFidelity = 0.500470\tKL_Divergence = 4.022622\n",
      "Epoch: 6\tFidelity = 0.500493\tKL_Divergence = 3.996777\n",
      "Epoch: 7\tFidelity = 0.500467\tKL_Divergence = 4.026457\n",
      "Epoch: 8\tFidelity = 0.500451\tKL_Divergence = 4.045980\n",
      "Epoch: 9\tFidelity = 0.500470\tKL_Divergence = 4.023047\n",
      "Epoch: 10\tFidelity = 0.500588\tKL_Divergence = 3.898542\n",
      "Epoch: 11\tFidelity = 0.500537\tKL_Divergence = 3.949145\n",
      "Epoch: 12\tFidelity = 0.500446\tKL_Divergence = 4.051714\n",
      "Epoch: 13\tFidelity = 0.500448\tKL_Divergence = 4.049347\n",
      "Epoch: 14\tFidelity = 0.500486\tKL_Divergence = 4.004177\n",
      "Epoch: 15\tFidelity = 0.500573\tKL_Divergence = 3.913014\n",
      "Epoch: 16\tFidelity = 0.500508\tKL_Divergence = 3.980057\n",
      "Epoch: 17\tFidelity = 0.500578\tKL_Divergence = 3.907761\n",
      "Epoch: 18\tFidelity = 0.500469\tKL_Divergence = 4.023929\n",
      "Epoch: 19\tFidelity = 0.500515\tKL_Divergence = 3.972262\n",
      "Epoch: 20\tFidelity = 0.500479\tKL_Divergence = 4.012675\n",
      "Epoch: 21\tFidelity = 0.500496\tKL_Divergence = 3.993491\n",
      "Epoch: 22\tFidelity = 0.500514\tKL_Divergence = 3.973952\n",
      "Epoch: 23\tFidelity = 0.500492\tKL_Divergence = 3.997337\n",
      "Epoch: 24\tFidelity = 0.500497\tKL_Divergence = 3.991784\n",
      "Epoch: 25\tFidelity = 0.500515\tKL_Divergence = 3.972644\n",
      "Epoch: 26\tFidelity = 0.500543\tKL_Divergence = 3.943515\n",
      "Epoch: 27\tFidelity = 0.500522\tKL_Divergence = 3.964724\n",
      "Epoch: 28\tFidelity = 0.500485\tKL_Divergence = 4.005198\n",
      "Epoch: 29\tFidelity = 0.500471\tKL_Divergence = 4.022291\n",
      "Epoch: 30\tFidelity = 0.500445\tKL_Divergence = 4.053584\n",
      "Epoch: 31\tFidelity = 0.500451\tKL_Divergence = 4.045560\n",
      "Epoch: 32\tFidelity = 0.500469\tKL_Divergence = 4.024770\n",
      "Epoch: 33\tFidelity = 0.500542\tKL_Divergence = 3.944322\n",
      "Epoch: 34\tFidelity = 0.500544\tKL_Divergence = 3.941549\n",
      "Epoch: 35\tFidelity = 0.500480\tKL_Divergence = 4.011508\n",
      "Epoch: 36\tFidelity = 0.500453\tKL_Divergence = 4.043823\n",
      "Epoch: 37\tFidelity = 0.500447\tKL_Divergence = 4.051333\n",
      "Epoch: 38\tFidelity = 0.500529\tKL_Divergence = 3.957364\n",
      "Epoch: 39\tFidelity = 0.500516\tKL_Divergence = 3.970973\n",
      "Epoch: 40\tFidelity = 0.500496\tKL_Divergence = 3.993681\n",
      "Epoch: 41\tFidelity = 0.500511\tKL_Divergence = 3.976816\n",
      "Epoch: 42\tFidelity = 0.500473\tKL_Divergence = 4.020226\n",
      "Epoch: 43\tFidelity = 0.500480\tKL_Divergence = 4.011712\n",
      "Epoch: 44\tFidelity = 0.500467\tKL_Divergence = 4.027417\n",
      "Epoch: 45\tFidelity = 0.500479\tKL_Divergence = 4.012605\n",
      "Epoch: 46\tFidelity = 0.500511\tKL_Divergence = 3.977050\n",
      "Epoch: 47\tFidelity = 0.500505\tKL_Divergence = 3.982997\n",
      "Epoch: 48\tFidelity = 0.500521\tKL_Divergence = 3.966489\n",
      "Epoch: 49\tFidelity = 0.500433\tKL_Divergence = 4.068690\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:53:24,722] Trial 405 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500499\tKL_Divergence = 3.990331\n",
      "Total time elapsed during training: 44.092 s\n",
      "Trial 405 pruned. \n",
      "Epoch: 1\tFidelity = 0.500483\tKL_Divergence = 4.008734\n",
      "Epoch: 2\tFidelity = 0.500512\tKL_Divergence = 3.976142\n",
      "Epoch: 3\tFidelity = 0.500476\tKL_Divergence = 4.016263\n",
      "Epoch: 4\tFidelity = 0.500482\tKL_Divergence = 4.009752\n",
      "Epoch: 5\tFidelity = 0.500468\tKL_Divergence = 4.026361\n",
      "Epoch: 6\tFidelity = 0.500492\tKL_Divergence = 3.998135\n",
      "Epoch: 7\tFidelity = 0.500480\tKL_Divergence = 4.011384\n",
      "Epoch: 8\tFidelity = 0.500530\tKL_Divergence = 3.957121\n",
      "Epoch: 9\tFidelity = 0.500467\tKL_Divergence = 4.026919\n",
      "Epoch: 10\tFidelity = 0.500448\tKL_Divergence = 4.050308\n",
      "Epoch: 11\tFidelity = 0.500487\tKL_Divergence = 4.004434\n",
      "Epoch: 12\tFidelity = 0.500495\tKL_Divergence = 3.994397\n",
      "Epoch: 13\tFidelity = 0.500489\tKL_Divergence = 4.001934\n",
      "Epoch: 14\tFidelity = 0.500491\tKL_Divergence = 3.998855\n",
      "Epoch: 15\tFidelity = 0.500468\tKL_Divergence = 4.025841\n",
      "Epoch: 16\tFidelity = 0.500490\tKL_Divergence = 4.000077\n",
      "Epoch: 17\tFidelity = 0.500502\tKL_Divergence = 3.986997\n",
      "Epoch: 18\tFidelity = 0.500484\tKL_Divergence = 4.007529\n",
      "Epoch: 19\tFidelity = 0.500460\tKL_Divergence = 4.035086\n",
      "Epoch: 20\tFidelity = 0.500485\tKL_Divergence = 4.005819\n",
      "Epoch: 21\tFidelity = 0.500460\tKL_Divergence = 4.035006\n",
      "Epoch: 22\tFidelity = 0.500502\tKL_Divergence = 3.986580\n",
      "Epoch: 23\tFidelity = 0.500487\tKL_Divergence = 4.004447\n",
      "Epoch: 24\tFidelity = 0.500478\tKL_Divergence = 4.014330\n",
      "Epoch: 25\tFidelity = 0.500469\tKL_Divergence = 4.024954\n",
      "Epoch: 26\tFidelity = 0.500466\tKL_Divergence = 4.028129\n",
      "Epoch: 27\tFidelity = 0.500492\tKL_Divergence = 3.997813\n",
      "Epoch: 28\tFidelity = 0.500468\tKL_Divergence = 4.026090\n",
      "Epoch: 29\tFidelity = 0.500498\tKL_Divergence = 3.991203\n",
      "Epoch: 30\tFidelity = 0.500524\tKL_Divergence = 3.963734\n",
      "Epoch: 31\tFidelity = 0.500464\tKL_Divergence = 4.031155\n",
      "Epoch: 32\tFidelity = 0.500445\tKL_Divergence = 4.053931\n",
      "Epoch: 33\tFidelity = 0.500429\tKL_Divergence = 4.074642\n",
      "Epoch: 34\tFidelity = 0.500466\tKL_Divergence = 4.028827\n",
      "Epoch: 35\tFidelity = 0.500469\tKL_Divergence = 4.024992\n",
      "Epoch: 36\tFidelity = 0.500466\tKL_Divergence = 4.028584\n",
      "Epoch: 37\tFidelity = 0.500453\tKL_Divergence = 4.043643\n",
      "Epoch: 38\tFidelity = 0.500456\tKL_Divergence = 4.040232\n",
      "Epoch: 39\tFidelity = 0.500484\tKL_Divergence = 4.007596\n",
      "Epoch: 40\tFidelity = 0.500484\tKL_Divergence = 4.007220\n",
      "Epoch: 41\tFidelity = 0.500477\tKL_Divergence = 4.015902\n",
      "Epoch: 42\tFidelity = 0.500490\tKL_Divergence = 4.001026\n",
      "Epoch: 43\tFidelity = 0.500450\tKL_Divergence = 4.047567\n",
      "Epoch: 44\tFidelity = 0.500470\tKL_Divergence = 4.023470\n",
      "Epoch: 45\tFidelity = 0.500477\tKL_Divergence = 4.015964\n",
      "Epoch: 46\tFidelity = 0.500482\tKL_Divergence = 4.009317\n",
      "Epoch: 47\tFidelity = 0.500466\tKL_Divergence = 4.028477\n",
      "Epoch: 48\tFidelity = 0.500459\tKL_Divergence = 4.036358\n",
      "Epoch: 49\tFidelity = 0.500499\tKL_Divergence = 3.990519\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:54:53,359] Trial 406 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500471\tKL_Divergence = 4.023003\n",
      "Total time elapsed during training: 88.432 s\n",
      "Trial 406 pruned. \n",
      "Epoch: 1\tFidelity = 0.500477\tKL_Divergence = 4.015292\n",
      "Epoch: 2\tFidelity = 0.500447\tKL_Divergence = 4.052048\n",
      "Epoch: 3\tFidelity = 0.500457\tKL_Divergence = 4.039511\n",
      "Epoch: 4\tFidelity = 0.500446\tKL_Divergence = 4.052577\n",
      "Epoch: 5\tFidelity = 0.500457\tKL_Divergence = 4.039489\n",
      "Epoch: 6\tFidelity = 0.500486\tKL_Divergence = 4.005104\n",
      "Epoch: 7\tFidelity = 0.500495\tKL_Divergence = 3.994471\n",
      "Epoch: 8\tFidelity = 0.500482\tKL_Divergence = 4.009287\n",
      "Epoch: 9\tFidelity = 0.500464\tKL_Divergence = 4.030976\n",
      "Epoch: 10\tFidelity = 0.500473\tKL_Divergence = 4.019709\n",
      "Epoch: 11\tFidelity = 0.500493\tKL_Divergence = 3.997029\n",
      "Epoch: 12\tFidelity = 0.500469\tKL_Divergence = 4.025097\n",
      "Epoch: 13\tFidelity = 0.500482\tKL_Divergence = 4.009855\n",
      "Epoch: 14\tFidelity = 0.500465\tKL_Divergence = 4.029283\n",
      "Epoch: 15\tFidelity = 0.500478\tKL_Divergence = 4.013944\n",
      "Epoch: 16\tFidelity = 0.500453\tKL_Divergence = 4.043856\n",
      "Epoch: 17\tFidelity = 0.500474\tKL_Divergence = 4.019588\n",
      "Epoch: 18\tFidelity = 0.500493\tKL_Divergence = 3.996722\n",
      "Epoch: 19\tFidelity = 0.500452\tKL_Divergence = 4.044972\n",
      "Epoch: 20\tFidelity = 0.500469\tKL_Divergence = 4.025059\n",
      "Epoch: 21\tFidelity = 0.500470\tKL_Divergence = 4.023214\n",
      "Epoch: 22\tFidelity = 0.500480\tKL_Divergence = 4.011913\n",
      "Epoch: 23\tFidelity = 0.500454\tKL_Divergence = 4.043192\n",
      "Epoch: 24\tFidelity = 0.500485\tKL_Divergence = 4.006428\n",
      "Epoch: 25\tFidelity = 0.500471\tKL_Divergence = 4.022353\n",
      "Epoch: 26\tFidelity = 0.500465\tKL_Divergence = 4.030270\n",
      "Epoch: 27\tFidelity = 0.500468\tKL_Divergence = 4.025893\n",
      "Epoch: 28\tFidelity = 0.500464\tKL_Divergence = 4.030953\n",
      "Epoch: 29\tFidelity = 0.500484\tKL_Divergence = 4.007068\n",
      "Epoch: 30\tFidelity = 0.500444\tKL_Divergence = 4.054913\n",
      "Epoch: 31\tFidelity = 0.500459\tKL_Divergence = 4.036962\n",
      "Epoch: 32\tFidelity = 0.500498\tKL_Divergence = 3.991658\n",
      "Epoch: 33\tFidelity = 0.500462\tKL_Divergence = 4.033533\n",
      "Epoch: 34\tFidelity = 0.500445\tKL_Divergence = 4.054698\n",
      "Epoch: 35\tFidelity = 0.500472\tKL_Divergence = 4.021522\n",
      "Epoch: 36\tFidelity = 0.500517\tKL_Divergence = 3.970552\n",
      "Epoch: 37\tFidelity = 0.500489\tKL_Divergence = 4.002057\n",
      "Epoch: 38\tFidelity = 0.500511\tKL_Divergence = 3.977835\n",
      "Epoch: 39\tFidelity = 0.500475\tKL_Divergence = 4.018144\n",
      "Epoch: 40\tFidelity = 0.500499\tKL_Divergence = 3.991007\n",
      "Epoch: 41\tFidelity = 0.500487\tKL_Divergence = 4.004202\n",
      "Epoch: 42\tFidelity = 0.500450\tKL_Divergence = 4.047988\n",
      "Epoch: 43\tFidelity = 0.500455\tKL_Divergence = 4.041616\n",
      "Epoch: 44\tFidelity = 0.500474\tKL_Divergence = 4.018741\n",
      "Epoch: 45\tFidelity = 0.500476\tKL_Divergence = 4.017085\n",
      "Epoch: 46\tFidelity = 0.500453\tKL_Divergence = 4.043801\n",
      "Epoch: 47\tFidelity = 0.500484\tKL_Divergence = 4.007789\n",
      "Epoch: 48\tFidelity = 0.500501\tKL_Divergence = 3.988261\n",
      "Epoch: 49\tFidelity = 0.500505\tKL_Divergence = 3.984366\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:55:25,779] Trial 407 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500476\tKL_Divergence = 4.017229\n",
      "Total time elapsed during training: 32.244 s\n",
      "Trial 407 pruned. \n",
      "Epoch: 1\tFidelity = 0.500505\tKL_Divergence = 3.984186\n",
      "Epoch: 2\tFidelity = 0.500461\tKL_Divergence = 4.034161\n",
      "Epoch: 3\tFidelity = 0.500495\tKL_Divergence = 3.994872\n",
      "Epoch: 4\tFidelity = 0.500454\tKL_Divergence = 4.043459\n",
      "Epoch: 5\tFidelity = 0.500461\tKL_Divergence = 4.034409\n",
      "Epoch: 6\tFidelity = 0.500490\tKL_Divergence = 4.000402\n",
      "Epoch: 7\tFidelity = 0.500502\tKL_Divergence = 3.986883\n",
      "Epoch: 8\tFidelity = 0.500486\tKL_Divergence = 4.005122\n",
      "Epoch: 9\tFidelity = 0.500473\tKL_Divergence = 4.019692\n",
      "Epoch: 10\tFidelity = 0.500470\tKL_Divergence = 4.023302\n",
      "Epoch: 11\tFidelity = 0.500464\tKL_Divergence = 4.030911\n",
      "Epoch: 12\tFidelity = 0.500435\tKL_Divergence = 4.066897\n",
      "Epoch: 13\tFidelity = 0.500476\tKL_Divergence = 4.016313\n",
      "Epoch: 14\tFidelity = 0.500444\tKL_Divergence = 4.054707\n",
      "Epoch: 15\tFidelity = 0.500491\tKL_Divergence = 3.999188\n",
      "Epoch: 16\tFidelity = 0.500485\tKL_Divergence = 4.005985\n",
      "Epoch: 17\tFidelity = 0.500488\tKL_Divergence = 4.002858\n",
      "Epoch: 18\tFidelity = 0.500479\tKL_Divergence = 4.013135\n",
      "Epoch: 19\tFidelity = 0.500462\tKL_Divergence = 4.032815\n",
      "Epoch: 20\tFidelity = 0.500453\tKL_Divergence = 4.043999\n",
      "Epoch: 21\tFidelity = 0.500498\tKL_Divergence = 3.991073\n",
      "Epoch: 22\tFidelity = 0.500453\tKL_Divergence = 4.044424\n",
      "Epoch: 23\tFidelity = 0.500473\tKL_Divergence = 4.020251\n",
      "Epoch: 24\tFidelity = 0.500511\tKL_Divergence = 3.977627\n",
      "Epoch: 25\tFidelity = 0.500509\tKL_Divergence = 3.979152\n",
      "Epoch: 26\tFidelity = 0.500449\tKL_Divergence = 4.049383\n",
      "Epoch: 27\tFidelity = 0.500481\tKL_Divergence = 4.010577\n",
      "Epoch: 28\tFidelity = 0.500426\tKL_Divergence = 4.078253\n",
      "Epoch: 29\tFidelity = 0.500496\tKL_Divergence = 3.993936\n",
      "Epoch: 30\tFidelity = 0.500447\tKL_Divergence = 4.051998\n",
      "Epoch: 31\tFidelity = 0.500464\tKL_Divergence = 4.031342\n",
      "Epoch: 32\tFidelity = 0.500465\tKL_Divergence = 4.029461\n",
      "Epoch: 33\tFidelity = 0.500440\tKL_Divergence = 4.060601\n",
      "Epoch: 34\tFidelity = 0.500490\tKL_Divergence = 4.000668\n",
      "Epoch: 35\tFidelity = 0.500453\tKL_Divergence = 4.044054\n",
      "Epoch: 36\tFidelity = 0.500521\tKL_Divergence = 3.966662\n",
      "Epoch: 37\tFidelity = 0.500440\tKL_Divergence = 4.059993\n",
      "Epoch: 38\tFidelity = 0.500511\tKL_Divergence = 3.976908\n",
      "Epoch: 39\tFidelity = 0.500513\tKL_Divergence = 3.975550\n",
      "Epoch: 40\tFidelity = 0.500516\tKL_Divergence = 3.971998\n",
      "Epoch: 41\tFidelity = 0.500462\tKL_Divergence = 4.033162\n",
      "Epoch: 42\tFidelity = 0.500499\tKL_Divergence = 3.991042\n",
      "Epoch: 43\tFidelity = 0.500459\tKL_Divergence = 4.036339\n",
      "Epoch: 44\tFidelity = 0.500487\tKL_Divergence = 4.003514\n",
      "Epoch: 45\tFidelity = 0.500525\tKL_Divergence = 3.962610\n",
      "Epoch: 46\tFidelity = 0.500493\tKL_Divergence = 3.997502\n",
      "Epoch: 47\tFidelity = 0.500469\tKL_Divergence = 4.024575\n",
      "Epoch: 48\tFidelity = 0.500477\tKL_Divergence = 4.015538\n",
      "Epoch: 49\tFidelity = 0.500474\tKL_Divergence = 4.019392\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:55:58,521] Trial 408 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500500\tKL_Divergence = 3.988981\n",
      "Total time elapsed during training: 32.569 s\n",
      "Trial 408 pruned. \n",
      "Epoch: 1\tFidelity = 0.500507\tKL_Divergence = 3.982020\n",
      "Epoch: 2\tFidelity = 0.500495\tKL_Divergence = 3.994915\n",
      "Epoch: 3\tFidelity = 0.500456\tKL_Divergence = 4.040244\n",
      "Epoch: 4\tFidelity = 0.500463\tKL_Divergence = 4.032046\n",
      "Epoch: 5\tFidelity = 0.500530\tKL_Divergence = 3.957016\n",
      "Epoch: 6\tFidelity = 0.500468\tKL_Divergence = 4.025682\n",
      "Epoch: 7\tFidelity = 0.500508\tKL_Divergence = 3.980888\n",
      "Epoch: 8\tFidelity = 0.500461\tKL_Divergence = 4.033985\n",
      "Epoch: 9\tFidelity = 0.500444\tKL_Divergence = 4.055553\n",
      "Epoch: 10\tFidelity = 0.500423\tKL_Divergence = 4.081733\n",
      "Epoch: 11\tFidelity = 0.500452\tKL_Divergence = 4.045968\n",
      "Epoch: 12\tFidelity = 0.500488\tKL_Divergence = 4.003280\n",
      "Epoch: 13\tFidelity = 0.500472\tKL_Divergence = 4.021049\n",
      "Epoch: 14\tFidelity = 0.500393\tKL_Divergence = 4.123507\n",
      "Epoch: 15\tFidelity = 0.500470\tKL_Divergence = 4.023843\n",
      "Epoch: 16\tFidelity = 0.500461\tKL_Divergence = 4.034990\n",
      "Epoch: 17\tFidelity = 0.500459\tKL_Divergence = 4.036433\n",
      "Epoch: 18\tFidelity = 0.500443\tKL_Divergence = 4.056668\n",
      "Epoch: 19\tFidelity = 0.500474\tKL_Divergence = 4.019065\n",
      "Epoch: 20\tFidelity = 0.500452\tKL_Divergence = 4.045073\n",
      "Epoch: 21\tFidelity = 0.500449\tKL_Divergence = 4.049559\n",
      "Epoch: 22\tFidelity = 0.500479\tKL_Divergence = 4.013401\n",
      "Epoch: 23\tFidelity = 0.500502\tKL_Divergence = 3.987006\n",
      "Epoch: 24\tFidelity = 0.500465\tKL_Divergence = 4.029442\n",
      "Epoch: 25\tFidelity = 0.500495\tKL_Divergence = 3.994876\n",
      "Epoch: 26\tFidelity = 0.500471\tKL_Divergence = 4.022302\n",
      "Epoch: 27\tFidelity = 0.500459\tKL_Divergence = 4.037315\n",
      "Epoch: 28\tFidelity = 0.500432\tKL_Divergence = 4.070133\n",
      "Epoch: 29\tFidelity = 0.500492\tKL_Divergence = 3.998087\n",
      "Epoch: 30\tFidelity = 0.500521\tKL_Divergence = 3.966665\n",
      "Epoch: 31\tFidelity = 0.500446\tKL_Divergence = 4.052390\n",
      "Epoch: 32\tFidelity = 0.500452\tKL_Divergence = 4.045458\n",
      "Epoch: 33\tFidelity = 0.500406\tKL_Divergence = 4.104315\n",
      "Epoch: 34\tFidelity = 0.500484\tKL_Divergence = 4.006962\n",
      "Epoch: 35\tFidelity = 0.500454\tKL_Divergence = 4.042366\n",
      "Epoch: 36\tFidelity = 0.500526\tKL_Divergence = 3.961014\n",
      "Epoch: 37\tFidelity = 0.500498\tKL_Divergence = 3.992084\n",
      "Epoch: 38\tFidelity = 0.500450\tKL_Divergence = 4.047487\n",
      "Epoch: 39\tFidelity = 0.500532\tKL_Divergence = 3.954711\n",
      "Epoch: 40\tFidelity = 0.500457\tKL_Divergence = 4.039128\n",
      "Epoch: 41\tFidelity = 0.500529\tKL_Divergence = 3.957943\n",
      "Epoch: 42\tFidelity = 0.500489\tKL_Divergence = 4.001797\n",
      "Epoch: 43\tFidelity = 0.500497\tKL_Divergence = 3.992745\n",
      "Epoch: 44\tFidelity = 0.500499\tKL_Divergence = 3.990010\n",
      "Epoch: 45\tFidelity = 0.500477\tKL_Divergence = 4.015575\n",
      "Epoch: 46\tFidelity = 0.500419\tKL_Divergence = 4.086796\n",
      "Epoch: 47\tFidelity = 0.500505\tKL_Divergence = 3.984075\n",
      "Epoch: 48\tFidelity = 0.500457\tKL_Divergence = 4.038832\n",
      "Epoch: 49\tFidelity = 0.500510\tKL_Divergence = 3.978219\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:56:38,066] Trial 409 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500474\tKL_Divergence = 4.019092\n",
      "Total time elapsed during training: 39.371 s\n",
      "Trial 409 pruned. \n",
      "Epoch: 1\tFidelity = 0.500470\tKL_Divergence = 4.022861\n",
      "Epoch: 2\tFidelity = 0.500466\tKL_Divergence = 4.027819\n",
      "Epoch: 3\tFidelity = 0.500471\tKL_Divergence = 4.021646\n",
      "Epoch: 4\tFidelity = 0.500523\tKL_Divergence = 3.963798\n",
      "Epoch: 5\tFidelity = 0.500480\tKL_Divergence = 4.011106\n",
      "Epoch: 6\tFidelity = 0.500524\tKL_Divergence = 3.961465\n",
      "Epoch: 7\tFidelity = 0.500486\tKL_Divergence = 4.003816\n",
      "Epoch: 8\tFidelity = 0.500494\tKL_Divergence = 3.995490\n",
      "Epoch: 9\tFidelity = 0.500522\tKL_Divergence = 3.965056\n",
      "Epoch: 10\tFidelity = 0.500451\tKL_Divergence = 4.045929\n",
      "Epoch: 11\tFidelity = 0.500489\tKL_Divergence = 4.001536\n",
      "Epoch: 12\tFidelity = 0.500491\tKL_Divergence = 3.999460\n",
      "Epoch: 13\tFidelity = 0.500415\tKL_Divergence = 4.092762\n",
      "Epoch: 14\tFidelity = 0.500434\tKL_Divergence = 4.067429\n",
      "Epoch: 15\tFidelity = 0.500571\tKL_Divergence = 3.915320\n",
      "Epoch: 16\tFidelity = 0.500558\tKL_Divergence = 3.928291\n",
      "Epoch: 17\tFidelity = 0.500513\tKL_Divergence = 3.975224\n",
      "Epoch: 18\tFidelity = 0.500559\tKL_Divergence = 3.926956\n",
      "Epoch: 19\tFidelity = 0.500537\tKL_Divergence = 3.949350\n",
      "Epoch: 20\tFidelity = 0.500479\tKL_Divergence = 4.011928\n",
      "Epoch: 21\tFidelity = 0.500563\tKL_Divergence = 3.922707\n",
      "Epoch: 22\tFidelity = 0.500523\tKL_Divergence = 3.963968\n",
      "Epoch: 23\tFidelity = 0.500527\tKL_Divergence = 3.959982\n",
      "Epoch: 24\tFidelity = 0.500500\tKL_Divergence = 3.989454\n",
      "Epoch: 25\tFidelity = 0.500550\tKL_Divergence = 3.936016\n",
      "Epoch: 26\tFidelity = 0.500562\tKL_Divergence = 3.924595\n",
      "Epoch: 27\tFidelity = 0.500540\tKL_Divergence = 3.946610\n",
      "Epoch: 28\tFidelity = 0.500441\tKL_Divergence = 4.058996\n",
      "Epoch: 29\tFidelity = 0.500454\tKL_Divergence = 4.043210\n",
      "Epoch: 30\tFidelity = 0.500514\tKL_Divergence = 3.974195\n",
      "Epoch: 31\tFidelity = 0.500433\tKL_Divergence = 4.069207\n",
      "Epoch: 32\tFidelity = 0.500500\tKL_Divergence = 3.988728\n",
      "Epoch: 33\tFidelity = 0.500517\tKL_Divergence = 3.970562\n",
      "Epoch: 34\tFidelity = 0.500475\tKL_Divergence = 4.017912\n",
      "Epoch: 35\tFidelity = 0.500473\tKL_Divergence = 4.020538\n",
      "Epoch: 36\tFidelity = 0.500523\tKL_Divergence = 3.963664\n",
      "Epoch: 37\tFidelity = 0.500551\tKL_Divergence = 3.935253\n",
      "Epoch: 38\tFidelity = 0.500475\tKL_Divergence = 4.017903\n",
      "Epoch: 39\tFidelity = 0.500525\tKL_Divergence = 3.961836\n",
      "Epoch: 40\tFidelity = 0.500518\tKL_Divergence = 3.969002\n",
      "Epoch: 41\tFidelity = 0.500411\tKL_Divergence = 4.097455\n",
      "Epoch: 42\tFidelity = 0.500403\tKL_Divergence = 4.109189\n",
      "Epoch: 43\tFidelity = 0.500518\tKL_Divergence = 3.968910\n",
      "Epoch: 44\tFidelity = 0.500426\tKL_Divergence = 4.077847\n",
      "Epoch: 45\tFidelity = 0.500457\tKL_Divergence = 4.039117\n",
      "Epoch: 46\tFidelity = 0.500516\tKL_Divergence = 3.971263\n",
      "Epoch: 47\tFidelity = 0.500465\tKL_Divergence = 4.028931\n",
      "Epoch: 48\tFidelity = 0.500415\tKL_Divergence = 4.092792\n",
      "Epoch: 49\tFidelity = 0.500435\tKL_Divergence = 4.066984\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:57:17,299] Trial 410 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500465\tKL_Divergence = 4.029631\n",
      "Total time elapsed during training: 39.058 s\n",
      "Trial 410 pruned. \n",
      "Epoch: 1\tFidelity = 0.500554\tKL_Divergence = 3.932389\n",
      "Epoch: 2\tFidelity = 0.500471\tKL_Divergence = 4.022392\n",
      "Epoch: 3\tFidelity = 0.500612\tKL_Divergence = 3.876753\n",
      "Epoch: 4\tFidelity = 0.500433\tKL_Divergence = 4.069131\n",
      "Epoch: 5\tFidelity = 0.500422\tKL_Divergence = 4.083617\n",
      "Epoch: 6\tFidelity = 0.500460\tKL_Divergence = 4.035599\n",
      "Epoch: 7\tFidelity = 0.500504\tKL_Divergence = 3.985192\n",
      "Epoch: 8\tFidelity = 0.500515\tKL_Divergence = 3.972747\n",
      "Epoch: 9\tFidelity = 0.500400\tKL_Divergence = 4.112051\n",
      "Epoch: 10\tFidelity = 0.500573\tKL_Divergence = 3.913589\n",
      "Epoch: 11\tFidelity = 0.500393\tKL_Divergence = 4.123171\n",
      "Epoch: 12\tFidelity = 0.500441\tKL_Divergence = 4.058833\n",
      "Epoch: 13\tFidelity = 0.500516\tKL_Divergence = 3.970404\n",
      "Epoch: 14\tFidelity = 0.500588\tKL_Divergence = 3.898861\n",
      "Epoch: 15\tFidelity = 0.500432\tKL_Divergence = 4.070432\n",
      "Epoch: 16\tFidelity = 0.500498\tKL_Divergence = 3.991515\n",
      "Epoch: 17\tFidelity = 0.500471\tKL_Divergence = 4.022088\n",
      "Epoch: 18\tFidelity = 0.500633\tKL_Divergence = 3.858298\n",
      "Epoch: 19\tFidelity = 0.500442\tKL_Divergence = 4.056960\n",
      "Epoch: 20\tFidelity = 0.500495\tKL_Divergence = 3.994750\n",
      "Epoch: 21\tFidelity = 0.500470\tKL_Divergence = 4.022787\n",
      "Epoch: 22\tFidelity = 0.500520\tKL_Divergence = 3.966413\n",
      "Epoch: 23\tFidelity = 0.500451\tKL_Divergence = 4.045921\n",
      "Epoch: 24\tFidelity = 0.500423\tKL_Divergence = 4.080430\n",
      "Epoch: 25\tFidelity = 0.500563\tKL_Divergence = 3.923369\n",
      "Epoch: 26\tFidelity = 0.500558\tKL_Divergence = 3.928125\n",
      "Epoch: 27\tFidelity = 0.500477\tKL_Divergence = 4.015530\n",
      "Epoch: 28\tFidelity = 0.500533\tKL_Divergence = 3.953001\n",
      "Epoch: 29\tFidelity = 0.500515\tKL_Divergence = 3.972362\n",
      "Epoch: 30\tFidelity = 0.500379\tKL_Divergence = 4.142874\n",
      "Epoch: 31\tFidelity = 0.500450\tKL_Divergence = 4.047538\n",
      "Epoch: 32\tFidelity = 0.500532\tKL_Divergence = 3.954226\n",
      "Epoch: 33\tFidelity = 0.500437\tKL_Divergence = 4.063217\n",
      "Epoch: 34\tFidelity = 0.500593\tKL_Divergence = 3.894914\n",
      "Epoch: 35\tFidelity = 0.500392\tKL_Divergence = 4.123735\n",
      "Epoch: 36\tFidelity = 0.500504\tKL_Divergence = 3.984787\n",
      "Epoch: 37\tFidelity = 0.500623\tKL_Divergence = 3.867446\n",
      "Epoch: 38\tFidelity = 0.500406\tKL_Divergence = 4.104664\n",
      "Epoch: 39\tFidelity = 0.500633\tKL_Divergence = 3.858024\n",
      "Epoch: 40\tFidelity = 0.500586\tKL_Divergence = 3.901028\n",
      "Epoch: 41\tFidelity = 0.500471\tKL_Divergence = 4.021846\n",
      "Epoch: 42\tFidelity = 0.500528\tKL_Divergence = 3.958397\n",
      "Epoch: 43\tFidelity = 0.500479\tKL_Divergence = 4.012405\n",
      "Epoch: 44\tFidelity = 0.500446\tKL_Divergence = 4.051871\n",
      "Epoch: 45\tFidelity = 0.500554\tKL_Divergence = 3.932152\n",
      "Epoch: 46\tFidelity = 0.500549\tKL_Divergence = 3.936483\n",
      "Epoch: 47\tFidelity = 0.500432\tKL_Divergence = 4.069937\n",
      "Epoch: 48\tFidelity = 0.500481\tKL_Divergence = 4.009955\n",
      "Epoch: 49\tFidelity = 0.500529\tKL_Divergence = 3.958279\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:58:03,281] Trial 411 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500542\tKL_Divergence = 3.944673\n",
      "Total time elapsed during training: 45.806 s\n",
      "Trial 411 pruned. \n",
      "Epoch: 1\tFidelity = 0.500537\tKL_Divergence = 3.949193\n",
      "Epoch: 2\tFidelity = 0.500421\tKL_Divergence = 4.085154\n",
      "Epoch: 3\tFidelity = 0.500482\tKL_Divergence = 4.008996\n",
      "Epoch: 4\tFidelity = 0.500419\tKL_Divergence = 4.087923\n",
      "Epoch: 5\tFidelity = 0.500490\tKL_Divergence = 4.000207\n",
      "Epoch: 6\tFidelity = 0.500510\tKL_Divergence = 3.977959\n",
      "Epoch: 7\tFidelity = 0.500420\tKL_Divergence = 4.086153\n",
      "Epoch: 8\tFidelity = 0.500513\tKL_Divergence = 3.975396\n",
      "Epoch: 9\tFidelity = 0.500477\tKL_Divergence = 4.015175\n",
      "Epoch: 10\tFidelity = 0.500544\tKL_Divergence = 3.942825\n",
      "Epoch: 11\tFidelity = 0.500550\tKL_Divergence = 3.936217\n",
      "Epoch: 12\tFidelity = 0.500536\tKL_Divergence = 3.950287\n",
      "Epoch: 13\tFidelity = 0.500560\tKL_Divergence = 3.926611\n",
      "Epoch: 14\tFidelity = 0.500480\tKL_Divergence = 4.011836\n",
      "Epoch: 15\tFidelity = 0.500471\tKL_Divergence = 4.022847\n",
      "Epoch: 16\tFidelity = 0.500514\tKL_Divergence = 3.973946\n",
      "Epoch: 17\tFidelity = 0.500554\tKL_Divergence = 3.931836\n",
      "Epoch: 18\tFidelity = 0.500546\tKL_Divergence = 3.939950\n",
      "Epoch: 19\tFidelity = 0.500520\tKL_Divergence = 3.967150\n",
      "Epoch: 20\tFidelity = 0.500445\tKL_Divergence = 4.053891\n",
      "Epoch: 21\tFidelity = 0.500519\tKL_Divergence = 3.968594\n",
      "Epoch: 22\tFidelity = 0.500476\tKL_Divergence = 4.016008\n",
      "Epoch: 23\tFidelity = 0.500517\tKL_Divergence = 3.970611\n",
      "Epoch: 24\tFidelity = 0.500430\tKL_Divergence = 4.073013\n",
      "Epoch: 25\tFidelity = 0.500492\tKL_Divergence = 3.998448\n",
      "Epoch: 26\tFidelity = 0.500460\tKL_Divergence = 4.035066\n",
      "Epoch: 27\tFidelity = 0.500469\tKL_Divergence = 4.025213\n",
      "Epoch: 28\tFidelity = 0.500471\tKL_Divergence = 4.022716\n",
      "Epoch: 29\tFidelity = 0.500475\tKL_Divergence = 4.017922\n",
      "Epoch: 30\tFidelity = 0.500486\tKL_Divergence = 4.004742\n",
      "Epoch: 31\tFidelity = 0.500500\tKL_Divergence = 3.989078\n",
      "Epoch: 32\tFidelity = 0.500612\tKL_Divergence = 3.876532\n",
      "Epoch: 33\tFidelity = 0.500551\tKL_Divergence = 3.934801\n",
      "Epoch: 34\tFidelity = 0.500528\tKL_Divergence = 3.959123\n",
      "Epoch: 35\tFidelity = 0.500526\tKL_Divergence = 3.960624\n",
      "Epoch: 36\tFidelity = 0.500600\tKL_Divergence = 3.887775\n",
      "Epoch: 37\tFidelity = 0.500587\tKL_Divergence = 3.900100\n",
      "Epoch: 38\tFidelity = 0.500496\tKL_Divergence = 3.993528\n",
      "Epoch: 39\tFidelity = 0.500453\tKL_Divergence = 4.043513\n",
      "Epoch: 40\tFidelity = 0.500477\tKL_Divergence = 4.015738\n",
      "Epoch: 41\tFidelity = 0.500485\tKL_Divergence = 4.005605\n",
      "Epoch: 42\tFidelity = 0.500455\tKL_Divergence = 4.042016\n",
      "Epoch: 43\tFidelity = 0.500541\tKL_Divergence = 3.945090\n",
      "Epoch: 44\tFidelity = 0.500563\tKL_Divergence = 3.923417\n",
      "Epoch: 45\tFidelity = 0.500551\tKL_Divergence = 3.935699\n",
      "Epoch: 46\tFidelity = 0.500572\tKL_Divergence = 3.914252\n",
      "Epoch: 47\tFidelity = 0.500549\tKL_Divergence = 3.937198\n",
      "Epoch: 48\tFidelity = 0.500532\tKL_Divergence = 3.955060\n",
      "Epoch: 49\tFidelity = 0.500452\tKL_Divergence = 4.044679\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 08:58:49,644] Trial 412 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500449\tKL_Divergence = 4.048963\n",
      "Total time elapsed during training: 46.182 s\n",
      "Trial 412 pruned. \n",
      "Epoch: 1\tFidelity = 0.500513\tKL_Divergence = 3.975321\n",
      "Epoch: 2\tFidelity = 0.500513\tKL_Divergence = 3.974851\n",
      "Epoch: 3\tFidelity = 0.500488\tKL_Divergence = 4.002300\n",
      "Epoch: 4\tFidelity = 0.500499\tKL_Divergence = 3.990466\n",
      "Epoch: 5\tFidelity = 0.500442\tKL_Divergence = 4.057927\n",
      "Epoch: 6\tFidelity = 0.500498\tKL_Divergence = 3.991612\n",
      "Epoch: 7\tFidelity = 0.500418\tKL_Divergence = 4.088943\n",
      "Epoch: 8\tFidelity = 0.500518\tKL_Divergence = 3.969805\n",
      "Epoch: 9\tFidelity = 0.500441\tKL_Divergence = 4.058553\n",
      "Epoch: 10\tFidelity = 0.500479\tKL_Divergence = 4.012706\n",
      "Epoch: 11\tFidelity = 0.500497\tKL_Divergence = 3.992737\n",
      "Epoch: 12\tFidelity = 0.500606\tKL_Divergence = 3.882720\n",
      "Epoch: 13\tFidelity = 0.500521\tKL_Divergence = 3.966802\n",
      "Epoch: 14\tFidelity = 0.500409\tKL_Divergence = 4.100647\n",
      "Epoch: 15\tFidelity = 0.500393\tKL_Divergence = 4.123429\n",
      "Epoch: 16\tFidelity = 0.500654\tKL_Divergence = 3.840234\n",
      "Epoch: 17\tFidelity = 0.500542\tKL_Divergence = 3.944824\n",
      "Epoch: 18\tFidelity = 0.500504\tKL_Divergence = 3.984911\n",
      "Epoch: 19\tFidelity = 0.500490\tKL_Divergence = 4.000020\n",
      "Epoch: 20\tFidelity = 0.500393\tKL_Divergence = 4.122552\n",
      "Epoch: 21\tFidelity = 0.500483\tKL_Divergence = 4.008608\n",
      "Epoch: 22\tFidelity = 0.500423\tKL_Divergence = 4.082139\n",
      "Epoch: 23\tFidelity = 0.500475\tKL_Divergence = 4.017555\n",
      "Epoch: 24\tFidelity = 0.500490\tKL_Divergence = 4.000082\n",
      "Epoch: 25\tFidelity = 0.500499\tKL_Divergence = 3.990333\n",
      "Epoch: 26\tFidelity = 0.500505\tKL_Divergence = 3.983848\n",
      "Epoch: 27\tFidelity = 0.500502\tKL_Divergence = 3.986837\n",
      "Epoch: 28\tFidelity = 0.500551\tKL_Divergence = 3.935151\n",
      "Epoch: 29\tFidelity = 0.500513\tKL_Divergence = 3.974679\n",
      "Epoch: 30\tFidelity = 0.500503\tKL_Divergence = 3.985583\n",
      "Epoch: 31\tFidelity = 0.500518\tKL_Divergence = 3.970063\n",
      "Epoch: 32\tFidelity = 0.500455\tKL_Divergence = 4.041022\n",
      "Epoch: 33\tFidelity = 0.500462\tKL_Divergence = 4.033420\n",
      "Epoch: 34\tFidelity = 0.500546\tKL_Divergence = 3.940875\n",
      "Epoch: 35\tFidelity = 0.500432\tKL_Divergence = 4.070642\n",
      "Epoch: 36\tFidelity = 0.500407\tKL_Divergence = 4.103397\n",
      "Epoch: 37\tFidelity = 0.500464\tKL_Divergence = 4.030422\n",
      "Epoch: 38\tFidelity = 0.500432\tKL_Divergence = 4.069899\n",
      "Epoch: 39\tFidelity = 0.500525\tKL_Divergence = 3.961854\n",
      "Epoch: 40\tFidelity = 0.500536\tKL_Divergence = 3.950980\n",
      "Epoch: 41\tFidelity = 0.500484\tKL_Divergence = 4.007158\n",
      "Epoch: 42\tFidelity = 0.500455\tKL_Divergence = 4.041781\n",
      "Epoch: 43\tFidelity = 0.500483\tKL_Divergence = 4.008574\n",
      "Epoch: 44\tFidelity = 0.500457\tKL_Divergence = 4.038820\n",
      "Epoch: 45\tFidelity = 0.500558\tKL_Divergence = 3.928697\n",
      "Epoch: 46\tFidelity = 0.500503\tKL_Divergence = 3.985582\n",
      "Epoch: 47\tFidelity = 0.500563\tKL_Divergence = 3.923607\n",
      "Epoch: 48\tFidelity = 0.500473\tKL_Divergence = 4.020459\n",
      "Epoch: 49\tFidelity = 0.500455\tKL_Divergence = 4.041429\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:00:12,980] Trial 413 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500458\tKL_Divergence = 4.038547\n",
      "Total time elapsed during training: 83.152 s\n",
      "Trial 413 pruned. \n",
      "Epoch: 1\tFidelity = 0.500570\tKL_Divergence = 3.916413\n",
      "Epoch: 2\tFidelity = 0.500444\tKL_Divergence = 4.055026\n",
      "Epoch: 3\tFidelity = 0.500528\tKL_Divergence = 3.958420\n",
      "Epoch: 4\tFidelity = 0.500531\tKL_Divergence = 3.954780\n",
      "Epoch: 5\tFidelity = 0.500427\tKL_Divergence = 4.076186\n",
      "Epoch: 6\tFidelity = 0.500518\tKL_Divergence = 3.968635\n",
      "Epoch: 7\tFidelity = 0.500504\tKL_Divergence = 3.984619\n",
      "Epoch: 8\tFidelity = 0.500425\tKL_Divergence = 4.078628\n",
      "Epoch: 9\tFidelity = 0.500421\tKL_Divergence = 4.083557\n",
      "Epoch: 10\tFidelity = 0.500415\tKL_Divergence = 4.091642\n",
      "Epoch: 11\tFidelity = 0.500481\tKL_Divergence = 4.010007\n",
      "Epoch: 12\tFidelity = 0.500505\tKL_Divergence = 3.982705\n",
      "Epoch: 13\tFidelity = 0.500490\tKL_Divergence = 3.999697\n",
      "Epoch: 14\tFidelity = 0.500480\tKL_Divergence = 4.011350\n",
      "Epoch: 15\tFidelity = 0.500567\tKL_Divergence = 3.918679\n",
      "Epoch: 16\tFidelity = 0.500519\tKL_Divergence = 3.967696\n",
      "Epoch: 17\tFidelity = 0.500526\tKL_Divergence = 3.960484\n",
      "Epoch: 18\tFidelity = 0.500530\tKL_Divergence = 3.955968\n",
      "Epoch: 19\tFidelity = 0.500518\tKL_Divergence = 3.968484\n",
      "Epoch: 20\tFidelity = 0.500417\tKL_Divergence = 4.089062\n",
      "Epoch: 21\tFidelity = 0.500399\tKL_Divergence = 4.113580\n",
      "Epoch: 22\tFidelity = 0.500436\tKL_Divergence = 4.065053\n",
      "Epoch: 23\tFidelity = 0.500422\tKL_Divergence = 4.083118\n",
      "Epoch: 24\tFidelity = 0.500563\tKL_Divergence = 3.922487\n",
      "Epoch: 25\tFidelity = 0.500494\tKL_Divergence = 3.995430\n",
      "Epoch: 26\tFidelity = 0.500513\tKL_Divergence = 3.974805\n",
      "Epoch: 27\tFidelity = 0.500519\tKL_Divergence = 3.968465\n",
      "Epoch: 28\tFidelity = 0.500445\tKL_Divergence = 4.054427\n",
      "Epoch: 29\tFidelity = 0.500445\tKL_Divergence = 4.053519\n",
      "Epoch: 30\tFidelity = 0.500461\tKL_Divergence = 4.034320\n",
      "Epoch: 31\tFidelity = 0.500447\tKL_Divergence = 4.051193\n",
      "Epoch: 32\tFidelity = 0.500455\tKL_Divergence = 4.041108\n",
      "Epoch: 33\tFidelity = 0.500512\tKL_Divergence = 3.975778\n",
      "Epoch: 34\tFidelity = 0.500394\tKL_Divergence = 4.121311\n",
      "Epoch: 35\tFidelity = 0.500496\tKL_Divergence = 3.993295\n",
      "Epoch: 36\tFidelity = 0.500464\tKL_Divergence = 4.030385\n",
      "Epoch: 37\tFidelity = 0.500577\tKL_Divergence = 3.909552\n",
      "Epoch: 38\tFidelity = 0.500541\tKL_Divergence = 3.944894\n",
      "Epoch: 39\tFidelity = 0.500437\tKL_Divergence = 4.063839\n",
      "Epoch: 40\tFidelity = 0.500435\tKL_Divergence = 4.066247\n",
      "Epoch: 41\tFidelity = 0.500423\tKL_Divergence = 4.081436\n",
      "Epoch: 42\tFidelity = 0.500479\tKL_Divergence = 4.012994\n",
      "Epoch: 43\tFidelity = 0.500435\tKL_Divergence = 4.065974\n",
      "Epoch: 44\tFidelity = 0.500472\tKL_Divergence = 4.020509\n",
      "Epoch: 45\tFidelity = 0.500468\tKL_Divergence = 4.025581\n",
      "Epoch: 46\tFidelity = 0.500446\tKL_Divergence = 4.052825\n",
      "Epoch: 47\tFidelity = 0.500463\tKL_Divergence = 4.031471\n",
      "Epoch: 48\tFidelity = 0.500437\tKL_Divergence = 4.063351\n",
      "Epoch: 49\tFidelity = 0.500487\tKL_Divergence = 4.003977\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:00:51,685] Trial 414 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500499\tKL_Divergence = 3.990807\n",
      "Total time elapsed during training: 38.524 s\n",
      "Trial 414 pruned. \n",
      "Epoch: 1\tFidelity = 0.500502\tKL_Divergence = 3.987084\n",
      "Epoch: 2\tFidelity = 0.500479\tKL_Divergence = 4.012686\n",
      "Epoch: 3\tFidelity = 0.500471\tKL_Divergence = 4.022724\n",
      "Epoch: 4\tFidelity = 0.500450\tKL_Divergence = 4.047718\n",
      "Epoch: 5\tFidelity = 0.500450\tKL_Divergence = 4.047792\n",
      "Epoch: 6\tFidelity = 0.500448\tKL_Divergence = 4.049959\n",
      "Epoch: 7\tFidelity = 0.500461\tKL_Divergence = 4.033945\n",
      "Epoch: 8\tFidelity = 0.500471\tKL_Divergence = 4.022427\n",
      "Epoch: 9\tFidelity = 0.500448\tKL_Divergence = 4.049780\n",
      "Epoch: 10\tFidelity = 0.500431\tKL_Divergence = 4.071926\n",
      "Epoch: 11\tFidelity = 0.500451\tKL_Divergence = 4.046467\n",
      "Epoch: 12\tFidelity = 0.500446\tKL_Divergence = 4.052377\n",
      "Epoch: 13\tFidelity = 0.500463\tKL_Divergence = 4.032393\n",
      "Epoch: 14\tFidelity = 0.500462\tKL_Divergence = 4.032987\n",
      "Epoch: 15\tFidelity = 0.500476\tKL_Divergence = 4.017058\n",
      "Epoch: 16\tFidelity = 0.500450\tKL_Divergence = 4.048162\n",
      "Epoch: 17\tFidelity = 0.500453\tKL_Divergence = 4.043661\n",
      "Epoch: 18\tFidelity = 0.500487\tKL_Divergence = 4.003458\n",
      "Epoch: 19\tFidelity = 0.500472\tKL_Divergence = 4.021675\n",
      "Epoch: 20\tFidelity = 0.500456\tKL_Divergence = 4.040168\n",
      "Epoch: 21\tFidelity = 0.500468\tKL_Divergence = 4.025348\n",
      "Epoch: 22\tFidelity = 0.500443\tKL_Divergence = 4.055891\n",
      "Epoch: 23\tFidelity = 0.500413\tKL_Divergence = 4.095207\n",
      "Epoch: 24\tFidelity = 0.500476\tKL_Divergence = 4.016391\n",
      "Epoch: 25\tFidelity = 0.500462\tKL_Divergence = 4.033485\n",
      "Epoch: 26\tFidelity = 0.500457\tKL_Divergence = 4.039406\n",
      "Epoch: 27\tFidelity = 0.500463\tKL_Divergence = 4.032027\n",
      "Epoch: 28\tFidelity = 0.500442\tKL_Divergence = 4.058152\n",
      "Epoch: 29\tFidelity = 0.500490\tKL_Divergence = 4.000085\n",
      "Epoch: 30\tFidelity = 0.500452\tKL_Divergence = 4.045819\n",
      "Epoch: 31\tFidelity = 0.500502\tKL_Divergence = 3.987159\n",
      "Epoch: 32\tFidelity = 0.500471\tKL_Divergence = 4.022818\n",
      "Epoch: 33\tFidelity = 0.500477\tKL_Divergence = 4.015097\n",
      "Epoch: 34\tFidelity = 0.500484\tKL_Divergence = 4.006887\n",
      "Epoch: 35\tFidelity = 0.500503\tKL_Divergence = 3.986347\n",
      "Epoch: 36\tFidelity = 0.500449\tKL_Divergence = 4.048977\n",
      "Epoch: 37\tFidelity = 0.500451\tKL_Divergence = 4.045899\n",
      "Epoch: 38\tFidelity = 0.500475\tKL_Divergence = 4.017564\n",
      "Epoch: 39\tFidelity = 0.500493\tKL_Divergence = 3.997143\n",
      "Epoch: 40\tFidelity = 0.500490\tKL_Divergence = 4.000728\n",
      "Epoch: 41\tFidelity = 0.500453\tKL_Divergence = 4.044237\n",
      "Epoch: 42\tFidelity = 0.500455\tKL_Divergence = 4.042009\n",
      "Epoch: 43\tFidelity = 0.500468\tKL_Divergence = 4.026372\n",
      "Epoch: 44\tFidelity = 0.500499\tKL_Divergence = 3.990435\n",
      "Epoch: 45\tFidelity = 0.500478\tKL_Divergence = 4.014141\n",
      "Epoch: 46\tFidelity = 0.500486\tKL_Divergence = 4.004757\n",
      "Epoch: 47\tFidelity = 0.500498\tKL_Divergence = 3.991148\n",
      "Epoch: 48\tFidelity = 0.500478\tKL_Divergence = 4.013757\n",
      "Epoch: 49\tFidelity = 0.500480\tKL_Divergence = 4.011747\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:01:31,274] Trial 415 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500490\tKL_Divergence = 4.000113\n",
      "Total time elapsed during training: 39.416 s\n",
      "Trial 415 pruned. \n",
      "Epoch: 1\tFidelity = 0.500441\tKL_Divergence = 4.059331\n",
      "Epoch: 2\tFidelity = 0.500440\tKL_Divergence = 4.060475\n",
      "Epoch: 3\tFidelity = 0.500401\tKL_Divergence = 4.111676\n",
      "Epoch: 4\tFidelity = 0.500466\tKL_Divergence = 4.028505\n",
      "Epoch: 5\tFidelity = 0.500436\tKL_Divergence = 4.065471\n",
      "Epoch: 6\tFidelity = 0.500483\tKL_Divergence = 4.008243\n",
      "Epoch: 7\tFidelity = 0.500586\tKL_Divergence = 3.901023\n",
      "Epoch: 8\tFidelity = 0.500459\tKL_Divergence = 4.036416\n",
      "Epoch: 9\tFidelity = 0.500516\tKL_Divergence = 3.971929\n",
      "Epoch: 10\tFidelity = 0.500478\tKL_Divergence = 4.013754\n",
      "Epoch: 11\tFidelity = 0.500474\tKL_Divergence = 4.018920\n",
      "Epoch: 12\tFidelity = 0.500504\tKL_Divergence = 3.984512\n",
      "Epoch: 13\tFidelity = 0.500477\tKL_Divergence = 4.015333\n",
      "Epoch: 14\tFidelity = 0.500477\tKL_Divergence = 4.015731\n",
      "Epoch: 15\tFidelity = 0.500472\tKL_Divergence = 4.021437\n",
      "Epoch: 16\tFidelity = 0.500590\tKL_Divergence = 3.897111\n",
      "Epoch: 17\tFidelity = 0.500475\tKL_Divergence = 4.018031\n",
      "Epoch: 18\tFidelity = 0.500480\tKL_Divergence = 4.011500\n",
      "Epoch: 19\tFidelity = 0.500421\tKL_Divergence = 4.084909\n",
      "Epoch: 20\tFidelity = 0.500499\tKL_Divergence = 3.990091\n",
      "Epoch: 21\tFidelity = 0.500502\tKL_Divergence = 3.986434\n",
      "Epoch: 22\tFidelity = 0.500530\tKL_Divergence = 3.957198\n",
      "Epoch: 23\tFidelity = 0.500399\tKL_Divergence = 4.114492\n",
      "Epoch: 24\tFidelity = 0.500428\tKL_Divergence = 4.076043\n",
      "Epoch: 25\tFidelity = 0.500484\tKL_Divergence = 4.007088\n",
      "Epoch: 26\tFidelity = 0.500481\tKL_Divergence = 4.011047\n",
      "Epoch: 27\tFidelity = 0.500439\tKL_Divergence = 4.061582\n",
      "Epoch: 28\tFidelity = 0.500343\tKL_Divergence = 4.197741\n",
      "Epoch: 29\tFidelity = 0.500469\tKL_Divergence = 4.024248\n",
      "Epoch: 30\tFidelity = 0.500480\tKL_Divergence = 4.012307\n",
      "Epoch: 31\tFidelity = 0.500579\tKL_Divergence = 3.907594\n",
      "Epoch: 32\tFidelity = 0.500533\tKL_Divergence = 3.953462\n",
      "Epoch: 33\tFidelity = 0.500439\tKL_Divergence = 4.061259\n",
      "Epoch: 34\tFidelity = 0.500526\tKL_Divergence = 3.961000\n",
      "Epoch: 35\tFidelity = 0.500577\tKL_Divergence = 3.909527\n",
      "Epoch: 36\tFidelity = 0.500571\tKL_Divergence = 3.915122\n",
      "Epoch: 37\tFidelity = 0.500542\tKL_Divergence = 3.943927\n",
      "Epoch: 38\tFidelity = 0.500527\tKL_Divergence = 3.959561\n",
      "Epoch: 39\tFidelity = 0.500526\tKL_Divergence = 3.960865\n",
      "Epoch: 40\tFidelity = 0.500407\tKL_Divergence = 4.103530\n",
      "Epoch: 41\tFidelity = 0.500462\tKL_Divergence = 4.032902\n",
      "Epoch: 42\tFidelity = 0.500504\tKL_Divergence = 3.984352\n",
      "Epoch: 43\tFidelity = 0.500427\tKL_Divergence = 4.076159\n",
      "Epoch: 44\tFidelity = 0.500528\tKL_Divergence = 3.958383\n",
      "Epoch: 45\tFidelity = 0.500671\tKL_Divergence = 3.825925\n",
      "Epoch: 46\tFidelity = 0.500515\tKL_Divergence = 3.972959\n",
      "Epoch: 47\tFidelity = 0.500479\tKL_Divergence = 4.012512\n",
      "Epoch: 48\tFidelity = 0.500523\tKL_Divergence = 3.963665\n",
      "Epoch: 49\tFidelity = 0.500510\tKL_Divergence = 3.977657\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:02:10,824] Trial 416 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500526\tKL_Divergence = 3.961091\n",
      "Total time elapsed during training: 39.356 s\n",
      "Trial 416 pruned. \n",
      "Epoch: 1\tFidelity = 0.500512\tKL_Divergence = 3.975417\n",
      "Epoch: 2\tFidelity = 0.500470\tKL_Divergence = 4.023152\n",
      "Epoch: 3\tFidelity = 0.500519\tKL_Divergence = 3.967908\n",
      "Epoch: 4\tFidelity = 0.500472\tKL_Divergence = 4.020731\n",
      "Epoch: 5\tFidelity = 0.500548\tKL_Divergence = 3.937782\n",
      "Epoch: 6\tFidelity = 0.500480\tKL_Divergence = 4.011548\n",
      "Epoch: 7\tFidelity = 0.500523\tKL_Divergence = 3.964152\n",
      "Epoch: 8\tFidelity = 0.500541\tKL_Divergence = 3.945101\n",
      "Epoch: 9\tFidelity = 0.500497\tKL_Divergence = 3.992307\n",
      "Epoch: 10\tFidelity = 0.500457\tKL_Divergence = 4.038471\n",
      "Epoch: 11\tFidelity = 0.500498\tKL_Divergence = 3.990769\n",
      "Epoch: 12\tFidelity = 0.500523\tKL_Divergence = 3.964502\n",
      "Epoch: 13\tFidelity = 0.500506\tKL_Divergence = 3.982398\n",
      "Epoch: 14\tFidelity = 0.500502\tKL_Divergence = 3.987257\n",
      "Epoch: 15\tFidelity = 0.500522\tKL_Divergence = 3.965410\n",
      "Epoch: 16\tFidelity = 0.500521\tKL_Divergence = 3.966545\n",
      "Epoch: 17\tFidelity = 0.500491\tKL_Divergence = 3.999308\n",
      "Epoch: 18\tFidelity = 0.500490\tKL_Divergence = 3.999916\n",
      "Epoch: 19\tFidelity = 0.500541\tKL_Divergence = 3.945311\n",
      "Epoch: 20\tFidelity = 0.500511\tKL_Divergence = 3.977247\n",
      "Epoch: 21\tFidelity = 0.500513\tKL_Divergence = 3.974490\n",
      "Epoch: 22\tFidelity = 0.500524\tKL_Divergence = 3.963280\n",
      "Epoch: 23\tFidelity = 0.500479\tKL_Divergence = 4.012425\n",
      "Epoch: 24\tFidelity = 0.500456\tKL_Divergence = 4.039963\n",
      "Epoch: 25\tFidelity = 0.500533\tKL_Divergence = 3.953857\n",
      "Epoch: 26\tFidelity = 0.500494\tKL_Divergence = 3.995714\n",
      "Epoch: 27\tFidelity = 0.500491\tKL_Divergence = 3.999579\n",
      "Epoch: 28\tFidelity = 0.500490\tKL_Divergence = 4.000745\n",
      "Epoch: 29\tFidelity = 0.500535\tKL_Divergence = 3.951105\n",
      "Epoch: 30\tFidelity = 0.500509\tKL_Divergence = 3.978745\n",
      "Epoch: 31\tFidelity = 0.500460\tKL_Divergence = 4.035315\n",
      "Epoch: 32\tFidelity = 0.500507\tKL_Divergence = 3.981778\n",
      "Epoch: 33\tFidelity = 0.500519\tKL_Divergence = 3.968381\n",
      "Epoch: 34\tFidelity = 0.500524\tKL_Divergence = 3.963101\n",
      "Epoch: 35\tFidelity = 0.500497\tKL_Divergence = 3.992598\n",
      "Epoch: 36\tFidelity = 0.500505\tKL_Divergence = 3.983637\n",
      "Epoch: 37\tFidelity = 0.500553\tKL_Divergence = 3.932944\n",
      "Epoch: 38\tFidelity = 0.500515\tKL_Divergence = 3.972730\n",
      "Epoch: 39\tFidelity = 0.500480\tKL_Divergence = 4.011541\n",
      "Epoch: 40\tFidelity = 0.500530\tKL_Divergence = 3.956720\n",
      "Epoch: 41\tFidelity = 0.500472\tKL_Divergence = 4.020725\n",
      "Epoch: 42\tFidelity = 0.500555\tKL_Divergence = 3.931189\n",
      "Epoch: 43\tFidelity = 0.500490\tKL_Divergence = 3.999775\n",
      "Epoch: 44\tFidelity = 0.500498\tKL_Divergence = 3.991458\n",
      "Epoch: 45\tFidelity = 0.500476\tKL_Divergence = 4.016640\n",
      "Epoch: 46\tFidelity = 0.500527\tKL_Divergence = 3.959582\n",
      "Epoch: 47\tFidelity = 0.500504\tKL_Divergence = 3.984388\n",
      "Epoch: 48\tFidelity = 0.500544\tKL_Divergence = 3.942301\n",
      "Epoch: 49\tFidelity = 0.500479\tKL_Divergence = 4.012854\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:02:43,552] Trial 417 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500540\tKL_Divergence = 3.946025\n",
      "Total time elapsed during training: 32.548 s\n",
      "Trial 417 pruned. \n",
      "Epoch: 1\tFidelity = 0.500550\tKL_Divergence = 3.936244\n",
      "Epoch: 2\tFidelity = 0.500529\tKL_Divergence = 3.957869\n",
      "Epoch: 3\tFidelity = 0.500452\tKL_Divergence = 4.045406\n",
      "Epoch: 4\tFidelity = 0.500507\tKL_Divergence = 3.981513\n",
      "Epoch: 5\tFidelity = 0.500488\tKL_Divergence = 4.002021\n",
      "Epoch: 6\tFidelity = 0.500454\tKL_Divergence = 4.043078\n",
      "Epoch: 7\tFidelity = 0.500540\tKL_Divergence = 3.945988\n",
      "Epoch: 8\tFidelity = 0.500488\tKL_Divergence = 4.002633\n",
      "Epoch: 9\tFidelity = 0.500497\tKL_Divergence = 3.992107\n",
      "Epoch: 10\tFidelity = 0.500473\tKL_Divergence = 4.019376\n",
      "Epoch: 11\tFidelity = 0.500505\tKL_Divergence = 3.983339\n",
      "Epoch: 12\tFidelity = 0.500457\tKL_Divergence = 4.038711\n",
      "Epoch: 13\tFidelity = 0.500475\tKL_Divergence = 4.017652\n",
      "Epoch: 14\tFidelity = 0.500491\tKL_Divergence = 3.999575\n",
      "Epoch: 15\tFidelity = 0.500497\tKL_Divergence = 3.992876\n",
      "Epoch: 16\tFidelity = 0.500527\tKL_Divergence = 3.960291\n",
      "Epoch: 17\tFidelity = 0.500566\tKL_Divergence = 3.920445\n",
      "Epoch: 18\tFidelity = 0.500495\tKL_Divergence = 3.994915\n",
      "Epoch: 19\tFidelity = 0.500477\tKL_Divergence = 4.014925\n",
      "Epoch: 20\tFidelity = 0.500567\tKL_Divergence = 3.919767\n",
      "Epoch: 21\tFidelity = 0.500478\tKL_Divergence = 4.013698\n",
      "Epoch: 22\tFidelity = 0.500482\tKL_Divergence = 4.008860\n",
      "Epoch: 23\tFidelity = 0.500517\tKL_Divergence = 3.970118\n",
      "Epoch: 24\tFidelity = 0.500499\tKL_Divergence = 3.990746\n",
      "Epoch: 25\tFidelity = 0.500470\tKL_Divergence = 4.023703\n",
      "Epoch: 26\tFidelity = 0.500508\tKL_Divergence = 3.979765\n",
      "Epoch: 27\tFidelity = 0.500603\tKL_Divergence = 3.885216\n",
      "Epoch: 28\tFidelity = 0.500506\tKL_Divergence = 3.982003\n",
      "Epoch: 29\tFidelity = 0.500515\tKL_Divergence = 3.972973\n",
      "Epoch: 30\tFidelity = 0.500486\tKL_Divergence = 4.004666\n",
      "Epoch: 31\tFidelity = 0.500490\tKL_Divergence = 4.000786\n",
      "Epoch: 32\tFidelity = 0.500532\tKL_Divergence = 3.955266\n",
      "Epoch: 33\tFidelity = 0.500474\tKL_Divergence = 4.018626\n",
      "Epoch: 34\tFidelity = 0.500476\tKL_Divergence = 4.016705\n",
      "Epoch: 35\tFidelity = 0.500464\tKL_Divergence = 4.030332\n",
      "Epoch: 36\tFidelity = 0.500477\tKL_Divergence = 4.014906\n",
      "Epoch: 37\tFidelity = 0.500486\tKL_Divergence = 4.005427\n",
      "Epoch: 38\tFidelity = 0.500556\tKL_Divergence = 3.930058\n",
      "Epoch: 39\tFidelity = 0.500514\tKL_Divergence = 3.973967\n",
      "Epoch: 40\tFidelity = 0.500490\tKL_Divergence = 4.000252\n",
      "Epoch: 41\tFidelity = 0.500479\tKL_Divergence = 4.012470\n",
      "Epoch: 42\tFidelity = 0.500464\tKL_Divergence = 4.030136\n",
      "Epoch: 43\tFidelity = 0.500465\tKL_Divergence = 4.029726\n",
      "Epoch: 44\tFidelity = 0.500500\tKL_Divergence = 3.988652\n",
      "Epoch: 45\tFidelity = 0.500439\tKL_Divergence = 4.060918\n",
      "Epoch: 46\tFidelity = 0.500564\tKL_Divergence = 3.922395\n",
      "Epoch: 47\tFidelity = 0.500473\tKL_Divergence = 4.019576\n",
      "Epoch: 48\tFidelity = 0.500481\tKL_Divergence = 4.011176\n",
      "Epoch: 49\tFidelity = 0.500465\tKL_Divergence = 4.028835\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:04:05,278] Trial 418 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500477\tKL_Divergence = 4.014747\n",
      "Total time elapsed during training: 81.552 s\n",
      "Trial 418 pruned. \n",
      "Epoch: 1\tFidelity = 0.500564\tKL_Divergence = 3.922163\n",
      "Epoch: 2\tFidelity = 0.500414\tKL_Divergence = 4.093637\n",
      "Epoch: 3\tFidelity = 0.500493\tKL_Divergence = 3.997412\n",
      "Epoch: 4\tFidelity = 0.500579\tKL_Divergence = 3.907499\n",
      "Epoch: 5\tFidelity = 0.500436\tKL_Divergence = 4.064927\n",
      "Epoch: 6\tFidelity = 0.500488\tKL_Divergence = 4.002122\n",
      "Epoch: 7\tFidelity = 0.500563\tKL_Divergence = 3.923149\n",
      "Epoch: 8\tFidelity = 0.500507\tKL_Divergence = 3.981338\n",
      "Epoch: 9\tFidelity = 0.500586\tKL_Divergence = 3.900827\n",
      "Epoch: 10\tFidelity = 0.500509\tKL_Divergence = 3.977806\n",
      "Epoch: 11\tFidelity = 0.500530\tKL_Divergence = 3.956683\n",
      "Epoch: 12\tFidelity = 0.500428\tKL_Divergence = 4.075708\n",
      "Epoch: 13\tFidelity = 0.500555\tKL_Divergence = 3.930965\n",
      "Epoch: 14\tFidelity = 0.500497\tKL_Divergence = 3.991914\n",
      "Epoch: 15\tFidelity = 0.500447\tKL_Divergence = 4.051165\n",
      "Epoch: 16\tFidelity = 0.500548\tKL_Divergence = 3.937891\n",
      "Epoch: 17\tFidelity = 0.500473\tKL_Divergence = 4.019546\n",
      "Epoch: 18\tFidelity = 0.500445\tKL_Divergence = 4.053385\n",
      "Epoch: 19\tFidelity = 0.500449\tKL_Divergence = 4.048405\n",
      "Epoch: 20\tFidelity = 0.500628\tKL_Divergence = 3.862538\n",
      "Epoch: 21\tFidelity = 0.500542\tKL_Divergence = 3.944109\n",
      "Epoch: 22\tFidelity = 0.500522\tKL_Divergence = 3.964762\n",
      "Epoch: 23\tFidelity = 0.500409\tKL_Divergence = 4.100062\n",
      "Epoch: 24\tFidelity = 0.500577\tKL_Divergence = 3.909358\n",
      "Epoch: 25\tFidelity = 0.500467\tKL_Divergence = 4.026847\n",
      "Epoch: 26\tFidelity = 0.500504\tKL_Divergence = 3.984269\n",
      "Epoch: 27\tFidelity = 0.500412\tKL_Divergence = 4.096149\n",
      "Epoch: 28\tFidelity = 0.500592\tKL_Divergence = 3.895688\n",
      "Epoch: 29\tFidelity = 0.500543\tKL_Divergence = 3.943123\n",
      "Epoch: 30\tFidelity = 0.500483\tKL_Divergence = 4.007887\n",
      "Epoch: 31\tFidelity = 0.500554\tKL_Divergence = 3.931806\n",
      "Epoch: 32\tFidelity = 0.500564\tKL_Divergence = 3.922564\n",
      "Epoch: 33\tFidelity = 0.500514\tKL_Divergence = 3.974050\n",
      "Epoch: 34\tFidelity = 0.500476\tKL_Divergence = 4.016714\n",
      "Epoch: 35\tFidelity = 0.500491\tKL_Divergence = 3.999610\n",
      "Epoch: 36\tFidelity = 0.500511\tKL_Divergence = 3.977104\n",
      "Epoch: 37\tFidelity = 0.500373\tKL_Divergence = 4.152091\n",
      "Epoch: 38\tFidelity = 0.500517\tKL_Divergence = 3.970318\n",
      "Epoch: 39\tFidelity = 0.500439\tKL_Divergence = 4.061395\n",
      "Epoch: 40\tFidelity = 0.500417\tKL_Divergence = 4.089515\n",
      "Epoch: 41\tFidelity = 0.500434\tKL_Divergence = 4.066665\n",
      "Epoch: 42\tFidelity = 0.500415\tKL_Divergence = 4.092065\n",
      "Epoch: 43\tFidelity = 0.500531\tKL_Divergence = 3.955913\n",
      "Epoch: 44\tFidelity = 0.500395\tKL_Divergence = 4.119327\n",
      "Epoch: 45\tFidelity = 0.500460\tKL_Divergence = 4.035140\n",
      "Epoch: 46\tFidelity = 0.500601\tKL_Divergence = 3.887407\n",
      "Epoch: 47\tFidelity = 0.500449\tKL_Divergence = 4.049340\n",
      "Epoch: 48\tFidelity = 0.500409\tKL_Divergence = 4.100280\n",
      "Epoch: 49\tFidelity = 0.500443\tKL_Divergence = 4.055642\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:05:04,169] Trial 419 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500493\tKL_Divergence = 3.996193\n",
      "Total time elapsed during training: 58.718 s\n",
      "Trial 419 pruned. \n",
      "Epoch: 1\tFidelity = 0.500503\tKL_Divergence = 3.985379\n",
      "Epoch: 2\tFidelity = 0.500478\tKL_Divergence = 4.014132\n",
      "Epoch: 3\tFidelity = 0.500500\tKL_Divergence = 3.988210\n",
      "Epoch: 4\tFidelity = 0.500461\tKL_Divergence = 4.033296\n",
      "Epoch: 5\tFidelity = 0.500490\tKL_Divergence = 3.999578\n",
      "Epoch: 6\tFidelity = 0.500477\tKL_Divergence = 4.014921\n",
      "Epoch: 7\tFidelity = 0.500485\tKL_Divergence = 4.005031\n",
      "Epoch: 8\tFidelity = 0.500475\tKL_Divergence = 4.016762\n",
      "Epoch: 9\tFidelity = 0.500456\tKL_Divergence = 4.039800\n",
      "Epoch: 10\tFidelity = 0.500479\tKL_Divergence = 4.012045\n",
      "Epoch: 11\tFidelity = 0.500516\tKL_Divergence = 3.971211\n",
      "Epoch: 12\tFidelity = 0.500459\tKL_Divergence = 4.036471\n",
      "Epoch: 13\tFidelity = 0.500502\tKL_Divergence = 3.986269\n",
      "Epoch: 14\tFidelity = 0.500458\tKL_Divergence = 4.037893\n",
      "Epoch: 15\tFidelity = 0.500506\tKL_Divergence = 3.981796\n",
      "Epoch: 16\tFidelity = 0.500511\tKL_Divergence = 3.976650\n",
      "Epoch: 17\tFidelity = 0.500506\tKL_Divergence = 3.982358\n",
      "Epoch: 18\tFidelity = 0.500487\tKL_Divergence = 4.003706\n",
      "Epoch: 19\tFidelity = 0.500518\tKL_Divergence = 3.968678\n",
      "Epoch: 20\tFidelity = 0.500479\tKL_Divergence = 4.012968\n",
      "Epoch: 21\tFidelity = 0.500511\tKL_Divergence = 3.976571\n",
      "Epoch: 22\tFidelity = 0.500501\tKL_Divergence = 3.987840\n",
      "Epoch: 23\tFidelity = 0.500489\tKL_Divergence = 4.001725\n",
      "Epoch: 24\tFidelity = 0.500475\tKL_Divergence = 4.017538\n",
      "Epoch: 25\tFidelity = 0.500484\tKL_Divergence = 4.006557\n",
      "Epoch: 26\tFidelity = 0.500474\tKL_Divergence = 4.018743\n",
      "Epoch: 27\tFidelity = 0.500464\tKL_Divergence = 4.030287\n",
      "Epoch: 28\tFidelity = 0.500484\tKL_Divergence = 4.006472\n",
      "Epoch: 29\tFidelity = 0.500475\tKL_Divergence = 4.016942\n",
      "Epoch: 30\tFidelity = 0.500461\tKL_Divergence = 4.034059\n",
      "Epoch: 31\tFidelity = 0.500465\tKL_Divergence = 4.028629\n",
      "Epoch: 32\tFidelity = 0.500473\tKL_Divergence = 4.019738\n",
      "Epoch: 33\tFidelity = 0.500463\tKL_Divergence = 4.031214\n",
      "Epoch: 34\tFidelity = 0.500491\tKL_Divergence = 3.999400\n",
      "Epoch: 35\tFidelity = 0.500467\tKL_Divergence = 4.026456\n",
      "Epoch: 36\tFidelity = 0.500501\tKL_Divergence = 3.987999\n",
      "Epoch: 37\tFidelity = 0.500465\tKL_Divergence = 4.029737\n",
      "Epoch: 38\tFidelity = 0.500472\tKL_Divergence = 4.020914\n",
      "Epoch: 39\tFidelity = 0.500485\tKL_Divergence = 4.005658\n",
      "Epoch: 40\tFidelity = 0.500476\tKL_Divergence = 4.015929\n",
      "Epoch: 41\tFidelity = 0.500463\tKL_Divergence = 4.031595\n",
      "Epoch: 42\tFidelity = 0.500475\tKL_Divergence = 4.017250\n",
      "Epoch: 43\tFidelity = 0.500494\tKL_Divergence = 3.995489\n",
      "Epoch: 44\tFidelity = 0.500458\tKL_Divergence = 4.038244\n",
      "Epoch: 45\tFidelity = 0.500505\tKL_Divergence = 3.983846\n",
      "Epoch: 46\tFidelity = 0.500451\tKL_Divergence = 4.045883\n",
      "Epoch: 47\tFidelity = 0.500487\tKL_Divergence = 4.003953\n",
      "Epoch: 48\tFidelity = 0.500529\tKL_Divergence = 3.957594\n",
      "Epoch: 49\tFidelity = 0.500475\tKL_Divergence = 4.017422\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:05:36,973] Trial 420 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500515\tKL_Divergence = 3.972594\n",
      "Total time elapsed during training: 32.625 s\n",
      "Trial 420 pruned. \n",
      "Epoch: 1\tFidelity = 0.500542\tKL_Divergence = 3.944004\n",
      "Epoch: 2\tFidelity = 0.500570\tKL_Divergence = 3.916302\n",
      "Epoch: 3\tFidelity = 0.500439\tKL_Divergence = 4.061237\n",
      "Epoch: 4\tFidelity = 0.500588\tKL_Divergence = 3.899095\n",
      "Epoch: 5\tFidelity = 0.500572\tKL_Divergence = 3.914330\n",
      "Epoch: 6\tFidelity = 0.500388\tKL_Divergence = 4.129776\n",
      "Epoch: 7\tFidelity = 0.500369\tKL_Divergence = 4.157798\n",
      "Epoch: 8\tFidelity = 0.500630\tKL_Divergence = 3.860545\n",
      "Epoch: 9\tFidelity = 0.500398\tKL_Divergence = 4.114776\n",
      "Epoch: 10\tFidelity = 0.500466\tKL_Divergence = 4.027440\n",
      "Epoch: 11\tFidelity = 0.500565\tKL_Divergence = 3.920494\n",
      "Epoch: 12\tFidelity = 0.500468\tKL_Divergence = 4.023412\n",
      "Epoch: 13\tFidelity = 0.500388\tKL_Divergence = 4.128960\n",
      "Epoch: 14\tFidelity = 0.500413\tKL_Divergence = 4.092791\n",
      "Epoch: 15\tFidelity = 0.500437\tKL_Divergence = 4.061745\n",
      "Epoch: 16\tFidelity = 0.500576\tKL_Divergence = 3.907673\n",
      "Epoch: 17\tFidelity = 0.500445\tKL_Divergence = 4.051374\n",
      "Epoch: 18\tFidelity = 0.500475\tKL_Divergence = 4.015090\n",
      "Epoch: 19\tFidelity = 0.500410\tKL_Divergence = 4.097901\n",
      "Epoch: 20\tFidelity = 0.500390\tKL_Divergence = 4.126606\n",
      "Epoch: 21\tFidelity = 0.500406\tKL_Divergence = 4.104909\n",
      "Epoch: 22\tFidelity = 0.500422\tKL_Divergence = 4.083118\n",
      "Epoch: 23\tFidelity = 0.500506\tKL_Divergence = 3.982280\n",
      "Epoch: 24\tFidelity = 0.500516\tKL_Divergence = 3.971239\n",
      "Epoch: 25\tFidelity = 0.500455\tKL_Divergence = 4.041393\n",
      "Epoch: 26\tFidelity = 0.500437\tKL_Divergence = 4.063764\n",
      "Epoch: 27\tFidelity = 0.500417\tKL_Divergence = 4.089990\n",
      "Epoch: 28\tFidelity = 0.500572\tKL_Divergence = 3.913938\n",
      "Epoch: 29\tFidelity = 0.500561\tKL_Divergence = 3.924676\n",
      "Epoch: 30\tFidelity = 0.500473\tKL_Divergence = 4.019338\n",
      "Epoch: 31\tFidelity = 0.500381\tKL_Divergence = 4.140194\n",
      "Epoch: 32\tFidelity = 0.500570\tKL_Divergence = 3.916110\n",
      "Epoch: 33\tFidelity = 0.500561\tKL_Divergence = 3.924725\n",
      "Epoch: 34\tFidelity = 0.500514\tKL_Divergence = 3.972956\n",
      "Epoch: 35\tFidelity = 0.500561\tKL_Divergence = 3.924934\n",
      "Epoch: 36\tFidelity = 0.500458\tKL_Divergence = 4.037803\n",
      "Epoch: 37\tFidelity = 0.500512\tKL_Divergence = 3.975715\n",
      "Epoch: 38\tFidelity = 0.500517\tKL_Divergence = 3.970590\n",
      "Epoch: 39\tFidelity = 0.500392\tKL_Divergence = 4.124147\n",
      "Epoch: 40\tFidelity = 0.500560\tKL_Divergence = 3.925862\n",
      "Epoch: 41\tFidelity = 0.500481\tKL_Divergence = 4.010782\n",
      "Epoch: 42\tFidelity = 0.500475\tKL_Divergence = 4.017784\n",
      "Epoch: 43\tFidelity = 0.500479\tKL_Divergence = 4.013152\n",
      "Epoch: 44\tFidelity = 0.500439\tKL_Divergence = 4.060905\n",
      "Epoch: 45\tFidelity = 0.500434\tKL_Divergence = 4.067378\n",
      "Epoch: 46\tFidelity = 0.500494\tKL_Divergence = 3.995264\n",
      "Epoch: 47\tFidelity = 0.500516\tKL_Divergence = 3.970780\n",
      "Epoch: 48\tFidelity = 0.500377\tKL_Divergence = 4.145370\n",
      "Epoch: 49\tFidelity = 0.500437\tKL_Divergence = 4.063416\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:06:15,942] Trial 421 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500446\tKL_Divergence = 4.052735\n",
      "Total time elapsed during training: 38.797 s\n",
      "Trial 421 pruned. \n",
      "Epoch: 1\tFidelity = 0.500466\tKL_Divergence = 4.027616\n",
      "Epoch: 2\tFidelity = 0.500479\tKL_Divergence = 4.012455\n",
      "Epoch: 3\tFidelity = 0.500501\tKL_Divergence = 3.988126\n",
      "Epoch: 4\tFidelity = 0.500535\tKL_Divergence = 3.951308\n",
      "Epoch: 5\tFidelity = 0.500492\tKL_Divergence = 3.998175\n",
      "Epoch: 6\tFidelity = 0.500501\tKL_Divergence = 3.988364\n",
      "Epoch: 7\tFidelity = 0.500557\tKL_Divergence = 3.928889\n",
      "Epoch: 8\tFidelity = 0.500496\tKL_Divergence = 3.993425\n",
      "Epoch: 9\tFidelity = 0.500540\tKL_Divergence = 3.946761\n",
      "Epoch: 10\tFidelity = 0.500502\tKL_Divergence = 3.986473\n",
      "Epoch: 11\tFidelity = 0.500509\tKL_Divergence = 3.979503\n",
      "Epoch: 12\tFidelity = 0.500487\tKL_Divergence = 4.003892\n",
      "Epoch: 13\tFidelity = 0.500495\tKL_Divergence = 3.994631\n",
      "Epoch: 14\tFidelity = 0.500473\tKL_Divergence = 4.020072\n",
      "Epoch: 15\tFidelity = 0.500517\tKL_Divergence = 3.970214\n",
      "Epoch: 16\tFidelity = 0.500480\tKL_Divergence = 4.011304\n",
      "Epoch: 17\tFidelity = 0.500475\tKL_Divergence = 4.017859\n",
      "Epoch: 18\tFidelity = 0.500494\tKL_Divergence = 3.995272\n",
      "Epoch: 19\tFidelity = 0.500482\tKL_Divergence = 4.008842\n",
      "Epoch: 20\tFidelity = 0.500520\tKL_Divergence = 3.967477\n",
      "Epoch: 21\tFidelity = 0.500518\tKL_Divergence = 3.969395\n",
      "Epoch: 22\tFidelity = 0.500449\tKL_Divergence = 4.048247\n",
      "Epoch: 23\tFidelity = 0.500509\tKL_Divergence = 3.979278\n",
      "Epoch: 24\tFidelity = 0.500544\tKL_Divergence = 3.942056\n",
      "Epoch: 25\tFidelity = 0.500507\tKL_Divergence = 3.980866\n",
      "Epoch: 26\tFidelity = 0.500476\tKL_Divergence = 4.015965\n",
      "Epoch: 27\tFidelity = 0.500492\tKL_Divergence = 3.997649\n",
      "Epoch: 28\tFidelity = 0.500523\tKL_Divergence = 3.963703\n",
      "Epoch: 29\tFidelity = 0.500453\tKL_Divergence = 4.043275\n",
      "Epoch: 30\tFidelity = 0.500532\tKL_Divergence = 3.954735\n",
      "Epoch: 31\tFidelity = 0.500510\tKL_Divergence = 3.978497\n",
      "Epoch: 32\tFidelity = 0.500502\tKL_Divergence = 3.986715\n",
      "Epoch: 33\tFidelity = 0.500501\tKL_Divergence = 3.987834\n",
      "Epoch: 34\tFidelity = 0.500526\tKL_Divergence = 3.961380\n",
      "Epoch: 35\tFidelity = 0.500517\tKL_Divergence = 3.970019\n",
      "Epoch: 36\tFidelity = 0.500555\tKL_Divergence = 3.930859\n",
      "Epoch: 37\tFidelity = 0.500540\tKL_Divergence = 3.946397\n",
      "Epoch: 38\tFidelity = 0.500500\tKL_Divergence = 3.989006\n",
      "Epoch: 39\tFidelity = 0.500520\tKL_Divergence = 3.966969\n",
      "Epoch: 40\tFidelity = 0.500538\tKL_Divergence = 3.948573\n",
      "Epoch: 41\tFidelity = 0.500548\tKL_Divergence = 3.937694\n",
      "Epoch: 42\tFidelity = 0.500498\tKL_Divergence = 3.991425\n",
      "Epoch: 43\tFidelity = 0.500459\tKL_Divergence = 4.036283\n",
      "Epoch: 44\tFidelity = 0.500448\tKL_Divergence = 4.050221\n",
      "Epoch: 45\tFidelity = 0.500535\tKL_Divergence = 3.951471\n",
      "Epoch: 46\tFidelity = 0.500538\tKL_Divergence = 3.948337\n",
      "Epoch: 47\tFidelity = 0.500507\tKL_Divergence = 3.981079\n",
      "Epoch: 48\tFidelity = 0.500580\tKL_Divergence = 3.907135\n",
      "Epoch: 49\tFidelity = 0.500496\tKL_Divergence = 3.993455\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:07:01,560] Trial 422 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500502\tKL_Divergence = 3.986334\n",
      "Total time elapsed during training: 45.445 s\n",
      "Trial 422 pruned. \n",
      "Epoch: 1\tFidelity = 0.500470\tKL_Divergence = 4.022782\n",
      "Epoch: 2\tFidelity = 0.500583\tKL_Divergence = 3.903504\n",
      "Epoch: 3\tFidelity = 0.500534\tKL_Divergence = 3.952468\n",
      "Epoch: 4\tFidelity = 0.500475\tKL_Divergence = 4.017266\n",
      "Epoch: 5\tFidelity = 0.500486\tKL_Divergence = 4.004371\n",
      "Epoch: 6\tFidelity = 0.500504\tKL_Divergence = 3.984490\n",
      "Epoch: 7\tFidelity = 0.500454\tKL_Divergence = 4.042238\n",
      "Epoch: 8\tFidelity = 0.500424\tKL_Divergence = 4.080725\n",
      "Epoch: 9\tFidelity = 0.500439\tKL_Divergence = 4.060781\n",
      "Epoch: 10\tFidelity = 0.500469\tKL_Divergence = 4.024411\n",
      "Epoch: 11\tFidelity = 0.500459\tKL_Divergence = 4.036522\n",
      "Epoch: 12\tFidelity = 0.500540\tKL_Divergence = 3.945835\n",
      "Epoch: 13\tFidelity = 0.500559\tKL_Divergence = 3.926909\n",
      "Epoch: 14\tFidelity = 0.500469\tKL_Divergence = 4.024186\n",
      "Epoch: 15\tFidelity = 0.500536\tKL_Divergence = 3.950443\n",
      "Epoch: 16\tFidelity = 0.500566\tKL_Divergence = 3.920366\n",
      "Epoch: 17\tFidelity = 0.500480\tKL_Divergence = 4.012171\n",
      "Epoch: 18\tFidelity = 0.500447\tKL_Divergence = 4.051132\n",
      "Epoch: 19\tFidelity = 0.500500\tKL_Divergence = 3.988722\n",
      "Epoch: 20\tFidelity = 0.500563\tKL_Divergence = 3.923268\n",
      "Epoch: 21\tFidelity = 0.500534\tKL_Divergence = 3.952394\n",
      "Epoch: 22\tFidelity = 0.500545\tKL_Divergence = 3.941093\n",
      "Epoch: 23\tFidelity = 0.500493\tKL_Divergence = 3.997389\n",
      "Epoch: 24\tFidelity = 0.500487\tKL_Divergence = 4.004098\n",
      "Epoch: 25\tFidelity = 0.500563\tKL_Divergence = 3.923385\n",
      "Epoch: 26\tFidelity = 0.500455\tKL_Divergence = 4.041149\n",
      "Epoch: 27\tFidelity = 0.500551\tKL_Divergence = 3.934835\n",
      "Epoch: 28\tFidelity = 0.500569\tKL_Divergence = 3.917226\n",
      "Epoch: 29\tFidelity = 0.500485\tKL_Divergence = 4.005844\n",
      "Epoch: 30\tFidelity = 0.500510\tKL_Divergence = 3.977862\n",
      "Epoch: 31\tFidelity = 0.500451\tKL_Divergence = 4.045899\n",
      "Epoch: 32\tFidelity = 0.500494\tKL_Divergence = 3.995994\n",
      "Epoch: 33\tFidelity = 0.500582\tKL_Divergence = 3.904748\n",
      "Epoch: 34\tFidelity = 0.500464\tKL_Divergence = 4.030089\n",
      "Epoch: 35\tFidelity = 0.500545\tKL_Divergence = 3.941166\n",
      "Epoch: 36\tFidelity = 0.500484\tKL_Divergence = 4.006607\n",
      "Epoch: 37\tFidelity = 0.500412\tKL_Divergence = 4.096071\n",
      "Epoch: 38\tFidelity = 0.500442\tKL_Divergence = 4.057913\n",
      "Epoch: 39\tFidelity = 0.500540\tKL_Divergence = 3.946552\n",
      "Epoch: 40\tFidelity = 0.500519\tKL_Divergence = 3.968123\n",
      "Epoch: 41\tFidelity = 0.500490\tKL_Divergence = 4.000115\n",
      "Epoch: 42\tFidelity = 0.500543\tKL_Divergence = 3.943433\n",
      "Epoch: 43\tFidelity = 0.500499\tKL_Divergence = 3.990097\n",
      "Epoch: 44\tFidelity = 0.500561\tKL_Divergence = 3.925142\n",
      "Epoch: 45\tFidelity = 0.500630\tKL_Divergence = 3.860549\n",
      "Epoch: 46\tFidelity = 0.500517\tKL_Divergence = 3.969741\n",
      "Epoch: 47\tFidelity = 0.500589\tKL_Divergence = 3.897635\n",
      "Epoch: 48\tFidelity = 0.500557\tKL_Divergence = 3.928991\n",
      "Epoch: 49\tFidelity = 0.500590\tKL_Divergence = 3.897379\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:07:40,250] Trial 423 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500541\tKL_Divergence = 3.944777\n",
      "Total time elapsed during training: 38.520 s\n",
      "Trial 423 pruned. \n",
      "Epoch: 1\tFidelity = 0.500536\tKL_Divergence = 3.950089\n",
      "Epoch: 2\tFidelity = 0.500501\tKL_Divergence = 3.987500\n",
      "Epoch: 3\tFidelity = 0.500533\tKL_Divergence = 3.953031\n",
      "Epoch: 4\tFidelity = 0.500549\tKL_Divergence = 3.937168\n",
      "Epoch: 5\tFidelity = 0.500509\tKL_Divergence = 3.979492\n",
      "Epoch: 6\tFidelity = 0.500583\tKL_Divergence = 3.904116\n",
      "Epoch: 7\tFidelity = 0.500565\tKL_Divergence = 3.920747\n",
      "Epoch: 8\tFidelity = 0.500563\tKL_Divergence = 3.922759\n",
      "Epoch: 9\tFidelity = 0.500554\tKL_Divergence = 3.931729\n",
      "Epoch: 10\tFidelity = 0.500504\tKL_Divergence = 3.984546\n",
      "Epoch: 11\tFidelity = 0.500506\tKL_Divergence = 3.982808\n",
      "Epoch: 12\tFidelity = 0.500508\tKL_Divergence = 3.979737\n",
      "Epoch: 13\tFidelity = 0.500575\tKL_Divergence = 3.911089\n",
      "Epoch: 14\tFidelity = 0.500564\tKL_Divergence = 3.922483\n",
      "Epoch: 15\tFidelity = 0.500523\tKL_Divergence = 3.964065\n",
      "Epoch: 16\tFidelity = 0.500560\tKL_Divergence = 3.926086\n",
      "Epoch: 17\tFidelity = 0.500496\tKL_Divergence = 3.993323\n",
      "Epoch: 18\tFidelity = 0.500520\tKL_Divergence = 3.967113\n",
      "Epoch: 19\tFidelity = 0.500546\tKL_Divergence = 3.940504\n",
      "Epoch: 20\tFidelity = 0.500531\tKL_Divergence = 3.955162\n",
      "Epoch: 21\tFidelity = 0.500548\tKL_Divergence = 3.937691\n",
      "Epoch: 22\tFidelity = 0.500575\tKL_Divergence = 3.911402\n",
      "Epoch: 23\tFidelity = 0.500543\tKL_Divergence = 3.942939\n",
      "Epoch: 24\tFidelity = 0.500544\tKL_Divergence = 3.941795\n",
      "Epoch: 25\tFidelity = 0.500542\tKL_Divergence = 3.944463\n",
      "Epoch: 26\tFidelity = 0.500586\tKL_Divergence = 3.901153\n",
      "Epoch: 27\tFidelity = 0.500518\tKL_Divergence = 3.968952\n",
      "Epoch: 28\tFidelity = 0.500554\tKL_Divergence = 3.931845\n",
      "Epoch: 29\tFidelity = 0.500503\tKL_Divergence = 3.985245\n",
      "Epoch: 30\tFidelity = 0.500425\tKL_Divergence = 4.078557\n",
      "Epoch: 31\tFidelity = 0.500513\tKL_Divergence = 3.974844\n",
      "Epoch: 32\tFidelity = 0.500586\tKL_Divergence = 3.901382\n",
      "Epoch: 33\tFidelity = 0.500540\tKL_Divergence = 3.946411\n",
      "Epoch: 34\tFidelity = 0.500516\tKL_Divergence = 3.971469\n",
      "Epoch: 35\tFidelity = 0.500543\tKL_Divergence = 3.942887\n",
      "Epoch: 36\tFidelity = 0.500536\tKL_Divergence = 3.949997\n",
      "Epoch: 37\tFidelity = 0.500499\tKL_Divergence = 3.990388\n",
      "Epoch: 38\tFidelity = 0.500550\tKL_Divergence = 3.935765\n",
      "Epoch: 39\tFidelity = 0.500513\tKL_Divergence = 3.974744\n",
      "Epoch: 40\tFidelity = 0.500554\tKL_Divergence = 3.932553\n",
      "Epoch: 41\tFidelity = 0.500514\tKL_Divergence = 3.973866\n",
      "Epoch: 42\tFidelity = 0.500566\tKL_Divergence = 3.920593\n",
      "Epoch: 43\tFidelity = 0.500527\tKL_Divergence = 3.959919\n",
      "Epoch: 44\tFidelity = 0.500537\tKL_Divergence = 3.949784\n",
      "Epoch: 45\tFidelity = 0.500534\tKL_Divergence = 3.952640\n",
      "Epoch: 46\tFidelity = 0.500498\tKL_Divergence = 3.990692\n",
      "Epoch: 47\tFidelity = 0.500482\tKL_Divergence = 4.008888\n",
      "Epoch: 48\tFidelity = 0.500518\tKL_Divergence = 3.969412\n",
      "Epoch: 49\tFidelity = 0.500483\tKL_Divergence = 4.007882\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:09:00,945] Trial 424 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500513\tKL_Divergence = 3.974853\n",
      "Total time elapsed during training: 80.522 s\n",
      "Trial 424 pruned. \n",
      "Epoch: 1\tFidelity = 0.500540\tKL_Divergence = 3.946310\n",
      "Epoch: 2\tFidelity = 0.500514\tKL_Divergence = 3.973276\n",
      "Epoch: 3\tFidelity = 0.500499\tKL_Divergence = 3.989903\n",
      "Epoch: 4\tFidelity = 0.500503\tKL_Divergence = 3.985640\n",
      "Epoch: 5\tFidelity = 0.500523\tKL_Divergence = 3.964591\n",
      "Epoch: 6\tFidelity = 0.500520\tKL_Divergence = 3.967665\n",
      "Epoch: 7\tFidelity = 0.500525\tKL_Divergence = 3.962179\n",
      "Epoch: 8\tFidelity = 0.500521\tKL_Divergence = 3.965946\n",
      "Epoch: 9\tFidelity = 0.500503\tKL_Divergence = 3.985866\n",
      "Epoch: 10\tFidelity = 0.500520\tKL_Divergence = 3.967541\n",
      "Epoch: 11\tFidelity = 0.500535\tKL_Divergence = 3.951563\n",
      "Epoch: 12\tFidelity = 0.500518\tKL_Divergence = 3.968917\n",
      "Epoch: 13\tFidelity = 0.500474\tKL_Divergence = 4.019182\n",
      "Epoch: 14\tFidelity = 0.500552\tKL_Divergence = 3.934140\n",
      "Epoch: 15\tFidelity = 0.500555\tKL_Divergence = 3.931147\n",
      "Epoch: 16\tFidelity = 0.500557\tKL_Divergence = 3.929434\n",
      "Epoch: 17\tFidelity = 0.500471\tKL_Divergence = 4.022286\n",
      "Epoch: 18\tFidelity = 0.500498\tKL_Divergence = 3.991053\n",
      "Epoch: 19\tFidelity = 0.500483\tKL_Divergence = 4.007990\n",
      "Epoch: 20\tFidelity = 0.500510\tKL_Divergence = 3.977711\n",
      "Epoch: 21\tFidelity = 0.500539\tKL_Divergence = 3.947166\n",
      "Epoch: 22\tFidelity = 0.500506\tKL_Divergence = 3.982853\n",
      "Epoch: 23\tFidelity = 0.500481\tKL_Divergence = 4.010685\n",
      "Epoch: 24\tFidelity = 0.500518\tKL_Divergence = 3.969324\n",
      "Epoch: 25\tFidelity = 0.500456\tKL_Divergence = 4.040709\n",
      "Epoch: 26\tFidelity = 0.500527\tKL_Divergence = 3.959975\n",
      "Epoch: 27\tFidelity = 0.500524\tKL_Divergence = 3.963306\n",
      "Epoch: 28\tFidelity = 0.500489\tKL_Divergence = 4.001374\n",
      "Epoch: 29\tFidelity = 0.500528\tKL_Divergence = 3.958586\n",
      "Epoch: 30\tFidelity = 0.500579\tKL_Divergence = 3.907332\n",
      "Epoch: 31\tFidelity = 0.500462\tKL_Divergence = 4.032508\n",
      "Epoch: 32\tFidelity = 0.500476\tKL_Divergence = 4.015953\n",
      "Epoch: 33\tFidelity = 0.500520\tKL_Divergence = 3.967060\n",
      "Epoch: 34\tFidelity = 0.500492\tKL_Divergence = 3.998535\n",
      "Epoch: 35\tFidelity = 0.500488\tKL_Divergence = 4.002167\n",
      "Epoch: 36\tFidelity = 0.500489\tKL_Divergence = 4.000987\n",
      "Epoch: 37\tFidelity = 0.500487\tKL_Divergence = 4.003516\n",
      "Epoch: 38\tFidelity = 0.500513\tKL_Divergence = 3.975223\n",
      "Epoch: 39\tFidelity = 0.500568\tKL_Divergence = 3.918510\n",
      "Epoch: 40\tFidelity = 0.500537\tKL_Divergence = 3.949372\n",
      "Epoch: 41\tFidelity = 0.500491\tKL_Divergence = 3.999123\n",
      "Epoch: 42\tFidelity = 0.500519\tKL_Divergence = 3.968823\n",
      "Epoch: 43\tFidelity = 0.500541\tKL_Divergence = 3.945215\n",
      "Epoch: 44\tFidelity = 0.500590\tKL_Divergence = 3.897362\n",
      "Epoch: 45\tFidelity = 0.500494\tKL_Divergence = 3.995664\n",
      "Epoch: 46\tFidelity = 0.500566\tKL_Divergence = 3.920458\n",
      "Epoch: 47\tFidelity = 0.500465\tKL_Divergence = 4.029720\n",
      "Epoch: 48\tFidelity = 0.500590\tKL_Divergence = 3.897422\n",
      "Epoch: 49\tFidelity = 0.500557\tKL_Divergence = 3.929404\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:09:40,090] Trial 425 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500513\tKL_Divergence = 3.974634\n",
      "Total time elapsed during training: 38.975 s\n",
      "Trial 425 pruned. \n",
      "Epoch: 1\tFidelity = 0.500572\tKL_Divergence = 3.914817\n",
      "Epoch: 2\tFidelity = 0.500540\tKL_Divergence = 3.946019\n",
      "Epoch: 3\tFidelity = 0.500507\tKL_Divergence = 3.981239\n",
      "Epoch: 4\tFidelity = 0.500585\tKL_Divergence = 3.901402\n",
      "Epoch: 5\tFidelity = 0.500628\tKL_Divergence = 3.860526\n",
      "Epoch: 6\tFidelity = 0.500478\tKL_Divergence = 4.011871\n",
      "Epoch: 7\tFidelity = 0.500536\tKL_Divergence = 3.947864\n",
      "Epoch: 8\tFidelity = 0.500448\tKL_Divergence = 4.047056\n",
      "Epoch: 9\tFidelity = 0.500514\tKL_Divergence = 3.971793\n",
      "Epoch: 10\tFidelity = 0.500470\tKL_Divergence = 4.020589\n",
      "Epoch: 11\tFidelity = 0.500425\tKL_Divergence = 4.074560\n",
      "Epoch: 12\tFidelity = 0.500476\tKL_Divergence = 4.013974\n",
      "Epoch: 13\tFidelity = 0.500428\tKL_Divergence = 4.072483\n",
      "Epoch: 14\tFidelity = 0.500459\tKL_Divergence = 4.034256\n",
      "Epoch: 15\tFidelity = 0.500596\tKL_Divergence = 3.890009\n",
      "Epoch: 16\tFidelity = 0.500531\tKL_Divergence = 3.955570\n",
      "Epoch: 17\tFidelity = 0.500439\tKL_Divergence = 4.061617\n",
      "Epoch: 18\tFidelity = 0.500518\tKL_Divergence = 3.969055\n",
      "Epoch: 19\tFidelity = 0.500493\tKL_Divergence = 3.996769\n",
      "Epoch: 20\tFidelity = 0.500480\tKL_Divergence = 4.011529\n",
      "Epoch: 21\tFidelity = 0.500572\tKL_Divergence = 3.914587\n",
      "Epoch: 22\tFidelity = 0.500636\tKL_Divergence = 3.855166\n",
      "Epoch: 23\tFidelity = 0.500479\tKL_Divergence = 4.012756\n",
      "Epoch: 24\tFidelity = 0.500543\tKL_Divergence = 3.943718\n",
      "Epoch: 25\tFidelity = 0.500576\tKL_Divergence = 3.910228\n",
      "Epoch: 26\tFidelity = 0.500484\tKL_Divergence = 4.006542\n",
      "Epoch: 27\tFidelity = 0.500569\tKL_Divergence = 3.916436\n",
      "Epoch: 28\tFidelity = 0.500598\tKL_Divergence = 3.889421\n",
      "Epoch: 29\tFidelity = 0.500462\tKL_Divergence = 4.031757\n",
      "Epoch: 30\tFidelity = 0.500531\tKL_Divergence = 3.954453\n",
      "Epoch: 31\tFidelity = 0.500454\tKL_Divergence = 4.041296\n",
      "Epoch: 32\tFidelity = 0.500579\tKL_Divergence = 3.907076\n",
      "Epoch: 33\tFidelity = 0.500618\tKL_Divergence = 3.871020\n",
      "Epoch: 34\tFidelity = 0.500441\tKL_Divergence = 4.058813\n",
      "Epoch: 35\tFidelity = 0.500525\tKL_Divergence = 3.962097\n",
      "Epoch: 36\tFidelity = 0.500456\tKL_Divergence = 4.039947\n",
      "Epoch: 37\tFidelity = 0.500487\tKL_Divergence = 4.003563\n",
      "Epoch: 38\tFidelity = 0.500517\tKL_Divergence = 3.970292\n",
      "Epoch: 39\tFidelity = 0.500556\tKL_Divergence = 3.929990\n",
      "Epoch: 40\tFidelity = 0.500492\tKL_Divergence = 3.998119\n",
      "Epoch: 41\tFidelity = 0.500624\tKL_Divergence = 3.866364\n",
      "Epoch: 42\tFidelity = 0.500549\tKL_Divergence = 3.937211\n",
      "Epoch: 43\tFidelity = 0.500561\tKL_Divergence = 3.925649\n",
      "Epoch: 44\tFidelity = 0.500495\tKL_Divergence = 3.994801\n",
      "Epoch: 45\tFidelity = 0.500579\tKL_Divergence = 3.907169\n",
      "Epoch: 46\tFidelity = 0.500427\tKL_Divergence = 4.076383\n",
      "Epoch: 47\tFidelity = 0.500575\tKL_Divergence = 3.911509\n",
      "Epoch: 48\tFidelity = 0.500486\tKL_Divergence = 4.004858\n",
      "Epoch: 49\tFidelity = 0.500541\tKL_Divergence = 3.945195\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:10:16,804] Trial 426 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500460\tKL_Divergence = 4.035499\n",
      "Total time elapsed during training: 36.539 s\n",
      "Trial 426 pruned. \n",
      "Epoch: 1\tFidelity = 0.500445\tKL_Divergence = 4.054150\n",
      "Epoch: 2\tFidelity = 0.500495\tKL_Divergence = 3.994865\n",
      "Epoch: 3\tFidelity = 0.500459\tKL_Divergence = 4.036104\n",
      "Epoch: 4\tFidelity = 0.500448\tKL_Divergence = 4.050150\n",
      "Epoch: 5\tFidelity = 0.500477\tKL_Divergence = 4.015519\n",
      "Epoch: 6\tFidelity = 0.500410\tKL_Divergence = 4.098615\n",
      "Epoch: 7\tFidelity = 0.500523\tKL_Divergence = 3.963793\n",
      "Epoch: 8\tFidelity = 0.500558\tKL_Divergence = 3.928151\n",
      "Epoch: 9\tFidelity = 0.500440\tKL_Divergence = 4.059969\n",
      "Epoch: 10\tFidelity = 0.500428\tKL_Divergence = 4.075011\n",
      "Epoch: 11\tFidelity = 0.500462\tKL_Divergence = 4.032428\n",
      "Epoch: 12\tFidelity = 0.500593\tKL_Divergence = 3.894939\n",
      "Epoch: 13\tFidelity = 0.500497\tKL_Divergence = 3.992825\n",
      "Epoch: 14\tFidelity = 0.500477\tKL_Divergence = 4.015356\n",
      "Epoch: 15\tFidelity = 0.500419\tKL_Divergence = 4.087781\n",
      "Epoch: 16\tFidelity = 0.500562\tKL_Divergence = 3.924254\n",
      "Epoch: 17\tFidelity = 0.500550\tKL_Divergence = 3.936068\n",
      "Epoch: 18\tFidelity = 0.500461\tKL_Divergence = 4.033502\n",
      "Epoch: 19\tFidelity = 0.500457\tKL_Divergence = 4.039153\n",
      "Epoch: 20\tFidelity = 0.500466\tKL_Divergence = 4.028394\n",
      "Epoch: 21\tFidelity = 0.500600\tKL_Divergence = 3.888150\n",
      "Epoch: 22\tFidelity = 0.500549\tKL_Divergence = 3.937250\n",
      "Epoch: 23\tFidelity = 0.500492\tKL_Divergence = 3.997699\n",
      "Epoch: 24\tFidelity = 0.500503\tKL_Divergence = 3.985879\n",
      "Epoch: 25\tFidelity = 0.500578\tKL_Divergence = 3.908487\n",
      "Epoch: 26\tFidelity = 0.500591\tKL_Divergence = 3.896327\n",
      "Epoch: 27\tFidelity = 0.500486\tKL_Divergence = 4.004970\n",
      "Epoch: 28\tFidelity = 0.500477\tKL_Divergence = 4.015468\n",
      "Epoch: 29\tFidelity = 0.500433\tKL_Divergence = 4.068819\n",
      "Epoch: 30\tFidelity = 0.500494\tKL_Divergence = 3.995846\n",
      "Epoch: 31\tFidelity = 0.500502\tKL_Divergence = 3.986104\n",
      "Epoch: 32\tFidelity = 0.500511\tKL_Divergence = 3.976724\n",
      "Epoch: 33\tFidelity = 0.500561\tKL_Divergence = 3.924849\n",
      "Epoch: 34\tFidelity = 0.500546\tKL_Divergence = 3.940196\n",
      "Epoch: 35\tFidelity = 0.500512\tKL_Divergence = 3.976117\n",
      "Epoch: 36\tFidelity = 0.500477\tKL_Divergence = 4.014720\n",
      "Epoch: 37\tFidelity = 0.500551\tKL_Divergence = 3.934905\n",
      "Epoch: 38\tFidelity = 0.500570\tKL_Divergence = 3.916127\n",
      "Epoch: 39\tFidelity = 0.500524\tKL_Divergence = 3.962893\n",
      "Epoch: 40\tFidelity = 0.500519\tKL_Divergence = 3.968027\n",
      "Epoch: 41\tFidelity = 0.500578\tKL_Divergence = 3.908423\n",
      "Epoch: 42\tFidelity = 0.500476\tKL_Divergence = 4.016160\n",
      "Epoch: 43\tFidelity = 0.500535\tKL_Divergence = 3.951585\n",
      "Epoch: 44\tFidelity = 0.500516\tKL_Divergence = 3.971659\n",
      "Epoch: 45\tFidelity = 0.500527\tKL_Divergence = 3.960273\n",
      "Epoch: 46\tFidelity = 0.500524\tKL_Divergence = 3.962842\n",
      "Epoch: 47\tFidelity = 0.500521\tKL_Divergence = 3.965864\n",
      "Epoch: 48\tFidelity = 0.500458\tKL_Divergence = 4.037679\n",
      "Epoch: 49\tFidelity = 0.500580\tKL_Divergence = 3.906557\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:11:00,249] Trial 427 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500484\tKL_Divergence = 4.006334\n",
      "Total time elapsed during training: 43.210 s\n",
      "Trial 427 pruned. \n",
      "Epoch: 1\tFidelity = 0.500527\tKL_Divergence = 3.960034\n",
      "Epoch: 2\tFidelity = 0.500548\tKL_Divergence = 3.937908\n",
      "Epoch: 3\tFidelity = 0.500483\tKL_Divergence = 4.007900\n",
      "Epoch: 4\tFidelity = 0.500620\tKL_Divergence = 3.869492\n",
      "Epoch: 5\tFidelity = 0.500475\tKL_Divergence = 4.017543\n",
      "Epoch: 6\tFidelity = 0.500544\tKL_Divergence = 3.941762\n",
      "Epoch: 7\tFidelity = 0.500484\tKL_Divergence = 4.007383\n",
      "Epoch: 8\tFidelity = 0.500508\tKL_Divergence = 3.980425\n",
      "Epoch: 9\tFidelity = 0.500447\tKL_Divergence = 4.051372\n",
      "Epoch: 10\tFidelity = 0.500487\tKL_Divergence = 4.002978\n",
      "Epoch: 11\tFidelity = 0.500504\tKL_Divergence = 3.984976\n",
      "Epoch: 12\tFidelity = 0.500502\tKL_Divergence = 3.986668\n",
      "Epoch: 13\tFidelity = 0.500575\tKL_Divergence = 3.911235\n",
      "Epoch: 14\tFidelity = 0.500598\tKL_Divergence = 3.889845\n",
      "Epoch: 15\tFidelity = 0.500506\tKL_Divergence = 3.982768\n",
      "Epoch: 16\tFidelity = 0.500508\tKL_Divergence = 3.979669\n",
      "Epoch: 17\tFidelity = 0.500605\tKL_Divergence = 3.883061\n",
      "Epoch: 18\tFidelity = 0.500523\tKL_Divergence = 3.963888\n",
      "Epoch: 19\tFidelity = 0.500469\tKL_Divergence = 4.024842\n",
      "Epoch: 20\tFidelity = 0.500539\tKL_Divergence = 3.947423\n",
      "Epoch: 21\tFidelity = 0.500459\tKL_Divergence = 4.036611\n",
      "Epoch: 22\tFidelity = 0.500473\tKL_Divergence = 4.020171\n",
      "Epoch: 23\tFidelity = 0.500504\tKL_Divergence = 3.985117\n",
      "Epoch: 24\tFidelity = 0.500503\tKL_Divergence = 3.985798\n",
      "Epoch: 25\tFidelity = 0.500489\tKL_Divergence = 4.001101\n",
      "Epoch: 26\tFidelity = 0.500506\tKL_Divergence = 3.982669\n",
      "Epoch: 27\tFidelity = 0.500514\tKL_Divergence = 3.974229\n",
      "Epoch: 28\tFidelity = 0.500511\tKL_Divergence = 3.976595\n",
      "Epoch: 29\tFidelity = 0.500521\tKL_Divergence = 3.966359\n",
      "Epoch: 30\tFidelity = 0.500486\tKL_Divergence = 4.004525\n",
      "Epoch: 31\tFidelity = 0.500432\tKL_Divergence = 4.070258\n",
      "Epoch: 32\tFidelity = 0.500506\tKL_Divergence = 3.981898\n",
      "Epoch: 33\tFidelity = 0.500553\tKL_Divergence = 3.932773\n",
      "Epoch: 34\tFidelity = 0.500501\tKL_Divergence = 3.988338\n",
      "Epoch: 35\tFidelity = 0.500592\tKL_Divergence = 3.895025\n",
      "Epoch: 36\tFidelity = 0.500552\tKL_Divergence = 3.934245\n",
      "Epoch: 37\tFidelity = 0.500487\tKL_Divergence = 4.003859\n",
      "Epoch: 38\tFidelity = 0.500505\tKL_Divergence = 3.983171\n",
      "Epoch: 39\tFidelity = 0.500550\tKL_Divergence = 3.935781\n",
      "Epoch: 40\tFidelity = 0.500587\tKL_Divergence = 3.900213\n",
      "Epoch: 41\tFidelity = 0.500488\tKL_Divergence = 4.002347\n",
      "Epoch: 42\tFidelity = 0.500566\tKL_Divergence = 3.920333\n",
      "Epoch: 43\tFidelity = 0.500500\tKL_Divergence = 3.988929\n",
      "Epoch: 44\tFidelity = 0.500542\tKL_Divergence = 3.944542\n",
      "Epoch: 45\tFidelity = 0.500508\tKL_Divergence = 3.980726\n",
      "Epoch: 46\tFidelity = 0.500543\tKL_Divergence = 3.942775\n",
      "Epoch: 47\tFidelity = 0.500572\tKL_Divergence = 3.914632\n",
      "Epoch: 48\tFidelity = 0.500584\tKL_Divergence = 3.903121\n",
      "Epoch: 49\tFidelity = 0.500474\tKL_Divergence = 4.019088\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:11:44,100] Trial 428 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500518\tKL_Divergence = 3.969759\n",
      "Total time elapsed during training: 43.682 s\n",
      "Trial 428 pruned. \n",
      "Epoch: 1\tFidelity = 0.500500\tKL_Divergence = 3.989078\n",
      "Epoch: 2\tFidelity = 0.500516\tKL_Divergence = 3.971838\n",
      "Epoch: 3\tFidelity = 0.500533\tKL_Divergence = 3.953304\n",
      "Epoch: 4\tFidelity = 0.500514\tKL_Divergence = 3.974098\n",
      "Epoch: 5\tFidelity = 0.500491\tKL_Divergence = 3.998813\n",
      "Epoch: 6\tFidelity = 0.500561\tKL_Divergence = 3.925137\n",
      "Epoch: 7\tFidelity = 0.500565\tKL_Divergence = 3.921042\n",
      "Epoch: 8\tFidelity = 0.500496\tKL_Divergence = 3.993713\n",
      "Epoch: 9\tFidelity = 0.500538\tKL_Divergence = 3.948758\n",
      "Epoch: 10\tFidelity = 0.500449\tKL_Divergence = 4.048712\n",
      "Epoch: 11\tFidelity = 0.500524\tKL_Divergence = 3.962544\n",
      "Epoch: 12\tFidelity = 0.500466\tKL_Divergence = 4.028042\n",
      "Epoch: 13\tFidelity = 0.500512\tKL_Divergence = 3.976149\n",
      "Epoch: 14\tFidelity = 0.500514\tKL_Divergence = 3.973758\n",
      "Epoch: 15\tFidelity = 0.500497\tKL_Divergence = 3.992794\n",
      "Epoch: 16\tFidelity = 0.500548\tKL_Divergence = 3.938077\n",
      "Epoch: 17\tFidelity = 0.500497\tKL_Divergence = 3.992631\n",
      "Epoch: 18\tFidelity = 0.500588\tKL_Divergence = 3.899041\n",
      "Epoch: 19\tFidelity = 0.500497\tKL_Divergence = 3.992975\n",
      "Epoch: 20\tFidelity = 0.500508\tKL_Divergence = 3.980259\n",
      "Epoch: 21\tFidelity = 0.500559\tKL_Divergence = 3.926844\n",
      "Epoch: 22\tFidelity = 0.500522\tKL_Divergence = 3.964858\n",
      "Epoch: 23\tFidelity = 0.500574\tKL_Divergence = 3.912586\n",
      "Epoch: 24\tFidelity = 0.500526\tKL_Divergence = 3.961401\n",
      "Epoch: 25\tFidelity = 0.500535\tKL_Divergence = 3.951406\n",
      "Epoch: 26\tFidelity = 0.500519\tKL_Divergence = 3.968243\n",
      "Epoch: 27\tFidelity = 0.500533\tKL_Divergence = 3.953697\n",
      "Epoch: 28\tFidelity = 0.500516\tKL_Divergence = 3.971239\n",
      "Epoch: 29\tFidelity = 0.500461\tKL_Divergence = 4.034057\n",
      "Epoch: 30\tFidelity = 0.500497\tKL_Divergence = 3.992543\n",
      "Epoch: 31\tFidelity = 0.500506\tKL_Divergence = 3.982151\n",
      "Epoch: 32\tFidelity = 0.500487\tKL_Divergence = 4.003412\n",
      "Epoch: 33\tFidelity = 0.500553\tKL_Divergence = 3.933116\n",
      "Epoch: 34\tFidelity = 0.500520\tKL_Divergence = 3.967104\n",
      "Epoch: 35\tFidelity = 0.500533\tKL_Divergence = 3.953972\n",
      "Epoch: 36\tFidelity = 0.500498\tKL_Divergence = 3.990846\n",
      "Epoch: 37\tFidelity = 0.500482\tKL_Divergence = 4.009181\n",
      "Epoch: 38\tFidelity = 0.500529\tKL_Divergence = 3.957549\n",
      "Epoch: 39\tFidelity = 0.500525\tKL_Divergence = 3.962280\n",
      "Epoch: 40\tFidelity = 0.500496\tKL_Divergence = 3.993626\n",
      "Epoch: 41\tFidelity = 0.500465\tKL_Divergence = 4.029373\n",
      "Epoch: 42\tFidelity = 0.500530\tKL_Divergence = 3.956582\n",
      "Epoch: 43\tFidelity = 0.500525\tKL_Divergence = 3.962392\n",
      "Epoch: 44\tFidelity = 0.500471\tKL_Divergence = 4.022725\n",
      "Epoch: 45\tFidelity = 0.500483\tKL_Divergence = 4.008036\n",
      "Epoch: 46\tFidelity = 0.500478\tKL_Divergence = 4.013559\n",
      "Epoch: 47\tFidelity = 0.500524\tKL_Divergence = 3.962844\n",
      "Epoch: 48\tFidelity = 0.500507\tKL_Divergence = 3.981979\n",
      "Epoch: 49\tFidelity = 0.500511\tKL_Divergence = 3.977122\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:13:01,434] Trial 429 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500494\tKL_Divergence = 3.995901\n",
      "Total time elapsed during training: 77.163 s\n",
      "Trial 429 pruned. \n",
      "Epoch: 1\tFidelity = 0.500464\tKL_Divergence = 4.030535\n",
      "Epoch: 2\tFidelity = 0.500505\tKL_Divergence = 3.983922\n",
      "Epoch: 3\tFidelity = 0.500540\tKL_Divergence = 3.945887\n",
      "Epoch: 4\tFidelity = 0.500599\tKL_Divergence = 3.889343\n",
      "Epoch: 5\tFidelity = 0.500504\tKL_Divergence = 3.984869\n",
      "Epoch: 6\tFidelity = 0.500528\tKL_Divergence = 3.959281\n",
      "Epoch: 7\tFidelity = 0.500448\tKL_Divergence = 4.050119\n",
      "Epoch: 8\tFidelity = 0.500498\tKL_Divergence = 3.991731\n",
      "Epoch: 9\tFidelity = 0.500546\tKL_Divergence = 3.939988\n",
      "Epoch: 10\tFidelity = 0.500529\tKL_Divergence = 3.957843\n",
      "Epoch: 11\tFidelity = 0.500532\tKL_Divergence = 3.954692\n",
      "Epoch: 12\tFidelity = 0.500562\tKL_Divergence = 3.924353\n",
      "Epoch: 13\tFidelity = 0.500582\tKL_Divergence = 3.905364\n",
      "Epoch: 14\tFidelity = 0.500498\tKL_Divergence = 3.991574\n",
      "Epoch: 15\tFidelity = 0.500480\tKL_Divergence = 4.011567\n",
      "Epoch: 16\tFidelity = 0.500403\tKL_Divergence = 4.108113\n",
      "Epoch: 17\tFidelity = 0.500551\tKL_Divergence = 3.935208\n",
      "Epoch: 18\tFidelity = 0.500430\tKL_Divergence = 4.072131\n",
      "Epoch: 19\tFidelity = 0.500548\tKL_Divergence = 3.937868\n",
      "Epoch: 20\tFidelity = 0.500563\tKL_Divergence = 3.922551\n",
      "Epoch: 21\tFidelity = 0.500490\tKL_Divergence = 3.999182\n",
      "Epoch: 22\tFidelity = 0.500570\tKL_Divergence = 3.916237\n",
      "Epoch: 23\tFidelity = 0.500464\tKL_Divergence = 4.031037\n",
      "Epoch: 24\tFidelity = 0.500560\tKL_Divergence = 3.926230\n",
      "Epoch: 25\tFidelity = 0.500468\tKL_Divergence = 4.026347\n",
      "Epoch: 26\tFidelity = 0.500470\tKL_Divergence = 4.023433\n",
      "Epoch: 27\tFidelity = 0.500573\tKL_Divergence = 3.913860\n",
      "Epoch: 28\tFidelity = 0.500463\tKL_Divergence = 4.031301\n",
      "Epoch: 29\tFidelity = 0.500584\tKL_Divergence = 3.902536\n",
      "Epoch: 30\tFidelity = 0.500498\tKL_Divergence = 3.991000\n",
      "Epoch: 31\tFidelity = 0.500581\tKL_Divergence = 3.905146\n",
      "Epoch: 32\tFidelity = 0.500494\tKL_Divergence = 3.995894\n",
      "Epoch: 33\tFidelity = 0.500595\tKL_Divergence = 3.891131\n",
      "Epoch: 34\tFidelity = 0.500521\tKL_Divergence = 3.965310\n",
      "Epoch: 35\tFidelity = 0.500606\tKL_Divergence = 3.881443\n",
      "Epoch: 36\tFidelity = 0.500448\tKL_Divergence = 4.048936\n",
      "Epoch: 37\tFidelity = 0.500469\tKL_Divergence = 4.023158\n",
      "Epoch: 38\tFidelity = 0.500497\tKL_Divergence = 3.990829\n",
      "Epoch: 39\tFidelity = 0.500559\tKL_Divergence = 3.926432\n",
      "Epoch: 40\tFidelity = 0.500472\tKL_Divergence = 4.019984\n",
      "Epoch: 41\tFidelity = 0.500443\tKL_Divergence = 4.055368\n",
      "Epoch: 42\tFidelity = 0.500561\tKL_Divergence = 3.924297\n",
      "Epoch: 43\tFidelity = 0.500578\tKL_Divergence = 3.907565\n",
      "Epoch: 44\tFidelity = 0.500548\tKL_Divergence = 3.938200\n",
      "Epoch: 45\tFidelity = 0.500458\tKL_Divergence = 4.038066\n",
      "Epoch: 46\tFidelity = 0.500524\tKL_Divergence = 3.963162\n",
      "Epoch: 47\tFidelity = 0.500482\tKL_Divergence = 4.008576\n",
      "Epoch: 48\tFidelity = 0.500448\tKL_Divergence = 4.049889\n",
      "Epoch: 49\tFidelity = 0.500579\tKL_Divergence = 3.907506\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:13:38,456] Trial 430 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500516\tKL_Divergence = 3.971660\n",
      "Total time elapsed during training: 36.858 s\n",
      "Trial 430 pruned. \n",
      "Epoch: 1\tFidelity = 0.500550\tKL_Divergence = 3.935733\n",
      "Epoch: 2\tFidelity = 0.500512\tKL_Divergence = 3.975343\n",
      "Epoch: 3\tFidelity = 0.500493\tKL_Divergence = 3.996790\n",
      "Epoch: 4\tFidelity = 0.500525\tKL_Divergence = 3.961735\n",
      "Epoch: 5\tFidelity = 0.500511\tKL_Divergence = 3.976753\n",
      "Epoch: 6\tFidelity = 0.500554\tKL_Divergence = 3.932084\n",
      "Epoch: 7\tFidelity = 0.500497\tKL_Divergence = 3.992237\n",
      "Epoch: 8\tFidelity = 0.500510\tKL_Divergence = 3.977242\n",
      "Epoch: 9\tFidelity = 0.500498\tKL_Divergence = 3.990839\n",
      "Epoch: 10\tFidelity = 0.500495\tKL_Divergence = 3.994799\n",
      "Epoch: 11\tFidelity = 0.500531\tKL_Divergence = 3.955690\n",
      "Epoch: 12\tFidelity = 0.500537\tKL_Divergence = 3.949413\n",
      "Epoch: 13\tFidelity = 0.500480\tKL_Divergence = 4.011467\n",
      "Epoch: 14\tFidelity = 0.500525\tKL_Divergence = 3.961534\n",
      "Epoch: 15\tFidelity = 0.500517\tKL_Divergence = 3.969827\n",
      "Epoch: 16\tFidelity = 0.500512\tKL_Divergence = 3.975542\n",
      "Epoch: 17\tFidelity = 0.500507\tKL_Divergence = 3.980771\n",
      "Epoch: 18\tFidelity = 0.500507\tKL_Divergence = 3.981101\n",
      "Epoch: 19\tFidelity = 0.500516\tKL_Divergence = 3.971202\n",
      "Epoch: 20\tFidelity = 0.500512\tKL_Divergence = 3.975814\n",
      "Epoch: 21\tFidelity = 0.500486\tKL_Divergence = 4.004683\n",
      "Epoch: 22\tFidelity = 0.500502\tKL_Divergence = 3.986476\n",
      "Epoch: 23\tFidelity = 0.500502\tKL_Divergence = 3.986529\n",
      "Epoch: 24\tFidelity = 0.500525\tKL_Divergence = 3.961679\n",
      "Epoch: 25\tFidelity = 0.500475\tKL_Divergence = 4.017291\n",
      "Epoch: 26\tFidelity = 0.500510\tKL_Divergence = 3.977991\n",
      "Epoch: 27\tFidelity = 0.500480\tKL_Divergence = 4.011238\n",
      "Epoch: 28\tFidelity = 0.500524\tKL_Divergence = 3.962967\n",
      "Epoch: 29\tFidelity = 0.500489\tKL_Divergence = 4.001500\n",
      "Epoch: 30\tFidelity = 0.500495\tKL_Divergence = 3.994293\n",
      "Epoch: 31\tFidelity = 0.500499\tKL_Divergence = 3.989567\n",
      "Epoch: 32\tFidelity = 0.500510\tKL_Divergence = 3.977631\n",
      "Epoch: 33\tFidelity = 0.500529\tKL_Divergence = 3.957563\n",
      "Epoch: 34\tFidelity = 0.500518\tKL_Divergence = 3.969293\n",
      "Epoch: 35\tFidelity = 0.500528\tKL_Divergence = 3.958249\n",
      "Epoch: 36\tFidelity = 0.500485\tKL_Divergence = 4.005533\n",
      "Epoch: 37\tFidelity = 0.500493\tKL_Divergence = 3.996242\n",
      "Epoch: 38\tFidelity = 0.500530\tKL_Divergence = 3.956382\n",
      "Epoch: 39\tFidelity = 0.500514\tKL_Divergence = 3.973389\n",
      "Epoch: 40\tFidelity = 0.500478\tKL_Divergence = 4.014063\n",
      "Epoch: 41\tFidelity = 0.500475\tKL_Divergence = 4.017176\n",
      "Epoch: 42\tFidelity = 0.500526\tKL_Divergence = 3.961022\n",
      "Epoch: 43\tFidelity = 0.500482\tKL_Divergence = 4.009816\n",
      "Epoch: 44\tFidelity = 0.500526\tKL_Divergence = 3.960962\n",
      "Epoch: 45\tFidelity = 0.500513\tKL_Divergence = 3.974539\n",
      "Epoch: 46\tFidelity = 0.500505\tKL_Divergence = 3.982882\n",
      "Epoch: 47\tFidelity = 0.500494\tKL_Divergence = 3.995848\n",
      "Epoch: 48\tFidelity = 0.500530\tKL_Divergence = 3.956739\n",
      "Epoch: 49\tFidelity = 0.500504\tKL_Divergence = 3.984958\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:14:09,621] Trial 431 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500504\tKL_Divergence = 3.984894\n",
      "Total time elapsed during training: 31.000 s\n",
      "Trial 431 pruned. \n",
      "Epoch: 1\tFidelity = 0.500517\tKL_Divergence = 3.970579\n",
      "Epoch: 2\tFidelity = 0.500482\tKL_Divergence = 4.009370\n",
      "Epoch: 3\tFidelity = 0.500525\tKL_Divergence = 3.961383\n",
      "Epoch: 4\tFidelity = 0.500503\tKL_Divergence = 3.985921\n",
      "Epoch: 5\tFidelity = 0.500509\tKL_Divergence = 3.979023\n",
      "Epoch: 6\tFidelity = 0.500480\tKL_Divergence = 4.012081\n",
      "Epoch: 7\tFidelity = 0.500531\tKL_Divergence = 3.955230\n",
      "Epoch: 8\tFidelity = 0.500475\tKL_Divergence = 4.017027\n",
      "Epoch: 9\tFidelity = 0.500516\tKL_Divergence = 3.971438\n",
      "Epoch: 10\tFidelity = 0.500483\tKL_Divergence = 4.008038\n",
      "Epoch: 11\tFidelity = 0.500494\tKL_Divergence = 3.996130\n",
      "Epoch: 12\tFidelity = 0.500471\tKL_Divergence = 4.021573\n",
      "Epoch: 13\tFidelity = 0.500510\tKL_Divergence = 3.977570\n",
      "Epoch: 14\tFidelity = 0.500490\tKL_Divergence = 4.000712\n",
      "Epoch: 15\tFidelity = 0.500497\tKL_Divergence = 3.991836\n",
      "Epoch: 16\tFidelity = 0.500530\tKL_Divergence = 3.956479\n",
      "Epoch: 17\tFidelity = 0.500499\tKL_Divergence = 3.989726\n",
      "Epoch: 18\tFidelity = 0.500484\tKL_Divergence = 4.006923\n",
      "Epoch: 19\tFidelity = 0.500510\tKL_Divergence = 3.978360\n",
      "Epoch: 20\tFidelity = 0.500471\tKL_Divergence = 4.021610\n",
      "Epoch: 21\tFidelity = 0.500473\tKL_Divergence = 4.020273\n",
      "Epoch: 22\tFidelity = 0.500530\tKL_Divergence = 3.956397\n",
      "Epoch: 23\tFidelity = 0.500475\tKL_Divergence = 4.018001\n",
      "Epoch: 24\tFidelity = 0.500493\tKL_Divergence = 3.996560\n",
      "Epoch: 25\tFidelity = 0.500475\tKL_Divergence = 4.017937\n",
      "Epoch: 26\tFidelity = 0.500493\tKL_Divergence = 3.997113\n",
      "Epoch: 27\tFidelity = 0.500460\tKL_Divergence = 4.035109\n",
      "Epoch: 28\tFidelity = 0.500500\tKL_Divergence = 3.988494\n",
      "Epoch: 29\tFidelity = 0.500511\tKL_Divergence = 3.976851\n",
      "Epoch: 30\tFidelity = 0.500496\tKL_Divergence = 3.993028\n",
      "Epoch: 31\tFidelity = 0.500495\tKL_Divergence = 3.994795\n",
      "Epoch: 32\tFidelity = 0.500523\tKL_Divergence = 3.963602\n",
      "Epoch: 33\tFidelity = 0.500498\tKL_Divergence = 3.991087\n",
      "Epoch: 34\tFidelity = 0.500505\tKL_Divergence = 3.983852\n",
      "Epoch: 35\tFidelity = 0.500501\tKL_Divergence = 3.987649\n",
      "Epoch: 36\tFidelity = 0.500512\tKL_Divergence = 3.976319\n",
      "Epoch: 37\tFidelity = 0.500515\tKL_Divergence = 3.972751\n",
      "Epoch: 38\tFidelity = 0.500512\tKL_Divergence = 3.975971\n",
      "Epoch: 39\tFidelity = 0.500510\tKL_Divergence = 3.977948\n",
      "Epoch: 40\tFidelity = 0.500511\tKL_Divergence = 3.976836\n",
      "Epoch: 41\tFidelity = 0.500520\tKL_Divergence = 3.967624\n",
      "Epoch: 42\tFidelity = 0.500506\tKL_Divergence = 3.982265\n",
      "Epoch: 43\tFidelity = 0.500504\tKL_Divergence = 3.984295\n",
      "Epoch: 44\tFidelity = 0.500494\tKL_Divergence = 3.996200\n",
      "Epoch: 45\tFidelity = 0.500461\tKL_Divergence = 4.034230\n",
      "Epoch: 46\tFidelity = 0.500488\tKL_Divergence = 4.002730\n",
      "Epoch: 47\tFidelity = 0.500522\tKL_Divergence = 3.965361\n",
      "Epoch: 48\tFidelity = 0.500481\tKL_Divergence = 4.010076\n",
      "Epoch: 49\tFidelity = 0.500507\tKL_Divergence = 3.981748\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:14:40,622] Trial 432 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500513\tKL_Divergence = 3.975033\n",
      "Total time elapsed during training: 30.834 s\n",
      "Trial 432 pruned. \n",
      "Epoch: 1\tFidelity = 0.500422\tKL_Divergence = 4.082863\n",
      "Epoch: 2\tFidelity = 0.500587\tKL_Divergence = 3.899959\n",
      "Epoch: 3\tFidelity = 0.500506\tKL_Divergence = 3.982085\n",
      "Epoch: 4\tFidelity = 0.500497\tKL_Divergence = 3.992112\n",
      "Epoch: 5\tFidelity = 0.500428\tKL_Divergence = 4.075685\n",
      "Epoch: 6\tFidelity = 0.500544\tKL_Divergence = 3.941949\n",
      "Epoch: 7\tFidelity = 0.500473\tKL_Divergence = 4.019413\n",
      "Epoch: 8\tFidelity = 0.500452\tKL_Divergence = 4.045248\n",
      "Epoch: 9\tFidelity = 0.500465\tKL_Divergence = 4.029302\n",
      "Epoch: 10\tFidelity = 0.500430\tKL_Divergence = 4.072474\n",
      "Epoch: 11\tFidelity = 0.500396\tKL_Divergence = 4.117722\n",
      "Epoch: 12\tFidelity = 0.500585\tKL_Divergence = 3.901444\n",
      "Epoch: 13\tFidelity = 0.500482\tKL_Divergence = 4.008934\n",
      "Epoch: 14\tFidelity = 0.500521\tKL_Divergence = 3.966094\n",
      "Epoch: 15\tFidelity = 0.500456\tKL_Divergence = 4.039982\n",
      "Epoch: 16\tFidelity = 0.500547\tKL_Divergence = 3.939011\n",
      "Epoch: 17\tFidelity = 0.500502\tKL_Divergence = 3.986620\n",
      "Epoch: 18\tFidelity = 0.500445\tKL_Divergence = 4.054226\n",
      "Epoch: 19\tFidelity = 0.500437\tKL_Divergence = 4.063259\n",
      "Epoch: 20\tFidelity = 0.500530\tKL_Divergence = 3.956653\n",
      "Epoch: 21\tFidelity = 0.500539\tKL_Divergence = 3.947754\n",
      "Epoch: 22\tFidelity = 0.500550\tKL_Divergence = 3.935995\n",
      "Epoch: 23\tFidelity = 0.500544\tKL_Divergence = 3.942796\n",
      "Epoch: 24\tFidelity = 0.500556\tKL_Divergence = 3.930446\n",
      "Epoch: 25\tFidelity = 0.500497\tKL_Divergence = 3.992514\n",
      "Epoch: 26\tFidelity = 0.500539\tKL_Divergence = 3.947246\n",
      "Epoch: 27\tFidelity = 0.500507\tKL_Divergence = 3.981515\n",
      "Epoch: 28\tFidelity = 0.500485\tKL_Divergence = 4.006591\n",
      "Epoch: 29\tFidelity = 0.500483\tKL_Divergence = 4.008196\n",
      "Epoch: 30\tFidelity = 0.500422\tKL_Divergence = 4.083908\n",
      "Epoch: 31\tFidelity = 0.500526\tKL_Divergence = 3.961337\n",
      "Epoch: 32\tFidelity = 0.500481\tKL_Divergence = 4.010712\n",
      "Epoch: 33\tFidelity = 0.500455\tKL_Divergence = 4.041639\n",
      "Epoch: 34\tFidelity = 0.500424\tKL_Divergence = 4.080700\n",
      "Epoch: 35\tFidelity = 0.500461\tKL_Divergence = 4.034689\n",
      "Epoch: 36\tFidelity = 0.500485\tKL_Divergence = 4.006064\n",
      "Epoch: 37\tFidelity = 0.500469\tKL_Divergence = 4.024561\n",
      "Epoch: 38\tFidelity = 0.500449\tKL_Divergence = 4.048674\n",
      "Epoch: 39\tFidelity = 0.500470\tKL_Divergence = 4.023081\n",
      "Epoch: 40\tFidelity = 0.500513\tKL_Divergence = 3.974527\n",
      "Epoch: 41\tFidelity = 0.500481\tKL_Divergence = 4.010923\n",
      "Epoch: 42\tFidelity = 0.500457\tKL_Divergence = 4.039568\n",
      "Epoch: 43\tFidelity = 0.500502\tKL_Divergence = 3.986753\n",
      "Epoch: 44\tFidelity = 0.500435\tKL_Divergence = 4.066154\n",
      "Epoch: 45\tFidelity = 0.500528\tKL_Divergence = 3.958857\n",
      "Epoch: 46\tFidelity = 0.500496\tKL_Divergence = 3.993583\n",
      "Epoch: 47\tFidelity = 0.500437\tKL_Divergence = 4.064496\n",
      "Epoch: 48\tFidelity = 0.500435\tKL_Divergence = 4.065953\n",
      "Epoch: 49\tFidelity = 0.500440\tKL_Divergence = 4.060485\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:15:17,924] Trial 433 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500459\tKL_Divergence = 4.036993\n",
      "Total time elapsed during training: 37.136 s\n",
      "Trial 433 pruned. \n",
      "Epoch: 1\tFidelity = 0.500436\tKL_Divergence = 4.065428\n",
      "Epoch: 2\tFidelity = 0.500591\tKL_Divergence = 3.896160\n",
      "Epoch: 3\tFidelity = 0.500446\tKL_Divergence = 4.052821\n",
      "Epoch: 4\tFidelity = 0.500430\tKL_Divergence = 4.072280\n",
      "Epoch: 5\tFidelity = 0.500452\tKL_Divergence = 4.045612\n",
      "Epoch: 6\tFidelity = 0.500462\tKL_Divergence = 4.032493\n",
      "Epoch: 7\tFidelity = 0.500421\tKL_Divergence = 4.084731\n",
      "Epoch: 8\tFidelity = 0.500503\tKL_Divergence = 3.986381\n",
      "Epoch: 9\tFidelity = 0.500458\tKL_Divergence = 4.038367\n",
      "Epoch: 10\tFidelity = 0.500488\tKL_Divergence = 4.003111\n",
      "Epoch: 11\tFidelity = 0.500420\tKL_Divergence = 4.086277\n",
      "Epoch: 12\tFidelity = 0.500458\tKL_Divergence = 4.037826\n",
      "Epoch: 13\tFidelity = 0.500582\tKL_Divergence = 3.904629\n",
      "Epoch: 14\tFidelity = 0.500512\tKL_Divergence = 3.976217\n",
      "Epoch: 15\tFidelity = 0.500440\tKL_Divergence = 4.059593\n",
      "Epoch: 16\tFidelity = 0.500397\tKL_Divergence = 4.117203\n",
      "Epoch: 17\tFidelity = 0.500495\tKL_Divergence = 3.994320\n",
      "Epoch: 18\tFidelity = 0.500574\tKL_Divergence = 3.912499\n",
      "Epoch: 19\tFidelity = 0.500575\tKL_Divergence = 3.911542\n",
      "Epoch: 20\tFidelity = 0.500554\tKL_Divergence = 3.932472\n",
      "Epoch: 21\tFidelity = 0.500457\tKL_Divergence = 4.038859\n",
      "Epoch: 22\tFidelity = 0.500388\tKL_Divergence = 4.130019\n",
      "Epoch: 23\tFidelity = 0.500504\tKL_Divergence = 3.985077\n",
      "Epoch: 24\tFidelity = 0.500560\tKL_Divergence = 3.926250\n",
      "Epoch: 25\tFidelity = 0.500515\tKL_Divergence = 3.972792\n",
      "Epoch: 26\tFidelity = 0.500426\tKL_Divergence = 4.078406\n",
      "Epoch: 27\tFidelity = 0.500394\tKL_Divergence = 4.121486\n",
      "Epoch: 28\tFidelity = 0.500648\tKL_Divergence = 3.845581\n",
      "Epoch: 29\tFidelity = 0.500492\tKL_Divergence = 3.998112\n",
      "Epoch: 30\tFidelity = 0.500425\tKL_Divergence = 4.079654\n",
      "Epoch: 31\tFidelity = 0.500585\tKL_Divergence = 3.902220\n",
      "Epoch: 32\tFidelity = 0.500515\tKL_Divergence = 3.972431\n",
      "Epoch: 33\tFidelity = 0.500498\tKL_Divergence = 3.990976\n",
      "Epoch: 34\tFidelity = 0.500423\tKL_Divergence = 4.081353\n",
      "Epoch: 35\tFidelity = 0.500416\tKL_Divergence = 4.090842\n",
      "Epoch: 36\tFidelity = 0.500433\tKL_Divergence = 4.068798\n",
      "Epoch: 37\tFidelity = 0.500579\tKL_Divergence = 3.907586\n",
      "Epoch: 38\tFidelity = 0.500512\tKL_Divergence = 3.975728\n",
      "Epoch: 39\tFidelity = 0.500501\tKL_Divergence = 3.988561\n",
      "Epoch: 40\tFidelity = 0.500414\tKL_Divergence = 4.094185\n",
      "Epoch: 41\tFidelity = 0.500470\tKL_Divergence = 4.023247\n",
      "Epoch: 42\tFidelity = 0.500396\tKL_Divergence = 4.118395\n",
      "Epoch: 43\tFidelity = 0.500523\tKL_Divergence = 3.963727\n",
      "Epoch: 44\tFidelity = 0.500484\tKL_Divergence = 4.007392\n",
      "Epoch: 45\tFidelity = 0.500546\tKL_Divergence = 3.940631\n",
      "Epoch: 46\tFidelity = 0.500489\tKL_Divergence = 4.001416\n",
      "Epoch: 47\tFidelity = 0.500607\tKL_Divergence = 3.881187\n",
      "Epoch: 48\tFidelity = 0.500463\tKL_Divergence = 4.031858\n",
      "Epoch: 49\tFidelity = 0.500398\tKL_Divergence = 4.115040\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:15:55,378] Trial 434 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500447\tKL_Divergence = 4.051577\n",
      "Total time elapsed during training: 37.287 s\n",
      "Trial 434 pruned. \n",
      "Epoch: 1\tFidelity = 0.500494\tKL_Divergence = 3.995567\n",
      "Epoch: 2\tFidelity = 0.500471\tKL_Divergence = 4.022516\n",
      "Epoch: 3\tFidelity = 0.500471\tKL_Divergence = 4.022847\n",
      "Epoch: 4\tFidelity = 0.500441\tKL_Divergence = 4.058291\n",
      "Epoch: 5\tFidelity = 0.500465\tKL_Divergence = 4.028890\n",
      "Epoch: 6\tFidelity = 0.500459\tKL_Divergence = 4.036843\n",
      "Epoch: 7\tFidelity = 0.500463\tKL_Divergence = 4.031466\n",
      "Epoch: 8\tFidelity = 0.500490\tKL_Divergence = 4.000812\n",
      "Epoch: 9\tFidelity = 0.500449\tKL_Divergence = 4.049187\n",
      "Epoch: 10\tFidelity = 0.500452\tKL_Divergence = 4.044724\n",
      "Epoch: 11\tFidelity = 0.500522\tKL_Divergence = 3.965686\n",
      "Epoch: 12\tFidelity = 0.500484\tKL_Divergence = 4.007048\n",
      "Epoch: 13\tFidelity = 0.500455\tKL_Divergence = 4.041813\n",
      "Epoch: 14\tFidelity = 0.500497\tKL_Divergence = 3.992758\n",
      "Epoch: 15\tFidelity = 0.500453\tKL_Divergence = 4.043491\n",
      "Epoch: 16\tFidelity = 0.500473\tKL_Divergence = 4.019660\n",
      "Epoch: 17\tFidelity = 0.500490\tKL_Divergence = 4.000544\n",
      "Epoch: 18\tFidelity = 0.500471\tKL_Divergence = 4.022367\n",
      "Epoch: 19\tFidelity = 0.500464\tKL_Divergence = 4.031002\n",
      "Epoch: 20\tFidelity = 0.500507\tKL_Divergence = 3.981713\n",
      "Epoch: 21\tFidelity = 0.500508\tKL_Divergence = 3.980721\n",
      "Epoch: 22\tFidelity = 0.500504\tKL_Divergence = 3.984868\n",
      "Epoch: 23\tFidelity = 0.500477\tKL_Divergence = 4.015153\n",
      "Epoch: 24\tFidelity = 0.500486\tKL_Divergence = 4.005183\n",
      "Epoch: 25\tFidelity = 0.500490\tKL_Divergence = 4.000886\n",
      "Epoch: 26\tFidelity = 0.500454\tKL_Divergence = 4.042234\n",
      "Epoch: 27\tFidelity = 0.500468\tKL_Divergence = 4.025568\n",
      "Epoch: 28\tFidelity = 0.500440\tKL_Divergence = 4.060080\n",
      "Epoch: 29\tFidelity = 0.500493\tKL_Divergence = 3.996537\n",
      "Epoch: 30\tFidelity = 0.500468\tKL_Divergence = 4.025652\n",
      "Epoch: 31\tFidelity = 0.500495\tKL_Divergence = 3.994453\n",
      "Epoch: 32\tFidelity = 0.500520\tKL_Divergence = 3.967668\n",
      "Epoch: 33\tFidelity = 0.500464\tKL_Divergence = 4.030274\n",
      "Epoch: 34\tFidelity = 0.500461\tKL_Divergence = 4.034540\n",
      "Epoch: 35\tFidelity = 0.500506\tKL_Divergence = 3.982524\n",
      "Epoch: 36\tFidelity = 0.500467\tKL_Divergence = 4.027356\n",
      "Epoch: 37\tFidelity = 0.500501\tKL_Divergence = 3.987558\n",
      "Epoch: 38\tFidelity = 0.500477\tKL_Divergence = 4.014984\n",
      "Epoch: 39\tFidelity = 0.500486\tKL_Divergence = 4.005380\n",
      "Epoch: 40\tFidelity = 0.500457\tKL_Divergence = 4.038815\n",
      "Epoch: 41\tFidelity = 0.500517\tKL_Divergence = 3.971104\n",
      "Epoch: 42\tFidelity = 0.500502\tKL_Divergence = 3.986626\n",
      "Epoch: 43\tFidelity = 0.500498\tKL_Divergence = 3.991312\n",
      "Epoch: 44\tFidelity = 0.500509\tKL_Divergence = 3.979001\n",
      "Epoch: 45\tFidelity = 0.500486\tKL_Divergence = 4.005333\n",
      "Epoch: 46\tFidelity = 0.500516\tKL_Divergence = 3.971414\n",
      "Epoch: 47\tFidelity = 0.500508\tKL_Divergence = 3.980404\n",
      "Epoch: 48\tFidelity = 0.500473\tKL_Divergence = 4.019420\n",
      "Epoch: 49\tFidelity = 0.500469\tKL_Divergence = 4.024459\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:17:13,512] Trial 435 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500451\tKL_Divergence = 4.046299\n",
      "Total time elapsed during training: 77.963 s\n",
      "Trial 435 pruned. \n",
      "Epoch: 1\tFidelity = 0.500558\tKL_Divergence = 3.928045\n",
      "Epoch: 2\tFidelity = 0.500589\tKL_Divergence = 3.898588\n",
      "Epoch: 3\tFidelity = 0.500487\tKL_Divergence = 4.003891\n",
      "Epoch: 4\tFidelity = 0.500557\tKL_Divergence = 3.929296\n",
      "Epoch: 5\tFidelity = 0.500398\tKL_Divergence = 4.114837\n",
      "Epoch: 6\tFidelity = 0.500481\tKL_Divergence = 4.010691\n",
      "Epoch: 7\tFidelity = 0.500403\tKL_Divergence = 4.108729\n",
      "Epoch: 8\tFidelity = 0.500497\tKL_Divergence = 3.992210\n",
      "Epoch: 9\tFidelity = 0.500575\tKL_Divergence = 3.911396\n",
      "Epoch: 10\tFidelity = 0.500469\tKL_Divergence = 4.024708\n",
      "Epoch: 11\tFidelity = 0.500528\tKL_Divergence = 3.958561\n",
      "Epoch: 12\tFidelity = 0.500425\tKL_Divergence = 4.078519\n",
      "Epoch: 13\tFidelity = 0.500464\tKL_Divergence = 4.030023\n",
      "Epoch: 14\tFidelity = 0.500407\tKL_Divergence = 4.103254\n",
      "Epoch: 15\tFidelity = 0.500411\tKL_Divergence = 4.097571\n",
      "Epoch: 16\tFidelity = 0.500513\tKL_Divergence = 3.975171\n",
      "Epoch: 17\tFidelity = 0.500419\tKL_Divergence = 4.086429\n",
      "Epoch: 18\tFidelity = 0.500460\tKL_Divergence = 4.035013\n",
      "Epoch: 19\tFidelity = 0.500605\tKL_Divergence = 3.882511\n",
      "Epoch: 20\tFidelity = 0.500550\tKL_Divergence = 3.936107\n",
      "Epoch: 21\tFidelity = 0.500572\tKL_Divergence = 3.913916\n",
      "Epoch: 22\tFidelity = 0.500467\tKL_Divergence = 4.026269\n",
      "Epoch: 23\tFidelity = 0.500445\tKL_Divergence = 4.052165\n",
      "Epoch: 24\tFidelity = 0.500582\tKL_Divergence = 3.904206\n",
      "Epoch: 25\tFidelity = 0.500552\tKL_Divergence = 3.934094\n",
      "Epoch: 26\tFidelity = 0.500536\tKL_Divergence = 3.950680\n",
      "Epoch: 27\tFidelity = 0.500657\tKL_Divergence = 3.837107\n",
      "Epoch: 28\tFidelity = 0.500463\tKL_Divergence = 4.031473\n",
      "Epoch: 29\tFidelity = 0.500441\tKL_Divergence = 4.058013\n",
      "Epoch: 30\tFidelity = 0.500491\tKL_Divergence = 3.998860\n",
      "Epoch: 31\tFidelity = 0.500566\tKL_Divergence = 3.919941\n",
      "Epoch: 32\tFidelity = 0.500536\tKL_Divergence = 3.950709\n",
      "Epoch: 33\tFidelity = 0.500505\tKL_Divergence = 3.983597\n",
      "Epoch: 34\tFidelity = 0.500654\tKL_Divergence = 3.840033\n",
      "Epoch: 35\tFidelity = 0.500498\tKL_Divergence = 3.990713\n",
      "Epoch: 36\tFidelity = 0.500406\tKL_Divergence = 4.104455\n",
      "Epoch: 37\tFidelity = 0.500649\tKL_Divergence = 3.844134\n",
      "Epoch: 38\tFidelity = 0.500564\tKL_Divergence = 3.921859\n",
      "Epoch: 39\tFidelity = 0.500537\tKL_Divergence = 3.949484\n",
      "Epoch: 40\tFidelity = 0.500475\tKL_Divergence = 4.017027\n",
      "Epoch: 41\tFidelity = 0.500427\tKL_Divergence = 4.076362\n",
      "Epoch: 42\tFidelity = 0.500653\tKL_Divergence = 3.841142\n",
      "Epoch: 43\tFidelity = 0.500693\tKL_Divergence = 3.807418\n",
      "Epoch: 44\tFidelity = 0.500496\tKL_Divergence = 3.992876\n",
      "Epoch: 45\tFidelity = 0.500547\tKL_Divergence = 3.939015\n",
      "Epoch: 46\tFidelity = 0.500519\tKL_Divergence = 3.967907\n",
      "Epoch: 47\tFidelity = 0.500563\tKL_Divergence = 3.922245\n",
      "Epoch: 48\tFidelity = 0.500688\tKL_Divergence = 3.811294\n",
      "Epoch: 49\tFidelity = 0.500511\tKL_Divergence = 3.976994\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:18:10,671] Trial 436 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500582\tKL_Divergence = 3.903985\n",
      "Total time elapsed during training: 56.985 s\n",
      "Trial 436 pruned. \n",
      "Epoch: 1\tFidelity = 0.500629\tKL_Divergence = 3.861144\n",
      "Epoch: 2\tFidelity = 0.500523\tKL_Divergence = 3.963388\n",
      "Epoch: 3\tFidelity = 0.500613\tKL_Divergence = 3.876176\n",
      "Epoch: 4\tFidelity = 0.500610\tKL_Divergence = 3.878563\n",
      "Epoch: 5\tFidelity = 0.500390\tKL_Divergence = 4.126364\n",
      "Epoch: 6\tFidelity = 0.500594\tKL_Divergence = 3.893046\n",
      "Epoch: 7\tFidelity = 0.500647\tKL_Divergence = 3.846237\n",
      "Epoch: 8\tFidelity = 0.500578\tKL_Divergence = 3.908877\n",
      "Epoch: 9\tFidelity = 0.500477\tKL_Divergence = 4.014685\n",
      "Epoch: 10\tFidelity = 0.500465\tKL_Divergence = 4.029268\n",
      "Epoch: 11\tFidelity = 0.500593\tKL_Divergence = 3.893841\n",
      "Epoch: 12\tFidelity = 0.500682\tKL_Divergence = 3.816117\n",
      "Epoch: 13\tFidelity = 0.500497\tKL_Divergence = 3.991349\n",
      "Epoch: 14\tFidelity = 0.500434\tKL_Divergence = 4.067653\n",
      "Epoch: 15\tFidelity = 0.500476\tKL_Divergence = 4.016118\n",
      "Epoch: 16\tFidelity = 0.500472\tKL_Divergence = 4.021132\n",
      "Epoch: 17\tFidelity = 0.500546\tKL_Divergence = 3.939701\n",
      "Epoch: 18\tFidelity = 0.500413\tKL_Divergence = 4.095268\n",
      "Epoch: 19\tFidelity = 0.500553\tKL_Divergence = 3.933310\n",
      "Epoch: 20\tFidelity = 0.500601\tKL_Divergence = 3.887085\n",
      "Epoch: 21\tFidelity = 0.500472\tKL_Divergence = 4.020416\n",
      "Epoch: 22\tFidelity = 0.500580\tKL_Divergence = 3.906461\n",
      "Epoch: 23\tFidelity = 0.500539\tKL_Divergence = 3.946648\n",
      "Epoch: 24\tFidelity = 0.500548\tKL_Divergence = 3.937663\n",
      "Epoch: 25\tFidelity = 0.500604\tKL_Divergence = 3.883834\n",
      "Epoch: 26\tFidelity = 0.500454\tKL_Divergence = 4.042533\n",
      "Epoch: 27\tFidelity = 0.500678\tKL_Divergence = 3.820068\n",
      "Epoch: 28\tFidelity = 0.500516\tKL_Divergence = 3.971513\n",
      "Epoch: 29\tFidelity = 0.500514\tKL_Divergence = 3.973018\n",
      "Epoch: 30\tFidelity = 0.500614\tKL_Divergence = 3.874705\n",
      "Epoch: 31\tFidelity = 0.500524\tKL_Divergence = 3.963082\n",
      "Epoch: 32\tFidelity = 0.500571\tKL_Divergence = 3.915047\n",
      "Epoch: 33\tFidelity = 0.500521\tKL_Divergence = 3.966180\n",
      "Epoch: 34\tFidelity = 0.500532\tKL_Divergence = 3.954816\n",
      "Epoch: 35\tFidelity = 0.500605\tKL_Divergence = 3.883244\n",
      "Epoch: 36\tFidelity = 0.500583\tKL_Divergence = 3.903810\n",
      "Epoch: 37\tFidelity = 0.500636\tKL_Divergence = 3.855498\n",
      "Epoch: 38\tFidelity = 0.500440\tKL_Divergence = 4.059816\n",
      "Epoch: 39\tFidelity = 0.500593\tKL_Divergence = 3.893886\n",
      "Epoch: 40\tFidelity = 0.500687\tKL_Divergence = 3.812235\n",
      "Epoch: 41\tFidelity = 0.500536\tKL_Divergence = 3.950502\n",
      "Epoch: 42\tFidelity = 0.500448\tKL_Divergence = 4.050278\n",
      "Epoch: 43\tFidelity = 0.500565\tKL_Divergence = 3.920832\n",
      "Epoch: 44\tFidelity = 0.500417\tKL_Divergence = 4.089440\n",
      "Epoch: 45\tFidelity = 0.500567\tKL_Divergence = 3.919441\n",
      "Epoch: 46\tFidelity = 0.500416\tKL_Divergence = 4.090894\n",
      "Epoch: 47\tFidelity = 0.500540\tKL_Divergence = 3.945823\n",
      "Epoch: 48\tFidelity = 0.500474\tKL_Divergence = 4.017810\n",
      "Epoch: 49\tFidelity = 0.500518\tKL_Divergence = 3.969388\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:18:48,427] Trial 437 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500426\tKL_Divergence = 4.077223\n",
      "Total time elapsed during training: 37.592 s\n",
      "Trial 437 pruned. \n",
      "Epoch: 1\tFidelity = 0.500573\tKL_Divergence = 3.912687\n",
      "Epoch: 2\tFidelity = 0.500472\tKL_Divergence = 4.020337\n",
      "Epoch: 3\tFidelity = 0.500461\tKL_Divergence = 4.034255\n",
      "Epoch: 4\tFidelity = 0.500563\tKL_Divergence = 3.923285\n",
      "Epoch: 5\tFidelity = 0.500567\tKL_Divergence = 3.919474\n",
      "Epoch: 6\tFidelity = 0.500537\tKL_Divergence = 3.948793\n",
      "Epoch: 7\tFidelity = 0.500610\tKL_Divergence = 3.878015\n",
      "Epoch: 8\tFidelity = 0.500495\tKL_Divergence = 3.994294\n",
      "Epoch: 9\tFidelity = 0.500610\tKL_Divergence = 3.877869\n",
      "Epoch: 10\tFidelity = 0.500443\tKL_Divergence = 4.054355\n",
      "Epoch: 11\tFidelity = 0.500618\tKL_Divergence = 3.870169\n",
      "Epoch: 12\tFidelity = 0.500544\tKL_Divergence = 3.940424\n",
      "Epoch: 13\tFidelity = 0.500436\tKL_Divergence = 4.061598\n",
      "Epoch: 14\tFidelity = 0.500537\tKL_Divergence = 3.946898\n",
      "Epoch: 15\tFidelity = 0.500545\tKL_Divergence = 3.937426\n",
      "Epoch: 16\tFidelity = 0.500504\tKL_Divergence = 3.981979\n",
      "Epoch: 17\tFidelity = 0.500566\tKL_Divergence = 3.918528\n",
      "Epoch: 18\tFidelity = 0.500607\tKL_Divergence = 3.879520\n",
      "Epoch: 19\tFidelity = 0.500477\tKL_Divergence = 4.013546\n",
      "Epoch: 20\tFidelity = 0.500512\tKL_Divergence = 3.974149\n",
      "Epoch: 21\tFidelity = 0.500631\tKL_Divergence = 3.857980\n",
      "Epoch: 22\tFidelity = 0.500476\tKL_Divergence = 4.014400\n",
      "Epoch: 23\tFidelity = 0.500516\tKL_Divergence = 3.970292\n",
      "Epoch: 24\tFidelity = 0.500509\tKL_Divergence = 3.975582\n",
      "Epoch: 25\tFidelity = 0.500475\tKL_Divergence = 4.015035\n",
      "Epoch: 26\tFidelity = 0.500664\tKL_Divergence = 3.829517\n",
      "Epoch: 27\tFidelity = 0.500481\tKL_Divergence = 4.008763\n",
      "Epoch: 28\tFidelity = 0.500571\tKL_Divergence = 3.913283\n",
      "Epoch: 29\tFidelity = 0.500638\tKL_Divergence = 3.852350\n",
      "Epoch: 30\tFidelity = 0.500543\tKL_Divergence = 3.943184\n",
      "Epoch: 31\tFidelity = 0.500614\tKL_Divergence = 3.874742\n",
      "Epoch: 32\tFidelity = 0.500548\tKL_Divergence = 3.937643\n",
      "Epoch: 33\tFidelity = 0.500601\tKL_Divergence = 3.886736\n",
      "Epoch: 34\tFidelity = 0.500653\tKL_Divergence = 3.840310\n",
      "Epoch: 35\tFidelity = 0.500547\tKL_Divergence = 3.938927\n",
      "Epoch: 36\tFidelity = 0.500478\tKL_Divergence = 4.013640\n",
      "Epoch: 37\tFidelity = 0.500561\tKL_Divergence = 3.925046\n",
      "Epoch: 38\tFidelity = 0.500554\tKL_Divergence = 3.931705\n",
      "Epoch: 39\tFidelity = 0.500568\tKL_Divergence = 3.917902\n",
      "Epoch: 40\tFidelity = 0.500645\tKL_Divergence = 3.847496\n",
      "Epoch: 41\tFidelity = 0.500629\tKL_Divergence = 3.861275\n",
      "Epoch: 42\tFidelity = 0.500639\tKL_Divergence = 3.852909\n",
      "Epoch: 43\tFidelity = 0.500509\tKL_Divergence = 3.978077\n",
      "Epoch: 44\tFidelity = 0.500574\tKL_Divergence = 3.911922\n",
      "Epoch: 45\tFidelity = 0.500599\tKL_Divergence = 3.888351\n",
      "Epoch: 46\tFidelity = 0.500655\tKL_Divergence = 3.838752\n",
      "Epoch: 47\tFidelity = 0.500565\tKL_Divergence = 3.920232\n",
      "Epoch: 48\tFidelity = 0.500555\tKL_Divergence = 3.930682\n",
      "Epoch: 49\tFidelity = 0.500637\tKL_Divergence = 3.853944\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:19:25,519] Trial 438 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500654\tKL_Divergence = 3.837566\n",
      "Total time elapsed during training: 36.926 s\n",
      "Trial 438 pruned. \n",
      "Epoch: 1\tFidelity = 0.500566\tKL_Divergence = 3.917812\n",
      "Epoch: 2\tFidelity = 0.500588\tKL_Divergence = 3.897409\n",
      "Epoch: 3\tFidelity = 0.500553\tKL_Divergence = 3.931457\n",
      "Epoch: 4\tFidelity = 0.500566\tKL_Divergence = 3.918145\n",
      "Epoch: 5\tFidelity = 0.500573\tKL_Divergence = 3.912025\n",
      "Epoch: 6\tFidelity = 0.500590\tKL_Divergence = 3.896015\n",
      "Epoch: 7\tFidelity = 0.500576\tKL_Divergence = 3.908842\n",
      "Epoch: 8\tFidelity = 0.500551\tKL_Divergence = 3.934133\n",
      "Epoch: 9\tFidelity = 0.500523\tKL_Divergence = 3.963360\n",
      "Epoch: 10\tFidelity = 0.500559\tKL_Divergence = 3.926484\n",
      "Epoch: 11\tFidelity = 0.500557\tKL_Divergence = 3.928597\n",
      "Epoch: 12\tFidelity = 0.500550\tKL_Divergence = 3.934975\n",
      "Epoch: 13\tFidelity = 0.500522\tKL_Divergence = 3.964073\n",
      "Epoch: 14\tFidelity = 0.500525\tKL_Divergence = 3.961269\n",
      "Epoch: 15\tFidelity = 0.500521\tKL_Divergence = 3.965715\n",
      "Epoch: 16\tFidelity = 0.500528\tKL_Divergence = 3.958453\n",
      "Epoch: 17\tFidelity = 0.500571\tKL_Divergence = 3.914442\n",
      "Epoch: 18\tFidelity = 0.500556\tKL_Divergence = 3.929474\n",
      "Epoch: 19\tFidelity = 0.500588\tKL_Divergence = 3.898604\n",
      "Epoch: 20\tFidelity = 0.500537\tKL_Divergence = 3.948815\n",
      "Epoch: 21\tFidelity = 0.500525\tKL_Divergence = 3.961459\n",
      "Epoch: 22\tFidelity = 0.500573\tKL_Divergence = 3.912763\n",
      "Epoch: 23\tFidelity = 0.500574\tKL_Divergence = 3.911522\n",
      "Epoch: 24\tFidelity = 0.500549\tKL_Divergence = 3.936588\n",
      "Epoch: 25\tFidelity = 0.500531\tKL_Divergence = 3.954848\n",
      "Epoch: 26\tFidelity = 0.500522\tKL_Divergence = 3.964433\n",
      "Epoch: 27\tFidelity = 0.500527\tKL_Divergence = 3.959891\n",
      "Epoch: 28\tFidelity = 0.500568\tKL_Divergence = 3.918208\n",
      "Epoch: 29\tFidelity = 0.500534\tKL_Divergence = 3.952106\n",
      "Epoch: 30\tFidelity = 0.500523\tKL_Divergence = 3.963848\n",
      "Epoch: 31\tFidelity = 0.500586\tKL_Divergence = 3.900557\n",
      "Epoch: 32\tFidelity = 0.500565\tKL_Divergence = 3.920530\n",
      "Epoch: 33\tFidelity = 0.500547\tKL_Divergence = 3.939358\n",
      "Epoch: 34\tFidelity = 0.500539\tKL_Divergence = 3.947176\n",
      "Epoch: 35\tFidelity = 0.500580\tKL_Divergence = 3.906433\n",
      "Epoch: 36\tFidelity = 0.500556\tKL_Divergence = 3.929554\n",
      "Epoch: 37\tFidelity = 0.500565\tKL_Divergence = 3.921256\n",
      "Epoch: 38\tFidelity = 0.500533\tKL_Divergence = 3.953725\n",
      "Epoch: 39\tFidelity = 0.500568\tKL_Divergence = 3.918501\n",
      "Epoch: 40\tFidelity = 0.500528\tKL_Divergence = 3.958695\n",
      "Epoch: 41\tFidelity = 0.500596\tKL_Divergence = 3.891282\n",
      "Epoch: 42\tFidelity = 0.500574\tKL_Divergence = 3.912514\n",
      "Epoch: 43\tFidelity = 0.500550\tKL_Divergence = 3.936376\n",
      "Epoch: 44\tFidelity = 0.500520\tKL_Divergence = 3.966650\n",
      "Epoch: 45\tFidelity = 0.500574\tKL_Divergence = 3.912600\n",
      "Epoch: 46\tFidelity = 0.500593\tKL_Divergence = 3.894457\n",
      "Epoch: 47\tFidelity = 0.500551\tKL_Divergence = 3.935448\n",
      "Epoch: 48\tFidelity = 0.500555\tKL_Divergence = 3.930826\n",
      "Epoch: 49\tFidelity = 0.500516\tKL_Divergence = 3.971445\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:20:09,205] Trial 439 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500516\tKL_Divergence = 3.971215\n",
      "Total time elapsed during training: 43.518 s\n",
      "Trial 439 pruned. \n",
      "Epoch: 1\tFidelity = 0.500510\tKL_Divergence = 3.977385\n",
      "Epoch: 2\tFidelity = 0.500570\tKL_Divergence = 3.916613\n",
      "Epoch: 3\tFidelity = 0.500573\tKL_Divergence = 3.913164\n",
      "Epoch: 4\tFidelity = 0.500548\tKL_Divergence = 3.938534\n",
      "Epoch: 5\tFidelity = 0.500559\tKL_Divergence = 3.926843\n",
      "Epoch: 6\tFidelity = 0.500495\tKL_Divergence = 3.994633\n",
      "Epoch: 7\tFidelity = 0.500495\tKL_Divergence = 3.994718\n",
      "Epoch: 8\tFidelity = 0.500505\tKL_Divergence = 3.983203\n",
      "Epoch: 9\tFidelity = 0.500510\tKL_Divergence = 3.977876\n",
      "Epoch: 10\tFidelity = 0.500533\tKL_Divergence = 3.953665\n",
      "Epoch: 11\tFidelity = 0.500569\tKL_Divergence = 3.917282\n",
      "Epoch: 12\tFidelity = 0.500508\tKL_Divergence = 3.980384\n",
      "Epoch: 13\tFidelity = 0.500528\tKL_Divergence = 3.958217\n",
      "Epoch: 14\tFidelity = 0.500491\tKL_Divergence = 3.999336\n",
      "Epoch: 15\tFidelity = 0.500574\tKL_Divergence = 3.912441\n",
      "Epoch: 16\tFidelity = 0.500554\tKL_Divergence = 3.932023\n",
      "Epoch: 17\tFidelity = 0.500606\tKL_Divergence = 3.882171\n",
      "Epoch: 18\tFidelity = 0.500532\tKL_Divergence = 3.954466\n",
      "Epoch: 19\tFidelity = 0.500529\tKL_Divergence = 3.957776\n",
      "Epoch: 20\tFidelity = 0.500521\tKL_Divergence = 3.966236\n",
      "Epoch: 21\tFidelity = 0.500576\tKL_Divergence = 3.910799\n",
      "Epoch: 22\tFidelity = 0.500578\tKL_Divergence = 3.908494\n",
      "Epoch: 23\tFidelity = 0.500592\tKL_Divergence = 3.894962\n",
      "Epoch: 24\tFidelity = 0.500540\tKL_Divergence = 3.946409\n",
      "Epoch: 25\tFidelity = 0.500583\tKL_Divergence = 3.903975\n",
      "Epoch: 26\tFidelity = 0.500529\tKL_Divergence = 3.957320\n",
      "Epoch: 27\tFidelity = 0.500550\tKL_Divergence = 3.936491\n",
      "Epoch: 28\tFidelity = 0.500575\tKL_Divergence = 3.911435\n",
      "Epoch: 29\tFidelity = 0.500584\tKL_Divergence = 3.903151\n",
      "Epoch: 30\tFidelity = 0.500514\tKL_Divergence = 3.973596\n",
      "Epoch: 31\tFidelity = 0.500585\tKL_Divergence = 3.902217\n",
      "Epoch: 32\tFidelity = 0.500507\tKL_Divergence = 3.981190\n",
      "Epoch: 33\tFidelity = 0.500635\tKL_Divergence = 3.856116\n",
      "Epoch: 34\tFidelity = 0.500573\tKL_Divergence = 3.913668\n",
      "Epoch: 35\tFidelity = 0.500583\tKL_Divergence = 3.904022\n",
      "Epoch: 36\tFidelity = 0.500555\tKL_Divergence = 3.930779\n",
      "Epoch: 37\tFidelity = 0.500495\tKL_Divergence = 3.994690\n",
      "Epoch: 38\tFidelity = 0.500559\tKL_Divergence = 3.927283\n",
      "Epoch: 39\tFidelity = 0.500549\tKL_Divergence = 3.936777\n",
      "Epoch: 40\tFidelity = 0.500569\tKL_Divergence = 3.916887\n",
      "Epoch: 41\tFidelity = 0.500547\tKL_Divergence = 3.938713\n",
      "Epoch: 42\tFidelity = 0.500564\tKL_Divergence = 3.921898\n",
      "Epoch: 43\tFidelity = 0.500541\tKL_Divergence = 3.945323\n",
      "Epoch: 44\tFidelity = 0.500469\tKL_Divergence = 4.023984\n",
      "Epoch: 45\tFidelity = 0.500562\tKL_Divergence = 3.923665\n",
      "Epoch: 46\tFidelity = 0.500558\tKL_Divergence = 3.928073\n",
      "Epoch: 47\tFidelity = 0.500521\tKL_Divergence = 3.965740\n",
      "Epoch: 48\tFidelity = 0.500550\tKL_Divergence = 3.935947\n",
      "Epoch: 49\tFidelity = 0.500537\tKL_Divergence = 3.949358\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:20:46,693] Trial 440 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500617\tKL_Divergence = 3.871899\n",
      "Total time elapsed during training: 37.322 s\n",
      "Trial 440 pruned. \n",
      "Epoch: 1\tFidelity = 0.500573\tKL_Divergence = 3.913336\n",
      "Epoch: 2\tFidelity = 0.500559\tKL_Divergence = 3.927062\n",
      "Epoch: 3\tFidelity = 0.500539\tKL_Divergence = 3.946857\n",
      "Epoch: 4\tFidelity = 0.500523\tKL_Divergence = 3.963802\n",
      "Epoch: 5\tFidelity = 0.500518\tKL_Divergence = 3.969460\n",
      "Epoch: 6\tFidelity = 0.500562\tKL_Divergence = 3.924189\n",
      "Epoch: 7\tFidelity = 0.500521\tKL_Divergence = 3.966505\n",
      "Epoch: 8\tFidelity = 0.500553\tKL_Divergence = 3.933007\n",
      "Epoch: 9\tFidelity = 0.500578\tKL_Divergence = 3.908693\n",
      "Epoch: 10\tFidelity = 0.500578\tKL_Divergence = 3.908724\n",
      "Epoch: 11\tFidelity = 0.500582\tKL_Divergence = 3.904681\n",
      "Epoch: 12\tFidelity = 0.500534\tKL_Divergence = 3.952177\n",
      "Epoch: 13\tFidelity = 0.500506\tKL_Divergence = 3.981964\n",
      "Epoch: 14\tFidelity = 0.500550\tKL_Divergence = 3.935828\n",
      "Epoch: 15\tFidelity = 0.500559\tKL_Divergence = 3.927472\n",
      "Epoch: 16\tFidelity = 0.500563\tKL_Divergence = 3.923515\n",
      "Epoch: 17\tFidelity = 0.500515\tKL_Divergence = 3.972083\n",
      "Epoch: 18\tFidelity = 0.500560\tKL_Divergence = 3.925823\n",
      "Epoch: 19\tFidelity = 0.500555\tKL_Divergence = 3.931171\n",
      "Epoch: 20\tFidelity = 0.500540\tKL_Divergence = 3.946247\n",
      "Epoch: 21\tFidelity = 0.500513\tKL_Divergence = 3.974785\n",
      "Epoch: 22\tFidelity = 0.500548\tKL_Divergence = 3.938452\n",
      "Epoch: 23\tFidelity = 0.500538\tKL_Divergence = 3.948751\n",
      "Epoch: 24\tFidelity = 0.500532\tKL_Divergence = 3.954536\n",
      "Epoch: 25\tFidelity = 0.500546\tKL_Divergence = 3.940438\n",
      "Epoch: 26\tFidelity = 0.500574\tKL_Divergence = 3.912427\n",
      "Epoch: 27\tFidelity = 0.500576\tKL_Divergence = 3.910318\n",
      "Epoch: 28\tFidelity = 0.500539\tKL_Divergence = 3.947566\n",
      "Epoch: 29\tFidelity = 0.500572\tKL_Divergence = 3.914688\n",
      "Epoch: 30\tFidelity = 0.500529\tKL_Divergence = 3.957807\n",
      "Epoch: 31\tFidelity = 0.500561\tKL_Divergence = 3.925189\n",
      "Epoch: 32\tFidelity = 0.500590\tKL_Divergence = 3.896690\n",
      "Epoch: 33\tFidelity = 0.500548\tKL_Divergence = 3.937944\n",
      "Epoch: 34\tFidelity = 0.500531\tKL_Divergence = 3.955803\n",
      "Epoch: 35\tFidelity = 0.500548\tKL_Divergence = 3.937855\n",
      "Epoch: 36\tFidelity = 0.500541\tKL_Divergence = 3.945592\n",
      "Epoch: 37\tFidelity = 0.500529\tKL_Divergence = 3.957526\n",
      "Epoch: 38\tFidelity = 0.500559\tKL_Divergence = 3.926583\n",
      "Epoch: 39\tFidelity = 0.500558\tKL_Divergence = 3.927585\n",
      "Epoch: 40\tFidelity = 0.500598\tKL_Divergence = 3.889985\n",
      "Epoch: 41\tFidelity = 0.500537\tKL_Divergence = 3.948884\n",
      "Epoch: 42\tFidelity = 0.500511\tKL_Divergence = 3.976424\n",
      "Epoch: 43\tFidelity = 0.500553\tKL_Divergence = 3.933308\n",
      "Epoch: 44\tFidelity = 0.500529\tKL_Divergence = 3.957496\n",
      "Epoch: 45\tFidelity = 0.500560\tKL_Divergence = 3.925628\n",
      "Epoch: 46\tFidelity = 0.500535\tKL_Divergence = 3.951243\n",
      "Epoch: 47\tFidelity = 0.500575\tKL_Divergence = 3.911674\n",
      "Epoch: 48\tFidelity = 0.500538\tKL_Divergence = 3.947812\n",
      "Epoch: 49\tFidelity = 0.500583\tKL_Divergence = 3.903918\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:21:17,736] Trial 441 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500525\tKL_Divergence = 3.961549\n",
      "Total time elapsed during training: 30.880 s\n",
      "Trial 441 pruned. \n",
      "Epoch: 1\tFidelity = 0.500541\tKL_Divergence = 3.945693\n",
      "Epoch: 2\tFidelity = 0.500584\tKL_Divergence = 3.903008\n",
      "Epoch: 3\tFidelity = 0.500483\tKL_Divergence = 4.007834\n",
      "Epoch: 4\tFidelity = 0.500538\tKL_Divergence = 3.948230\n",
      "Epoch: 5\tFidelity = 0.500538\tKL_Divergence = 3.947929\n",
      "Epoch: 6\tFidelity = 0.500511\tKL_Divergence = 3.977283\n",
      "Epoch: 7\tFidelity = 0.500549\tKL_Divergence = 3.937208\n",
      "Epoch: 8\tFidelity = 0.500596\tKL_Divergence = 3.891299\n",
      "Epoch: 9\tFidelity = 0.500550\tKL_Divergence = 3.936453\n",
      "Epoch: 10\tFidelity = 0.500553\tKL_Divergence = 3.932689\n",
      "Epoch: 11\tFidelity = 0.500557\tKL_Divergence = 3.928954\n",
      "Epoch: 12\tFidelity = 0.500527\tKL_Divergence = 3.959371\n",
      "Epoch: 13\tFidelity = 0.500497\tKL_Divergence = 3.992299\n",
      "Epoch: 14\tFidelity = 0.500592\tKL_Divergence = 3.894758\n",
      "Epoch: 15\tFidelity = 0.500542\tKL_Divergence = 3.944135\n",
      "Epoch: 16\tFidelity = 0.500524\tKL_Divergence = 3.963150\n",
      "Epoch: 17\tFidelity = 0.500526\tKL_Divergence = 3.960888\n",
      "Epoch: 18\tFidelity = 0.500565\tKL_Divergence = 3.921364\n",
      "Epoch: 19\tFidelity = 0.500563\tKL_Divergence = 3.923185\n",
      "Epoch: 20\tFidelity = 0.500535\tKL_Divergence = 3.951798\n",
      "Epoch: 21\tFidelity = 0.500529\tKL_Divergence = 3.957787\n",
      "Epoch: 22\tFidelity = 0.500554\tKL_Divergence = 3.932073\n",
      "Epoch: 23\tFidelity = 0.500558\tKL_Divergence = 3.927717\n",
      "Epoch: 24\tFidelity = 0.500580\tKL_Divergence = 3.906585\n",
      "Epoch: 25\tFidelity = 0.500581\tKL_Divergence = 3.905462\n",
      "Epoch: 26\tFidelity = 0.500517\tKL_Divergence = 3.970127\n",
      "Epoch: 27\tFidelity = 0.500510\tKL_Divergence = 3.978458\n",
      "Epoch: 28\tFidelity = 0.500562\tKL_Divergence = 3.923962\n",
      "Epoch: 29\tFidelity = 0.500552\tKL_Divergence = 3.934274\n",
      "Epoch: 30\tFidelity = 0.500548\tKL_Divergence = 3.937944\n",
      "Epoch: 31\tFidelity = 0.500559\tKL_Divergence = 3.926924\n",
      "Epoch: 32\tFidelity = 0.500511\tKL_Divergence = 3.976562\n",
      "Epoch: 33\tFidelity = 0.500547\tKL_Divergence = 3.939447\n",
      "Epoch: 34\tFidelity = 0.500532\tKL_Divergence = 3.954420\n",
      "Epoch: 35\tFidelity = 0.500542\tKL_Divergence = 3.943965\n",
      "Epoch: 36\tFidelity = 0.500573\tKL_Divergence = 3.913174\n",
      "Epoch: 37\tFidelity = 0.500507\tKL_Divergence = 3.981370\n",
      "Epoch: 38\tFidelity = 0.500586\tKL_Divergence = 3.900969\n",
      "Epoch: 39\tFidelity = 0.500560\tKL_Divergence = 3.926361\n",
      "Epoch: 40\tFidelity = 0.500524\tKL_Divergence = 3.963221\n",
      "Epoch: 41\tFidelity = 0.500564\tKL_Divergence = 3.921774\n",
      "Epoch: 42\tFidelity = 0.500553\tKL_Divergence = 3.932865\n",
      "Epoch: 43\tFidelity = 0.500576\tKL_Divergence = 3.909988\n",
      "Epoch: 44\tFidelity = 0.500516\tKL_Divergence = 3.971344\n",
      "Epoch: 45\tFidelity = 0.500548\tKL_Divergence = 3.938112\n",
      "Epoch: 46\tFidelity = 0.500545\tKL_Divergence = 3.940954\n",
      "Epoch: 47\tFidelity = 0.500587\tKL_Divergence = 3.899705\n",
      "Epoch: 48\tFidelity = 0.500535\tKL_Divergence = 3.951361\n",
      "Epoch: 49\tFidelity = 0.500558\tKL_Divergence = 3.928238\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:22:35,116] Trial 442 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500543\tKL_Divergence = 3.943101\n",
      "Total time elapsed during training: 77.220 s\n",
      "Trial 442 pruned. \n",
      "Epoch: 1\tFidelity = 0.500491\tKL_Divergence = 3.998684\n",
      "Epoch: 2\tFidelity = 0.500588\tKL_Divergence = 3.898633\n",
      "Epoch: 3\tFidelity = 0.500650\tKL_Divergence = 3.843513\n",
      "Epoch: 4\tFidelity = 0.500520\tKL_Divergence = 3.967713\n",
      "Epoch: 5\tFidelity = 0.500486\tKL_Divergence = 4.004703\n",
      "Epoch: 6\tFidelity = 0.500582\tKL_Divergence = 3.904804\n",
      "Epoch: 7\tFidelity = 0.500576\tKL_Divergence = 3.910336\n",
      "Epoch: 8\tFidelity = 0.500563\tKL_Divergence = 3.923096\n",
      "Epoch: 9\tFidelity = 0.500567\tKL_Divergence = 3.919276\n",
      "Epoch: 10\tFidelity = 0.500575\tKL_Divergence = 3.911660\n",
      "Epoch: 11\tFidelity = 0.500562\tKL_Divergence = 3.924275\n",
      "Epoch: 12\tFidelity = 0.500508\tKL_Divergence = 3.979992\n",
      "Epoch: 13\tFidelity = 0.500440\tKL_Divergence = 4.059311\n",
      "Epoch: 14\tFidelity = 0.500524\tKL_Divergence = 3.963260\n",
      "Epoch: 15\tFidelity = 0.500546\tKL_Divergence = 3.940355\n",
      "Epoch: 16\tFidelity = 0.500566\tKL_Divergence = 3.920226\n",
      "Epoch: 17\tFidelity = 0.500566\tKL_Divergence = 3.919884\n",
      "Epoch: 18\tFidelity = 0.500488\tKL_Divergence = 4.002689\n",
      "Epoch: 19\tFidelity = 0.500505\tKL_Divergence = 3.983549\n",
      "Epoch: 20\tFidelity = 0.500464\tKL_Divergence = 4.029835\n",
      "Epoch: 21\tFidelity = 0.500556\tKL_Divergence = 3.929925\n",
      "Epoch: 22\tFidelity = 0.500596\tKL_Divergence = 3.891798\n",
      "Epoch: 23\tFidelity = 0.500468\tKL_Divergence = 4.025380\n",
      "Epoch: 24\tFidelity = 0.500550\tKL_Divergence = 3.935972\n",
      "Epoch: 25\tFidelity = 0.500579\tKL_Divergence = 3.907636\n",
      "Epoch: 26\tFidelity = 0.500553\tKL_Divergence = 3.932700\n",
      "Epoch: 27\tFidelity = 0.500612\tKL_Divergence = 3.876805\n",
      "Epoch: 28\tFidelity = 0.500616\tKL_Divergence = 3.872831\n",
      "Epoch: 29\tFidelity = 0.500572\tKL_Divergence = 3.914560\n",
      "Epoch: 30\tFidelity = 0.500483\tKL_Divergence = 4.008589\n",
      "Epoch: 31\tFidelity = 0.500524\tKL_Divergence = 3.962788\n",
      "Epoch: 32\tFidelity = 0.500613\tKL_Divergence = 3.875854\n",
      "Epoch: 33\tFidelity = 0.500509\tKL_Divergence = 3.978651\n",
      "Epoch: 34\tFidelity = 0.500537\tKL_Divergence = 3.949376\n",
      "Epoch: 35\tFidelity = 0.500442\tKL_Divergence = 4.057002\n",
      "Epoch: 36\tFidelity = 0.500542\tKL_Divergence = 3.944453\n",
      "Epoch: 37\tFidelity = 0.500513\tKL_Divergence = 3.974214\n",
      "Epoch: 38\tFidelity = 0.500486\tKL_Divergence = 4.004394\n",
      "Epoch: 39\tFidelity = 0.500534\tKL_Divergence = 3.951985\n",
      "Epoch: 40\tFidelity = 0.500506\tKL_Divergence = 3.981847\n",
      "Epoch: 41\tFidelity = 0.500461\tKL_Divergence = 4.034067\n",
      "Epoch: 42\tFidelity = 0.500566\tKL_Divergence = 3.920647\n",
      "Epoch: 43\tFidelity = 0.500576\tKL_Divergence = 3.910460\n",
      "Epoch: 44\tFidelity = 0.500607\tKL_Divergence = 3.881121\n",
      "Epoch: 45\tFidelity = 0.500674\tKL_Divergence = 3.823144\n",
      "Epoch: 46\tFidelity = 0.500684\tKL_Divergence = 3.815077\n",
      "Epoch: 47\tFidelity = 0.500522\tKL_Divergence = 3.965476\n",
      "Epoch: 48\tFidelity = 0.500526\tKL_Divergence = 3.961218\n",
      "Epoch: 49\tFidelity = 0.500615\tKL_Divergence = 3.873684\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:23:06,135] Trial 443 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500525\tKL_Divergence = 3.961625\n",
      "Total time elapsed during training: 30.839 s\n",
      "Trial 443 pruned. \n",
      "Epoch: 1\tFidelity = 0.500594\tKL_Divergence = 3.892938\n",
      "Epoch: 2\tFidelity = 0.500567\tKL_Divergence = 3.919194\n",
      "Epoch: 3\tFidelity = 0.500547\tKL_Divergence = 3.938583\n",
      "Epoch: 4\tFidelity = 0.500543\tKL_Divergence = 3.943612\n",
      "Epoch: 5\tFidelity = 0.500544\tKL_Divergence = 3.942238\n",
      "Epoch: 6\tFidelity = 0.500548\tKL_Divergence = 3.938091\n",
      "Epoch: 7\tFidelity = 0.500535\tKL_Divergence = 3.951159\n",
      "Epoch: 8\tFidelity = 0.500580\tKL_Divergence = 3.906718\n",
      "Epoch: 9\tFidelity = 0.500570\tKL_Divergence = 3.915769\n",
      "Epoch: 10\tFidelity = 0.500521\tKL_Divergence = 3.966040\n",
      "Epoch: 11\tFidelity = 0.500577\tKL_Divergence = 3.909828\n",
      "Epoch: 12\tFidelity = 0.500514\tKL_Divergence = 3.973209\n",
      "Epoch: 13\tFidelity = 0.500500\tKL_Divergence = 3.988773\n",
      "Epoch: 14\tFidelity = 0.500522\tKL_Divergence = 3.965216\n",
      "Epoch: 15\tFidelity = 0.500569\tKL_Divergence = 3.917570\n",
      "Epoch: 16\tFidelity = 0.500542\tKL_Divergence = 3.943809\n",
      "Epoch: 17\tFidelity = 0.500494\tKL_Divergence = 3.995604\n",
      "Epoch: 18\tFidelity = 0.500559\tKL_Divergence = 3.927276\n",
      "Epoch: 19\tFidelity = 0.500575\tKL_Divergence = 3.910889\n",
      "Epoch: 20\tFidelity = 0.500574\tKL_Divergence = 3.911929\n",
      "Epoch: 21\tFidelity = 0.500576\tKL_Divergence = 3.910342\n",
      "Epoch: 22\tFidelity = 0.500554\tKL_Divergence = 3.932252\n",
      "Epoch: 23\tFidelity = 0.500540\tKL_Divergence = 3.945904\n",
      "Epoch: 24\tFidelity = 0.500577\tKL_Divergence = 3.909811\n",
      "Epoch: 25\tFidelity = 0.500537\tKL_Divergence = 3.948853\n",
      "Epoch: 26\tFidelity = 0.500551\tKL_Divergence = 3.934981\n",
      "Epoch: 27\tFidelity = 0.500504\tKL_Divergence = 3.984104\n",
      "Epoch: 28\tFidelity = 0.500501\tKL_Divergence = 3.987339\n",
      "Epoch: 29\tFidelity = 0.500561\tKL_Divergence = 3.924542\n",
      "Epoch: 30\tFidelity = 0.500554\tKL_Divergence = 3.932278\n",
      "Epoch: 31\tFidelity = 0.500530\tKL_Divergence = 3.956054\n",
      "Epoch: 32\tFidelity = 0.500559\tKL_Divergence = 3.927445\n",
      "Epoch: 33\tFidelity = 0.500549\tKL_Divergence = 3.937137\n",
      "Epoch: 34\tFidelity = 0.500560\tKL_Divergence = 3.925864\n",
      "Epoch: 35\tFidelity = 0.500547\tKL_Divergence = 3.939423\n",
      "Epoch: 36\tFidelity = 0.500558\tKL_Divergence = 3.928457\n",
      "Epoch: 37\tFidelity = 0.500537\tKL_Divergence = 3.949244\n",
      "Epoch: 38\tFidelity = 0.500553\tKL_Divergence = 3.933369\n",
      "Epoch: 39\tFidelity = 0.500552\tKL_Divergence = 3.933960\n",
      "Epoch: 40\tFidelity = 0.500528\tKL_Divergence = 3.958194\n",
      "Epoch: 41\tFidelity = 0.500575\tKL_Divergence = 3.910962\n",
      "Epoch: 42\tFidelity = 0.500512\tKL_Divergence = 3.975910\n",
      "Epoch: 43\tFidelity = 0.500532\tKL_Divergence = 3.954208\n",
      "Epoch: 44\tFidelity = 0.500588\tKL_Divergence = 3.898534\n",
      "Epoch: 45\tFidelity = 0.500506\tKL_Divergence = 3.982215\n",
      "Epoch: 46\tFidelity = 0.500543\tKL_Divergence = 3.942650\n",
      "Epoch: 47\tFidelity = 0.500560\tKL_Divergence = 3.926232\n",
      "Epoch: 48\tFidelity = 0.500550\tKL_Divergence = 3.935523\n",
      "Epoch: 49\tFidelity = 0.500544\tKL_Divergence = 3.941951\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:23:44,034] Trial 444 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500540\tKL_Divergence = 3.946496\n",
      "Total time elapsed during training: 37.708 s\n",
      "Trial 444 pruned. \n",
      "Epoch: 1\tFidelity = 0.500518\tKL_Divergence = 3.968942\n",
      "Epoch: 2\tFidelity = 0.500576\tKL_Divergence = 3.910856\n",
      "Epoch: 3\tFidelity = 0.500597\tKL_Divergence = 3.890215\n",
      "Epoch: 4\tFidelity = 0.500546\tKL_Divergence = 3.939957\n",
      "Epoch: 5\tFidelity = 0.500558\tKL_Divergence = 3.928236\n",
      "Epoch: 6\tFidelity = 0.500544\tKL_Divergence = 3.942146\n",
      "Epoch: 7\tFidelity = 0.500531\tKL_Divergence = 3.955724\n",
      "Epoch: 8\tFidelity = 0.500583\tKL_Divergence = 3.903182\n",
      "Epoch: 9\tFidelity = 0.500481\tKL_Divergence = 4.010346\n",
      "Epoch: 10\tFidelity = 0.500574\tKL_Divergence = 3.911754\n",
      "Epoch: 11\tFidelity = 0.500524\tKL_Divergence = 3.963155\n",
      "Epoch: 12\tFidelity = 0.500561\tKL_Divergence = 3.925502\n",
      "Epoch: 13\tFidelity = 0.500584\tKL_Divergence = 3.902228\n",
      "Epoch: 14\tFidelity = 0.500626\tKL_Divergence = 3.864256\n",
      "Epoch: 15\tFidelity = 0.500529\tKL_Divergence = 3.957317\n",
      "Epoch: 16\tFidelity = 0.500535\tKL_Divergence = 3.951812\n",
      "Epoch: 17\tFidelity = 0.500517\tKL_Divergence = 3.970319\n",
      "Epoch: 18\tFidelity = 0.500603\tKL_Divergence = 3.884707\n",
      "Epoch: 19\tFidelity = 0.500509\tKL_Divergence = 3.979156\n",
      "Epoch: 20\tFidelity = 0.500488\tKL_Divergence = 4.002590\n",
      "Epoch: 21\tFidelity = 0.500478\tKL_Divergence = 4.013971\n",
      "Epoch: 22\tFidelity = 0.500583\tKL_Divergence = 3.903997\n",
      "Epoch: 23\tFidelity = 0.500535\tKL_Divergence = 3.950949\n",
      "Epoch: 24\tFidelity = 0.500579\tKL_Divergence = 3.907324\n",
      "Epoch: 25\tFidelity = 0.500525\tKL_Divergence = 3.961467\n",
      "Epoch: 26\tFidelity = 0.500532\tKL_Divergence = 3.953756\n",
      "Epoch: 27\tFidelity = 0.500578\tKL_Divergence = 3.908278\n",
      "Epoch: 28\tFidelity = 0.500498\tKL_Divergence = 3.990938\n",
      "Epoch: 29\tFidelity = 0.500451\tKL_Divergence = 4.046514\n",
      "Epoch: 30\tFidelity = 0.500460\tKL_Divergence = 4.034986\n",
      "Epoch: 31\tFidelity = 0.500518\tKL_Divergence = 3.969716\n",
      "Epoch: 32\tFidelity = 0.500555\tKL_Divergence = 3.931029\n",
      "Epoch: 33\tFidelity = 0.500587\tKL_Divergence = 3.900245\n",
      "Epoch: 34\tFidelity = 0.500576\tKL_Divergence = 3.910618\n",
      "Epoch: 35\tFidelity = 0.500467\tKL_Divergence = 4.027290\n",
      "Epoch: 36\tFidelity = 0.500557\tKL_Divergence = 3.929020\n",
      "Epoch: 37\tFidelity = 0.500596\tKL_Divergence = 3.891183\n",
      "Epoch: 38\tFidelity = 0.500570\tKL_Divergence = 3.915983\n",
      "Epoch: 39\tFidelity = 0.500482\tKL_Divergence = 4.008546\n",
      "Epoch: 40\tFidelity = 0.500543\tKL_Divergence = 3.942776\n",
      "Epoch: 41\tFidelity = 0.500625\tKL_Divergence = 3.865241\n",
      "Epoch: 42\tFidelity = 0.500606\tKL_Divergence = 3.882492\n",
      "Epoch: 43\tFidelity = 0.500566\tKL_Divergence = 3.920145\n",
      "Epoch: 44\tFidelity = 0.500573\tKL_Divergence = 3.912864\n",
      "Epoch: 45\tFidelity = 0.500503\tKL_Divergence = 3.985105\n",
      "Epoch: 46\tFidelity = 0.500484\tKL_Divergence = 4.005599\n",
      "Epoch: 47\tFidelity = 0.500537\tKL_Divergence = 3.947721\n",
      "Epoch: 48\tFidelity = 0.500541\tKL_Divergence = 3.942734\n",
      "Epoch: 49\tFidelity = 0.500571\tKL_Divergence = 3.913586\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:24:20,789] Trial 445 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500582\tKL_Divergence = 3.902876\n",
      "Total time elapsed during training: 36.577 s\n",
      "Trial 445 pruned. \n",
      "Epoch: 1\tFidelity = 0.500536\tKL_Divergence = 3.948186\n",
      "Epoch: 2\tFidelity = 0.500583\tKL_Divergence = 3.901590\n",
      "Epoch: 3\tFidelity = 0.500575\tKL_Divergence = 3.909179\n",
      "Epoch: 4\tFidelity = 0.500499\tKL_Divergence = 3.987929\n",
      "Epoch: 5\tFidelity = 0.500551\tKL_Divergence = 3.933563\n",
      "Epoch: 6\tFidelity = 0.500509\tKL_Divergence = 3.977113\n",
      "Epoch: 7\tFidelity = 0.500487\tKL_Divergence = 4.002058\n",
      "Epoch: 8\tFidelity = 0.500513\tKL_Divergence = 3.972816\n",
      "Epoch: 9\tFidelity = 0.500535\tKL_Divergence = 3.950192\n",
      "Epoch: 10\tFidelity = 0.500613\tKL_Divergence = 3.874936\n",
      "Epoch: 11\tFidelity = 0.500542\tKL_Divergence = 3.943287\n",
      "Epoch: 12\tFidelity = 0.500554\tKL_Divergence = 3.931849\n",
      "Epoch: 13\tFidelity = 0.500554\tKL_Divergence = 3.931661\n",
      "Epoch: 14\tFidelity = 0.500589\tKL_Divergence = 3.897914\n",
      "Epoch: 15\tFidelity = 0.500538\tKL_Divergence = 3.948126\n",
      "Epoch: 16\tFidelity = 0.500578\tKL_Divergence = 3.908198\n",
      "Epoch: 17\tFidelity = 0.500574\tKL_Divergence = 3.911748\n",
      "Epoch: 18\tFidelity = 0.500595\tKL_Divergence = 3.891666\n",
      "Epoch: 19\tFidelity = 0.500556\tKL_Divergence = 3.929827\n",
      "Epoch: 20\tFidelity = 0.500553\tKL_Divergence = 3.931889\n",
      "Epoch: 21\tFidelity = 0.500535\tKL_Divergence = 3.950540\n",
      "Epoch: 22\tFidelity = 0.500593\tKL_Divergence = 3.893880\n",
      "Epoch: 23\tFidelity = 0.500547\tKL_Divergence = 3.938771\n",
      "Epoch: 24\tFidelity = 0.500614\tKL_Divergence = 3.874619\n",
      "Epoch: 25\tFidelity = 0.500548\tKL_Divergence = 3.937976\n",
      "Epoch: 26\tFidelity = 0.500563\tKL_Divergence = 3.922645\n",
      "Epoch: 27\tFidelity = 0.500630\tKL_Divergence = 3.860698\n",
      "Epoch: 28\tFidelity = 0.500577\tKL_Divergence = 3.909437\n",
      "Epoch: 29\tFidelity = 0.500578\tKL_Divergence = 3.908083\n",
      "Epoch: 30\tFidelity = 0.500629\tKL_Divergence = 3.861826\n",
      "Epoch: 31\tFidelity = 0.500576\tKL_Divergence = 3.910071\n",
      "Epoch: 32\tFidelity = 0.500571\tKL_Divergence = 3.915320\n",
      "Epoch: 33\tFidelity = 0.500586\tKL_Divergence = 3.900804\n",
      "Epoch: 34\tFidelity = 0.500527\tKL_Divergence = 3.960224\n",
      "Epoch: 35\tFidelity = 0.500532\tKL_Divergence = 3.954273\n",
      "Epoch: 36\tFidelity = 0.500581\tKL_Divergence = 3.905958\n",
      "Epoch: 37\tFidelity = 0.500536\tKL_Divergence = 3.950605\n",
      "Epoch: 38\tFidelity = 0.500517\tKL_Divergence = 3.969939\n",
      "Epoch: 39\tFidelity = 0.500511\tKL_Divergence = 3.976990\n",
      "Epoch: 40\tFidelity = 0.500569\tKL_Divergence = 3.916926\n",
      "Epoch: 41\tFidelity = 0.500593\tKL_Divergence = 3.893958\n",
      "Epoch: 42\tFidelity = 0.500623\tKL_Divergence = 3.866574\n",
      "Epoch: 43\tFidelity = 0.500609\tKL_Divergence = 3.879426\n",
      "Epoch: 44\tFidelity = 0.500531\tKL_Divergence = 3.955493\n",
      "Epoch: 45\tFidelity = 0.500525\tKL_Divergence = 3.961797\n",
      "Epoch: 46\tFidelity = 0.500522\tKL_Divergence = 3.965279\n",
      "Epoch: 47\tFidelity = 0.500528\tKL_Divergence = 3.958278\n",
      "Epoch: 48\tFidelity = 0.500511\tKL_Divergence = 3.977035\n",
      "Epoch: 49\tFidelity = 0.500544\tKL_Divergence = 3.941557\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:25:03,815] Trial 446 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500542\tKL_Divergence = 3.944115\n",
      "Total time elapsed during training: 42.864 s\n",
      "Trial 446 pruned. \n",
      "Epoch: 1\tFidelity = 0.500568\tKL_Divergence = 3.917753\n",
      "Epoch: 2\tFidelity = 0.500537\tKL_Divergence = 3.949485\n",
      "Epoch: 3\tFidelity = 0.500522\tKL_Divergence = 3.964591\n",
      "Epoch: 4\tFidelity = 0.500538\tKL_Divergence = 3.948697\n",
      "Epoch: 5\tFidelity = 0.500518\tKL_Divergence = 3.969016\n",
      "Epoch: 6\tFidelity = 0.500512\tKL_Divergence = 3.975575\n",
      "Epoch: 7\tFidelity = 0.500559\tKL_Divergence = 3.927001\n",
      "Epoch: 8\tFidelity = 0.500555\tKL_Divergence = 3.930663\n",
      "Epoch: 9\tFidelity = 0.500558\tKL_Divergence = 3.928251\n",
      "Epoch: 10\tFidelity = 0.500557\tKL_Divergence = 3.929354\n",
      "Epoch: 11\tFidelity = 0.500573\tKL_Divergence = 3.912793\n",
      "Epoch: 12\tFidelity = 0.500539\tKL_Divergence = 3.946853\n",
      "Epoch: 13\tFidelity = 0.500523\tKL_Divergence = 3.963864\n",
      "Epoch: 14\tFidelity = 0.500554\tKL_Divergence = 3.932214\n",
      "Epoch: 15\tFidelity = 0.500550\tKL_Divergence = 3.935516\n",
      "Epoch: 16\tFidelity = 0.500575\tKL_Divergence = 3.911154\n",
      "Epoch: 17\tFidelity = 0.500542\tKL_Divergence = 3.944094\n",
      "Epoch: 18\tFidelity = 0.500560\tKL_Divergence = 3.926384\n",
      "Epoch: 19\tFidelity = 0.500540\tKL_Divergence = 3.945881\n",
      "Epoch: 20\tFidelity = 0.500539\tKL_Divergence = 3.946734\n",
      "Epoch: 21\tFidelity = 0.500526\tKL_Divergence = 3.960405\n",
      "Epoch: 22\tFidelity = 0.500595\tKL_Divergence = 3.892679\n",
      "Epoch: 23\tFidelity = 0.500536\tKL_Divergence = 3.950251\n",
      "Epoch: 24\tFidelity = 0.500580\tKL_Divergence = 3.906428\n",
      "Epoch: 25\tFidelity = 0.500587\tKL_Divergence = 3.899978\n",
      "Epoch: 26\tFidelity = 0.500533\tKL_Divergence = 3.953265\n",
      "Epoch: 27\tFidelity = 0.500565\tKL_Divergence = 3.920744\n",
      "Epoch: 28\tFidelity = 0.500541\tKL_Divergence = 3.944825\n",
      "Epoch: 29\tFidelity = 0.500572\tKL_Divergence = 3.914301\n",
      "Epoch: 30\tFidelity = 0.500535\tKL_Divergence = 3.951063\n",
      "Epoch: 31\tFidelity = 0.500544\tKL_Divergence = 3.941608\n",
      "Epoch: 32\tFidelity = 0.500572\tKL_Divergence = 3.914068\n",
      "Epoch: 33\tFidelity = 0.500585\tKL_Divergence = 3.901458\n",
      "Epoch: 34\tFidelity = 0.500567\tKL_Divergence = 3.918851\n",
      "Epoch: 35\tFidelity = 0.500550\tKL_Divergence = 3.935746\n",
      "Epoch: 36\tFidelity = 0.500559\tKL_Divergence = 3.926876\n",
      "Epoch: 37\tFidelity = 0.500571\tKL_Divergence = 3.915238\n",
      "Epoch: 38\tFidelity = 0.500546\tKL_Divergence = 3.940011\n",
      "Epoch: 39\tFidelity = 0.500564\tKL_Divergence = 3.921710\n",
      "Epoch: 40\tFidelity = 0.500551\tKL_Divergence = 3.934707\n",
      "Epoch: 41\tFidelity = 0.500550\tKL_Divergence = 3.935628\n",
      "Epoch: 42\tFidelity = 0.500595\tKL_Divergence = 3.892733\n",
      "Epoch: 43\tFidelity = 0.500590\tKL_Divergence = 3.896810\n",
      "Epoch: 44\tFidelity = 0.500542\tKL_Divergence = 3.944396\n",
      "Epoch: 45\tFidelity = 0.500566\tKL_Divergence = 3.919683\n",
      "Epoch: 46\tFidelity = 0.500593\tKL_Divergence = 3.894147\n",
      "Epoch: 47\tFidelity = 0.500612\tKL_Divergence = 3.876982\n",
      "Epoch: 48\tFidelity = 0.500551\tKL_Divergence = 3.935169\n",
      "Epoch: 49\tFidelity = 0.500519\tKL_Divergence = 3.968538\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:25:47,905] Trial 447 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500562\tKL_Divergence = 3.923871\n",
      "Total time elapsed during training: 43.918 s\n",
      "Trial 447 pruned. \n",
      "Epoch: 1\tFidelity = 0.500626\tKL_Divergence = 3.864282\n",
      "Epoch: 2\tFidelity = 0.500569\tKL_Divergence = 3.917284\n",
      "Epoch: 3\tFidelity = 0.500531\tKL_Divergence = 3.955473\n",
      "Epoch: 4\tFidelity = 0.500538\tKL_Divergence = 3.948538\n",
      "Epoch: 5\tFidelity = 0.500600\tKL_Divergence = 3.887631\n",
      "Epoch: 6\tFidelity = 0.500512\tKL_Divergence = 3.976155\n",
      "Epoch: 7\tFidelity = 0.500587\tKL_Divergence = 3.899510\n",
      "Epoch: 8\tFidelity = 0.500554\tKL_Divergence = 3.931945\n",
      "Epoch: 9\tFidelity = 0.500515\tKL_Divergence = 3.972794\n",
      "Epoch: 10\tFidelity = 0.500500\tKL_Divergence = 3.989409\n",
      "Epoch: 11\tFidelity = 0.500532\tKL_Divergence = 3.954449\n",
      "Epoch: 12\tFidelity = 0.500535\tKL_Divergence = 3.951019\n",
      "Epoch: 13\tFidelity = 0.500482\tKL_Divergence = 4.008828\n",
      "Epoch: 14\tFidelity = 0.500534\tKL_Divergence = 3.952372\n",
      "Epoch: 15\tFidelity = 0.500589\tKL_Divergence = 3.897891\n",
      "Epoch: 16\tFidelity = 0.500506\tKL_Divergence = 3.982273\n",
      "Epoch: 17\tFidelity = 0.500543\tKL_Divergence = 3.942823\n",
      "Epoch: 18\tFidelity = 0.500467\tKL_Divergence = 4.026951\n",
      "Epoch: 19\tFidelity = 0.500612\tKL_Divergence = 3.877158\n",
      "Epoch: 20\tFidelity = 0.500576\tKL_Divergence = 3.909964\n",
      "Epoch: 21\tFidelity = 0.500519\tKL_Divergence = 3.968226\n",
      "Epoch: 22\tFidelity = 0.500560\tKL_Divergence = 3.925830\n",
      "Epoch: 23\tFidelity = 0.500552\tKL_Divergence = 3.933596\n",
      "Epoch: 24\tFidelity = 0.500550\tKL_Divergence = 3.936095\n",
      "Epoch: 25\tFidelity = 0.500587\tKL_Divergence = 3.900067\n",
      "Epoch: 26\tFidelity = 0.500533\tKL_Divergence = 3.953848\n",
      "Epoch: 27\tFidelity = 0.500485\tKL_Divergence = 4.005533\n",
      "Epoch: 28\tFidelity = 0.500608\tKL_Divergence = 3.880279\n",
      "Epoch: 29\tFidelity = 0.500607\tKL_Divergence = 3.881715\n",
      "Epoch: 30\tFidelity = 0.500495\tKL_Divergence = 3.994959\n",
      "Epoch: 31\tFidelity = 0.500513\tKL_Divergence = 3.974870\n",
      "Epoch: 32\tFidelity = 0.500550\tKL_Divergence = 3.936444\n",
      "Epoch: 33\tFidelity = 0.500485\tKL_Divergence = 4.006147\n",
      "Epoch: 34\tFidelity = 0.500559\tKL_Divergence = 3.926981\n",
      "Epoch: 35\tFidelity = 0.500600\tKL_Divergence = 3.887476\n",
      "Epoch: 36\tFidelity = 0.500577\tKL_Divergence = 3.909218\n",
      "Epoch: 37\tFidelity = 0.500552\tKL_Divergence = 3.934249\n",
      "Epoch: 38\tFidelity = 0.500549\tKL_Divergence = 3.937342\n",
      "Epoch: 39\tFidelity = 0.500561\tKL_Divergence = 3.925358\n",
      "Epoch: 40\tFidelity = 0.500597\tKL_Divergence = 3.890148\n",
      "Epoch: 41\tFidelity = 0.500556\tKL_Divergence = 3.930163\n",
      "Epoch: 42\tFidelity = 0.500556\tKL_Divergence = 3.930459\n",
      "Epoch: 43\tFidelity = 0.500522\tKL_Divergence = 3.964657\n",
      "Epoch: 44\tFidelity = 0.500487\tKL_Divergence = 4.003735\n",
      "Epoch: 45\tFidelity = 0.500505\tKL_Divergence = 3.983403\n",
      "Epoch: 46\tFidelity = 0.500536\tKL_Divergence = 3.950062\n",
      "Epoch: 47\tFidelity = 0.500476\tKL_Divergence = 4.016615\n",
      "Epoch: 48\tFidelity = 0.500487\tKL_Divergence = 4.003178\n",
      "Epoch: 49\tFidelity = 0.500502\tKL_Divergence = 3.987050\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:27:08,250] Trial 448 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500529\tKL_Divergence = 3.957723\n",
      "Total time elapsed during training: 80.168 s\n",
      "Trial 448 pruned. \n",
      "Epoch: 1\tFidelity = 0.500579\tKL_Divergence = 3.907645\n",
      "Epoch: 2\tFidelity = 0.500466\tKL_Divergence = 4.027523\n",
      "Epoch: 3\tFidelity = 0.500461\tKL_Divergence = 4.034547\n",
      "Epoch: 4\tFidelity = 0.500609\tKL_Divergence = 3.879155\n",
      "Epoch: 5\tFidelity = 0.500625\tKL_Divergence = 3.864931\n",
      "Epoch: 6\tFidelity = 0.500519\tKL_Divergence = 3.968663\n",
      "Epoch: 7\tFidelity = 0.500545\tKL_Divergence = 3.940866\n",
      "Epoch: 8\tFidelity = 0.500521\tKL_Divergence = 3.965945\n",
      "Epoch: 9\tFidelity = 0.500643\tKL_Divergence = 3.849013\n",
      "Epoch: 10\tFidelity = 0.500628\tKL_Divergence = 3.862121\n",
      "Epoch: 11\tFidelity = 0.500547\tKL_Divergence = 3.938935\n",
      "Epoch: 12\tFidelity = 0.500585\tKL_Divergence = 3.901922\n",
      "Epoch: 13\tFidelity = 0.500628\tKL_Divergence = 3.862579\n",
      "Epoch: 14\tFidelity = 0.500603\tKL_Divergence = 3.884654\n",
      "Epoch: 15\tFidelity = 0.500553\tKL_Divergence = 3.933321\n",
      "Epoch: 16\tFidelity = 0.500520\tKL_Divergence = 3.966899\n",
      "Epoch: 17\tFidelity = 0.500437\tKL_Divergence = 4.063096\n",
      "Epoch: 18\tFidelity = 0.500555\tKL_Divergence = 3.930565\n",
      "Epoch: 19\tFidelity = 0.500631\tKL_Divergence = 3.859831\n",
      "Epoch: 20\tFidelity = 0.500565\tKL_Divergence = 3.920684\n",
      "Epoch: 21\tFidelity = 0.500438\tKL_Divergence = 4.062499\n",
      "Epoch: 22\tFidelity = 0.500509\tKL_Divergence = 3.978420\n",
      "Epoch: 23\tFidelity = 0.500550\tKL_Divergence = 3.935560\n",
      "Epoch: 24\tFidelity = 0.500430\tKL_Divergence = 4.072199\n",
      "Epoch: 25\tFidelity = 0.500450\tKL_Divergence = 4.047245\n",
      "Epoch: 26\tFidelity = 0.500533\tKL_Divergence = 3.953486\n",
      "Epoch: 27\tFidelity = 0.500560\tKL_Divergence = 3.925619\n",
      "Epoch: 28\tFidelity = 0.500472\tKL_Divergence = 4.020988\n",
      "Epoch: 29\tFidelity = 0.500522\tKL_Divergence = 3.964995\n",
      "Epoch: 30\tFidelity = 0.500515\tKL_Divergence = 3.972570\n",
      "Epoch: 31\tFidelity = 0.500491\tKL_Divergence = 3.998901\n",
      "Epoch: 32\tFidelity = 0.500498\tKL_Divergence = 3.991200\n",
      "Epoch: 33\tFidelity = 0.500597\tKL_Divergence = 3.890994\n",
      "Epoch: 34\tFidelity = 0.500570\tKL_Divergence = 3.915775\n",
      "Epoch: 35\tFidelity = 0.500617\tKL_Divergence = 3.872162\n",
      "Epoch: 36\tFidelity = 0.500609\tKL_Divergence = 3.879693\n",
      "Epoch: 37\tFidelity = 0.500443\tKL_Divergence = 4.055751\n",
      "Epoch: 38\tFidelity = 0.500498\tKL_Divergence = 3.991580\n",
      "Epoch: 39\tFidelity = 0.500591\tKL_Divergence = 3.896301\n",
      "Epoch: 40\tFidelity = 0.500561\tKL_Divergence = 3.924600\n",
      "Epoch: 41\tFidelity = 0.500489\tKL_Divergence = 4.000696\n",
      "Epoch: 42\tFidelity = 0.500592\tKL_Divergence = 3.894971\n",
      "Epoch: 43\tFidelity = 0.500541\tKL_Divergence = 3.945028\n",
      "Epoch: 44\tFidelity = 0.500420\tKL_Divergence = 4.085646\n",
      "Epoch: 45\tFidelity = 0.500459\tKL_Divergence = 4.036499\n",
      "Epoch: 46\tFidelity = 0.500466\tKL_Divergence = 4.028084\n",
      "Epoch: 47\tFidelity = 0.500484\tKL_Divergence = 4.006582\n",
      "Epoch: 48\tFidelity = 0.500500\tKL_Divergence = 3.989132\n",
      "Epoch: 49\tFidelity = 0.500519\tKL_Divergence = 3.967779\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:27:46,631] Trial 449 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500606\tKL_Divergence = 3.882619\n",
      "Total time elapsed during training: 38.202 s\n",
      "Trial 449 pruned. \n",
      "Epoch: 1\tFidelity = 0.500573\tKL_Divergence = 3.912902\n",
      "Epoch: 2\tFidelity = 0.500480\tKL_Divergence = 4.011143\n",
      "Epoch: 3\tFidelity = 0.500453\tKL_Divergence = 4.043718\n",
      "Epoch: 4\tFidelity = 0.500450\tKL_Divergence = 4.047074\n",
      "Epoch: 5\tFidelity = 0.500551\tKL_Divergence = 3.934688\n",
      "Epoch: 6\tFidelity = 0.500448\tKL_Divergence = 4.049613\n",
      "Epoch: 7\tFidelity = 0.500461\tKL_Divergence = 4.033522\n",
      "Epoch: 8\tFidelity = 0.500504\tKL_Divergence = 3.984006\n",
      "Epoch: 9\tFidelity = 0.500455\tKL_Divergence = 4.039527\n",
      "Epoch: 10\tFidelity = 0.500466\tKL_Divergence = 4.027078\n",
      "Epoch: 11\tFidelity = 0.500514\tKL_Divergence = 3.973915\n",
      "Epoch: 12\tFidelity = 0.500449\tKL_Divergence = 4.047204\n",
      "Epoch: 13\tFidelity = 0.500429\tKL_Divergence = 4.072504\n",
      "Epoch: 14\tFidelity = 0.500556\tKL_Divergence = 3.929155\n",
      "Epoch: 15\tFidelity = 0.500441\tKL_Divergence = 4.059097\n",
      "Epoch: 16\tFidelity = 0.500472\tKL_Divergence = 4.018895\n",
      "Epoch: 17\tFidelity = 0.500541\tKL_Divergence = 3.942982\n",
      "Epoch: 18\tFidelity = 0.500404\tKL_Divergence = 4.105800\n",
      "Epoch: 19\tFidelity = 0.500493\tKL_Divergence = 3.995072\n",
      "Epoch: 20\tFidelity = 0.500617\tKL_Divergence = 3.871121\n",
      "Epoch: 21\tFidelity = 0.500467\tKL_Divergence = 4.026097\n",
      "Epoch: 22\tFidelity = 0.500473\tKL_Divergence = 4.019465\n",
      "Epoch: 23\tFidelity = 0.500555\tKL_Divergence = 3.930582\n",
      "Epoch: 24\tFidelity = 0.500524\tKL_Divergence = 3.962127\n",
      "Epoch: 25\tFidelity = 0.500517\tKL_Divergence = 3.968626\n",
      "Epoch: 26\tFidelity = 0.500441\tKL_Divergence = 4.056825\n",
      "Epoch: 27\tFidelity = 0.500475\tKL_Divergence = 4.016731\n",
      "Epoch: 28\tFidelity = 0.500583\tKL_Divergence = 3.903896\n",
      "Epoch: 29\tFidelity = 0.500549\tKL_Divergence = 3.936813\n",
      "Epoch: 30\tFidelity = 0.500550\tKL_Divergence = 3.935946\n",
      "Epoch: 31\tFidelity = 0.500452\tKL_Divergence = 4.045054\n",
      "Epoch: 32\tFidelity = 0.500524\tKL_Divergence = 3.963131\n",
      "Epoch: 33\tFidelity = 0.500488\tKL_Divergence = 4.002460\n",
      "Epoch: 34\tFidelity = 0.500670\tKL_Divergence = 3.826401\n",
      "Epoch: 35\tFidelity = 0.500612\tKL_Divergence = 3.876834\n",
      "Epoch: 36\tFidelity = 0.500584\tKL_Divergence = 3.902302\n",
      "Epoch: 37\tFidelity = 0.500527\tKL_Divergence = 3.959364\n",
      "Epoch: 38\tFidelity = 0.500629\tKL_Divergence = 3.860964\n",
      "Epoch: 39\tFidelity = 0.500615\tKL_Divergence = 3.873887\n",
      "Epoch: 40\tFidelity = 0.500532\tKL_Divergence = 3.953819\n",
      "Epoch: 41\tFidelity = 0.500480\tKL_Divergence = 4.011414\n",
      "Epoch: 42\tFidelity = 0.500472\tKL_Divergence = 4.020641\n",
      "Epoch: 43\tFidelity = 0.500637\tKL_Divergence = 3.854206\n",
      "Epoch: 44\tFidelity = 0.500514\tKL_Divergence = 3.973407\n",
      "Epoch: 45\tFidelity = 0.500555\tKL_Divergence = 3.930570\n",
      "Epoch: 46\tFidelity = 0.500510\tKL_Divergence = 3.977856\n",
      "Epoch: 47\tFidelity = 0.500575\tKL_Divergence = 3.911200\n",
      "Epoch: 48\tFidelity = 0.500504\tKL_Divergence = 3.984700\n",
      "Epoch: 49\tFidelity = 0.500601\tKL_Divergence = 3.886865\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:28:24,700] Trial 450 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500453\tKL_Divergence = 4.043431\n",
      "Total time elapsed during training: 37.901 s\n",
      "Trial 450 pruned. \n",
      "Epoch: 1\tFidelity = 0.500517\tKL_Divergence = 3.970000\n",
      "Epoch: 2\tFidelity = 0.500509\tKL_Divergence = 3.979216\n",
      "Epoch: 3\tFidelity = 0.500578\tKL_Divergence = 3.908417\n",
      "Epoch: 4\tFidelity = 0.500616\tKL_Divergence = 3.873290\n",
      "Epoch: 5\tFidelity = 0.500650\tKL_Divergence = 3.843526\n",
      "Epoch: 6\tFidelity = 0.500526\tKL_Divergence = 3.961117\n",
      "Epoch: 7\tFidelity = 0.500510\tKL_Divergence = 3.977370\n",
      "Epoch: 8\tFidelity = 0.500652\tKL_Divergence = 3.841338\n",
      "Epoch: 9\tFidelity = 0.500611\tKL_Divergence = 3.877831\n",
      "Epoch: 10\tFidelity = 0.500575\tKL_Divergence = 3.911041\n",
      "Epoch: 11\tFidelity = 0.500461\tKL_Divergence = 4.033984\n",
      "Epoch: 12\tFidelity = 0.500601\tKL_Divergence = 3.886820\n",
      "Epoch: 13\tFidelity = 0.500578\tKL_Divergence = 3.908847\n",
      "Epoch: 14\tFidelity = 0.500505\tKL_Divergence = 3.983442\n",
      "Epoch: 15\tFidelity = 0.500478\tKL_Divergence = 4.013557\n",
      "Epoch: 16\tFidelity = 0.500523\tKL_Divergence = 3.963996\n",
      "Epoch: 17\tFidelity = 0.500610\tKL_Divergence = 3.878583\n",
      "Epoch: 18\tFidelity = 0.500478\tKL_Divergence = 4.013518\n",
      "Epoch: 19\tFidelity = 0.500552\tKL_Divergence = 3.934052\n",
      "Epoch: 20\tFidelity = 0.500552\tKL_Divergence = 3.933802\n",
      "Epoch: 21\tFidelity = 0.500508\tKL_Divergence = 3.980317\n",
      "Epoch: 22\tFidelity = 0.500471\tKL_Divergence = 4.021683\n",
      "Epoch: 23\tFidelity = 0.500490\tKL_Divergence = 4.000183\n",
      "Epoch: 24\tFidelity = 0.500589\tKL_Divergence = 3.898133\n",
      "Epoch: 25\tFidelity = 0.500533\tKL_Divergence = 3.954047\n",
      "Epoch: 26\tFidelity = 0.500467\tKL_Divergence = 4.026901\n",
      "Epoch: 27\tFidelity = 0.500583\tKL_Divergence = 3.904012\n",
      "Epoch: 28\tFidelity = 0.500565\tKL_Divergence = 3.920861\n",
      "Epoch: 29\tFidelity = 0.500571\tKL_Divergence = 3.914945\n",
      "Epoch: 30\tFidelity = 0.500556\tKL_Divergence = 3.929929\n",
      "Epoch: 31\tFidelity = 0.500478\tKL_Divergence = 4.014565\n",
      "Epoch: 32\tFidelity = 0.500522\tKL_Divergence = 3.965422\n",
      "Epoch: 33\tFidelity = 0.500486\tKL_Divergence = 4.005420\n",
      "Epoch: 34\tFidelity = 0.500481\tKL_Divergence = 4.010564\n",
      "Epoch: 35\tFidelity = 0.500471\tKL_Divergence = 4.021937\n",
      "Epoch: 36\tFidelity = 0.500430\tKL_Divergence = 4.073282\n",
      "Epoch: 37\tFidelity = 0.500456\tKL_Divergence = 4.040565\n",
      "Epoch: 38\tFidelity = 0.500487\tKL_Divergence = 4.003658\n",
      "Epoch: 39\tFidelity = 0.500408\tKL_Divergence = 4.101426\n",
      "Epoch: 40\tFidelity = 0.500520\tKL_Divergence = 3.966974\n",
      "Epoch: 41\tFidelity = 0.500528\tKL_Divergence = 3.959048\n",
      "Epoch: 42\tFidelity = 0.500631\tKL_Divergence = 3.860037\n",
      "Epoch: 43\tFidelity = 0.500466\tKL_Divergence = 4.028675\n",
      "Epoch: 44\tFidelity = 0.500519\tKL_Divergence = 3.968218\n",
      "Epoch: 45\tFidelity = 0.500392\tKL_Divergence = 4.123621\n",
      "Epoch: 46\tFidelity = 0.500495\tKL_Divergence = 3.995256\n",
      "Epoch: 47\tFidelity = 0.500548\tKL_Divergence = 3.938268\n",
      "Epoch: 48\tFidelity = 0.500540\tKL_Divergence = 3.946109\n",
      "Epoch: 49\tFidelity = 0.500507\tKL_Divergence = 3.981189\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:29:02,973] Trial 451 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500525\tKL_Divergence = 3.961919\n",
      "Total time elapsed during training: 38.028 s\n",
      "Trial 451 pruned. \n",
      "Epoch: 1\tFidelity = 0.500492\tKL_Divergence = 3.998224\n",
      "Epoch: 2\tFidelity = 0.500499\tKL_Divergence = 3.990445\n",
      "Epoch: 3\tFidelity = 0.500520\tKL_Divergence = 3.967396\n",
      "Epoch: 4\tFidelity = 0.500519\tKL_Divergence = 3.968038\n",
      "Epoch: 5\tFidelity = 0.500494\tKL_Divergence = 3.995330\n",
      "Epoch: 6\tFidelity = 0.500500\tKL_Divergence = 3.989485\n",
      "Epoch: 7\tFidelity = 0.500502\tKL_Divergence = 3.987020\n",
      "Epoch: 8\tFidelity = 0.500475\tKL_Divergence = 4.017930\n",
      "Epoch: 9\tFidelity = 0.500515\tKL_Divergence = 3.972621\n",
      "Epoch: 10\tFidelity = 0.500503\tKL_Divergence = 3.986151\n",
      "Epoch: 11\tFidelity = 0.500519\tKL_Divergence = 3.968647\n",
      "Epoch: 12\tFidelity = 0.500500\tKL_Divergence = 3.988883\n",
      "Epoch: 13\tFidelity = 0.500525\tKL_Divergence = 3.962411\n",
      "Epoch: 14\tFidelity = 0.500508\tKL_Divergence = 3.980311\n",
      "Epoch: 15\tFidelity = 0.500503\tKL_Divergence = 3.985912\n",
      "Epoch: 16\tFidelity = 0.500520\tKL_Divergence = 3.967840\n",
      "Epoch: 17\tFidelity = 0.500517\tKL_Divergence = 3.971054\n",
      "Epoch: 18\tFidelity = 0.500517\tKL_Divergence = 3.970059\n",
      "Epoch: 19\tFidelity = 0.500503\tKL_Divergence = 3.985775\n",
      "Epoch: 20\tFidelity = 0.500510\tKL_Divergence = 3.978465\n",
      "Epoch: 21\tFidelity = 0.500511\tKL_Divergence = 3.977206\n",
      "Epoch: 22\tFidelity = 0.500526\tKL_Divergence = 3.960881\n",
      "Epoch: 23\tFidelity = 0.500499\tKL_Divergence = 3.990397\n",
      "Epoch: 24\tFidelity = 0.500538\tKL_Divergence = 3.948954\n",
      "Epoch: 25\tFidelity = 0.500480\tKL_Divergence = 4.011465\n",
      "Epoch: 26\tFidelity = 0.500479\tKL_Divergence = 4.013149\n",
      "Epoch: 27\tFidelity = 0.500512\tKL_Divergence = 3.975692\n",
      "Epoch: 28\tFidelity = 0.500496\tKL_Divergence = 3.993071\n",
      "Epoch: 29\tFidelity = 0.500477\tKL_Divergence = 4.015549\n",
      "Epoch: 30\tFidelity = 0.500516\tKL_Divergence = 3.971159\n",
      "Epoch: 31\tFidelity = 0.500518\tKL_Divergence = 3.969933\n",
      "Epoch: 32\tFidelity = 0.500492\tKL_Divergence = 3.998493\n",
      "Epoch: 33\tFidelity = 0.500505\tKL_Divergence = 3.983215\n",
      "Epoch: 34\tFidelity = 0.500493\tKL_Divergence = 3.997142\n",
      "Epoch: 35\tFidelity = 0.500531\tKL_Divergence = 3.956053\n",
      "Epoch: 36\tFidelity = 0.500476\tKL_Divergence = 4.016406\n",
      "Epoch: 37\tFidelity = 0.500522\tKL_Divergence = 3.965566\n",
      "Epoch: 38\tFidelity = 0.500493\tKL_Divergence = 3.997125\n",
      "Epoch: 39\tFidelity = 0.500478\tKL_Divergence = 4.013628\n",
      "Epoch: 40\tFidelity = 0.500515\tKL_Divergence = 3.972570\n",
      "Epoch: 41\tFidelity = 0.500471\tKL_Divergence = 4.021806\n",
      "Epoch: 42\tFidelity = 0.500495\tKL_Divergence = 3.994515\n",
      "Epoch: 43\tFidelity = 0.500472\tKL_Divergence = 4.021461\n",
      "Epoch: 44\tFidelity = 0.500492\tKL_Divergence = 3.997785\n",
      "Epoch: 45\tFidelity = 0.500506\tKL_Divergence = 3.982246\n",
      "Epoch: 46\tFidelity = 0.500546\tKL_Divergence = 3.940313\n",
      "Epoch: 47\tFidelity = 0.500496\tKL_Divergence = 3.993073\n",
      "Epoch: 48\tFidelity = 0.500521\tKL_Divergence = 3.966032\n",
      "Epoch: 49\tFidelity = 0.500514\tKL_Divergence = 3.974210\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:29:34,609] Trial 452 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500480\tKL_Divergence = 4.011930\n",
      "Total time elapsed during training: 31.468 s\n",
      "Trial 452 pruned. \n",
      "Epoch: 1\tFidelity = 0.500486\tKL_Divergence = 4.004304\n",
      "Epoch: 2\tFidelity = 0.500451\tKL_Divergence = 4.046797\n",
      "Epoch: 3\tFidelity = 0.500524\tKL_Divergence = 3.963040\n",
      "Epoch: 4\tFidelity = 0.500520\tKL_Divergence = 3.967211\n",
      "Epoch: 5\tFidelity = 0.500498\tKL_Divergence = 3.991259\n",
      "Epoch: 6\tFidelity = 0.500544\tKL_Divergence = 3.941944\n",
      "Epoch: 7\tFidelity = 0.500486\tKL_Divergence = 4.004640\n",
      "Epoch: 8\tFidelity = 0.500493\tKL_Divergence = 3.996718\n",
      "Epoch: 9\tFidelity = 0.500503\tKL_Divergence = 3.985636\n",
      "Epoch: 10\tFidelity = 0.500523\tKL_Divergence = 3.964417\n",
      "Epoch: 11\tFidelity = 0.500474\tKL_Divergence = 4.018370\n",
      "Epoch: 12\tFidelity = 0.500542\tKL_Divergence = 3.944237\n",
      "Epoch: 13\tFidelity = 0.500477\tKL_Divergence = 4.015217\n",
      "Epoch: 14\tFidelity = 0.500505\tKL_Divergence = 3.983902\n",
      "Epoch: 15\tFidelity = 0.500494\tKL_Divergence = 3.995901\n",
      "Epoch: 16\tFidelity = 0.500529\tKL_Divergence = 3.957587\n",
      "Epoch: 17\tFidelity = 0.500440\tKL_Divergence = 4.059478\n",
      "Epoch: 18\tFidelity = 0.500496\tKL_Divergence = 3.993311\n",
      "Epoch: 19\tFidelity = 0.500447\tKL_Divergence = 4.050967\n",
      "Epoch: 20\tFidelity = 0.500526\tKL_Divergence = 3.961253\n",
      "Epoch: 21\tFidelity = 0.500473\tKL_Divergence = 4.019736\n",
      "Epoch: 22\tFidelity = 0.500476\tKL_Divergence = 4.016434\n",
      "Epoch: 23\tFidelity = 0.500532\tKL_Divergence = 3.954358\n",
      "Epoch: 24\tFidelity = 0.500479\tKL_Divergence = 4.012875\n",
      "Epoch: 25\tFidelity = 0.500487\tKL_Divergence = 4.004201\n",
      "Epoch: 26\tFidelity = 0.500469\tKL_Divergence = 4.024045\n",
      "Epoch: 27\tFidelity = 0.500519\tKL_Divergence = 3.968343\n",
      "Epoch: 28\tFidelity = 0.500523\tKL_Divergence = 3.963795\n",
      "Epoch: 29\tFidelity = 0.500507\tKL_Divergence = 3.981136\n",
      "Epoch: 30\tFidelity = 0.500469\tKL_Divergence = 4.024432\n",
      "Epoch: 31\tFidelity = 0.500500\tKL_Divergence = 3.988833\n",
      "Epoch: 32\tFidelity = 0.500552\tKL_Divergence = 3.934111\n",
      "Epoch: 33\tFidelity = 0.500521\tKL_Divergence = 3.966431\n",
      "Epoch: 34\tFidelity = 0.500539\tKL_Divergence = 3.947328\n",
      "Epoch: 35\tFidelity = 0.500470\tKL_Divergence = 4.023706\n",
      "Epoch: 36\tFidelity = 0.500546\tKL_Divergence = 3.939700\n",
      "Epoch: 37\tFidelity = 0.500534\tKL_Divergence = 3.952104\n",
      "Epoch: 38\tFidelity = 0.500554\tKL_Divergence = 3.931732\n",
      "Epoch: 39\tFidelity = 0.500534\tKL_Divergence = 3.952025\n",
      "Epoch: 40\tFidelity = 0.500451\tKL_Divergence = 4.046424\n",
      "Epoch: 41\tFidelity = 0.500538\tKL_Divergence = 3.948580\n",
      "Epoch: 42\tFidelity = 0.500525\tKL_Divergence = 3.961529\n",
      "Epoch: 43\tFidelity = 0.500539\tKL_Divergence = 3.947106\n",
      "Epoch: 44\tFidelity = 0.500493\tKL_Divergence = 3.996253\n",
      "Epoch: 45\tFidelity = 0.500489\tKL_Divergence = 4.000517\n",
      "Epoch: 46\tFidelity = 0.500387\tKL_Divergence = 4.130363\n",
      "Epoch: 47\tFidelity = 0.500499\tKL_Divergence = 3.989317\n",
      "Epoch: 48\tFidelity = 0.500511\tKL_Divergence = 3.977146\n",
      "Epoch: 49\tFidelity = 0.500474\tKL_Divergence = 4.018321\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:30:31,674] Trial 453 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500549\tKL_Divergence = 3.936965\n",
      "Total time elapsed during training: 56.895 s\n",
      "Trial 453 pruned. \n",
      "Epoch: 1\tFidelity = 0.500502\tKL_Divergence = 3.986096\n",
      "Epoch: 2\tFidelity = 0.500470\tKL_Divergence = 4.023310\n",
      "Epoch: 3\tFidelity = 0.500511\tKL_Divergence = 3.976704\n",
      "Epoch: 4\tFidelity = 0.500502\tKL_Divergence = 3.986197\n",
      "Epoch: 5\tFidelity = 0.500518\tKL_Divergence = 3.969052\n",
      "Epoch: 6\tFidelity = 0.500521\tKL_Divergence = 3.966203\n",
      "Epoch: 7\tFidelity = 0.500485\tKL_Divergence = 4.005913\n",
      "Epoch: 8\tFidelity = 0.500526\tKL_Divergence = 3.960609\n",
      "Epoch: 9\tFidelity = 0.500485\tKL_Divergence = 4.005593\n",
      "Epoch: 10\tFidelity = 0.500485\tKL_Divergence = 4.005279\n",
      "Epoch: 11\tFidelity = 0.500499\tKL_Divergence = 3.989567\n",
      "Epoch: 12\tFidelity = 0.500547\tKL_Divergence = 3.939190\n",
      "Epoch: 13\tFidelity = 0.500525\tKL_Divergence = 3.962357\n",
      "Epoch: 14\tFidelity = 0.500511\tKL_Divergence = 3.976903\n",
      "Epoch: 15\tFidelity = 0.500506\tKL_Divergence = 3.982219\n",
      "Epoch: 16\tFidelity = 0.500521\tKL_Divergence = 3.966155\n",
      "Epoch: 17\tFidelity = 0.500526\tKL_Divergence = 3.960650\n",
      "Epoch: 18\tFidelity = 0.500488\tKL_Divergence = 4.002050\n",
      "Epoch: 19\tFidelity = 0.500527\tKL_Divergence = 3.959846\n",
      "Epoch: 20\tFidelity = 0.500533\tKL_Divergence = 3.953190\n",
      "Epoch: 21\tFidelity = 0.500508\tKL_Divergence = 3.980319\n",
      "Epoch: 22\tFidelity = 0.500540\tKL_Divergence = 3.945852\n",
      "Epoch: 23\tFidelity = 0.500492\tKL_Divergence = 3.997609\n",
      "Epoch: 24\tFidelity = 0.500510\tKL_Divergence = 3.978269\n",
      "Epoch: 25\tFidelity = 0.500535\tKL_Divergence = 3.951532\n",
      "Epoch: 26\tFidelity = 0.500509\tKL_Divergence = 3.978765\n",
      "Epoch: 27\tFidelity = 0.500495\tKL_Divergence = 3.994792\n",
      "Epoch: 28\tFidelity = 0.500516\tKL_Divergence = 3.971692\n",
      "Epoch: 29\tFidelity = 0.500536\tKL_Divergence = 3.950880\n",
      "Epoch: 30\tFidelity = 0.500555\tKL_Divergence = 3.931519\n",
      "Epoch: 31\tFidelity = 0.500529\tKL_Divergence = 3.958087\n",
      "Epoch: 32\tFidelity = 0.500470\tKL_Divergence = 4.023814\n",
      "Epoch: 33\tFidelity = 0.500495\tKL_Divergence = 3.994682\n",
      "Epoch: 34\tFidelity = 0.500508\tKL_Divergence = 3.979873\n",
      "Epoch: 35\tFidelity = 0.500470\tKL_Divergence = 4.022923\n",
      "Epoch: 36\tFidelity = 0.500532\tKL_Divergence = 3.954248\n",
      "Epoch: 37\tFidelity = 0.500508\tKL_Divergence = 3.979835\n",
      "Epoch: 38\tFidelity = 0.500485\tKL_Divergence = 4.005819\n",
      "Epoch: 39\tFidelity = 0.500533\tKL_Divergence = 3.953983\n",
      "Epoch: 40\tFidelity = 0.500473\tKL_Divergence = 4.019900\n",
      "Epoch: 41\tFidelity = 0.500530\tKL_Divergence = 3.956834\n",
      "Epoch: 42\tFidelity = 0.500483\tKL_Divergence = 4.008515\n",
      "Epoch: 43\tFidelity = 0.500537\tKL_Divergence = 3.949315\n",
      "Epoch: 44\tFidelity = 0.500492\tKL_Divergence = 3.998043\n",
      "Epoch: 45\tFidelity = 0.500502\tKL_Divergence = 3.986852\n",
      "Epoch: 46\tFidelity = 0.500530\tKL_Divergence = 3.956675\n",
      "Epoch: 47\tFidelity = 0.500512\tKL_Divergence = 3.976115\n",
      "Epoch: 48\tFidelity = 0.500546\tKL_Divergence = 3.940542\n",
      "Epoch: 49\tFidelity = 0.500510\tKL_Divergence = 3.977964\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:31:03,153] Trial 454 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500519\tKL_Divergence = 3.968600\n",
      "Total time elapsed during training: 31.310 s\n",
      "Trial 454 pruned. \n",
      "Epoch: 1\tFidelity = 0.500501\tKL_Divergence = 3.988143\n",
      "Epoch: 2\tFidelity = 0.500561\tKL_Divergence = 3.925316\n",
      "Epoch: 3\tFidelity = 0.500504\tKL_Divergence = 3.984829\n",
      "Epoch: 4\tFidelity = 0.500496\tKL_Divergence = 3.993505\n",
      "Epoch: 5\tFidelity = 0.500486\tKL_Divergence = 4.004548\n",
      "Epoch: 6\tFidelity = 0.500521\tKL_Divergence = 3.966759\n",
      "Epoch: 7\tFidelity = 0.500428\tKL_Divergence = 4.074878\n",
      "Epoch: 8\tFidelity = 0.500526\tKL_Divergence = 3.960541\n",
      "Epoch: 9\tFidelity = 0.500484\tKL_Divergence = 4.007411\n",
      "Epoch: 10\tFidelity = 0.500524\tKL_Divergence = 3.962782\n",
      "Epoch: 11\tFidelity = 0.500521\tKL_Divergence = 3.966560\n",
      "Epoch: 12\tFidelity = 0.500578\tKL_Divergence = 3.908997\n",
      "Epoch: 13\tFidelity = 0.500512\tKL_Divergence = 3.976424\n",
      "Epoch: 14\tFidelity = 0.500573\tKL_Divergence = 3.913232\n",
      "Epoch: 15\tFidelity = 0.500547\tKL_Divergence = 3.939637\n",
      "Epoch: 16\tFidelity = 0.500485\tKL_Divergence = 4.005455\n",
      "Epoch: 17\tFidelity = 0.500524\tKL_Divergence = 3.962896\n",
      "Epoch: 18\tFidelity = 0.500489\tKL_Divergence = 4.001344\n",
      "Epoch: 19\tFidelity = 0.500512\tKL_Divergence = 3.975948\n",
      "Epoch: 20\tFidelity = 0.500555\tKL_Divergence = 3.931578\n",
      "Epoch: 21\tFidelity = 0.500503\tKL_Divergence = 3.985552\n",
      "Epoch: 22\tFidelity = 0.500550\tKL_Divergence = 3.936162\n",
      "Epoch: 23\tFidelity = 0.500518\tKL_Divergence = 3.969478\n",
      "Epoch: 24\tFidelity = 0.500545\tKL_Divergence = 3.941420\n",
      "Epoch: 25\tFidelity = 0.500502\tKL_Divergence = 3.986478\n",
      "Epoch: 26\tFidelity = 0.500504\tKL_Divergence = 3.984980\n",
      "Epoch: 27\tFidelity = 0.500516\tKL_Divergence = 3.972073\n",
      "Epoch: 28\tFidelity = 0.500494\tKL_Divergence = 3.995342\n",
      "Epoch: 29\tFidelity = 0.500489\tKL_Divergence = 4.001372\n",
      "Epoch: 30\tFidelity = 0.500503\tKL_Divergence = 3.986179\n",
      "Epoch: 31\tFidelity = 0.500516\tKL_Divergence = 3.971578\n",
      "Epoch: 32\tFidelity = 0.500485\tKL_Divergence = 4.006046\n",
      "Epoch: 33\tFidelity = 0.500555\tKL_Divergence = 3.931300\n",
      "Epoch: 34\tFidelity = 0.500544\tKL_Divergence = 3.942674\n",
      "Epoch: 35\tFidelity = 0.500565\tKL_Divergence = 3.921229\n",
      "Epoch: 36\tFidelity = 0.500479\tKL_Divergence = 4.012297\n",
      "Epoch: 37\tFidelity = 0.500586\tKL_Divergence = 3.901087\n",
      "Epoch: 38\tFidelity = 0.500508\tKL_Divergence = 3.979799\n",
      "Epoch: 39\tFidelity = 0.500462\tKL_Divergence = 4.032892\n",
      "Epoch: 40\tFidelity = 0.500474\tKL_Divergence = 4.018928\n",
      "Epoch: 41\tFidelity = 0.500502\tKL_Divergence = 3.987295\n",
      "Epoch: 42\tFidelity = 0.500561\tKL_Divergence = 3.925677\n",
      "Epoch: 43\tFidelity = 0.500511\tKL_Divergence = 3.976961\n",
      "Epoch: 44\tFidelity = 0.500492\tKL_Divergence = 3.997984\n",
      "Epoch: 45\tFidelity = 0.500544\tKL_Divergence = 3.942055\n",
      "Epoch: 46\tFidelity = 0.500558\tKL_Divergence = 3.928474\n",
      "Epoch: 47\tFidelity = 0.500524\tKL_Divergence = 3.963319\n",
      "Epoch: 48\tFidelity = 0.500543\tKL_Divergence = 3.943588\n",
      "Epoch: 49\tFidelity = 0.500588\tKL_Divergence = 3.899541\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:32:21,829] Trial 455 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500517\tKL_Divergence = 3.970830\n",
      "Total time elapsed during training: 78.506 s\n",
      "Trial 455 pruned. \n",
      "Epoch: 1\tFidelity = 0.500542\tKL_Divergence = 3.944617\n",
      "Epoch: 2\tFidelity = 0.500531\tKL_Divergence = 3.955441\n",
      "Epoch: 3\tFidelity = 0.500516\tKL_Divergence = 3.971823\n",
      "Epoch: 4\tFidelity = 0.500512\tKL_Divergence = 3.976395\n",
      "Epoch: 5\tFidelity = 0.500514\tKL_Divergence = 3.973711\n",
      "Epoch: 6\tFidelity = 0.500494\tKL_Divergence = 3.995475\n",
      "Epoch: 7\tFidelity = 0.500511\tKL_Divergence = 3.976971\n",
      "Epoch: 8\tFidelity = 0.500487\tKL_Divergence = 4.004034\n",
      "Epoch: 9\tFidelity = 0.500540\tKL_Divergence = 3.946800\n",
      "Epoch: 10\tFidelity = 0.500514\tKL_Divergence = 3.973420\n",
      "Epoch: 11\tFidelity = 0.500522\tKL_Divergence = 3.965351\n",
      "Epoch: 12\tFidelity = 0.500487\tKL_Divergence = 4.003748\n",
      "Epoch: 13\tFidelity = 0.500478\tKL_Divergence = 4.013667\n",
      "Epoch: 14\tFidelity = 0.500497\tKL_Divergence = 3.992216\n",
      "Epoch: 15\tFidelity = 0.500480\tKL_Divergence = 4.011157\n",
      "Epoch: 16\tFidelity = 0.500539\tKL_Divergence = 3.947556\n",
      "Epoch: 17\tFidelity = 0.500522\tKL_Divergence = 3.964938\n",
      "Epoch: 18\tFidelity = 0.500526\tKL_Divergence = 3.960991\n",
      "Epoch: 19\tFidelity = 0.500507\tKL_Divergence = 3.981855\n",
      "Epoch: 20\tFidelity = 0.500533\tKL_Divergence = 3.954088\n",
      "Epoch: 21\tFidelity = 0.500540\tKL_Divergence = 3.946764\n",
      "Epoch: 22\tFidelity = 0.500495\tKL_Divergence = 3.994479\n",
      "Epoch: 23\tFidelity = 0.500474\tKL_Divergence = 4.018384\n",
      "Epoch: 24\tFidelity = 0.500506\tKL_Divergence = 3.982244\n",
      "Epoch: 25\tFidelity = 0.500560\tKL_Divergence = 3.926419\n",
      "Epoch: 26\tFidelity = 0.500510\tKL_Divergence = 3.978001\n",
      "Epoch: 27\tFidelity = 0.500492\tKL_Divergence = 3.998356\n",
      "Epoch: 28\tFidelity = 0.500470\tKL_Divergence = 4.023836\n",
      "Epoch: 29\tFidelity = 0.500511\tKL_Divergence = 3.977196\n",
      "Epoch: 30\tFidelity = 0.500491\tKL_Divergence = 3.999072\n",
      "Epoch: 31\tFidelity = 0.500506\tKL_Divergence = 3.982273\n",
      "Epoch: 32\tFidelity = 0.500558\tKL_Divergence = 3.928396\n",
      "Epoch: 33\tFidelity = 0.500528\tKL_Divergence = 3.958866\n",
      "Epoch: 34\tFidelity = 0.500536\tKL_Divergence = 3.950371\n",
      "Epoch: 35\tFidelity = 0.500495\tKL_Divergence = 3.995033\n",
      "Epoch: 36\tFidelity = 0.500496\tKL_Divergence = 3.993448\n",
      "Epoch: 37\tFidelity = 0.500516\tKL_Divergence = 3.971600\n",
      "Epoch: 38\tFidelity = 0.500496\tKL_Divergence = 3.993452\n",
      "Epoch: 39\tFidelity = 0.500499\tKL_Divergence = 3.989822\n",
      "Epoch: 40\tFidelity = 0.500487\tKL_Divergence = 4.004173\n",
      "Epoch: 41\tFidelity = 0.500515\tKL_Divergence = 3.972211\n",
      "Epoch: 42\tFidelity = 0.500515\tKL_Divergence = 3.973035\n",
      "Epoch: 43\tFidelity = 0.500509\tKL_Divergence = 3.978618\n",
      "Epoch: 44\tFidelity = 0.500490\tKL_Divergence = 4.000716\n",
      "Epoch: 45\tFidelity = 0.500527\tKL_Divergence = 3.960391\n",
      "Epoch: 46\tFidelity = 0.500532\tKL_Divergence = 3.954627\n",
      "Epoch: 47\tFidelity = 0.500508\tKL_Divergence = 3.979708\n",
      "Epoch: 48\tFidelity = 0.500477\tKL_Divergence = 4.015380\n",
      "Epoch: 49\tFidelity = 0.500484\tKL_Divergence = 4.006544\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:33:06,114] Trial 456 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500523\tKL_Divergence = 3.964025\n",
      "Total time elapsed during training: 44.119 s\n",
      "Trial 456 pruned. \n",
      "Epoch: 1\tFidelity = 0.500544\tKL_Divergence = 3.942605\n",
      "Epoch: 2\tFidelity = 0.500447\tKL_Divergence = 4.051278\n",
      "Epoch: 3\tFidelity = 0.500561\tKL_Divergence = 3.925006\n",
      "Epoch: 4\tFidelity = 0.500548\tKL_Divergence = 3.937889\n",
      "Epoch: 5\tFidelity = 0.500470\tKL_Divergence = 4.023007\n",
      "Epoch: 6\tFidelity = 0.500531\tKL_Divergence = 3.954306\n",
      "Epoch: 7\tFidelity = 0.500515\tKL_Divergence = 3.971499\n",
      "Epoch: 8\tFidelity = 0.500465\tKL_Divergence = 4.027495\n",
      "Epoch: 9\tFidelity = 0.500653\tKL_Divergence = 3.839729\n",
      "Epoch: 10\tFidelity = 0.500518\tKL_Divergence = 3.967719\n",
      "Epoch: 11\tFidelity = 0.500502\tKL_Divergence = 3.985043\n",
      "Epoch: 12\tFidelity = 0.500475\tKL_Divergence = 4.015967\n",
      "Epoch: 13\tFidelity = 0.500537\tKL_Divergence = 3.948825\n",
      "Epoch: 14\tFidelity = 0.500432\tKL_Divergence = 4.069295\n",
      "Epoch: 15\tFidelity = 0.500448\tKL_Divergence = 4.047975\n",
      "Epoch: 16\tFidelity = 0.500583\tKL_Divergence = 3.902328\n",
      "Epoch: 17\tFidelity = 0.500526\tKL_Divergence = 3.959396\n",
      "Epoch: 18\tFidelity = 0.500464\tKL_Divergence = 4.027305\n",
      "Epoch: 19\tFidelity = 0.500549\tKL_Divergence = 3.933933\n",
      "Epoch: 20\tFidelity = 0.500559\tKL_Divergence = 3.922149\n",
      "Epoch: 21\tFidelity = 0.500607\tKL_Divergence = 3.876607\n",
      "Epoch: 22\tFidelity = 0.500511\tKL_Divergence = 3.972931\n",
      "Epoch: 23\tFidelity = 0.500525\tKL_Divergence = 3.958744\n",
      "Epoch: 24\tFidelity = 0.500435\tKL_Divergence = 4.062688\n",
      "Epoch: 25\tFidelity = 0.500494\tKL_Divergence = 3.990957\n",
      "Epoch: 26\tFidelity = 0.500566\tKL_Divergence = 3.918184\n",
      "Epoch: 27\tFidelity = 0.500501\tKL_Divergence = 3.985818\n",
      "Epoch: 28\tFidelity = 0.500535\tKL_Divergence = 3.949030\n",
      "Epoch: 29\tFidelity = 0.500479\tKL_Divergence = 4.011796\n",
      "Epoch: 30\tFidelity = 0.500491\tKL_Divergence = 3.996770\n",
      "Epoch: 31\tFidelity = 0.500473\tKL_Divergence = 4.017848\n",
      "Epoch: 32\tFidelity = 0.500529\tKL_Divergence = 3.956563\n",
      "Epoch: 33\tFidelity = 0.500477\tKL_Divergence = 4.014822\n",
      "Epoch: 34\tFidelity = 0.500597\tKL_Divergence = 3.890338\n",
      "Epoch: 35\tFidelity = 0.500515\tKL_Divergence = 3.972370\n",
      "Epoch: 36\tFidelity = 0.500526\tKL_Divergence = 3.960479\n",
      "Epoch: 37\tFidelity = 0.500486\tKL_Divergence = 4.004610\n",
      "Epoch: 38\tFidelity = 0.500480\tKL_Divergence = 4.011358\n",
      "Epoch: 39\tFidelity = 0.500430\tKL_Divergence = 4.072322\n",
      "Epoch: 40\tFidelity = 0.500502\tKL_Divergence = 3.986707\n",
      "Epoch: 41\tFidelity = 0.500518\tKL_Divergence = 3.969837\n",
      "Epoch: 42\tFidelity = 0.500480\tKL_Divergence = 4.011471\n",
      "Epoch: 43\tFidelity = 0.500441\tKL_Divergence = 4.058300\n",
      "Epoch: 44\tFidelity = 0.500538\tKL_Divergence = 3.948754\n",
      "Epoch: 45\tFidelity = 0.500508\tKL_Divergence = 3.980666\n",
      "Epoch: 46\tFidelity = 0.500551\tKL_Divergence = 3.935360\n",
      "Epoch: 47\tFidelity = 0.500573\tKL_Divergence = 3.913315\n",
      "Epoch: 48\tFidelity = 0.500586\tKL_Divergence = 3.901446\n",
      "Epoch: 49\tFidelity = 0.500517\tKL_Divergence = 3.970250\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:33:43,471] Trial 457 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500481\tKL_Divergence = 4.009993\n",
      "Total time elapsed during training: 37.186 s\n",
      "Trial 457 pruned. \n",
      "Epoch: 1\tFidelity = 0.500477\tKL_Divergence = 4.014847\n",
      "Epoch: 2\tFidelity = 0.500452\tKL_Divergence = 4.045185\n",
      "Epoch: 3\tFidelity = 0.500498\tKL_Divergence = 3.990523\n",
      "Epoch: 4\tFidelity = 0.500461\tKL_Divergence = 4.034130\n",
      "Epoch: 5\tFidelity = 0.500478\tKL_Divergence = 4.013827\n",
      "Epoch: 6\tFidelity = 0.500506\tKL_Divergence = 3.982652\n",
      "Epoch: 7\tFidelity = 0.500498\tKL_Divergence = 3.990595\n",
      "Epoch: 8\tFidelity = 0.500494\tKL_Divergence = 3.995064\n",
      "Epoch: 9\tFidelity = 0.500529\tKL_Divergence = 3.957380\n",
      "Epoch: 10\tFidelity = 0.500501\tKL_Divergence = 3.987298\n",
      "Epoch: 11\tFidelity = 0.500534\tKL_Divergence = 3.952347\n",
      "Epoch: 12\tFidelity = 0.500497\tKL_Divergence = 3.992622\n",
      "Epoch: 13\tFidelity = 0.500498\tKL_Divergence = 3.991350\n",
      "Epoch: 14\tFidelity = 0.500487\tKL_Divergence = 4.003935\n",
      "Epoch: 15\tFidelity = 0.500506\tKL_Divergence = 3.982707\n",
      "Epoch: 16\tFidelity = 0.500465\tKL_Divergence = 4.029311\n",
      "Epoch: 17\tFidelity = 0.500482\tKL_Divergence = 4.009257\n",
      "Epoch: 18\tFidelity = 0.500525\tKL_Divergence = 3.961927\n",
      "Epoch: 19\tFidelity = 0.500501\tKL_Divergence = 3.988135\n",
      "Epoch: 20\tFidelity = 0.500461\tKL_Divergence = 4.033642\n",
      "Epoch: 21\tFidelity = 0.500452\tKL_Divergence = 4.045240\n",
      "Epoch: 22\tFidelity = 0.500470\tKL_Divergence = 4.023428\n",
      "Epoch: 23\tFidelity = 0.500494\tKL_Divergence = 3.995579\n",
      "Epoch: 24\tFidelity = 0.500537\tKL_Divergence = 3.949875\n",
      "Epoch: 25\tFidelity = 0.500499\tKL_Divergence = 3.990651\n",
      "Epoch: 26\tFidelity = 0.500483\tKL_Divergence = 4.008283\n",
      "Epoch: 27\tFidelity = 0.500486\tKL_Divergence = 4.004618\n",
      "Epoch: 28\tFidelity = 0.500485\tKL_Divergence = 4.006388\n",
      "Epoch: 29\tFidelity = 0.500475\tKL_Divergence = 4.017696\n",
      "Epoch: 30\tFidelity = 0.500482\tKL_Divergence = 4.009271\n",
      "Epoch: 31\tFidelity = 0.500471\tKL_Divergence = 4.022236\n",
      "Epoch: 32\tFidelity = 0.500506\tKL_Divergence = 3.982000\n",
      "Epoch: 33\tFidelity = 0.500490\tKL_Divergence = 4.000251\n",
      "Epoch: 34\tFidelity = 0.500497\tKL_Divergence = 3.992131\n",
      "Epoch: 35\tFidelity = 0.500501\tKL_Divergence = 3.987736\n",
      "Epoch: 36\tFidelity = 0.500530\tKL_Divergence = 3.956770\n",
      "Epoch: 37\tFidelity = 0.500522\tKL_Divergence = 3.965361\n",
      "Epoch: 38\tFidelity = 0.500478\tKL_Divergence = 4.013973\n",
      "Epoch: 39\tFidelity = 0.500489\tKL_Divergence = 4.001722\n",
      "Epoch: 40\tFidelity = 0.500487\tKL_Divergence = 4.004264\n",
      "Epoch: 41\tFidelity = 0.500517\tKL_Divergence = 3.970834\n",
      "Epoch: 42\tFidelity = 0.500505\tKL_Divergence = 3.983742\n",
      "Epoch: 43\tFidelity = 0.500495\tKL_Divergence = 3.994177\n",
      "Epoch: 44\tFidelity = 0.500492\tKL_Divergence = 3.997792\n",
      "Epoch: 45\tFidelity = 0.500499\tKL_Divergence = 3.989789\n",
      "Epoch: 46\tFidelity = 0.500483\tKL_Divergence = 4.007925\n",
      "Epoch: 47\tFidelity = 0.500508\tKL_Divergence = 3.980354\n",
      "Epoch: 48\tFidelity = 0.500488\tKL_Divergence = 4.002688\n",
      "Epoch: 49\tFidelity = 0.500461\tKL_Divergence = 4.034405\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:34:21,930] Trial 458 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500495\tKL_Divergence = 3.994204\n",
      "Total time elapsed during training: 38.287 s\n",
      "Trial 458 pruned. \n",
      "Epoch: 1\tFidelity = 0.500471\tKL_Divergence = 4.022727\n",
      "Epoch: 2\tFidelity = 0.500488\tKL_Divergence = 4.002022\n",
      "Epoch: 3\tFidelity = 0.500525\tKL_Divergence = 3.962073\n",
      "Epoch: 4\tFidelity = 0.500442\tKL_Divergence = 4.057863\n",
      "Epoch: 5\tFidelity = 0.500417\tKL_Divergence = 4.089571\n",
      "Epoch: 6\tFidelity = 0.500491\tKL_Divergence = 3.998641\n",
      "Epoch: 7\tFidelity = 0.500536\tKL_Divergence = 3.950483\n",
      "Epoch: 8\tFidelity = 0.500457\tKL_Divergence = 4.038834\n",
      "Epoch: 9\tFidelity = 0.500572\tKL_Divergence = 3.914564\n",
      "Epoch: 10\tFidelity = 0.500520\tKL_Divergence = 3.967793\n",
      "Epoch: 11\tFidelity = 0.500433\tKL_Divergence = 4.069309\n",
      "Epoch: 12\tFidelity = 0.500545\tKL_Divergence = 3.941143\n",
      "Epoch: 13\tFidelity = 0.500494\tKL_Divergence = 3.996182\n",
      "Epoch: 14\tFidelity = 0.500579\tKL_Divergence = 3.907987\n",
      "Epoch: 15\tFidelity = 0.500454\tKL_Divergence = 4.042662\n",
      "Epoch: 16\tFidelity = 0.500473\tKL_Divergence = 4.019246\n",
      "Epoch: 17\tFidelity = 0.500420\tKL_Divergence = 4.085276\n",
      "Epoch: 18\tFidelity = 0.500618\tKL_Divergence = 3.870981\n",
      "Epoch: 19\tFidelity = 0.500568\tKL_Divergence = 3.917968\n",
      "Epoch: 20\tFidelity = 0.500489\tKL_Divergence = 4.001272\n",
      "Epoch: 21\tFidelity = 0.500581\tKL_Divergence = 3.905608\n",
      "Epoch: 22\tFidelity = 0.500463\tKL_Divergence = 4.031158\n",
      "Epoch: 23\tFidelity = 0.500564\tKL_Divergence = 3.922417\n",
      "Epoch: 24\tFidelity = 0.500557\tKL_Divergence = 3.929179\n",
      "Epoch: 25\tFidelity = 0.500498\tKL_Divergence = 3.991319\n",
      "Epoch: 26\tFidelity = 0.500522\tKL_Divergence = 3.965321\n",
      "Epoch: 27\tFidelity = 0.500576\tKL_Divergence = 3.910600\n",
      "Epoch: 28\tFidelity = 0.500573\tKL_Divergence = 3.913573\n",
      "Epoch: 29\tFidelity = 0.500672\tKL_Divergence = 3.825134\n",
      "Epoch: 30\tFidelity = 0.500442\tKL_Divergence = 4.057898\n",
      "Epoch: 31\tFidelity = 0.500565\tKL_Divergence = 3.921402\n",
      "Epoch: 32\tFidelity = 0.500551\tKL_Divergence = 3.934873\n",
      "Epoch: 33\tFidelity = 0.500572\tKL_Divergence = 3.914249\n",
      "Epoch: 34\tFidelity = 0.500582\tKL_Divergence = 3.904533\n",
      "Epoch: 35\tFidelity = 0.500547\tKL_Divergence = 3.938762\n",
      "Epoch: 36\tFidelity = 0.500594\tKL_Divergence = 3.892976\n",
      "Epoch: 37\tFidelity = 0.500465\tKL_Divergence = 4.029402\n",
      "Epoch: 38\tFidelity = 0.500556\tKL_Divergence = 3.929677\n",
      "Epoch: 39\tFidelity = 0.500558\tKL_Divergence = 3.928542\n",
      "Epoch: 40\tFidelity = 0.500533\tKL_Divergence = 3.953153\n",
      "Epoch: 41\tFidelity = 0.500522\tKL_Divergence = 3.964890\n",
      "Epoch: 42\tFidelity = 0.500521\tKL_Divergence = 3.966434\n",
      "Epoch: 43\tFidelity = 0.500467\tKL_Divergence = 4.027056\n",
      "Epoch: 44\tFidelity = 0.500428\tKL_Divergence = 4.075443\n",
      "Epoch: 45\tFidelity = 0.500514\tKL_Divergence = 3.974258\n",
      "Epoch: 46\tFidelity = 0.500504\tKL_Divergence = 3.984407\n",
      "Epoch: 47\tFidelity = 0.500574\tKL_Divergence = 3.912933\n",
      "Epoch: 48\tFidelity = 0.500566\tKL_Divergence = 3.919795\n",
      "Epoch: 49\tFidelity = 0.500590\tKL_Divergence = 3.897163\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:35:43,391] Trial 459 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500550\tKL_Divergence = 3.936489\n",
      "Total time elapsed during training: 81.289 s\n",
      "Trial 459 pruned. \n",
      "Epoch: 1\tFidelity = 0.500504\tKL_Divergence = 3.984918\n",
      "Epoch: 2\tFidelity = 0.500493\tKL_Divergence = 3.996563\n",
      "Epoch: 3\tFidelity = 0.500500\tKL_Divergence = 3.988408\n",
      "Epoch: 4\tFidelity = 0.500494\tKL_Divergence = 3.995282\n",
      "Epoch: 5\tFidelity = 0.500469\tKL_Divergence = 4.024895\n",
      "Epoch: 6\tFidelity = 0.500496\tKL_Divergence = 3.993910\n",
      "Epoch: 7\tFidelity = 0.500532\tKL_Divergence = 3.954729\n",
      "Epoch: 8\tFidelity = 0.500500\tKL_Divergence = 3.988786\n",
      "Epoch: 9\tFidelity = 0.500534\tKL_Divergence = 3.952744\n",
      "Epoch: 10\tFidelity = 0.500502\tKL_Divergence = 3.987309\n",
      "Epoch: 11\tFidelity = 0.500510\tKL_Divergence = 3.977825\n",
      "Epoch: 12\tFidelity = 0.500560\tKL_Divergence = 3.926195\n",
      "Epoch: 13\tFidelity = 0.500494\tKL_Divergence = 3.995681\n",
      "Epoch: 14\tFidelity = 0.500514\tKL_Divergence = 3.973229\n",
      "Epoch: 15\tFidelity = 0.500512\tKL_Divergence = 3.975796\n",
      "Epoch: 16\tFidelity = 0.500516\tKL_Divergence = 3.971735\n",
      "Epoch: 17\tFidelity = 0.500503\tKL_Divergence = 3.985152\n",
      "Epoch: 18\tFidelity = 0.500449\tKL_Divergence = 4.049125\n",
      "Epoch: 19\tFidelity = 0.500503\tKL_Divergence = 3.985720\n",
      "Epoch: 20\tFidelity = 0.500540\tKL_Divergence = 3.946123\n",
      "Epoch: 21\tFidelity = 0.500454\tKL_Divergence = 4.042855\n",
      "Epoch: 22\tFidelity = 0.500485\tKL_Divergence = 4.005887\n",
      "Epoch: 23\tFidelity = 0.500509\tKL_Divergence = 3.979004\n",
      "Epoch: 24\tFidelity = 0.500523\tKL_Divergence = 3.964279\n",
      "Epoch: 25\tFidelity = 0.500515\tKL_Divergence = 3.972401\n",
      "Epoch: 26\tFidelity = 0.500540\tKL_Divergence = 3.946224\n",
      "Epoch: 27\tFidelity = 0.500530\tKL_Divergence = 3.957105\n",
      "Epoch: 28\tFidelity = 0.500495\tKL_Divergence = 3.994810\n",
      "Epoch: 29\tFidelity = 0.500516\tKL_Divergence = 3.971312\n",
      "Epoch: 30\tFidelity = 0.500499\tKL_Divergence = 3.990518\n",
      "Epoch: 31\tFidelity = 0.500529\tKL_Divergence = 3.958290\n",
      "Epoch: 32\tFidelity = 0.500484\tKL_Divergence = 4.007459\n",
      "Epoch: 33\tFidelity = 0.500485\tKL_Divergence = 4.005569\n",
      "Epoch: 34\tFidelity = 0.500531\tKL_Divergence = 3.955417\n",
      "Epoch: 35\tFidelity = 0.500514\tKL_Divergence = 3.974059\n",
      "Epoch: 36\tFidelity = 0.500490\tKL_Divergence = 4.000050\n",
      "Epoch: 37\tFidelity = 0.500532\tKL_Divergence = 3.954816\n",
      "Epoch: 38\tFidelity = 0.500517\tKL_Divergence = 3.970815\n",
      "Epoch: 39\tFidelity = 0.500465\tKL_Divergence = 4.029727\n",
      "Epoch: 40\tFidelity = 0.500507\tKL_Divergence = 3.980824\n",
      "Epoch: 41\tFidelity = 0.500461\tKL_Divergence = 4.033588\n",
      "Epoch: 42\tFidelity = 0.500475\tKL_Divergence = 4.017403\n",
      "Epoch: 43\tFidelity = 0.500497\tKL_Divergence = 3.992287\n",
      "Epoch: 44\tFidelity = 0.500516\tKL_Divergence = 3.971546\n",
      "Epoch: 45\tFidelity = 0.500536\tKL_Divergence = 3.950426\n",
      "Epoch: 46\tFidelity = 0.500481\tKL_Divergence = 4.010719\n",
      "Epoch: 47\tFidelity = 0.500509\tKL_Divergence = 3.979257\n",
      "Epoch: 48\tFidelity = 0.500494\tKL_Divergence = 3.995380\n",
      "Epoch: 49\tFidelity = 0.500516\tKL_Divergence = 3.971364\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:36:21,392] Trial 460 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500537\tKL_Divergence = 3.949765\n",
      "Total time elapsed during training: 37.835 s\n",
      "Trial 460 pruned. \n",
      "Epoch: 1\tFidelity = 0.500579\tKL_Divergence = 3.907492\n",
      "Epoch: 2\tFidelity = 0.500491\tKL_Divergence = 3.999184\n",
      "Epoch: 3\tFidelity = 0.500460\tKL_Divergence = 4.035368\n",
      "Epoch: 4\tFidelity = 0.500471\tKL_Divergence = 4.022362\n",
      "Epoch: 5\tFidelity = 0.500543\tKL_Divergence = 3.942944\n",
      "Epoch: 6\tFidelity = 0.500545\tKL_Divergence = 3.940889\n",
      "Epoch: 7\tFidelity = 0.500524\tKL_Divergence = 3.963032\n",
      "Epoch: 8\tFidelity = 0.500538\tKL_Divergence = 3.947971\n",
      "Epoch: 9\tFidelity = 0.500552\tKL_Divergence = 3.934080\n",
      "Epoch: 10\tFidelity = 0.500469\tKL_Divergence = 4.024547\n",
      "Epoch: 11\tFidelity = 0.500476\tKL_Divergence = 4.016287\n",
      "Epoch: 12\tFidelity = 0.500500\tKL_Divergence = 3.989259\n",
      "Epoch: 13\tFidelity = 0.500462\tKL_Divergence = 4.032307\n",
      "Epoch: 14\tFidelity = 0.500450\tKL_Divergence = 4.047713\n",
      "Epoch: 15\tFidelity = 0.500505\tKL_Divergence = 3.983110\n",
      "Epoch: 16\tFidelity = 0.500470\tKL_Divergence = 4.023467\n",
      "Epoch: 17\tFidelity = 0.500472\tKL_Divergence = 4.020944\n",
      "Epoch: 18\tFidelity = 0.500537\tKL_Divergence = 3.949241\n",
      "Epoch: 19\tFidelity = 0.500531\tKL_Divergence = 3.955423\n",
      "Epoch: 20\tFidelity = 0.500533\tKL_Divergence = 3.953811\n",
      "Epoch: 21\tFidelity = 0.500487\tKL_Divergence = 4.003569\n",
      "Epoch: 22\tFidelity = 0.500532\tKL_Divergence = 3.954364\n",
      "Epoch: 23\tFidelity = 0.500550\tKL_Divergence = 3.935700\n",
      "Epoch: 24\tFidelity = 0.500576\tKL_Divergence = 3.910684\n",
      "Epoch: 25\tFidelity = 0.500514\tKL_Divergence = 3.973210\n",
      "Epoch: 26\tFidelity = 0.500479\tKL_Divergence = 4.012806\n",
      "Epoch: 27\tFidelity = 0.500500\tKL_Divergence = 3.988511\n",
      "Epoch: 28\tFidelity = 0.500548\tKL_Divergence = 3.937734\n",
      "Epoch: 29\tFidelity = 0.500504\tKL_Divergence = 3.984892\n",
      "Epoch: 30\tFidelity = 0.500479\tKL_Divergence = 4.012526\n",
      "Epoch: 31\tFidelity = 0.500467\tKL_Divergence = 4.026999\n",
      "Epoch: 32\tFidelity = 0.500527\tKL_Divergence = 3.959722\n",
      "Epoch: 33\tFidelity = 0.500478\tKL_Divergence = 4.013713\n",
      "Epoch: 34\tFidelity = 0.500452\tKL_Divergence = 4.044717\n",
      "Epoch: 35\tFidelity = 0.500538\tKL_Divergence = 3.948171\n",
      "Epoch: 36\tFidelity = 0.500474\tKL_Divergence = 4.019118\n",
      "Epoch: 37\tFidelity = 0.500545\tKL_Divergence = 3.941146\n",
      "Epoch: 38\tFidelity = 0.500483\tKL_Divergence = 4.007507\n",
      "Epoch: 39\tFidelity = 0.500510\tKL_Divergence = 3.977595\n",
      "Epoch: 40\tFidelity = 0.500498\tKL_Divergence = 3.991583\n",
      "Epoch: 41\tFidelity = 0.500473\tKL_Divergence = 4.019772\n",
      "Epoch: 42\tFidelity = 0.500517\tKL_Divergence = 3.970785\n",
      "Epoch: 43\tFidelity = 0.500473\tKL_Divergence = 4.019989\n",
      "Epoch: 44\tFidelity = 0.500463\tKL_Divergence = 4.031104\n",
      "Epoch: 45\tFidelity = 0.500477\tKL_Divergence = 4.014815\n",
      "Epoch: 46\tFidelity = 0.500518\tKL_Divergence = 3.969651\n",
      "Epoch: 47\tFidelity = 0.500505\tKL_Divergence = 3.983509\n",
      "Epoch: 48\tFidelity = 0.500477\tKL_Divergence = 4.015692\n",
      "Epoch: 49\tFidelity = 0.500498\tKL_Divergence = 3.990919\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:37:00,016] Trial 461 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500463\tKL_Divergence = 4.031482\n",
      "Total time elapsed during training: 38.460 s\n",
      "Trial 461 pruned. \n",
      "Epoch: 1\tFidelity = 0.500529\tKL_Divergence = 3.957857\n",
      "Epoch: 2\tFidelity = 0.500473\tKL_Divergence = 4.019218\n",
      "Epoch: 3\tFidelity = 0.500450\tKL_Divergence = 4.047324\n",
      "Epoch: 4\tFidelity = 0.500445\tKL_Divergence = 4.054147\n",
      "Epoch: 5\tFidelity = 0.500458\tKL_Divergence = 4.037334\n",
      "Epoch: 6\tFidelity = 0.500507\tKL_Divergence = 3.981609\n",
      "Epoch: 7\tFidelity = 0.500389\tKL_Divergence = 4.128088\n",
      "Epoch: 8\tFidelity = 0.500501\tKL_Divergence = 3.988321\n",
      "Epoch: 9\tFidelity = 0.500509\tKL_Divergence = 3.979455\n",
      "Epoch: 10\tFidelity = 0.500525\tKL_Divergence = 3.962350\n",
      "Epoch: 11\tFidelity = 0.500572\tKL_Divergence = 3.914534\n",
      "Epoch: 12\tFidelity = 0.500419\tKL_Divergence = 4.086551\n",
      "Epoch: 13\tFidelity = 0.500611\tKL_Divergence = 3.877511\n",
      "Epoch: 14\tFidelity = 0.500605\tKL_Divergence = 3.882797\n",
      "Epoch: 15\tFidelity = 0.500547\tKL_Divergence = 3.938338\n",
      "Epoch: 16\tFidelity = 0.500498\tKL_Divergence = 3.990918\n",
      "Epoch: 17\tFidelity = 0.500514\tKL_Divergence = 3.973308\n",
      "Epoch: 18\tFidelity = 0.500502\tKL_Divergence = 3.986760\n",
      "Epoch: 19\tFidelity = 0.500503\tKL_Divergence = 3.985905\n",
      "Epoch: 20\tFidelity = 0.500474\tKL_Divergence = 4.018017\n",
      "Epoch: 21\tFidelity = 0.500517\tKL_Divergence = 3.970639\n",
      "Epoch: 22\tFidelity = 0.500457\tKL_Divergence = 4.038355\n",
      "Epoch: 23\tFidelity = 0.500474\tKL_Divergence = 4.018563\n",
      "Epoch: 24\tFidelity = 0.500597\tKL_Divergence = 3.890545\n",
      "Epoch: 25\tFidelity = 0.500583\tKL_Divergence = 3.903999\n",
      "Epoch: 26\tFidelity = 0.500549\tKL_Divergence = 3.937642\n",
      "Epoch: 27\tFidelity = 0.500444\tKL_Divergence = 4.055443\n",
      "Epoch: 28\tFidelity = 0.500459\tKL_Divergence = 4.036250\n",
      "Epoch: 29\tFidelity = 0.500492\tKL_Divergence = 3.998421\n",
      "Epoch: 30\tFidelity = 0.500478\tKL_Divergence = 4.013878\n",
      "Epoch: 31\tFidelity = 0.500404\tKL_Divergence = 4.107872\n",
      "Epoch: 32\tFidelity = 0.500531\tKL_Divergence = 3.955109\n",
      "Epoch: 33\tFidelity = 0.500525\tKL_Divergence = 3.961997\n",
      "Epoch: 34\tFidelity = 0.500595\tKL_Divergence = 3.891958\n",
      "Epoch: 35\tFidelity = 0.500588\tKL_Divergence = 3.898486\n",
      "Epoch: 36\tFidelity = 0.500500\tKL_Divergence = 3.988882\n",
      "Epoch: 37\tFidelity = 0.500512\tKL_Divergence = 3.975578\n",
      "Epoch: 38\tFidelity = 0.500468\tKL_Divergence = 4.025743\n",
      "Epoch: 39\tFidelity = 0.500510\tKL_Divergence = 3.977852\n",
      "Epoch: 40\tFidelity = 0.500585\tKL_Divergence = 3.901704\n",
      "Epoch: 41\tFidelity = 0.500435\tKL_Divergence = 4.066464\n",
      "Epoch: 42\tFidelity = 0.500534\tKL_Divergence = 3.951878\n",
      "Epoch: 43\tFidelity = 0.500504\tKL_Divergence = 3.984181\n",
      "Epoch: 44\tFidelity = 0.500592\tKL_Divergence = 3.895246\n",
      "Epoch: 45\tFidelity = 0.500421\tKL_Divergence = 4.084057\n",
      "Epoch: 46\tFidelity = 0.500452\tKL_Divergence = 4.044860\n",
      "Epoch: 47\tFidelity = 0.500536\tKL_Divergence = 3.950516\n",
      "Epoch: 48\tFidelity = 0.500496\tKL_Divergence = 3.993486\n",
      "Epoch: 49\tFidelity = 0.500481\tKL_Divergence = 4.010143\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:37:45,959] Trial 462 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500510\tKL_Divergence = 3.978538\n",
      "Total time elapsed during training: 45.759 s\n",
      "Trial 462 pruned. \n",
      "Epoch: 1\tFidelity = 0.500529\tKL_Divergence = 3.957534\n",
      "Epoch: 2\tFidelity = 0.500478\tKL_Divergence = 4.013657\n",
      "Epoch: 3\tFidelity = 0.500481\tKL_Divergence = 4.010755\n",
      "Epoch: 4\tFidelity = 0.500559\tKL_Divergence = 3.927269\n",
      "Epoch: 5\tFidelity = 0.500500\tKL_Divergence = 3.989044\n",
      "Epoch: 6\tFidelity = 0.500583\tKL_Divergence = 3.904218\n",
      "Epoch: 7\tFidelity = 0.500547\tKL_Divergence = 3.938965\n",
      "Epoch: 8\tFidelity = 0.500496\tKL_Divergence = 3.993323\n",
      "Epoch: 9\tFidelity = 0.500510\tKL_Divergence = 3.977739\n",
      "Epoch: 10\tFidelity = 0.500555\tKL_Divergence = 3.931073\n",
      "Epoch: 11\tFidelity = 0.500513\tKL_Divergence = 3.975227\n",
      "Epoch: 12\tFidelity = 0.500477\tKL_Divergence = 4.015643\n",
      "Epoch: 13\tFidelity = 0.500573\tKL_Divergence = 3.913391\n",
      "Epoch: 14\tFidelity = 0.500465\tKL_Divergence = 4.028879\n",
      "Epoch: 15\tFidelity = 0.500509\tKL_Divergence = 3.978658\n",
      "Epoch: 16\tFidelity = 0.500502\tKL_Divergence = 3.987109\n",
      "Epoch: 17\tFidelity = 0.500526\tKL_Divergence = 3.961037\n",
      "Epoch: 18\tFidelity = 0.500538\tKL_Divergence = 3.948617\n",
      "Epoch: 19\tFidelity = 0.500604\tKL_Divergence = 3.884049\n",
      "Epoch: 20\tFidelity = 0.500529\tKL_Divergence = 3.957990\n",
      "Epoch: 21\tFidelity = 0.500497\tKL_Divergence = 3.992648\n",
      "Epoch: 22\tFidelity = 0.500522\tKL_Divergence = 3.964917\n",
      "Epoch: 23\tFidelity = 0.500558\tKL_Divergence = 3.928284\n",
      "Epoch: 24\tFidelity = 0.500492\tKL_Divergence = 3.998529\n",
      "Epoch: 25\tFidelity = 0.500553\tKL_Divergence = 3.933177\n",
      "Epoch: 26\tFidelity = 0.500482\tKL_Divergence = 4.009844\n",
      "Epoch: 27\tFidelity = 0.500515\tKL_Divergence = 3.972321\n",
      "Epoch: 28\tFidelity = 0.500513\tKL_Divergence = 3.974835\n",
      "Epoch: 29\tFidelity = 0.500468\tKL_Divergence = 4.025684\n",
      "Epoch: 30\tFidelity = 0.500505\tKL_Divergence = 3.983856\n",
      "Epoch: 31\tFidelity = 0.500571\tKL_Divergence = 3.915588\n",
      "Epoch: 32\tFidelity = 0.500548\tKL_Divergence = 3.938362\n",
      "Epoch: 33\tFidelity = 0.500586\tKL_Divergence = 3.901302\n",
      "Epoch: 34\tFidelity = 0.500511\tKL_Divergence = 3.976906\n",
      "Epoch: 35\tFidelity = 0.500494\tKL_Divergence = 3.995371\n",
      "Epoch: 36\tFidelity = 0.500467\tKL_Divergence = 4.026858\n",
      "Epoch: 37\tFidelity = 0.500464\tKL_Divergence = 4.030921\n",
      "Epoch: 38\tFidelity = 0.500530\tKL_Divergence = 3.957271\n",
      "Epoch: 39\tFidelity = 0.500497\tKL_Divergence = 3.992430\n",
      "Epoch: 40\tFidelity = 0.500476\tKL_Divergence = 4.016506\n",
      "Epoch: 41\tFidelity = 0.500500\tKL_Divergence = 3.988542\n",
      "Epoch: 42\tFidelity = 0.500532\tKL_Divergence = 3.954959\n",
      "Epoch: 43\tFidelity = 0.500520\tKL_Divergence = 3.967030\n",
      "Epoch: 44\tFidelity = 0.500483\tKL_Divergence = 4.008692\n",
      "Epoch: 45\tFidelity = 0.500485\tKL_Divergence = 4.006188\n",
      "Epoch: 46\tFidelity = 0.500544\tKL_Divergence = 3.942290\n",
      "Epoch: 47\tFidelity = 0.500470\tKL_Divergence = 4.022918\n",
      "Epoch: 48\tFidelity = 0.500483\tKL_Divergence = 4.007761\n",
      "Epoch: 49\tFidelity = 0.500460\tKL_Divergence = 4.034721\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:38:32,502] Trial 463 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500484\tKL_Divergence = 4.007422\n",
      "Total time elapsed during training: 46.368 s\n",
      "Trial 463 pruned. \n",
      "Epoch: 1\tFidelity = 0.500511\tKL_Divergence = 3.977287\n",
      "Epoch: 2\tFidelity = 0.500499\tKL_Divergence = 3.990662\n",
      "Epoch: 3\tFidelity = 0.500552\tKL_Divergence = 3.934515\n",
      "Epoch: 4\tFidelity = 0.500488\tKL_Divergence = 4.003051\n",
      "Epoch: 5\tFidelity = 0.500474\tKL_Divergence = 4.018578\n",
      "Epoch: 6\tFidelity = 0.500464\tKL_Divergence = 4.031097\n",
      "Epoch: 7\tFidelity = 0.500514\tKL_Divergence = 3.974016\n",
      "Epoch: 8\tFidelity = 0.500494\tKL_Divergence = 3.995828\n",
      "Epoch: 9\tFidelity = 0.500505\tKL_Divergence = 3.983114\n",
      "Epoch: 10\tFidelity = 0.500473\tKL_Divergence = 4.020351\n",
      "Epoch: 11\tFidelity = 0.500470\tKL_Divergence = 4.023901\n",
      "Epoch: 12\tFidelity = 0.500483\tKL_Divergence = 4.007849\n",
      "Epoch: 13\tFidelity = 0.500518\tKL_Divergence = 3.969493\n",
      "Epoch: 14\tFidelity = 0.500502\tKL_Divergence = 3.986756\n",
      "Epoch: 15\tFidelity = 0.500482\tKL_Divergence = 4.009470\n",
      "Epoch: 16\tFidelity = 0.500497\tKL_Divergence = 3.992571\n",
      "Epoch: 17\tFidelity = 0.500525\tKL_Divergence = 3.961787\n",
      "Epoch: 18\tFidelity = 0.500511\tKL_Divergence = 3.976941\n",
      "Epoch: 19\tFidelity = 0.500459\tKL_Divergence = 4.036929\n",
      "Epoch: 20\tFidelity = 0.500456\tKL_Divergence = 4.039618\n",
      "Epoch: 21\tFidelity = 0.500523\tKL_Divergence = 3.964501\n",
      "Epoch: 22\tFidelity = 0.500478\tKL_Divergence = 4.014552\n",
      "Epoch: 23\tFidelity = 0.500485\tKL_Divergence = 4.006413\n",
      "Epoch: 24\tFidelity = 0.500539\tKL_Divergence = 3.947582\n",
      "Epoch: 25\tFidelity = 0.500472\tKL_Divergence = 4.021382\n",
      "Epoch: 26\tFidelity = 0.500532\tKL_Divergence = 3.954560\n",
      "Epoch: 27\tFidelity = 0.500467\tKL_Divergence = 4.026771\n",
      "Epoch: 28\tFidelity = 0.500455\tKL_Divergence = 4.041435\n",
      "Epoch: 29\tFidelity = 0.500507\tKL_Divergence = 3.981207\n",
      "Epoch: 30\tFidelity = 0.500482\tKL_Divergence = 4.009940\n",
      "Epoch: 31\tFidelity = 0.500486\tKL_Divergence = 4.004638\n",
      "Epoch: 32\tFidelity = 0.500503\tKL_Divergence = 3.985318\n",
      "Epoch: 33\tFidelity = 0.500515\tKL_Divergence = 3.972485\n",
      "Epoch: 34\tFidelity = 0.500477\tKL_Divergence = 4.015400\n",
      "Epoch: 35\tFidelity = 0.500499\tKL_Divergence = 3.990217\n",
      "Epoch: 36\tFidelity = 0.500495\tKL_Divergence = 3.994539\n",
      "Epoch: 37\tFidelity = 0.500465\tKL_Divergence = 4.029565\n",
      "Epoch: 38\tFidelity = 0.500484\tKL_Divergence = 4.006559\n",
      "Epoch: 39\tFidelity = 0.500464\tKL_Divergence = 4.030147\n",
      "Epoch: 40\tFidelity = 0.500509\tKL_Divergence = 3.979130\n",
      "Epoch: 41\tFidelity = 0.500458\tKL_Divergence = 4.038289\n",
      "Epoch: 42\tFidelity = 0.500513\tKL_Divergence = 3.975284\n",
      "Epoch: 43\tFidelity = 0.500474\tKL_Divergence = 4.018763\n",
      "Epoch: 44\tFidelity = 0.500503\tKL_Divergence = 3.985914\n",
      "Epoch: 45\tFidelity = 0.500533\tKL_Divergence = 3.953317\n",
      "Epoch: 46\tFidelity = 0.500475\tKL_Divergence = 4.018016\n",
      "Epoch: 47\tFidelity = 0.500529\tKL_Divergence = 3.957657\n",
      "Epoch: 48\tFidelity = 0.500499\tKL_Divergence = 3.990592\n",
      "Epoch: 49\tFidelity = 0.500510\tKL_Divergence = 3.978131\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:39:05,109] Trial 464 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500519\tKL_Divergence = 3.968663\n",
      "Total time elapsed during training: 32.440 s\n",
      "Trial 464 pruned. \n",
      "Epoch: 1\tFidelity = 0.500580\tKL_Divergence = 3.906608\n",
      "Epoch: 2\tFidelity = 0.500499\tKL_Divergence = 3.990391\n",
      "Epoch: 3\tFidelity = 0.500501\tKL_Divergence = 3.988030\n",
      "Epoch: 4\tFidelity = 0.500499\tKL_Divergence = 3.990634\n",
      "Epoch: 5\tFidelity = 0.500530\tKL_Divergence = 3.956605\n",
      "Epoch: 6\tFidelity = 0.500502\tKL_Divergence = 3.987170\n",
      "Epoch: 7\tFidelity = 0.500474\tKL_Divergence = 4.018164\n",
      "Epoch: 8\tFidelity = 0.500467\tKL_Divergence = 4.026415\n",
      "Epoch: 9\tFidelity = 0.500485\tKL_Divergence = 4.005515\n",
      "Epoch: 10\tFidelity = 0.500493\tKL_Divergence = 3.997022\n",
      "Epoch: 11\tFidelity = 0.500479\tKL_Divergence = 4.012847\n",
      "Epoch: 12\tFidelity = 0.500429\tKL_Divergence = 4.074423\n",
      "Epoch: 13\tFidelity = 0.500485\tKL_Divergence = 4.006027\n",
      "Epoch: 14\tFidelity = 0.500463\tKL_Divergence = 4.031802\n",
      "Epoch: 15\tFidelity = 0.500467\tKL_Divergence = 4.027337\n",
      "Epoch: 16\tFidelity = 0.500536\tKL_Divergence = 3.950200\n",
      "Epoch: 17\tFidelity = 0.500500\tKL_Divergence = 3.989508\n",
      "Epoch: 18\tFidelity = 0.500523\tKL_Divergence = 3.964498\n",
      "Epoch: 19\tFidelity = 0.500481\tKL_Divergence = 4.010554\n",
      "Epoch: 20\tFidelity = 0.500503\tKL_Divergence = 3.985596\n",
      "Epoch: 21\tFidelity = 0.500614\tKL_Divergence = 3.875485\n",
      "Epoch: 22\tFidelity = 0.500526\tKL_Divergence = 3.961419\n",
      "Epoch: 23\tFidelity = 0.500524\tKL_Divergence = 3.963420\n",
      "Epoch: 24\tFidelity = 0.500475\tKL_Divergence = 4.017840\n",
      "Epoch: 25\tFidelity = 0.500553\tKL_Divergence = 3.933356\n",
      "Epoch: 26\tFidelity = 0.500543\tKL_Divergence = 3.943030\n",
      "Epoch: 27\tFidelity = 0.500522\tKL_Divergence = 3.965085\n",
      "Epoch: 28\tFidelity = 0.500560\tKL_Divergence = 3.925693\n",
      "Epoch: 29\tFidelity = 0.500548\tKL_Divergence = 3.938552\n",
      "Epoch: 30\tFidelity = 0.500462\tKL_Divergence = 4.033163\n",
      "Epoch: 31\tFidelity = 0.500521\tKL_Divergence = 3.966741\n",
      "Epoch: 32\tFidelity = 0.500528\tKL_Divergence = 3.958633\n",
      "Epoch: 33\tFidelity = 0.500480\tKL_Divergence = 4.011847\n",
      "Epoch: 34\tFidelity = 0.500524\tKL_Divergence = 3.962682\n",
      "Epoch: 35\tFidelity = 0.500513\tKL_Divergence = 3.974909\n",
      "Epoch: 36\tFidelity = 0.500469\tKL_Divergence = 4.024192\n",
      "Epoch: 37\tFidelity = 0.500494\tKL_Divergence = 3.996043\n",
      "Epoch: 38\tFidelity = 0.500540\tKL_Divergence = 3.946157\n",
      "Epoch: 39\tFidelity = 0.500523\tKL_Divergence = 3.963924\n",
      "Epoch: 40\tFidelity = 0.500479\tKL_Divergence = 4.012390\n",
      "Epoch: 41\tFidelity = 0.500491\tKL_Divergence = 3.999025\n",
      "Epoch: 42\tFidelity = 0.500522\tKL_Divergence = 3.965492\n",
      "Epoch: 43\tFidelity = 0.500508\tKL_Divergence = 3.979887\n",
      "Epoch: 44\tFidelity = 0.500527\tKL_Divergence = 3.959623\n",
      "Epoch: 45\tFidelity = 0.500581\tKL_Divergence = 3.905611\n",
      "Epoch: 46\tFidelity = 0.500564\tKL_Divergence = 3.922547\n",
      "Epoch: 47\tFidelity = 0.500489\tKL_Divergence = 4.001779\n",
      "Epoch: 48\tFidelity = 0.500532\tKL_Divergence = 3.954913\n",
      "Epoch: 49\tFidelity = 0.500504\tKL_Divergence = 3.985099\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:39:37,757] Trial 465 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500494\tKL_Divergence = 3.995452\n",
      "Total time elapsed during training: 32.464 s\n",
      "Trial 465 pruned. \n",
      "Epoch: 1\tFidelity = 0.500554\tKL_Divergence = 3.932102\n",
      "Epoch: 2\tFidelity = 0.500508\tKL_Divergence = 3.979692\n",
      "Epoch: 3\tFidelity = 0.500415\tKL_Divergence = 4.091953\n",
      "Epoch: 4\tFidelity = 0.500462\tKL_Divergence = 4.032982\n",
      "Epoch: 5\tFidelity = 0.500432\tKL_Divergence = 4.070218\n",
      "Epoch: 6\tFidelity = 0.500474\tKL_Divergence = 4.018052\n",
      "Epoch: 7\tFidelity = 0.500558\tKL_Divergence = 3.927982\n",
      "Epoch: 8\tFidelity = 0.500553\tKL_Divergence = 3.932623\n",
      "Epoch: 9\tFidelity = 0.500481\tKL_Divergence = 4.010066\n",
      "Epoch: 10\tFidelity = 0.500518\tKL_Divergence = 3.969047\n",
      "Epoch: 11\tFidelity = 0.500541\tKL_Divergence = 3.944840\n",
      "Epoch: 12\tFidelity = 0.500438\tKL_Divergence = 4.062975\n",
      "Epoch: 13\tFidelity = 0.500503\tKL_Divergence = 3.985923\n",
      "Epoch: 14\tFidelity = 0.500606\tKL_Divergence = 3.882714\n",
      "Epoch: 15\tFidelity = 0.500512\tKL_Divergence = 3.976173\n",
      "Epoch: 16\tFidelity = 0.500532\tKL_Divergence = 3.954958\n",
      "Epoch: 17\tFidelity = 0.500422\tKL_Divergence = 4.082817\n",
      "Epoch: 18\tFidelity = 0.500674\tKL_Divergence = 3.823328\n",
      "Epoch: 19\tFidelity = 0.500474\tKL_Divergence = 4.018665\n",
      "Epoch: 20\tFidelity = 0.500542\tKL_Divergence = 3.944219\n",
      "Epoch: 21\tFidelity = 0.500611\tKL_Divergence = 3.877930\n",
      "Epoch: 22\tFidelity = 0.500652\tKL_Divergence = 3.841240\n",
      "Epoch: 23\tFidelity = 0.500520\tKL_Divergence = 3.967314\n",
      "Epoch: 24\tFidelity = 0.500547\tKL_Divergence = 3.938561\n",
      "Epoch: 25\tFidelity = 0.500573\tKL_Divergence = 3.912787\n",
      "Epoch: 26\tFidelity = 0.500486\tKL_Divergence = 4.004062\n",
      "Epoch: 27\tFidelity = 0.500462\tKL_Divergence = 4.032264\n",
      "Epoch: 28\tFidelity = 0.500517\tKL_Divergence = 3.970471\n",
      "Epoch: 29\tFidelity = 0.500566\tKL_Divergence = 3.920035\n",
      "Epoch: 30\tFidelity = 0.500607\tKL_Divergence = 3.880736\n",
      "Epoch: 31\tFidelity = 0.500523\tKL_Divergence = 3.964114\n",
      "Epoch: 32\tFidelity = 0.500468\tKL_Divergence = 4.024903\n",
      "Epoch: 33\tFidelity = 0.500584\tKL_Divergence = 3.902646\n",
      "Epoch: 34\tFidelity = 0.500525\tKL_Divergence = 3.961641\n",
      "Epoch: 35\tFidelity = 0.500585\tKL_Divergence = 3.901891\n",
      "Epoch: 36\tFidelity = 0.500558\tKL_Divergence = 3.927976\n",
      "Epoch: 37\tFidelity = 0.500820\tKL_Divergence = 3.714317\n",
      "Epoch: 38\tFidelity = 0.500619\tKL_Divergence = 3.870376\n",
      "Epoch: 39\tFidelity = 0.500458\tKL_Divergence = 4.036831\n",
      "Epoch: 40\tFidelity = 0.500499\tKL_Divergence = 3.989554\n",
      "Epoch: 41\tFidelity = 0.500512\tKL_Divergence = 3.975690\n",
      "Epoch: 42\tFidelity = 0.500578\tKL_Divergence = 3.907981\n",
      "Epoch: 43\tFidelity = 0.500690\tKL_Divergence = 3.810212\n",
      "Epoch: 44\tFidelity = 0.500647\tKL_Divergence = 3.845734\n",
      "Epoch: 45\tFidelity = 0.500610\tKL_Divergence = 3.878822\n",
      "Epoch: 46\tFidelity = 0.500570\tKL_Divergence = 3.915937\n",
      "Epoch: 47\tFidelity = 0.500597\tKL_Divergence = 3.890645\n",
      "Epoch: 48\tFidelity = 0.500632\tKL_Divergence = 3.858847\n",
      "Epoch: 49\tFidelity = 0.500534\tKL_Divergence = 3.951995\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:41:00,530] Trial 466 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500541\tKL_Divergence = 3.945282\n",
      "Total time elapsed during training: 82.603 s\n",
      "Trial 466 pruned. \n",
      "Epoch: 1\tFidelity = 0.500506\tKL_Divergence = 3.982600\n",
      "Epoch: 2\tFidelity = 0.500533\tKL_Divergence = 3.953568\n",
      "Epoch: 3\tFidelity = 0.500544\tKL_Divergence = 3.941940\n",
      "Epoch: 4\tFidelity = 0.500565\tKL_Divergence = 3.921370\n",
      "Epoch: 5\tFidelity = 0.500569\tKL_Divergence = 3.917310\n",
      "Epoch: 6\tFidelity = 0.500554\tKL_Divergence = 3.932317\n",
      "Epoch: 7\tFidelity = 0.500591\tKL_Divergence = 3.895652\n",
      "Epoch: 8\tFidelity = 0.500523\tKL_Divergence = 3.963290\n",
      "Epoch: 9\tFidelity = 0.500499\tKL_Divergence = 3.989496\n",
      "Epoch: 10\tFidelity = 0.500525\tKL_Divergence = 3.961700\n",
      "Epoch: 11\tFidelity = 0.500491\tKL_Divergence = 3.998228\n",
      "Epoch: 12\tFidelity = 0.500456\tKL_Divergence = 4.039605\n",
      "Epoch: 13\tFidelity = 0.500504\tKL_Divergence = 3.984480\n",
      "Epoch: 14\tFidelity = 0.500561\tKL_Divergence = 3.925072\n",
      "Epoch: 15\tFidelity = 0.500570\tKL_Divergence = 3.916118\n",
      "Epoch: 16\tFidelity = 0.500535\tKL_Divergence = 3.950935\n",
      "Epoch: 17\tFidelity = 0.500504\tKL_Divergence = 3.984279\n",
      "Epoch: 18\tFidelity = 0.500571\tKL_Divergence = 3.915570\n",
      "Epoch: 19\tFidelity = 0.500573\tKL_Divergence = 3.912787\n",
      "Epoch: 20\tFidelity = 0.500559\tKL_Divergence = 3.926587\n",
      "Epoch: 21\tFidelity = 0.500579\tKL_Divergence = 3.907872\n",
      "Epoch: 22\tFidelity = 0.500552\tKL_Divergence = 3.933768\n",
      "Epoch: 23\tFidelity = 0.500517\tKL_Divergence = 3.970662\n",
      "Epoch: 24\tFidelity = 0.500547\tKL_Divergence = 3.938607\n",
      "Epoch: 25\tFidelity = 0.500593\tKL_Divergence = 3.893804\n",
      "Epoch: 26\tFidelity = 0.500553\tKL_Divergence = 3.932865\n",
      "Epoch: 27\tFidelity = 0.500558\tKL_Divergence = 3.928215\n",
      "Epoch: 28\tFidelity = 0.500539\tKL_Divergence = 3.947612\n",
      "Epoch: 29\tFidelity = 0.500555\tKL_Divergence = 3.931129\n",
      "Epoch: 30\tFidelity = 0.500572\tKL_Divergence = 3.914480\n",
      "Epoch: 31\tFidelity = 0.500523\tKL_Divergence = 3.963967\n",
      "Epoch: 32\tFidelity = 0.500529\tKL_Divergence = 3.957202\n",
      "Epoch: 33\tFidelity = 0.500519\tKL_Divergence = 3.968190\n",
      "Epoch: 34\tFidelity = 0.500512\tKL_Divergence = 3.975933\n",
      "Epoch: 35\tFidelity = 0.500511\tKL_Divergence = 3.976763\n",
      "Epoch: 36\tFidelity = 0.500543\tKL_Divergence = 3.942762\n",
      "Epoch: 37\tFidelity = 0.500581\tKL_Divergence = 3.905463\n",
      "Epoch: 38\tFidelity = 0.500558\tKL_Divergence = 3.928094\n",
      "Epoch: 39\tFidelity = 0.500579\tKL_Divergence = 3.907027\n",
      "Epoch: 40\tFidelity = 0.500551\tKL_Divergence = 3.934626\n",
      "Epoch: 41\tFidelity = 0.500560\tKL_Divergence = 3.926425\n",
      "Epoch: 42\tFidelity = 0.500539\tKL_Divergence = 3.946837\n",
      "Epoch: 43\tFidelity = 0.500479\tKL_Divergence = 4.013086\n",
      "Epoch: 44\tFidelity = 0.500536\tKL_Divergence = 3.950750\n",
      "Epoch: 45\tFidelity = 0.500527\tKL_Divergence = 3.959744\n",
      "Epoch: 46\tFidelity = 0.500503\tKL_Divergence = 3.985735\n",
      "Epoch: 47\tFidelity = 0.500546\tKL_Divergence = 3.940446\n",
      "Epoch: 48\tFidelity = 0.500504\tKL_Divergence = 3.984320\n",
      "Epoch: 49\tFidelity = 0.500551\tKL_Divergence = 3.934532\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:41:39,984] Trial 467 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500602\tKL_Divergence = 3.886098\n",
      "Total time elapsed during training: 39.277 s\n",
      "Trial 467 pruned. \n",
      "Epoch: 1\tFidelity = 0.500529\tKL_Divergence = 3.957311\n",
      "Epoch: 2\tFidelity = 0.500512\tKL_Divergence = 3.975099\n",
      "Epoch: 3\tFidelity = 0.500506\tKL_Divergence = 3.981453\n",
      "Epoch: 4\tFidelity = 0.500538\tKL_Divergence = 3.948098\n",
      "Epoch: 5\tFidelity = 0.500545\tKL_Divergence = 3.940889\n",
      "Epoch: 6\tFidelity = 0.500472\tKL_Divergence = 4.020337\n",
      "Epoch: 7\tFidelity = 0.500547\tKL_Divergence = 3.938875\n",
      "Epoch: 8\tFidelity = 0.500549\tKL_Divergence = 3.936767\n",
      "Epoch: 9\tFidelity = 0.500571\tKL_Divergence = 3.914567\n",
      "Epoch: 10\tFidelity = 0.500468\tKL_Divergence = 4.025054\n",
      "Epoch: 11\tFidelity = 0.500548\tKL_Divergence = 3.937745\n",
      "Epoch: 12\tFidelity = 0.500548\tKL_Divergence = 3.937768\n",
      "Epoch: 13\tFidelity = 0.500507\tKL_Divergence = 3.981177\n",
      "Epoch: 14\tFidelity = 0.500589\tKL_Divergence = 3.896850\n",
      "Epoch: 15\tFidelity = 0.500546\tKL_Divergence = 3.939233\n",
      "Epoch: 16\tFidelity = 0.500513\tKL_Divergence = 3.973399\n",
      "Epoch: 17\tFidelity = 0.500559\tKL_Divergence = 3.926264\n",
      "Epoch: 18\tFidelity = 0.500541\tKL_Divergence = 3.944349\n",
      "Epoch: 19\tFidelity = 0.500547\tKL_Divergence = 3.938731\n",
      "Epoch: 20\tFidelity = 0.500504\tKL_Divergence = 3.984112\n",
      "Epoch: 21\tFidelity = 0.500507\tKL_Divergence = 3.980600\n",
      "Epoch: 22\tFidelity = 0.500581\tKL_Divergence = 3.904406\n",
      "Epoch: 23\tFidelity = 0.500505\tKL_Divergence = 3.982601\n",
      "Epoch: 24\tFidelity = 0.500483\tKL_Divergence = 4.007146\n",
      "Epoch: 25\tFidelity = 0.500535\tKL_Divergence = 3.949910\n",
      "Epoch: 26\tFidelity = 0.500498\tKL_Divergence = 3.989779\n",
      "Epoch: 27\tFidelity = 0.500556\tKL_Divergence = 3.928078\n",
      "Epoch: 28\tFidelity = 0.500530\tKL_Divergence = 3.954812\n",
      "Epoch: 29\tFidelity = 0.500575\tKL_Divergence = 3.909260\n",
      "Epoch: 30\tFidelity = 0.500588\tKL_Divergence = 3.897487\n",
      "Epoch: 31\tFidelity = 0.500534\tKL_Divergence = 3.950499\n",
      "Epoch: 32\tFidelity = 0.500472\tKL_Divergence = 4.018745\n",
      "Epoch: 33\tFidelity = 0.500505\tKL_Divergence = 3.981067\n",
      "Epoch: 34\tFidelity = 0.500585\tKL_Divergence = 3.899693\n",
      "Epoch: 35\tFidelity = 0.500507\tKL_Divergence = 3.979055\n",
      "Epoch: 36\tFidelity = 0.500502\tKL_Divergence = 3.985191\n",
      "Epoch: 37\tFidelity = 0.500522\tKL_Divergence = 3.962370\n",
      "Epoch: 38\tFidelity = 0.500535\tKL_Divergence = 3.948829\n",
      "Epoch: 39\tFidelity = 0.500583\tKL_Divergence = 3.900651\n",
      "Epoch: 40\tFidelity = 0.500565\tKL_Divergence = 3.918191\n",
      "Epoch: 41\tFidelity = 0.500512\tKL_Divergence = 3.973510\n",
      "Epoch: 42\tFidelity = 0.500502\tKL_Divergence = 3.984072\n",
      "Epoch: 43\tFidelity = 0.500500\tKL_Divergence = 3.986374\n",
      "Epoch: 44\tFidelity = 0.500571\tKL_Divergence = 3.913342\n",
      "Epoch: 45\tFidelity = 0.500516\tKL_Divergence = 3.968599\n",
      "Epoch: 46\tFidelity = 0.500564\tKL_Divergence = 3.920154\n",
      "Epoch: 47\tFidelity = 0.500575\tKL_Divergence = 3.909402\n",
      "Epoch: 48\tFidelity = 0.500546\tKL_Divergence = 3.938236\n",
      "Epoch: 49\tFidelity = 0.500533\tKL_Divergence = 3.951343\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:42:19,071] Trial 468 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500560\tKL_Divergence = 3.924303\n",
      "Total time elapsed during training: 38.908 s\n",
      "Trial 468 pruned. \n",
      "Epoch: 1\tFidelity = 0.500537\tKL_Divergence = 3.947356\n",
      "Epoch: 2\tFidelity = 0.500541\tKL_Divergence = 3.943205\n",
      "Epoch: 3\tFidelity = 0.500521\tKL_Divergence = 3.965156\n",
      "Epoch: 4\tFidelity = 0.500499\tKL_Divergence = 3.988828\n",
      "Epoch: 5\tFidelity = 0.500534\tKL_Divergence = 3.950590\n",
      "Epoch: 6\tFidelity = 0.500566\tKL_Divergence = 3.918552\n",
      "Epoch: 7\tFidelity = 0.500533\tKL_Divergence = 3.951981\n",
      "Epoch: 8\tFidelity = 0.500562\tKL_Divergence = 3.922965\n",
      "Epoch: 9\tFidelity = 0.500504\tKL_Divergence = 3.983595\n",
      "Epoch: 10\tFidelity = 0.500548\tKL_Divergence = 3.937077\n",
      "Epoch: 11\tFidelity = 0.500519\tKL_Divergence = 3.967436\n",
      "Epoch: 12\tFidelity = 0.500542\tKL_Divergence = 3.943708\n",
      "Epoch: 13\tFidelity = 0.500549\tKL_Divergence = 3.936310\n",
      "Epoch: 14\tFidelity = 0.500508\tKL_Divergence = 3.979676\n",
      "Epoch: 15\tFidelity = 0.500544\tKL_Divergence = 3.941497\n",
      "Epoch: 16\tFidelity = 0.500545\tKL_Divergence = 3.939772\n",
      "Epoch: 17\tFidelity = 0.500516\tKL_Divergence = 3.971159\n",
      "Epoch: 18\tFidelity = 0.500519\tKL_Divergence = 3.967924\n",
      "Epoch: 19\tFidelity = 0.500548\tKL_Divergence = 3.937795\n",
      "Epoch: 20\tFidelity = 0.500543\tKL_Divergence = 3.942895\n",
      "Epoch: 21\tFidelity = 0.500546\tKL_Divergence = 3.939294\n",
      "Epoch: 22\tFidelity = 0.500504\tKL_Divergence = 3.983511\n",
      "Epoch: 23\tFidelity = 0.500573\tKL_Divergence = 3.912934\n",
      "Epoch: 24\tFidelity = 0.500539\tKL_Divergence = 3.946318\n",
      "Epoch: 25\tFidelity = 0.500552\tKL_Divergence = 3.933861\n",
      "Epoch: 26\tFidelity = 0.500515\tKL_Divergence = 3.972276\n",
      "Epoch: 27\tFidelity = 0.500526\tKL_Divergence = 3.960792\n",
      "Epoch: 28\tFidelity = 0.500552\tKL_Divergence = 3.933938\n",
      "Epoch: 29\tFidelity = 0.500565\tKL_Divergence = 3.921126\n",
      "Epoch: 30\tFidelity = 0.500551\tKL_Divergence = 3.935050\n",
      "Epoch: 31\tFidelity = 0.500527\tKL_Divergence = 3.959050\n",
      "Epoch: 32\tFidelity = 0.500515\tKL_Divergence = 3.972147\n",
      "Epoch: 33\tFidelity = 0.500554\tKL_Divergence = 3.931479\n",
      "Epoch: 34\tFidelity = 0.500532\tKL_Divergence = 3.953856\n",
      "Epoch: 35\tFidelity = 0.500563\tKL_Divergence = 3.922402\n",
      "Epoch: 36\tFidelity = 0.500495\tKL_Divergence = 3.994289\n",
      "Epoch: 37\tFidelity = 0.500582\tKL_Divergence = 3.904785\n",
      "Epoch: 38\tFidelity = 0.500513\tKL_Divergence = 3.974761\n",
      "Epoch: 39\tFidelity = 0.500505\tKL_Divergence = 3.983364\n",
      "Epoch: 40\tFidelity = 0.500572\tKL_Divergence = 3.913692\n",
      "Epoch: 41\tFidelity = 0.500561\tKL_Divergence = 3.925021\n",
      "Epoch: 42\tFidelity = 0.500545\tKL_Divergence = 3.941108\n",
      "Epoch: 43\tFidelity = 0.500554\tKL_Divergence = 3.932081\n",
      "Epoch: 44\tFidelity = 0.500512\tKL_Divergence = 3.975430\n",
      "Epoch: 45\tFidelity = 0.500527\tKL_Divergence = 3.959165\n",
      "Epoch: 46\tFidelity = 0.500543\tKL_Divergence = 3.943438\n",
      "Epoch: 47\tFidelity = 0.500535\tKL_Divergence = 3.950894\n",
      "Epoch: 48\tFidelity = 0.500498\tKL_Divergence = 3.990616\n",
      "Epoch: 49\tFidelity = 0.500600\tKL_Divergence = 3.888003\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:42:59,326] Trial 469 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500521\tKL_Divergence = 3.966268\n",
      "Total time elapsed during training: 40.081 s\n",
      "Trial 469 pruned. \n",
      "Epoch: 1\tFidelity = 0.500616\tKL_Divergence = 3.873267\n",
      "Epoch: 2\tFidelity = 0.500483\tKL_Divergence = 4.007596\n",
      "Epoch: 3\tFidelity = 0.500645\tKL_Divergence = 3.847322\n",
      "Epoch: 4\tFidelity = 0.500638\tKL_Divergence = 3.853179\n",
      "Epoch: 5\tFidelity = 0.500570\tKL_Divergence = 3.916049\n",
      "Epoch: 6\tFidelity = 0.500516\tKL_Divergence = 3.970950\n",
      "Epoch: 7\tFidelity = 0.500573\tKL_Divergence = 3.913687\n",
      "Epoch: 8\tFidelity = 0.500671\tKL_Divergence = 3.825253\n",
      "Epoch: 9\tFidelity = 0.500426\tKL_Divergence = 4.076716\n",
      "Epoch: 10\tFidelity = 0.500473\tKL_Divergence = 4.018963\n",
      "Epoch: 11\tFidelity = 0.500484\tKL_Divergence = 4.006729\n",
      "Epoch: 12\tFidelity = 0.500553\tKL_Divergence = 3.932808\n",
      "Epoch: 13\tFidelity = 0.500398\tKL_Divergence = 4.115401\n",
      "Epoch: 14\tFidelity = 0.500531\tKL_Divergence = 3.954968\n",
      "Epoch: 15\tFidelity = 0.500653\tKL_Divergence = 3.840221\n",
      "Epoch: 16\tFidelity = 0.500419\tKL_Divergence = 4.087161\n",
      "Epoch: 17\tFidelity = 0.500495\tKL_Divergence = 3.994036\n",
      "Epoch: 18\tFidelity = 0.500564\tKL_Divergence = 3.922369\n",
      "Epoch: 19\tFidelity = 0.500445\tKL_Divergence = 4.052822\n",
      "Epoch: 20\tFidelity = 0.500569\tKL_Divergence = 3.917406\n",
      "Epoch: 21\tFidelity = 0.500586\tKL_Divergence = 3.900445\n",
      "Epoch: 22\tFidelity = 0.500547\tKL_Divergence = 3.938678\n",
      "Epoch: 23\tFidelity = 0.500600\tKL_Divergence = 3.887343\n",
      "Epoch: 24\tFidelity = 0.500605\tKL_Divergence = 3.882591\n",
      "Epoch: 25\tFidelity = 0.500761\tKL_Divergence = 3.755440\n",
      "Epoch: 26\tFidelity = 0.500568\tKL_Divergence = 3.918024\n",
      "Epoch: 27\tFidelity = 0.500511\tKL_Divergence = 3.976356\n",
      "Epoch: 28\tFidelity = 0.500509\tKL_Divergence = 3.977639\n",
      "Epoch: 29\tFidelity = 0.500455\tKL_Divergence = 4.041000\n",
      "Epoch: 30\tFidelity = 0.500609\tKL_Divergence = 3.879037\n",
      "Epoch: 31\tFidelity = 0.500540\tKL_Divergence = 3.946328\n",
      "Epoch: 32\tFidelity = 0.500508\tKL_Divergence = 3.979805\n",
      "Epoch: 33\tFidelity = 0.500536\tKL_Divergence = 3.950128\n",
      "Epoch: 34\tFidelity = 0.500514\tKL_Divergence = 3.973366\n",
      "Epoch: 35\tFidelity = 0.500522\tKL_Divergence = 3.964472\n",
      "Epoch: 36\tFidelity = 0.500584\tKL_Divergence = 3.902886\n",
      "Epoch: 37\tFidelity = 0.500681\tKL_Divergence = 3.817413\n",
      "Epoch: 38\tFidelity = 0.500624\tKL_Divergence = 3.865775\n",
      "Epoch: 39\tFidelity = 0.500448\tKL_Divergence = 4.050308\n",
      "Epoch: 40\tFidelity = 0.500545\tKL_Divergence = 3.941211\n",
      "Epoch: 41\tFidelity = 0.500574\tKL_Divergence = 3.912081\n",
      "Epoch: 42\tFidelity = 0.500455\tKL_Divergence = 4.040710\n",
      "Epoch: 43\tFidelity = 0.500378\tKL_Divergence = 4.144531\n",
      "Epoch: 44\tFidelity = 0.500506\tKL_Divergence = 3.982615\n",
      "Epoch: 45\tFidelity = 0.500508\tKL_Divergence = 3.980474\n",
      "Epoch: 46\tFidelity = 0.500454\tKL_Divergence = 4.043007\n",
      "Epoch: 47\tFidelity = 0.500416\tKL_Divergence = 4.090520\n",
      "Epoch: 48\tFidelity = 0.500463\tKL_Divergence = 4.031410\n",
      "Epoch: 49\tFidelity = 0.500542\tKL_Divergence = 3.943994\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:44:00,395] Trial 470 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500591\tKL_Divergence = 3.896223\n",
      "Total time elapsed during training: 60.862 s\n",
      "Trial 470 pruned. \n",
      "Epoch: 1\tFidelity = 0.500524\tKL_Divergence = 3.962456\n",
      "Epoch: 2\tFidelity = 0.500540\tKL_Divergence = 3.946504\n",
      "Epoch: 3\tFidelity = 0.500562\tKL_Divergence = 3.924365\n",
      "Epoch: 4\tFidelity = 0.500445\tKL_Divergence = 4.052936\n",
      "Epoch: 5\tFidelity = 0.500498\tKL_Divergence = 3.990666\n",
      "Epoch: 6\tFidelity = 0.500552\tKL_Divergence = 3.934087\n",
      "Epoch: 7\tFidelity = 0.500527\tKL_Divergence = 3.960044\n",
      "Epoch: 8\tFidelity = 0.500483\tKL_Divergence = 4.007580\n",
      "Epoch: 9\tFidelity = 0.500477\tKL_Divergence = 4.015001\n",
      "Epoch: 10\tFidelity = 0.500480\tKL_Divergence = 4.012001\n",
      "Epoch: 11\tFidelity = 0.500501\tKL_Divergence = 3.988100\n",
      "Epoch: 12\tFidelity = 0.500507\tKL_Divergence = 3.980837\n",
      "Epoch: 13\tFidelity = 0.500511\tKL_Divergence = 3.977053\n",
      "Epoch: 14\tFidelity = 0.500491\tKL_Divergence = 3.998766\n",
      "Epoch: 15\tFidelity = 0.500469\tKL_Divergence = 4.024877\n",
      "Epoch: 16\tFidelity = 0.500482\tKL_Divergence = 4.009358\n",
      "Epoch: 17\tFidelity = 0.500534\tKL_Divergence = 3.952673\n",
      "Epoch: 18\tFidelity = 0.500602\tKL_Divergence = 3.886076\n",
      "Epoch: 19\tFidelity = 0.500500\tKL_Divergence = 3.988967\n",
      "Epoch: 20\tFidelity = 0.500510\tKL_Divergence = 3.977388\n",
      "Epoch: 21\tFidelity = 0.500545\tKL_Divergence = 3.940511\n",
      "Epoch: 22\tFidelity = 0.500556\tKL_Divergence = 3.929705\n",
      "Epoch: 23\tFidelity = 0.500575\tKL_Divergence = 3.910860\n",
      "Epoch: 24\tFidelity = 0.500509\tKL_Divergence = 3.978536\n",
      "Epoch: 25\tFidelity = 0.500568\tKL_Divergence = 3.918436\n",
      "Epoch: 26\tFidelity = 0.500543\tKL_Divergence = 3.942950\n",
      "Epoch: 27\tFidelity = 0.500463\tKL_Divergence = 4.031746\n",
      "Epoch: 28\tFidelity = 0.500538\tKL_Divergence = 3.948366\n",
      "Epoch: 29\tFidelity = 0.500568\tKL_Divergence = 3.918539\n",
      "Epoch: 30\tFidelity = 0.500527\tKL_Divergence = 3.959097\n",
      "Epoch: 31\tFidelity = 0.500538\tKL_Divergence = 3.947702\n",
      "Epoch: 32\tFidelity = 0.500571\tKL_Divergence = 3.914981\n",
      "Epoch: 33\tFidelity = 0.500567\tKL_Divergence = 3.919408\n",
      "Epoch: 34\tFidelity = 0.500548\tKL_Divergence = 3.937928\n",
      "Epoch: 35\tFidelity = 0.500489\tKL_Divergence = 4.001358\n",
      "Epoch: 36\tFidelity = 0.500550\tKL_Divergence = 3.935970\n",
      "Epoch: 37\tFidelity = 0.500530\tKL_Divergence = 3.956281\n",
      "Epoch: 38\tFidelity = 0.500491\tKL_Divergence = 3.998625\n",
      "Epoch: 39\tFidelity = 0.500504\tKL_Divergence = 3.983938\n",
      "Epoch: 40\tFidelity = 0.500590\tKL_Divergence = 3.896850\n",
      "Epoch: 41\tFidelity = 0.500559\tKL_Divergence = 3.926978\n",
      "Epoch: 42\tFidelity = 0.500487\tKL_Divergence = 4.003370\n",
      "Epoch: 43\tFidelity = 0.500506\tKL_Divergence = 3.982470\n",
      "Epoch: 44\tFidelity = 0.500530\tKL_Divergence = 3.956031\n",
      "Epoch: 45\tFidelity = 0.500495\tKL_Divergence = 3.994156\n",
      "Epoch: 46\tFidelity = 0.500528\tKL_Divergence = 3.958833\n",
      "Epoch: 47\tFidelity = 0.500542\tKL_Divergence = 3.944419\n",
      "Epoch: 48\tFidelity = 0.500514\tKL_Divergence = 3.973795\n",
      "Epoch: 49\tFidelity = 0.500571\tKL_Divergence = 3.915105\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:45:24,770] Trial 471 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500554\tKL_Divergence = 3.932225\n",
      "Total time elapsed during training: 84.202 s\n",
      "Trial 471 pruned. \n",
      "Epoch: 1\tFidelity = 0.500611\tKL_Divergence = 3.877358\n",
      "Epoch: 2\tFidelity = 0.500549\tKL_Divergence = 3.937082\n",
      "Epoch: 3\tFidelity = 0.500487\tKL_Divergence = 4.003867\n",
      "Epoch: 4\tFidelity = 0.500571\tKL_Divergence = 3.914929\n",
      "Epoch: 5\tFidelity = 0.500451\tKL_Divergence = 4.046073\n",
      "Epoch: 6\tFidelity = 0.500540\tKL_Divergence = 3.946151\n",
      "Epoch: 7\tFidelity = 0.500472\tKL_Divergence = 4.020567\n",
      "Epoch: 8\tFidelity = 0.500517\tKL_Divergence = 3.970543\n",
      "Epoch: 9\tFidelity = 0.500459\tKL_Divergence = 4.035766\n",
      "Epoch: 10\tFidelity = 0.500508\tKL_Divergence = 3.979897\n",
      "Epoch: 11\tFidelity = 0.500554\tKL_Divergence = 3.932005\n",
      "Epoch: 12\tFidelity = 0.500503\tKL_Divergence = 3.985204\n",
      "Epoch: 13\tFidelity = 0.500497\tKL_Divergence = 3.991583\n",
      "Epoch: 14\tFidelity = 0.500518\tKL_Divergence = 3.969238\n",
      "Epoch: 15\tFidelity = 0.500517\tKL_Divergence = 3.969831\n",
      "Epoch: 16\tFidelity = 0.500526\tKL_Divergence = 3.961089\n",
      "Epoch: 17\tFidelity = 0.500526\tKL_Divergence = 3.960446\n",
      "Epoch: 18\tFidelity = 0.500570\tKL_Divergence = 3.916276\n",
      "Epoch: 19\tFidelity = 0.500530\tKL_Divergence = 3.956157\n",
      "Epoch: 20\tFidelity = 0.500537\tKL_Divergence = 3.948703\n",
      "Epoch: 21\tFidelity = 0.500457\tKL_Divergence = 4.038191\n",
      "Epoch: 22\tFidelity = 0.500545\tKL_Divergence = 3.940824\n",
      "Epoch: 23\tFidelity = 0.500573\tKL_Divergence = 3.913521\n",
      "Epoch: 24\tFidelity = 0.500490\tKL_Divergence = 4.000135\n",
      "Epoch: 25\tFidelity = 0.500539\tKL_Divergence = 3.947524\n",
      "Epoch: 26\tFidelity = 0.500545\tKL_Divergence = 3.941365\n",
      "Epoch: 27\tFidelity = 0.500524\tKL_Divergence = 3.963180\n",
      "Epoch: 28\tFidelity = 0.500512\tKL_Divergence = 3.975906\n",
      "Epoch: 29\tFidelity = 0.500479\tKL_Divergence = 4.012065\n",
      "Epoch: 30\tFidelity = 0.500532\tKL_Divergence = 3.954608\n",
      "Epoch: 31\tFidelity = 0.500577\tKL_Divergence = 3.909480\n",
      "Epoch: 32\tFidelity = 0.500446\tKL_Divergence = 4.052469\n",
      "Epoch: 33\tFidelity = 0.500528\tKL_Divergence = 3.958603\n",
      "Epoch: 34\tFidelity = 0.500557\tKL_Divergence = 3.928969\n",
      "Epoch: 35\tFidelity = 0.500502\tKL_Divergence = 3.986317\n",
      "Epoch: 36\tFidelity = 0.500444\tKL_Divergence = 4.054809\n",
      "Epoch: 37\tFidelity = 0.500515\tKL_Divergence = 3.972013\n",
      "Epoch: 38\tFidelity = 0.500523\tKL_Divergence = 3.963889\n",
      "Epoch: 39\tFidelity = 0.500533\tKL_Divergence = 3.953131\n",
      "Epoch: 40\tFidelity = 0.500476\tKL_Divergence = 4.015841\n",
      "Epoch: 41\tFidelity = 0.500503\tKL_Divergence = 3.985533\n",
      "Epoch: 42\tFidelity = 0.500449\tKL_Divergence = 4.048067\n",
      "Epoch: 43\tFidelity = 0.500516\tKL_Divergence = 3.970889\n",
      "Epoch: 44\tFidelity = 0.500452\tKL_Divergence = 4.045403\n",
      "Epoch: 45\tFidelity = 0.500445\tKL_Divergence = 4.052855\n",
      "Epoch: 46\tFidelity = 0.500493\tKL_Divergence = 3.996288\n",
      "Epoch: 47\tFidelity = 0.500515\tKL_Divergence = 3.972890\n",
      "Epoch: 48\tFidelity = 0.500476\tKL_Divergence = 4.016242\n",
      "Epoch: 49\tFidelity = 0.500479\tKL_Divergence = 4.012958\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:46:11,688] Trial 472 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500466\tKL_Divergence = 4.027488\n",
      "Total time elapsed during training: 46.737 s\n",
      "Trial 472 pruned. \n",
      "Epoch: 1\tFidelity = 0.500514\tKL_Divergence = 3.973734\n",
      "Epoch: 2\tFidelity = 0.500545\tKL_Divergence = 3.940726\n",
      "Epoch: 3\tFidelity = 0.500524\tKL_Divergence = 3.962847\n",
      "Epoch: 4\tFidelity = 0.500486\tKL_Divergence = 4.005010\n",
      "Epoch: 5\tFidelity = 0.500489\tKL_Divergence = 4.000874\n",
      "Epoch: 6\tFidelity = 0.500478\tKL_Divergence = 4.013485\n",
      "Epoch: 7\tFidelity = 0.500516\tKL_Divergence = 3.971086\n",
      "Epoch: 8\tFidelity = 0.500439\tKL_Divergence = 4.061017\n",
      "Epoch: 9\tFidelity = 0.500461\tKL_Divergence = 4.033958\n",
      "Epoch: 10\tFidelity = 0.500463\tKL_Divergence = 4.031342\n",
      "Epoch: 11\tFidelity = 0.500462\tKL_Divergence = 4.032493\n",
      "Epoch: 12\tFidelity = 0.500513\tKL_Divergence = 3.974136\n",
      "Epoch: 13\tFidelity = 0.500473\tKL_Divergence = 4.019494\n",
      "Epoch: 14\tFidelity = 0.500454\tKL_Divergence = 4.042664\n",
      "Epoch: 15\tFidelity = 0.500552\tKL_Divergence = 3.933591\n",
      "Epoch: 16\tFidelity = 0.500551\tKL_Divergence = 3.934858\n",
      "Epoch: 17\tFidelity = 0.500562\tKL_Divergence = 3.923621\n",
      "Epoch: 18\tFidelity = 0.500575\tKL_Divergence = 3.911215\n",
      "Epoch: 19\tFidelity = 0.500518\tKL_Divergence = 3.968744\n",
      "Epoch: 20\tFidelity = 0.500527\tKL_Divergence = 3.959103\n",
      "Epoch: 21\tFidelity = 0.500546\tKL_Divergence = 3.939652\n",
      "Epoch: 22\tFidelity = 0.500482\tKL_Divergence = 4.008529\n",
      "Epoch: 23\tFidelity = 0.500470\tKL_Divergence = 4.022518\n",
      "Epoch: 24\tFidelity = 0.500459\tKL_Divergence = 4.035621\n",
      "Epoch: 25\tFidelity = 0.500493\tKL_Divergence = 3.995875\n",
      "Epoch: 26\tFidelity = 0.500525\tKL_Divergence = 3.961301\n",
      "Epoch: 27\tFidelity = 0.500502\tKL_Divergence = 3.986139\n",
      "Epoch: 28\tFidelity = 0.500578\tKL_Divergence = 3.908221\n",
      "Epoch: 29\tFidelity = 0.500473\tKL_Divergence = 4.018593\n",
      "Epoch: 30\tFidelity = 0.500583\tKL_Divergence = 3.903561\n",
      "Epoch: 31\tFidelity = 0.500459\tKL_Divergence = 4.036290\n",
      "Epoch: 32\tFidelity = 0.500543\tKL_Divergence = 3.942353\n",
      "Epoch: 33\tFidelity = 0.500518\tKL_Divergence = 3.968108\n",
      "Epoch: 34\tFidelity = 0.500526\tKL_Divergence = 3.960025\n",
      "Epoch: 35\tFidelity = 0.500480\tKL_Divergence = 4.010601\n",
      "Epoch: 36\tFidelity = 0.500518\tKL_Divergence = 3.968445\n",
      "Epoch: 37\tFidelity = 0.500513\tKL_Divergence = 3.973917\n",
      "Epoch: 38\tFidelity = 0.500495\tKL_Divergence = 3.993314\n",
      "Epoch: 39\tFidelity = 0.500532\tKL_Divergence = 3.953382\n",
      "Epoch: 40\tFidelity = 0.500580\tKL_Divergence = 3.905498\n",
      "Epoch: 41\tFidelity = 0.500537\tKL_Divergence = 3.948257\n",
      "Epoch: 42\tFidelity = 0.500453\tKL_Divergence = 4.043033\n",
      "Epoch: 43\tFidelity = 0.500519\tKL_Divergence = 3.967380\n",
      "Epoch: 44\tFidelity = 0.500485\tKL_Divergence = 4.004928\n",
      "Epoch: 45\tFidelity = 0.500504\tKL_Divergence = 3.984055\n",
      "Epoch: 46\tFidelity = 0.500488\tKL_Divergence = 4.002077\n",
      "Epoch: 47\tFidelity = 0.500545\tKL_Divergence = 3.940944\n",
      "Epoch: 48\tFidelity = 0.500551\tKL_Divergence = 3.934648\n",
      "Epoch: 49\tFidelity = 0.500471\tKL_Divergence = 4.021406\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:46:52,200] Trial 473 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500518\tKL_Divergence = 3.968608\n",
      "Total time elapsed during training: 40.341 s\n",
      "Trial 473 pruned. \n",
      "Epoch: 1\tFidelity = 0.500567\tKL_Divergence = 3.918313\n",
      "Epoch: 2\tFidelity = 0.500381\tKL_Divergence = 4.139148\n",
      "Epoch: 3\tFidelity = 0.500580\tKL_Divergence = 3.906078\n",
      "Epoch: 4\tFidelity = 0.500457\tKL_Divergence = 4.038297\n",
      "Epoch: 5\tFidelity = 0.500536\tKL_Divergence = 3.950046\n",
      "Epoch: 6\tFidelity = 0.500438\tKL_Divergence = 4.062316\n",
      "Epoch: 7\tFidelity = 0.500535\tKL_Divergence = 3.950558\n",
      "Epoch: 8\tFidelity = 0.500420\tKL_Divergence = 4.085312\n",
      "Epoch: 9\tFidelity = 0.500554\tKL_Divergence = 3.931440\n",
      "Epoch: 10\tFidelity = 0.500677\tKL_Divergence = 3.820391\n",
      "Epoch: 11\tFidelity = 0.500565\tKL_Divergence = 3.920797\n",
      "Epoch: 12\tFidelity = 0.500524\tKL_Divergence = 3.960427\n",
      "Epoch: 13\tFidelity = 0.500467\tKL_Divergence = 4.024573\n",
      "Epoch: 14\tFidelity = 0.500483\tKL_Divergence = 4.005291\n",
      "Epoch: 15\tFidelity = 0.500532\tKL_Divergence = 3.952350\n",
      "Epoch: 16\tFidelity = 0.500481\tKL_Divergence = 4.008910\n",
      "Epoch: 17\tFidelity = 0.500578\tKL_Divergence = 3.905019\n",
      "Epoch: 18\tFidelity = 0.500450\tKL_Divergence = 4.042921\n",
      "Epoch: 19\tFidelity = 0.500492\tKL_Divergence = 3.994736\n",
      "Epoch: 20\tFidelity = 0.500444\tKL_Divergence = 4.052560\n",
      "Epoch: 21\tFidelity = 0.500488\tKL_Divergence = 4.000252\n",
      "Epoch: 22\tFidelity = 0.500439\tKL_Divergence = 4.058833\n",
      "Epoch: 23\tFidelity = 0.500541\tKL_Divergence = 3.943817\n",
      "Epoch: 24\tFidelity = 0.500485\tKL_Divergence = 4.004988\n",
      "Epoch: 25\tFidelity = 0.500437\tKL_Divergence = 4.061525\n",
      "Epoch: 26\tFidelity = 0.500469\tKL_Divergence = 4.021643\n",
      "Epoch: 27\tFidelity = 0.500489\tKL_Divergence = 3.997259\n",
      "Epoch: 28\tFidelity = 0.500461\tKL_Divergence = 4.030814\n",
      "Epoch: 29\tFidelity = 0.500490\tKL_Divergence = 3.997453\n",
      "Epoch: 30\tFidelity = 0.500420\tKL_Divergence = 4.080456\n",
      "Epoch: 31\tFidelity = 0.500459\tKL_Divergence = 4.031548\n",
      "Epoch: 32\tFidelity = 0.500370\tKL_Divergence = 4.151434\n",
      "Epoch: 33\tFidelity = 0.500362\tKL_Divergence = 4.161794\n",
      "Epoch: 34\tFidelity = 0.500569\tKL_Divergence = 3.913119\n",
      "Epoch: 35\tFidelity = 0.500566\tKL_Divergence = 3.917628\n",
      "Epoch: 36\tFidelity = 0.500586\tKL_Divergence = 3.897473\n",
      "Epoch: 37\tFidelity = 0.500639\tKL_Divergence = 3.850716\n",
      "Epoch: 38\tFidelity = 0.500597\tKL_Divergence = 3.889741\n",
      "Epoch: 39\tFidelity = 0.500457\tKL_Divergence = 4.037069\n",
      "Epoch: 40\tFidelity = 0.500502\tKL_Divergence = 3.985038\n",
      "Epoch: 41\tFidelity = 0.500477\tKL_Divergence = 4.012805\n",
      "Epoch: 42\tFidelity = 0.500470\tKL_Divergence = 4.021792\n",
      "Epoch: 43\tFidelity = 0.500536\tKL_Divergence = 3.948640\n",
      "Epoch: 44\tFidelity = 0.500449\tKL_Divergence = 4.048207\n",
      "Epoch: 45\tFidelity = 0.500529\tKL_Divergence = 3.956992\n",
      "Epoch: 46\tFidelity = 0.500550\tKL_Divergence = 3.935341\n",
      "Epoch: 47\tFidelity = 0.500553\tKL_Divergence = 3.933478\n",
      "Epoch: 48\tFidelity = 0.500501\tKL_Divergence = 3.987784\n",
      "Epoch: 49\tFidelity = 0.500386\tKL_Divergence = 4.133261\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:47:31,056] Trial 474 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500483\tKL_Divergence = 4.007930\n",
      "Total time elapsed during training: 38.676 s\n",
      "Trial 474 pruned. \n",
      "Epoch: 1\tFidelity = 0.500438\tKL_Divergence = 4.061905\n",
      "Epoch: 2\tFidelity = 0.500499\tKL_Divergence = 3.990264\n",
      "Epoch: 3\tFidelity = 0.500527\tKL_Divergence = 3.959803\n",
      "Epoch: 4\tFidelity = 0.500465\tKL_Divergence = 4.029334\n",
      "Epoch: 5\tFidelity = 0.500488\tKL_Divergence = 4.001973\n",
      "Epoch: 6\tFidelity = 0.500532\tKL_Divergence = 3.954617\n",
      "Epoch: 7\tFidelity = 0.500397\tKL_Divergence = 4.116722\n",
      "Epoch: 8\tFidelity = 0.500497\tKL_Divergence = 3.991623\n",
      "Epoch: 9\tFidelity = 0.500559\tKL_Divergence = 3.926504\n",
      "Epoch: 10\tFidelity = 0.500516\tKL_Divergence = 3.971253\n",
      "Epoch: 11\tFidelity = 0.500451\tKL_Divergence = 4.046368\n",
      "Epoch: 12\tFidelity = 0.500448\tKL_Divergence = 4.050412\n",
      "Epoch: 13\tFidelity = 0.500477\tKL_Divergence = 4.014836\n",
      "Epoch: 14\tFidelity = 0.500485\tKL_Divergence = 4.006222\n",
      "Epoch: 15\tFidelity = 0.500552\tKL_Divergence = 3.933800\n",
      "Epoch: 16\tFidelity = 0.500520\tKL_Divergence = 3.967606\n",
      "Epoch: 17\tFidelity = 0.500518\tKL_Divergence = 3.969366\n",
      "Epoch: 18\tFidelity = 0.500528\tKL_Divergence = 3.958453\n",
      "Epoch: 19\tFidelity = 0.500446\tKL_Divergence = 4.053045\n",
      "Epoch: 20\tFidelity = 0.500392\tKL_Divergence = 4.124576\n",
      "Epoch: 21\tFidelity = 0.500424\tKL_Divergence = 4.080778\n",
      "Epoch: 22\tFidelity = 0.500511\tKL_Divergence = 3.977257\n",
      "Epoch: 23\tFidelity = 0.500411\tKL_Divergence = 4.097246\n",
      "Epoch: 24\tFidelity = 0.500399\tKL_Divergence = 4.114387\n",
      "Epoch: 25\tFidelity = 0.500481\tKL_Divergence = 4.011035\n",
      "Epoch: 26\tFidelity = 0.500417\tKL_Divergence = 4.090373\n",
      "Epoch: 27\tFidelity = 0.500429\tKL_Divergence = 4.074314\n",
      "Epoch: 28\tFidelity = 0.500514\tKL_Divergence = 3.973504\n",
      "Epoch: 29\tFidelity = 0.500558\tKL_Divergence = 3.927899\n",
      "Epoch: 30\tFidelity = 0.500564\tKL_Divergence = 3.921848\n",
      "Epoch: 31\tFidelity = 0.500451\tKL_Divergence = 4.046158\n",
      "Epoch: 32\tFidelity = 0.500482\tKL_Divergence = 4.009209\n",
      "Epoch: 33\tFidelity = 0.500501\tKL_Divergence = 3.987597\n",
      "Epoch: 34\tFidelity = 0.500547\tKL_Divergence = 3.939245\n",
      "Epoch: 35\tFidelity = 0.500540\tKL_Divergence = 3.946396\n",
      "Epoch: 36\tFidelity = 0.500538\tKL_Divergence = 3.947985\n",
      "Epoch: 37\tFidelity = 0.500553\tKL_Divergence = 3.933334\n",
      "Epoch: 38\tFidelity = 0.500427\tKL_Divergence = 4.076327\n",
      "Epoch: 39\tFidelity = 0.500565\tKL_Divergence = 3.920800\n",
      "Epoch: 40\tFidelity = 0.500559\tKL_Divergence = 3.927187\n",
      "Epoch: 41\tFidelity = 0.500406\tKL_Divergence = 4.104469\n",
      "Epoch: 42\tFidelity = 0.500508\tKL_Divergence = 3.979586\n",
      "Epoch: 43\tFidelity = 0.500469\tKL_Divergence = 4.024363\n",
      "Epoch: 44\tFidelity = 0.500444\tKL_Divergence = 4.054805\n",
      "Epoch: 45\tFidelity = 0.500434\tKL_Divergence = 4.067203\n",
      "Epoch: 46\tFidelity = 0.500393\tKL_Divergence = 4.122871\n",
      "Epoch: 47\tFidelity = 0.500459\tKL_Divergence = 4.036372\n",
      "Epoch: 48\tFidelity = 0.500526\tKL_Divergence = 3.960760\n",
      "Epoch: 49\tFidelity = 0.500505\tKL_Divergence = 3.983864\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:48:10,469] Trial 475 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500470\tKL_Divergence = 4.023726\n",
      "Total time elapsed during training: 39.230 s\n",
      "Trial 475 pruned. \n",
      "Epoch: 1\tFidelity = 0.500375\tKL_Divergence = 4.148185\n",
      "Epoch: 2\tFidelity = 0.500511\tKL_Divergence = 3.976506\n",
      "Epoch: 3\tFidelity = 0.500504\tKL_Divergence = 3.984285\n",
      "Epoch: 4\tFidelity = 0.500459\tKL_Divergence = 4.036986\n",
      "Epoch: 5\tFidelity = 0.500544\tKL_Divergence = 3.942157\n",
      "Epoch: 6\tFidelity = 0.500534\tKL_Divergence = 3.952521\n",
      "Epoch: 7\tFidelity = 0.500471\tKL_Divergence = 4.021601\n",
      "Epoch: 8\tFidelity = 0.500494\tKL_Divergence = 3.995738\n",
      "Epoch: 9\tFidelity = 0.500513\tKL_Divergence = 3.974622\n",
      "Epoch: 10\tFidelity = 0.500479\tKL_Divergence = 4.012271\n",
      "Epoch: 11\tFidelity = 0.500488\tKL_Divergence = 4.002889\n",
      "Epoch: 12\tFidelity = 0.500503\tKL_Divergence = 3.985678\n",
      "Epoch: 13\tFidelity = 0.500472\tKL_Divergence = 4.021116\n",
      "Epoch: 14\tFidelity = 0.500537\tKL_Divergence = 3.949524\n",
      "Epoch: 15\tFidelity = 0.500495\tKL_Divergence = 3.994133\n",
      "Epoch: 16\tFidelity = 0.500422\tKL_Divergence = 4.083312\n",
      "Epoch: 17\tFidelity = 0.500543\tKL_Divergence = 3.943415\n",
      "Epoch: 18\tFidelity = 0.500442\tKL_Divergence = 4.057803\n",
      "Epoch: 19\tFidelity = 0.500481\tKL_Divergence = 4.010603\n",
      "Epoch: 20\tFidelity = 0.500508\tKL_Divergence = 3.980667\n",
      "Epoch: 21\tFidelity = 0.500527\tKL_Divergence = 3.959881\n",
      "Epoch: 22\tFidelity = 0.500466\tKL_Divergence = 4.028510\n",
      "Epoch: 23\tFidelity = 0.500485\tKL_Divergence = 4.006429\n",
      "Epoch: 24\tFidelity = 0.500419\tKL_Divergence = 4.087077\n",
      "Epoch: 25\tFidelity = 0.500525\tKL_Divergence = 3.962172\n",
      "Epoch: 26\tFidelity = 0.500506\tKL_Divergence = 3.982856\n",
      "Epoch: 27\tFidelity = 0.500461\tKL_Divergence = 4.034316\n",
      "Epoch: 28\tFidelity = 0.500416\tKL_Divergence = 4.091656\n",
      "Epoch: 29\tFidelity = 0.500523\tKL_Divergence = 3.963908\n",
      "Epoch: 30\tFidelity = 0.500470\tKL_Divergence = 4.023150\n",
      "Epoch: 31\tFidelity = 0.500501\tKL_Divergence = 3.987523\n",
      "Epoch: 32\tFidelity = 0.500460\tKL_Divergence = 4.034736\n",
      "Epoch: 33\tFidelity = 0.500506\tKL_Divergence = 3.982970\n",
      "Epoch: 34\tFidelity = 0.500492\tKL_Divergence = 3.997949\n",
      "Epoch: 35\tFidelity = 0.500452\tKL_Divergence = 4.045565\n",
      "Epoch: 36\tFidelity = 0.500463\tKL_Divergence = 4.031721\n",
      "Epoch: 37\tFidelity = 0.500538\tKL_Divergence = 3.948920\n",
      "Epoch: 38\tFidelity = 0.500435\tKL_Divergence = 4.065803\n",
      "Epoch: 39\tFidelity = 0.500373\tKL_Divergence = 4.151517\n",
      "Epoch: 40\tFidelity = 0.500518\tKL_Divergence = 3.969881\n",
      "Epoch: 41\tFidelity = 0.500533\tKL_Divergence = 3.953208\n",
      "Epoch: 42\tFidelity = 0.500495\tKL_Divergence = 3.995005\n",
      "Epoch: 43\tFidelity = 0.500505\tKL_Divergence = 3.983954\n",
      "Epoch: 44\tFidelity = 0.500470\tKL_Divergence = 4.023856\n",
      "Epoch: 45\tFidelity = 0.500452\tKL_Divergence = 4.045353\n",
      "Epoch: 46\tFidelity = 0.500523\tKL_Divergence = 3.964060\n",
      "Epoch: 47\tFidelity = 0.500446\tKL_Divergence = 4.052161\n",
      "Epoch: 48\tFidelity = 0.500522\tKL_Divergence = 3.964689\n",
      "Epoch: 49\tFidelity = 0.500589\tKL_Divergence = 3.898163\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:48:43,227] Trial 476 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500460\tKL_Divergence = 4.035159\n",
      "Total time elapsed during training: 32.586 s\n",
      "Trial 476 pruned. \n",
      "Epoch: 1\tFidelity = 0.500509\tKL_Divergence = 3.978938\n",
      "Epoch: 2\tFidelity = 0.500481\tKL_Divergence = 4.010293\n",
      "Epoch: 3\tFidelity = 0.500534\tKL_Divergence = 3.953081\n",
      "Epoch: 4\tFidelity = 0.500475\tKL_Divergence = 4.017379\n",
      "Epoch: 5\tFidelity = 0.500460\tKL_Divergence = 4.035591\n",
      "Epoch: 6\tFidelity = 0.500433\tKL_Divergence = 4.068446\n",
      "Epoch: 7\tFidelity = 0.500483\tKL_Divergence = 4.008241\n",
      "Epoch: 8\tFidelity = 0.500459\tKL_Divergence = 4.036227\n",
      "Epoch: 9\tFidelity = 0.500478\tKL_Divergence = 4.014114\n",
      "Epoch: 10\tFidelity = 0.500529\tKL_Divergence = 3.957355\n",
      "Epoch: 11\tFidelity = 0.500507\tKL_Divergence = 3.981267\n",
      "Epoch: 12\tFidelity = 0.500502\tKL_Divergence = 3.986436\n",
      "Epoch: 13\tFidelity = 0.500515\tKL_Divergence = 3.972937\n",
      "Epoch: 14\tFidelity = 0.500534\tKL_Divergence = 3.953090\n",
      "Epoch: 15\tFidelity = 0.500537\tKL_Divergence = 3.949999\n",
      "Epoch: 16\tFidelity = 0.500508\tKL_Divergence = 3.979790\n",
      "Epoch: 17\tFidelity = 0.500545\tKL_Divergence = 3.941083\n",
      "Epoch: 18\tFidelity = 0.500522\tKL_Divergence = 3.965216\n",
      "Epoch: 19\tFidelity = 0.500516\tKL_Divergence = 3.971487\n",
      "Epoch: 20\tFidelity = 0.500515\tKL_Divergence = 3.973232\n",
      "Epoch: 21\tFidelity = 0.500480\tKL_Divergence = 4.011984\n",
      "Epoch: 22\tFidelity = 0.500439\tKL_Divergence = 4.061153\n",
      "Epoch: 23\tFidelity = 0.500430\tKL_Divergence = 4.072713\n",
      "Epoch: 24\tFidelity = 0.500458\tKL_Divergence = 4.037308\n",
      "Epoch: 25\tFidelity = 0.500488\tKL_Divergence = 4.002389\n",
      "Epoch: 26\tFidelity = 0.500503\tKL_Divergence = 3.986325\n",
      "Epoch: 27\tFidelity = 0.500483\tKL_Divergence = 4.008150\n",
      "Epoch: 28\tFidelity = 0.500453\tKL_Divergence = 4.044092\n",
      "Epoch: 29\tFidelity = 0.500514\tKL_Divergence = 3.973967\n",
      "Epoch: 30\tFidelity = 0.500538\tKL_Divergence = 3.948037\n",
      "Epoch: 31\tFidelity = 0.500499\tKL_Divergence = 3.990196\n",
      "Epoch: 32\tFidelity = 0.500493\tKL_Divergence = 3.997301\n",
      "Epoch: 33\tFidelity = 0.500507\tKL_Divergence = 3.981804\n",
      "Epoch: 34\tFidelity = 0.500470\tKL_Divergence = 4.023411\n",
      "Epoch: 35\tFidelity = 0.500467\tKL_Divergence = 4.026944\n",
      "Epoch: 36\tFidelity = 0.500470\tKL_Divergence = 4.023337\n",
      "Epoch: 37\tFidelity = 0.500483\tKL_Divergence = 4.008136\n",
      "Epoch: 38\tFidelity = 0.500428\tKL_Divergence = 4.075476\n",
      "Epoch: 39\tFidelity = 0.500472\tKL_Divergence = 4.021445\n",
      "Epoch: 40\tFidelity = 0.500438\tKL_Divergence = 4.062869\n",
      "Epoch: 41\tFidelity = 0.500508\tKL_Divergence = 3.979959\n",
      "Epoch: 42\tFidelity = 0.500550\tKL_Divergence = 3.936576\n",
      "Epoch: 43\tFidelity = 0.500532\tKL_Divergence = 3.954525\n",
      "Epoch: 44\tFidelity = 0.500533\tKL_Divergence = 3.953643\n",
      "Epoch: 45\tFidelity = 0.500480\tKL_Divergence = 4.012231\n",
      "Epoch: 46\tFidelity = 0.500536\tKL_Divergence = 3.950528\n",
      "Epoch: 47\tFidelity = 0.500477\tKL_Divergence = 4.014844\n",
      "Epoch: 48\tFidelity = 0.500481\tKL_Divergence = 4.010752\n",
      "Epoch: 49\tFidelity = 0.500466\tKL_Divergence = 4.027772\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:49:15,851] Trial 477 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500512\tKL_Divergence = 3.975914\n",
      "Total time elapsed during training: 32.438 s\n",
      "Trial 477 pruned. \n",
      "Epoch: 1\tFidelity = 0.500387\tKL_Divergence = 4.131677\n",
      "Epoch: 2\tFidelity = 0.500593\tKL_Divergence = 3.894333\n",
      "Epoch: 3\tFidelity = 0.500532\tKL_Divergence = 3.954764\n",
      "Epoch: 4\tFidelity = 0.500552\tKL_Divergence = 3.933893\n",
      "Epoch: 5\tFidelity = 0.500421\tKL_Divergence = 4.084267\n",
      "Epoch: 6\tFidelity = 0.500542\tKL_Divergence = 3.944382\n",
      "Epoch: 7\tFidelity = 0.500489\tKL_Divergence = 4.001849\n",
      "Epoch: 8\tFidelity = 0.500545\tKL_Divergence = 3.941468\n",
      "Epoch: 9\tFidelity = 0.500590\tKL_Divergence = 3.896875\n",
      "Epoch: 10\tFidelity = 0.500499\tKL_Divergence = 3.989896\n",
      "Epoch: 11\tFidelity = 0.500423\tKL_Divergence = 4.082082\n",
      "Epoch: 12\tFidelity = 0.500586\tKL_Divergence = 3.900956\n",
      "Epoch: 13\tFidelity = 0.500480\tKL_Divergence = 4.011965\n",
      "Epoch: 14\tFidelity = 0.500554\tKL_Divergence = 3.932078\n",
      "Epoch: 15\tFidelity = 0.500492\tKL_Divergence = 3.998250\n",
      "Epoch: 16\tFidelity = 0.500662\tKL_Divergence = 3.833399\n",
      "Epoch: 17\tFidelity = 0.500416\tKL_Divergence = 4.091584\n",
      "Epoch: 18\tFidelity = 0.500514\tKL_Divergence = 3.973932\n",
      "Epoch: 19\tFidelity = 0.500688\tKL_Divergence = 3.811760\n",
      "Epoch: 20\tFidelity = 0.500532\tKL_Divergence = 3.954856\n",
      "Epoch: 21\tFidelity = 0.500590\tKL_Divergence = 3.897720\n",
      "Epoch: 22\tFidelity = 0.500431\tKL_Divergence = 4.071465\n",
      "Epoch: 23\tFidelity = 0.500541\tKL_Divergence = 3.944864\n",
      "Epoch: 24\tFidelity = 0.500583\tKL_Divergence = 3.904224\n",
      "Epoch: 25\tFidelity = 0.500492\tKL_Divergence = 3.998236\n",
      "Epoch: 26\tFidelity = 0.500486\tKL_Divergence = 4.004388\n",
      "Epoch: 27\tFidelity = 0.500437\tKL_Divergence = 4.064330\n",
      "Epoch: 28\tFidelity = 0.500535\tKL_Divergence = 3.951629\n",
      "Epoch: 29\tFidelity = 0.500441\tKL_Divergence = 4.058512\n",
      "Epoch: 30\tFidelity = 0.500579\tKL_Divergence = 3.908041\n",
      "Epoch: 31\tFidelity = 0.500425\tKL_Divergence = 4.079579\n",
      "Epoch: 32\tFidelity = 0.500434\tKL_Divergence = 4.067713\n",
      "Epoch: 33\tFidelity = 0.500502\tKL_Divergence = 3.987091\n",
      "Epoch: 34\tFidelity = 0.500493\tKL_Divergence = 3.996525\n",
      "Epoch: 35\tFidelity = 0.500498\tKL_Divergence = 3.991530\n",
      "Epoch: 36\tFidelity = 0.500402\tKL_Divergence = 4.110012\n",
      "Epoch: 37\tFidelity = 0.500492\tKL_Divergence = 3.998524\n",
      "Epoch: 38\tFidelity = 0.500521\tKL_Divergence = 3.966526\n",
      "Epoch: 39\tFidelity = 0.500366\tKL_Divergence = 4.161925\n",
      "Epoch: 40\tFidelity = 0.500646\tKL_Divergence = 3.847316\n",
      "Epoch: 41\tFidelity = 0.500413\tKL_Divergence = 4.094533\n",
      "Epoch: 42\tFidelity = 0.500519\tKL_Divergence = 3.967897\n",
      "Epoch: 43\tFidelity = 0.500530\tKL_Divergence = 3.956419\n",
      "Epoch: 44\tFidelity = 0.500488\tKL_Divergence = 4.002555\n",
      "Epoch: 45\tFidelity = 0.500528\tKL_Divergence = 3.959037\n",
      "Epoch: 46\tFidelity = 0.500499\tKL_Divergence = 3.990639\n",
      "Epoch: 47\tFidelity = 0.500473\tKL_Divergence = 4.019823\n",
      "Epoch: 48\tFidelity = 0.500510\tKL_Divergence = 3.978088\n",
      "Epoch: 49\tFidelity = 0.500535\tKL_Divergence = 3.951844\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:50:38,170] Trial 478 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500438\tKL_Divergence = 4.062766\n",
      "Total time elapsed during training: 82.144 s\n",
      "Trial 478 pruned. \n",
      "Epoch: 1\tFidelity = 0.500412\tKL_Divergence = 4.096857\n",
      "Epoch: 2\tFidelity = 0.500463\tKL_Divergence = 4.031453\n",
      "Epoch: 3\tFidelity = 0.500486\tKL_Divergence = 4.004640\n",
      "Epoch: 4\tFidelity = 0.500505\tKL_Divergence = 3.983070\n",
      "Epoch: 5\tFidelity = 0.500473\tKL_Divergence = 4.020033\n",
      "Epoch: 6\tFidelity = 0.500545\tKL_Divergence = 3.941057\n",
      "Epoch: 7\tFidelity = 0.500457\tKL_Divergence = 4.038769\n",
      "Epoch: 8\tFidelity = 0.500513\tKL_Divergence = 3.975173\n",
      "Epoch: 9\tFidelity = 0.500450\tKL_Divergence = 4.047809\n",
      "Epoch: 10\tFidelity = 0.500533\tKL_Divergence = 3.953266\n",
      "Epoch: 11\tFidelity = 0.500439\tKL_Divergence = 4.061124\n",
      "Epoch: 12\tFidelity = 0.500427\tKL_Divergence = 4.076848\n",
      "Epoch: 13\tFidelity = 0.500495\tKL_Divergence = 3.995282\n",
      "Epoch: 14\tFidelity = 0.500340\tKL_Divergence = 4.203585\n",
      "Epoch: 15\tFidelity = 0.500488\tKL_Divergence = 4.002981\n",
      "Epoch: 16\tFidelity = 0.500562\tKL_Divergence = 3.923870\n",
      "Epoch: 17\tFidelity = 0.500468\tKL_Divergence = 4.025855\n",
      "Epoch: 18\tFidelity = 0.500358\tKL_Divergence = 4.173792\n",
      "Epoch: 19\tFidelity = 0.500423\tKL_Divergence = 4.081452\n",
      "Epoch: 20\tFidelity = 0.500456\tKL_Divergence = 4.039813\n",
      "Epoch: 21\tFidelity = 0.500512\tKL_Divergence = 3.975525\n",
      "Epoch: 22\tFidelity = 0.500525\tKL_Divergence = 3.962203\n",
      "Epoch: 23\tFidelity = 0.500436\tKL_Divergence = 4.064712\n",
      "Epoch: 24\tFidelity = 0.500415\tKL_Divergence = 4.092457\n",
      "Epoch: 25\tFidelity = 0.500526\tKL_Divergence = 3.960946\n",
      "Epoch: 26\tFidelity = 0.500524\tKL_Divergence = 3.962881\n",
      "Epoch: 27\tFidelity = 0.500536\tKL_Divergence = 3.950556\n",
      "Epoch: 28\tFidelity = 0.500461\tKL_Divergence = 4.034330\n",
      "Epoch: 29\tFidelity = 0.500445\tKL_Divergence = 4.053294\n",
      "Epoch: 30\tFidelity = 0.500455\tKL_Divergence = 4.041474\n",
      "Epoch: 31\tFidelity = 0.500467\tKL_Divergence = 4.027093\n",
      "Epoch: 32\tFidelity = 0.500471\tKL_Divergence = 4.022854\n",
      "Epoch: 33\tFidelity = 0.500461\tKL_Divergence = 4.034031\n",
      "Epoch: 34\tFidelity = 0.500503\tKL_Divergence = 3.985613\n",
      "Epoch: 35\tFidelity = 0.500436\tKL_Divergence = 4.065368\n",
      "Epoch: 36\tFidelity = 0.500411\tKL_Divergence = 4.098166\n",
      "Epoch: 37\tFidelity = 0.500442\tKL_Divergence = 4.057662\n",
      "Epoch: 38\tFidelity = 0.500403\tKL_Divergence = 4.109000\n",
      "Epoch: 39\tFidelity = 0.500439\tKL_Divergence = 4.061566\n",
      "Epoch: 40\tFidelity = 0.500418\tKL_Divergence = 4.088093\n",
      "Epoch: 41\tFidelity = 0.500421\tKL_Divergence = 4.084579\n",
      "Epoch: 42\tFidelity = 0.500547\tKL_Divergence = 3.939489\n",
      "Epoch: 43\tFidelity = 0.500445\tKL_Divergence = 4.054256\n",
      "Epoch: 44\tFidelity = 0.500375\tKL_Divergence = 4.148108\n",
      "Epoch: 45\tFidelity = 0.500563\tKL_Divergence = 3.923501\n",
      "Epoch: 46\tFidelity = 0.500533\tKL_Divergence = 3.953847\n",
      "Epoch: 47\tFidelity = 0.500505\tKL_Divergence = 3.983821\n",
      "Epoch: 48\tFidelity = 0.500559\tKL_Divergence = 3.927572\n",
      "Epoch: 49\tFidelity = 0.500421\tKL_Divergence = 4.084453\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:51:17,208] Trial 479 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500455\tKL_Divergence = 4.041080\n",
      "Total time elapsed during training: 38.849 s\n",
      "Trial 479 pruned. \n",
      "Epoch: 1\tFidelity = 0.500468\tKL_Divergence = 4.025977\n",
      "Epoch: 2\tFidelity = 0.500490\tKL_Divergence = 3.999989\n",
      "Epoch: 3\tFidelity = 0.500498\tKL_Divergence = 3.991117\n",
      "Epoch: 4\tFidelity = 0.500443\tKL_Divergence = 4.055594\n",
      "Epoch: 5\tFidelity = 0.500492\tKL_Divergence = 3.997840\n",
      "Epoch: 6\tFidelity = 0.500467\tKL_Divergence = 4.027112\n",
      "Epoch: 7\tFidelity = 0.500428\tKL_Divergence = 4.075594\n",
      "Epoch: 8\tFidelity = 0.500475\tKL_Divergence = 4.017208\n",
      "Epoch: 9\tFidelity = 0.500421\tKL_Divergence = 4.084172\n",
      "Epoch: 10\tFidelity = 0.500456\tKL_Divergence = 4.039924\n",
      "Epoch: 11\tFidelity = 0.500417\tKL_Divergence = 4.089506\n",
      "Epoch: 12\tFidelity = 0.500393\tKL_Divergence = 4.122088\n",
      "Epoch: 13\tFidelity = 0.500428\tKL_Divergence = 4.075425\n",
      "Epoch: 14\tFidelity = 0.500457\tKL_Divergence = 4.038780\n",
      "Epoch: 15\tFidelity = 0.500444\tKL_Divergence = 4.055350\n",
      "Epoch: 16\tFidelity = 0.500470\tKL_Divergence = 4.023529\n",
      "Epoch: 17\tFidelity = 0.500469\tKL_Divergence = 4.024603\n",
      "Epoch: 18\tFidelity = 0.500453\tKL_Divergence = 4.043321\n",
      "Epoch: 19\tFidelity = 0.500487\tKL_Divergence = 4.003717\n",
      "Epoch: 20\tFidelity = 0.500452\tKL_Divergence = 4.045429\n",
      "Epoch: 21\tFidelity = 0.500458\tKL_Divergence = 4.037492\n",
      "Epoch: 22\tFidelity = 0.500461\tKL_Divergence = 4.033923\n",
      "Epoch: 23\tFidelity = 0.500452\tKL_Divergence = 4.045094\n",
      "Epoch: 24\tFidelity = 0.500441\tKL_Divergence = 4.059114\n",
      "Epoch: 25\tFidelity = 0.500460\tKL_Divergence = 4.034999\n",
      "Epoch: 26\tFidelity = 0.500475\tKL_Divergence = 4.017501\n",
      "Epoch: 27\tFidelity = 0.500490\tKL_Divergence = 4.000124\n",
      "Epoch: 28\tFidelity = 0.500446\tKL_Divergence = 4.052385\n",
      "Epoch: 29\tFidelity = 0.500468\tKL_Divergence = 4.025455\n",
      "Epoch: 30\tFidelity = 0.500466\tKL_Divergence = 4.028571\n",
      "Epoch: 31\tFidelity = 0.500466\tKL_Divergence = 4.028044\n",
      "Epoch: 32\tFidelity = 0.500447\tKL_Divergence = 4.050793\n",
      "Epoch: 33\tFidelity = 0.500424\tKL_Divergence = 4.079855\n",
      "Epoch: 34\tFidelity = 0.500457\tKL_Divergence = 4.038610\n",
      "Epoch: 35\tFidelity = 0.500473\tKL_Divergence = 4.020041\n",
      "Epoch: 36\tFidelity = 0.500460\tKL_Divergence = 4.035161\n",
      "Epoch: 37\tFidelity = 0.500503\tKL_Divergence = 3.985779\n",
      "Epoch: 38\tFidelity = 0.500465\tKL_Divergence = 4.028740\n",
      "Epoch: 39\tFidelity = 0.500466\tKL_Divergence = 4.028471\n",
      "Epoch: 40\tFidelity = 0.500444\tKL_Divergence = 4.054976\n",
      "Epoch: 41\tFidelity = 0.500426\tKL_Divergence = 4.077899\n",
      "Epoch: 42\tFidelity = 0.500436\tKL_Divergence = 4.064200\n",
      "Epoch: 43\tFidelity = 0.500517\tKL_Divergence = 3.970334\n",
      "Epoch: 44\tFidelity = 0.500517\tKL_Divergence = 3.970716\n",
      "Epoch: 45\tFidelity = 0.500449\tKL_Divergence = 4.047739\n",
      "Epoch: 46\tFidelity = 0.500490\tKL_Divergence = 4.000257\n",
      "Epoch: 47\tFidelity = 0.500461\tKL_Divergence = 4.033774\n",
      "Epoch: 48\tFidelity = 0.500477\tKL_Divergence = 4.014476\n",
      "Epoch: 49\tFidelity = 0.500456\tKL_Divergence = 4.040046\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:51:55,985] Trial 480 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500473\tKL_Divergence = 4.019299\n",
      "Total time elapsed during training: 38.591 s\n",
      "Trial 480 pruned. \n",
      "Epoch: 1\tFidelity = 0.500411\tKL_Divergence = 4.098017\n",
      "Epoch: 2\tFidelity = 0.500356\tKL_Divergence = 4.177919\n",
      "Epoch: 3\tFidelity = 0.500465\tKL_Divergence = 4.029046\n",
      "Epoch: 4\tFidelity = 0.500553\tKL_Divergence = 3.933087\n",
      "Epoch: 5\tFidelity = 0.500601\tKL_Divergence = 3.886438\n",
      "Epoch: 6\tFidelity = 0.500532\tKL_Divergence = 3.954945\n",
      "Epoch: 7\tFidelity = 0.500564\tKL_Divergence = 3.922341\n",
      "Epoch: 8\tFidelity = 0.500462\tKL_Divergence = 4.032602\n",
      "Epoch: 9\tFidelity = 0.500483\tKL_Divergence = 4.008739\n",
      "Epoch: 10\tFidelity = 0.500552\tKL_Divergence = 3.933507\n",
      "Epoch: 11\tFidelity = 0.500539\tKL_Divergence = 3.947070\n",
      "Epoch: 12\tFidelity = 0.500416\tKL_Divergence = 4.091003\n",
      "Epoch: 13\tFidelity = 0.500430\tKL_Divergence = 4.073248\n",
      "Epoch: 14\tFidelity = 0.500418\tKL_Divergence = 4.088150\n",
      "Epoch: 15\tFidelity = 0.500476\tKL_Divergence = 4.015190\n",
      "Epoch: 16\tFidelity = 0.500586\tKL_Divergence = 3.899513\n",
      "Epoch: 17\tFidelity = 0.500364\tKL_Divergence = 4.164335\n",
      "Epoch: 18\tFidelity = 0.500414\tKL_Divergence = 4.092636\n",
      "Epoch: 19\tFidelity = 0.500556\tKL_Divergence = 3.930393\n",
      "Epoch: 20\tFidelity = 0.500517\tKL_Divergence = 3.969856\n",
      "Epoch: 21\tFidelity = 0.500453\tKL_Divergence = 4.044215\n",
      "Epoch: 22\tFidelity = 0.500362\tKL_Divergence = 4.168185\n",
      "Epoch: 23\tFidelity = 0.500468\tKL_Divergence = 4.025791\n",
      "Epoch: 24\tFidelity = 0.500453\tKL_Divergence = 4.044000\n",
      "Epoch: 25\tFidelity = 0.500381\tKL_Divergence = 4.139527\n",
      "Epoch: 26\tFidelity = 0.500461\tKL_Divergence = 4.034256\n",
      "Epoch: 27\tFidelity = 0.500457\tKL_Divergence = 4.038509\n",
      "Epoch: 28\tFidelity = 0.500462\tKL_Divergence = 4.033172\n",
      "Epoch: 29\tFidelity = 0.500435\tKL_Divergence = 4.065749\n",
      "Epoch: 30\tFidelity = 0.500480\tKL_Divergence = 4.011609\n",
      "Epoch: 31\tFidelity = 0.500423\tKL_Divergence = 4.081256\n",
      "Epoch: 32\tFidelity = 0.500416\tKL_Divergence = 4.090507\n",
      "Epoch: 33\tFidelity = 0.500474\tKL_Divergence = 4.019076\n",
      "Epoch: 34\tFidelity = 0.500568\tKL_Divergence = 3.917626\n",
      "Epoch: 35\tFidelity = 0.500364\tKL_Divergence = 4.163935\n",
      "Epoch: 36\tFidelity = 0.500544\tKL_Divergence = 3.940934\n",
      "Epoch: 37\tFidelity = 0.500432\tKL_Divergence = 4.069309\n",
      "Epoch: 38\tFidelity = 0.500410\tKL_Divergence = 4.098579\n",
      "Epoch: 39\tFidelity = 0.500509\tKL_Divergence = 3.978354\n",
      "Epoch: 40\tFidelity = 0.500432\tKL_Divergence = 4.068407\n",
      "Epoch: 41\tFidelity = 0.500556\tKL_Divergence = 3.929514\n",
      "Epoch: 42\tFidelity = 0.500458\tKL_Divergence = 4.036526\n",
      "Epoch: 43\tFidelity = 0.500451\tKL_Divergence = 4.044598\n",
      "Epoch: 44\tFidelity = 0.500310\tKL_Divergence = 4.252051\n",
      "Epoch: 45\tFidelity = 0.500416\tKL_Divergence = 4.089326\n",
      "Epoch: 46\tFidelity = 0.500392\tKL_Divergence = 4.122116\n",
      "Epoch: 47\tFidelity = 0.500346\tKL_Divergence = 4.190324\n",
      "Epoch: 48\tFidelity = 0.500500\tKL_Divergence = 3.985623\n",
      "Epoch: 49\tFidelity = 0.500392\tKL_Divergence = 4.120720\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:52:41,412] Trial 481 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500349\tKL_Divergence = 4.186194\n",
      "Total time elapsed during training: 45.249 s\n",
      "Trial 481 pruned. \n",
      "Epoch: 1\tFidelity = 0.500341\tKL_Divergence = 4.199601\n",
      "Epoch: 2\tFidelity = 0.500460\tKL_Divergence = 4.032910\n",
      "Epoch: 3\tFidelity = 0.500440\tKL_Divergence = 4.058477\n",
      "Epoch: 4\tFidelity = 0.500440\tKL_Divergence = 4.058495\n",
      "Epoch: 5\tFidelity = 0.500375\tKL_Divergence = 4.147844\n",
      "Epoch: 6\tFidelity = 0.500455\tKL_Divergence = 4.040706\n",
      "Epoch: 7\tFidelity = 0.500484\tKL_Divergence = 4.007002\n",
      "Epoch: 8\tFidelity = 0.500376\tKL_Divergence = 4.147099\n",
      "Epoch: 9\tFidelity = 0.500444\tKL_Divergence = 4.054910\n",
      "Epoch: 10\tFidelity = 0.500426\tKL_Divergence = 4.077672\n",
      "Epoch: 11\tFidelity = 0.500439\tKL_Divergence = 4.061336\n",
      "Epoch: 12\tFidelity = 0.500406\tKL_Divergence = 4.104308\n",
      "Epoch: 13\tFidelity = 0.500436\tKL_Divergence = 4.065582\n",
      "Epoch: 14\tFidelity = 0.500434\tKL_Divergence = 4.067569\n",
      "Epoch: 15\tFidelity = 0.500421\tKL_Divergence = 4.084128\n",
      "Epoch: 16\tFidelity = 0.500432\tKL_Divergence = 4.070854\n",
      "Epoch: 17\tFidelity = 0.500413\tKL_Divergence = 4.094600\n",
      "Epoch: 18\tFidelity = 0.500364\tKL_Divergence = 4.165230\n",
      "Epoch: 19\tFidelity = 0.500436\tKL_Divergence = 4.065699\n",
      "Epoch: 20\tFidelity = 0.500400\tKL_Divergence = 4.113182\n",
      "Epoch: 21\tFidelity = 0.500451\tKL_Divergence = 4.047023\n",
      "Epoch: 22\tFidelity = 0.500426\tKL_Divergence = 4.078034\n",
      "Epoch: 23\tFidelity = 0.500433\tKL_Divergence = 4.068685\n",
      "Epoch: 24\tFidelity = 0.500433\tKL_Divergence = 4.069335\n",
      "Epoch: 25\tFidelity = 0.500445\tKL_Divergence = 4.053548\n",
      "Epoch: 26\tFidelity = 0.500426\tKL_Divergence = 4.077534\n",
      "Epoch: 27\tFidelity = 0.500492\tKL_Divergence = 3.997942\n",
      "Epoch: 28\tFidelity = 0.500439\tKL_Divergence = 4.061190\n",
      "Epoch: 29\tFidelity = 0.500428\tKL_Divergence = 4.075725\n",
      "Epoch: 30\tFidelity = 0.500471\tKL_Divergence = 4.022763\n",
      "Epoch: 31\tFidelity = 0.500381\tKL_Divergence = 4.139942\n",
      "Epoch: 32\tFidelity = 0.500440\tKL_Divergence = 4.060509\n",
      "Epoch: 33\tFidelity = 0.500411\tKL_Divergence = 4.097696\n",
      "Epoch: 34\tFidelity = 0.500409\tKL_Divergence = 4.100964\n",
      "Epoch: 35\tFidelity = 0.500421\tKL_Divergence = 4.085131\n",
      "Epoch: 36\tFidelity = 0.500425\tKL_Divergence = 4.079638\n",
      "Epoch: 37\tFidelity = 0.500407\tKL_Divergence = 4.103995\n",
      "Epoch: 38\tFidelity = 0.500453\tKL_Divergence = 4.043781\n",
      "Epoch: 39\tFidelity = 0.500410\tKL_Divergence = 4.098917\n",
      "Epoch: 40\tFidelity = 0.500401\tKL_Divergence = 4.111121\n",
      "Epoch: 41\tFidelity = 0.500416\tKL_Divergence = 4.091425\n",
      "Epoch: 42\tFidelity = 0.500480\tKL_Divergence = 4.011376\n",
      "Epoch: 43\tFidelity = 0.500468\tKL_Divergence = 4.025861\n",
      "Epoch: 44\tFidelity = 0.500431\tKL_Divergence = 4.072095\n",
      "Epoch: 45\tFidelity = 0.500462\tKL_Divergence = 4.033616\n",
      "Epoch: 46\tFidelity = 0.500496\tKL_Divergence = 3.994089\n",
      "Epoch: 47\tFidelity = 0.500456\tKL_Divergence = 4.040519\n",
      "Epoch: 48\tFidelity = 0.500395\tKL_Divergence = 4.120389\n",
      "Epoch: 49\tFidelity = 0.500442\tKL_Divergence = 4.057873\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:53:28,232] Trial 482 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500380\tKL_Divergence = 4.140967\n",
      "Total time elapsed during training: 46.630 s\n",
      "Trial 482 pruned. \n",
      "Epoch: 1\tFidelity = 0.500454\tKL_Divergence = 4.042262\n",
      "Epoch: 2\tFidelity = 0.500476\tKL_Divergence = 4.016812\n",
      "Epoch: 3\tFidelity = 0.500390\tKL_Divergence = 4.126444\n",
      "Epoch: 4\tFidelity = 0.500359\tKL_Divergence = 4.172332\n",
      "Epoch: 5\tFidelity = 0.500364\tKL_Divergence = 4.165285\n",
      "Epoch: 6\tFidelity = 0.500401\tKL_Divergence = 4.111022\n",
      "Epoch: 7\tFidelity = 0.500469\tKL_Divergence = 4.024925\n",
      "Epoch: 8\tFidelity = 0.500400\tKL_Divergence = 4.113419\n",
      "Epoch: 9\tFidelity = 0.500411\tKL_Divergence = 4.098347\n",
      "Epoch: 10\tFidelity = 0.500424\tKL_Divergence = 4.080377\n",
      "Epoch: 11\tFidelity = 0.500368\tKL_Divergence = 4.158835\n",
      "Epoch: 12\tFidelity = 0.500449\tKL_Divergence = 4.048476\n",
      "Epoch: 13\tFidelity = 0.500478\tKL_Divergence = 4.014586\n",
      "Epoch: 14\tFidelity = 0.500429\tKL_Divergence = 4.074768\n",
      "Epoch: 15\tFidelity = 0.500405\tKL_Divergence = 4.105926\n",
      "Epoch: 16\tFidelity = 0.500375\tKL_Divergence = 4.148655\n",
      "Epoch: 17\tFidelity = 0.500429\tKL_Divergence = 4.074658\n",
      "Epoch: 18\tFidelity = 0.500456\tKL_Divergence = 4.040719\n",
      "Epoch: 19\tFidelity = 0.500418\tKL_Divergence = 4.088363\n",
      "Epoch: 20\tFidelity = 0.500388\tKL_Divergence = 4.129260\n",
      "Epoch: 21\tFidelity = 0.500447\tKL_Divergence = 4.051948\n",
      "Epoch: 22\tFidelity = 0.500361\tKL_Divergence = 4.170013\n",
      "Epoch: 23\tFidelity = 0.500403\tKL_Divergence = 4.108904\n",
      "Epoch: 24\tFidelity = 0.500420\tKL_Divergence = 4.086568\n",
      "Epoch: 25\tFidelity = 0.500493\tKL_Divergence = 3.996832\n",
      "Epoch: 26\tFidelity = 0.500423\tKL_Divergence = 4.082407\n",
      "Epoch: 27\tFidelity = 0.500463\tKL_Divergence = 4.032121\n",
      "Epoch: 28\tFidelity = 0.500468\tKL_Divergence = 4.026085\n",
      "Epoch: 29\tFidelity = 0.500432\tKL_Divergence = 4.070223\n",
      "Epoch: 30\tFidelity = 0.500449\tKL_Divergence = 4.048551\n",
      "Epoch: 31\tFidelity = 0.500389\tKL_Divergence = 4.128136\n",
      "Epoch: 32\tFidelity = 0.500434\tKL_Divergence = 4.067658\n",
      "Epoch: 33\tFidelity = 0.500453\tKL_Divergence = 4.044346\n",
      "Epoch: 34\tFidelity = 0.500464\tKL_Divergence = 4.030941\n",
      "Epoch: 35\tFidelity = 0.500446\tKL_Divergence = 4.052313\n",
      "Epoch: 36\tFidelity = 0.500447\tKL_Divergence = 4.051171\n",
      "Epoch: 37\tFidelity = 0.500498\tKL_Divergence = 3.991868\n",
      "Epoch: 38\tFidelity = 0.500456\tKL_Divergence = 4.040464\n",
      "Epoch: 39\tFidelity = 0.500380\tKL_Divergence = 4.141375\n",
      "Epoch: 40\tFidelity = 0.500436\tKL_Divergence = 4.065536\n",
      "Epoch: 41\tFidelity = 0.500470\tKL_Divergence = 4.023514\n",
      "Epoch: 42\tFidelity = 0.500417\tKL_Divergence = 4.090257\n",
      "Epoch: 43\tFidelity = 0.500478\tKL_Divergence = 4.014572\n",
      "Epoch: 44\tFidelity = 0.500436\tKL_Divergence = 4.065493\n",
      "Epoch: 45\tFidelity = 0.500389\tKL_Divergence = 4.128745\n",
      "Epoch: 46\tFidelity = 0.500474\tKL_Divergence = 4.018475\n",
      "Epoch: 47\tFidelity = 0.500500\tKL_Divergence = 3.988656\n",
      "Epoch: 48\tFidelity = 0.500449\tKL_Divergence = 4.049039\n",
      "Epoch: 49\tFidelity = 0.500513\tKL_Divergence = 3.974529\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:54:52,424] Trial 483 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500446\tKL_Divergence = 4.052432\n",
      "Total time elapsed during training: 84.016 s\n",
      "Trial 483 pruned. \n",
      "Epoch: 1\tFidelity = 0.500424\tKL_Divergence = 4.080527\n",
      "Epoch: 2\tFidelity = 0.500406\tKL_Divergence = 4.104493\n",
      "Epoch: 3\tFidelity = 0.500382\tKL_Divergence = 4.138165\n",
      "Epoch: 4\tFidelity = 0.500468\tKL_Divergence = 4.026306\n",
      "Epoch: 5\tFidelity = 0.500447\tKL_Divergence = 4.050701\n",
      "Epoch: 6\tFidelity = 0.500444\tKL_Divergence = 4.055563\n",
      "Epoch: 7\tFidelity = 0.500466\tKL_Divergence = 4.028472\n",
      "Epoch: 8\tFidelity = 0.500431\tKL_Divergence = 4.071401\n",
      "Epoch: 9\tFidelity = 0.500421\tKL_Divergence = 4.084490\n",
      "Epoch: 10\tFidelity = 0.500446\tKL_Divergence = 4.052952\n",
      "Epoch: 11\tFidelity = 0.500438\tKL_Divergence = 4.062701\n",
      "Epoch: 12\tFidelity = 0.500426\tKL_Divergence = 4.078215\n",
      "Epoch: 13\tFidelity = 0.500433\tKL_Divergence = 4.069156\n",
      "Epoch: 14\tFidelity = 0.500433\tKL_Divergence = 4.068745\n",
      "Epoch: 15\tFidelity = 0.500469\tKL_Divergence = 4.025123\n",
      "Epoch: 16\tFidelity = 0.500453\tKL_Divergence = 4.044471\n",
      "Epoch: 17\tFidelity = 0.500427\tKL_Divergence = 4.076693\n",
      "Epoch: 18\tFidelity = 0.500407\tKL_Divergence = 4.102779\n",
      "Epoch: 19\tFidelity = 0.500447\tKL_Divergence = 4.050792\n",
      "Epoch: 20\tFidelity = 0.500425\tKL_Divergence = 4.078751\n",
      "Epoch: 21\tFidelity = 0.500415\tKL_Divergence = 4.093129\n",
      "Epoch: 22\tFidelity = 0.500430\tKL_Divergence = 4.072494\n",
      "Epoch: 23\tFidelity = 0.500466\tKL_Divergence = 4.028563\n",
      "Epoch: 24\tFidelity = 0.500485\tKL_Divergence = 4.006440\n",
      "Epoch: 25\tFidelity = 0.500458\tKL_Divergence = 4.037501\n",
      "Epoch: 26\tFidelity = 0.500449\tKL_Divergence = 4.048817\n",
      "Epoch: 27\tFidelity = 0.500452\tKL_Divergence = 4.045701\n",
      "Epoch: 28\tFidelity = 0.500463\tKL_Divergence = 4.031513\n",
      "Epoch: 29\tFidelity = 0.500397\tKL_Divergence = 4.116695\n",
      "Epoch: 30\tFidelity = 0.500470\tKL_Divergence = 4.023491\n",
      "Epoch: 31\tFidelity = 0.500394\tKL_Divergence = 4.121081\n",
      "Epoch: 32\tFidelity = 0.500431\tKL_Divergence = 4.071522\n",
      "Epoch: 33\tFidelity = 0.500448\tKL_Divergence = 4.049572\n",
      "Epoch: 34\tFidelity = 0.500431\tKL_Divergence = 4.071113\n",
      "Epoch: 35\tFidelity = 0.500422\tKL_Divergence = 4.083293\n",
      "Epoch: 36\tFidelity = 0.500460\tKL_Divergence = 4.035753\n",
      "Epoch: 37\tFidelity = 0.500433\tKL_Divergence = 4.068854\n",
      "Epoch: 38\tFidelity = 0.500434\tKL_Divergence = 4.067247\n",
      "Epoch: 39\tFidelity = 0.500417\tKL_Divergence = 4.089618\n",
      "Epoch: 40\tFidelity = 0.500419\tKL_Divergence = 4.087316\n",
      "Epoch: 41\tFidelity = 0.500444\tKL_Divergence = 4.054687\n",
      "Epoch: 42\tFidelity = 0.500432\tKL_Divergence = 4.069771\n",
      "Epoch: 43\tFidelity = 0.500430\tKL_Divergence = 4.073018\n",
      "Epoch: 44\tFidelity = 0.500436\tKL_Divergence = 4.064619\n",
      "Epoch: 45\tFidelity = 0.500441\tKL_Divergence = 4.059344\n",
      "Epoch: 46\tFidelity = 0.500445\tKL_Divergence = 4.054020\n",
      "Epoch: 47\tFidelity = 0.500472\tKL_Divergence = 4.021598\n",
      "Epoch: 48\tFidelity = 0.500434\tKL_Divergence = 4.067259\n",
      "Epoch: 49\tFidelity = 0.500400\tKL_Divergence = 4.112318\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:55:31,870] Trial 484 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500424\tKL_Divergence = 4.080618\n",
      "Total time elapsed during training: 39.264 s\n",
      "Trial 484 pruned. \n",
      "Epoch: 1\tFidelity = 0.500384\tKL_Divergence = 4.135223\n",
      "Epoch: 2\tFidelity = 0.500369\tKL_Divergence = 4.158016\n",
      "Epoch: 3\tFidelity = 0.500466\tKL_Divergence = 4.028371\n",
      "Epoch: 4\tFidelity = 0.500499\tKL_Divergence = 3.989730\n",
      "Epoch: 5\tFidelity = 0.500511\tKL_Divergence = 3.976503\n",
      "Epoch: 6\tFidelity = 0.500428\tKL_Divergence = 4.074044\n",
      "Epoch: 7\tFidelity = 0.500340\tKL_Divergence = 4.202516\n",
      "Epoch: 8\tFidelity = 0.500484\tKL_Divergence = 4.005859\n",
      "Epoch: 9\tFidelity = 0.500531\tKL_Divergence = 3.955878\n",
      "Epoch: 10\tFidelity = 0.500439\tKL_Divergence = 4.061361\n",
      "Epoch: 11\tFidelity = 0.500352\tKL_Divergence = 4.182646\n",
      "Epoch: 12\tFidelity = 0.500341\tKL_Divergence = 4.200214\n",
      "Epoch: 13\tFidelity = 0.500335\tKL_Divergence = 4.210619\n",
      "Epoch: 14\tFidelity = 0.500406\tKL_Divergence = 4.103885\n",
      "Epoch: 15\tFidelity = 0.500595\tKL_Divergence = 3.892973\n",
      "Epoch: 16\tFidelity = 0.500310\tKL_Divergence = 4.253536\n",
      "Epoch: 17\tFidelity = 0.500346\tKL_Divergence = 4.193117\n",
      "Epoch: 18\tFidelity = 0.500349\tKL_Divergence = 4.188058\n",
      "Epoch: 19\tFidelity = 0.500450\tKL_Divergence = 4.046420\n",
      "Epoch: 20\tFidelity = 0.500527\tKL_Divergence = 3.959021\n",
      "Epoch: 21\tFidelity = 0.500498\tKL_Divergence = 3.991523\n",
      "Epoch: 22\tFidelity = 0.500539\tKL_Divergence = 3.947900\n",
      "Epoch: 23\tFidelity = 0.500513\tKL_Divergence = 3.975350\n",
      "Epoch: 24\tFidelity = 0.500562\tKL_Divergence = 3.924440\n",
      "Epoch: 25\tFidelity = 0.500510\tKL_Divergence = 3.977710\n",
      "Epoch: 26\tFidelity = 0.500453\tKL_Divergence = 4.043302\n",
      "Epoch: 27\tFidelity = 0.500430\tKL_Divergence = 4.073152\n",
      "Epoch: 28\tFidelity = 0.500324\tKL_Divergence = 4.229773\n",
      "Epoch: 29\tFidelity = 0.500364\tKL_Divergence = 4.165174\n",
      "Epoch: 30\tFidelity = 0.500324\tKL_Divergence = 4.229781\n",
      "Epoch: 31\tFidelity = 0.500389\tKL_Divergence = 4.128025\n",
      "Epoch: 32\tFidelity = 0.500545\tKL_Divergence = 3.940929\n",
      "Epoch: 33\tFidelity = 0.500550\tKL_Divergence = 3.936560\n",
      "Epoch: 34\tFidelity = 0.500593\tKL_Divergence = 3.894455\n",
      "Epoch: 35\tFidelity = 0.500369\tKL_Divergence = 4.158206\n",
      "Epoch: 36\tFidelity = 0.500382\tKL_Divergence = 4.138353\n",
      "Epoch: 37\tFidelity = 0.500460\tKL_Divergence = 4.035451\n",
      "Epoch: 38\tFidelity = 0.500394\tKL_Divergence = 4.120773\n",
      "Epoch: 39\tFidelity = 0.500289\tKL_Divergence = 4.292608\n",
      "Epoch: 40\tFidelity = 0.500402\tKL_Divergence = 4.109608\n",
      "Epoch: 41\tFidelity = 0.500504\tKL_Divergence = 3.984127\n",
      "Epoch: 42\tFidelity = 0.500443\tKL_Divergence = 4.056389\n",
      "Epoch: 43\tFidelity = 0.500549\tKL_Divergence = 3.936876\n",
      "Epoch: 44\tFidelity = 0.500483\tKL_Divergence = 4.008103\n",
      "Epoch: 45\tFidelity = 0.500511\tKL_Divergence = 3.977459\n",
      "Epoch: 46\tFidelity = 0.500432\tKL_Divergence = 4.070775\n",
      "Epoch: 47\tFidelity = 0.500380\tKL_Divergence = 4.142153\n",
      "Epoch: 48\tFidelity = 0.500292\tKL_Divergence = 4.287696\n",
      "Epoch: 49\tFidelity = 0.500437\tKL_Divergence = 4.064032\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:56:11,184] Trial 485 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500392\tKL_Divergence = 4.123455\n",
      "Total time elapsed during training: 39.100 s\n",
      "Trial 485 pruned. \n",
      "Epoch: 1\tFidelity = 0.500434\tKL_Divergence = 4.067587\n",
      "Epoch: 2\tFidelity = 0.500380\tKL_Divergence = 4.140758\n",
      "Epoch: 3\tFidelity = 0.500391\tKL_Divergence = 4.125045\n",
      "Epoch: 4\tFidelity = 0.500438\tKL_Divergence = 4.063044\n",
      "Epoch: 5\tFidelity = 0.500451\tKL_Divergence = 4.046900\n",
      "Epoch: 6\tFidelity = 0.500424\tKL_Divergence = 4.081286\n",
      "Epoch: 7\tFidelity = 0.500406\tKL_Divergence = 4.104847\n",
      "Epoch: 8\tFidelity = 0.500449\tKL_Divergence = 4.048910\n",
      "Epoch: 9\tFidelity = 0.500451\tKL_Divergence = 4.046486\n",
      "Epoch: 10\tFidelity = 0.500430\tKL_Divergence = 4.073012\n",
      "Epoch: 11\tFidelity = 0.500435\tKL_Divergence = 4.066592\n",
      "Epoch: 12\tFidelity = 0.500404\tKL_Divergence = 4.107328\n",
      "Epoch: 13\tFidelity = 0.500467\tKL_Divergence = 4.027148\n",
      "Epoch: 14\tFidelity = 0.500495\tKL_Divergence = 3.995311\n",
      "Epoch: 15\tFidelity = 0.500473\tKL_Divergence = 4.020220\n",
      "Epoch: 16\tFidelity = 0.500391\tKL_Divergence = 4.125495\n",
      "Epoch: 17\tFidelity = 0.500470\tKL_Divergence = 4.023107\n",
      "Epoch: 18\tFidelity = 0.500446\tKL_Divergence = 4.052278\n",
      "Epoch: 19\tFidelity = 0.500425\tKL_Divergence = 4.080073\n",
      "Epoch: 20\tFidelity = 0.500386\tKL_Divergence = 4.133420\n",
      "Epoch: 21\tFidelity = 0.500493\tKL_Divergence = 3.996715\n",
      "Epoch: 22\tFidelity = 0.500460\tKL_Divergence = 4.035504\n",
      "Epoch: 23\tFidelity = 0.500494\tKL_Divergence = 3.996477\n",
      "Epoch: 24\tFidelity = 0.500405\tKL_Divergence = 4.106694\n",
      "Epoch: 25\tFidelity = 0.500490\tKL_Divergence = 4.000972\n",
      "Epoch: 26\tFidelity = 0.500471\tKL_Divergence = 4.021776\n",
      "Epoch: 27\tFidelity = 0.500506\tKL_Divergence = 3.982705\n",
      "Epoch: 28\tFidelity = 0.500523\tKL_Divergence = 3.964628\n",
      "Epoch: 29\tFidelity = 0.500542\tKL_Divergence = 3.944857\n",
      "Epoch: 30\tFidelity = 0.500427\tKL_Divergence = 4.076565\n",
      "Epoch: 31\tFidelity = 0.500402\tKL_Divergence = 4.109668\n",
      "Epoch: 32\tFidelity = 0.500420\tKL_Divergence = 4.085419\n",
      "Epoch: 33\tFidelity = 0.500321\tKL_Divergence = 4.234268\n",
      "Epoch: 34\tFidelity = 0.500378\tKL_Divergence = 4.144958\n",
      "Epoch: 35\tFidelity = 0.500433\tKL_Divergence = 4.069513\n",
      "Epoch: 36\tFidelity = 0.500531\tKL_Divergence = 3.955997\n",
      "Epoch: 37\tFidelity = 0.500391\tKL_Divergence = 4.126044\n",
      "Epoch: 38\tFidelity = 0.500535\tKL_Divergence = 3.951963\n",
      "Epoch: 39\tFidelity = 0.500386\tKL_Divergence = 4.132880\n",
      "Epoch: 40\tFidelity = 0.500484\tKL_Divergence = 4.007717\n",
      "Epoch: 41\tFidelity = 0.500473\tKL_Divergence = 4.019760\n",
      "Epoch: 42\tFidelity = 0.500502\tKL_Divergence = 3.987030\n",
      "Epoch: 43\tFidelity = 0.500463\tKL_Divergence = 4.031648\n",
      "Epoch: 44\tFidelity = 0.500498\tKL_Divergence = 3.991356\n",
      "Epoch: 45\tFidelity = 0.500332\tKL_Divergence = 4.216374\n",
      "Epoch: 46\tFidelity = 0.500529\tKL_Divergence = 3.958374\n",
      "Epoch: 47\tFidelity = 0.500486\tKL_Divergence = 4.004981\n",
      "Epoch: 48\tFidelity = 0.500458\tKL_Divergence = 4.038243\n",
      "Epoch: 49\tFidelity = 0.500426\tKL_Divergence = 4.077971\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:56:50,425] Trial 486 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500474\tKL_Divergence = 4.018712\n",
      "Total time elapsed during training: 39.055 s\n",
      "Trial 486 pruned. \n",
      "Epoch: 1\tFidelity = 0.500427\tKL_Divergence = 4.076944\n",
      "Epoch: 2\tFidelity = 0.500436\tKL_Divergence = 4.065802\n",
      "Epoch: 3\tFidelity = 0.500450\tKL_Divergence = 4.047992\n",
      "Epoch: 4\tFidelity = 0.500435\tKL_Divergence = 4.066587\n",
      "Epoch: 5\tFidelity = 0.500448\tKL_Divergence = 4.049676\n",
      "Epoch: 6\tFidelity = 0.500441\tKL_Divergence = 4.059053\n",
      "Epoch: 7\tFidelity = 0.500412\tKL_Divergence = 4.097308\n",
      "Epoch: 8\tFidelity = 0.500420\tKL_Divergence = 4.086209\n",
      "Epoch: 9\tFidelity = 0.500418\tKL_Divergence = 4.088315\n",
      "Epoch: 10\tFidelity = 0.500410\tKL_Divergence = 4.099848\n",
      "Epoch: 11\tFidelity = 0.500407\tKL_Divergence = 4.103532\n",
      "Epoch: 12\tFidelity = 0.500449\tKL_Divergence = 4.049361\n",
      "Epoch: 13\tFidelity = 0.500433\tKL_Divergence = 4.068930\n",
      "Epoch: 14\tFidelity = 0.500417\tKL_Divergence = 4.089863\n",
      "Epoch: 15\tFidelity = 0.500454\tKL_Divergence = 4.042901\n",
      "Epoch: 16\tFidelity = 0.500478\tKL_Divergence = 4.014112\n",
      "Epoch: 17\tFidelity = 0.500456\tKL_Divergence = 4.040150\n",
      "Epoch: 18\tFidelity = 0.500448\tKL_Divergence = 4.050739\n",
      "Epoch: 19\tFidelity = 0.500441\tKL_Divergence = 4.059113\n",
      "Epoch: 20\tFidelity = 0.500432\tKL_Divergence = 4.069861\n",
      "Epoch: 21\tFidelity = 0.500431\tKL_Divergence = 4.071773\n",
      "Epoch: 22\tFidelity = 0.500436\tKL_Divergence = 4.065515\n",
      "Epoch: 23\tFidelity = 0.500425\tKL_Divergence = 4.080026\n",
      "Epoch: 24\tFidelity = 0.500446\tKL_Divergence = 4.052330\n",
      "Epoch: 25\tFidelity = 0.500407\tKL_Divergence = 4.103481\n",
      "Epoch: 26\tFidelity = 0.500465\tKL_Divergence = 4.028917\n",
      "Epoch: 27\tFidelity = 0.500435\tKL_Divergence = 4.066637\n",
      "Epoch: 28\tFidelity = 0.500455\tKL_Divergence = 4.042027\n",
      "Epoch: 29\tFidelity = 0.500422\tKL_Divergence = 4.082921\n",
      "Epoch: 30\tFidelity = 0.500459\tKL_Divergence = 4.036424\n",
      "Epoch: 31\tFidelity = 0.500423\tKL_Divergence = 4.081655\n",
      "Epoch: 32\tFidelity = 0.500465\tKL_Divergence = 4.029200\n",
      "Epoch: 33\tFidelity = 0.500411\tKL_Divergence = 4.097687\n",
      "Epoch: 34\tFidelity = 0.500413\tKL_Divergence = 4.095672\n",
      "Epoch: 35\tFidelity = 0.500458\tKL_Divergence = 4.037821\n",
      "Epoch: 36\tFidelity = 0.500459\tKL_Divergence = 4.037214\n",
      "Epoch: 37\tFidelity = 0.500416\tKL_Divergence = 4.091852\n",
      "Epoch: 38\tFidelity = 0.500427\tKL_Divergence = 4.076184\n",
      "Epoch: 39\tFidelity = 0.500452\tKL_Divergence = 4.045505\n",
      "Epoch: 40\tFidelity = 0.500445\tKL_Divergence = 4.053281\n",
      "Epoch: 41\tFidelity = 0.500443\tKL_Divergence = 4.055966\n",
      "Epoch: 42\tFidelity = 0.500416\tKL_Divergence = 4.090935\n",
      "Epoch: 43\tFidelity = 0.500449\tKL_Divergence = 4.049340\n",
      "Epoch: 44\tFidelity = 0.500456\tKL_Divergence = 4.040724\n",
      "Epoch: 45\tFidelity = 0.500415\tKL_Divergence = 4.092747\n",
      "Epoch: 46\tFidelity = 0.500439\tKL_Divergence = 4.062014\n",
      "Epoch: 47\tFidelity = 0.500456\tKL_Divergence = 4.040618\n",
      "Epoch: 48\tFidelity = 0.500450\tKL_Divergence = 4.047468\n",
      "Epoch: 49\tFidelity = 0.500417\tKL_Divergence = 4.090325\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:57:22,998] Trial 487 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500471\tKL_Divergence = 4.022793\n",
      "Total time elapsed during training: 32.375 s\n",
      "Trial 487 pruned. \n",
      "Epoch: 1\tFidelity = 0.500393\tKL_Divergence = 4.123448\n",
      "Epoch: 2\tFidelity = 0.500497\tKL_Divergence = 3.992868\n",
      "Epoch: 3\tFidelity = 0.500371\tKL_Divergence = 4.154828\n",
      "Epoch: 4\tFidelity = 0.500438\tKL_Divergence = 4.062060\n",
      "Epoch: 5\tFidelity = 0.500473\tKL_Divergence = 4.019591\n",
      "Epoch: 6\tFidelity = 0.500370\tKL_Divergence = 4.156621\n",
      "Epoch: 7\tFidelity = 0.500506\tKL_Divergence = 3.982837\n",
      "Epoch: 8\tFidelity = 0.500426\tKL_Divergence = 4.077679\n",
      "Epoch: 9\tFidelity = 0.500460\tKL_Divergence = 4.035037\n",
      "Epoch: 10\tFidelity = 0.500415\tKL_Divergence = 4.092948\n",
      "Epoch: 11\tFidelity = 0.500402\tKL_Divergence = 4.110077\n",
      "Epoch: 12\tFidelity = 0.500474\tKL_Divergence = 4.018291\n",
      "Epoch: 13\tFidelity = 0.500395\tKL_Divergence = 4.119923\n",
      "Epoch: 14\tFidelity = 0.500442\tKL_Divergence = 4.058267\n",
      "Epoch: 15\tFidelity = 0.500415\tKL_Divergence = 4.092722\n",
      "Epoch: 16\tFidelity = 0.500514\tKL_Divergence = 3.974250\n",
      "Epoch: 17\tFidelity = 0.500417\tKL_Divergence = 4.089433\n",
      "Epoch: 18\tFidelity = 0.500396\tKL_Divergence = 4.118736\n",
      "Epoch: 19\tFidelity = 0.500454\tKL_Divergence = 4.043129\n",
      "Epoch: 20\tFidelity = 0.500452\tKL_Divergence = 4.045802\n",
      "Epoch: 21\tFidelity = 0.500427\tKL_Divergence = 4.076269\n",
      "Epoch: 22\tFidelity = 0.500415\tKL_Divergence = 4.093022\n",
      "Epoch: 23\tFidelity = 0.500434\tKL_Divergence = 4.068282\n",
      "Epoch: 24\tFidelity = 0.500439\tKL_Divergence = 4.061431\n",
      "Epoch: 25\tFidelity = 0.500440\tKL_Divergence = 4.059860\n",
      "Epoch: 26\tFidelity = 0.500470\tKL_Divergence = 4.023008\n",
      "Epoch: 27\tFidelity = 0.500383\tKL_Divergence = 4.137828\n",
      "Epoch: 28\tFidelity = 0.500497\tKL_Divergence = 3.992408\n",
      "Epoch: 29\tFidelity = 0.500461\tKL_Divergence = 4.034005\n",
      "Epoch: 30\tFidelity = 0.500420\tKL_Divergence = 4.086027\n",
      "Epoch: 31\tFidelity = 0.500451\tKL_Divergence = 4.046249\n",
      "Epoch: 32\tFidelity = 0.500501\tKL_Divergence = 3.988572\n",
      "Epoch: 33\tFidelity = 0.500411\tKL_Divergence = 4.097383\n",
      "Epoch: 34\tFidelity = 0.500457\tKL_Divergence = 4.039077\n",
      "Epoch: 35\tFidelity = 0.500386\tKL_Divergence = 4.132322\n",
      "Epoch: 36\tFidelity = 0.500507\tKL_Divergence = 3.981954\n",
      "Epoch: 37\tFidelity = 0.500404\tKL_Divergence = 4.107280\n",
      "Epoch: 38\tFidelity = 0.500431\tKL_Divergence = 4.071151\n",
      "Epoch: 39\tFidelity = 0.500420\tKL_Divergence = 4.085863\n",
      "Epoch: 40\tFidelity = 0.500507\tKL_Divergence = 3.981353\n",
      "Epoch: 41\tFidelity = 0.500387\tKL_Divergence = 4.130866\n",
      "Epoch: 42\tFidelity = 0.500453\tKL_Divergence = 4.043652\n",
      "Epoch: 43\tFidelity = 0.500382\tKL_Divergence = 4.137885\n",
      "Epoch: 44\tFidelity = 0.500509\tKL_Divergence = 3.979650\n",
      "Epoch: 45\tFidelity = 0.500384\tKL_Divergence = 4.135623\n",
      "Epoch: 46\tFidelity = 0.500489\tKL_Divergence = 4.001495\n",
      "Epoch: 47\tFidelity = 0.500396\tKL_Divergence = 4.117993\n",
      "Epoch: 48\tFidelity = 0.500485\tKL_Divergence = 4.006513\n",
      "Epoch: 49\tFidelity = 0.500435\tKL_Divergence = 4.067102\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:57:56,275] Trial 488 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500428\tKL_Divergence = 4.075833\n",
      "Total time elapsed during training: 33.084 s\n",
      "Trial 488 pruned. \n",
      "Epoch: 1\tFidelity = 0.500394\tKL_Divergence = 4.121276\n",
      "Epoch: 2\tFidelity = 0.500433\tKL_Divergence = 4.068631\n",
      "Epoch: 3\tFidelity = 0.500397\tKL_Divergence = 4.116945\n",
      "Epoch: 4\tFidelity = 0.500433\tKL_Divergence = 4.069103\n",
      "Epoch: 5\tFidelity = 0.500365\tKL_Divergence = 4.164025\n",
      "Epoch: 6\tFidelity = 0.500477\tKL_Divergence = 4.015301\n",
      "Epoch: 7\tFidelity = 0.500399\tKL_Divergence = 4.114158\n",
      "Epoch: 8\tFidelity = 0.500518\tKL_Divergence = 3.969920\n",
      "Epoch: 9\tFidelity = 0.500434\tKL_Divergence = 4.067666\n",
      "Epoch: 10\tFidelity = 0.500387\tKL_Divergence = 4.130736\n",
      "Epoch: 11\tFidelity = 0.500473\tKL_Divergence = 4.020469\n",
      "Epoch: 12\tFidelity = 0.500365\tKL_Divergence = 4.163751\n",
      "Epoch: 13\tFidelity = 0.500491\tKL_Divergence = 3.999898\n",
      "Epoch: 14\tFidelity = 0.500368\tKL_Divergence = 4.158848\n",
      "Epoch: 15\tFidelity = 0.500323\tKL_Divergence = 4.231101\n",
      "Epoch: 16\tFidelity = 0.500395\tKL_Divergence = 4.119801\n",
      "Epoch: 17\tFidelity = 0.500506\tKL_Divergence = 3.982894\n",
      "Epoch: 18\tFidelity = 0.500385\tKL_Divergence = 4.134123\n",
      "Epoch: 19\tFidelity = 0.500469\tKL_Divergence = 4.025320\n",
      "Epoch: 20\tFidelity = 0.500387\tKL_Divergence = 4.132019\n",
      "Epoch: 21\tFidelity = 0.500386\tKL_Divergence = 4.132854\n",
      "Epoch: 22\tFidelity = 0.500397\tKL_Divergence = 4.117437\n",
      "Epoch: 23\tFidelity = 0.500401\tKL_Divergence = 4.111852\n",
      "Epoch: 24\tFidelity = 0.500507\tKL_Divergence = 3.981318\n",
      "Epoch: 25\tFidelity = 0.500452\tKL_Divergence = 4.044831\n",
      "Epoch: 26\tFidelity = 0.500438\tKL_Divergence = 4.062157\n",
      "Epoch: 27\tFidelity = 0.500365\tKL_Divergence = 4.163863\n",
      "Epoch: 28\tFidelity = 0.500389\tKL_Divergence = 4.129238\n",
      "Epoch: 29\tFidelity = 0.500410\tKL_Divergence = 4.099949\n",
      "Epoch: 30\tFidelity = 0.500378\tKL_Divergence = 4.145098\n",
      "Epoch: 31\tFidelity = 0.500436\tKL_Divergence = 4.065232\n",
      "Epoch: 32\tFidelity = 0.500399\tKL_Divergence = 4.114157\n",
      "Epoch: 33\tFidelity = 0.500332\tKL_Divergence = 4.216398\n",
      "Epoch: 34\tFidelity = 0.500495\tKL_Divergence = 3.995265\n",
      "Epoch: 35\tFidelity = 0.500428\tKL_Divergence = 4.075315\n",
      "Epoch: 36\tFidelity = 0.500378\tKL_Divergence = 4.144203\n",
      "Epoch: 37\tFidelity = 0.500455\tKL_Divergence = 4.041374\n",
      "Epoch: 38\tFidelity = 0.500357\tKL_Divergence = 4.176635\n",
      "Epoch: 39\tFidelity = 0.500431\tKL_Divergence = 4.071044\n",
      "Epoch: 40\tFidelity = 0.500463\tKL_Divergence = 4.031211\n",
      "Epoch: 41\tFidelity = 0.500508\tKL_Divergence = 3.979809\n",
      "Epoch: 42\tFidelity = 0.500548\tKL_Divergence = 3.937849\n",
      "Epoch: 43\tFidelity = 0.500504\tKL_Divergence = 3.984576\n",
      "Epoch: 44\tFidelity = 0.500478\tKL_Divergence = 4.013969\n",
      "Epoch: 45\tFidelity = 0.500541\tKL_Divergence = 3.944848\n",
      "Epoch: 46\tFidelity = 0.500409\tKL_Divergence = 4.100110\n",
      "Epoch: 47\tFidelity = 0.500413\tKL_Divergence = 4.094533\n",
      "Epoch: 48\tFidelity = 0.500447\tKL_Divergence = 4.051733\n",
      "Epoch: 49\tFidelity = 0.500341\tKL_Divergence = 4.200641\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 09:58:55,311] Trial 489 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500438\tKL_Divergence = 4.062537\n",
      "Total time elapsed during training: 58.864 s\n",
      "Trial 489 pruned. \n",
      "Epoch: 1\tFidelity = 0.500480\tKL_Divergence = 4.011293\n",
      "Epoch: 2\tFidelity = 0.500419\tKL_Divergence = 4.086503\n",
      "Epoch: 3\tFidelity = 0.500454\tKL_Divergence = 4.041988\n",
      "Epoch: 4\tFidelity = 0.500429\tKL_Divergence = 4.073687\n",
      "Epoch: 5\tFidelity = 0.500510\tKL_Divergence = 3.978448\n",
      "Epoch: 6\tFidelity = 0.500425\tKL_Divergence = 4.078749\n",
      "Epoch: 7\tFidelity = 0.500504\tKL_Divergence = 3.984644\n",
      "Epoch: 8\tFidelity = 0.500421\tKL_Divergence = 4.084846\n",
      "Epoch: 9\tFidelity = 0.500445\tKL_Divergence = 4.053446\n",
      "Epoch: 10\tFidelity = 0.500465\tKL_Divergence = 4.029042\n",
      "Epoch: 11\tFidelity = 0.500481\tKL_Divergence = 4.010785\n",
      "Epoch: 12\tFidelity = 0.500497\tKL_Divergence = 3.992807\n",
      "Epoch: 13\tFidelity = 0.500444\tKL_Divergence = 4.054828\n",
      "Epoch: 14\tFidelity = 0.500453\tKL_Divergence = 4.043419\n",
      "Epoch: 15\tFidelity = 0.500455\tKL_Divergence = 4.041242\n",
      "Epoch: 16\tFidelity = 0.500476\tKL_Divergence = 4.015934\n",
      "Epoch: 17\tFidelity = 0.500459\tKL_Divergence = 4.036882\n",
      "Epoch: 18\tFidelity = 0.500413\tKL_Divergence = 4.095603\n",
      "Epoch: 19\tFidelity = 0.500484\tKL_Divergence = 4.007434\n",
      "Epoch: 20\tFidelity = 0.500426\tKL_Divergence = 4.078384\n",
      "Epoch: 21\tFidelity = 0.500416\tKL_Divergence = 4.091083\n",
      "Epoch: 22\tFidelity = 0.500417\tKL_Divergence = 4.090071\n",
      "Epoch: 23\tFidelity = 0.500428\tKL_Divergence = 4.074933\n",
      "Epoch: 24\tFidelity = 0.500448\tKL_Divergence = 4.050044\n",
      "Epoch: 25\tFidelity = 0.500439\tKL_Divergence = 4.061452\n",
      "Epoch: 26\tFidelity = 0.500454\tKL_Divergence = 4.042895\n",
      "Epoch: 27\tFidelity = 0.500440\tKL_Divergence = 4.059670\n",
      "Epoch: 28\tFidelity = 0.500472\tKL_Divergence = 4.020818\n",
      "Epoch: 29\tFidelity = 0.500467\tKL_Divergence = 4.026490\n",
      "Epoch: 30\tFidelity = 0.500462\tKL_Divergence = 4.032676\n",
      "Epoch: 31\tFidelity = 0.500444\tKL_Divergence = 4.055014\n",
      "Epoch: 32\tFidelity = 0.500431\tKL_Divergence = 4.071445\n",
      "Epoch: 33\tFidelity = 0.500446\tKL_Divergence = 4.052478\n",
      "Epoch: 34\tFidelity = 0.500426\tKL_Divergence = 4.077400\n",
      "Epoch: 35\tFidelity = 0.500435\tKL_Divergence = 4.066370\n",
      "Epoch: 36\tFidelity = 0.500493\tKL_Divergence = 3.996949\n",
      "Epoch: 37\tFidelity = 0.500458\tKL_Divergence = 4.038063\n",
      "Epoch: 38\tFidelity = 0.500478\tKL_Divergence = 4.013606\n",
      "Epoch: 39\tFidelity = 0.500465\tKL_Divergence = 4.028781\n",
      "Epoch: 40\tFidelity = 0.500467\tKL_Divergence = 4.026914\n",
      "Epoch: 41\tFidelity = 0.500428\tKL_Divergence = 4.075025\n",
      "Epoch: 42\tFidelity = 0.500400\tKL_Divergence = 4.113503\n",
      "Epoch: 43\tFidelity = 0.500497\tKL_Divergence = 3.992470\n",
      "Epoch: 44\tFidelity = 0.500428\tKL_Divergence = 4.074978\n",
      "Epoch: 45\tFidelity = 0.500372\tKL_Divergence = 4.152641\n",
      "Epoch: 46\tFidelity = 0.500446\tKL_Divergence = 4.052418\n",
      "Epoch: 47\tFidelity = 0.500463\tKL_Divergence = 4.031322\n",
      "Epoch: 48\tFidelity = 0.500451\tKL_Divergence = 4.046137\n",
      "Epoch: 49\tFidelity = 0.500500\tKL_Divergence = 3.988586\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:00:17,810] Trial 490 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500429\tKL_Divergence = 4.074153\n",
      "Total time elapsed during training: 82.327 s\n",
      "Trial 490 pruned. \n",
      "Epoch: 1\tFidelity = 0.500499\tKL_Divergence = 3.989907\n",
      "Epoch: 2\tFidelity = 0.500442\tKL_Divergence = 4.057810\n",
      "Epoch: 3\tFidelity = 0.500431\tKL_Divergence = 4.071806\n",
      "Epoch: 4\tFidelity = 0.500473\tKL_Divergence = 4.020396\n",
      "Epoch: 5\tFidelity = 0.500445\tKL_Divergence = 4.054215\n",
      "Epoch: 6\tFidelity = 0.500441\tKL_Divergence = 4.059207\n",
      "Epoch: 7\tFidelity = 0.500438\tKL_Divergence = 4.063164\n",
      "Epoch: 8\tFidelity = 0.500448\tKL_Divergence = 4.049524\n",
      "Epoch: 9\tFidelity = 0.500447\tKL_Divergence = 4.051256\n",
      "Epoch: 10\tFidelity = 0.500457\tKL_Divergence = 4.039353\n",
      "Epoch: 11\tFidelity = 0.500476\tKL_Divergence = 4.016000\n",
      "Epoch: 12\tFidelity = 0.500444\tKL_Divergence = 4.055321\n",
      "Epoch: 13\tFidelity = 0.500521\tKL_Divergence = 3.966493\n",
      "Epoch: 14\tFidelity = 0.500475\tKL_Divergence = 4.017645\n",
      "Epoch: 15\tFidelity = 0.500484\tKL_Divergence = 4.007001\n",
      "Epoch: 16\tFidelity = 0.500484\tKL_Divergence = 4.007544\n",
      "Epoch: 17\tFidelity = 0.500491\tKL_Divergence = 3.999305\n",
      "Epoch: 18\tFidelity = 0.500470\tKL_Divergence = 4.023736\n",
      "Epoch: 19\tFidelity = 0.500484\tKL_Divergence = 4.006564\n",
      "Epoch: 20\tFidelity = 0.500428\tKL_Divergence = 4.075250\n",
      "Epoch: 21\tFidelity = 0.500459\tKL_Divergence = 4.036512\n",
      "Epoch: 22\tFidelity = 0.500479\tKL_Divergence = 4.012340\n",
      "Epoch: 23\tFidelity = 0.500448\tKL_Divergence = 4.049785\n",
      "Epoch: 24\tFidelity = 0.500440\tKL_Divergence = 4.060109\n",
      "Epoch: 25\tFidelity = 0.500478\tKL_Divergence = 4.014042\n",
      "Epoch: 26\tFidelity = 0.500445\tKL_Divergence = 4.053390\n",
      "Epoch: 27\tFidelity = 0.500477\tKL_Divergence = 4.015443\n",
      "Epoch: 28\tFidelity = 0.500445\tKL_Divergence = 4.054216\n",
      "Epoch: 29\tFidelity = 0.500480\tKL_Divergence = 4.012095\n",
      "Epoch: 30\tFidelity = 0.500465\tKL_Divergence = 4.029293\n",
      "Epoch: 31\tFidelity = 0.500494\tKL_Divergence = 3.995612\n",
      "Epoch: 32\tFidelity = 0.500474\tKL_Divergence = 4.019212\n",
      "Epoch: 33\tFidelity = 0.500427\tKL_Divergence = 4.076361\n",
      "Epoch: 34\tFidelity = 0.500455\tKL_Divergence = 4.041159\n",
      "Epoch: 35\tFidelity = 0.500481\tKL_Divergence = 4.010140\n",
      "Epoch: 36\tFidelity = 0.500461\tKL_Divergence = 4.034688\n",
      "Epoch: 37\tFidelity = 0.500452\tKL_Divergence = 4.044545\n",
      "Epoch: 38\tFidelity = 0.500455\tKL_Divergence = 4.040901\n",
      "Epoch: 39\tFidelity = 0.500465\tKL_Divergence = 4.029568\n",
      "Epoch: 40\tFidelity = 0.500431\tKL_Divergence = 4.071599\n",
      "Epoch: 41\tFidelity = 0.500446\tKL_Divergence = 4.052516\n",
      "Epoch: 42\tFidelity = 0.500472\tKL_Divergence = 4.021049\n",
      "Epoch: 43\tFidelity = 0.500474\tKL_Divergence = 4.018956\n",
      "Epoch: 44\tFidelity = 0.500465\tKL_Divergence = 4.029134\n",
      "Epoch: 45\tFidelity = 0.500452\tKL_Divergence = 4.044608\n",
      "Epoch: 46\tFidelity = 0.500443\tKL_Divergence = 4.056358\n",
      "Epoch: 47\tFidelity = 0.500479\tKL_Divergence = 4.012750\n",
      "Epoch: 48\tFidelity = 0.500436\tKL_Divergence = 4.064700\n",
      "Epoch: 49\tFidelity = 0.500438\tKL_Divergence = 4.061982\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:01:04,661] Trial 491 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500467\tKL_Divergence = 4.027162\n",
      "Total time elapsed during training: 46.669 s\n",
      "Trial 491 pruned. \n",
      "Epoch: 1\tFidelity = 0.500410\tKL_Divergence = 4.099241\n",
      "Epoch: 2\tFidelity = 0.500488\tKL_Divergence = 4.002824\n",
      "Epoch: 3\tFidelity = 0.500431\tKL_Divergence = 4.071315\n",
      "Epoch: 4\tFidelity = 0.500401\tKL_Divergence = 4.111272\n",
      "Epoch: 5\tFidelity = 0.500455\tKL_Divergence = 4.041265\n",
      "Epoch: 6\tFidelity = 0.500387\tKL_Divergence = 4.130797\n",
      "Epoch: 7\tFidelity = 0.500423\tKL_Divergence = 4.081853\n",
      "Epoch: 8\tFidelity = 0.500452\tKL_Divergence = 4.045414\n",
      "Epoch: 9\tFidelity = 0.500494\tKL_Divergence = 3.995575\n",
      "Epoch: 10\tFidelity = 0.500489\tKL_Divergence = 4.001117\n",
      "Epoch: 11\tFidelity = 0.500488\tKL_Divergence = 4.002615\n",
      "Epoch: 12\tFidelity = 0.500436\tKL_Divergence = 4.064996\n",
      "Epoch: 13\tFidelity = 0.500488\tKL_Divergence = 4.002312\n",
      "Epoch: 14\tFidelity = 0.500448\tKL_Divergence = 4.050411\n",
      "Epoch: 15\tFidelity = 0.500467\tKL_Divergence = 4.026620\n",
      "Epoch: 16\tFidelity = 0.500475\tKL_Divergence = 4.018051\n",
      "Epoch: 17\tFidelity = 0.500502\tKL_Divergence = 3.986606\n",
      "Epoch: 18\tFidelity = 0.500462\tKL_Divergence = 4.033271\n",
      "Epoch: 19\tFidelity = 0.500465\tKL_Divergence = 4.029682\n",
      "Epoch: 20\tFidelity = 0.500433\tKL_Divergence = 4.069270\n",
      "Epoch: 21\tFidelity = 0.500434\tKL_Divergence = 4.068013\n",
      "Epoch: 22\tFidelity = 0.500424\tKL_Divergence = 4.080066\n",
      "Epoch: 23\tFidelity = 0.500442\tKL_Divergence = 4.057136\n",
      "Epoch: 24\tFidelity = 0.500468\tKL_Divergence = 4.025444\n",
      "Epoch: 25\tFidelity = 0.500431\tKL_Divergence = 4.071421\n",
      "Epoch: 26\tFidelity = 0.500473\tKL_Divergence = 4.019362\n",
      "Epoch: 27\tFidelity = 0.500458\tKL_Divergence = 4.037598\n",
      "Epoch: 28\tFidelity = 0.500461\tKL_Divergence = 4.034381\n",
      "Epoch: 29\tFidelity = 0.500459\tKL_Divergence = 4.036507\n",
      "Epoch: 30\tFidelity = 0.500414\tKL_Divergence = 4.093239\n",
      "Epoch: 31\tFidelity = 0.500408\tKL_Divergence = 4.101766\n",
      "Epoch: 32\tFidelity = 0.500426\tKL_Divergence = 4.078407\n",
      "Epoch: 33\tFidelity = 0.500426\tKL_Divergence = 4.077731\n",
      "Epoch: 34\tFidelity = 0.500492\tKL_Divergence = 3.997907\n",
      "Epoch: 35\tFidelity = 0.500439\tKL_Divergence = 4.060979\n",
      "Epoch: 36\tFidelity = 0.500454\tKL_Divergence = 4.042885\n",
      "Epoch: 37\tFidelity = 0.500434\tKL_Divergence = 4.067748\n",
      "Epoch: 38\tFidelity = 0.500485\tKL_Divergence = 4.005767\n",
      "Epoch: 39\tFidelity = 0.500435\tKL_Divergence = 4.067001\n",
      "Epoch: 40\tFidelity = 0.500427\tKL_Divergence = 4.077304\n",
      "Epoch: 41\tFidelity = 0.500422\tKL_Divergence = 4.083040\n",
      "Epoch: 42\tFidelity = 0.500410\tKL_Divergence = 4.099560\n",
      "Epoch: 43\tFidelity = 0.500440\tKL_Divergence = 4.060362\n",
      "Epoch: 44\tFidelity = 0.500398\tKL_Divergence = 4.115124\n",
      "Epoch: 45\tFidelity = 0.500423\tKL_Divergence = 4.082277\n",
      "Epoch: 46\tFidelity = 0.500407\tKL_Divergence = 4.103583\n",
      "Epoch: 47\tFidelity = 0.500428\tKL_Divergence = 4.075274\n",
      "Epoch: 48\tFidelity = 0.500420\tKL_Divergence = 4.085868\n",
      "Epoch: 49\tFidelity = 0.500438\tKL_Divergence = 4.063003\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:01:44,025] Trial 492 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500425\tKL_Divergence = 4.078852\n",
      "Total time elapsed during training: 39.182 s\n",
      "Trial 492 pruned. \n",
      "Epoch: 1\tFidelity = 0.500411\tKL_Divergence = 4.097797\n",
      "Epoch: 2\tFidelity = 0.500555\tKL_Divergence = 3.931092\n",
      "Epoch: 3\tFidelity = 0.500407\tKL_Divergence = 4.103631\n",
      "Epoch: 4\tFidelity = 0.500481\tKL_Divergence = 4.010250\n",
      "Epoch: 5\tFidelity = 0.500502\tKL_Divergence = 3.987269\n",
      "Epoch: 6\tFidelity = 0.500508\tKL_Divergence = 3.979873\n",
      "Epoch: 7\tFidelity = 0.500467\tKL_Divergence = 4.026748\n",
      "Epoch: 8\tFidelity = 0.500419\tKL_Divergence = 4.087053\n",
      "Epoch: 9\tFidelity = 0.500469\tKL_Divergence = 4.024888\n",
      "Epoch: 10\tFidelity = 0.500472\tKL_Divergence = 4.020508\n",
      "Epoch: 11\tFidelity = 0.500431\tKL_Divergence = 4.070854\n",
      "Epoch: 12\tFidelity = 0.500438\tKL_Divergence = 4.062824\n",
      "Epoch: 13\tFidelity = 0.500494\tKL_Divergence = 3.995994\n",
      "Epoch: 14\tFidelity = 0.500533\tKL_Divergence = 3.953856\n",
      "Epoch: 15\tFidelity = 0.500470\tKL_Divergence = 4.022778\n",
      "Epoch: 16\tFidelity = 0.500418\tKL_Divergence = 4.088079\n",
      "Epoch: 17\tFidelity = 0.500397\tKL_Divergence = 4.117292\n",
      "Epoch: 18\tFidelity = 0.500418\tKL_Divergence = 4.089025\n",
      "Epoch: 19\tFidelity = 0.500426\tKL_Divergence = 4.077976\n",
      "Epoch: 20\tFidelity = 0.500465\tKL_Divergence = 4.029769\n",
      "Epoch: 21\tFidelity = 0.500430\tKL_Divergence = 4.072519\n",
      "Epoch: 22\tFidelity = 0.500425\tKL_Divergence = 4.079100\n",
      "Epoch: 23\tFidelity = 0.500446\tKL_Divergence = 4.052175\n",
      "Epoch: 24\tFidelity = 0.500525\tKL_Divergence = 3.962448\n",
      "Epoch: 25\tFidelity = 0.500468\tKL_Divergence = 4.025586\n",
      "Epoch: 26\tFidelity = 0.500403\tKL_Divergence = 4.108684\n",
      "Epoch: 27\tFidelity = 0.500512\tKL_Divergence = 3.976374\n",
      "Epoch: 28\tFidelity = 0.500476\tKL_Divergence = 4.016860\n",
      "Epoch: 29\tFidelity = 0.500423\tKL_Divergence = 4.081868\n",
      "Epoch: 30\tFidelity = 0.500445\tKL_Divergence = 4.054137\n",
      "Epoch: 31\tFidelity = 0.500481\tKL_Divergence = 4.010587\n",
      "Epoch: 32\tFidelity = 0.500398\tKL_Divergence = 4.115252\n",
      "Epoch: 33\tFidelity = 0.500474\tKL_Divergence = 4.018326\n",
      "Epoch: 34\tFidelity = 0.500467\tKL_Divergence = 4.027399\n",
      "Epoch: 35\tFidelity = 0.500452\tKL_Divergence = 4.044837\n",
      "Epoch: 36\tFidelity = 0.500488\tKL_Divergence = 4.002652\n",
      "Epoch: 37\tFidelity = 0.500459\tKL_Divergence = 4.035975\n",
      "Epoch: 38\tFidelity = 0.500444\tKL_Divergence = 4.054639\n",
      "Epoch: 39\tFidelity = 0.500399\tKL_Divergence = 4.114031\n",
      "Epoch: 40\tFidelity = 0.500473\tKL_Divergence = 4.020329\n",
      "Epoch: 41\tFidelity = 0.500405\tKL_Divergence = 4.105607\n",
      "Epoch: 42\tFidelity = 0.500477\tKL_Divergence = 4.015767\n",
      "Epoch: 43\tFidelity = 0.500463\tKL_Divergence = 4.031643\n",
      "Epoch: 44\tFidelity = 0.500411\tKL_Divergence = 4.098305\n",
      "Epoch: 45\tFidelity = 0.500445\tKL_Divergence = 4.054202\n",
      "Epoch: 46\tFidelity = 0.500429\tKL_Divergence = 4.073643\n",
      "Epoch: 47\tFidelity = 0.500463\tKL_Divergence = 4.031689\n",
      "Epoch: 48\tFidelity = 0.500425\tKL_Divergence = 4.079816\n",
      "Epoch: 49\tFidelity = 0.500470\tKL_Divergence = 4.023372\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:02:25,088] Trial 493 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500444\tKL_Divergence = 4.055082\n",
      "Total time elapsed during training: 40.898 s\n",
      "Trial 493 pruned. \n",
      "Epoch: 1\tFidelity = 0.500437\tKL_Divergence = 4.064012\n",
      "Epoch: 2\tFidelity = 0.500425\tKL_Divergence = 4.078925\n",
      "Epoch: 3\tFidelity = 0.500439\tKL_Divergence = 4.060684\n",
      "Epoch: 4\tFidelity = 0.500451\tKL_Divergence = 4.045746\n",
      "Epoch: 5\tFidelity = 0.500475\tKL_Divergence = 4.017147\n",
      "Epoch: 6\tFidelity = 0.500465\tKL_Divergence = 4.029083\n",
      "Epoch: 7\tFidelity = 0.500475\tKL_Divergence = 4.017771\n",
      "Epoch: 8\tFidelity = 0.500426\tKL_Divergence = 4.077948\n",
      "Epoch: 9\tFidelity = 0.500439\tKL_Divergence = 4.061654\n",
      "Epoch: 10\tFidelity = 0.500451\tKL_Divergence = 4.045761\n",
      "Epoch: 11\tFidelity = 0.500451\tKL_Divergence = 4.046652\n",
      "Epoch: 12\tFidelity = 0.500484\tKL_Divergence = 4.006755\n",
      "Epoch: 13\tFidelity = 0.500420\tKL_Divergence = 4.086246\n",
      "Epoch: 14\tFidelity = 0.500501\tKL_Divergence = 3.988465\n",
      "Epoch: 15\tFidelity = 0.500447\tKL_Divergence = 4.051350\n",
      "Epoch: 16\tFidelity = 0.500447\tKL_Divergence = 4.050944\n",
      "Epoch: 17\tFidelity = 0.500494\tKL_Divergence = 3.995298\n",
      "Epoch: 18\tFidelity = 0.500478\tKL_Divergence = 4.014309\n",
      "Epoch: 19\tFidelity = 0.500455\tKL_Divergence = 4.041273\n",
      "Epoch: 20\tFidelity = 0.500470\tKL_Divergence = 4.023548\n",
      "Epoch: 21\tFidelity = 0.500477\tKL_Divergence = 4.014781\n",
      "Epoch: 22\tFidelity = 0.500453\tKL_Divergence = 4.043783\n",
      "Epoch: 23\tFidelity = 0.500434\tKL_Divergence = 4.067086\n",
      "Epoch: 24\tFidelity = 0.500445\tKL_Divergence = 4.053599\n",
      "Epoch: 25\tFidelity = 0.500452\tKL_Divergence = 4.044768\n",
      "Epoch: 26\tFidelity = 0.500433\tKL_Divergence = 4.068855\n",
      "Epoch: 27\tFidelity = 0.500460\tKL_Divergence = 4.035069\n",
      "Epoch: 28\tFidelity = 0.500401\tKL_Divergence = 4.111853\n",
      "Epoch: 29\tFidelity = 0.500416\tKL_Divergence = 4.091504\n",
      "Epoch: 30\tFidelity = 0.500437\tKL_Divergence = 4.064182\n",
      "Epoch: 31\tFidelity = 0.500468\tKL_Divergence = 4.025919\n",
      "Epoch: 32\tFidelity = 0.500453\tKL_Divergence = 4.044278\n",
      "Epoch: 33\tFidelity = 0.500469\tKL_Divergence = 4.024168\n",
      "Epoch: 34\tFidelity = 0.500483\tKL_Divergence = 4.007913\n",
      "Epoch: 35\tFidelity = 0.500494\tKL_Divergence = 3.995808\n",
      "Epoch: 36\tFidelity = 0.500423\tKL_Divergence = 4.081537\n",
      "Epoch: 37\tFidelity = 0.500448\tKL_Divergence = 4.050153\n",
      "Epoch: 38\tFidelity = 0.500453\tKL_Divergence = 4.044143\n",
      "Epoch: 39\tFidelity = 0.500458\tKL_Divergence = 4.037595\n",
      "Epoch: 40\tFidelity = 0.500483\tKL_Divergence = 4.008036\n",
      "Epoch: 41\tFidelity = 0.500444\tKL_Divergence = 4.055284\n",
      "Epoch: 42\tFidelity = 0.500460\tKL_Divergence = 4.035210\n",
      "Epoch: 43\tFidelity = 0.500429\tKL_Divergence = 4.073881\n",
      "Epoch: 44\tFidelity = 0.500476\tKL_Divergence = 4.016563\n",
      "Epoch: 45\tFidelity = 0.500481\tKL_Divergence = 4.011160\n",
      "Epoch: 46\tFidelity = 0.500457\tKL_Divergence = 4.039013\n",
      "Epoch: 47\tFidelity = 0.500464\tKL_Divergence = 4.030492\n",
      "Epoch: 48\tFidelity = 0.500480\tKL_Divergence = 4.011596\n",
      "Epoch: 49\tFidelity = 0.500426\tKL_Divergence = 4.078239\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:03:48,683] Trial 494 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500437\tKL_Divergence = 4.063655\n",
      "Total time elapsed during training: 83.413 s\n",
      "Trial 494 pruned. \n",
      "Epoch: 1\tFidelity = 0.500517\tKL_Divergence = 3.970103\n",
      "Epoch: 2\tFidelity = 0.500484\tKL_Divergence = 4.007510\n",
      "Epoch: 3\tFidelity = 0.500522\tKL_Divergence = 3.965488\n",
      "Epoch: 4\tFidelity = 0.500461\tKL_Divergence = 4.034749\n",
      "Epoch: 5\tFidelity = 0.500505\tKL_Divergence = 3.984169\n",
      "Epoch: 6\tFidelity = 0.500451\tKL_Divergence = 4.045801\n",
      "Epoch: 7\tFidelity = 0.500430\tKL_Divergence = 4.072610\n",
      "Epoch: 8\tFidelity = 0.500449\tKL_Divergence = 4.048906\n",
      "Epoch: 9\tFidelity = 0.500466\tKL_Divergence = 4.028211\n",
      "Epoch: 10\tFidelity = 0.500411\tKL_Divergence = 4.098124\n",
      "Epoch: 11\tFidelity = 0.500464\tKL_Divergence = 4.030671\n",
      "Epoch: 12\tFidelity = 0.500492\tKL_Divergence = 3.997698\n",
      "Epoch: 13\tFidelity = 0.500394\tKL_Divergence = 4.121918\n",
      "Epoch: 14\tFidelity = 0.500452\tKL_Divergence = 4.044735\n",
      "Epoch: 15\tFidelity = 0.500458\tKL_Divergence = 4.037670\n",
      "Epoch: 16\tFidelity = 0.500485\tKL_Divergence = 4.006206\n",
      "Epoch: 17\tFidelity = 0.500470\tKL_Divergence = 4.024009\n",
      "Epoch: 18\tFidelity = 0.500491\tKL_Divergence = 3.998694\n",
      "Epoch: 19\tFidelity = 0.500467\tKL_Divergence = 4.027039\n",
      "Epoch: 20\tFidelity = 0.500466\tKL_Divergence = 4.028511\n",
      "Epoch: 21\tFidelity = 0.500536\tKL_Divergence = 3.950875\n",
      "Epoch: 22\tFidelity = 0.500463\tKL_Divergence = 4.031219\n",
      "Epoch: 23\tFidelity = 0.500468\tKL_Divergence = 4.026442\n",
      "Epoch: 24\tFidelity = 0.500487\tKL_Divergence = 4.004116\n",
      "Epoch: 25\tFidelity = 0.500454\tKL_Divergence = 4.043051\n",
      "Epoch: 26\tFidelity = 0.500434\tKL_Divergence = 4.067768\n",
      "Epoch: 27\tFidelity = 0.500424\tKL_Divergence = 4.080644\n",
      "Epoch: 28\tFidelity = 0.500421\tKL_Divergence = 4.084476\n",
      "Epoch: 29\tFidelity = 0.500446\tKL_Divergence = 4.052592\n",
      "Epoch: 30\tFidelity = 0.500457\tKL_Divergence = 4.038799\n",
      "Epoch: 31\tFidelity = 0.500416\tKL_Divergence = 4.090726\n",
      "Epoch: 32\tFidelity = 0.500487\tKL_Divergence = 4.003991\n",
      "Epoch: 33\tFidelity = 0.500487\tKL_Divergence = 4.004093\n",
      "Epoch: 34\tFidelity = 0.500488\tKL_Divergence = 4.002350\n",
      "Epoch: 35\tFidelity = 0.500448\tKL_Divergence = 4.050015\n",
      "Epoch: 36\tFidelity = 0.500429\tKL_Divergence = 4.073746\n",
      "Epoch: 37\tFidelity = 0.500449\tKL_Divergence = 4.048487\n",
      "Epoch: 38\tFidelity = 0.500506\tKL_Divergence = 3.982341\n",
      "Epoch: 39\tFidelity = 0.500487\tKL_Divergence = 4.003546\n",
      "Epoch: 40\tFidelity = 0.500499\tKL_Divergence = 3.990245\n",
      "Epoch: 41\tFidelity = 0.500479\tKL_Divergence = 4.012796\n",
      "Epoch: 42\tFidelity = 0.500463\tKL_Divergence = 4.031680\n",
      "Epoch: 43\tFidelity = 0.500450\tKL_Divergence = 4.047510\n",
      "Epoch: 44\tFidelity = 0.500427\tKL_Divergence = 4.077139\n",
      "Epoch: 45\tFidelity = 0.500433\tKL_Divergence = 4.068347\n",
      "Epoch: 46\tFidelity = 0.500428\tKL_Divergence = 4.075596\n",
      "Epoch: 47\tFidelity = 0.500458\tKL_Divergence = 4.038132\n",
      "Epoch: 48\tFidelity = 0.500487\tKL_Divergence = 4.003367\n",
      "Epoch: 49\tFidelity = 0.500464\tKL_Divergence = 4.030561\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:04:28,831] Trial 495 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500524\tKL_Divergence = 3.963092\n",
      "Total time elapsed during training: 39.965 s\n",
      "Trial 495 pruned. \n",
      "Epoch: 1\tFidelity = 0.500440\tKL_Divergence = 4.059530\n",
      "Epoch: 2\tFidelity = 0.500504\tKL_Divergence = 3.985138\n",
      "Epoch: 3\tFidelity = 0.500453\tKL_Divergence = 4.043442\n",
      "Epoch: 4\tFidelity = 0.500475\tKL_Divergence = 4.017459\n",
      "Epoch: 5\tFidelity = 0.500431\tKL_Divergence = 4.070838\n",
      "Epoch: 6\tFidelity = 0.500433\tKL_Divergence = 4.068647\n",
      "Epoch: 7\tFidelity = 0.500447\tKL_Divergence = 4.051454\n",
      "Epoch: 8\tFidelity = 0.500494\tKL_Divergence = 3.995656\n",
      "Epoch: 9\tFidelity = 0.500473\tKL_Divergence = 4.020403\n",
      "Epoch: 10\tFidelity = 0.500541\tKL_Divergence = 3.945102\n",
      "Epoch: 11\tFidelity = 0.500461\tKL_Divergence = 4.033771\n",
      "Epoch: 12\tFidelity = 0.500436\tKL_Divergence = 4.065616\n",
      "Epoch: 13\tFidelity = 0.500501\tKL_Divergence = 3.987739\n",
      "Epoch: 14\tFidelity = 0.500433\tKL_Divergence = 4.068514\n",
      "Epoch: 15\tFidelity = 0.500491\tKL_Divergence = 3.998874\n",
      "Epoch: 16\tFidelity = 0.500524\tKL_Divergence = 3.963594\n",
      "Epoch: 17\tFidelity = 0.500431\tKL_Divergence = 4.070866\n",
      "Epoch: 18\tFidelity = 0.500508\tKL_Divergence = 3.980726\n",
      "Epoch: 19\tFidelity = 0.500439\tKL_Divergence = 4.061510\n",
      "Epoch: 20\tFidelity = 0.500414\tKL_Divergence = 4.093122\n",
      "Epoch: 21\tFidelity = 0.500422\tKL_Divergence = 4.083319\n",
      "Epoch: 22\tFidelity = 0.500490\tKL_Divergence = 4.000485\n",
      "Epoch: 23\tFidelity = 0.500450\tKL_Divergence = 4.047758\n",
      "Epoch: 24\tFidelity = 0.500450\tKL_Divergence = 4.047528\n",
      "Epoch: 25\tFidelity = 0.500477\tKL_Divergence = 4.015737\n",
      "Epoch: 26\tFidelity = 0.500480\tKL_Divergence = 4.011227\n",
      "Epoch: 27\tFidelity = 0.500505\tKL_Divergence = 3.983613\n",
      "Epoch: 28\tFidelity = 0.500480\tKL_Divergence = 4.012044\n",
      "Epoch: 29\tFidelity = 0.500403\tKL_Divergence = 4.108245\n",
      "Epoch: 30\tFidelity = 0.500481\tKL_Divergence = 4.010615\n",
      "Epoch: 31\tFidelity = 0.500476\tKL_Divergence = 4.016481\n",
      "Epoch: 32\tFidelity = 0.500469\tKL_Divergence = 4.023928\n",
      "Epoch: 33\tFidelity = 0.500495\tKL_Divergence = 3.994216\n",
      "Epoch: 34\tFidelity = 0.500467\tKL_Divergence = 4.026977\n",
      "Epoch: 35\tFidelity = 0.500507\tKL_Divergence = 3.981571\n",
      "Epoch: 36\tFidelity = 0.500451\tKL_Divergence = 4.046026\n",
      "Epoch: 37\tFidelity = 0.500444\tKL_Divergence = 4.054283\n",
      "Epoch: 38\tFidelity = 0.500495\tKL_Divergence = 3.994563\n",
      "Epoch: 39\tFidelity = 0.500531\tKL_Divergence = 3.956093\n",
      "Epoch: 40\tFidelity = 0.500447\tKL_Divergence = 4.051594\n",
      "Epoch: 41\tFidelity = 0.500467\tKL_Divergence = 4.027022\n",
      "Epoch: 42\tFidelity = 0.500447\tKL_Divergence = 4.050760\n",
      "Epoch: 43\tFidelity = 0.500434\tKL_Divergence = 4.067940\n",
      "Epoch: 44\tFidelity = 0.500471\tKL_Divergence = 4.022331\n",
      "Epoch: 45\tFidelity = 0.500533\tKL_Divergence = 3.953814\n",
      "Epoch: 46\tFidelity = 0.500462\tKL_Divergence = 4.032519\n",
      "Epoch: 47\tFidelity = 0.500401\tKL_Divergence = 4.111588\n",
      "Epoch: 48\tFidelity = 0.500467\tKL_Divergence = 4.027286\n",
      "Epoch: 49\tFidelity = 0.500431\tKL_Divergence = 4.071559\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:05:14,429] Trial 496 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500499\tKL_Divergence = 3.989575\n",
      "Total time elapsed during training: 45.413 s\n",
      "Trial 496 pruned. \n",
      "Epoch: 1\tFidelity = 0.500514\tKL_Divergence = 3.974251\n",
      "Epoch: 2\tFidelity = 0.500465\tKL_Divergence = 4.029426\n",
      "Epoch: 3\tFidelity = 0.500475\tKL_Divergence = 4.017262\n",
      "Epoch: 4\tFidelity = 0.500471\tKL_Divergence = 4.022553\n",
      "Epoch: 5\tFidelity = 0.500460\tKL_Divergence = 4.034992\n",
      "Epoch: 6\tFidelity = 0.500430\tKL_Divergence = 4.073209\n",
      "Epoch: 7\tFidelity = 0.500500\tKL_Divergence = 3.989445\n",
      "Epoch: 8\tFidelity = 0.500435\tKL_Divergence = 4.066313\n",
      "Epoch: 9\tFidelity = 0.500476\tKL_Divergence = 4.016224\n",
      "Epoch: 10\tFidelity = 0.500470\tKL_Divergence = 4.022896\n",
      "Epoch: 11\tFidelity = 0.500454\tKL_Divergence = 4.042466\n",
      "Epoch: 12\tFidelity = 0.500430\tKL_Divergence = 4.072514\n",
      "Epoch: 13\tFidelity = 0.500449\tKL_Divergence = 4.048763\n",
      "Epoch: 14\tFidelity = 0.500423\tKL_Divergence = 4.081444\n",
      "Epoch: 15\tFidelity = 0.500485\tKL_Divergence = 4.006107\n",
      "Epoch: 16\tFidelity = 0.500444\tKL_Divergence = 4.054985\n",
      "Epoch: 17\tFidelity = 0.500432\tKL_Divergence = 4.069992\n",
      "Epoch: 18\tFidelity = 0.500451\tKL_Divergence = 4.046860\n",
      "Epoch: 19\tFidelity = 0.500448\tKL_Divergence = 4.050203\n",
      "Epoch: 20\tFidelity = 0.500520\tKL_Divergence = 3.967664\n",
      "Epoch: 21\tFidelity = 0.500427\tKL_Divergence = 4.076971\n",
      "Epoch: 22\tFidelity = 0.500447\tKL_Divergence = 4.051603\n",
      "Epoch: 23\tFidelity = 0.500498\tKL_Divergence = 3.991782\n",
      "Epoch: 24\tFidelity = 0.500463\tKL_Divergence = 4.032198\n",
      "Epoch: 25\tFidelity = 0.500482\tKL_Divergence = 4.009252\n",
      "Epoch: 26\tFidelity = 0.500534\tKL_Divergence = 3.952619\n",
      "Epoch: 27\tFidelity = 0.500401\tKL_Divergence = 4.110923\n",
      "Epoch: 28\tFidelity = 0.500475\tKL_Divergence = 4.018149\n",
      "Epoch: 29\tFidelity = 0.500418\tKL_Divergence = 4.088728\n",
      "Epoch: 30\tFidelity = 0.500476\tKL_Divergence = 4.016226\n",
      "Epoch: 31\tFidelity = 0.500466\tKL_Divergence = 4.027639\n",
      "Epoch: 32\tFidelity = 0.500441\tKL_Divergence = 4.058898\n",
      "Epoch: 33\tFidelity = 0.500418\tKL_Divergence = 4.089214\n",
      "Epoch: 34\tFidelity = 0.500434\tKL_Divergence = 4.067743\n",
      "Epoch: 35\tFidelity = 0.500427\tKL_Divergence = 4.077139\n",
      "Epoch: 36\tFidelity = 0.500471\tKL_Divergence = 4.022087\n",
      "Epoch: 37\tFidelity = 0.500437\tKL_Divergence = 4.064109\n",
      "Epoch: 38\tFidelity = 0.500438\tKL_Divergence = 4.062622\n",
      "Epoch: 39\tFidelity = 0.500417\tKL_Divergence = 4.089777\n",
      "Epoch: 40\tFidelity = 0.500447\tKL_Divergence = 4.051605\n",
      "Epoch: 41\tFidelity = 0.500459\tKL_Divergence = 4.036701\n",
      "Epoch: 42\tFidelity = 0.500462\tKL_Divergence = 4.032572\n",
      "Epoch: 43\tFidelity = 0.500419\tKL_Divergence = 4.087865\n",
      "Epoch: 44\tFidelity = 0.500468\tKL_Divergence = 4.025682\n",
      "Epoch: 45\tFidelity = 0.500464\tKL_Divergence = 4.030339\n",
      "Epoch: 46\tFidelity = 0.500433\tKL_Divergence = 4.069611\n",
      "Epoch: 47\tFidelity = 0.500427\tKL_Divergence = 4.076367\n",
      "Epoch: 48\tFidelity = 0.500428\tKL_Divergence = 4.075183\n",
      "Epoch: 49\tFidelity = 0.500482\tKL_Divergence = 4.009657\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:05:53,914] Trial 497 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500438\tKL_Divergence = 4.062657\n",
      "Total time elapsed during training: 39.233 s\n",
      "Trial 497 pruned. \n",
      "Epoch: 1\tFidelity = 0.500433\tKL_Divergence = 4.068517\n",
      "Epoch: 2\tFidelity = 0.500444\tKL_Divergence = 4.054959\n",
      "Epoch: 3\tFidelity = 0.500484\tKL_Divergence = 4.007191\n",
      "Epoch: 4\tFidelity = 0.500456\tKL_Divergence = 4.040734\n",
      "Epoch: 5\tFidelity = 0.500469\tKL_Divergence = 4.024333\n",
      "Epoch: 6\tFidelity = 0.500446\tKL_Divergence = 4.052703\n",
      "Epoch: 7\tFidelity = 0.500458\tKL_Divergence = 4.037446\n",
      "Epoch: 8\tFidelity = 0.500451\tKL_Divergence = 4.045756\n",
      "Epoch: 9\tFidelity = 0.500479\tKL_Divergence = 4.012482\n",
      "Epoch: 10\tFidelity = 0.500439\tKL_Divergence = 4.061811\n",
      "Epoch: 11\tFidelity = 0.500434\tKL_Divergence = 4.067217\n",
      "Epoch: 12\tFidelity = 0.500465\tKL_Divergence = 4.028961\n",
      "Epoch: 13\tFidelity = 0.500448\tKL_Divergence = 4.049862\n",
      "Epoch: 14\tFidelity = 0.500421\tKL_Divergence = 4.084266\n",
      "Epoch: 15\tFidelity = 0.500484\tKL_Divergence = 4.007598\n",
      "Epoch: 16\tFidelity = 0.500454\tKL_Divergence = 4.043019\n",
      "Epoch: 17\tFidelity = 0.500443\tKL_Divergence = 4.055783\n",
      "Epoch: 18\tFidelity = 0.500445\tKL_Divergence = 4.053963\n",
      "Epoch: 19\tFidelity = 0.500440\tKL_Divergence = 4.059649\n",
      "Epoch: 20\tFidelity = 0.500466\tKL_Divergence = 4.027649\n",
      "Epoch: 21\tFidelity = 0.500446\tKL_Divergence = 4.052997\n",
      "Epoch: 22\tFidelity = 0.500450\tKL_Divergence = 4.047018\n",
      "Epoch: 23\tFidelity = 0.500432\tKL_Divergence = 4.070447\n",
      "Epoch: 24\tFidelity = 0.500441\tKL_Divergence = 4.058203\n",
      "Epoch: 25\tFidelity = 0.500429\tKL_Divergence = 4.074025\n",
      "Epoch: 26\tFidelity = 0.500433\tKL_Divergence = 4.069232\n",
      "Epoch: 27\tFidelity = 0.500472\tKL_Divergence = 4.020539\n",
      "Epoch: 28\tFidelity = 0.500461\tKL_Divergence = 4.034056\n",
      "Epoch: 29\tFidelity = 0.500452\tKL_Divergence = 4.044517\n",
      "Epoch: 30\tFidelity = 0.500461\tKL_Divergence = 4.034455\n",
      "Epoch: 31\tFidelity = 0.500442\tKL_Divergence = 4.057040\n",
      "Epoch: 32\tFidelity = 0.500446\tKL_Divergence = 4.052805\n",
      "Epoch: 33\tFidelity = 0.500442\tKL_Divergence = 4.057009\n",
      "Epoch: 34\tFidelity = 0.500469\tKL_Divergence = 4.024801\n",
      "Epoch: 35\tFidelity = 0.500422\tKL_Divergence = 4.083021\n",
      "Epoch: 36\tFidelity = 0.500443\tKL_Divergence = 4.056151\n",
      "Epoch: 37\tFidelity = 0.500428\tKL_Divergence = 4.074991\n",
      "Epoch: 38\tFidelity = 0.500436\tKL_Divergence = 4.065576\n",
      "Epoch: 39\tFidelity = 0.500430\tKL_Divergence = 4.072575\n",
      "Epoch: 40\tFidelity = 0.500447\tKL_Divergence = 4.051239\n",
      "Epoch: 41\tFidelity = 0.500460\tKL_Divergence = 4.035888\n",
      "Epoch: 42\tFidelity = 0.500451\tKL_Divergence = 4.046032\n",
      "Epoch: 43\tFidelity = 0.500452\tKL_Divergence = 4.045431\n",
      "Epoch: 44\tFidelity = 0.500449\tKL_Divergence = 4.048362\n",
      "Epoch: 45\tFidelity = 0.500482\tKL_Divergence = 4.009775\n",
      "Epoch: 46\tFidelity = 0.500459\tKL_Divergence = 4.036221\n",
      "Epoch: 47\tFidelity = 0.500477\tKL_Divergence = 4.014978\n",
      "Epoch: 48\tFidelity = 0.500483\tKL_Divergence = 4.008224\n",
      "Epoch: 49\tFidelity = 0.500472\tKL_Divergence = 4.020518\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:06:26,870] Trial 498 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500439\tKL_Divergence = 4.061815\n",
      "Total time elapsed during training: 32.776 s\n",
      "Trial 498 pruned. \n",
      "Epoch: 1\tFidelity = 0.500416\tKL_Divergence = 4.090984\n",
      "Epoch: 2\tFidelity = 0.500455\tKL_Divergence = 4.041306\n",
      "Epoch: 3\tFidelity = 0.500469\tKL_Divergence = 4.025203\n",
      "Epoch: 4\tFidelity = 0.500425\tKL_Divergence = 4.079380\n",
      "Epoch: 5\tFidelity = 0.500428\tKL_Divergence = 4.075108\n",
      "Epoch: 6\tFidelity = 0.500451\tKL_Divergence = 4.046218\n",
      "Epoch: 7\tFidelity = 0.500434\tKL_Divergence = 4.067332\n",
      "Epoch: 8\tFidelity = 0.500410\tKL_Divergence = 4.098954\n",
      "Epoch: 9\tFidelity = 0.500486\tKL_Divergence = 4.005156\n",
      "Epoch: 10\tFidelity = 0.500424\tKL_Divergence = 4.080192\n",
      "Epoch: 11\tFidelity = 0.500429\tKL_Divergence = 4.073588\n",
      "Epoch: 12\tFidelity = 0.500454\tKL_Divergence = 4.042631\n",
      "Epoch: 13\tFidelity = 0.500541\tKL_Divergence = 3.945720\n",
      "Epoch: 14\tFidelity = 0.500498\tKL_Divergence = 3.990828\n",
      "Epoch: 15\tFidelity = 0.500504\tKL_Divergence = 3.984786\n",
      "Epoch: 16\tFidelity = 0.500584\tKL_Divergence = 3.903274\n",
      "Epoch: 17\tFidelity = 0.500510\tKL_Divergence = 3.978173\n",
      "Epoch: 18\tFidelity = 0.500450\tKL_Divergence = 4.047455\n",
      "Epoch: 19\tFidelity = 0.500428\tKL_Divergence = 4.074803\n",
      "Epoch: 20\tFidelity = 0.500503\tKL_Divergence = 3.986024\n",
      "Epoch: 21\tFidelity = 0.500505\tKL_Divergence = 3.984167\n",
      "Epoch: 22\tFidelity = 0.500489\tKL_Divergence = 4.001083\n",
      "Epoch: 23\tFidelity = 0.500477\tKL_Divergence = 4.015794\n",
      "Epoch: 24\tFidelity = 0.500464\tKL_Divergence = 4.030466\n",
      "Epoch: 25\tFidelity = 0.500494\tKL_Divergence = 3.995646\n",
      "Epoch: 26\tFidelity = 0.500387\tKL_Divergence = 4.131554\n",
      "Epoch: 27\tFidelity = 0.500459\tKL_Divergence = 4.036201\n",
      "Epoch: 28\tFidelity = 0.500431\tKL_Divergence = 4.071863\n",
      "Epoch: 29\tFidelity = 0.500456\tKL_Divergence = 4.039913\n",
      "Epoch: 30\tFidelity = 0.500475\tKL_Divergence = 4.017308\n",
      "Epoch: 31\tFidelity = 0.500439\tKL_Divergence = 4.061898\n",
      "Epoch: 32\tFidelity = 0.500406\tKL_Divergence = 4.105276\n",
      "Epoch: 33\tFidelity = 0.500466\tKL_Divergence = 4.028530\n",
      "Epoch: 34\tFidelity = 0.500491\tKL_Divergence = 3.998945\n",
      "Epoch: 35\tFidelity = 0.500460\tKL_Divergence = 4.035367\n",
      "Epoch: 36\tFidelity = 0.500473\tKL_Divergence = 4.019529\n",
      "Epoch: 37\tFidelity = 0.500419\tKL_Divergence = 4.087812\n",
      "Epoch: 38\tFidelity = 0.500438\tKL_Divergence = 4.063043\n",
      "Epoch: 39\tFidelity = 0.500455\tKL_Divergence = 4.041418\n",
      "Epoch: 40\tFidelity = 0.500505\tKL_Divergence = 3.984167\n",
      "Epoch: 41\tFidelity = 0.500420\tKL_Divergence = 4.085708\n",
      "Epoch: 42\tFidelity = 0.500495\tKL_Divergence = 3.994553\n",
      "Epoch: 43\tFidelity = 0.500501\tKL_Divergence = 3.987996\n",
      "Epoch: 44\tFidelity = 0.500443\tKL_Divergence = 4.056399\n",
      "Epoch: 45\tFidelity = 0.500458\tKL_Divergence = 4.038275\n",
      "Epoch: 46\tFidelity = 0.500449\tKL_Divergence = 4.048374\n",
      "Epoch: 47\tFidelity = 0.500438\tKL_Divergence = 4.062532\n",
      "Epoch: 48\tFidelity = 0.500428\tKL_Divergence = 4.075917\n",
      "Epoch: 49\tFidelity = 0.500433\tKL_Divergence = 4.069512\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:07:13,296] Trial 499 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500443\tKL_Divergence = 4.056662\n",
      "Total time elapsed during training: 46.233 s\n",
      "Trial 499 pruned. \n",
      "Epoch: 1\tFidelity = 0.500379\tKL_Divergence = 4.142694\n",
      "Epoch: 2\tFidelity = 0.500478\tKL_Divergence = 4.014634\n",
      "Epoch: 3\tFidelity = 0.500429\tKL_Divergence = 4.074621\n",
      "Epoch: 4\tFidelity = 0.500447\tKL_Divergence = 4.051883\n",
      "Epoch: 5\tFidelity = 0.500437\tKL_Divergence = 4.064374\n",
      "Epoch: 6\tFidelity = 0.500460\tKL_Divergence = 4.035961\n",
      "Epoch: 7\tFidelity = 0.500470\tKL_Divergence = 4.023040\n",
      "Epoch: 8\tFidelity = 0.500478\tKL_Divergence = 4.014438\n",
      "Epoch: 9\tFidelity = 0.500374\tKL_Divergence = 4.150253\n",
      "Epoch: 10\tFidelity = 0.500471\tKL_Divergence = 4.022516\n",
      "Epoch: 11\tFidelity = 0.500435\tKL_Divergence = 4.066514\n",
      "Epoch: 12\tFidelity = 0.500455\tKL_Divergence = 4.041001\n",
      "Epoch: 13\tFidelity = 0.500421\tKL_Divergence = 4.085262\n",
      "Epoch: 14\tFidelity = 0.500380\tKL_Divergence = 4.140928\n",
      "Epoch: 15\tFidelity = 0.500482\tKL_Divergence = 4.009290\n",
      "Epoch: 16\tFidelity = 0.500425\tKL_Divergence = 4.078894\n",
      "Epoch: 17\tFidelity = 0.500470\tKL_Divergence = 4.023240\n",
      "Epoch: 18\tFidelity = 0.500460\tKL_Divergence = 4.036029\n",
      "Epoch: 19\tFidelity = 0.500480\tKL_Divergence = 4.012322\n",
      "Epoch: 20\tFidelity = 0.500467\tKL_Divergence = 4.026576\n",
      "Epoch: 21\tFidelity = 0.500408\tKL_Divergence = 4.102730\n",
      "Epoch: 22\tFidelity = 0.500451\tKL_Divergence = 4.046910\n",
      "Epoch: 23\tFidelity = 0.500428\tKL_Divergence = 4.075342\n",
      "Epoch: 24\tFidelity = 0.500475\tKL_Divergence = 4.017862\n",
      "Epoch: 25\tFidelity = 0.500426\tKL_Divergence = 4.077694\n",
      "Epoch: 26\tFidelity = 0.500515\tKL_Divergence = 3.972517\n",
      "Epoch: 27\tFidelity = 0.500497\tKL_Divergence = 3.993105\n",
      "Epoch: 28\tFidelity = 0.500455\tKL_Divergence = 4.041417\n",
      "Epoch: 29\tFidelity = 0.500461\tKL_Divergence = 4.034339\n",
      "Epoch: 30\tFidelity = 0.500461\tKL_Divergence = 4.034555\n",
      "Epoch: 31\tFidelity = 0.500441\tKL_Divergence = 4.058482\n",
      "Epoch: 32\tFidelity = 0.500430\tKL_Divergence = 4.072914\n",
      "Epoch: 33\tFidelity = 0.500391\tKL_Divergence = 4.126363\n",
      "Epoch: 34\tFidelity = 0.500459\tKL_Divergence = 4.036911\n",
      "Epoch: 35\tFidelity = 0.500442\tKL_Divergence = 4.058115\n",
      "Epoch: 36\tFidelity = 0.500465\tKL_Divergence = 4.029774\n",
      "Epoch: 37\tFidelity = 0.500390\tKL_Divergence = 4.127646\n",
      "Epoch: 38\tFidelity = 0.500447\tKL_Divergence = 4.051916\n",
      "Epoch: 39\tFidelity = 0.500473\tKL_Divergence = 4.020280\n",
      "Epoch: 40\tFidelity = 0.500461\tKL_Divergence = 4.034173\n",
      "Epoch: 41\tFidelity = 0.500442\tKL_Divergence = 4.057889\n",
      "Epoch: 42\tFidelity = 0.500455\tKL_Divergence = 4.041122\n",
      "Epoch: 43\tFidelity = 0.500387\tKL_Divergence = 4.131827\n",
      "Epoch: 44\tFidelity = 0.500472\tKL_Divergence = 4.020785\n",
      "Epoch: 45\tFidelity = 0.500446\tKL_Divergence = 4.052100\n",
      "Epoch: 46\tFidelity = 0.500410\tKL_Divergence = 4.099832\n",
      "Epoch: 47\tFidelity = 0.500494\tKL_Divergence = 3.995667\n",
      "Epoch: 48\tFidelity = 0.500415\tKL_Divergence = 4.092027\n",
      "Epoch: 49\tFidelity = 0.500504\tKL_Divergence = 3.984317\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:07:46,105] Trial 500 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500431\tKL_Divergence = 4.071865\n",
      "Total time elapsed during training: 32.629 s\n",
      "Trial 500 pruned. \n",
      "Epoch: 1\tFidelity = 0.500448\tKL_Divergence = 4.050342\n",
      "Epoch: 2\tFidelity = 0.500430\tKL_Divergence = 4.073129\n",
      "Epoch: 3\tFidelity = 0.500447\tKL_Divergence = 4.051913\n",
      "Epoch: 4\tFidelity = 0.500458\tKL_Divergence = 4.037912\n",
      "Epoch: 5\tFidelity = 0.500451\tKL_Divergence = 4.046349\n",
      "Epoch: 6\tFidelity = 0.500411\tKL_Divergence = 4.098073\n",
      "Epoch: 7\tFidelity = 0.500456\tKL_Divergence = 4.040381\n",
      "Epoch: 8\tFidelity = 0.500450\tKL_Divergence = 4.047827\n",
      "Epoch: 9\tFidelity = 0.500438\tKL_Divergence = 4.062635\n",
      "Epoch: 10\tFidelity = 0.500449\tKL_Divergence = 4.048812\n",
      "Epoch: 11\tFidelity = 0.500433\tKL_Divergence = 4.068831\n",
      "Epoch: 12\tFidelity = 0.500415\tKL_Divergence = 4.092906\n",
      "Epoch: 13\tFidelity = 0.500444\tKL_Divergence = 4.055174\n",
      "Epoch: 14\tFidelity = 0.500461\tKL_Divergence = 4.034637\n",
      "Epoch: 15\tFidelity = 0.500477\tKL_Divergence = 4.015218\n",
      "Epoch: 16\tFidelity = 0.500434\tKL_Divergence = 4.068080\n",
      "Epoch: 17\tFidelity = 0.500446\tKL_Divergence = 4.052474\n",
      "Epoch: 18\tFidelity = 0.500436\tKL_Divergence = 4.065213\n",
      "Epoch: 19\tFidelity = 0.500485\tKL_Divergence = 4.006686\n",
      "Epoch: 20\tFidelity = 0.500449\tKL_Divergence = 4.048415\n",
      "Epoch: 21\tFidelity = 0.500399\tKL_Divergence = 4.114136\n",
      "Epoch: 22\tFidelity = 0.500413\tKL_Divergence = 4.095351\n",
      "Epoch: 23\tFidelity = 0.500426\tKL_Divergence = 4.078688\n",
      "Epoch: 24\tFidelity = 0.500489\tKL_Divergence = 4.001749\n",
      "Epoch: 25\tFidelity = 0.500451\tKL_Divergence = 4.046879\n",
      "Epoch: 26\tFidelity = 0.500465\tKL_Divergence = 4.029705\n",
      "Epoch: 27\tFidelity = 0.500420\tKL_Divergence = 4.085341\n",
      "Epoch: 28\tFidelity = 0.500449\tKL_Divergence = 4.048959\n",
      "Epoch: 29\tFidelity = 0.500447\tKL_Divergence = 4.050822\n",
      "Epoch: 30\tFidelity = 0.500442\tKL_Divergence = 4.057526\n",
      "Epoch: 31\tFidelity = 0.500439\tKL_Divergence = 4.061477\n",
      "Epoch: 32\tFidelity = 0.500452\tKL_Divergence = 4.045788\n",
      "Epoch: 33\tFidelity = 0.500454\tKL_Divergence = 4.043279\n",
      "Epoch: 34\tFidelity = 0.500485\tKL_Divergence = 4.006491\n",
      "Epoch: 35\tFidelity = 0.500486\tKL_Divergence = 4.005285\n",
      "Epoch: 36\tFidelity = 0.500477\tKL_Divergence = 4.014887\n",
      "Epoch: 37\tFidelity = 0.500453\tKL_Divergence = 4.044455\n",
      "Epoch: 38\tFidelity = 0.500454\tKL_Divergence = 4.042687\n",
      "Epoch: 39\tFidelity = 0.500427\tKL_Divergence = 4.077017\n",
      "Epoch: 40\tFidelity = 0.500479\tKL_Divergence = 4.012695\n",
      "Epoch: 41\tFidelity = 0.500416\tKL_Divergence = 4.091096\n",
      "Epoch: 42\tFidelity = 0.500440\tKL_Divergence = 4.059744\n",
      "Epoch: 43\tFidelity = 0.500442\tKL_Divergence = 4.058049\n",
      "Epoch: 44\tFidelity = 0.500449\tKL_Divergence = 4.048698\n",
      "Epoch: 45\tFidelity = 0.500418\tKL_Divergence = 4.088942\n",
      "Epoch: 46\tFidelity = 0.500427\tKL_Divergence = 4.077040\n",
      "Epoch: 47\tFidelity = 0.500422\tKL_Divergence = 4.083635\n",
      "Epoch: 48\tFidelity = 0.500420\tKL_Divergence = 4.086343\n",
      "Epoch: 49\tFidelity = 0.500461\tKL_Divergence = 4.033895\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:09:11,188] Trial 501 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500499\tKL_Divergence = 3.990756\n",
      "Total time elapsed during training: 84.900 s\n",
      "Trial 501 pruned. \n",
      "Epoch: 1\tFidelity = 0.500526\tKL_Divergence = 3.960859\n",
      "Epoch: 2\tFidelity = 0.500560\tKL_Divergence = 3.925919\n",
      "Epoch: 3\tFidelity = 0.500359\tKL_Divergence = 4.173323\n",
      "Epoch: 4\tFidelity = 0.500534\tKL_Divergence = 3.952170\n",
      "Epoch: 5\tFidelity = 0.500515\tKL_Divergence = 3.973308\n",
      "Epoch: 6\tFidelity = 0.500525\tKL_Divergence = 3.962249\n",
      "Epoch: 7\tFidelity = 0.500472\tKL_Divergence = 4.020735\n",
      "Epoch: 8\tFidelity = 0.500364\tKL_Divergence = 4.166062\n",
      "Epoch: 9\tFidelity = 0.500449\tKL_Divergence = 4.048916\n",
      "Epoch: 10\tFidelity = 0.500354\tKL_Divergence = 4.181058\n",
      "Epoch: 11\tFidelity = 0.500449\tKL_Divergence = 4.048643\n",
      "Epoch: 12\tFidelity = 0.500407\tKL_Divergence = 4.103399\n",
      "Epoch: 13\tFidelity = 0.500392\tKL_Divergence = 4.123787\n",
      "Epoch: 14\tFidelity = 0.500501\tKL_Divergence = 3.988711\n",
      "Epoch: 15\tFidelity = 0.500419\tKL_Divergence = 4.087162\n",
      "Epoch: 16\tFidelity = 0.500446\tKL_Divergence = 4.052108\n",
      "Epoch: 17\tFidelity = 0.500376\tKL_Divergence = 4.147483\n",
      "Epoch: 18\tFidelity = 0.500551\tKL_Divergence = 3.935169\n",
      "Epoch: 19\tFidelity = 0.500495\tKL_Divergence = 3.995091\n",
      "Epoch: 20\tFidelity = 0.500468\tKL_Divergence = 4.025496\n",
      "Epoch: 21\tFidelity = 0.500474\tKL_Divergence = 4.018955\n",
      "Epoch: 22\tFidelity = 0.500486\tKL_Divergence = 4.005138\n",
      "Epoch: 23\tFidelity = 0.500510\tKL_Divergence = 3.978560\n",
      "Epoch: 24\tFidelity = 0.500409\tKL_Divergence = 4.101098\n",
      "Epoch: 25\tFidelity = 0.500480\tKL_Divergence = 4.011604\n",
      "Epoch: 26\tFidelity = 0.500542\tKL_Divergence = 3.944250\n",
      "Epoch: 27\tFidelity = 0.500440\tKL_Divergence = 4.059344\n",
      "Epoch: 28\tFidelity = 0.500393\tKL_Divergence = 4.122491\n",
      "Epoch: 29\tFidelity = 0.500396\tKL_Divergence = 4.118691\n",
      "Epoch: 30\tFidelity = 0.500426\tKL_Divergence = 4.078203\n",
      "Epoch: 31\tFidelity = 0.500384\tKL_Divergence = 4.135868\n",
      "Epoch: 32\tFidelity = 0.500439\tKL_Divergence = 4.060980\n",
      "Epoch: 33\tFidelity = 0.500421\tKL_Divergence = 4.084597\n",
      "Epoch: 34\tFidelity = 0.500457\tKL_Divergence = 4.038987\n",
      "Epoch: 35\tFidelity = 0.500507\tKL_Divergence = 3.981650\n",
      "Epoch: 36\tFidelity = 0.500400\tKL_Divergence = 4.113022\n",
      "Epoch: 37\tFidelity = 0.500534\tKL_Divergence = 3.952597\n",
      "Epoch: 38\tFidelity = 0.500481\tKL_Divergence = 4.011198\n",
      "Epoch: 39\tFidelity = 0.500343\tKL_Divergence = 4.198079\n",
      "Epoch: 40\tFidelity = 0.500401\tKL_Divergence = 4.111146\n",
      "Epoch: 41\tFidelity = 0.500411\tKL_Divergence = 4.097510\n",
      "Epoch: 42\tFidelity = 0.500453\tKL_Divergence = 4.043900\n",
      "Epoch: 43\tFidelity = 0.500448\tKL_Divergence = 4.050193\n",
      "Epoch: 44\tFidelity = 0.500485\tKL_Divergence = 4.006373\n",
      "Epoch: 45\tFidelity = 0.500494\tKL_Divergence = 3.996493\n",
      "Epoch: 46\tFidelity = 0.500499\tKL_Divergence = 3.990899\n",
      "Epoch: 47\tFidelity = 0.500354\tKL_Divergence = 4.180179\n",
      "Epoch: 48\tFidelity = 0.500412\tKL_Divergence = 4.096743\n",
      "Epoch: 49\tFidelity = 0.500404\tKL_Divergence = 4.108041\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:09:51,433] Trial 502 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500437\tKL_Divergence = 4.063443\n",
      "Total time elapsed during training: 40.056 s\n",
      "Trial 502 pruned. \n",
      "Epoch: 1\tFidelity = 0.500412\tKL_Divergence = 4.096206\n",
      "Epoch: 2\tFidelity = 0.500458\tKL_Divergence = 4.038246\n",
      "Epoch: 3\tFidelity = 0.500439\tKL_Divergence = 4.061567\n",
      "Epoch: 4\tFidelity = 0.500436\tKL_Divergence = 4.065053\n",
      "Epoch: 5\tFidelity = 0.500489\tKL_Divergence = 4.002015\n",
      "Epoch: 6\tFidelity = 0.500429\tKL_Divergence = 4.073619\n",
      "Epoch: 7\tFidelity = 0.500433\tKL_Divergence = 4.069265\n",
      "Epoch: 8\tFidelity = 0.500452\tKL_Divergence = 4.044893\n",
      "Epoch: 9\tFidelity = 0.500490\tKL_Divergence = 4.000045\n",
      "Epoch: 10\tFidelity = 0.500458\tKL_Divergence = 4.037630\n",
      "Epoch: 11\tFidelity = 0.500391\tKL_Divergence = 4.126062\n",
      "Epoch: 12\tFidelity = 0.500411\tKL_Divergence = 4.097404\n",
      "Epoch: 13\tFidelity = 0.500526\tKL_Divergence = 3.960843\n",
      "Epoch: 14\tFidelity = 0.500481\tKL_Divergence = 4.011076\n",
      "Epoch: 15\tFidelity = 0.500409\tKL_Divergence = 4.100987\n",
      "Epoch: 16\tFidelity = 0.500371\tKL_Divergence = 4.154986\n",
      "Epoch: 17\tFidelity = 0.500400\tKL_Divergence = 4.113556\n",
      "Epoch: 18\tFidelity = 0.500475\tKL_Divergence = 4.018054\n",
      "Epoch: 19\tFidelity = 0.500370\tKL_Divergence = 4.156797\n",
      "Epoch: 20\tFidelity = 0.500376\tKL_Divergence = 4.147882\n",
      "Epoch: 21\tFidelity = 0.500403\tKL_Divergence = 4.108528\n",
      "Epoch: 22\tFidelity = 0.500511\tKL_Divergence = 3.976699\n",
      "Epoch: 23\tFidelity = 0.500472\tKL_Divergence = 4.021690\n",
      "Epoch: 24\tFidelity = 0.500426\tKL_Divergence = 4.077598\n",
      "Epoch: 25\tFidelity = 0.500477\tKL_Divergence = 4.015587\n",
      "Epoch: 26\tFidelity = 0.500422\tKL_Divergence = 4.083751\n",
      "Epoch: 27\tFidelity = 0.500387\tKL_Divergence = 4.131656\n",
      "Epoch: 28\tFidelity = 0.500383\tKL_Divergence = 4.136770\n",
      "Epoch: 29\tFidelity = 0.500412\tKL_Divergence = 4.096577\n",
      "Epoch: 30\tFidelity = 0.500400\tKL_Divergence = 4.112127\n",
      "Epoch: 31\tFidelity = 0.500372\tKL_Divergence = 4.153236\n",
      "Epoch: 32\tFidelity = 0.500396\tKL_Divergence = 4.117691\n",
      "Epoch: 33\tFidelity = 0.500371\tKL_Divergence = 4.154352\n",
      "Epoch: 34\tFidelity = 0.500446\tKL_Divergence = 4.052750\n",
      "Epoch: 35\tFidelity = 0.500390\tKL_Divergence = 4.126660\n",
      "Epoch: 36\tFidelity = 0.500371\tKL_Divergence = 4.154003\n",
      "Epoch: 37\tFidelity = 0.500360\tKL_Divergence = 4.171737\n",
      "Epoch: 38\tFidelity = 0.500477\tKL_Divergence = 4.015290\n",
      "Epoch: 39\tFidelity = 0.500402\tKL_Divergence = 4.110585\n",
      "Epoch: 40\tFidelity = 0.500432\tKL_Divergence = 4.070901\n",
      "Epoch: 41\tFidelity = 0.500451\tKL_Divergence = 4.045981\n",
      "Epoch: 42\tFidelity = 0.500423\tKL_Divergence = 4.081787\n",
      "Epoch: 43\tFidelity = 0.500500\tKL_Divergence = 3.989400\n",
      "Epoch: 44\tFidelity = 0.500526\tKL_Divergence = 3.961556\n",
      "Epoch: 45\tFidelity = 0.500439\tKL_Divergence = 4.061441\n",
      "Epoch: 46\tFidelity = 0.500533\tKL_Divergence = 3.953951\n",
      "Epoch: 47\tFidelity = 0.500490\tKL_Divergence = 4.000056\n",
      "Epoch: 48\tFidelity = 0.500514\tKL_Divergence = 3.973712\n",
      "Epoch: 49\tFidelity = 0.500420\tKL_Divergence = 4.086712\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:10:31,200] Trial 503 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500436\tKL_Divergence = 4.065674\n",
      "Total time elapsed during training: 39.589 s\n",
      "Trial 503 pruned. \n",
      "Epoch: 1\tFidelity = 0.500446\tKL_Divergence = 4.053109\n",
      "Epoch: 2\tFidelity = 0.500466\tKL_Divergence = 4.028159\n",
      "Epoch: 3\tFidelity = 0.500494\tKL_Divergence = 3.995468\n",
      "Epoch: 4\tFidelity = 0.500373\tKL_Divergence = 4.152264\n",
      "Epoch: 5\tFidelity = 0.500541\tKL_Divergence = 3.945518\n",
      "Epoch: 6\tFidelity = 0.500401\tKL_Divergence = 4.111225\n",
      "Epoch: 7\tFidelity = 0.500478\tKL_Divergence = 4.014682\n",
      "Epoch: 8\tFidelity = 0.500477\tKL_Divergence = 4.015998\n",
      "Epoch: 9\tFidelity = 0.500414\tKL_Divergence = 4.093329\n",
      "Epoch: 10\tFidelity = 0.500428\tKL_Divergence = 4.075420\n",
      "Epoch: 11\tFidelity = 0.500440\tKL_Divergence = 4.060090\n",
      "Epoch: 12\tFidelity = 0.500378\tKL_Divergence = 4.144724\n",
      "Epoch: 13\tFidelity = 0.500506\tKL_Divergence = 3.982378\n",
      "Epoch: 14\tFidelity = 0.500393\tKL_Divergence = 4.123384\n",
      "Epoch: 15\tFidelity = 0.500392\tKL_Divergence = 4.123858\n",
      "Epoch: 16\tFidelity = 0.500440\tKL_Divergence = 4.059649\n",
      "Epoch: 17\tFidelity = 0.500458\tKL_Divergence = 4.037458\n",
      "Epoch: 18\tFidelity = 0.500439\tKL_Divergence = 4.060881\n",
      "Epoch: 19\tFidelity = 0.500452\tKL_Divergence = 4.045218\n",
      "Epoch: 20\tFidelity = 0.500469\tKL_Divergence = 4.025209\n",
      "Epoch: 21\tFidelity = 0.500439\tKL_Divergence = 4.061041\n",
      "Epoch: 22\tFidelity = 0.500463\tKL_Divergence = 4.031543\n",
      "Epoch: 23\tFidelity = 0.500441\tKL_Divergence = 4.058872\n",
      "Epoch: 24\tFidelity = 0.500427\tKL_Divergence = 4.076497\n",
      "Epoch: 25\tFidelity = 0.500432\tKL_Divergence = 4.069980\n",
      "Epoch: 26\tFidelity = 0.500453\tKL_Divergence = 4.044420\n",
      "Epoch: 27\tFidelity = 0.500417\tKL_Divergence = 4.090382\n",
      "Epoch: 28\tFidelity = 0.500495\tKL_Divergence = 3.994382\n",
      "Epoch: 29\tFidelity = 0.500477\tKL_Divergence = 4.015047\n",
      "Epoch: 30\tFidelity = 0.500436\tKL_Divergence = 4.065077\n",
      "Epoch: 31\tFidelity = 0.500421\tKL_Divergence = 4.084931\n",
      "Epoch: 32\tFidelity = 0.500421\tKL_Divergence = 4.084786\n",
      "Epoch: 33\tFidelity = 0.500472\tKL_Divergence = 4.020717\n",
      "Epoch: 34\tFidelity = 0.500388\tKL_Divergence = 4.129912\n",
      "Epoch: 35\tFidelity = 0.500404\tKL_Divergence = 4.107122\n",
      "Epoch: 36\tFidelity = 0.500372\tKL_Divergence = 4.153810\n",
      "Epoch: 37\tFidelity = 0.500429\tKL_Divergence = 4.073995\n",
      "Epoch: 38\tFidelity = 0.500462\tKL_Divergence = 4.032689\n",
      "Epoch: 39\tFidelity = 0.500466\tKL_Divergence = 4.028079\n",
      "Epoch: 40\tFidelity = 0.500351\tKL_Divergence = 4.185404\n",
      "Epoch: 41\tFidelity = 0.500407\tKL_Divergence = 4.103293\n",
      "Epoch: 42\tFidelity = 0.500494\tKL_Divergence = 3.995722\n",
      "Epoch: 43\tFidelity = 0.500424\tKL_Divergence = 4.081189\n",
      "Epoch: 44\tFidelity = 0.500386\tKL_Divergence = 4.132725\n",
      "Epoch: 45\tFidelity = 0.500461\tKL_Divergence = 4.034856\n",
      "Epoch: 46\tFidelity = 0.500441\tKL_Divergence = 4.059275\n",
      "Epoch: 47\tFidelity = 0.500393\tKL_Divergence = 4.123516\n",
      "Epoch: 48\tFidelity = 0.500388\tKL_Divergence = 4.130126\n",
      "Epoch: 49\tFidelity = 0.500430\tKL_Divergence = 4.072707\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:11:11,111] Trial 504 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500370\tKL_Divergence = 4.155691\n",
      "Total time elapsed during training: 39.719 s\n",
      "Trial 504 pruned. \n",
      "Epoch: 1\tFidelity = 0.500406\tKL_Divergence = 4.104488\n",
      "Epoch: 2\tFidelity = 0.500438\tKL_Divergence = 4.062416\n",
      "Epoch: 3\tFidelity = 0.500439\tKL_Divergence = 4.061048\n",
      "Epoch: 4\tFidelity = 0.500426\tKL_Divergence = 4.077775\n",
      "Epoch: 5\tFidelity = 0.500404\tKL_Divergence = 4.108105\n",
      "Epoch: 6\tFidelity = 0.500406\tKL_Divergence = 4.105158\n",
      "Epoch: 7\tFidelity = 0.500424\tKL_Divergence = 4.080511\n",
      "Epoch: 8\tFidelity = 0.500417\tKL_Divergence = 4.089608\n",
      "Epoch: 9\tFidelity = 0.500445\tKL_Divergence = 4.053748\n",
      "Epoch: 10\tFidelity = 0.500465\tKL_Divergence = 4.029749\n",
      "Epoch: 11\tFidelity = 0.500426\tKL_Divergence = 4.078599\n",
      "Epoch: 12\tFidelity = 0.500428\tKL_Divergence = 4.075580\n",
      "Epoch: 13\tFidelity = 0.500455\tKL_Divergence = 4.041906\n",
      "Epoch: 14\tFidelity = 0.500420\tKL_Divergence = 4.086206\n",
      "Epoch: 15\tFidelity = 0.500448\tKL_Divergence = 4.050307\n",
      "Epoch: 16\tFidelity = 0.500419\tKL_Divergence = 4.087821\n",
      "Epoch: 17\tFidelity = 0.500418\tKL_Divergence = 4.089135\n",
      "Epoch: 18\tFidelity = 0.500443\tKL_Divergence = 4.056734\n",
      "Epoch: 19\tFidelity = 0.500445\tKL_Divergence = 4.054456\n",
      "Epoch: 20\tFidelity = 0.500440\tKL_Divergence = 4.060319\n",
      "Epoch: 21\tFidelity = 0.500422\tKL_Divergence = 4.083418\n",
      "Epoch: 22\tFidelity = 0.500424\tKL_Divergence = 4.081251\n",
      "Epoch: 23\tFidelity = 0.500427\tKL_Divergence = 4.076672\n",
      "Epoch: 24\tFidelity = 0.500413\tKL_Divergence = 4.094893\n",
      "Epoch: 25\tFidelity = 0.500405\tKL_Divergence = 4.105949\n",
      "Epoch: 26\tFidelity = 0.500438\tKL_Divergence = 4.062801\n",
      "Epoch: 27\tFidelity = 0.500434\tKL_Divergence = 4.067685\n",
      "Epoch: 28\tFidelity = 0.500433\tKL_Divergence = 4.069071\n",
      "Epoch: 29\tFidelity = 0.500431\tKL_Divergence = 4.072261\n",
      "Epoch: 30\tFidelity = 0.500440\tKL_Divergence = 4.059960\n",
      "Epoch: 31\tFidelity = 0.500428\tKL_Divergence = 4.075968\n",
      "Epoch: 32\tFidelity = 0.500424\tKL_Divergence = 4.080261\n",
      "Epoch: 33\tFidelity = 0.500451\tKL_Divergence = 4.047006\n",
      "Epoch: 34\tFidelity = 0.500423\tKL_Divergence = 4.081578\n",
      "Epoch: 35\tFidelity = 0.500410\tKL_Divergence = 4.099822\n",
      "Epoch: 36\tFidelity = 0.500432\tKL_Divergence = 4.070117\n",
      "Epoch: 37\tFidelity = 0.500457\tKL_Divergence = 4.038997\n",
      "Epoch: 38\tFidelity = 0.500463\tKL_Divergence = 4.032598\n",
      "Epoch: 39\tFidelity = 0.500459\tKL_Divergence = 4.036526\n",
      "Epoch: 40\tFidelity = 0.500475\tKL_Divergence = 4.018426\n",
      "Epoch: 41\tFidelity = 0.500438\tKL_Divergence = 4.062652\n",
      "Epoch: 42\tFidelity = 0.500450\tKL_Divergence = 4.047979\n",
      "Epoch: 43\tFidelity = 0.500442\tKL_Divergence = 4.057865\n",
      "Epoch: 44\tFidelity = 0.500472\tKL_Divergence = 4.020900\n",
      "Epoch: 45\tFidelity = 0.500433\tKL_Divergence = 4.068686\n",
      "Epoch: 46\tFidelity = 0.500427\tKL_Divergence = 4.077567\n",
      "Epoch: 47\tFidelity = 0.500409\tKL_Divergence = 4.101252\n",
      "Epoch: 48\tFidelity = 0.500423\tKL_Divergence = 4.081768\n",
      "Epoch: 49\tFidelity = 0.500439\tKL_Divergence = 4.061303\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:11:50,862] Trial 505 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500438\tKL_Divergence = 4.062897\n",
      "Total time elapsed during training: 39.565 s\n",
      "Trial 505 pruned. \n",
      "Epoch: 1\tFidelity = 0.500439\tKL_Divergence = 4.061207\n",
      "Epoch: 2\tFidelity = 0.500477\tKL_Divergence = 4.016040\n",
      "Epoch: 3\tFidelity = 0.500421\tKL_Divergence = 4.085369\n",
      "Epoch: 4\tFidelity = 0.500416\tKL_Divergence = 4.091460\n",
      "Epoch: 5\tFidelity = 0.500458\tKL_Divergence = 4.038086\n",
      "Epoch: 6\tFidelity = 0.500458\tKL_Divergence = 4.038079\n",
      "Epoch: 7\tFidelity = 0.500469\tKL_Divergence = 4.025111\n",
      "Epoch: 8\tFidelity = 0.500398\tKL_Divergence = 4.116191\n",
      "Epoch: 9\tFidelity = 0.500436\tKL_Divergence = 4.065377\n",
      "Epoch: 10\tFidelity = 0.500438\tKL_Divergence = 4.063053\n",
      "Epoch: 11\tFidelity = 0.500466\tKL_Divergence = 4.028784\n",
      "Epoch: 12\tFidelity = 0.500470\tKL_Divergence = 4.023781\n",
      "Epoch: 13\tFidelity = 0.500448\tKL_Divergence = 4.050527\n",
      "Epoch: 14\tFidelity = 0.500434\tKL_Divergence = 4.067676\n",
      "Epoch: 15\tFidelity = 0.500457\tKL_Divergence = 4.039555\n",
      "Epoch: 16\tFidelity = 0.500423\tKL_Divergence = 4.081846\n",
      "Epoch: 17\tFidelity = 0.500416\tKL_Divergence = 4.091977\n",
      "Epoch: 18\tFidelity = 0.500459\tKL_Divergence = 4.036354\n",
      "Epoch: 19\tFidelity = 0.500434\tKL_Divergence = 4.068010\n",
      "Epoch: 20\tFidelity = 0.500420\tKL_Divergence = 4.085645\n",
      "Epoch: 21\tFidelity = 0.500444\tKL_Divergence = 4.054917\n",
      "Epoch: 22\tFidelity = 0.500475\tKL_Divergence = 4.017681\n",
      "Epoch: 23\tFidelity = 0.500444\tKL_Divergence = 4.055408\n",
      "Epoch: 24\tFidelity = 0.500431\tKL_Divergence = 4.072029\n",
      "Epoch: 25\tFidelity = 0.500453\tKL_Divergence = 4.043715\n",
      "Epoch: 26\tFidelity = 0.500455\tKL_Divergence = 4.041957\n",
      "Epoch: 27\tFidelity = 0.500446\tKL_Divergence = 4.052949\n",
      "Epoch: 28\tFidelity = 0.500464\tKL_Divergence = 4.031194\n",
      "Epoch: 29\tFidelity = 0.500457\tKL_Divergence = 4.039730\n",
      "Epoch: 30\tFidelity = 0.500449\tKL_Divergence = 4.049392\n",
      "Epoch: 31\tFidelity = 0.500452\tKL_Divergence = 4.044984\n",
      "Epoch: 32\tFidelity = 0.500459\tKL_Divergence = 4.036372\n",
      "Epoch: 33\tFidelity = 0.500442\tKL_Divergence = 4.057870\n",
      "Epoch: 34\tFidelity = 0.500420\tKL_Divergence = 4.085420\n",
      "Epoch: 35\tFidelity = 0.500466\tKL_Divergence = 4.028639\n",
      "Epoch: 36\tFidelity = 0.500439\tKL_Divergence = 4.061506\n",
      "Epoch: 37\tFidelity = 0.500434\tKL_Divergence = 4.068057\n",
      "Epoch: 38\tFidelity = 0.500455\tKL_Divergence = 4.042012\n",
      "Epoch: 39\tFidelity = 0.500445\tKL_Divergence = 4.054484\n",
      "Epoch: 40\tFidelity = 0.500424\tKL_Divergence = 4.080817\n",
      "Epoch: 41\tFidelity = 0.500447\tKL_Divergence = 4.051633\n",
      "Epoch: 42\tFidelity = 0.500466\tKL_Divergence = 4.027990\n",
      "Epoch: 43\tFidelity = 0.500416\tKL_Divergence = 4.091583\n",
      "Epoch: 44\tFidelity = 0.500440\tKL_Divergence = 4.060015\n",
      "Epoch: 45\tFidelity = 0.500470\tKL_Divergence = 4.024132\n",
      "Epoch: 46\tFidelity = 0.500453\tKL_Divergence = 4.044378\n",
      "Epoch: 47\tFidelity = 0.500454\tKL_Divergence = 4.042402\n",
      "Epoch: 48\tFidelity = 0.500467\tKL_Divergence = 4.027182\n",
      "Epoch: 49\tFidelity = 0.500460\tKL_Divergence = 4.035389\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:13:14,766] Trial 506 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500431\tKL_Divergence = 4.072345\n",
      "Total time elapsed during training: 83.708 s\n",
      "Trial 506 pruned. \n",
      "Epoch: 1\tFidelity = 0.500437\tKL_Divergence = 4.064267\n",
      "Epoch: 2\tFidelity = 0.500511\tKL_Divergence = 3.977539\n",
      "Epoch: 3\tFidelity = 0.500482\tKL_Divergence = 4.010239\n",
      "Epoch: 4\tFidelity = 0.500462\tKL_Divergence = 4.032943\n",
      "Epoch: 5\tFidelity = 0.500419\tKL_Divergence = 4.086780\n",
      "Epoch: 6\tFidelity = 0.500450\tKL_Divergence = 4.047410\n",
      "Epoch: 7\tFidelity = 0.500489\tKL_Divergence = 4.001505\n",
      "Epoch: 8\tFidelity = 0.500478\tKL_Divergence = 4.014686\n",
      "Epoch: 9\tFidelity = 0.500449\tKL_Divergence = 4.049106\n",
      "Epoch: 10\tFidelity = 0.500422\tKL_Divergence = 4.083796\n",
      "Epoch: 11\tFidelity = 0.500446\tKL_Divergence = 4.052125\n",
      "Epoch: 12\tFidelity = 0.500393\tKL_Divergence = 4.122366\n",
      "Epoch: 13\tFidelity = 0.500415\tKL_Divergence = 4.092428\n",
      "Epoch: 14\tFidelity = 0.500436\tKL_Divergence = 4.064872\n",
      "Epoch: 15\tFidelity = 0.500417\tKL_Divergence = 4.089879\n",
      "Epoch: 16\tFidelity = 0.500461\tKL_Divergence = 4.033960\n",
      "Epoch: 17\tFidelity = 0.500453\tKL_Divergence = 4.044246\n",
      "Epoch: 18\tFidelity = 0.500464\tKL_Divergence = 4.030996\n",
      "Epoch: 19\tFidelity = 0.500494\tKL_Divergence = 3.996070\n",
      "Epoch: 20\tFidelity = 0.500428\tKL_Divergence = 4.075073\n",
      "Epoch: 21\tFidelity = 0.500430\tKL_Divergence = 4.073334\n",
      "Epoch: 22\tFidelity = 0.500420\tKL_Divergence = 4.086598\n",
      "Epoch: 23\tFidelity = 0.500479\tKL_Divergence = 4.012921\n",
      "Epoch: 24\tFidelity = 0.500479\tKL_Divergence = 4.013336\n",
      "Epoch: 25\tFidelity = 0.500453\tKL_Divergence = 4.043451\n",
      "Epoch: 26\tFidelity = 0.500479\tKL_Divergence = 4.013559\n",
      "Epoch: 27\tFidelity = 0.500468\tKL_Divergence = 4.025991\n",
      "Epoch: 28\tFidelity = 0.500445\tKL_Divergence = 4.054325\n",
      "Epoch: 29\tFidelity = 0.500416\tKL_Divergence = 4.091115\n",
      "Epoch: 30\tFidelity = 0.500433\tKL_Divergence = 4.068785\n",
      "Epoch: 31\tFidelity = 0.500454\tKL_Divergence = 4.042539\n",
      "Epoch: 32\tFidelity = 0.500456\tKL_Divergence = 4.040914\n",
      "Epoch: 33\tFidelity = 0.500459\tKL_Divergence = 4.036610\n",
      "Epoch: 34\tFidelity = 0.500480\tKL_Divergence = 4.011543\n",
      "Epoch: 35\tFidelity = 0.500475\tKL_Divergence = 4.017832\n",
      "Epoch: 36\tFidelity = 0.500444\tKL_Divergence = 4.055134\n",
      "Epoch: 37\tFidelity = 0.500476\tKL_Divergence = 4.016131\n",
      "Epoch: 38\tFidelity = 0.500453\tKL_Divergence = 4.044618\n",
      "Epoch: 39\tFidelity = 0.500463\tKL_Divergence = 4.031884\n",
      "Epoch: 40\tFidelity = 0.500462\tKL_Divergence = 4.032959\n",
      "Epoch: 41\tFidelity = 0.500511\tKL_Divergence = 3.976748\n",
      "Epoch: 42\tFidelity = 0.500473\tKL_Divergence = 4.019778\n",
      "Epoch: 43\tFidelity = 0.500483\tKL_Divergence = 4.008896\n",
      "Epoch: 44\tFidelity = 0.500466\tKL_Divergence = 4.028649\n",
      "Epoch: 45\tFidelity = 0.500427\tKL_Divergence = 4.076868\n",
      "Epoch: 46\tFidelity = 0.500445\tKL_Divergence = 4.053369\n",
      "Epoch: 47\tFidelity = 0.500433\tKL_Divergence = 4.068791\n",
      "Epoch: 48\tFidelity = 0.500475\tKL_Divergence = 4.017382\n",
      "Epoch: 49\tFidelity = 0.500432\tKL_Divergence = 4.070807\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:14:15,135] Trial 507 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500417\tKL_Divergence = 4.089611\n",
      "Total time elapsed during training: 60.184 s\n",
      "Trial 507 pruned. \n",
      "Epoch: 1\tFidelity = 0.500441\tKL_Divergence = 4.058880\n",
      "Epoch: 2\tFidelity = 0.500429\tKL_Divergence = 4.074889\n",
      "Epoch: 3\tFidelity = 0.500464\tKL_Divergence = 4.031040\n",
      "Epoch: 4\tFidelity = 0.500446\tKL_Divergence = 4.052929\n",
      "Epoch: 5\tFidelity = 0.500381\tKL_Divergence = 4.140082\n",
      "Epoch: 6\tFidelity = 0.500477\tKL_Divergence = 4.015187\n",
      "Epoch: 7\tFidelity = 0.500484\tKL_Divergence = 4.006960\n",
      "Epoch: 8\tFidelity = 0.500404\tKL_Divergence = 4.108167\n",
      "Epoch: 9\tFidelity = 0.500464\tKL_Divergence = 4.030606\n",
      "Epoch: 10\tFidelity = 0.500475\tKL_Divergence = 4.017435\n",
      "Epoch: 11\tFidelity = 0.500426\tKL_Divergence = 4.077587\n",
      "Epoch: 12\tFidelity = 0.500500\tKL_Divergence = 3.989156\n",
      "Epoch: 13\tFidelity = 0.500565\tKL_Divergence = 3.921314\n",
      "Epoch: 14\tFidelity = 0.500432\tKL_Divergence = 4.070744\n",
      "Epoch: 15\tFidelity = 0.500507\tKL_Divergence = 3.981795\n",
      "Epoch: 16\tFidelity = 0.500458\tKL_Divergence = 4.038374\n",
      "Epoch: 17\tFidelity = 0.500408\tKL_Divergence = 4.102363\n",
      "Epoch: 18\tFidelity = 0.500486\tKL_Divergence = 4.004668\n",
      "Epoch: 19\tFidelity = 0.500405\tKL_Divergence = 4.106692\n",
      "Epoch: 20\tFidelity = 0.500465\tKL_Divergence = 4.030065\n",
      "Epoch: 21\tFidelity = 0.500526\tKL_Divergence = 3.960762\n",
      "Epoch: 22\tFidelity = 0.500482\tKL_Divergence = 4.010099\n",
      "Epoch: 23\tFidelity = 0.500429\tKL_Divergence = 4.074352\n",
      "Epoch: 24\tFidelity = 0.500451\tKL_Divergence = 4.046995\n",
      "Epoch: 25\tFidelity = 0.500483\tKL_Divergence = 4.008999\n",
      "Epoch: 26\tFidelity = 0.500366\tKL_Divergence = 4.161886\n",
      "Epoch: 27\tFidelity = 0.500485\tKL_Divergence = 4.006331\n",
      "Epoch: 28\tFidelity = 0.500438\tKL_Divergence = 4.062257\n",
      "Epoch: 29\tFidelity = 0.500411\tKL_Divergence = 4.097499\n",
      "Epoch: 30\tFidelity = 0.500375\tKL_Divergence = 4.149265\n",
      "Epoch: 31\tFidelity = 0.500391\tKL_Divergence = 4.125140\n",
      "Epoch: 32\tFidelity = 0.500443\tKL_Divergence = 4.056280\n",
      "Epoch: 33\tFidelity = 0.500490\tKL_Divergence = 4.000041\n",
      "Epoch: 34\tFidelity = 0.500446\tKL_Divergence = 4.053075\n",
      "Epoch: 35\tFidelity = 0.500519\tKL_Divergence = 3.969044\n",
      "Epoch: 36\tFidelity = 0.500573\tKL_Divergence = 3.914086\n",
      "Epoch: 37\tFidelity = 0.500532\tKL_Divergence = 3.955224\n",
      "Epoch: 38\tFidelity = 0.500495\tKL_Divergence = 3.994265\n",
      "Epoch: 39\tFidelity = 0.500490\tKL_Divergence = 4.000144\n",
      "Epoch: 40\tFidelity = 0.500518\tKL_Divergence = 3.969193\n",
      "Epoch: 41\tFidelity = 0.500410\tKL_Divergence = 4.099718\n",
      "Epoch: 42\tFidelity = 0.500491\tKL_Divergence = 3.999722\n",
      "Epoch: 43\tFidelity = 0.500452\tKL_Divergence = 4.045667\n",
      "Epoch: 44\tFidelity = 0.500428\tKL_Divergence = 4.075220\n",
      "Epoch: 45\tFidelity = 0.500525\tKL_Divergence = 3.962513\n",
      "Epoch: 46\tFidelity = 0.500440\tKL_Divergence = 4.059715\n",
      "Epoch: 47\tFidelity = 0.500451\tKL_Divergence = 4.046668\n",
      "Epoch: 48\tFidelity = 0.500519\tKL_Divergence = 3.968478\n",
      "Epoch: 49\tFidelity = 0.500531\tKL_Divergence = 3.955449\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:15:01,512] Trial 508 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500462\tKL_Divergence = 4.033350\n",
      "Total time elapsed during training: 46.193 s\n",
      "Trial 508 pruned. \n",
      "Epoch: 1\tFidelity = 0.500384\tKL_Divergence = 4.135439\n",
      "Epoch: 2\tFidelity = 0.500391\tKL_Divergence = 4.125897\n",
      "Epoch: 3\tFidelity = 0.500410\tKL_Divergence = 4.098400\n",
      "Epoch: 4\tFidelity = 0.500501\tKL_Divergence = 3.987686\n",
      "Epoch: 5\tFidelity = 0.500504\tKL_Divergence = 3.984251\n",
      "Epoch: 6\tFidelity = 0.500433\tKL_Divergence = 4.068069\n",
      "Epoch: 7\tFidelity = 0.500432\tKL_Divergence = 4.070387\n",
      "Epoch: 8\tFidelity = 0.500411\tKL_Divergence = 4.096666\n",
      "Epoch: 9\tFidelity = 0.500450\tKL_Divergence = 4.047370\n",
      "Epoch: 10\tFidelity = 0.500448\tKL_Divergence = 4.050363\n",
      "Epoch: 11\tFidelity = 0.500486\tKL_Divergence = 4.004058\n",
      "Epoch: 12\tFidelity = 0.500522\tKL_Divergence = 3.964147\n",
      "Epoch: 13\tFidelity = 0.500436\tKL_Divergence = 4.064130\n",
      "Epoch: 14\tFidelity = 0.500502\tKL_Divergence = 3.985444\n",
      "Epoch: 15\tFidelity = 0.500515\tKL_Divergence = 3.972357\n",
      "Epoch: 16\tFidelity = 0.500481\tKL_Divergence = 4.010132\n",
      "Epoch: 17\tFidelity = 0.500534\tKL_Divergence = 3.951443\n",
      "Epoch: 18\tFidelity = 0.500512\tKL_Divergence = 3.975348\n",
      "Epoch: 19\tFidelity = 0.500476\tKL_Divergence = 4.016583\n",
      "Epoch: 20\tFidelity = 0.500556\tKL_Divergence = 3.929407\n",
      "Epoch: 21\tFidelity = 0.500489\tKL_Divergence = 4.000911\n",
      "Epoch: 22\tFidelity = 0.500548\tKL_Divergence = 3.938472\n",
      "Epoch: 23\tFidelity = 0.500499\tKL_Divergence = 3.990846\n",
      "Epoch: 24\tFidelity = 0.500438\tKL_Divergence = 4.063245\n",
      "Epoch: 25\tFidelity = 0.500457\tKL_Divergence = 4.039386\n",
      "Epoch: 26\tFidelity = 0.500464\tKL_Divergence = 4.030863\n",
      "Epoch: 27\tFidelity = 0.500431\tKL_Divergence = 4.071630\n",
      "Epoch: 28\tFidelity = 0.500458\tKL_Divergence = 4.037604\n",
      "Epoch: 29\tFidelity = 0.500429\tKL_Divergence = 4.073602\n",
      "Epoch: 30\tFidelity = 0.500483\tKL_Divergence = 4.008073\n",
      "Epoch: 31\tFidelity = 0.500418\tKL_Divergence = 4.088337\n",
      "Epoch: 32\tFidelity = 0.500464\tKL_Divergence = 4.031130\n",
      "Epoch: 33\tFidelity = 0.500495\tKL_Divergence = 3.994958\n",
      "Epoch: 34\tFidelity = 0.500471\tKL_Divergence = 4.022477\n",
      "Epoch: 35\tFidelity = 0.500519\tKL_Divergence = 3.968855\n",
      "Epoch: 36\tFidelity = 0.500449\tKL_Divergence = 4.048799\n",
      "Epoch: 37\tFidelity = 0.500482\tKL_Divergence = 4.009520\n",
      "Epoch: 38\tFidelity = 0.500514\tKL_Divergence = 3.973280\n",
      "Epoch: 39\tFidelity = 0.500506\tKL_Divergence = 3.983053\n",
      "Epoch: 40\tFidelity = 0.500465\tKL_Divergence = 4.029030\n",
      "Epoch: 41\tFidelity = 0.500495\tKL_Divergence = 3.994463\n",
      "Epoch: 42\tFidelity = 0.500448\tKL_Divergence = 4.049935\n",
      "Epoch: 43\tFidelity = 0.500437\tKL_Divergence = 4.064249\n",
      "Epoch: 44\tFidelity = 0.500436\tKL_Divergence = 4.064893\n",
      "Epoch: 45\tFidelity = 0.500435\tKL_Divergence = 4.066752\n",
      "Epoch: 46\tFidelity = 0.500467\tKL_Divergence = 4.027176\n",
      "Epoch: 47\tFidelity = 0.500446\tKL_Divergence = 4.052155\n",
      "Epoch: 48\tFidelity = 0.500497\tKL_Divergence = 3.991963\n",
      "Epoch: 49\tFidelity = 0.500503\tKL_Divergence = 3.986050\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:15:41,109] Trial 509 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500527\tKL_Divergence = 3.960290\n",
      "Total time elapsed during training: 39.417 s\n",
      "Trial 509 pruned. \n",
      "Epoch: 1\tFidelity = 0.500487\tKL_Divergence = 4.003964\n",
      "Epoch: 2\tFidelity = 0.500472\tKL_Divergence = 4.020590\n",
      "Epoch: 3\tFidelity = 0.500501\tKL_Divergence = 3.988350\n",
      "Epoch: 4\tFidelity = 0.500456\tKL_Divergence = 4.040667\n",
      "Epoch: 5\tFidelity = 0.500469\tKL_Divergence = 4.024022\n",
      "Epoch: 6\tFidelity = 0.500475\tKL_Divergence = 4.017308\n",
      "Epoch: 7\tFidelity = 0.500476\tKL_Divergence = 4.016481\n",
      "Epoch: 8\tFidelity = 0.500506\tKL_Divergence = 3.982469\n",
      "Epoch: 9\tFidelity = 0.500495\tKL_Divergence = 3.994963\n",
      "Epoch: 10\tFidelity = 0.500487\tKL_Divergence = 4.004169\n",
      "Epoch: 11\tFidelity = 0.500488\tKL_Divergence = 4.002340\n",
      "Epoch: 12\tFidelity = 0.500528\tKL_Divergence = 3.959295\n",
      "Epoch: 13\tFidelity = 0.500470\tKL_Divergence = 4.023193\n",
      "Epoch: 14\tFidelity = 0.500444\tKL_Divergence = 4.055503\n",
      "Epoch: 15\tFidelity = 0.500455\tKL_Divergence = 4.041626\n",
      "Epoch: 16\tFidelity = 0.500503\tKL_Divergence = 3.985414\n",
      "Epoch: 17\tFidelity = 0.500490\tKL_Divergence = 4.000644\n",
      "Epoch: 18\tFidelity = 0.500535\tKL_Divergence = 3.951750\n",
      "Epoch: 19\tFidelity = 0.500464\tKL_Divergence = 4.030046\n",
      "Epoch: 20\tFidelity = 0.500503\tKL_Divergence = 3.985275\n",
      "Epoch: 21\tFidelity = 0.500488\tKL_Divergence = 4.002199\n",
      "Epoch: 22\tFidelity = 0.500516\tKL_Divergence = 3.972014\n",
      "Epoch: 23\tFidelity = 0.500469\tKL_Divergence = 4.024142\n",
      "Epoch: 24\tFidelity = 0.500495\tKL_Divergence = 3.994183\n",
      "Epoch: 25\tFidelity = 0.500509\tKL_Divergence = 3.978796\n",
      "Epoch: 26\tFidelity = 0.500514\tKL_Divergence = 3.973475\n",
      "Epoch: 27\tFidelity = 0.500523\tKL_Divergence = 3.964646\n",
      "Epoch: 28\tFidelity = 0.500473\tKL_Divergence = 4.019964\n",
      "Epoch: 29\tFidelity = 0.500430\tKL_Divergence = 4.072889\n",
      "Epoch: 30\tFidelity = 0.500481\tKL_Divergence = 4.011013\n",
      "Epoch: 31\tFidelity = 0.500456\tKL_Divergence = 4.039841\n",
      "Epoch: 32\tFidelity = 0.500492\tKL_Divergence = 3.998006\n",
      "Epoch: 33\tFidelity = 0.500503\tKL_Divergence = 3.985375\n",
      "Epoch: 34\tFidelity = 0.500458\tKL_Divergence = 4.037498\n",
      "Epoch: 35\tFidelity = 0.500487\tKL_Divergence = 4.003523\n",
      "Epoch: 36\tFidelity = 0.500455\tKL_Divergence = 4.041589\n",
      "Epoch: 37\tFidelity = 0.500496\tKL_Divergence = 3.993476\n",
      "Epoch: 38\tFidelity = 0.500448\tKL_Divergence = 4.050557\n",
      "Epoch: 39\tFidelity = 0.500493\tKL_Divergence = 3.996778\n",
      "Epoch: 40\tFidelity = 0.500481\tKL_Divergence = 4.010649\n",
      "Epoch: 41\tFidelity = 0.500455\tKL_Divergence = 4.041785\n",
      "Epoch: 42\tFidelity = 0.500468\tKL_Divergence = 4.025364\n",
      "Epoch: 43\tFidelity = 0.500501\tKL_Divergence = 3.987813\n",
      "Epoch: 44\tFidelity = 0.500498\tKL_Divergence = 3.991521\n",
      "Epoch: 45\tFidelity = 0.500497\tKL_Divergence = 3.992202\n",
      "Epoch: 46\tFidelity = 0.500434\tKL_Divergence = 4.068063\n",
      "Epoch: 47\tFidelity = 0.500460\tKL_Divergence = 4.035051\n",
      "Epoch: 48\tFidelity = 0.500456\tKL_Divergence = 4.040211\n",
      "Epoch: 49\tFidelity = 0.500484\tKL_Divergence = 4.006990\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:16:13,869] Trial 510 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500502\tKL_Divergence = 3.987251\n",
      "Total time elapsed during training: 32.576 s\n",
      "Trial 510 pruned. \n",
      "Epoch: 1\tFidelity = 0.500552\tKL_Divergence = 3.933829\n",
      "Epoch: 2\tFidelity = 0.500582\tKL_Divergence = 3.905206\n",
      "Epoch: 3\tFidelity = 0.500630\tKL_Divergence = 3.860882\n",
      "Epoch: 4\tFidelity = 0.500611\tKL_Divergence = 3.877635\n",
      "Epoch: 5\tFidelity = 0.500510\tKL_Divergence = 3.978186\n",
      "Epoch: 6\tFidelity = 0.500556\tKL_Divergence = 3.930706\n",
      "Epoch: 7\tFidelity = 0.500624\tKL_Divergence = 3.866573\n",
      "Epoch: 8\tFidelity = 0.500635\tKL_Divergence = 3.856297\n",
      "Epoch: 9\tFidelity = 0.500681\tKL_Divergence = 3.817374\n",
      "Epoch: 10\tFidelity = 0.500629\tKL_Divergence = 3.861230\n",
      "Epoch: 11\tFidelity = 0.500545\tKL_Divergence = 3.940984\n",
      "Epoch: 12\tFidelity = 0.500482\tKL_Divergence = 4.008263\n",
      "Epoch: 13\tFidelity = 0.500528\tKL_Divergence = 3.958371\n",
      "Epoch: 14\tFidelity = 0.500650\tKL_Divergence = 3.843310\n",
      "Epoch: 15\tFidelity = 0.500425\tKL_Divergence = 4.078886\n",
      "Epoch: 16\tFidelity = 0.500593\tKL_Divergence = 3.894994\n",
      "Epoch: 17\tFidelity = 0.500446\tKL_Divergence = 4.052883\n",
      "Epoch: 18\tFidelity = 0.500449\tKL_Divergence = 4.048622\n",
      "Epoch: 19\tFidelity = 0.500553\tKL_Divergence = 3.933204\n",
      "Epoch: 20\tFidelity = 0.500468\tKL_Divergence = 4.026385\n",
      "Epoch: 21\tFidelity = 0.500510\tKL_Divergence = 3.978337\n",
      "Epoch: 22\tFidelity = 0.500493\tKL_Divergence = 3.996881\n",
      "Epoch: 23\tFidelity = 0.500508\tKL_Divergence = 3.980287\n",
      "Epoch: 24\tFidelity = 0.500443\tKL_Divergence = 4.056553\n",
      "Epoch: 25\tFidelity = 0.500396\tKL_Divergence = 4.119016\n",
      "Epoch: 26\tFidelity = 0.500387\tKL_Divergence = 4.130568\n",
      "Epoch: 27\tFidelity = 0.500516\tKL_Divergence = 3.971288\n",
      "Epoch: 28\tFidelity = 0.500449\tKL_Divergence = 4.049485\n",
      "Epoch: 29\tFidelity = 0.500387\tKL_Divergence = 4.131585\n",
      "Epoch: 30\tFidelity = 0.500365\tKL_Divergence = 4.164354\n",
      "Epoch: 31\tFidelity = 0.500389\tKL_Divergence = 4.129089\n",
      "Epoch: 32\tFidelity = 0.500484\tKL_Divergence = 4.007489\n",
      "Epoch: 33\tFidelity = 0.500600\tKL_Divergence = 3.887718\n",
      "Epoch: 34\tFidelity = 0.500461\tKL_Divergence = 4.034731\n",
      "Epoch: 35\tFidelity = 0.500421\tKL_Divergence = 4.084135\n",
      "Epoch: 36\tFidelity = 0.500503\tKL_Divergence = 3.986222\n",
      "Epoch: 37\tFidelity = 0.500496\tKL_Divergence = 3.993213\n",
      "Epoch: 38\tFidelity = 0.500567\tKL_Divergence = 3.919483\n",
      "Epoch: 39\tFidelity = 0.500553\tKL_Divergence = 3.933498\n",
      "Epoch: 40\tFidelity = 0.500531\tKL_Divergence = 3.956260\n",
      "Epoch: 41\tFidelity = 0.500377\tKL_Divergence = 4.145258\n",
      "Epoch: 42\tFidelity = 0.500434\tKL_Divergence = 4.067810\n",
      "Epoch: 43\tFidelity = 0.500489\tKL_Divergence = 4.001836\n",
      "Epoch: 44\tFidelity = 0.500409\tKL_Divergence = 4.100009\n",
      "Epoch: 45\tFidelity = 0.500670\tKL_Divergence = 3.826899\n",
      "Epoch: 46\tFidelity = 0.500662\tKL_Divergence = 3.833100\n",
      "Epoch: 47\tFidelity = 0.500563\tKL_Divergence = 3.923166\n",
      "Epoch: 48\tFidelity = 0.500548\tKL_Divergence = 3.938346\n",
      "Epoch: 49\tFidelity = 0.500466\tKL_Divergence = 4.027908\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:16:52,803] Trial 511 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500477\tKL_Divergence = 4.014673\n",
      "Total time elapsed during training: 38.752 s\n",
      "Trial 511 pruned. \n",
      "Epoch: 1\tFidelity = 0.500540\tKL_Divergence = 3.946065\n",
      "Epoch: 2\tFidelity = 0.500490\tKL_Divergence = 3.999868\n",
      "Epoch: 3\tFidelity = 0.500557\tKL_Divergence = 3.928893\n",
      "Epoch: 4\tFidelity = 0.500446\tKL_Divergence = 4.052429\n",
      "Epoch: 5\tFidelity = 0.500457\tKL_Divergence = 4.039380\n",
      "Epoch: 6\tFidelity = 0.500537\tKL_Divergence = 3.949434\n",
      "Epoch: 7\tFidelity = 0.500463\tKL_Divergence = 4.031276\n",
      "Epoch: 8\tFidelity = 0.500452\tKL_Divergence = 4.044868\n",
      "Epoch: 9\tFidelity = 0.500457\tKL_Divergence = 4.038855\n",
      "Epoch: 10\tFidelity = 0.500437\tKL_Divergence = 4.064505\n",
      "Epoch: 11\tFidelity = 0.500465\tKL_Divergence = 4.029738\n",
      "Epoch: 12\tFidelity = 0.500518\tKL_Divergence = 3.969851\n",
      "Epoch: 13\tFidelity = 0.500464\tKL_Divergence = 4.030177\n",
      "Epoch: 14\tFidelity = 0.500476\tKL_Divergence = 4.016182\n",
      "Epoch: 15\tFidelity = 0.500527\tKL_Divergence = 3.959803\n",
      "Epoch: 16\tFidelity = 0.500547\tKL_Divergence = 3.938852\n",
      "Epoch: 17\tFidelity = 0.500474\tKL_Divergence = 4.018576\n",
      "Epoch: 18\tFidelity = 0.500460\tKL_Divergence = 4.035247\n",
      "Epoch: 19\tFidelity = 0.500470\tKL_Divergence = 4.023066\n",
      "Epoch: 20\tFidelity = 0.500499\tKL_Divergence = 3.990440\n",
      "Epoch: 21\tFidelity = 0.500402\tKL_Divergence = 4.109859\n",
      "Epoch: 22\tFidelity = 0.500437\tKL_Divergence = 4.064201\n",
      "Epoch: 23\tFidelity = 0.500463\tKL_Divergence = 4.032110\n",
      "Epoch: 24\tFidelity = 0.500380\tKL_Divergence = 4.141370\n",
      "Epoch: 25\tFidelity = 0.500446\tKL_Divergence = 4.052335\n",
      "Epoch: 26\tFidelity = 0.500512\tKL_Divergence = 3.975820\n",
      "Epoch: 27\tFidelity = 0.500543\tKL_Divergence = 3.943460\n",
      "Epoch: 28\tFidelity = 0.500455\tKL_Divergence = 4.041623\n",
      "Epoch: 29\tFidelity = 0.500436\tKL_Divergence = 4.065759\n",
      "Epoch: 30\tFidelity = 0.500476\tKL_Divergence = 4.016278\n",
      "Epoch: 31\tFidelity = 0.500478\tKL_Divergence = 4.013980\n",
      "Epoch: 32\tFidelity = 0.500446\tKL_Divergence = 4.052229\n",
      "Epoch: 33\tFidelity = 0.500445\tKL_Divergence = 4.054277\n",
      "Epoch: 34\tFidelity = 0.500447\tKL_Divergence = 4.051319\n",
      "Epoch: 35\tFidelity = 0.500519\tKL_Divergence = 3.968853\n",
      "Epoch: 36\tFidelity = 0.500477\tKL_Divergence = 4.015185\n",
      "Epoch: 37\tFidelity = 0.500510\tKL_Divergence = 3.978387\n",
      "Epoch: 38\tFidelity = 0.500474\tKL_Divergence = 4.019142\n",
      "Epoch: 39\tFidelity = 0.500423\tKL_Divergence = 4.081581\n",
      "Epoch: 40\tFidelity = 0.500475\tKL_Divergence = 4.017938\n",
      "Epoch: 41\tFidelity = 0.500376\tKL_Divergence = 4.147758\n",
      "Epoch: 42\tFidelity = 0.500397\tKL_Divergence = 4.117327\n",
      "Epoch: 43\tFidelity = 0.500501\tKL_Divergence = 3.987822\n",
      "Epoch: 44\tFidelity = 0.500422\tKL_Divergence = 4.082840\n",
      "Epoch: 45\tFidelity = 0.500384\tKL_Divergence = 4.135389\n",
      "Epoch: 46\tFidelity = 0.500480\tKL_Divergence = 4.011381\n",
      "Epoch: 47\tFidelity = 0.500480\tKL_Divergence = 4.011671\n",
      "Epoch: 48\tFidelity = 0.500403\tKL_Divergence = 4.109085\n",
      "Epoch: 49\tFidelity = 0.500463\tKL_Divergence = 4.032259\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:17:25,201] Trial 512 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500507\tKL_Divergence = 3.981474\n",
      "Total time elapsed during training: 32.216 s\n",
      "Trial 512 pruned. \n",
      "Epoch: 1\tFidelity = 0.500472\tKL_Divergence = 4.021086\n",
      "Epoch: 2\tFidelity = 0.500485\tKL_Divergence = 4.006252\n",
      "Epoch: 3\tFidelity = 0.500468\tKL_Divergence = 4.025526\n",
      "Epoch: 4\tFidelity = 0.500453\tKL_Divergence = 4.044604\n",
      "Epoch: 5\tFidelity = 0.500422\tKL_Divergence = 4.083190\n",
      "Epoch: 6\tFidelity = 0.500491\tKL_Divergence = 3.998785\n",
      "Epoch: 7\tFidelity = 0.500444\tKL_Divergence = 4.055210\n",
      "Epoch: 8\tFidelity = 0.500454\tKL_Divergence = 4.043359\n",
      "Epoch: 9\tFidelity = 0.500465\tKL_Divergence = 4.029129\n",
      "Epoch: 10\tFidelity = 0.500412\tKL_Divergence = 4.096822\n",
      "Epoch: 11\tFidelity = 0.500425\tKL_Divergence = 4.079153\n",
      "Epoch: 12\tFidelity = 0.500478\tKL_Divergence = 4.013783\n",
      "Epoch: 13\tFidelity = 0.500432\tKL_Divergence = 4.069791\n",
      "Epoch: 14\tFidelity = 0.500439\tKL_Divergence = 4.061494\n",
      "Epoch: 15\tFidelity = 0.500465\tKL_Divergence = 4.029147\n",
      "Epoch: 16\tFidelity = 0.500427\tKL_Divergence = 4.076134\n",
      "Epoch: 17\tFidelity = 0.500418\tKL_Divergence = 4.088550\n",
      "Epoch: 18\tFidelity = 0.500458\tKL_Divergence = 4.038280\n",
      "Epoch: 19\tFidelity = 0.500479\tKL_Divergence = 4.013023\n",
      "Epoch: 20\tFidelity = 0.500460\tKL_Divergence = 4.035778\n",
      "Epoch: 21\tFidelity = 0.500464\tKL_Divergence = 4.030145\n",
      "Epoch: 22\tFidelity = 0.500457\tKL_Divergence = 4.039124\n",
      "Epoch: 23\tFidelity = 0.500486\tKL_Divergence = 4.004841\n",
      "Epoch: 24\tFidelity = 0.500469\tKL_Divergence = 4.024372\n",
      "Epoch: 25\tFidelity = 0.500472\tKL_Divergence = 4.020920\n",
      "Epoch: 26\tFidelity = 0.500492\tKL_Divergence = 3.997849\n",
      "Epoch: 27\tFidelity = 0.500437\tKL_Divergence = 4.063303\n",
      "Epoch: 28\tFidelity = 0.500428\tKL_Divergence = 4.075071\n",
      "Epoch: 29\tFidelity = 0.500449\tKL_Divergence = 4.048646\n",
      "Epoch: 30\tFidelity = 0.500466\tKL_Divergence = 4.027934\n",
      "Epoch: 31\tFidelity = 0.500470\tKL_Divergence = 4.023543\n",
      "Epoch: 32\tFidelity = 0.500458\tKL_Divergence = 4.037615\n",
      "Epoch: 33\tFidelity = 0.500425\tKL_Divergence = 4.079509\n",
      "Epoch: 34\tFidelity = 0.500450\tKL_Divergence = 4.048245\n",
      "Epoch: 35\tFidelity = 0.500464\tKL_Divergence = 4.030974\n",
      "Epoch: 36\tFidelity = 0.500436\tKL_Divergence = 4.064592\n",
      "Epoch: 37\tFidelity = 0.500496\tKL_Divergence = 3.993925\n",
      "Epoch: 38\tFidelity = 0.500467\tKL_Divergence = 4.026977\n",
      "Epoch: 39\tFidelity = 0.500451\tKL_Divergence = 4.046388\n",
      "Epoch: 40\tFidelity = 0.500437\tKL_Divergence = 4.063482\n",
      "Epoch: 41\tFidelity = 0.500466\tKL_Divergence = 4.027791\n",
      "Epoch: 42\tFidelity = 0.500479\tKL_Divergence = 4.013270\n",
      "Epoch: 43\tFidelity = 0.500463\tKL_Divergence = 4.031700\n",
      "Epoch: 44\tFidelity = 0.500458\tKL_Divergence = 4.037839\n",
      "Epoch: 45\tFidelity = 0.500436\tKL_Divergence = 4.064907\n",
      "Epoch: 46\tFidelity = 0.500462\tKL_Divergence = 4.033328\n",
      "Epoch: 47\tFidelity = 0.500481\tKL_Divergence = 4.010791\n",
      "Epoch: 48\tFidelity = 0.500471\tKL_Divergence = 4.021950\n",
      "Epoch: 49\tFidelity = 0.500459\tKL_Divergence = 4.037178\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:18:50,191] Trial 513 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500465\tKL_Divergence = 4.029511\n",
      "Total time elapsed during training: 84.810 s\n",
      "Trial 513 pruned. \n",
      "Epoch: 1\tFidelity = 0.500440\tKL_Divergence = 4.060389\n",
      "Epoch: 2\tFidelity = 0.500472\tKL_Divergence = 4.020849\n",
      "Epoch: 3\tFidelity = 0.500489\tKL_Divergence = 4.001406\n",
      "Epoch: 4\tFidelity = 0.500467\tKL_Divergence = 4.027529\n",
      "Epoch: 5\tFidelity = 0.500486\tKL_Divergence = 4.005153\n",
      "Epoch: 6\tFidelity = 0.500439\tKL_Divergence = 4.061322\n",
      "Epoch: 7\tFidelity = 0.500446\tKL_Divergence = 4.052796\n",
      "Epoch: 8\tFidelity = 0.500496\tKL_Divergence = 3.993820\n",
      "Epoch: 9\tFidelity = 0.500465\tKL_Divergence = 4.029191\n",
      "Epoch: 10\tFidelity = 0.500489\tKL_Divergence = 4.001758\n",
      "Epoch: 11\tFidelity = 0.500481\tKL_Divergence = 4.010859\n",
      "Epoch: 12\tFidelity = 0.500428\tKL_Divergence = 4.075267\n",
      "Epoch: 13\tFidelity = 0.500430\tKL_Divergence = 4.073049\n",
      "Epoch: 14\tFidelity = 0.500511\tKL_Divergence = 3.976969\n",
      "Epoch: 15\tFidelity = 0.500453\tKL_Divergence = 4.044454\n",
      "Epoch: 16\tFidelity = 0.500440\tKL_Divergence = 4.060288\n",
      "Epoch: 17\tFidelity = 0.500445\tKL_Divergence = 4.053508\n",
      "Epoch: 18\tFidelity = 0.500453\tKL_Divergence = 4.043930\n",
      "Epoch: 19\tFidelity = 0.500461\tKL_Divergence = 4.034429\n",
      "Epoch: 20\tFidelity = 0.500427\tKL_Divergence = 4.076140\n",
      "Epoch: 21\tFidelity = 0.500452\tKL_Divergence = 4.044770\n",
      "Epoch: 22\tFidelity = 0.500492\tKL_Divergence = 3.997725\n",
      "Epoch: 23\tFidelity = 0.500448\tKL_Divergence = 4.050343\n",
      "Epoch: 24\tFidelity = 0.500499\tKL_Divergence = 3.990619\n",
      "Epoch: 25\tFidelity = 0.500407\tKL_Divergence = 4.102977\n",
      "Epoch: 26\tFidelity = 0.500425\tKL_Divergence = 4.078747\n",
      "Epoch: 27\tFidelity = 0.500490\tKL_Divergence = 4.000163\n",
      "Epoch: 28\tFidelity = 0.500450\tKL_Divergence = 4.048012\n",
      "Epoch: 29\tFidelity = 0.500505\tKL_Divergence = 3.983969\n",
      "Epoch: 30\tFidelity = 0.500500\tKL_Divergence = 3.988725\n",
      "Epoch: 31\tFidelity = 0.500478\tKL_Divergence = 4.013858\n",
      "Epoch: 32\tFidelity = 0.500493\tKL_Divergence = 3.996582\n",
      "Epoch: 33\tFidelity = 0.500435\tKL_Divergence = 4.066039\n",
      "Epoch: 34\tFidelity = 0.500482\tKL_Divergence = 4.009249\n",
      "Epoch: 35\tFidelity = 0.500432\tKL_Divergence = 4.070265\n",
      "Epoch: 36\tFidelity = 0.500488\tKL_Divergence = 4.003077\n",
      "Epoch: 37\tFidelity = 0.500501\tKL_Divergence = 3.987901\n",
      "Epoch: 38\tFidelity = 0.500455\tKL_Divergence = 4.041215\n",
      "Epoch: 39\tFidelity = 0.500409\tKL_Divergence = 4.100094\n",
      "Epoch: 40\tFidelity = 0.500458\tKL_Divergence = 4.038282\n",
      "Epoch: 41\tFidelity = 0.500433\tKL_Divergence = 4.069115\n",
      "Epoch: 42\tFidelity = 0.500435\tKL_Divergence = 4.066300\n",
      "Epoch: 43\tFidelity = 0.500440\tKL_Divergence = 4.060489\n",
      "Epoch: 44\tFidelity = 0.500439\tKL_Divergence = 4.061457\n",
      "Epoch: 45\tFidelity = 0.500497\tKL_Divergence = 3.992229\n",
      "Epoch: 46\tFidelity = 0.500409\tKL_Divergence = 4.100910\n",
      "Epoch: 47\tFidelity = 0.500434\tKL_Divergence = 4.067656\n",
      "Epoch: 48\tFidelity = 0.500484\tKL_Divergence = 4.006770\n",
      "Epoch: 49\tFidelity = 0.500514\tKL_Divergence = 3.974168\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:19:29,997] Trial 514 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500477\tKL_Divergence = 4.014836\n",
      "Total time elapsed during training: 39.632 s\n",
      "Trial 514 pruned. \n",
      "Epoch: 1\tFidelity = 0.500429\tKL_Divergence = 4.074521\n",
      "Epoch: 2\tFidelity = 0.500374\tKL_Divergence = 4.150569\n",
      "Epoch: 3\tFidelity = 0.500566\tKL_Divergence = 3.920063\n",
      "Epoch: 4\tFidelity = 0.500402\tKL_Divergence = 4.110365\n",
      "Epoch: 5\tFidelity = 0.500663\tKL_Divergence = 3.832354\n",
      "Epoch: 6\tFidelity = 0.500353\tKL_Divergence = 4.181382\n",
      "Epoch: 7\tFidelity = 0.500482\tKL_Divergence = 4.009509\n",
      "Epoch: 8\tFidelity = 0.500391\tKL_Divergence = 4.125553\n",
      "Epoch: 9\tFidelity = 0.500409\tKL_Divergence = 4.101080\n",
      "Epoch: 10\tFidelity = 0.500508\tKL_Divergence = 3.980029\n",
      "Epoch: 11\tFidelity = 0.500468\tKL_Divergence = 4.026161\n",
      "Epoch: 12\tFidelity = 0.500505\tKL_Divergence = 3.983891\n",
      "Epoch: 13\tFidelity = 0.500489\tKL_Divergence = 4.001130\n",
      "Epoch: 14\tFidelity = 0.500435\tKL_Divergence = 4.065791\n",
      "Epoch: 15\tFidelity = 0.500492\tKL_Divergence = 3.997597\n",
      "Epoch: 16\tFidelity = 0.500481\tKL_Divergence = 4.010423\n",
      "Epoch: 17\tFidelity = 0.500413\tKL_Divergence = 4.094599\n",
      "Epoch: 18\tFidelity = 0.500388\tKL_Divergence = 4.129290\n",
      "Epoch: 19\tFidelity = 0.500447\tKL_Divergence = 4.051387\n",
      "Epoch: 20\tFidelity = 0.500335\tKL_Divergence = 4.211667\n",
      "Epoch: 21\tFidelity = 0.500618\tKL_Divergence = 3.871616\n",
      "Epoch: 22\tFidelity = 0.500429\tKL_Divergence = 4.072981\n",
      "Epoch: 23\tFidelity = 0.500431\tKL_Divergence = 4.071475\n",
      "Epoch: 24\tFidelity = 0.500607\tKL_Divergence = 3.880949\n",
      "Epoch: 25\tFidelity = 0.500386\tKL_Divergence = 4.131781\n",
      "Epoch: 26\tFidelity = 0.500520\tKL_Divergence = 3.967068\n",
      "Epoch: 27\tFidelity = 0.500429\tKL_Divergence = 4.073227\n",
      "Epoch: 28\tFidelity = 0.500493\tKL_Divergence = 3.995219\n",
      "Epoch: 29\tFidelity = 0.500434\tKL_Divergence = 4.066852\n",
      "Epoch: 30\tFidelity = 0.500482\tKL_Divergence = 4.008553\n",
      "Epoch: 31\tFidelity = 0.500354\tKL_Divergence = 4.180411\n",
      "Epoch: 32\tFidelity = 0.500609\tKL_Divergence = 3.878179\n",
      "Epoch: 33\tFidelity = 0.500501\tKL_Divergence = 3.985978\n",
      "Epoch: 34\tFidelity = 0.500496\tKL_Divergence = 3.992590\n",
      "Epoch: 35\tFidelity = 0.500357\tKL_Divergence = 4.175320\n",
      "Epoch: 36\tFidelity = 0.500419\tKL_Divergence = 4.086773\n",
      "Epoch: 37\tFidelity = 0.500480\tKL_Divergence = 4.012017\n",
      "Epoch: 38\tFidelity = 0.500440\tKL_Divergence = 4.059925\n",
      "Epoch: 39\tFidelity = 0.500361\tKL_Divergence = 4.170004\n",
      "Epoch: 40\tFidelity = 0.500570\tKL_Divergence = 3.916126\n",
      "Epoch: 41\tFidelity = 0.500457\tKL_Divergence = 4.039153\n",
      "Epoch: 42\tFidelity = 0.500405\tKL_Divergence = 4.106655\n",
      "Epoch: 43\tFidelity = 0.500489\tKL_Divergence = 4.001177\n",
      "Epoch: 44\tFidelity = 0.500454\tKL_Divergence = 4.042628\n",
      "Epoch: 45\tFidelity = 0.500541\tKL_Divergence = 3.945314\n",
      "Epoch: 46\tFidelity = 0.500351\tKL_Divergence = 4.184917\n",
      "Epoch: 47\tFidelity = 0.500518\tKL_Divergence = 3.969420\n",
      "Epoch: 48\tFidelity = 0.500415\tKL_Divergence = 4.092671\n",
      "Epoch: 49\tFidelity = 0.500514\tKL_Divergence = 3.974127\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:20:16,103] Trial 515 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500432\tKL_Divergence = 4.070937\n",
      "Total time elapsed during training: 45.924 s\n",
      "Trial 515 pruned. \n",
      "Epoch: 1\tFidelity = 0.500430\tKL_Divergence = 4.072570\n",
      "Epoch: 2\tFidelity = 0.500447\tKL_Divergence = 4.051595\n",
      "Epoch: 3\tFidelity = 0.500494\tKL_Divergence = 3.996070\n",
      "Epoch: 4\tFidelity = 0.500462\tKL_Divergence = 4.032484\n",
      "Epoch: 5\tFidelity = 0.500431\tKL_Divergence = 4.071802\n",
      "Epoch: 6\tFidelity = 0.500440\tKL_Divergence = 4.060345\n",
      "Epoch: 7\tFidelity = 0.500404\tKL_Divergence = 4.106373\n",
      "Epoch: 8\tFidelity = 0.500400\tKL_Divergence = 4.112831\n",
      "Epoch: 9\tFidelity = 0.500436\tKL_Divergence = 4.065175\n",
      "Epoch: 10\tFidelity = 0.500462\tKL_Divergence = 4.032299\n",
      "Epoch: 11\tFidelity = 0.500497\tKL_Divergence = 3.992164\n",
      "Epoch: 12\tFidelity = 0.500454\tKL_Divergence = 4.043191\n",
      "Epoch: 13\tFidelity = 0.500462\tKL_Divergence = 4.032951\n",
      "Epoch: 14\tFidelity = 0.500427\tKL_Divergence = 4.076383\n",
      "Epoch: 15\tFidelity = 0.500392\tKL_Divergence = 4.124978\n",
      "Epoch: 16\tFidelity = 0.500416\tKL_Divergence = 4.090792\n",
      "Epoch: 17\tFidelity = 0.500400\tKL_Divergence = 4.113627\n",
      "Epoch: 18\tFidelity = 0.500445\tKL_Divergence = 4.053882\n",
      "Epoch: 19\tFidelity = 0.500439\tKL_Divergence = 4.061546\n",
      "Epoch: 20\tFidelity = 0.500432\tKL_Divergence = 4.069800\n",
      "Epoch: 21\tFidelity = 0.500398\tKL_Divergence = 4.116319\n",
      "Epoch: 22\tFidelity = 0.500449\tKL_Divergence = 4.048492\n",
      "Epoch: 23\tFidelity = 0.500407\tKL_Divergence = 4.103686\n",
      "Epoch: 24\tFidelity = 0.500459\tKL_Divergence = 4.036790\n",
      "Epoch: 25\tFidelity = 0.500487\tKL_Divergence = 4.003762\n",
      "Epoch: 26\tFidelity = 0.500496\tKL_Divergence = 3.993657\n",
      "Epoch: 27\tFidelity = 0.500418\tKL_Divergence = 4.088521\n",
      "Epoch: 28\tFidelity = 0.500421\tKL_Divergence = 4.085101\n",
      "Epoch: 29\tFidelity = 0.500421\tKL_Divergence = 4.085209\n",
      "Epoch: 30\tFidelity = 0.500414\tKL_Divergence = 4.094253\n",
      "Epoch: 31\tFidelity = 0.500427\tKL_Divergence = 4.076612\n",
      "Epoch: 32\tFidelity = 0.500420\tKL_Divergence = 4.086326\n",
      "Epoch: 33\tFidelity = 0.500464\tKL_Divergence = 4.030554\n",
      "Epoch: 34\tFidelity = 0.500427\tKL_Divergence = 4.076385\n",
      "Epoch: 35\tFidelity = 0.500458\tKL_Divergence = 4.037803\n",
      "Epoch: 36\tFidelity = 0.500483\tKL_Divergence = 4.008801\n",
      "Epoch: 37\tFidelity = 0.500429\tKL_Divergence = 4.074721\n",
      "Epoch: 38\tFidelity = 0.500452\tKL_Divergence = 4.045272\n",
      "Epoch: 39\tFidelity = 0.500453\tKL_Divergence = 4.043588\n",
      "Epoch: 40\tFidelity = 0.500407\tKL_Divergence = 4.103602\n",
      "Epoch: 41\tFidelity = 0.500378\tKL_Divergence = 4.145104\n",
      "Epoch: 42\tFidelity = 0.500431\tKL_Divergence = 4.071085\n",
      "Epoch: 43\tFidelity = 0.500453\tKL_Divergence = 4.043656\n",
      "Epoch: 44\tFidelity = 0.500428\tKL_Divergence = 4.075871\n",
      "Epoch: 45\tFidelity = 0.500414\tKL_Divergence = 4.093668\n",
      "Epoch: 46\tFidelity = 0.500400\tKL_Divergence = 4.112445\n",
      "Epoch: 47\tFidelity = 0.500427\tKL_Divergence = 4.076684\n",
      "Epoch: 48\tFidelity = 0.500416\tKL_Divergence = 4.090830\n",
      "Epoch: 49\tFidelity = 0.500416\tKL_Divergence = 4.091158\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:20:55,253] Trial 516 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500399\tKL_Divergence = 4.114906\n",
      "Total time elapsed during training: 38.968 s\n",
      "Trial 516 pruned. \n",
      "Epoch: 1\tFidelity = 0.500490\tKL_Divergence = 4.000628\n",
      "Epoch: 2\tFidelity = 0.500364\tKL_Divergence = 4.164923\n",
      "Epoch: 3\tFidelity = 0.500617\tKL_Divergence = 3.872587\n",
      "Epoch: 4\tFidelity = 0.500337\tKL_Divergence = 4.208461\n",
      "Epoch: 5\tFidelity = 0.500353\tKL_Divergence = 4.182354\n",
      "Epoch: 6\tFidelity = 0.500546\tKL_Divergence = 3.940069\n",
      "Epoch: 7\tFidelity = 0.500420\tKL_Divergence = 4.085323\n",
      "Epoch: 8\tFidelity = 0.500549\tKL_Divergence = 3.937208\n",
      "Epoch: 9\tFidelity = 0.500569\tKL_Divergence = 3.917822\n",
      "Epoch: 10\tFidelity = 0.500493\tKL_Divergence = 3.997228\n",
      "Epoch: 11\tFidelity = 0.500495\tKL_Divergence = 3.994774\n",
      "Epoch: 12\tFidelity = 0.500537\tKL_Divergence = 3.949837\n",
      "Epoch: 13\tFidelity = 0.500438\tKL_Divergence = 4.062986\n",
      "Epoch: 14\tFidelity = 0.500484\tKL_Divergence = 4.006873\n",
      "Epoch: 15\tFidelity = 0.500510\tKL_Divergence = 3.978653\n",
      "Epoch: 16\tFidelity = 0.500472\tKL_Divergence = 4.021613\n",
      "Epoch: 17\tFidelity = 0.500506\tKL_Divergence = 3.982867\n",
      "Epoch: 18\tFidelity = 0.500406\tKL_Divergence = 4.104376\n",
      "Epoch: 19\tFidelity = 0.500424\tKL_Divergence = 4.081030\n",
      "Epoch: 20\tFidelity = 0.500506\tKL_Divergence = 3.982826\n",
      "Epoch: 21\tFidelity = 0.500498\tKL_Divergence = 3.991152\n",
      "Epoch: 22\tFidelity = 0.500452\tKL_Divergence = 4.045197\n",
      "Epoch: 23\tFidelity = 0.500363\tKL_Divergence = 4.166546\n",
      "Epoch: 24\tFidelity = 0.500375\tKL_Divergence = 4.148798\n",
      "Epoch: 25\tFidelity = 0.500429\tKL_Divergence = 4.074321\n",
      "Epoch: 26\tFidelity = 0.500477\tKL_Divergence = 4.015535\n",
      "Epoch: 27\tFidelity = 0.500364\tKL_Divergence = 4.164830\n",
      "Epoch: 28\tFidelity = 0.500453\tKL_Divergence = 4.044263\n",
      "Epoch: 29\tFidelity = 0.500484\tKL_Divergence = 4.007754\n",
      "Epoch: 30\tFidelity = 0.500404\tKL_Divergence = 4.107210\n",
      "Epoch: 31\tFidelity = 0.500428\tKL_Divergence = 4.074913\n",
      "Epoch: 32\tFidelity = 0.500470\tKL_Divergence = 4.023338\n",
      "Epoch: 33\tFidelity = 0.500461\tKL_Divergence = 4.033909\n",
      "Epoch: 34\tFidelity = 0.500459\tKL_Divergence = 4.036500\n",
      "Epoch: 35\tFidelity = 0.500435\tKL_Divergence = 4.066057\n",
      "Epoch: 36\tFidelity = 0.500435\tKL_Divergence = 4.066329\n",
      "Epoch: 37\tFidelity = 0.500388\tKL_Divergence = 4.130277\n",
      "Epoch: 38\tFidelity = 0.500494\tKL_Divergence = 3.995392\n",
      "Epoch: 39\tFidelity = 0.500357\tKL_Divergence = 4.176026\n",
      "Epoch: 40\tFidelity = 0.500488\tKL_Divergence = 4.002366\n",
      "Epoch: 41\tFidelity = 0.500468\tKL_Divergence = 4.025887\n",
      "Epoch: 42\tFidelity = 0.500432\tKL_Divergence = 4.070275\n",
      "Epoch: 43\tFidelity = 0.500450\tKL_Divergence = 4.047772\n",
      "Epoch: 44\tFidelity = 0.500483\tKL_Divergence = 4.008500\n",
      "Epoch: 45\tFidelity = 0.500398\tKL_Divergence = 4.115691\n",
      "Epoch: 46\tFidelity = 0.500440\tKL_Divergence = 4.059480\n",
      "Epoch: 47\tFidelity = 0.500530\tKL_Divergence = 3.956984\n",
      "Epoch: 48\tFidelity = 0.500418\tKL_Divergence = 4.088796\n",
      "Epoch: 49\tFidelity = 0.500464\tKL_Divergence = 4.030833\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:21:41,925] Trial 517 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500547\tKL_Divergence = 3.939521\n",
      "Total time elapsed during training: 46.480 s\n",
      "Trial 517 pruned. \n",
      "Epoch: 1\tFidelity = 0.500447\tKL_Divergence = 4.051486\n",
      "Epoch: 2\tFidelity = 0.500477\tKL_Divergence = 4.015368\n",
      "Epoch: 3\tFidelity = 0.500420\tKL_Divergence = 4.085632\n",
      "Epoch: 4\tFidelity = 0.500460\tKL_Divergence = 4.034913\n",
      "Epoch: 5\tFidelity = 0.500519\tKL_Divergence = 3.967964\n",
      "Epoch: 6\tFidelity = 0.500491\tKL_Divergence = 3.999502\n",
      "Epoch: 7\tFidelity = 0.500483\tKL_Divergence = 4.008584\n",
      "Epoch: 8\tFidelity = 0.500469\tKL_Divergence = 4.024756\n",
      "Epoch: 9\tFidelity = 0.500543\tKL_Divergence = 3.942862\n",
      "Epoch: 10\tFidelity = 0.500441\tKL_Divergence = 4.059209\n",
      "Epoch: 11\tFidelity = 0.500438\tKL_Divergence = 4.062613\n",
      "Epoch: 12\tFidelity = 0.500403\tKL_Divergence = 4.108674\n",
      "Epoch: 13\tFidelity = 0.500510\tKL_Divergence = 3.978299\n",
      "Epoch: 14\tFidelity = 0.500497\tKL_Divergence = 3.992218\n",
      "Epoch: 15\tFidelity = 0.500428\tKL_Divergence = 4.074951\n",
      "Epoch: 16\tFidelity = 0.500423\tKL_Divergence = 4.082427\n",
      "Epoch: 17\tFidelity = 0.500423\tKL_Divergence = 4.081420\n",
      "Epoch: 18\tFidelity = 0.500437\tKL_Divergence = 4.063945\n",
      "Epoch: 19\tFidelity = 0.500426\tKL_Divergence = 4.077695\n",
      "Epoch: 20\tFidelity = 0.500503\tKL_Divergence = 3.985656\n",
      "Epoch: 21\tFidelity = 0.500541\tKL_Divergence = 3.945567\n",
      "Epoch: 22\tFidelity = 0.500446\tKL_Divergence = 4.052148\n",
      "Epoch: 23\tFidelity = 0.500506\tKL_Divergence = 3.981993\n",
      "Epoch: 24\tFidelity = 0.500437\tKL_Divergence = 4.063981\n",
      "Epoch: 25\tFidelity = 0.500581\tKL_Divergence = 3.905527\n",
      "Epoch: 26\tFidelity = 0.500565\tKL_Divergence = 3.921404\n",
      "Epoch: 27\tFidelity = 0.500400\tKL_Divergence = 4.113251\n",
      "Epoch: 28\tFidelity = 0.500447\tKL_Divergence = 4.051216\n",
      "Epoch: 29\tFidelity = 0.500579\tKL_Divergence = 3.907759\n",
      "Epoch: 30\tFidelity = 0.500464\tKL_Divergence = 4.030343\n",
      "Epoch: 31\tFidelity = 0.500487\tKL_Divergence = 4.003400\n",
      "Epoch: 32\tFidelity = 0.500581\tKL_Divergence = 3.905453\n",
      "Epoch: 33\tFidelity = 0.500503\tKL_Divergence = 3.985701\n",
      "Epoch: 34\tFidelity = 0.500470\tKL_Divergence = 4.023314\n",
      "Epoch: 35\tFidelity = 0.500534\tKL_Divergence = 3.953013\n",
      "Epoch: 36\tFidelity = 0.500553\tKL_Divergence = 3.933577\n",
      "Epoch: 37\tFidelity = 0.500454\tKL_Divergence = 4.042391\n",
      "Epoch: 38\tFidelity = 0.500479\tKL_Divergence = 4.012409\n",
      "Epoch: 39\tFidelity = 0.500530\tKL_Divergence = 3.956939\n",
      "Epoch: 40\tFidelity = 0.500443\tKL_Divergence = 4.055824\n",
      "Epoch: 41\tFidelity = 0.500531\tKL_Divergence = 3.955040\n",
      "Epoch: 42\tFidelity = 0.500547\tKL_Divergence = 3.939547\n",
      "Epoch: 43\tFidelity = 0.500462\tKL_Divergence = 4.033087\n",
      "Epoch: 44\tFidelity = 0.500421\tKL_Divergence = 4.084401\n",
      "Epoch: 45\tFidelity = 0.500507\tKL_Divergence = 3.981095\n",
      "Epoch: 46\tFidelity = 0.500430\tKL_Divergence = 4.072491\n",
      "Epoch: 47\tFidelity = 0.500516\tKL_Divergence = 3.971558\n",
      "Epoch: 48\tFidelity = 0.500553\tKL_Divergence = 3.933318\n",
      "Epoch: 49\tFidelity = 0.500426\tKL_Divergence = 4.077189\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:23:05,860] Trial 518 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500531\tKL_Divergence = 3.955577\n",
      "Total time elapsed during training: 83.741 s\n",
      "Trial 518 pruned. \n",
      "Epoch: 1\tFidelity = 0.500490\tKL_Divergence = 3.999805\n",
      "Epoch: 2\tFidelity = 0.500515\tKL_Divergence = 3.972417\n",
      "Epoch: 3\tFidelity = 0.500487\tKL_Divergence = 4.003728\n",
      "Epoch: 4\tFidelity = 0.500519\tKL_Divergence = 3.967895\n",
      "Epoch: 5\tFidelity = 0.500480\tKL_Divergence = 4.011365\n",
      "Epoch: 6\tFidelity = 0.500528\tKL_Divergence = 3.958367\n",
      "Epoch: 7\tFidelity = 0.500470\tKL_Divergence = 4.022612\n",
      "Epoch: 8\tFidelity = 0.500556\tKL_Divergence = 3.930034\n",
      "Epoch: 9\tFidelity = 0.500485\tKL_Divergence = 4.005646\n",
      "Epoch: 10\tFidelity = 0.500552\tKL_Divergence = 3.933738\n",
      "Epoch: 11\tFidelity = 0.500552\tKL_Divergence = 3.934157\n",
      "Epoch: 12\tFidelity = 0.500496\tKL_Divergence = 3.993819\n",
      "Epoch: 13\tFidelity = 0.500495\tKL_Divergence = 3.994814\n",
      "Epoch: 14\tFidelity = 0.500515\tKL_Divergence = 3.972210\n",
      "Epoch: 15\tFidelity = 0.500532\tKL_Divergence = 3.954811\n",
      "Epoch: 16\tFidelity = 0.500519\tKL_Divergence = 3.968111\n",
      "Epoch: 17\tFidelity = 0.500475\tKL_Divergence = 4.017283\n",
      "Epoch: 18\tFidelity = 0.500518\tKL_Divergence = 3.969242\n",
      "Epoch: 19\tFidelity = 0.500526\tKL_Divergence = 3.960978\n",
      "Epoch: 20\tFidelity = 0.500500\tKL_Divergence = 3.989242\n",
      "Epoch: 21\tFidelity = 0.500518\tKL_Divergence = 3.968668\n",
      "Epoch: 22\tFidelity = 0.500513\tKL_Divergence = 3.974266\n",
      "Epoch: 23\tFidelity = 0.500556\tKL_Divergence = 3.929730\n",
      "Epoch: 24\tFidelity = 0.500499\tKL_Divergence = 3.989746\n",
      "Epoch: 25\tFidelity = 0.500573\tKL_Divergence = 3.912972\n",
      "Epoch: 26\tFidelity = 0.500574\tKL_Divergence = 3.912502\n",
      "Epoch: 27\tFidelity = 0.500464\tKL_Divergence = 4.030560\n",
      "Epoch: 28\tFidelity = 0.500447\tKL_Divergence = 4.050382\n",
      "Epoch: 29\tFidelity = 0.500518\tKL_Divergence = 3.968848\n",
      "Epoch: 30\tFidelity = 0.500536\tKL_Divergence = 3.950279\n",
      "Epoch: 31\tFidelity = 0.500498\tKL_Divergence = 3.990511\n",
      "Epoch: 32\tFidelity = 0.500498\tKL_Divergence = 3.991576\n",
      "Epoch: 33\tFidelity = 0.500542\tKL_Divergence = 3.944444\n",
      "Epoch: 34\tFidelity = 0.500557\tKL_Divergence = 3.929119\n",
      "Epoch: 35\tFidelity = 0.500485\tKL_Divergence = 4.005549\n",
      "Epoch: 36\tFidelity = 0.500480\tKL_Divergence = 4.011941\n",
      "Epoch: 37\tFidelity = 0.500516\tKL_Divergence = 3.971804\n",
      "Epoch: 38\tFidelity = 0.500488\tKL_Divergence = 4.001924\n",
      "Epoch: 39\tFidelity = 0.500545\tKL_Divergence = 3.941015\n",
      "Epoch: 40\tFidelity = 0.500563\tKL_Divergence = 3.923004\n",
      "Epoch: 41\tFidelity = 0.500496\tKL_Divergence = 3.993551\n",
      "Epoch: 42\tFidelity = 0.500581\tKL_Divergence = 3.905667\n",
      "Epoch: 43\tFidelity = 0.500473\tKL_Divergence = 4.019484\n",
      "Epoch: 44\tFidelity = 0.500480\tKL_Divergence = 4.011236\n",
      "Epoch: 45\tFidelity = 0.500505\tKL_Divergence = 3.983118\n",
      "Epoch: 46\tFidelity = 0.500462\tKL_Divergence = 4.033000\n",
      "Epoch: 47\tFidelity = 0.500473\tKL_Divergence = 4.019864\n",
      "Epoch: 48\tFidelity = 0.500547\tKL_Divergence = 3.938913\n",
      "Epoch: 49\tFidelity = 0.500442\tKL_Divergence = 4.057563\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:23:45,395] Trial 519 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500459\tKL_Divergence = 4.035642\n",
      "Total time elapsed during training: 39.350 s\n",
      "Trial 519 pruned. \n",
      "Epoch: 1\tFidelity = 0.500508\tKL_Divergence = 3.979671\n",
      "Epoch: 2\tFidelity = 0.500475\tKL_Divergence = 4.017470\n",
      "Epoch: 3\tFidelity = 0.500519\tKL_Divergence = 3.967646\n",
      "Epoch: 4\tFidelity = 0.500465\tKL_Divergence = 4.028510\n",
      "Epoch: 5\tFidelity = 0.500518\tKL_Divergence = 3.969154\n",
      "Epoch: 6\tFidelity = 0.500510\tKL_Divergence = 3.978432\n",
      "Epoch: 7\tFidelity = 0.500488\tKL_Divergence = 4.001882\n",
      "Epoch: 8\tFidelity = 0.500509\tKL_Divergence = 3.978776\n",
      "Epoch: 9\tFidelity = 0.500547\tKL_Divergence = 3.938454\n",
      "Epoch: 10\tFidelity = 0.500542\tKL_Divergence = 3.943866\n",
      "Epoch: 11\tFidelity = 0.500443\tKL_Divergence = 4.056361\n",
      "Epoch: 12\tFidelity = 0.500478\tKL_Divergence = 4.013690\n",
      "Epoch: 13\tFidelity = 0.500563\tKL_Divergence = 3.923295\n",
      "Epoch: 14\tFidelity = 0.500529\tKL_Divergence = 3.956933\n",
      "Epoch: 15\tFidelity = 0.500545\tKL_Divergence = 3.940929\n",
      "Epoch: 16\tFidelity = 0.500493\tKL_Divergence = 3.996741\n",
      "Epoch: 17\tFidelity = 0.500441\tKL_Divergence = 4.059146\n",
      "Epoch: 18\tFidelity = 0.500543\tKL_Divergence = 3.942977\n",
      "Epoch: 19\tFidelity = 0.500525\tKL_Divergence = 3.962307\n",
      "Epoch: 20\tFidelity = 0.500443\tKL_Divergence = 4.055908\n",
      "Epoch: 21\tFidelity = 0.500449\tKL_Divergence = 4.048336\n",
      "Epoch: 22\tFidelity = 0.500493\tKL_Divergence = 3.997201\n",
      "Epoch: 23\tFidelity = 0.500441\tKL_Divergence = 4.058967\n",
      "Epoch: 24\tFidelity = 0.500480\tKL_Divergence = 4.011891\n",
      "Epoch: 25\tFidelity = 0.500406\tKL_Divergence = 4.104519\n",
      "Epoch: 26\tFidelity = 0.500479\tKL_Divergence = 4.012849\n",
      "Epoch: 27\tFidelity = 0.500428\tKL_Divergence = 4.074298\n",
      "Epoch: 28\tFidelity = 0.500541\tKL_Divergence = 3.944977\n",
      "Epoch: 29\tFidelity = 0.500441\tKL_Divergence = 4.058093\n",
      "Epoch: 30\tFidelity = 0.500487\tKL_Divergence = 4.003334\n",
      "Epoch: 31\tFidelity = 0.500465\tKL_Divergence = 4.029301\n",
      "Epoch: 32\tFidelity = 0.500444\tKL_Divergence = 4.055133\n",
      "Epoch: 33\tFidelity = 0.500483\tKL_Divergence = 4.007572\n",
      "Epoch: 34\tFidelity = 0.500537\tKL_Divergence = 3.949476\n",
      "Epoch: 35\tFidelity = 0.500566\tKL_Divergence = 3.920098\n",
      "Epoch: 36\tFidelity = 0.500560\tKL_Divergence = 3.925612\n",
      "Epoch: 37\tFidelity = 0.500566\tKL_Divergence = 3.920005\n",
      "Epoch: 38\tFidelity = 0.500551\tKL_Divergence = 3.934656\n",
      "Epoch: 39\tFidelity = 0.500566\tKL_Divergence = 3.919659\n",
      "Epoch: 40\tFidelity = 0.500527\tKL_Divergence = 3.959978\n",
      "Epoch: 41\tFidelity = 0.500456\tKL_Divergence = 4.040271\n",
      "Epoch: 42\tFidelity = 0.500537\tKL_Divergence = 3.949416\n",
      "Epoch: 43\tFidelity = 0.500492\tKL_Divergence = 3.997805\n",
      "Epoch: 44\tFidelity = 0.500443\tKL_Divergence = 4.055524\n",
      "Epoch: 45\tFidelity = 0.500475\tKL_Divergence = 4.016973\n",
      "Epoch: 46\tFidelity = 0.500490\tKL_Divergence = 4.000293\n",
      "Epoch: 47\tFidelity = 0.500417\tKL_Divergence = 4.089559\n",
      "Epoch: 48\tFidelity = 0.500489\tKL_Divergence = 4.001000\n",
      "Epoch: 49\tFidelity = 0.500563\tKL_Divergence = 3.923189\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:24:24,173] Trial 520 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500567\tKL_Divergence = 3.918615\n",
      "Total time elapsed during training: 38.592 s\n",
      "Trial 520 pruned. \n",
      "Epoch: 1\tFidelity = 0.500509\tKL_Divergence = 3.979262\n",
      "Epoch: 2\tFidelity = 0.500496\tKL_Divergence = 3.993185\n",
      "Epoch: 3\tFidelity = 0.500468\tKL_Divergence = 4.026054\n",
      "Epoch: 4\tFidelity = 0.500505\tKL_Divergence = 3.982869\n",
      "Epoch: 5\tFidelity = 0.500488\tKL_Divergence = 4.002183\n",
      "Epoch: 6\tFidelity = 0.500519\tKL_Divergence = 3.967930\n",
      "Epoch: 7\tFidelity = 0.500539\tKL_Divergence = 3.947302\n",
      "Epoch: 8\tFidelity = 0.500524\tKL_Divergence = 3.962520\n",
      "Epoch: 9\tFidelity = 0.500530\tKL_Divergence = 3.956094\n",
      "Epoch: 10\tFidelity = 0.500476\tKL_Divergence = 4.016000\n",
      "Epoch: 11\tFidelity = 0.500483\tKL_Divergence = 4.007820\n",
      "Epoch: 12\tFidelity = 0.500539\tKL_Divergence = 3.947084\n",
      "Epoch: 13\tFidelity = 0.500518\tKL_Divergence = 3.968911\n",
      "Epoch: 14\tFidelity = 0.500497\tKL_Divergence = 3.992216\n",
      "Epoch: 15\tFidelity = 0.500528\tKL_Divergence = 3.959130\n",
      "Epoch: 16\tFidelity = 0.500491\tKL_Divergence = 3.998929\n",
      "Epoch: 17\tFidelity = 0.500526\tKL_Divergence = 3.960847\n",
      "Epoch: 18\tFidelity = 0.500534\tKL_Divergence = 3.952101\n",
      "Epoch: 19\tFidelity = 0.500500\tKL_Divergence = 3.989120\n",
      "Epoch: 20\tFidelity = 0.500492\tKL_Divergence = 3.997871\n",
      "Epoch: 21\tFidelity = 0.500470\tKL_Divergence = 4.023193\n",
      "Epoch: 22\tFidelity = 0.500579\tKL_Divergence = 3.907532\n",
      "Epoch: 23\tFidelity = 0.500514\tKL_Divergence = 3.973919\n",
      "Epoch: 24\tFidelity = 0.500491\tKL_Divergence = 3.998964\n",
      "Epoch: 25\tFidelity = 0.500487\tKL_Divergence = 4.003865\n",
      "Epoch: 26\tFidelity = 0.500524\tKL_Divergence = 3.962578\n",
      "Epoch: 27\tFidelity = 0.500526\tKL_Divergence = 3.961130\n",
      "Epoch: 28\tFidelity = 0.500513\tKL_Divergence = 3.974571\n",
      "Epoch: 29\tFidelity = 0.500518\tKL_Divergence = 3.968972\n",
      "Epoch: 30\tFidelity = 0.500519\tKL_Divergence = 3.968373\n",
      "Epoch: 31\tFidelity = 0.500536\tKL_Divergence = 3.950354\n",
      "Epoch: 32\tFidelity = 0.500478\tKL_Divergence = 4.014158\n",
      "Epoch: 33\tFidelity = 0.500490\tKL_Divergence = 3.999893\n",
      "Epoch: 34\tFidelity = 0.500545\tKL_Divergence = 3.941015\n",
      "Epoch: 35\tFidelity = 0.500555\tKL_Divergence = 3.930830\n",
      "Epoch: 36\tFidelity = 0.500537\tKL_Divergence = 3.949516\n",
      "Epoch: 37\tFidelity = 0.500551\tKL_Divergence = 3.935187\n",
      "Epoch: 38\tFidelity = 0.500509\tKL_Divergence = 3.979214\n",
      "Epoch: 39\tFidelity = 0.500504\tKL_Divergence = 3.984003\n",
      "Epoch: 40\tFidelity = 0.500509\tKL_Divergence = 3.979298\n",
      "Epoch: 41\tFidelity = 0.500488\tKL_Divergence = 4.002508\n",
      "Epoch: 42\tFidelity = 0.500545\tKL_Divergence = 3.940797\n",
      "Epoch: 43\tFidelity = 0.500539\tKL_Divergence = 3.947378\n",
      "Epoch: 44\tFidelity = 0.500546\tKL_Divergence = 3.940338\n",
      "Epoch: 45\tFidelity = 0.500515\tKL_Divergence = 3.972527\n",
      "Epoch: 46\tFidelity = 0.500541\tKL_Divergence = 3.945250\n",
      "Epoch: 47\tFidelity = 0.500505\tKL_Divergence = 3.982829\n",
      "Epoch: 48\tFidelity = 0.500562\tKL_Divergence = 3.923806\n",
      "Epoch: 49\tFidelity = 0.500565\tKL_Divergence = 3.921248\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:25:04,007] Trial 521 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500568\tKL_Divergence = 3.918145\n",
      "Total time elapsed during training: 39.651 s\n",
      "Trial 521 pruned. \n",
      "Epoch: 1\tFidelity = 0.500483\tKL_Divergence = 4.008394\n",
      "Epoch: 2\tFidelity = 0.500540\tKL_Divergence = 3.946234\n",
      "Epoch: 3\tFidelity = 0.500613\tKL_Divergence = 3.875886\n",
      "Epoch: 4\tFidelity = 0.500496\tKL_Divergence = 3.993247\n",
      "Epoch: 5\tFidelity = 0.500545\tKL_Divergence = 3.941255\n",
      "Epoch: 6\tFidelity = 0.500548\tKL_Divergence = 3.938189\n",
      "Epoch: 7\tFidelity = 0.500511\tKL_Divergence = 3.976440\n",
      "Epoch: 8\tFidelity = 0.500551\tKL_Divergence = 3.935175\n",
      "Epoch: 9\tFidelity = 0.500473\tKL_Divergence = 4.019411\n",
      "Epoch: 10\tFidelity = 0.500476\tKL_Divergence = 4.015700\n",
      "Epoch: 11\tFidelity = 0.500602\tKL_Divergence = 3.885601\n",
      "Epoch: 12\tFidelity = 0.500550\tKL_Divergence = 3.935780\n",
      "Epoch: 13\tFidelity = 0.500593\tKL_Divergence = 3.894003\n",
      "Epoch: 14\tFidelity = 0.500582\tKL_Divergence = 3.904884\n",
      "Epoch: 15\tFidelity = 0.500475\tKL_Divergence = 4.017551\n",
      "Epoch: 16\tFidelity = 0.500489\tKL_Divergence = 4.001030\n",
      "Epoch: 17\tFidelity = 0.500514\tKL_Divergence = 3.973022\n",
      "Epoch: 18\tFidelity = 0.500489\tKL_Divergence = 4.001594\n",
      "Epoch: 19\tFidelity = 0.500490\tKL_Divergence = 3.999739\n",
      "Epoch: 20\tFidelity = 0.500512\tKL_Divergence = 3.976084\n",
      "Epoch: 21\tFidelity = 0.500523\tKL_Divergence = 3.963690\n",
      "Epoch: 22\tFidelity = 0.500473\tKL_Divergence = 4.019740\n",
      "Epoch: 23\tFidelity = 0.500522\tKL_Divergence = 3.965188\n",
      "Epoch: 24\tFidelity = 0.500470\tKL_Divergence = 4.023684\n",
      "Epoch: 25\tFidelity = 0.500554\tKL_Divergence = 3.931817\n",
      "Epoch: 26\tFidelity = 0.500547\tKL_Divergence = 3.939173\n",
      "Epoch: 27\tFidelity = 0.500482\tKL_Divergence = 4.009333\n",
      "Epoch: 28\tFidelity = 0.500505\tKL_Divergence = 3.983762\n",
      "Epoch: 29\tFidelity = 0.500460\tKL_Divergence = 4.034609\n",
      "Epoch: 30\tFidelity = 0.500548\tKL_Divergence = 3.937832\n",
      "Epoch: 31\tFidelity = 0.500570\tKL_Divergence = 3.915857\n",
      "Epoch: 32\tFidelity = 0.500572\tKL_Divergence = 3.914094\n",
      "Epoch: 33\tFidelity = 0.500545\tKL_Divergence = 3.940762\n",
      "Epoch: 34\tFidelity = 0.500486\tKL_Divergence = 4.004271\n",
      "Epoch: 35\tFidelity = 0.500483\tKL_Divergence = 4.007465\n",
      "Epoch: 36\tFidelity = 0.500502\tKL_Divergence = 3.986451\n",
      "Epoch: 37\tFidelity = 0.500458\tKL_Divergence = 4.037264\n",
      "Epoch: 38\tFidelity = 0.500612\tKL_Divergence = 3.876599\n",
      "Epoch: 39\tFidelity = 0.500551\tKL_Divergence = 3.935078\n",
      "Epoch: 40\tFidelity = 0.500547\tKL_Divergence = 3.939252\n",
      "Epoch: 41\tFidelity = 0.500608\tKL_Divergence = 3.879972\n",
      "Epoch: 42\tFidelity = 0.500564\tKL_Divergence = 3.922363\n",
      "Epoch: 43\tFidelity = 0.500533\tKL_Divergence = 3.953137\n",
      "Epoch: 44\tFidelity = 0.500487\tKL_Divergence = 4.003217\n",
      "Epoch: 45\tFidelity = 0.500481\tKL_Divergence = 4.010895\n",
      "Epoch: 46\tFidelity = 0.500571\tKL_Divergence = 3.915637\n",
      "Epoch: 47\tFidelity = 0.500568\tKL_Divergence = 3.917890\n",
      "Epoch: 48\tFidelity = 0.500549\tKL_Divergence = 3.937488\n",
      "Epoch: 49\tFidelity = 0.500505\tKL_Divergence = 3.983125\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:26:04,580] Trial 522 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500482\tKL_Divergence = 4.008949\n",
      "Total time elapsed during training: 60.393 s\n",
      "Trial 522 pruned. \n",
      "Epoch: 1\tFidelity = 0.500534\tKL_Divergence = 3.952417\n",
      "Epoch: 2\tFidelity = 0.500487\tKL_Divergence = 4.003324\n",
      "Epoch: 3\tFidelity = 0.500481\tKL_Divergence = 4.010828\n",
      "Epoch: 4\tFidelity = 0.500517\tKL_Divergence = 3.969977\n",
      "Epoch: 5\tFidelity = 0.500577\tKL_Divergence = 3.909267\n",
      "Epoch: 6\tFidelity = 0.500496\tKL_Divergence = 3.992893\n",
      "Epoch: 7\tFidelity = 0.500518\tKL_Divergence = 3.968828\n",
      "Epoch: 8\tFidelity = 0.500486\tKL_Divergence = 4.004442\n",
      "Epoch: 9\tFidelity = 0.500510\tKL_Divergence = 3.977628\n",
      "Epoch: 10\tFidelity = 0.500535\tKL_Divergence = 3.951150\n",
      "Epoch: 11\tFidelity = 0.500508\tKL_Divergence = 3.979696\n",
      "Epoch: 12\tFidelity = 0.500558\tKL_Divergence = 3.927872\n",
      "Epoch: 13\tFidelity = 0.500486\tKL_Divergence = 4.004668\n",
      "Epoch: 14\tFidelity = 0.500478\tKL_Divergence = 4.013631\n",
      "Epoch: 15\tFidelity = 0.500542\tKL_Divergence = 3.944024\n",
      "Epoch: 16\tFidelity = 0.500482\tKL_Divergence = 4.009574\n",
      "Epoch: 17\tFidelity = 0.500497\tKL_Divergence = 3.991686\n",
      "Epoch: 18\tFidelity = 0.500547\tKL_Divergence = 3.939390\n",
      "Epoch: 19\tFidelity = 0.500471\tKL_Divergence = 4.022294\n",
      "Epoch: 20\tFidelity = 0.500538\tKL_Divergence = 3.947736\n",
      "Epoch: 21\tFidelity = 0.500517\tKL_Divergence = 3.970149\n",
      "Epoch: 22\tFidelity = 0.500491\tKL_Divergence = 3.999295\n",
      "Epoch: 23\tFidelity = 0.500550\tKL_Divergence = 3.936324\n",
      "Epoch: 24\tFidelity = 0.500509\tKL_Divergence = 3.978590\n",
      "Epoch: 25\tFidelity = 0.500505\tKL_Divergence = 3.983225\n",
      "Epoch: 26\tFidelity = 0.500561\tKL_Divergence = 3.924852\n",
      "Epoch: 27\tFidelity = 0.500465\tKL_Divergence = 4.028588\n",
      "Epoch: 28\tFidelity = 0.500539\tKL_Divergence = 3.947293\n",
      "Epoch: 29\tFidelity = 0.500546\tKL_Divergence = 3.940237\n",
      "Epoch: 30\tFidelity = 0.500466\tKL_Divergence = 4.027874\n",
      "Epoch: 31\tFidelity = 0.500559\tKL_Divergence = 3.926672\n",
      "Epoch: 32\tFidelity = 0.500468\tKL_Divergence = 4.025485\n",
      "Epoch: 33\tFidelity = 0.500574\tKL_Divergence = 3.911810\n",
      "Epoch: 34\tFidelity = 0.500522\tKL_Divergence = 3.965322\n",
      "Epoch: 35\tFidelity = 0.500482\tKL_Divergence = 4.009377\n",
      "Epoch: 36\tFidelity = 0.500555\tKL_Divergence = 3.931324\n",
      "Epoch: 37\tFidelity = 0.500473\tKL_Divergence = 4.019326\n",
      "Epoch: 38\tFidelity = 0.500568\tKL_Divergence = 3.917841\n",
      "Epoch: 39\tFidelity = 0.500470\tKL_Divergence = 4.023648\n",
      "Epoch: 40\tFidelity = 0.500547\tKL_Divergence = 3.939149\n",
      "Epoch: 41\tFidelity = 0.500506\tKL_Divergence = 3.981729\n",
      "Epoch: 42\tFidelity = 0.500534\tKL_Divergence = 3.952116\n",
      "Epoch: 43\tFidelity = 0.500545\tKL_Divergence = 3.941453\n",
      "Epoch: 44\tFidelity = 0.500469\tKL_Divergence = 4.024354\n",
      "Epoch: 45\tFidelity = 0.500518\tKL_Divergence = 3.968917\n",
      "Epoch: 46\tFidelity = 0.500486\tKL_Divergence = 4.004615\n",
      "Epoch: 47\tFidelity = 0.500503\tKL_Divergence = 3.985992\n",
      "Epoch: 48\tFidelity = 0.500516\tKL_Divergence = 3.971322\n",
      "Epoch: 49\tFidelity = 0.500507\tKL_Divergence = 3.981110\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:26:37,703] Trial 523 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500551\tKL_Divergence = 3.934626\n",
      "Total time elapsed during training: 32.950 s\n",
      "Trial 523 pruned. \n",
      "Epoch: 1\tFidelity = 0.500460\tKL_Divergence = 4.035669\n",
      "Epoch: 2\tFidelity = 0.500543\tKL_Divergence = 3.943138\n",
      "Epoch: 3\tFidelity = 0.500485\tKL_Divergence = 4.006128\n",
      "Epoch: 4\tFidelity = 0.500532\tKL_Divergence = 3.954252\n",
      "Epoch: 5\tFidelity = 0.500442\tKL_Divergence = 4.057448\n",
      "Epoch: 6\tFidelity = 0.500486\tKL_Divergence = 4.004924\n",
      "Epoch: 7\tFidelity = 0.500584\tKL_Divergence = 3.902845\n",
      "Epoch: 8\tFidelity = 0.500510\tKL_Divergence = 3.978326\n",
      "Epoch: 9\tFidelity = 0.500492\tKL_Divergence = 3.998219\n",
      "Epoch: 10\tFidelity = 0.500532\tKL_Divergence = 3.954901\n",
      "Epoch: 11\tFidelity = 0.500542\tKL_Divergence = 3.944341\n",
      "Epoch: 12\tFidelity = 0.500548\tKL_Divergence = 3.937804\n",
      "Epoch: 13\tFidelity = 0.500498\tKL_Divergence = 3.991499\n",
      "Epoch: 14\tFidelity = 0.500606\tKL_Divergence = 3.882305\n",
      "Epoch: 15\tFidelity = 0.500635\tKL_Divergence = 3.855880\n",
      "Epoch: 16\tFidelity = 0.500499\tKL_Divergence = 3.990201\n",
      "Epoch: 17\tFidelity = 0.500489\tKL_Divergence = 4.001479\n",
      "Epoch: 18\tFidelity = 0.500475\tKL_Divergence = 4.017702\n",
      "Epoch: 19\tFidelity = 0.500547\tKL_Divergence = 3.939047\n",
      "Epoch: 20\tFidelity = 0.500422\tKL_Divergence = 4.082792\n",
      "Epoch: 21\tFidelity = 0.500526\tKL_Divergence = 3.960697\n",
      "Epoch: 22\tFidelity = 0.500432\tKL_Divergence = 4.070054\n",
      "Epoch: 23\tFidelity = 0.500538\tKL_Divergence = 3.947989\n",
      "Epoch: 24\tFidelity = 0.500540\tKL_Divergence = 3.945771\n",
      "Epoch: 25\tFidelity = 0.500502\tKL_Divergence = 3.986262\n",
      "Epoch: 26\tFidelity = 0.500433\tKL_Divergence = 4.068012\n",
      "Epoch: 27\tFidelity = 0.500590\tKL_Divergence = 3.896521\n",
      "Epoch: 28\tFidelity = 0.500502\tKL_Divergence = 3.986583\n",
      "Epoch: 29\tFidelity = 0.500429\tKL_Divergence = 4.074021\n",
      "Epoch: 30\tFidelity = 0.500527\tKL_Divergence = 3.959456\n",
      "Epoch: 31\tFidelity = 0.500478\tKL_Divergence = 4.013660\n",
      "Epoch: 32\tFidelity = 0.500612\tKL_Divergence = 3.876459\n",
      "Epoch: 33\tFidelity = 0.500498\tKL_Divergence = 3.990928\n",
      "Epoch: 34\tFidelity = 0.500550\tKL_Divergence = 3.936323\n",
      "Epoch: 35\tFidelity = 0.500581\tKL_Divergence = 3.905666\n",
      "Epoch: 36\tFidelity = 0.500533\tKL_Divergence = 3.953472\n",
      "Epoch: 37\tFidelity = 0.500545\tKL_Divergence = 3.940571\n",
      "Epoch: 38\tFidelity = 0.500557\tKL_Divergence = 3.928662\n",
      "Epoch: 39\tFidelity = 0.500605\tKL_Divergence = 3.882926\n",
      "Epoch: 40\tFidelity = 0.500498\tKL_Divergence = 3.990666\n",
      "Epoch: 41\tFidelity = 0.500491\tKL_Divergence = 3.998692\n",
      "Epoch: 42\tFidelity = 0.500537\tKL_Divergence = 3.949505\n",
      "Epoch: 43\tFidelity = 0.500539\tKL_Divergence = 3.946931\n",
      "Epoch: 44\tFidelity = 0.500442\tKL_Divergence = 4.056919\n",
      "Epoch: 45\tFidelity = 0.500503\tKL_Divergence = 3.985012\n",
      "Epoch: 46\tFidelity = 0.500478\tKL_Divergence = 4.014278\n",
      "Epoch: 47\tFidelity = 0.500518\tKL_Divergence = 3.968690\n",
      "Epoch: 48\tFidelity = 0.500597\tKL_Divergence = 3.890116\n",
      "Epoch: 49\tFidelity = 0.500438\tKL_Divergence = 4.061604\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:27:10,948] Trial 524 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500493\tKL_Divergence = 3.996590\n",
      "Total time elapsed during training: 33.061 s\n",
      "Trial 524 pruned. \n",
      "Epoch: 1\tFidelity = 0.500565\tKL_Divergence = 3.920773\n",
      "Epoch: 2\tFidelity = 0.500516\tKL_Divergence = 3.971124\n",
      "Epoch: 3\tFidelity = 0.500498\tKL_Divergence = 3.991544\n",
      "Epoch: 4\tFidelity = 0.500502\tKL_Divergence = 3.987014\n",
      "Epoch: 5\tFidelity = 0.500518\tKL_Divergence = 3.969378\n",
      "Epoch: 6\tFidelity = 0.500559\tKL_Divergence = 3.926643\n",
      "Epoch: 7\tFidelity = 0.500526\tKL_Divergence = 3.960739\n",
      "Epoch: 8\tFidelity = 0.500545\tKL_Divergence = 3.940660\n",
      "Epoch: 9\tFidelity = 0.500463\tKL_Divergence = 4.031688\n",
      "Epoch: 10\tFidelity = 0.500523\tKL_Divergence = 3.963550\n",
      "Epoch: 11\tFidelity = 0.500503\tKL_Divergence = 3.985583\n",
      "Epoch: 12\tFidelity = 0.500548\tKL_Divergence = 3.937974\n",
      "Epoch: 13\tFidelity = 0.500483\tKL_Divergence = 4.008300\n",
      "Epoch: 14\tFidelity = 0.500540\tKL_Divergence = 3.945815\n",
      "Epoch: 15\tFidelity = 0.500517\tKL_Divergence = 3.970071\n",
      "Epoch: 16\tFidelity = 0.500570\tKL_Divergence = 3.916466\n",
      "Epoch: 17\tFidelity = 0.500529\tKL_Divergence = 3.957131\n",
      "Epoch: 18\tFidelity = 0.500558\tKL_Divergence = 3.927860\n",
      "Epoch: 19\tFidelity = 0.500533\tKL_Divergence = 3.953620\n",
      "Epoch: 20\tFidelity = 0.500489\tKL_Divergence = 4.001353\n",
      "Epoch: 21\tFidelity = 0.500509\tKL_Divergence = 3.979008\n",
      "Epoch: 22\tFidelity = 0.500557\tKL_Divergence = 3.929300\n",
      "Epoch: 23\tFidelity = 0.500518\tKL_Divergence = 3.968685\n",
      "Epoch: 24\tFidelity = 0.500480\tKL_Divergence = 4.010936\n",
      "Epoch: 25\tFidelity = 0.500532\tKL_Divergence = 3.954048\n",
      "Epoch: 26\tFidelity = 0.500553\tKL_Divergence = 3.932796\n",
      "Epoch: 27\tFidelity = 0.500500\tKL_Divergence = 3.988946\n",
      "Epoch: 28\tFidelity = 0.500490\tKL_Divergence = 3.999609\n",
      "Epoch: 29\tFidelity = 0.500541\tKL_Divergence = 3.944751\n",
      "Epoch: 30\tFidelity = 0.500491\tKL_Divergence = 3.999170\n",
      "Epoch: 31\tFidelity = 0.500493\tKL_Divergence = 3.996800\n",
      "Epoch: 32\tFidelity = 0.500515\tKL_Divergence = 3.972310\n",
      "Epoch: 33\tFidelity = 0.500512\tKL_Divergence = 3.976177\n",
      "Epoch: 34\tFidelity = 0.500589\tKL_Divergence = 3.898042\n",
      "Epoch: 35\tFidelity = 0.500499\tKL_Divergence = 3.989390\n",
      "Epoch: 36\tFidelity = 0.500510\tKL_Divergence = 3.978207\n",
      "Epoch: 37\tFidelity = 0.500537\tKL_Divergence = 3.949171\n",
      "Epoch: 38\tFidelity = 0.500533\tKL_Divergence = 3.953791\n",
      "Epoch: 39\tFidelity = 0.500519\tKL_Divergence = 3.968521\n",
      "Epoch: 40\tFidelity = 0.500494\tKL_Divergence = 3.995120\n",
      "Epoch: 41\tFidelity = 0.500550\tKL_Divergence = 3.935748\n",
      "Epoch: 42\tFidelity = 0.500521\tKL_Divergence = 3.966313\n",
      "Epoch: 43\tFidelity = 0.500549\tKL_Divergence = 3.936968\n",
      "Epoch: 44\tFidelity = 0.500544\tKL_Divergence = 3.942080\n",
      "Epoch: 45\tFidelity = 0.500516\tKL_Divergence = 3.971096\n",
      "Epoch: 46\tFidelity = 0.500505\tKL_Divergence = 3.983770\n",
      "Epoch: 47\tFidelity = 0.500489\tKL_Divergence = 4.001075\n",
      "Epoch: 48\tFidelity = 0.500479\tKL_Divergence = 4.012492\n",
      "Epoch: 49\tFidelity = 0.500499\tKL_Divergence = 3.989892\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:28:35,810] Trial 525 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500476\tKL_Divergence = 4.016030\n",
      "Total time elapsed during training: 84.679 s\n",
      "Trial 525 pruned. \n",
      "Epoch: 1\tFidelity = 0.500552\tKL_Divergence = 3.934122\n",
      "Epoch: 2\tFidelity = 0.500559\tKL_Divergence = 3.926741\n",
      "Epoch: 3\tFidelity = 0.500578\tKL_Divergence = 3.908364\n",
      "Epoch: 4\tFidelity = 0.500471\tKL_Divergence = 4.021718\n",
      "Epoch: 5\tFidelity = 0.500587\tKL_Divergence = 3.900065\n",
      "Epoch: 6\tFidelity = 0.500426\tKL_Divergence = 4.078257\n",
      "Epoch: 7\tFidelity = 0.500430\tKL_Divergence = 4.072435\n",
      "Epoch: 8\tFidelity = 0.500542\tKL_Divergence = 3.944078\n",
      "Epoch: 9\tFidelity = 0.500650\tKL_Divergence = 3.843312\n",
      "Epoch: 10\tFidelity = 0.500456\tKL_Divergence = 4.040202\n",
      "Epoch: 11\tFidelity = 0.500610\tKL_Divergence = 3.878107\n",
      "Epoch: 12\tFidelity = 0.500496\tKL_Divergence = 3.992871\n",
      "Epoch: 13\tFidelity = 0.500424\tKL_Divergence = 4.079703\n",
      "Epoch: 14\tFidelity = 0.500600\tKL_Divergence = 3.887873\n",
      "Epoch: 15\tFidelity = 0.500635\tKL_Divergence = 3.856489\n",
      "Epoch: 16\tFidelity = 0.500502\tKL_Divergence = 3.986916\n",
      "Epoch: 17\tFidelity = 0.500464\tKL_Divergence = 4.030090\n",
      "Epoch: 18\tFidelity = 0.500648\tKL_Divergence = 3.845081\n",
      "Epoch: 19\tFidelity = 0.500483\tKL_Divergence = 4.008255\n",
      "Epoch: 20\tFidelity = 0.500553\tKL_Divergence = 3.933161\n",
      "Epoch: 21\tFidelity = 0.500599\tKL_Divergence = 3.888765\n",
      "Epoch: 22\tFidelity = 0.500413\tKL_Divergence = 4.094207\n",
      "Epoch: 23\tFidelity = 0.500486\tKL_Divergence = 4.004783\n",
      "Epoch: 24\tFidelity = 0.500479\tKL_Divergence = 4.013061\n",
      "Epoch: 25\tFidelity = 0.500576\tKL_Divergence = 3.910669\n",
      "Epoch: 26\tFidelity = 0.500533\tKL_Divergence = 3.953314\n",
      "Epoch: 27\tFidelity = 0.500517\tKL_Divergence = 3.969921\n",
      "Epoch: 28\tFidelity = 0.500547\tKL_Divergence = 3.939443\n",
      "Epoch: 29\tFidelity = 0.500525\tKL_Divergence = 3.961229\n",
      "Epoch: 30\tFidelity = 0.500574\tKL_Divergence = 3.912129\n",
      "Epoch: 31\tFidelity = 0.500565\tKL_Divergence = 3.921400\n",
      "Epoch: 32\tFidelity = 0.500512\tKL_Divergence = 3.975998\n",
      "Epoch: 33\tFidelity = 0.500571\tKL_Divergence = 3.915331\n",
      "Epoch: 34\tFidelity = 0.500588\tKL_Divergence = 3.899301\n",
      "Epoch: 35\tFidelity = 0.500455\tKL_Divergence = 4.040994\n",
      "Epoch: 36\tFidelity = 0.500544\tKL_Divergence = 3.942311\n",
      "Epoch: 37\tFidelity = 0.500543\tKL_Divergence = 3.943401\n",
      "Epoch: 38\tFidelity = 0.500483\tKL_Divergence = 4.008276\n",
      "Epoch: 39\tFidelity = 0.500503\tKL_Divergence = 3.984967\n",
      "Epoch: 40\tFidelity = 0.500503\tKL_Divergence = 3.985348\n",
      "Epoch: 41\tFidelity = 0.500557\tKL_Divergence = 3.928879\n",
      "Epoch: 42\tFidelity = 0.500487\tKL_Divergence = 4.003088\n",
      "Epoch: 43\tFidelity = 0.500444\tKL_Divergence = 4.054961\n",
      "Epoch: 44\tFidelity = 0.500435\tKL_Divergence = 4.066305\n",
      "Epoch: 45\tFidelity = 0.500519\tKL_Divergence = 3.968252\n",
      "Epoch: 46\tFidelity = 0.500463\tKL_Divergence = 4.031220\n",
      "Epoch: 47\tFidelity = 0.500461\tKL_Divergence = 4.033655\n",
      "Epoch: 48\tFidelity = 0.500509\tKL_Divergence = 3.979034\n",
      "Epoch: 49\tFidelity = 0.500590\tKL_Divergence = 3.896593\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:29:22,533] Trial 526 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500548\tKL_Divergence = 3.937841\n",
      "Total time elapsed during training: 46.539 s\n",
      "Trial 526 pruned. \n",
      "Epoch: 1\tFidelity = 0.500571\tKL_Divergence = 3.914864\n",
      "Epoch: 2\tFidelity = 0.500484\tKL_Divergence = 4.006704\n",
      "Epoch: 3\tFidelity = 0.500477\tKL_Divergence = 4.015187\n",
      "Epoch: 4\tFidelity = 0.500665\tKL_Divergence = 3.830486\n",
      "Epoch: 5\tFidelity = 0.500518\tKL_Divergence = 3.968513\n",
      "Epoch: 6\tFidelity = 0.500636\tKL_Divergence = 3.854706\n",
      "Epoch: 7\tFidelity = 0.500633\tKL_Divergence = 3.856944\n",
      "Epoch: 8\tFidelity = 0.500640\tKL_Divergence = 3.851337\n",
      "Epoch: 9\tFidelity = 0.500720\tKL_Divergence = 3.786344\n",
      "Epoch: 10\tFidelity = 0.500550\tKL_Divergence = 3.935495\n",
      "Epoch: 11\tFidelity = 0.500631\tKL_Divergence = 3.860036\n",
      "Epoch: 12\tFidelity = 0.500505\tKL_Divergence = 3.982688\n",
      "Epoch: 13\tFidelity = 0.500591\tKL_Divergence = 3.896309\n",
      "Epoch: 14\tFidelity = 0.500465\tKL_Divergence = 4.029157\n",
      "Epoch: 15\tFidelity = 0.500651\tKL_Divergence = 3.842278\n",
      "Epoch: 16\tFidelity = 0.500456\tKL_Divergence = 4.040120\n",
      "Epoch: 17\tFidelity = 0.500552\tKL_Divergence = 3.934071\n",
      "Epoch: 18\tFidelity = 0.500550\tKL_Divergence = 3.935425\n",
      "Epoch: 19\tFidelity = 0.500596\tKL_Divergence = 3.891555\n",
      "Epoch: 20\tFidelity = 0.500617\tKL_Divergence = 3.872217\n",
      "Epoch: 21\tFidelity = 0.500576\tKL_Divergence = 3.910363\n",
      "Epoch: 22\tFidelity = 0.500610\tKL_Divergence = 3.878724\n",
      "Epoch: 23\tFidelity = 0.500648\tKL_Divergence = 3.844715\n",
      "Epoch: 24\tFidelity = 0.500546\tKL_Divergence = 3.940197\n",
      "Epoch: 25\tFidelity = 0.500595\tKL_Divergence = 3.892626\n",
      "Epoch: 26\tFidelity = 0.500525\tKL_Divergence = 3.961622\n",
      "Epoch: 27\tFidelity = 0.500550\tKL_Divergence = 3.936180\n",
      "Epoch: 28\tFidelity = 0.500485\tKL_Divergence = 4.005832\n",
      "Epoch: 29\tFidelity = 0.500484\tKL_Divergence = 4.006716\n",
      "Epoch: 30\tFidelity = 0.500438\tKL_Divergence = 4.061387\n",
      "Epoch: 31\tFidelity = 0.500567\tKL_Divergence = 3.919260\n",
      "Epoch: 32\tFidelity = 0.500567\tKL_Divergence = 3.919195\n",
      "Epoch: 33\tFidelity = 0.500603\tKL_Divergence = 3.884982\n",
      "Epoch: 34\tFidelity = 0.500562\tKL_Divergence = 3.924166\n",
      "Epoch: 35\tFidelity = 0.500565\tKL_Divergence = 3.920988\n",
      "Epoch: 36\tFidelity = 0.500490\tKL_Divergence = 3.999349\n",
      "Epoch: 37\tFidelity = 0.500533\tKL_Divergence = 3.953202\n",
      "Epoch: 38\tFidelity = 0.500525\tKL_Divergence = 3.961237\n",
      "Epoch: 39\tFidelity = 0.500519\tKL_Divergence = 3.967351\n",
      "Epoch: 40\tFidelity = 0.500580\tKL_Divergence = 3.906028\n",
      "Epoch: 41\tFidelity = 0.500514\tKL_Divergence = 3.973353\n",
      "Epoch: 42\tFidelity = 0.500484\tKL_Divergence = 4.006722\n",
      "Epoch: 43\tFidelity = 0.500510\tKL_Divergence = 3.977464\n",
      "Epoch: 44\tFidelity = 0.500512\tKL_Divergence = 3.975192\n",
      "Epoch: 45\tFidelity = 0.500545\tKL_Divergence = 3.940151\n",
      "Epoch: 46\tFidelity = 0.500490\tKL_Divergence = 3.999676\n",
      "Epoch: 47\tFidelity = 0.500531\tKL_Divergence = 3.954717\n",
      "Epoch: 48\tFidelity = 0.500568\tKL_Divergence = 3.918213\n",
      "Epoch: 49\tFidelity = 0.500547\tKL_Divergence = 3.938620\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:30:02,053] Trial 527 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500599\tKL_Divergence = 3.887866\n",
      "Total time elapsed during training: 39.351 s\n",
      "Trial 527 pruned. \n",
      "Epoch: 1\tFidelity = 0.500544\tKL_Divergence = 3.941409\n",
      "Epoch: 2\tFidelity = 0.500560\tKL_Divergence = 3.925819\n",
      "Epoch: 3\tFidelity = 0.500499\tKL_Divergence = 3.989397\n",
      "Epoch: 4\tFidelity = 0.500639\tKL_Divergence = 3.852697\n",
      "Epoch: 5\tFidelity = 0.500543\tKL_Divergence = 3.942549\n",
      "Epoch: 6\tFidelity = 0.500559\tKL_Divergence = 3.925991\n",
      "Epoch: 7\tFidelity = 0.500557\tKL_Divergence = 3.928836\n",
      "Epoch: 8\tFidelity = 0.500556\tKL_Divergence = 3.929973\n",
      "Epoch: 9\tFidelity = 0.500448\tKL_Divergence = 4.049485\n",
      "Epoch: 10\tFidelity = 0.500538\tKL_Divergence = 3.947729\n",
      "Epoch: 11\tFidelity = 0.500688\tKL_Divergence = 3.811792\n",
      "Epoch: 12\tFidelity = 0.500692\tKL_Divergence = 3.807827\n",
      "Epoch: 13\tFidelity = 0.500607\tKL_Divergence = 3.880755\n",
      "Epoch: 14\tFidelity = 0.500568\tKL_Divergence = 3.918190\n",
      "Epoch: 15\tFidelity = 0.500601\tKL_Divergence = 3.886861\n",
      "Epoch: 16\tFidelity = 0.500555\tKL_Divergence = 3.930486\n",
      "Epoch: 17\tFidelity = 0.500598\tKL_Divergence = 3.889195\n",
      "Epoch: 18\tFidelity = 0.500522\tKL_Divergence = 3.964526\n",
      "Epoch: 19\tFidelity = 0.500623\tKL_Divergence = 3.865988\n",
      "Epoch: 20\tFidelity = 0.500715\tKL_Divergence = 3.790242\n",
      "Epoch: 21\tFidelity = 0.500561\tKL_Divergence = 3.924016\n",
      "Epoch: 22\tFidelity = 0.500628\tKL_Divergence = 3.862230\n",
      "Epoch: 23\tFidelity = 0.500439\tKL_Divergence = 4.060508\n",
      "Epoch: 24\tFidelity = 0.500458\tKL_Divergence = 4.036484\n",
      "Epoch: 25\tFidelity = 0.500517\tKL_Divergence = 3.970095\n",
      "Epoch: 26\tFidelity = 0.500606\tKL_Divergence = 3.882148\n",
      "Epoch: 27\tFidelity = 0.500681\tKL_Divergence = 3.817168\n",
      "Epoch: 28\tFidelity = 0.500733\tKL_Divergence = 3.776270\n",
      "Epoch: 29\tFidelity = 0.500609\tKL_Divergence = 3.879357\n",
      "Epoch: 30\tFidelity = 0.500625\tKL_Divergence = 3.864751\n",
      "Epoch: 31\tFidelity = 0.500602\tKL_Divergence = 3.885749\n",
      "Epoch: 32\tFidelity = 0.500578\tKL_Divergence = 3.908383\n",
      "Epoch: 33\tFidelity = 0.500517\tKL_Divergence = 3.970173\n",
      "Epoch: 34\tFidelity = 0.500525\tKL_Divergence = 3.960955\n",
      "Epoch: 35\tFidelity = 0.500579\tKL_Divergence = 3.907043\n",
      "Epoch: 36\tFidelity = 0.500479\tKL_Divergence = 4.012046\n",
      "Epoch: 37\tFidelity = 0.500645\tKL_Divergence = 3.847175\n",
      "Epoch: 38\tFidelity = 0.500581\tKL_Divergence = 3.904812\n",
      "Epoch: 39\tFidelity = 0.500720\tKL_Divergence = 3.786166\n",
      "Epoch: 40\tFidelity = 0.500486\tKL_Divergence = 4.004723\n",
      "Epoch: 41\tFidelity = 0.500683\tKL_Divergence = 3.815562\n",
      "Epoch: 42\tFidelity = 0.500584\tKL_Divergence = 3.902262\n",
      "Epoch: 43\tFidelity = 0.500567\tKL_Divergence = 3.918799\n",
      "Epoch: 44\tFidelity = 0.500574\tKL_Divergence = 3.912301\n",
      "Epoch: 45\tFidelity = 0.500611\tKL_Divergence = 3.877580\n",
      "Epoch: 46\tFidelity = 0.500476\tKL_Divergence = 4.016178\n",
      "Epoch: 47\tFidelity = 0.500642\tKL_Divergence = 3.849952\n",
      "Epoch: 48\tFidelity = 0.500413\tKL_Divergence = 4.094078\n",
      "Epoch: 49\tFidelity = 0.500548\tKL_Divergence = 3.937886\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:30:41,677] Trial 528 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500454\tKL_Divergence = 4.041706\n",
      "Total time elapsed during training: 39.429 s\n",
      "Trial 528 pruned. \n",
      "Epoch: 1\tFidelity = 0.500577\tKL_Divergence = 3.909063\n",
      "Epoch: 2\tFidelity = 0.500592\tKL_Divergence = 3.894853\n",
      "Epoch: 3\tFidelity = 0.500549\tKL_Divergence = 3.937147\n",
      "Epoch: 4\tFidelity = 0.500571\tKL_Divergence = 3.915091\n",
      "Epoch: 5\tFidelity = 0.500609\tKL_Divergence = 3.879118\n",
      "Epoch: 6\tFidelity = 0.500538\tKL_Divergence = 3.948477\n",
      "Epoch: 7\tFidelity = 0.500615\tKL_Divergence = 3.873702\n",
      "Epoch: 8\tFidelity = 0.500521\tKL_Divergence = 3.965326\n",
      "Epoch: 9\tFidelity = 0.500536\tKL_Divergence = 3.950102\n",
      "Epoch: 10\tFidelity = 0.500446\tKL_Divergence = 4.052118\n",
      "Epoch: 11\tFidelity = 0.500526\tKL_Divergence = 3.960678\n",
      "Epoch: 12\tFidelity = 0.500529\tKL_Divergence = 3.956921\n",
      "Epoch: 13\tFidelity = 0.500584\tKL_Divergence = 3.902082\n",
      "Epoch: 14\tFidelity = 0.500683\tKL_Divergence = 3.815275\n",
      "Epoch: 15\tFidelity = 0.500545\tKL_Divergence = 3.940660\n",
      "Epoch: 16\tFidelity = 0.500529\tKL_Divergence = 3.957680\n",
      "Epoch: 17\tFidelity = 0.500559\tKL_Divergence = 3.926408\n",
      "Epoch: 18\tFidelity = 0.500598\tKL_Divergence = 3.889619\n",
      "Epoch: 19\tFidelity = 0.500504\tKL_Divergence = 3.984440\n",
      "Epoch: 20\tFidelity = 0.500486\tKL_Divergence = 4.003965\n",
      "Epoch: 21\tFidelity = 0.500500\tKL_Divergence = 3.988812\n",
      "Epoch: 22\tFidelity = 0.500631\tKL_Divergence = 3.859471\n",
      "Epoch: 23\tFidelity = 0.500473\tKL_Divergence = 4.019693\n",
      "Epoch: 24\tFidelity = 0.500587\tKL_Divergence = 3.899994\n",
      "Epoch: 25\tFidelity = 0.500573\tKL_Divergence = 3.913108\n",
      "Epoch: 26\tFidelity = 0.500598\tKL_Divergence = 3.889467\n",
      "Epoch: 27\tFidelity = 0.500547\tKL_Divergence = 3.938931\n",
      "Epoch: 28\tFidelity = 0.500549\tKL_Divergence = 3.936393\n",
      "Epoch: 29\tFidelity = 0.500462\tKL_Divergence = 4.033115\n",
      "Epoch: 30\tFidelity = 0.500522\tKL_Divergence = 3.964654\n",
      "Epoch: 31\tFidelity = 0.500549\tKL_Divergence = 3.937137\n",
      "Epoch: 32\tFidelity = 0.500528\tKL_Divergence = 3.958702\n",
      "Epoch: 33\tFidelity = 0.500515\tKL_Divergence = 3.972333\n",
      "Epoch: 34\tFidelity = 0.500545\tKL_Divergence = 3.941379\n",
      "Epoch: 35\tFidelity = 0.500522\tKL_Divergence = 3.964611\n",
      "Epoch: 36\tFidelity = 0.500472\tKL_Divergence = 4.020635\n",
      "Epoch: 37\tFidelity = 0.500597\tKL_Divergence = 3.890725\n",
      "Epoch: 38\tFidelity = 0.500658\tKL_Divergence = 3.836363\n",
      "Epoch: 39\tFidelity = 0.500532\tKL_Divergence = 3.954278\n",
      "Epoch: 40\tFidelity = 0.500520\tKL_Divergence = 3.966804\n",
      "Epoch: 41\tFidelity = 0.500466\tKL_Divergence = 4.028199\n",
      "Epoch: 42\tFidelity = 0.500540\tKL_Divergence = 3.945853\n",
      "Epoch: 43\tFidelity = 0.500552\tKL_Divergence = 3.934335\n",
      "Epoch: 44\tFidelity = 0.500538\tKL_Divergence = 3.947976\n",
      "Epoch: 45\tFidelity = 0.500616\tKL_Divergence = 3.872912\n",
      "Epoch: 46\tFidelity = 0.500558\tKL_Divergence = 3.927641\n",
      "Epoch: 47\tFidelity = 0.500586\tKL_Divergence = 3.900474\n",
      "Epoch: 48\tFidelity = 0.500498\tKL_Divergence = 3.991284\n",
      "Epoch: 49\tFidelity = 0.500463\tKL_Divergence = 4.031635\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:32:05,117] Trial 529 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500584\tKL_Divergence = 3.903030\n",
      "Total time elapsed during training: 83.255 s\n",
      "Trial 529 pruned. \n",
      "Epoch: 1\tFidelity = 0.500608\tKL_Divergence = 3.880162\n",
      "Epoch: 2\tFidelity = 0.500524\tKL_Divergence = 3.962605\n",
      "Epoch: 3\tFidelity = 0.500523\tKL_Divergence = 3.963774\n",
      "Epoch: 4\tFidelity = 0.500501\tKL_Divergence = 3.988046\n",
      "Epoch: 5\tFidelity = 0.500477\tKL_Divergence = 4.014819\n",
      "Epoch: 6\tFidelity = 0.500489\tKL_Divergence = 4.001018\n",
      "Epoch: 7\tFidelity = 0.500573\tKL_Divergence = 3.913224\n",
      "Epoch: 8\tFidelity = 0.500640\tKL_Divergence = 3.851701\n",
      "Epoch: 9\tFidelity = 0.500536\tKL_Divergence = 3.950152\n",
      "Epoch: 10\tFidelity = 0.500545\tKL_Divergence = 3.940969\n",
      "Epoch: 11\tFidelity = 0.500513\tKL_Divergence = 3.974938\n",
      "Epoch: 12\tFidelity = 0.500515\tKL_Divergence = 3.971888\n",
      "Epoch: 13\tFidelity = 0.500502\tKL_Divergence = 3.987044\n",
      "Epoch: 14\tFidelity = 0.500587\tKL_Divergence = 3.900140\n",
      "Epoch: 15\tFidelity = 0.500495\tKL_Divergence = 3.994383\n",
      "Epoch: 16\tFidelity = 0.500459\tKL_Divergence = 4.036006\n",
      "Epoch: 17\tFidelity = 0.500548\tKL_Divergence = 3.937630\n",
      "Epoch: 18\tFidelity = 0.500492\tKL_Divergence = 3.998091\n",
      "Epoch: 19\tFidelity = 0.500600\tKL_Divergence = 3.887401\n",
      "Epoch: 20\tFidelity = 0.500519\tKL_Divergence = 3.967764\n",
      "Epoch: 21\tFidelity = 0.500594\tKL_Divergence = 3.893422\n",
      "Epoch: 22\tFidelity = 0.500466\tKL_Divergence = 4.027198\n",
      "Epoch: 23\tFidelity = 0.500661\tKL_Divergence = 3.834255\n",
      "Epoch: 24\tFidelity = 0.500544\tKL_Divergence = 3.941957\n",
      "Epoch: 25\tFidelity = 0.500570\tKL_Divergence = 3.915823\n",
      "Epoch: 26\tFidelity = 0.500558\tKL_Divergence = 3.927567\n",
      "Epoch: 27\tFidelity = 0.500659\tKL_Divergence = 3.835727\n",
      "Epoch: 28\tFidelity = 0.500613\tKL_Divergence = 3.875377\n",
      "Epoch: 29\tFidelity = 0.500535\tKL_Divergence = 3.951204\n",
      "Epoch: 30\tFidelity = 0.500651\tKL_Divergence = 3.842222\n",
      "Epoch: 31\tFidelity = 0.500603\tKL_Divergence = 3.884584\n",
      "Epoch: 32\tFidelity = 0.500602\tKL_Divergence = 3.885343\n",
      "Epoch: 33\tFidelity = 0.500615\tKL_Divergence = 3.873805\n",
      "Epoch: 34\tFidelity = 0.500526\tKL_Divergence = 3.960867\n",
      "Epoch: 35\tFidelity = 0.500472\tKL_Divergence = 4.020617\n",
      "Epoch: 36\tFidelity = 0.500589\tKL_Divergence = 3.898171\n",
      "Epoch: 37\tFidelity = 0.500502\tKL_Divergence = 3.986836\n",
      "Epoch: 38\tFidelity = 0.500543\tKL_Divergence = 3.943132\n",
      "Epoch: 39\tFidelity = 0.500465\tKL_Divergence = 4.028467\n",
      "Epoch: 40\tFidelity = 0.500466\tKL_Divergence = 4.027828\n",
      "Epoch: 41\tFidelity = 0.500479\tKL_Divergence = 4.012506\n",
      "Epoch: 42\tFidelity = 0.500559\tKL_Divergence = 3.926892\n",
      "Epoch: 43\tFidelity = 0.500482\tKL_Divergence = 4.008837\n",
      "Epoch: 44\tFidelity = 0.500534\tKL_Divergence = 3.952416\n",
      "Epoch: 45\tFidelity = 0.500539\tKL_Divergence = 3.946967\n",
      "Epoch: 46\tFidelity = 0.500581\tKL_Divergence = 3.905105\n",
      "Epoch: 47\tFidelity = 0.500560\tKL_Divergence = 3.925763\n",
      "Epoch: 48\tFidelity = 0.500526\tKL_Divergence = 3.960372\n",
      "Epoch: 49\tFidelity = 0.500519\tKL_Divergence = 3.968431\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:32:44,424] Trial 530 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500443\tKL_Divergence = 4.056355\n",
      "Total time elapsed during training: 39.124 s\n",
      "Trial 530 pruned. \n",
      "Epoch: 1\tFidelity = 0.500567\tKL_Divergence = 3.918839\n",
      "Epoch: 2\tFidelity = 0.500497\tKL_Divergence = 3.992433\n",
      "Epoch: 3\tFidelity = 0.500604\tKL_Divergence = 3.883890\n",
      "Epoch: 4\tFidelity = 0.500551\tKL_Divergence = 3.935080\n",
      "Epoch: 5\tFidelity = 0.500617\tKL_Divergence = 3.871989\n",
      "Epoch: 6\tFidelity = 0.500557\tKL_Divergence = 3.928793\n",
      "Epoch: 7\tFidelity = 0.500581\tKL_Divergence = 3.905780\n",
      "Epoch: 8\tFidelity = 0.500474\tKL_Divergence = 4.018889\n",
      "Epoch: 9\tFidelity = 0.500539\tKL_Divergence = 3.946727\n",
      "Epoch: 10\tFidelity = 0.500510\tKL_Divergence = 3.977704\n",
      "Epoch: 11\tFidelity = 0.500579\tKL_Divergence = 3.907773\n",
      "Epoch: 12\tFidelity = 0.500528\tKL_Divergence = 3.958996\n",
      "Epoch: 13\tFidelity = 0.500545\tKL_Divergence = 3.941222\n",
      "Epoch: 14\tFidelity = 0.500491\tKL_Divergence = 3.999409\n",
      "Epoch: 15\tFidelity = 0.500470\tKL_Divergence = 4.022527\n",
      "Epoch: 16\tFidelity = 0.500467\tKL_Divergence = 4.026502\n",
      "Epoch: 17\tFidelity = 0.500473\tKL_Divergence = 4.018560\n",
      "Epoch: 18\tFidelity = 0.500560\tKL_Divergence = 3.925783\n",
      "Epoch: 19\tFidelity = 0.500603\tKL_Divergence = 3.885013\n",
      "Epoch: 20\tFidelity = 0.500514\tKL_Divergence = 3.973619\n",
      "Epoch: 21\tFidelity = 0.500585\tKL_Divergence = 3.901221\n",
      "Epoch: 22\tFidelity = 0.500527\tKL_Divergence = 3.958939\n",
      "Epoch: 23\tFidelity = 0.500521\tKL_Divergence = 3.966210\n",
      "Epoch: 24\tFidelity = 0.500548\tKL_Divergence = 3.937396\n",
      "Epoch: 25\tFidelity = 0.500470\tKL_Divergence = 4.023313\n",
      "Epoch: 26\tFidelity = 0.500515\tKL_Divergence = 3.971609\n",
      "Epoch: 27\tFidelity = 0.500585\tKL_Divergence = 3.901839\n",
      "Epoch: 28\tFidelity = 0.500507\tKL_Divergence = 3.981075\n",
      "Epoch: 29\tFidelity = 0.500560\tKL_Divergence = 3.926323\n",
      "Epoch: 30\tFidelity = 0.500546\tKL_Divergence = 3.940379\n",
      "Epoch: 31\tFidelity = 0.500563\tKL_Divergence = 3.923311\n",
      "Epoch: 32\tFidelity = 0.500494\tKL_Divergence = 3.995590\n",
      "Epoch: 33\tFidelity = 0.500538\tKL_Divergence = 3.947998\n",
      "Epoch: 34\tFidelity = 0.500586\tKL_Divergence = 3.900277\n",
      "Epoch: 35\tFidelity = 0.500605\tKL_Divergence = 3.882920\n",
      "Epoch: 36\tFidelity = 0.500580\tKL_Divergence = 3.906008\n",
      "Epoch: 37\tFidelity = 0.500510\tKL_Divergence = 3.977747\n",
      "Epoch: 38\tFidelity = 0.500498\tKL_Divergence = 3.990798\n",
      "Epoch: 39\tFidelity = 0.500505\tKL_Divergence = 3.983513\n",
      "Epoch: 40\tFidelity = 0.500475\tKL_Divergence = 4.017333\n",
      "Epoch: 41\tFidelity = 0.500499\tKL_Divergence = 3.990290\n",
      "Epoch: 42\tFidelity = 0.500534\tKL_Divergence = 3.952674\n",
      "Epoch: 43\tFidelity = 0.500559\tKL_Divergence = 3.927214\n",
      "Epoch: 44\tFidelity = 0.500453\tKL_Divergence = 4.043568\n",
      "Epoch: 45\tFidelity = 0.500538\tKL_Divergence = 3.947627\n",
      "Epoch: 46\tFidelity = 0.500608\tKL_Divergence = 3.880497\n",
      "Epoch: 47\tFidelity = 0.500575\tKL_Divergence = 3.911634\n",
      "Epoch: 48\tFidelity = 0.500594\tKL_Divergence = 3.892743\n",
      "Epoch: 49\tFidelity = 0.500522\tKL_Divergence = 3.965033\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:33:29,865] Trial 531 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500674\tKL_Divergence = 3.823295\n",
      "Total time elapsed during training: 45.260 s\n",
      "Trial 531 pruned. \n",
      "Epoch: 1\tFidelity = 0.500504\tKL_Divergence = 3.984165\n",
      "Epoch: 2\tFidelity = 0.500573\tKL_Divergence = 3.913282\n",
      "Epoch: 3\tFidelity = 0.500601\tKL_Divergence = 3.887146\n",
      "Epoch: 4\tFidelity = 0.500649\tKL_Divergence = 3.843751\n",
      "Epoch: 5\tFidelity = 0.500480\tKL_Divergence = 4.011385\n",
      "Epoch: 6\tFidelity = 0.500588\tKL_Divergence = 3.898572\n",
      "Epoch: 7\tFidelity = 0.500586\tKL_Divergence = 3.900391\n",
      "Epoch: 8\tFidelity = 0.500695\tKL_Divergence = 3.805915\n",
      "Epoch: 9\tFidelity = 0.500577\tKL_Divergence = 3.909251\n",
      "Epoch: 10\tFidelity = 0.500527\tKL_Divergence = 3.958842\n",
      "Epoch: 11\tFidelity = 0.500596\tKL_Divergence = 3.890343\n",
      "Epoch: 12\tFidelity = 0.500496\tKL_Divergence = 3.992085\n",
      "Epoch: 13\tFidelity = 0.500572\tKL_Divergence = 3.912869\n",
      "Epoch: 14\tFidelity = 0.500482\tKL_Divergence = 4.007531\n",
      "Epoch: 15\tFidelity = 0.500522\tKL_Divergence = 3.963922\n",
      "Epoch: 16\tFidelity = 0.500538\tKL_Divergence = 3.946595\n",
      "Epoch: 17\tFidelity = 0.500546\tKL_Divergence = 3.939293\n",
      "Epoch: 18\tFidelity = 0.500502\tKL_Divergence = 3.986027\n",
      "Epoch: 19\tFidelity = 0.500455\tKL_Divergence = 4.040226\n",
      "Epoch: 20\tFidelity = 0.500533\tKL_Divergence = 3.953344\n",
      "Epoch: 21\tFidelity = 0.500521\tKL_Divergence = 3.965592\n",
      "Epoch: 22\tFidelity = 0.500484\tKL_Divergence = 4.006901\n",
      "Epoch: 23\tFidelity = 0.500594\tKL_Divergence = 3.892813\n",
      "Epoch: 24\tFidelity = 0.500636\tKL_Divergence = 3.855418\n",
      "Epoch: 25\tFidelity = 0.500567\tKL_Divergence = 3.918693\n",
      "Epoch: 26\tFidelity = 0.500506\tKL_Divergence = 3.981533\n",
      "Epoch: 27\tFidelity = 0.500479\tKL_Divergence = 4.012807\n",
      "Epoch: 28\tFidelity = 0.500554\tKL_Divergence = 3.932170\n",
      "Epoch: 29\tFidelity = 0.500585\tKL_Divergence = 3.901345\n",
      "Epoch: 30\tFidelity = 0.500557\tKL_Divergence = 3.928489\n",
      "Epoch: 31\tFidelity = 0.500612\tKL_Divergence = 3.876664\n",
      "Epoch: 32\tFidelity = 0.500602\tKL_Divergence = 3.886071\n",
      "Epoch: 33\tFidelity = 0.500553\tKL_Divergence = 3.932979\n",
      "Epoch: 34\tFidelity = 0.500514\tKL_Divergence = 3.973474\n",
      "Epoch: 35\tFidelity = 0.500641\tKL_Divergence = 3.851005\n",
      "Epoch: 36\tFidelity = 0.500496\tKL_Divergence = 3.992830\n",
      "Epoch: 37\tFidelity = 0.500611\tKL_Divergence = 3.877471\n",
      "Epoch: 38\tFidelity = 0.500517\tKL_Divergence = 3.969606\n",
      "Epoch: 39\tFidelity = 0.500474\tKL_Divergence = 4.017949\n",
      "Epoch: 40\tFidelity = 0.500455\tKL_Divergence = 4.040331\n",
      "Epoch: 41\tFidelity = 0.500518\tKL_Divergence = 3.967913\n",
      "Epoch: 42\tFidelity = 0.500543\tKL_Divergence = 3.942467\n",
      "Epoch: 43\tFidelity = 0.500562\tKL_Divergence = 3.923430\n",
      "Epoch: 44\tFidelity = 0.500481\tKL_Divergence = 4.010669\n",
      "Epoch: 45\tFidelity = 0.500543\tKL_Divergence = 3.942457\n",
      "Epoch: 46\tFidelity = 0.500584\tKL_Divergence = 3.902739\n",
      "Epoch: 47\tFidelity = 0.500441\tKL_Divergence = 4.058039\n",
      "Epoch: 48\tFidelity = 0.500551\tKL_Divergence = 3.934882\n",
      "Epoch: 49\tFidelity = 0.500524\tKL_Divergence = 3.962272\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:34:08,743] Trial 532 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500546\tKL_Divergence = 3.939494\n",
      "Total time elapsed during training: 38.690 s\n",
      "Trial 532 pruned. \n",
      "Epoch: 1\tFidelity = 0.500511\tKL_Divergence = 3.976041\n",
      "Epoch: 2\tFidelity = 0.500533\tKL_Divergence = 3.952727\n",
      "Epoch: 3\tFidelity = 0.500490\tKL_Divergence = 3.999797\n",
      "Epoch: 4\tFidelity = 0.500540\tKL_Divergence = 3.945776\n",
      "Epoch: 5\tFidelity = 0.500511\tKL_Divergence = 3.976706\n",
      "Epoch: 6\tFidelity = 0.500591\tKL_Divergence = 3.895624\n",
      "Epoch: 7\tFidelity = 0.500535\tKL_Divergence = 3.950477\n",
      "Epoch: 8\tFidelity = 0.500499\tKL_Divergence = 3.989490\n",
      "Epoch: 9\tFidelity = 0.500532\tKL_Divergence = 3.954521\n",
      "Epoch: 10\tFidelity = 0.500547\tKL_Divergence = 3.938745\n",
      "Epoch: 11\tFidelity = 0.500499\tKL_Divergence = 3.989906\n",
      "Epoch: 12\tFidelity = 0.500545\tKL_Divergence = 3.940981\n",
      "Epoch: 13\tFidelity = 0.500519\tKL_Divergence = 3.968263\n",
      "Epoch: 14\tFidelity = 0.500563\tKL_Divergence = 3.922613\n",
      "Epoch: 15\tFidelity = 0.500502\tKL_Divergence = 3.985920\n",
      "Epoch: 16\tFidelity = 0.500512\tKL_Divergence = 3.975593\n",
      "Epoch: 17\tFidelity = 0.500536\tKL_Divergence = 3.949556\n",
      "Epoch: 18\tFidelity = 0.500530\tKL_Divergence = 3.956167\n",
      "Epoch: 19\tFidelity = 0.500504\tKL_Divergence = 3.983979\n",
      "Epoch: 20\tFidelity = 0.500546\tKL_Divergence = 3.939560\n",
      "Epoch: 21\tFidelity = 0.500495\tKL_Divergence = 3.993663\n",
      "Epoch: 22\tFidelity = 0.500521\tKL_Divergence = 3.965863\n",
      "Epoch: 23\tFidelity = 0.500583\tKL_Divergence = 3.903876\n",
      "Epoch: 24\tFidelity = 0.500520\tKL_Divergence = 3.966938\n",
      "Epoch: 25\tFidelity = 0.500551\tKL_Divergence = 3.934790\n",
      "Epoch: 26\tFidelity = 0.500502\tKL_Divergence = 3.986995\n",
      "Epoch: 27\tFidelity = 0.500555\tKL_Divergence = 3.930299\n",
      "Epoch: 28\tFidelity = 0.500546\tKL_Divergence = 3.939682\n",
      "Epoch: 29\tFidelity = 0.500469\tKL_Divergence = 4.023818\n",
      "Epoch: 30\tFidelity = 0.500535\tKL_Divergence = 3.951258\n",
      "Epoch: 31\tFidelity = 0.500503\tKL_Divergence = 3.985813\n",
      "Epoch: 32\tFidelity = 0.500564\tKL_Divergence = 3.921590\n",
      "Epoch: 33\tFidelity = 0.500583\tKL_Divergence = 3.903919\n",
      "Epoch: 34\tFidelity = 0.500502\tKL_Divergence = 3.986902\n",
      "Epoch: 35\tFidelity = 0.500523\tKL_Divergence = 3.964314\n",
      "Epoch: 36\tFidelity = 0.500525\tKL_Divergence = 3.961488\n",
      "Epoch: 37\tFidelity = 0.500529\tKL_Divergence = 3.957650\n",
      "Epoch: 38\tFidelity = 0.500512\tKL_Divergence = 3.975984\n",
      "Epoch: 39\tFidelity = 0.500510\tKL_Divergence = 3.977651\n",
      "Epoch: 40\tFidelity = 0.500483\tKL_Divergence = 4.007815\n",
      "Epoch: 41\tFidelity = 0.500567\tKL_Divergence = 3.919165\n",
      "Epoch: 42\tFidelity = 0.500529\tKL_Divergence = 3.957775\n",
      "Epoch: 43\tFidelity = 0.500494\tKL_Divergence = 3.995497\n",
      "Epoch: 44\tFidelity = 0.500541\tKL_Divergence = 3.944873\n",
      "Epoch: 45\tFidelity = 0.500504\tKL_Divergence = 3.984664\n",
      "Epoch: 46\tFidelity = 0.500535\tKL_Divergence = 3.950743\n",
      "Epoch: 47\tFidelity = 0.500483\tKL_Divergence = 4.007790\n",
      "Epoch: 48\tFidelity = 0.500502\tKL_Divergence = 3.987097\n",
      "Epoch: 49\tFidelity = 0.500498\tKL_Divergence = 3.990629\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:34:41,483] Trial 533 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500528\tKL_Divergence = 3.958160\n",
      "Total time elapsed during training: 32.563 s\n",
      "Trial 533 pruned. \n",
      "Epoch: 1\tFidelity = 0.500511\tKL_Divergence = 3.977172\n",
      "Epoch: 2\tFidelity = 0.500533\tKL_Divergence = 3.952860\n",
      "Epoch: 3\tFidelity = 0.500588\tKL_Divergence = 3.898857\n",
      "Epoch: 4\tFidelity = 0.500502\tKL_Divergence = 3.986713\n",
      "Epoch: 5\tFidelity = 0.500569\tKL_Divergence = 3.916983\n",
      "Epoch: 6\tFidelity = 0.500543\tKL_Divergence = 3.943563\n",
      "Epoch: 7\tFidelity = 0.500448\tKL_Divergence = 4.049638\n",
      "Epoch: 8\tFidelity = 0.500540\tKL_Divergence = 3.946541\n",
      "Epoch: 9\tFidelity = 0.500591\tKL_Divergence = 3.895669\n",
      "Epoch: 10\tFidelity = 0.500565\tKL_Divergence = 3.920883\n",
      "Epoch: 11\tFidelity = 0.500580\tKL_Divergence = 3.906763\n",
      "Epoch: 12\tFidelity = 0.500494\tKL_Divergence = 3.995413\n",
      "Epoch: 13\tFidelity = 0.500541\tKL_Divergence = 3.944758\n",
      "Epoch: 14\tFidelity = 0.500564\tKL_Divergence = 3.922019\n",
      "Epoch: 15\tFidelity = 0.500563\tKL_Divergence = 3.923461\n",
      "Epoch: 16\tFidelity = 0.500510\tKL_Divergence = 3.977949\n",
      "Epoch: 17\tFidelity = 0.500525\tKL_Divergence = 3.961549\n",
      "Epoch: 18\tFidelity = 0.500485\tKL_Divergence = 4.006043\n",
      "Epoch: 19\tFidelity = 0.500540\tKL_Divergence = 3.946253\n",
      "Epoch: 20\tFidelity = 0.500567\tKL_Divergence = 3.919049\n",
      "Epoch: 21\tFidelity = 0.500507\tKL_Divergence = 3.981333\n",
      "Epoch: 22\tFidelity = 0.500545\tKL_Divergence = 3.940932\n",
      "Epoch: 23\tFidelity = 0.500526\tKL_Divergence = 3.960469\n",
      "Epoch: 24\tFidelity = 0.500528\tKL_Divergence = 3.958892\n",
      "Epoch: 25\tFidelity = 0.500518\tKL_Divergence = 3.969338\n",
      "Epoch: 26\tFidelity = 0.500577\tKL_Divergence = 3.909055\n",
      "Epoch: 27\tFidelity = 0.500615\tKL_Divergence = 3.874227\n",
      "Epoch: 28\tFidelity = 0.500579\tKL_Divergence = 3.907314\n",
      "Epoch: 29\tFidelity = 0.500521\tKL_Divergence = 3.965493\n",
      "Epoch: 30\tFidelity = 0.500589\tKL_Divergence = 3.897648\n",
      "Epoch: 31\tFidelity = 0.500588\tKL_Divergence = 3.899344\n",
      "Epoch: 32\tFidelity = 0.500622\tKL_Divergence = 3.868089\n",
      "Epoch: 33\tFidelity = 0.500623\tKL_Divergence = 3.866682\n",
      "Epoch: 34\tFidelity = 0.500572\tKL_Divergence = 3.914215\n",
      "Epoch: 35\tFidelity = 0.500512\tKL_Divergence = 3.975235\n",
      "Epoch: 36\tFidelity = 0.500570\tKL_Divergence = 3.915866\n",
      "Epoch: 37\tFidelity = 0.500554\tKL_Divergence = 3.931718\n",
      "Epoch: 38\tFidelity = 0.500566\tKL_Divergence = 3.920110\n",
      "Epoch: 39\tFidelity = 0.500545\tKL_Divergence = 3.941065\n",
      "Epoch: 40\tFidelity = 0.500533\tKL_Divergence = 3.953543\n",
      "Epoch: 41\tFidelity = 0.500525\tKL_Divergence = 3.961613\n",
      "Epoch: 42\tFidelity = 0.500537\tKL_Divergence = 3.949702\n",
      "Epoch: 43\tFidelity = 0.500528\tKL_Divergence = 3.958528\n",
      "Epoch: 44\tFidelity = 0.500550\tKL_Divergence = 3.935460\n",
      "Epoch: 45\tFidelity = 0.500515\tKL_Divergence = 3.972651\n",
      "Epoch: 46\tFidelity = 0.500546\tKL_Divergence = 3.939785\n",
      "Epoch: 47\tFidelity = 0.500575\tKL_Divergence = 3.910932\n",
      "Epoch: 48\tFidelity = 0.500556\tKL_Divergence = 3.929443\n",
      "Epoch: 49\tFidelity = 0.500576\tKL_Divergence = 3.910447\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:35:27,984] Trial 534 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500607\tKL_Divergence = 3.880967\n",
      "Total time elapsed during training: 46.321 s\n",
      "Trial 534 pruned. \n",
      "Epoch: 1\tFidelity = 0.500548\tKL_Divergence = 3.937911\n",
      "Epoch: 2\tFidelity = 0.500514\tKL_Divergence = 3.973339\n",
      "Epoch: 3\tFidelity = 0.500538\tKL_Divergence = 3.948662\n",
      "Epoch: 4\tFidelity = 0.500500\tKL_Divergence = 3.988889\n",
      "Epoch: 5\tFidelity = 0.500510\tKL_Divergence = 3.977912\n",
      "Epoch: 6\tFidelity = 0.500554\tKL_Divergence = 3.931788\n",
      "Epoch: 7\tFidelity = 0.500522\tKL_Divergence = 3.965182\n",
      "Epoch: 8\tFidelity = 0.500537\tKL_Divergence = 3.949412\n",
      "Epoch: 9\tFidelity = 0.500518\tKL_Divergence = 3.969539\n",
      "Epoch: 10\tFidelity = 0.500507\tKL_Divergence = 3.981383\n",
      "Epoch: 11\tFidelity = 0.500540\tKL_Divergence = 3.946122\n",
      "Epoch: 12\tFidelity = 0.500547\tKL_Divergence = 3.939195\n",
      "Epoch: 13\tFidelity = 0.500501\tKL_Divergence = 3.987343\n",
      "Epoch: 14\tFidelity = 0.500532\tKL_Divergence = 3.954021\n",
      "Epoch: 15\tFidelity = 0.500529\tKL_Divergence = 3.957424\n",
      "Epoch: 16\tFidelity = 0.500536\tKL_Divergence = 3.950689\n",
      "Epoch: 17\tFidelity = 0.500500\tKL_Divergence = 3.989180\n",
      "Epoch: 18\tFidelity = 0.500555\tKL_Divergence = 3.931096\n",
      "Epoch: 19\tFidelity = 0.500497\tKL_Divergence = 3.992110\n",
      "Epoch: 20\tFidelity = 0.500569\tKL_Divergence = 3.917271\n",
      "Epoch: 21\tFidelity = 0.500570\tKL_Divergence = 3.916570\n",
      "Epoch: 22\tFidelity = 0.500488\tKL_Divergence = 4.001802\n",
      "Epoch: 23\tFidelity = 0.500543\tKL_Divergence = 3.942889\n",
      "Epoch: 24\tFidelity = 0.500503\tKL_Divergence = 3.985739\n",
      "Epoch: 25\tFidelity = 0.500567\tKL_Divergence = 3.919349\n",
      "Epoch: 26\tFidelity = 0.500535\tKL_Divergence = 3.951074\n",
      "Epoch: 27\tFidelity = 0.500537\tKL_Divergence = 3.949585\n",
      "Epoch: 28\tFidelity = 0.500559\tKL_Divergence = 3.927287\n",
      "Epoch: 29\tFidelity = 0.500548\tKL_Divergence = 3.937744\n",
      "Epoch: 30\tFidelity = 0.500487\tKL_Divergence = 4.003473\n",
      "Epoch: 31\tFidelity = 0.500552\tKL_Divergence = 3.934070\n",
      "Epoch: 32\tFidelity = 0.500575\tKL_Divergence = 3.911057\n",
      "Epoch: 33\tFidelity = 0.500523\tKL_Divergence = 3.963597\n",
      "Epoch: 34\tFidelity = 0.500539\tKL_Divergence = 3.947100\n",
      "Epoch: 35\tFidelity = 0.500509\tKL_Divergence = 3.979220\n",
      "Epoch: 36\tFidelity = 0.500571\tKL_Divergence = 3.914993\n",
      "Epoch: 37\tFidelity = 0.500531\tKL_Divergence = 3.955124\n",
      "Epoch: 38\tFidelity = 0.500504\tKL_Divergence = 3.984973\n",
      "Epoch: 39\tFidelity = 0.500483\tKL_Divergence = 4.007576\n",
      "Epoch: 40\tFidelity = 0.500552\tKL_Divergence = 3.933696\n",
      "Epoch: 41\tFidelity = 0.500517\tKL_Divergence = 3.970453\n",
      "Epoch: 42\tFidelity = 0.500522\tKL_Divergence = 3.964511\n",
      "Epoch: 43\tFidelity = 0.500508\tKL_Divergence = 3.980588\n",
      "Epoch: 44\tFidelity = 0.500524\tKL_Divergence = 3.963317\n",
      "Epoch: 45\tFidelity = 0.500522\tKL_Divergence = 3.964841\n",
      "Epoch: 46\tFidelity = 0.500553\tKL_Divergence = 3.932838\n",
      "Epoch: 47\tFidelity = 0.500538\tKL_Divergence = 3.948294\n",
      "Epoch: 48\tFidelity = 0.500516\tKL_Divergence = 3.971701\n",
      "Epoch: 49\tFidelity = 0.500511\tKL_Divergence = 3.976540\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:36:00,637] Trial 535 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500518\tKL_Divergence = 3.968842\n",
      "Total time elapsed during training: 32.471 s\n",
      "Trial 535 pruned. \n",
      "Epoch: 1\tFidelity = 0.500583\tKL_Divergence = 3.903941\n",
      "Epoch: 2\tFidelity = 0.500538\tKL_Divergence = 3.948693\n",
      "Epoch: 3\tFidelity = 0.500530\tKL_Divergence = 3.956169\n",
      "Epoch: 4\tFidelity = 0.500546\tKL_Divergence = 3.939672\n",
      "Epoch: 5\tFidelity = 0.500561\tKL_Divergence = 3.924690\n",
      "Epoch: 6\tFidelity = 0.500522\tKL_Divergence = 3.965253\n",
      "Epoch: 7\tFidelity = 0.500558\tKL_Divergence = 3.928278\n",
      "Epoch: 8\tFidelity = 0.500535\tKL_Divergence = 3.951424\n",
      "Epoch: 9\tFidelity = 0.500539\tKL_Divergence = 3.946762\n",
      "Epoch: 10\tFidelity = 0.500546\tKL_Divergence = 3.939516\n",
      "Epoch: 11\tFidelity = 0.500483\tKL_Divergence = 4.007679\n",
      "Epoch: 12\tFidelity = 0.500558\tKL_Divergence = 3.928039\n",
      "Epoch: 13\tFidelity = 0.500533\tKL_Divergence = 3.953018\n",
      "Epoch: 14\tFidelity = 0.500536\tKL_Divergence = 3.949858\n",
      "Epoch: 15\tFidelity = 0.500466\tKL_Divergence = 4.028117\n",
      "Epoch: 16\tFidelity = 0.500484\tKL_Divergence = 4.006323\n",
      "Epoch: 17\tFidelity = 0.500524\tKL_Divergence = 3.962638\n",
      "Epoch: 18\tFidelity = 0.500498\tKL_Divergence = 3.990705\n",
      "Epoch: 19\tFidelity = 0.500491\tKL_Divergence = 3.998829\n",
      "Epoch: 20\tFidelity = 0.500469\tKL_Divergence = 4.024192\n",
      "Epoch: 21\tFidelity = 0.500512\tKL_Divergence = 3.975651\n",
      "Epoch: 22\tFidelity = 0.500587\tKL_Divergence = 3.900307\n",
      "Epoch: 23\tFidelity = 0.500539\tKL_Divergence = 3.946825\n",
      "Epoch: 24\tFidelity = 0.500547\tKL_Divergence = 3.939197\n",
      "Epoch: 25\tFidelity = 0.500540\tKL_Divergence = 3.946255\n",
      "Epoch: 26\tFidelity = 0.500583\tKL_Divergence = 3.903996\n",
      "Epoch: 27\tFidelity = 0.500502\tKL_Divergence = 3.986257\n",
      "Epoch: 28\tFidelity = 0.500512\tKL_Divergence = 3.976131\n",
      "Epoch: 29\tFidelity = 0.500539\tKL_Divergence = 3.946704\n",
      "Epoch: 30\tFidelity = 0.500514\tKL_Divergence = 3.973441\n",
      "Epoch: 31\tFidelity = 0.500542\tKL_Divergence = 3.944165\n",
      "Epoch: 32\tFidelity = 0.500513\tKL_Divergence = 3.974508\n",
      "Epoch: 33\tFidelity = 0.500492\tKL_Divergence = 3.997383\n",
      "Epoch: 34\tFidelity = 0.500526\tKL_Divergence = 3.960460\n",
      "Epoch: 35\tFidelity = 0.500528\tKL_Divergence = 3.958485\n",
      "Epoch: 36\tFidelity = 0.500555\tKL_Divergence = 3.931347\n",
      "Epoch: 37\tFidelity = 0.500539\tKL_Divergence = 3.947355\n",
      "Epoch: 38\tFidelity = 0.500577\tKL_Divergence = 3.909016\n",
      "Epoch: 39\tFidelity = 0.500520\tKL_Divergence = 3.967129\n",
      "Epoch: 40\tFidelity = 0.500576\tKL_Divergence = 3.910656\n",
      "Epoch: 41\tFidelity = 0.500550\tKL_Divergence = 3.935630\n",
      "Epoch: 42\tFidelity = 0.500531\tKL_Divergence = 3.955181\n",
      "Epoch: 43\tFidelity = 0.500515\tKL_Divergence = 3.972957\n",
      "Epoch: 44\tFidelity = 0.500562\tKL_Divergence = 3.923951\n",
      "Epoch: 45\tFidelity = 0.500557\tKL_Divergence = 3.928597\n",
      "Epoch: 46\tFidelity = 0.500528\tKL_Divergence = 3.959019\n",
      "Epoch: 47\tFidelity = 0.500555\tKL_Divergence = 3.931064\n",
      "Epoch: 48\tFidelity = 0.500567\tKL_Divergence = 3.919022\n",
      "Epoch: 49\tFidelity = 0.500515\tKL_Divergence = 3.972554\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:36:40,322] Trial 536 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500514\tKL_Divergence = 3.973665\n",
      "Total time elapsed during training: 39.503 s\n",
      "Trial 536 pruned. \n",
      "Epoch: 1\tFidelity = 0.500471\tKL_Divergence = 4.022267\n",
      "Epoch: 2\tFidelity = 0.500528\tKL_Divergence = 3.958759\n",
      "Epoch: 3\tFidelity = 0.500486\tKL_Divergence = 4.004530\n",
      "Epoch: 4\tFidelity = 0.500594\tKL_Divergence = 3.892965\n",
      "Epoch: 5\tFidelity = 0.500539\tKL_Divergence = 3.947198\n",
      "Epoch: 6\tFidelity = 0.500499\tKL_Divergence = 3.990304\n",
      "Epoch: 7\tFidelity = 0.500523\tKL_Divergence = 3.964124\n",
      "Epoch: 8\tFidelity = 0.500485\tKL_Divergence = 4.006102\n",
      "Epoch: 9\tFidelity = 0.500521\tKL_Divergence = 3.966123\n",
      "Epoch: 10\tFidelity = 0.500502\tKL_Divergence = 3.986882\n",
      "Epoch: 11\tFidelity = 0.500472\tKL_Divergence = 4.021139\n",
      "Epoch: 12\tFidelity = 0.500508\tKL_Divergence = 3.979786\n",
      "Epoch: 13\tFidelity = 0.500535\tKL_Divergence = 3.950925\n",
      "Epoch: 14\tFidelity = 0.500478\tKL_Divergence = 4.013871\n",
      "Epoch: 15\tFidelity = 0.500518\tKL_Divergence = 3.969553\n",
      "Epoch: 16\tFidelity = 0.500494\tKL_Divergence = 3.995304\n",
      "Epoch: 17\tFidelity = 0.500513\tKL_Divergence = 3.974304\n",
      "Epoch: 18\tFidelity = 0.500505\tKL_Divergence = 3.983763\n",
      "Epoch: 19\tFidelity = 0.500472\tKL_Divergence = 4.020574\n",
      "Epoch: 20\tFidelity = 0.500465\tKL_Divergence = 4.028764\n",
      "Epoch: 21\tFidelity = 0.500505\tKL_Divergence = 3.983182\n",
      "Epoch: 22\tFidelity = 0.500431\tKL_Divergence = 4.071112\n",
      "Epoch: 23\tFidelity = 0.500495\tKL_Divergence = 3.994558\n",
      "Epoch: 24\tFidelity = 0.500481\tKL_Divergence = 4.010172\n",
      "Epoch: 25\tFidelity = 0.500490\tKL_Divergence = 4.000131\n",
      "Epoch: 26\tFidelity = 0.500500\tKL_Divergence = 3.989299\n",
      "Epoch: 27\tFidelity = 0.500500\tKL_Divergence = 3.988960\n",
      "Epoch: 28\tFidelity = 0.500514\tKL_Divergence = 3.973503\n",
      "Epoch: 29\tFidelity = 0.500518\tKL_Divergence = 3.969391\n",
      "Epoch: 30\tFidelity = 0.500502\tKL_Divergence = 3.986343\n",
      "Epoch: 31\tFidelity = 0.500456\tKL_Divergence = 4.040406\n",
      "Epoch: 32\tFidelity = 0.500536\tKL_Divergence = 3.950070\n",
      "Epoch: 33\tFidelity = 0.500473\tKL_Divergence = 4.019260\n",
      "Epoch: 34\tFidelity = 0.500544\tKL_Divergence = 3.941898\n",
      "Epoch: 35\tFidelity = 0.500542\tKL_Divergence = 3.944646\n",
      "Epoch: 36\tFidelity = 0.500508\tKL_Divergence = 3.980246\n",
      "Epoch: 37\tFidelity = 0.500533\tKL_Divergence = 3.953459\n",
      "Epoch: 38\tFidelity = 0.500524\tKL_Divergence = 3.963104\n",
      "Epoch: 39\tFidelity = 0.500488\tKL_Divergence = 4.002155\n",
      "Epoch: 40\tFidelity = 0.500547\tKL_Divergence = 3.939181\n",
      "Epoch: 41\tFidelity = 0.500524\tKL_Divergence = 3.963273\n",
      "Epoch: 42\tFidelity = 0.500486\tKL_Divergence = 4.004472\n",
      "Epoch: 43\tFidelity = 0.500550\tKL_Divergence = 3.936400\n",
      "Epoch: 44\tFidelity = 0.500496\tKL_Divergence = 3.993869\n",
      "Epoch: 45\tFidelity = 0.500547\tKL_Divergence = 3.939476\n",
      "Epoch: 46\tFidelity = 0.500500\tKL_Divergence = 3.989279\n",
      "Epoch: 47\tFidelity = 0.500530\tKL_Divergence = 3.956222\n",
      "Epoch: 48\tFidelity = 0.500526\tKL_Divergence = 3.960940\n",
      "Epoch: 49\tFidelity = 0.500535\tKL_Divergence = 3.950894\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:38:01,919] Trial 537 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500542\tKL_Divergence = 3.944106\n",
      "Total time elapsed during training: 81.417 s\n",
      "Trial 537 pruned. \n",
      "Epoch: 1\tFidelity = 0.500502\tKL_Divergence = 3.986224\n",
      "Epoch: 2\tFidelity = 0.500572\tKL_Divergence = 3.913826\n",
      "Epoch: 3\tFidelity = 0.500437\tKL_Divergence = 4.063801\n",
      "Epoch: 4\tFidelity = 0.500483\tKL_Divergence = 4.008420\n",
      "Epoch: 5\tFidelity = 0.500508\tKL_Divergence = 3.979884\n",
      "Epoch: 6\tFidelity = 0.500551\tKL_Divergence = 3.935013\n",
      "Epoch: 7\tFidelity = 0.500531\tKL_Divergence = 3.955148\n",
      "Epoch: 8\tFidelity = 0.500540\tKL_Divergence = 3.946335\n",
      "Epoch: 9\tFidelity = 0.500553\tKL_Divergence = 3.932909\n",
      "Epoch: 10\tFidelity = 0.500560\tKL_Divergence = 3.926091\n",
      "Epoch: 11\tFidelity = 0.500496\tKL_Divergence = 3.993301\n",
      "Epoch: 12\tFidelity = 0.500540\tKL_Divergence = 3.946568\n",
      "Epoch: 13\tFidelity = 0.500537\tKL_Divergence = 3.948758\n",
      "Epoch: 14\tFidelity = 0.500531\tKL_Divergence = 3.955222\n",
      "Epoch: 15\tFidelity = 0.500466\tKL_Divergence = 4.027212\n",
      "Epoch: 16\tFidelity = 0.500544\tKL_Divergence = 3.942249\n",
      "Epoch: 17\tFidelity = 0.500493\tKL_Divergence = 3.996801\n",
      "Epoch: 18\tFidelity = 0.500487\tKL_Divergence = 4.003676\n",
      "Epoch: 19\tFidelity = 0.500630\tKL_Divergence = 3.860700\n",
      "Epoch: 20\tFidelity = 0.500606\tKL_Divergence = 3.881728\n",
      "Epoch: 21\tFidelity = 0.500549\tKL_Divergence = 3.937204\n",
      "Epoch: 22\tFidelity = 0.500525\tKL_Divergence = 3.961550\n",
      "Epoch: 23\tFidelity = 0.500536\tKL_Divergence = 3.950437\n",
      "Epoch: 24\tFidelity = 0.500610\tKL_Divergence = 3.878465\n",
      "Epoch: 25\tFidelity = 0.500605\tKL_Divergence = 3.882795\n",
      "Epoch: 26\tFidelity = 0.500538\tKL_Divergence = 3.948370\n",
      "Epoch: 27\tFidelity = 0.500563\tKL_Divergence = 3.922313\n",
      "Epoch: 28\tFidelity = 0.500546\tKL_Divergence = 3.939312\n",
      "Epoch: 29\tFidelity = 0.500510\tKL_Divergence = 3.977252\n",
      "Epoch: 30\tFidelity = 0.500574\tKL_Divergence = 3.912277\n",
      "Epoch: 31\tFidelity = 0.500569\tKL_Divergence = 3.916535\n",
      "Epoch: 32\tFidelity = 0.500544\tKL_Divergence = 3.942126\n",
      "Epoch: 33\tFidelity = 0.500528\tKL_Divergence = 3.958636\n",
      "Epoch: 34\tFidelity = 0.500535\tKL_Divergence = 3.951239\n",
      "Epoch: 35\tFidelity = 0.500526\tKL_Divergence = 3.960834\n",
      "Epoch: 36\tFidelity = 0.500509\tKL_Divergence = 3.978657\n",
      "Epoch: 37\tFidelity = 0.500498\tKL_Divergence = 3.990967\n",
      "Epoch: 38\tFidelity = 0.500479\tKL_Divergence = 4.012576\n",
      "Epoch: 39\tFidelity = 0.500457\tKL_Divergence = 4.038019\n",
      "Epoch: 40\tFidelity = 0.500510\tKL_Divergence = 3.977652\n",
      "Epoch: 41\tFidelity = 0.500480\tKL_Divergence = 4.010903\n",
      "Epoch: 42\tFidelity = 0.500519\tKL_Divergence = 3.967083\n",
      "Epoch: 43\tFidelity = 0.500474\tKL_Divergence = 4.017371\n",
      "Epoch: 44\tFidelity = 0.500400\tKL_Divergence = 4.112278\n",
      "Epoch: 45\tFidelity = 0.500550\tKL_Divergence = 3.935458\n",
      "Epoch: 46\tFidelity = 0.500611\tKL_Divergence = 3.877365\n",
      "Epoch: 47\tFidelity = 0.500553\tKL_Divergence = 3.932721\n",
      "Epoch: 48\tFidelity = 0.500495\tKL_Divergence = 3.993821\n",
      "Epoch: 49\tFidelity = 0.500526\tKL_Divergence = 3.960944\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:38:41,066] Trial 538 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500557\tKL_Divergence = 3.929303\n",
      "Total time elapsed during training: 38.969 s\n",
      "Trial 538 pruned. \n",
      "Epoch: 1\tFidelity = 0.500459\tKL_Divergence = 4.035974\n",
      "Epoch: 2\tFidelity = 0.500479\tKL_Divergence = 4.012924\n",
      "Epoch: 3\tFidelity = 0.500440\tKL_Divergence = 4.059849\n",
      "Epoch: 4\tFidelity = 0.500495\tKL_Divergence = 3.994813\n",
      "Epoch: 5\tFidelity = 0.500506\tKL_Divergence = 3.982221\n",
      "Epoch: 6\tFidelity = 0.500526\tKL_Divergence = 3.961179\n",
      "Epoch: 7\tFidelity = 0.500493\tKL_Divergence = 3.996216\n",
      "Epoch: 8\tFidelity = 0.500513\tKL_Divergence = 3.974502\n",
      "Epoch: 9\tFidelity = 0.500513\tKL_Divergence = 3.974284\n",
      "Epoch: 10\tFidelity = 0.500544\tKL_Divergence = 3.942254\n",
      "Epoch: 11\tFidelity = 0.500423\tKL_Divergence = 4.081440\n",
      "Epoch: 12\tFidelity = 0.500551\tKL_Divergence = 3.935291\n",
      "Epoch: 13\tFidelity = 0.500562\tKL_Divergence = 3.923812\n",
      "Epoch: 14\tFidelity = 0.500528\tKL_Divergence = 3.958001\n",
      "Epoch: 15\tFidelity = 0.500498\tKL_Divergence = 3.990464\n",
      "Epoch: 16\tFidelity = 0.500426\tKL_Divergence = 4.077380\n",
      "Epoch: 17\tFidelity = 0.500443\tKL_Divergence = 4.055891\n",
      "Epoch: 18\tFidelity = 0.500488\tKL_Divergence = 4.002725\n",
      "Epoch: 19\tFidelity = 0.500439\tKL_Divergence = 4.060557\n",
      "Epoch: 20\tFidelity = 0.500511\tKL_Divergence = 3.976817\n",
      "Epoch: 21\tFidelity = 0.500574\tKL_Divergence = 3.911990\n",
      "Epoch: 22\tFidelity = 0.500544\tKL_Divergence = 3.942445\n",
      "Epoch: 23\tFidelity = 0.500569\tKL_Divergence = 3.917438\n",
      "Epoch: 24\tFidelity = 0.500438\tKL_Divergence = 4.062096\n",
      "Epoch: 25\tFidelity = 0.500541\tKL_Divergence = 3.945171\n",
      "Epoch: 26\tFidelity = 0.500468\tKL_Divergence = 4.025552\n",
      "Epoch: 27\tFidelity = 0.500533\tKL_Divergence = 3.953179\n",
      "Epoch: 28\tFidelity = 0.500501\tKL_Divergence = 3.987864\n",
      "Epoch: 29\tFidelity = 0.500477\tKL_Divergence = 4.015196\n",
      "Epoch: 30\tFidelity = 0.500488\tKL_Divergence = 4.002280\n",
      "Epoch: 31\tFidelity = 0.500452\tKL_Divergence = 4.044824\n",
      "Epoch: 32\tFidelity = 0.500400\tKL_Divergence = 4.113139\n",
      "Epoch: 33\tFidelity = 0.500465\tKL_Divergence = 4.029073\n",
      "Epoch: 34\tFidelity = 0.500455\tKL_Divergence = 4.041066\n",
      "Epoch: 35\tFidelity = 0.500459\tKL_Divergence = 4.035859\n",
      "Epoch: 36\tFidelity = 0.500467\tKL_Divergence = 4.025957\n",
      "Epoch: 37\tFidelity = 0.500459\tKL_Divergence = 4.035949\n",
      "Epoch: 38\tFidelity = 0.500440\tKL_Divergence = 4.059527\n",
      "Epoch: 39\tFidelity = 0.500541\tKL_Divergence = 3.944438\n",
      "Epoch: 40\tFidelity = 0.500546\tKL_Divergence = 3.939321\n",
      "Epoch: 41\tFidelity = 0.500456\tKL_Divergence = 4.040248\n",
      "Epoch: 42\tFidelity = 0.500459\tKL_Divergence = 4.036737\n",
      "Epoch: 43\tFidelity = 0.500543\tKL_Divergence = 3.943427\n",
      "Epoch: 44\tFidelity = 0.500598\tKL_Divergence = 3.889374\n",
      "Epoch: 45\tFidelity = 0.500585\tKL_Divergence = 3.901344\n",
      "Epoch: 46\tFidelity = 0.500601\tKL_Divergence = 3.886459\n",
      "Epoch: 47\tFidelity = 0.500519\tKL_Divergence = 3.968499\n",
      "Epoch: 48\tFidelity = 0.500537\tKL_Divergence = 3.949468\n",
      "Epoch: 49\tFidelity = 0.500588\tKL_Divergence = 3.899294\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:39:19,563] Trial 539 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500479\tKL_Divergence = 4.012894\n",
      "Total time elapsed during training: 38.325 s\n",
      "Trial 539 pruned. \n",
      "Epoch: 1\tFidelity = 0.500494\tKL_Divergence = 3.995767\n",
      "Epoch: 2\tFidelity = 0.500504\tKL_Divergence = 3.984546\n",
      "Epoch: 3\tFidelity = 0.500515\tKL_Divergence = 3.972963\n",
      "Epoch: 4\tFidelity = 0.500478\tKL_Divergence = 4.013897\n",
      "Epoch: 5\tFidelity = 0.500558\tKL_Divergence = 3.928384\n",
      "Epoch: 6\tFidelity = 0.500527\tKL_Divergence = 3.960007\n",
      "Epoch: 7\tFidelity = 0.500534\tKL_Divergence = 3.951979\n",
      "Epoch: 8\tFidelity = 0.500492\tKL_Divergence = 3.998253\n",
      "Epoch: 9\tFidelity = 0.500503\tKL_Divergence = 3.985052\n",
      "Epoch: 10\tFidelity = 0.500514\tKL_Divergence = 3.973858\n",
      "Epoch: 11\tFidelity = 0.500496\tKL_Divergence = 3.993488\n",
      "Epoch: 12\tFidelity = 0.500526\tKL_Divergence = 3.960259\n",
      "Epoch: 13\tFidelity = 0.500487\tKL_Divergence = 4.003354\n",
      "Epoch: 14\tFidelity = 0.500526\tKL_Divergence = 3.960311\n",
      "Epoch: 15\tFidelity = 0.500531\tKL_Divergence = 3.955969\n",
      "Epoch: 16\tFidelity = 0.500501\tKL_Divergence = 3.987465\n",
      "Epoch: 17\tFidelity = 0.500521\tKL_Divergence = 3.966330\n",
      "Epoch: 18\tFidelity = 0.500521\tKL_Divergence = 3.966546\n",
      "Epoch: 19\tFidelity = 0.500499\tKL_Divergence = 3.989479\n",
      "Epoch: 20\tFidelity = 0.500529\tKL_Divergence = 3.957387\n",
      "Epoch: 21\tFidelity = 0.500481\tKL_Divergence = 4.010575\n",
      "Epoch: 22\tFidelity = 0.500512\tKL_Divergence = 3.975385\n",
      "Epoch: 23\tFidelity = 0.500499\tKL_Divergence = 3.989561\n",
      "Epoch: 24\tFidelity = 0.500489\tKL_Divergence = 4.001304\n",
      "Epoch: 25\tFidelity = 0.500511\tKL_Divergence = 3.977253\n",
      "Epoch: 26\tFidelity = 0.500476\tKL_Divergence = 4.016040\n",
      "Epoch: 27\tFidelity = 0.500514\tKL_Divergence = 3.973400\n",
      "Epoch: 28\tFidelity = 0.500496\tKL_Divergence = 3.993878\n",
      "Epoch: 29\tFidelity = 0.500520\tKL_Divergence = 3.967264\n",
      "Epoch: 30\tFidelity = 0.500518\tKL_Divergence = 3.969339\n",
      "Epoch: 31\tFidelity = 0.500484\tKL_Divergence = 4.007089\n",
      "Epoch: 32\tFidelity = 0.500502\tKL_Divergence = 3.986260\n",
      "Epoch: 33\tFidelity = 0.500507\tKL_Divergence = 3.980684\n",
      "Epoch: 34\tFidelity = 0.500512\tKL_Divergence = 3.976093\n",
      "Epoch: 35\tFidelity = 0.500548\tKL_Divergence = 3.937566\n",
      "Epoch: 36\tFidelity = 0.500502\tKL_Divergence = 3.986834\n",
      "Epoch: 37\tFidelity = 0.500549\tKL_Divergence = 3.936747\n",
      "Epoch: 38\tFidelity = 0.500470\tKL_Divergence = 4.022728\n",
      "Epoch: 39\tFidelity = 0.500483\tKL_Divergence = 4.007940\n",
      "Epoch: 40\tFidelity = 0.500522\tKL_Divergence = 3.964546\n",
      "Epoch: 41\tFidelity = 0.500523\tKL_Divergence = 3.964202\n",
      "Epoch: 42\tFidelity = 0.500480\tKL_Divergence = 4.011821\n",
      "Epoch: 43\tFidelity = 0.500485\tKL_Divergence = 4.006186\n",
      "Epoch: 44\tFidelity = 0.500516\tKL_Divergence = 3.971682\n",
      "Epoch: 45\tFidelity = 0.500531\tKL_Divergence = 3.955958\n",
      "Epoch: 46\tFidelity = 0.500490\tKL_Divergence = 4.000038\n",
      "Epoch: 47\tFidelity = 0.500494\tKL_Divergence = 3.996147\n",
      "Epoch: 48\tFidelity = 0.500518\tKL_Divergence = 3.968808\n",
      "Epoch: 49\tFidelity = 0.500494\tKL_Divergence = 3.995806\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:39:59,123] Trial 540 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500498\tKL_Divergence = 3.991497\n",
      "Total time elapsed during training: 39.381 s\n",
      "Trial 540 pruned. \n",
      "Epoch: 1\tFidelity = 0.500575\tKL_Divergence = 3.911299\n",
      "Epoch: 2\tFidelity = 0.500436\tKL_Divergence = 4.064373\n",
      "Epoch: 3\tFidelity = 0.500462\tKL_Divergence = 4.032823\n",
      "Epoch: 4\tFidelity = 0.500419\tKL_Divergence = 4.087285\n",
      "Epoch: 5\tFidelity = 0.500542\tKL_Divergence = 3.943957\n",
      "Epoch: 6\tFidelity = 0.500598\tKL_Divergence = 3.889944\n",
      "Epoch: 7\tFidelity = 0.500661\tKL_Divergence = 3.834041\n",
      "Epoch: 8\tFidelity = 0.500524\tKL_Divergence = 3.962823\n",
      "Epoch: 9\tFidelity = 0.500559\tKL_Divergence = 3.927085\n",
      "Epoch: 10\tFidelity = 0.500576\tKL_Divergence = 3.910260\n",
      "Epoch: 11\tFidelity = 0.500522\tKL_Divergence = 3.964714\n",
      "Epoch: 12\tFidelity = 0.500598\tKL_Divergence = 3.890033\n",
      "Epoch: 13\tFidelity = 0.500479\tKL_Divergence = 4.012455\n",
      "Epoch: 14\tFidelity = 0.500400\tKL_Divergence = 4.112095\n",
      "Epoch: 15\tFidelity = 0.500469\tKL_Divergence = 4.024383\n",
      "Epoch: 16\tFidelity = 0.500415\tKL_Divergence = 4.092002\n",
      "Epoch: 17\tFidelity = 0.500603\tKL_Divergence = 3.884972\n",
      "Epoch: 18\tFidelity = 0.500641\tKL_Divergence = 3.851117\n",
      "Epoch: 19\tFidelity = 0.500440\tKL_Divergence = 4.060146\n",
      "Epoch: 20\tFidelity = 0.500475\tKL_Divergence = 4.017569\n",
      "Epoch: 21\tFidelity = 0.500372\tKL_Divergence = 4.153425\n",
      "Epoch: 22\tFidelity = 0.500404\tKL_Divergence = 4.106544\n",
      "Epoch: 23\tFidelity = 0.500467\tKL_Divergence = 4.027120\n",
      "Epoch: 24\tFidelity = 0.500550\tKL_Divergence = 3.935954\n",
      "Epoch: 25\tFidelity = 0.500435\tKL_Divergence = 4.066774\n",
      "Epoch: 26\tFidelity = 0.500624\tKL_Divergence = 3.865963\n",
      "Epoch: 27\tFidelity = 0.500468\tKL_Divergence = 4.026033\n",
      "Epoch: 28\tFidelity = 0.500428\tKL_Divergence = 4.075250\n",
      "Epoch: 29\tFidelity = 0.500407\tKL_Divergence = 4.103577\n",
      "Epoch: 30\tFidelity = 0.500652\tKL_Divergence = 3.841617\n",
      "Epoch: 31\tFidelity = 0.500511\tKL_Divergence = 3.976353\n",
      "Epoch: 32\tFidelity = 0.500455\tKL_Divergence = 4.039931\n",
      "Epoch: 33\tFidelity = 0.500502\tKL_Divergence = 3.986557\n",
      "Epoch: 34\tFidelity = 0.500617\tKL_Divergence = 3.871584\n",
      "Epoch: 35\tFidelity = 0.500476\tKL_Divergence = 4.015374\n",
      "Epoch: 36\tFidelity = 0.500535\tKL_Divergence = 3.950891\n",
      "Epoch: 37\tFidelity = 0.500449\tKL_Divergence = 4.047854\n",
      "Epoch: 38\tFidelity = 0.500621\tKL_Divergence = 3.868026\n",
      "Epoch: 39\tFidelity = 0.500662\tKL_Divergence = 3.832330\n",
      "Epoch: 40\tFidelity = 0.500586\tKL_Divergence = 3.900023\n",
      "Epoch: 41\tFidelity = 0.500432\tKL_Divergence = 4.069237\n",
      "Epoch: 42\tFidelity = 0.500678\tKL_Divergence = 3.819607\n",
      "Epoch: 43\tFidelity = 0.500398\tKL_Divergence = 4.114942\n",
      "Epoch: 44\tFidelity = 0.500449\tKL_Divergence = 4.048295\n",
      "Epoch: 45\tFidelity = 0.500494\tKL_Divergence = 3.995174\n",
      "Epoch: 46\tFidelity = 0.500526\tKL_Divergence = 3.960477\n",
      "Epoch: 47\tFidelity = 0.500596\tKL_Divergence = 3.891577\n",
      "Epoch: 48\tFidelity = 0.500550\tKL_Divergence = 3.935927\n",
      "Epoch: 49\tFidelity = 0.500540\tKL_Divergence = 3.946136\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:40:59,110] Trial 541 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500549\tKL_Divergence = 3.937011\n",
      "Total time elapsed during training: 59.790 s\n",
      "Trial 541 pruned. \n",
      "Epoch: 1\tFidelity = 0.500558\tKL_Divergence = 3.928003\n",
      "Epoch: 2\tFidelity = 0.500648\tKL_Divergence = 3.844654\n",
      "Epoch: 3\tFidelity = 0.500597\tKL_Divergence = 3.890741\n",
      "Epoch: 4\tFidelity = 0.500560\tKL_Divergence = 3.925520\n",
      "Epoch: 5\tFidelity = 0.500540\tKL_Divergence = 3.946508\n",
      "Epoch: 6\tFidelity = 0.500572\tKL_Divergence = 3.913927\n",
      "Epoch: 7\tFidelity = 0.500665\tKL_Divergence = 3.830968\n",
      "Epoch: 8\tFidelity = 0.500553\tKL_Divergence = 3.933013\n",
      "Epoch: 9\tFidelity = 0.500417\tKL_Divergence = 4.089618\n",
      "Epoch: 10\tFidelity = 0.500598\tKL_Divergence = 3.889668\n",
      "Epoch: 11\tFidelity = 0.500492\tKL_Divergence = 3.997927\n",
      "Epoch: 12\tFidelity = 0.500552\tKL_Divergence = 3.934440\n",
      "Epoch: 13\tFidelity = 0.500431\tKL_Divergence = 4.070911\n",
      "Epoch: 14\tFidelity = 0.500537\tKL_Divergence = 3.948877\n",
      "Epoch: 15\tFidelity = 0.500501\tKL_Divergence = 3.987349\n",
      "Epoch: 16\tFidelity = 0.500580\tKL_Divergence = 3.906203\n",
      "Epoch: 17\tFidelity = 0.500501\tKL_Divergence = 3.987384\n",
      "Epoch: 18\tFidelity = 0.500395\tKL_Divergence = 4.119035\n",
      "Epoch: 19\tFidelity = 0.500481\tKL_Divergence = 4.010594\n",
      "Epoch: 20\tFidelity = 0.500584\tKL_Divergence = 3.902330\n",
      "Epoch: 21\tFidelity = 0.500534\tKL_Divergence = 3.952311\n",
      "Epoch: 22\tFidelity = 0.500508\tKL_Divergence = 3.980398\n",
      "Epoch: 23\tFidelity = 0.500480\tKL_Divergence = 4.011885\n",
      "Epoch: 24\tFidelity = 0.500418\tKL_Divergence = 4.088467\n",
      "Epoch: 25\tFidelity = 0.500429\tKL_Divergence = 4.073305\n",
      "Epoch: 26\tFidelity = 0.500573\tKL_Divergence = 3.913644\n",
      "Epoch: 27\tFidelity = 0.500426\tKL_Divergence = 4.078002\n",
      "Epoch: 28\tFidelity = 0.500538\tKL_Divergence = 3.948055\n",
      "Epoch: 29\tFidelity = 0.500475\tKL_Divergence = 4.017144\n",
      "Epoch: 30\tFidelity = 0.500580\tKL_Divergence = 3.906381\n",
      "Epoch: 31\tFidelity = 0.500610\tKL_Divergence = 3.878329\n",
      "Epoch: 32\tFidelity = 0.500389\tKL_Divergence = 4.127894\n",
      "Epoch: 33\tFidelity = 0.500450\tKL_Divergence = 4.047467\n",
      "Epoch: 34\tFidelity = 0.500524\tKL_Divergence = 3.962608\n",
      "Epoch: 35\tFidelity = 0.500497\tKL_Divergence = 3.992579\n",
      "Epoch: 36\tFidelity = 0.500579\tKL_Divergence = 3.907490\n",
      "Epoch: 37\tFidelity = 0.500481\tKL_Divergence = 4.010563\n",
      "Epoch: 38\tFidelity = 0.500512\tKL_Divergence = 3.975317\n",
      "Epoch: 39\tFidelity = 0.500558\tKL_Divergence = 3.928247\n",
      "Epoch: 40\tFidelity = 0.500513\tKL_Divergence = 3.974837\n",
      "Epoch: 41\tFidelity = 0.500468\tKL_Divergence = 4.025787\n",
      "Epoch: 42\tFidelity = 0.500426\tKL_Divergence = 4.077165\n",
      "Epoch: 43\tFidelity = 0.500686\tKL_Divergence = 3.813321\n",
      "Epoch: 44\tFidelity = 0.500536\tKL_Divergence = 3.950137\n",
      "Epoch: 45\tFidelity = 0.500592\tKL_Divergence = 3.895163\n",
      "Epoch: 46\tFidelity = 0.500433\tKL_Divergence = 4.068263\n",
      "Epoch: 47\tFidelity = 0.500576\tKL_Divergence = 3.910430\n",
      "Epoch: 48\tFidelity = 0.500491\tKL_Divergence = 3.999280\n",
      "Epoch: 49\tFidelity = 0.500503\tKL_Divergence = 3.985527\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:42:20,224] Trial 542 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500611\tKL_Divergence = 3.877666\n",
      "Total time elapsed during training: 80.921 s\n",
      "Trial 542 pruned. \n",
      "Epoch: 1\tFidelity = 0.500504\tKL_Divergence = 3.984700\n",
      "Epoch: 2\tFidelity = 0.500511\tKL_Divergence = 3.976404\n",
      "Epoch: 3\tFidelity = 0.500539\tKL_Divergence = 3.947289\n",
      "Epoch: 4\tFidelity = 0.500534\tKL_Divergence = 3.952692\n",
      "Epoch: 5\tFidelity = 0.500536\tKL_Divergence = 3.949818\n",
      "Epoch: 6\tFidelity = 0.500544\tKL_Divergence = 3.942038\n",
      "Epoch: 7\tFidelity = 0.500574\tKL_Divergence = 3.912292\n",
      "Epoch: 8\tFidelity = 0.500554\tKL_Divergence = 3.931371\n",
      "Epoch: 9\tFidelity = 0.500585\tKL_Divergence = 3.902175\n",
      "Epoch: 10\tFidelity = 0.500523\tKL_Divergence = 3.963763\n",
      "Epoch: 11\tFidelity = 0.500535\tKL_Divergence = 3.950728\n",
      "Epoch: 12\tFidelity = 0.500521\tKL_Divergence = 3.965964\n",
      "Epoch: 13\tFidelity = 0.500558\tKL_Divergence = 3.928230\n",
      "Epoch: 14\tFidelity = 0.500599\tKL_Divergence = 3.888452\n",
      "Epoch: 15\tFidelity = 0.500599\tKL_Divergence = 3.888563\n",
      "Epoch: 16\tFidelity = 0.500553\tKL_Divergence = 3.932683\n",
      "Epoch: 17\tFidelity = 0.500559\tKL_Divergence = 3.926386\n",
      "Epoch: 18\tFidelity = 0.500527\tKL_Divergence = 3.959406\n",
      "Epoch: 19\tFidelity = 0.500529\tKL_Divergence = 3.957115\n",
      "Epoch: 20\tFidelity = 0.500507\tKL_Divergence = 3.981207\n",
      "Epoch: 21\tFidelity = 0.500530\tKL_Divergence = 3.956233\n",
      "Epoch: 22\tFidelity = 0.500550\tKL_Divergence = 3.935443\n",
      "Epoch: 23\tFidelity = 0.500567\tKL_Divergence = 3.918739\n",
      "Epoch: 24\tFidelity = 0.500490\tKL_Divergence = 3.999676\n",
      "Epoch: 25\tFidelity = 0.500486\tKL_Divergence = 4.004412\n",
      "Epoch: 26\tFidelity = 0.500565\tKL_Divergence = 3.920697\n",
      "Epoch: 27\tFidelity = 0.500488\tKL_Divergence = 4.001872\n",
      "Epoch: 28\tFidelity = 0.500550\tKL_Divergence = 3.935859\n",
      "Epoch: 29\tFidelity = 0.500543\tKL_Divergence = 3.942910\n",
      "Epoch: 30\tFidelity = 0.500521\tKL_Divergence = 3.965454\n",
      "Epoch: 31\tFidelity = 0.500499\tKL_Divergence = 3.989789\n",
      "Epoch: 32\tFidelity = 0.500522\tKL_Divergence = 3.964235\n",
      "Epoch: 33\tFidelity = 0.500558\tKL_Divergence = 3.927335\n",
      "Epoch: 34\tFidelity = 0.500494\tKL_Divergence = 3.995373\n",
      "Epoch: 35\tFidelity = 0.500521\tKL_Divergence = 3.965870\n",
      "Epoch: 36\tFidelity = 0.500515\tKL_Divergence = 3.972594\n",
      "Epoch: 37\tFidelity = 0.500533\tKL_Divergence = 3.952800\n",
      "Epoch: 38\tFidelity = 0.500504\tKL_Divergence = 3.984756\n",
      "Epoch: 39\tFidelity = 0.500475\tKL_Divergence = 4.016739\n",
      "Epoch: 40\tFidelity = 0.500567\tKL_Divergence = 3.919266\n",
      "Epoch: 41\tFidelity = 0.500606\tKL_Divergence = 3.882247\n",
      "Epoch: 42\tFidelity = 0.500554\tKL_Divergence = 3.932246\n",
      "Epoch: 43\tFidelity = 0.500530\tKL_Divergence = 3.956531\n",
      "Epoch: 44\tFidelity = 0.500581\tKL_Divergence = 3.905808\n",
      "Epoch: 45\tFidelity = 0.500522\tKL_Divergence = 3.964772\n",
      "Epoch: 46\tFidelity = 0.500557\tKL_Divergence = 3.929077\n",
      "Epoch: 47\tFidelity = 0.500498\tKL_Divergence = 3.990866\n",
      "Epoch: 48\tFidelity = 0.500522\tKL_Divergence = 3.964984\n",
      "Epoch: 49\tFidelity = 0.500512\tKL_Divergence = 3.976113\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:42:57,133] Trial 543 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500510\tKL_Divergence = 3.977779\n",
      "Total time elapsed during training: 36.730 s\n",
      "Trial 543 pruned. \n",
      "Epoch: 1\tFidelity = 0.500525\tKL_Divergence = 3.961608\n",
      "Epoch: 2\tFidelity = 0.500575\tKL_Divergence = 3.911562\n",
      "Epoch: 3\tFidelity = 0.500538\tKL_Divergence = 3.948164\n",
      "Epoch: 4\tFidelity = 0.500505\tKL_Divergence = 3.983522\n",
      "Epoch: 5\tFidelity = 0.500518\tKL_Divergence = 3.969398\n",
      "Epoch: 6\tFidelity = 0.500515\tKL_Divergence = 3.972800\n",
      "Epoch: 7\tFidelity = 0.500530\tKL_Divergence = 3.956210\n",
      "Epoch: 8\tFidelity = 0.500567\tKL_Divergence = 3.919136\n",
      "Epoch: 9\tFidelity = 0.500514\tKL_Divergence = 3.973877\n",
      "Epoch: 10\tFidelity = 0.500557\tKL_Divergence = 3.929290\n",
      "Epoch: 11\tFidelity = 0.500540\tKL_Divergence = 3.946601\n",
      "Epoch: 12\tFidelity = 0.500609\tKL_Divergence = 3.879506\n",
      "Epoch: 13\tFidelity = 0.500544\tKL_Divergence = 3.941987\n",
      "Epoch: 14\tFidelity = 0.500530\tKL_Divergence = 3.956760\n",
      "Epoch: 15\tFidelity = 0.500574\tKL_Divergence = 3.911824\n",
      "Epoch: 16\tFidelity = 0.500522\tKL_Divergence = 3.965107\n",
      "Epoch: 17\tFidelity = 0.500513\tKL_Divergence = 3.974641\n",
      "Epoch: 18\tFidelity = 0.500596\tKL_Divergence = 3.891662\n",
      "Epoch: 19\tFidelity = 0.500559\tKL_Divergence = 3.927228\n",
      "Epoch: 20\tFidelity = 0.500583\tKL_Divergence = 3.903197\n",
      "Epoch: 21\tFidelity = 0.500521\tKL_Divergence = 3.965948\n",
      "Epoch: 22\tFidelity = 0.500574\tKL_Divergence = 3.912555\n",
      "Epoch: 23\tFidelity = 0.500581\tKL_Divergence = 3.905417\n",
      "Epoch: 24\tFidelity = 0.500546\tKL_Divergence = 3.940454\n",
      "Epoch: 25\tFidelity = 0.500539\tKL_Divergence = 3.946752\n",
      "Epoch: 26\tFidelity = 0.500560\tKL_Divergence = 3.925897\n",
      "Epoch: 27\tFidelity = 0.500533\tKL_Divergence = 3.953315\n",
      "Epoch: 28\tFidelity = 0.500542\tKL_Divergence = 3.943562\n",
      "Epoch: 29\tFidelity = 0.500529\tKL_Divergence = 3.957409\n",
      "Epoch: 30\tFidelity = 0.500559\tKL_Divergence = 3.926936\n",
      "Epoch: 31\tFidelity = 0.500529\tKL_Divergence = 3.957925\n",
      "Epoch: 32\tFidelity = 0.500515\tKL_Divergence = 3.972140\n",
      "Epoch: 33\tFidelity = 0.500530\tKL_Divergence = 3.956050\n",
      "Epoch: 34\tFidelity = 0.500540\tKL_Divergence = 3.946007\n",
      "Epoch: 35\tFidelity = 0.500527\tKL_Divergence = 3.959264\n",
      "Epoch: 36\tFidelity = 0.500518\tKL_Divergence = 3.969322\n",
      "Epoch: 37\tFidelity = 0.500569\tKL_Divergence = 3.917139\n",
      "Epoch: 38\tFidelity = 0.500535\tKL_Divergence = 3.951186\n",
      "Epoch: 39\tFidelity = 0.500549\tKL_Divergence = 3.937440\n",
      "Epoch: 40\tFidelity = 0.500566\tKL_Divergence = 3.920138\n",
      "Epoch: 41\tFidelity = 0.500564\tKL_Divergence = 3.921902\n",
      "Epoch: 42\tFidelity = 0.500525\tKL_Divergence = 3.961839\n",
      "Epoch: 43\tFidelity = 0.500558\tKL_Divergence = 3.928381\n",
      "Epoch: 44\tFidelity = 0.500558\tKL_Divergence = 3.928025\n",
      "Epoch: 45\tFidelity = 0.500547\tKL_Divergence = 3.938570\n",
      "Epoch: 46\tFidelity = 0.500537\tKL_Divergence = 3.949545\n",
      "Epoch: 47\tFidelity = 0.500533\tKL_Divergence = 3.953627\n",
      "Epoch: 48\tFidelity = 0.500518\tKL_Divergence = 3.969636\n",
      "Epoch: 49\tFidelity = 0.500522\tKL_Divergence = 3.964620\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:43:41,278] Trial 544 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500554\tKL_Divergence = 3.931608\n",
      "Total time elapsed during training: 43.883 s\n",
      "Trial 544 pruned. \n",
      "Epoch: 1\tFidelity = 0.500507\tKL_Divergence = 3.980911\n",
      "Epoch: 2\tFidelity = 0.500550\tKL_Divergence = 3.935820\n",
      "Epoch: 3\tFidelity = 0.500507\tKL_Divergence = 3.980791\n",
      "Epoch: 4\tFidelity = 0.500559\tKL_Divergence = 3.926886\n",
      "Epoch: 5\tFidelity = 0.500554\tKL_Divergence = 3.931591\n",
      "Epoch: 6\tFidelity = 0.500568\tKL_Divergence = 3.917675\n",
      "Epoch: 7\tFidelity = 0.500546\tKL_Divergence = 3.940382\n",
      "Epoch: 8\tFidelity = 0.500519\tKL_Divergence = 3.968379\n",
      "Epoch: 9\tFidelity = 0.500542\tKL_Divergence = 3.943912\n",
      "Epoch: 10\tFidelity = 0.500515\tKL_Divergence = 3.971965\n",
      "Epoch: 11\tFidelity = 0.500559\tKL_Divergence = 3.926763\n",
      "Epoch: 12\tFidelity = 0.500500\tKL_Divergence = 3.988867\n",
      "Epoch: 13\tFidelity = 0.500534\tKL_Divergence = 3.951921\n",
      "Epoch: 14\tFidelity = 0.500493\tKL_Divergence = 3.996224\n",
      "Epoch: 15\tFidelity = 0.500563\tKL_Divergence = 3.923140\n",
      "Epoch: 16\tFidelity = 0.500538\tKL_Divergence = 3.948526\n",
      "Epoch: 17\tFidelity = 0.500587\tKL_Divergence = 3.900146\n",
      "Epoch: 18\tFidelity = 0.500512\tKL_Divergence = 3.975401\n",
      "Epoch: 19\tFidelity = 0.500580\tKL_Divergence = 3.906524\n",
      "Epoch: 20\tFidelity = 0.500537\tKL_Divergence = 3.949654\n",
      "Epoch: 21\tFidelity = 0.500557\tKL_Divergence = 3.929192\n",
      "Epoch: 22\tFidelity = 0.500552\tKL_Divergence = 3.933794\n",
      "Epoch: 23\tFidelity = 0.500559\tKL_Divergence = 3.926550\n",
      "Epoch: 24\tFidelity = 0.500533\tKL_Divergence = 3.953829\n",
      "Epoch: 25\tFidelity = 0.500526\tKL_Divergence = 3.960574\n",
      "Epoch: 26\tFidelity = 0.500558\tKL_Divergence = 3.927917\n",
      "Epoch: 27\tFidelity = 0.500512\tKL_Divergence = 3.975222\n",
      "Epoch: 28\tFidelity = 0.500529\tKL_Divergence = 3.957584\n",
      "Epoch: 29\tFidelity = 0.500525\tKL_Divergence = 3.962049\n",
      "Epoch: 30\tFidelity = 0.500502\tKL_Divergence = 3.987047\n",
      "Epoch: 31\tFidelity = 0.500505\tKL_Divergence = 3.983176\n",
      "Epoch: 32\tFidelity = 0.500560\tKL_Divergence = 3.925703\n",
      "Epoch: 33\tFidelity = 0.500545\tKL_Divergence = 3.940513\n",
      "Epoch: 34\tFidelity = 0.500525\tKL_Divergence = 3.961577\n",
      "Epoch: 35\tFidelity = 0.500527\tKL_Divergence = 3.959498\n",
      "Epoch: 36\tFidelity = 0.500531\tKL_Divergence = 3.955925\n",
      "Epoch: 37\tFidelity = 0.500567\tKL_Divergence = 3.918690\n",
      "Epoch: 38\tFidelity = 0.500510\tKL_Divergence = 3.977741\n",
      "Epoch: 39\tFidelity = 0.500530\tKL_Divergence = 3.956381\n",
      "Epoch: 40\tFidelity = 0.500526\tKL_Divergence = 3.960648\n",
      "Epoch: 41\tFidelity = 0.500545\tKL_Divergence = 3.940837\n",
      "Epoch: 42\tFidelity = 0.500483\tKL_Divergence = 4.007820\n",
      "Epoch: 43\tFidelity = 0.500543\tKL_Divergence = 3.942934\n",
      "Epoch: 44\tFidelity = 0.500535\tKL_Divergence = 3.951411\n",
      "Epoch: 45\tFidelity = 0.500561\tKL_Divergence = 3.924477\n",
      "Epoch: 46\tFidelity = 0.500518\tKL_Divergence = 3.969382\n",
      "Epoch: 47\tFidelity = 0.500530\tKL_Divergence = 3.956294\n",
      "Epoch: 48\tFidelity = 0.500508\tKL_Divergence = 3.979616\n",
      "Epoch: 49\tFidelity = 0.500547\tKL_Divergence = 3.938778\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:44:12,303] Trial 545 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500529\tKL_Divergence = 3.957512\n",
      "Total time elapsed during training: 30.834 s\n",
      "Trial 545 pruned. \n",
      "Epoch: 1\tFidelity = 0.500523\tKL_Divergence = 3.963942\n",
      "Epoch: 2\tFidelity = 0.500513\tKL_Divergence = 3.974866\n",
      "Epoch: 3\tFidelity = 0.500530\tKL_Divergence = 3.956121\n",
      "Epoch: 4\tFidelity = 0.500495\tKL_Divergence = 3.994549\n",
      "Epoch: 5\tFidelity = 0.500607\tKL_Divergence = 3.880912\n",
      "Epoch: 6\tFidelity = 0.500508\tKL_Divergence = 3.980184\n",
      "Epoch: 7\tFidelity = 0.500504\tKL_Divergence = 3.984619\n",
      "Epoch: 8\tFidelity = 0.500518\tKL_Divergence = 3.968951\n",
      "Epoch: 9\tFidelity = 0.500469\tKL_Divergence = 4.024223\n",
      "Epoch: 10\tFidelity = 0.500570\tKL_Divergence = 3.915881\n",
      "Epoch: 11\tFidelity = 0.500543\tKL_Divergence = 3.942832\n",
      "Epoch: 12\tFidelity = 0.500565\tKL_Divergence = 3.920606\n",
      "Epoch: 13\tFidelity = 0.500549\tKL_Divergence = 3.936492\n",
      "Epoch: 14\tFidelity = 0.500514\tKL_Divergence = 3.973860\n",
      "Epoch: 15\tFidelity = 0.500543\tKL_Divergence = 3.943127\n",
      "Epoch: 16\tFidelity = 0.500555\tKL_Divergence = 3.931095\n",
      "Epoch: 17\tFidelity = 0.500506\tKL_Divergence = 3.982552\n",
      "Epoch: 18\tFidelity = 0.500546\tKL_Divergence = 3.939839\n",
      "Epoch: 19\tFidelity = 0.500490\tKL_Divergence = 3.999930\n",
      "Epoch: 20\tFidelity = 0.500576\tKL_Divergence = 3.909926\n",
      "Epoch: 21\tFidelity = 0.500476\tKL_Divergence = 4.015624\n",
      "Epoch: 22\tFidelity = 0.500524\tKL_Divergence = 3.962865\n",
      "Epoch: 23\tFidelity = 0.500524\tKL_Divergence = 3.962641\n",
      "Epoch: 24\tFidelity = 0.500491\tKL_Divergence = 3.999349\n",
      "Epoch: 25\tFidelity = 0.500524\tKL_Divergence = 3.962939\n",
      "Epoch: 26\tFidelity = 0.500523\tKL_Divergence = 3.963372\n",
      "Epoch: 27\tFidelity = 0.500510\tKL_Divergence = 3.977331\n",
      "Epoch: 28\tFidelity = 0.500506\tKL_Divergence = 3.982563\n",
      "Epoch: 29\tFidelity = 0.500496\tKL_Divergence = 3.993658\n",
      "Epoch: 30\tFidelity = 0.500572\tKL_Divergence = 3.914538\n",
      "Epoch: 31\tFidelity = 0.500538\tKL_Divergence = 3.947785\n",
      "Epoch: 32\tFidelity = 0.500551\tKL_Divergence = 3.934884\n",
      "Epoch: 33\tFidelity = 0.500515\tKL_Divergence = 3.971956\n",
      "Epoch: 34\tFidelity = 0.500508\tKL_Divergence = 3.979854\n",
      "Epoch: 35\tFidelity = 0.500509\tKL_Divergence = 3.978530\n",
      "Epoch: 36\tFidelity = 0.500486\tKL_Divergence = 4.004886\n",
      "Epoch: 37\tFidelity = 0.500598\tKL_Divergence = 3.889174\n",
      "Epoch: 38\tFidelity = 0.500549\tKL_Divergence = 3.937403\n",
      "Epoch: 39\tFidelity = 0.500522\tKL_Divergence = 3.965321\n",
      "Epoch: 40\tFidelity = 0.500531\tKL_Divergence = 3.955957\n",
      "Epoch: 41\tFidelity = 0.500520\tKL_Divergence = 3.966881\n",
      "Epoch: 42\tFidelity = 0.500532\tKL_Divergence = 3.954287\n",
      "Epoch: 43\tFidelity = 0.500556\tKL_Divergence = 3.930299\n",
      "Epoch: 44\tFidelity = 0.500532\tKL_Divergence = 3.954530\n",
      "Epoch: 45\tFidelity = 0.500547\tKL_Divergence = 3.938661\n",
      "Epoch: 46\tFidelity = 0.500562\tKL_Divergence = 3.924286\n",
      "Epoch: 47\tFidelity = 0.500512\tKL_Divergence = 3.975495\n",
      "Epoch: 48\tFidelity = 0.500537\tKL_Divergence = 3.949319\n",
      "Epoch: 49\tFidelity = 0.500563\tKL_Divergence = 3.922543\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:44:49,745] Trial 546 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500572\tKL_Divergence = 3.914603\n",
      "Total time elapsed during training: 37.272 s\n",
      "Trial 546 pruned. \n",
      "Epoch: 1\tFidelity = 0.500518\tKL_Divergence = 3.969579\n",
      "Epoch: 2\tFidelity = 0.500422\tKL_Divergence = 4.083030\n",
      "Epoch: 3\tFidelity = 0.500532\tKL_Divergence = 3.954273\n",
      "Epoch: 4\tFidelity = 0.500687\tKL_Divergence = 3.812534\n",
      "Epoch: 5\tFidelity = 0.500540\tKL_Divergence = 3.945801\n",
      "Epoch: 6\tFidelity = 0.500473\tKL_Divergence = 4.019312\n",
      "Epoch: 7\tFidelity = 0.500600\tKL_Divergence = 3.888088\n",
      "Epoch: 8\tFidelity = 0.500525\tKL_Divergence = 3.961536\n",
      "Epoch: 9\tFidelity = 0.500541\tKL_Divergence = 3.944876\n",
      "Epoch: 10\tFidelity = 0.500635\tKL_Divergence = 3.856080\n",
      "Epoch: 11\tFidelity = 0.500582\tKL_Divergence = 3.904440\n",
      "Epoch: 12\tFidelity = 0.500567\tKL_Divergence = 3.918755\n",
      "Epoch: 13\tFidelity = 0.500563\tKL_Divergence = 3.923240\n",
      "Epoch: 14\tFidelity = 0.500691\tKL_Divergence = 3.809196\n",
      "Epoch: 15\tFidelity = 0.500568\tKL_Divergence = 3.918527\n",
      "Epoch: 16\tFidelity = 0.500629\tKL_Divergence = 3.861348\n",
      "Epoch: 17\tFidelity = 0.500445\tKL_Divergence = 4.053001\n",
      "Epoch: 18\tFidelity = 0.500404\tKL_Divergence = 4.106889\n",
      "Epoch: 19\tFidelity = 0.500605\tKL_Divergence = 3.882828\n",
      "Epoch: 20\tFidelity = 0.500460\tKL_Divergence = 4.034834\n",
      "Epoch: 21\tFidelity = 0.500472\tKL_Divergence = 4.020265\n",
      "Epoch: 22\tFidelity = 0.500567\tKL_Divergence = 3.918656\n",
      "Epoch: 23\tFidelity = 0.500580\tKL_Divergence = 3.906754\n",
      "Epoch: 24\tFidelity = 0.500591\tKL_Divergence = 3.896417\n",
      "Epoch: 25\tFidelity = 0.500593\tKL_Divergence = 3.894399\n",
      "Epoch: 26\tFidelity = 0.500662\tKL_Divergence = 3.833061\n",
      "Epoch: 27\tFidelity = 0.500525\tKL_Divergence = 3.961337\n",
      "Epoch: 28\tFidelity = 0.500599\tKL_Divergence = 3.888587\n",
      "Epoch: 29\tFidelity = 0.500495\tKL_Divergence = 3.994441\n",
      "Epoch: 30\tFidelity = 0.500525\tKL_Divergence = 3.962299\n",
      "Epoch: 31\tFidelity = 0.500523\tKL_Divergence = 3.964266\n",
      "Epoch: 32\tFidelity = 0.500501\tKL_Divergence = 3.987917\n",
      "Epoch: 33\tFidelity = 0.500592\tKL_Divergence = 3.894913\n",
      "Epoch: 34\tFidelity = 0.500626\tKL_Divergence = 3.864453\n",
      "Epoch: 35\tFidelity = 0.500591\tKL_Divergence = 3.895621\n",
      "Epoch: 36\tFidelity = 0.500574\tKL_Divergence = 3.912550\n",
      "Epoch: 37\tFidelity = 0.500619\tKL_Divergence = 3.870003\n",
      "Epoch: 38\tFidelity = 0.500644\tKL_Divergence = 3.848674\n",
      "Epoch: 39\tFidelity = 0.500522\tKL_Divergence = 3.965380\n",
      "Epoch: 40\tFidelity = 0.500557\tKL_Divergence = 3.929244\n",
      "Epoch: 41\tFidelity = 0.500493\tKL_Divergence = 3.996357\n",
      "Epoch: 42\tFidelity = 0.500590\tKL_Divergence = 3.897151\n",
      "Epoch: 43\tFidelity = 0.500510\tKL_Divergence = 3.977915\n",
      "Epoch: 44\tFidelity = 0.500476\tKL_Divergence = 4.015733\n",
      "Epoch: 45\tFidelity = 0.500448\tKL_Divergence = 4.050161\n",
      "Epoch: 46\tFidelity = 0.500602\tKL_Divergence = 3.885781\n",
      "Epoch: 47\tFidelity = 0.500487\tKL_Divergence = 4.003418\n",
      "Epoch: 48\tFidelity = 0.500615\tKL_Divergence = 3.874320\n",
      "Epoch: 49\tFidelity = 0.500555\tKL_Divergence = 3.931281\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:45:20,581] Trial 547 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500558\tKL_Divergence = 3.928323\n",
      "Total time elapsed during training: 30.657 s\n",
      "Trial 547 pruned. \n",
      "Epoch: 1\tFidelity = 0.500513\tKL_Divergence = 3.974740\n",
      "Epoch: 2\tFidelity = 0.500535\tKL_Divergence = 3.951762\n",
      "Epoch: 3\tFidelity = 0.500651\tKL_Divergence = 3.842559\n",
      "Epoch: 4\tFidelity = 0.500544\tKL_Divergence = 3.942248\n",
      "Epoch: 5\tFidelity = 0.500536\tKL_Divergence = 3.950153\n",
      "Epoch: 6\tFidelity = 0.500488\tKL_Divergence = 4.002000\n",
      "Epoch: 7\tFidelity = 0.500527\tKL_Divergence = 3.959477\n",
      "Epoch: 8\tFidelity = 0.500534\tKL_Divergence = 3.952348\n",
      "Epoch: 9\tFidelity = 0.500470\tKL_Divergence = 4.023613\n",
      "Epoch: 10\tFidelity = 0.500533\tKL_Divergence = 3.953193\n",
      "Epoch: 11\tFidelity = 0.500597\tKL_Divergence = 3.890670\n",
      "Epoch: 12\tFidelity = 0.500508\tKL_Divergence = 3.980046\n",
      "Epoch: 13\tFidelity = 0.500500\tKL_Divergence = 3.989384\n",
      "Epoch: 14\tFidelity = 0.500450\tKL_Divergence = 4.046902\n",
      "Epoch: 15\tFidelity = 0.500608\tKL_Divergence = 3.880200\n",
      "Epoch: 16\tFidelity = 0.500635\tKL_Divergence = 3.856479\n",
      "Epoch: 17\tFidelity = 0.500561\tKL_Divergence = 3.925319\n",
      "Epoch: 18\tFidelity = 0.500535\tKL_Divergence = 3.951244\n",
      "Epoch: 19\tFidelity = 0.500628\tKL_Divergence = 3.861990\n",
      "Epoch: 20\tFidelity = 0.500564\tKL_Divergence = 3.921814\n",
      "Epoch: 21\tFidelity = 0.500510\tKL_Divergence = 3.977649\n",
      "Epoch: 22\tFidelity = 0.500484\tKL_Divergence = 4.006831\n",
      "Epoch: 23\tFidelity = 0.500608\tKL_Divergence = 3.880506\n",
      "Epoch: 24\tFidelity = 0.500489\tKL_Divergence = 4.001468\n",
      "Epoch: 25\tFidelity = 0.500586\tKL_Divergence = 3.900510\n",
      "Epoch: 26\tFidelity = 0.500505\tKL_Divergence = 3.982980\n",
      "Epoch: 27\tFidelity = 0.500477\tKL_Divergence = 4.015000\n",
      "Epoch: 28\tFidelity = 0.500485\tKL_Divergence = 4.005895\n",
      "Epoch: 29\tFidelity = 0.500431\tKL_Divergence = 4.070947\n",
      "Epoch: 30\tFidelity = 0.500540\tKL_Divergence = 3.945699\n",
      "Epoch: 31\tFidelity = 0.500449\tKL_Divergence = 4.048221\n",
      "Epoch: 32\tFidelity = 0.500574\tKL_Divergence = 3.912184\n",
      "Epoch: 33\tFidelity = 0.500513\tKL_Divergence = 3.974101\n",
      "Epoch: 34\tFidelity = 0.500684\tKL_Divergence = 3.814933\n",
      "Epoch: 35\tFidelity = 0.500556\tKL_Divergence = 3.930194\n",
      "Epoch: 36\tFidelity = 0.500433\tKL_Divergence = 4.069040\n",
      "Epoch: 37\tFidelity = 0.500491\tKL_Divergence = 3.998395\n",
      "Epoch: 38\tFidelity = 0.500553\tKL_Divergence = 3.932553\n",
      "Epoch: 39\tFidelity = 0.500456\tKL_Divergence = 4.040053\n",
      "Epoch: 40\tFidelity = 0.500482\tKL_Divergence = 4.009400\n",
      "Epoch: 41\tFidelity = 0.500464\tKL_Divergence = 4.030621\n",
      "Epoch: 42\tFidelity = 0.500450\tKL_Divergence = 4.047398\n",
      "Epoch: 43\tFidelity = 0.500588\tKL_Divergence = 3.899090\n",
      "Epoch: 44\tFidelity = 0.500684\tKL_Divergence = 3.814941\n",
      "Epoch: 45\tFidelity = 0.500515\tKL_Divergence = 3.972331\n",
      "Epoch: 46\tFidelity = 0.500486\tKL_Divergence = 4.004573\n",
      "Epoch: 47\tFidelity = 0.500482\tKL_Divergence = 4.008587\n",
      "Epoch: 48\tFidelity = 0.500676\tKL_Divergence = 3.821230\n",
      "Epoch: 49\tFidelity = 0.500423\tKL_Divergence = 4.082121\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:46:40,061] Trial 548 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500516\tKL_Divergence = 3.970880\n",
      "Total time elapsed during training: 79.308 s\n",
      "Trial 548 pruned. \n",
      "Epoch: 1\tFidelity = 0.500545\tKL_Divergence = 3.941185\n",
      "Epoch: 2\tFidelity = 0.500519\tKL_Divergence = 3.967914\n",
      "Epoch: 3\tFidelity = 0.500550\tKL_Divergence = 3.935457\n",
      "Epoch: 4\tFidelity = 0.500517\tKL_Divergence = 3.970272\n",
      "Epoch: 5\tFidelity = 0.500533\tKL_Divergence = 3.953494\n",
      "Epoch: 6\tFidelity = 0.500494\tKL_Divergence = 3.995413\n",
      "Epoch: 7\tFidelity = 0.500533\tKL_Divergence = 3.953059\n",
      "Epoch: 8\tFidelity = 0.500494\tKL_Divergence = 3.995430\n",
      "Epoch: 9\tFidelity = 0.500545\tKL_Divergence = 3.941375\n",
      "Epoch: 10\tFidelity = 0.500555\tKL_Divergence = 3.930629\n",
      "Epoch: 11\tFidelity = 0.500504\tKL_Divergence = 3.984786\n",
      "Epoch: 12\tFidelity = 0.500518\tKL_Divergence = 3.969235\n",
      "Epoch: 13\tFidelity = 0.500536\tKL_Divergence = 3.949791\n",
      "Epoch: 14\tFidelity = 0.500502\tKL_Divergence = 3.986234\n",
      "Epoch: 15\tFidelity = 0.500478\tKL_Divergence = 4.013773\n",
      "Epoch: 16\tFidelity = 0.500512\tKL_Divergence = 3.976140\n",
      "Epoch: 17\tFidelity = 0.500542\tKL_Divergence = 3.943786\n",
      "Epoch: 18\tFidelity = 0.500569\tKL_Divergence = 3.917006\n",
      "Epoch: 19\tFidelity = 0.500499\tKL_Divergence = 3.990509\n",
      "Epoch: 20\tFidelity = 0.500521\tKL_Divergence = 3.965986\n",
      "Epoch: 21\tFidelity = 0.500504\tKL_Divergence = 3.984263\n",
      "Epoch: 22\tFidelity = 0.500522\tKL_Divergence = 3.965250\n",
      "Epoch: 23\tFidelity = 0.500532\tKL_Divergence = 3.954094\n",
      "Epoch: 24\tFidelity = 0.500570\tKL_Divergence = 3.915858\n",
      "Epoch: 25\tFidelity = 0.500541\tKL_Divergence = 3.945573\n",
      "Epoch: 26\tFidelity = 0.500533\tKL_Divergence = 3.953056\n",
      "Epoch: 27\tFidelity = 0.500499\tKL_Divergence = 3.989911\n",
      "Epoch: 28\tFidelity = 0.500497\tKL_Divergence = 3.991687\n",
      "Epoch: 29\tFidelity = 0.500550\tKL_Divergence = 3.935541\n",
      "Epoch: 30\tFidelity = 0.500550\tKL_Divergence = 3.935539\n",
      "Epoch: 31\tFidelity = 0.500557\tKL_Divergence = 3.928970\n",
      "Epoch: 32\tFidelity = 0.500546\tKL_Divergence = 3.939605\n",
      "Epoch: 33\tFidelity = 0.500554\tKL_Divergence = 3.932123\n",
      "Epoch: 34\tFidelity = 0.500538\tKL_Divergence = 3.948512\n",
      "Epoch: 35\tFidelity = 0.500525\tKL_Divergence = 3.961251\n",
      "Epoch: 36\tFidelity = 0.500572\tKL_Divergence = 3.914206\n",
      "Epoch: 37\tFidelity = 0.500560\tKL_Divergence = 3.925507\n",
      "Epoch: 38\tFidelity = 0.500526\tKL_Divergence = 3.961051\n",
      "Epoch: 39\tFidelity = 0.500531\tKL_Divergence = 3.955048\n",
      "Epoch: 40\tFidelity = 0.500531\tKL_Divergence = 3.954949\n",
      "Epoch: 41\tFidelity = 0.500555\tKL_Divergence = 3.930503\n",
      "Epoch: 42\tFidelity = 0.500562\tKL_Divergence = 3.924345\n",
      "Epoch: 43\tFidelity = 0.500570\tKL_Divergence = 3.915769\n",
      "Epoch: 44\tFidelity = 0.500554\tKL_Divergence = 3.932186\n",
      "Epoch: 45\tFidelity = 0.500511\tKL_Divergence = 3.976714\n",
      "Epoch: 46\tFidelity = 0.500569\tKL_Divergence = 3.917487\n",
      "Epoch: 47\tFidelity = 0.500581\tKL_Divergence = 3.905339\n",
      "Epoch: 48\tFidelity = 0.500553\tKL_Divergence = 3.932753\n",
      "Epoch: 49\tFidelity = 0.500518\tKL_Divergence = 3.969230\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:47:18,552] Trial 549 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500549\tKL_Divergence = 3.937313\n",
      "Total time elapsed during training: 38.313 s\n",
      "Trial 549 pruned. \n",
      "Epoch: 1\tFidelity = 0.500489\tKL_Divergence = 4.001098\n",
      "Epoch: 2\tFidelity = 0.500530\tKL_Divergence = 3.956430\n",
      "Epoch: 3\tFidelity = 0.500516\tKL_Divergence = 3.970995\n",
      "Epoch: 4\tFidelity = 0.500510\tKL_Divergence = 3.978126\n",
      "Epoch: 5\tFidelity = 0.500503\tKL_Divergence = 3.984901\n",
      "Epoch: 6\tFidelity = 0.500564\tKL_Divergence = 3.921267\n",
      "Epoch: 7\tFidelity = 0.500573\tKL_Divergence = 3.913026\n",
      "Epoch: 8\tFidelity = 0.500510\tKL_Divergence = 3.977863\n",
      "Epoch: 9\tFidelity = 0.500531\tKL_Divergence = 3.955525\n",
      "Epoch: 10\tFidelity = 0.500577\tKL_Divergence = 3.908607\n",
      "Epoch: 11\tFidelity = 0.500549\tKL_Divergence = 3.936861\n",
      "Epoch: 12\tFidelity = 0.500521\tKL_Divergence = 3.965988\n",
      "Epoch: 13\tFidelity = 0.500543\tKL_Divergence = 3.942795\n",
      "Epoch: 14\tFidelity = 0.500463\tKL_Divergence = 4.031583\n",
      "Epoch: 15\tFidelity = 0.500531\tKL_Divergence = 3.954439\n",
      "Epoch: 16\tFidelity = 0.500543\tKL_Divergence = 3.942709\n",
      "Epoch: 17\tFidelity = 0.500482\tKL_Divergence = 4.009377\n",
      "Epoch: 18\tFidelity = 0.500563\tKL_Divergence = 3.922681\n",
      "Epoch: 19\tFidelity = 0.500534\tKL_Divergence = 3.951818\n",
      "Epoch: 20\tFidelity = 0.500554\tKL_Divergence = 3.932023\n",
      "Epoch: 21\tFidelity = 0.500517\tKL_Divergence = 3.970358\n",
      "Epoch: 22\tFidelity = 0.500576\tKL_Divergence = 3.910086\n",
      "Epoch: 23\tFidelity = 0.500553\tKL_Divergence = 3.932732\n",
      "Epoch: 24\tFidelity = 0.500521\tKL_Divergence = 3.965761\n",
      "Epoch: 25\tFidelity = 0.500556\tKL_Divergence = 3.929204\n",
      "Epoch: 26\tFidelity = 0.500519\tKL_Divergence = 3.968089\n",
      "Epoch: 27\tFidelity = 0.500519\tKL_Divergence = 3.967055\n",
      "Epoch: 28\tFidelity = 0.500521\tKL_Divergence = 3.964969\n",
      "Epoch: 29\tFidelity = 0.500525\tKL_Divergence = 3.960185\n",
      "Epoch: 30\tFidelity = 0.500533\tKL_Divergence = 3.952958\n",
      "Epoch: 31\tFidelity = 0.500513\tKL_Divergence = 3.974131\n",
      "Epoch: 32\tFidelity = 0.500511\tKL_Divergence = 3.976108\n",
      "Epoch: 33\tFidelity = 0.500502\tKL_Divergence = 3.986461\n",
      "Epoch: 34\tFidelity = 0.500518\tKL_Divergence = 3.968205\n",
      "Epoch: 35\tFidelity = 0.500501\tKL_Divergence = 3.987303\n",
      "Epoch: 36\tFidelity = 0.500546\tKL_Divergence = 3.939361\n",
      "Epoch: 37\tFidelity = 0.500524\tKL_Divergence = 3.962702\n",
      "Epoch: 38\tFidelity = 0.500503\tKL_Divergence = 3.984730\n",
      "Epoch: 39\tFidelity = 0.500529\tKL_Divergence = 3.957314\n",
      "Epoch: 40\tFidelity = 0.500559\tKL_Divergence = 3.926441\n",
      "Epoch: 41\tFidelity = 0.500526\tKL_Divergence = 3.960706\n",
      "Epoch: 42\tFidelity = 0.500497\tKL_Divergence = 3.991536\n",
      "Epoch: 43\tFidelity = 0.500524\tKL_Divergence = 3.961936\n",
      "Epoch: 44\tFidelity = 0.500526\tKL_Divergence = 3.960494\n",
      "Epoch: 45\tFidelity = 0.500505\tKL_Divergence = 3.983120\n",
      "Epoch: 46\tFidelity = 0.500475\tKL_Divergence = 4.016953\n",
      "Epoch: 47\tFidelity = 0.500511\tKL_Divergence = 3.976351\n",
      "Epoch: 48\tFidelity = 0.500521\tKL_Divergence = 3.965662\n",
      "Epoch: 49\tFidelity = 0.500526\tKL_Divergence = 3.960296\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:48:04,842] Trial 550 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500491\tKL_Divergence = 3.998188\n",
      "Total time elapsed during training: 46.098 s\n",
      "Trial 550 pruned. \n",
      "Epoch: 1\tFidelity = 0.500535\tKL_Divergence = 3.950607\n",
      "Epoch: 2\tFidelity = 0.500516\tKL_Divergence = 3.970649\n",
      "Epoch: 3\tFidelity = 0.500569\tKL_Divergence = 3.916209\n",
      "Epoch: 4\tFidelity = 0.500509\tKL_Divergence = 3.978577\n",
      "Epoch: 5\tFidelity = 0.500561\tKL_Divergence = 3.924383\n",
      "Epoch: 6\tFidelity = 0.500511\tKL_Divergence = 3.976210\n",
      "Epoch: 7\tFidelity = 0.500472\tKL_Divergence = 4.020020\n",
      "Epoch: 8\tFidelity = 0.500577\tKL_Divergence = 3.907672\n",
      "Epoch: 9\tFidelity = 0.500596\tKL_Divergence = 3.889449\n",
      "Epoch: 10\tFidelity = 0.500640\tKL_Divergence = 3.849656\n",
      "Epoch: 11\tFidelity = 0.500585\tKL_Divergence = 3.899954\n",
      "Epoch: 12\tFidelity = 0.500529\tKL_Divergence = 3.955905\n",
      "Epoch: 13\tFidelity = 0.500539\tKL_Divergence = 3.945239\n",
      "Epoch: 14\tFidelity = 0.500560\tKL_Divergence = 3.924386\n",
      "Epoch: 15\tFidelity = 0.500625\tKL_Divergence = 3.863493\n",
      "Epoch: 16\tFidelity = 0.500504\tKL_Divergence = 3.982587\n",
      "Epoch: 17\tFidelity = 0.500494\tKL_Divergence = 3.993466\n",
      "Epoch: 18\tFidelity = 0.500557\tKL_Divergence = 3.926253\n",
      "Epoch: 19\tFidelity = 0.500515\tKL_Divergence = 3.970992\n",
      "Epoch: 20\tFidelity = 0.500486\tKL_Divergence = 4.002749\n",
      "Epoch: 21\tFidelity = 0.500507\tKL_Divergence = 3.980029\n",
      "Epoch: 22\tFidelity = 0.500520\tKL_Divergence = 3.965909\n",
      "Epoch: 23\tFidelity = 0.500552\tKL_Divergence = 3.932519\n",
      "Epoch: 24\tFidelity = 0.500525\tKL_Divergence = 3.961045\n",
      "Epoch: 25\tFidelity = 0.500552\tKL_Divergence = 3.932637\n",
      "Epoch: 26\tFidelity = 0.500545\tKL_Divergence = 3.940415\n",
      "Epoch: 27\tFidelity = 0.500552\tKL_Divergence = 3.933610\n",
      "Epoch: 28\tFidelity = 0.500541\tKL_Divergence = 3.943673\n",
      "Epoch: 29\tFidelity = 0.500543\tKL_Divergence = 3.941414\n",
      "Epoch: 30\tFidelity = 0.500605\tKL_Divergence = 3.881695\n",
      "Epoch: 31\tFidelity = 0.500569\tKL_Divergence = 3.915522\n",
      "Epoch: 32\tFidelity = 0.500516\tKL_Divergence = 3.970372\n",
      "Epoch: 33\tFidelity = 0.500511\tKL_Divergence = 3.975608\n",
      "Epoch: 34\tFidelity = 0.500553\tKL_Divergence = 3.930682\n",
      "Epoch: 35\tFidelity = 0.500547\tKL_Divergence = 3.936816\n",
      "Epoch: 36\tFidelity = 0.500512\tKL_Divergence = 3.973268\n",
      "Epoch: 37\tFidelity = 0.500574\tKL_Divergence = 3.909988\n",
      "Epoch: 38\tFidelity = 0.500564\tKL_Divergence = 3.919686\n",
      "Epoch: 39\tFidelity = 0.500616\tKL_Divergence = 3.871090\n",
      "Epoch: 40\tFidelity = 0.500533\tKL_Divergence = 3.951735\n",
      "Epoch: 41\tFidelity = 0.500512\tKL_Divergence = 3.974608\n",
      "Epoch: 42\tFidelity = 0.500487\tKL_Divergence = 4.001630\n",
      "Epoch: 43\tFidelity = 0.500563\tKL_Divergence = 3.920855\n",
      "Epoch: 44\tFidelity = 0.500557\tKL_Divergence = 3.926950\n",
      "Epoch: 45\tFidelity = 0.500491\tKL_Divergence = 3.996723\n",
      "Epoch: 46\tFidelity = 0.500500\tKL_Divergence = 3.986904\n",
      "Epoch: 47\tFidelity = 0.500455\tKL_Divergence = 4.039422\n",
      "Epoch: 48\tFidelity = 0.500496\tKL_Divergence = 3.992432\n",
      "Epoch: 49\tFidelity = 0.500507\tKL_Divergence = 3.980460\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:48:44,365] Trial 551 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500490\tKL_Divergence = 3.999069\n",
      "Total time elapsed during training: 39.341 s\n",
      "Trial 551 pruned. \n",
      "Epoch: 1\tFidelity = 0.500573\tKL_Divergence = 3.912693\n",
      "Epoch: 2\tFidelity = 0.500568\tKL_Divergence = 3.917186\n",
      "Epoch: 3\tFidelity = 0.500525\tKL_Divergence = 3.961478\n",
      "Epoch: 4\tFidelity = 0.500519\tKL_Divergence = 3.967840\n",
      "Epoch: 5\tFidelity = 0.500487\tKL_Divergence = 4.003524\n",
      "Epoch: 6\tFidelity = 0.500494\tKL_Divergence = 3.995097\n",
      "Epoch: 7\tFidelity = 0.500521\tKL_Divergence = 3.965722\n",
      "Epoch: 8\tFidelity = 0.500516\tKL_Divergence = 3.971466\n",
      "Epoch: 9\tFidelity = 0.500490\tKL_Divergence = 3.999880\n",
      "Epoch: 10\tFidelity = 0.500492\tKL_Divergence = 3.997154\n",
      "Epoch: 11\tFidelity = 0.500538\tKL_Divergence = 3.947778\n",
      "Epoch: 12\tFidelity = 0.500533\tKL_Divergence = 3.952675\n",
      "Epoch: 13\tFidelity = 0.500570\tKL_Divergence = 3.915980\n",
      "Epoch: 14\tFidelity = 0.500576\tKL_Divergence = 3.910102\n",
      "Epoch: 15\tFidelity = 0.500546\tKL_Divergence = 3.939808\n",
      "Epoch: 16\tFidelity = 0.500522\tKL_Divergence = 3.964406\n",
      "Epoch: 17\tFidelity = 0.500505\tKL_Divergence = 3.983521\n",
      "Epoch: 18\tFidelity = 0.500518\tKL_Divergence = 3.969115\n",
      "Epoch: 19\tFidelity = 0.500570\tKL_Divergence = 3.915732\n",
      "Epoch: 20\tFidelity = 0.500549\tKL_Divergence = 3.936611\n",
      "Epoch: 21\tFidelity = 0.500537\tKL_Divergence = 3.949294\n",
      "Epoch: 22\tFidelity = 0.500554\tKL_Divergence = 3.931611\n",
      "Epoch: 23\tFidelity = 0.500508\tKL_Divergence = 3.979445\n",
      "Epoch: 24\tFidelity = 0.500616\tKL_Divergence = 3.873162\n",
      "Epoch: 25\tFidelity = 0.500512\tKL_Divergence = 3.975527\n",
      "Epoch: 26\tFidelity = 0.500533\tKL_Divergence = 3.953720\n",
      "Epoch: 27\tFidelity = 0.500576\tKL_Divergence = 3.910197\n",
      "Epoch: 28\tFidelity = 0.500596\tKL_Divergence = 3.890982\n",
      "Epoch: 29\tFidelity = 0.500580\tKL_Divergence = 3.906714\n",
      "Epoch: 30\tFidelity = 0.500575\tKL_Divergence = 3.911221\n",
      "Epoch: 31\tFidelity = 0.500525\tKL_Divergence = 3.961474\n",
      "Epoch: 32\tFidelity = 0.500601\tKL_Divergence = 3.887041\n",
      "Epoch: 33\tFidelity = 0.500579\tKL_Divergence = 3.906925\n",
      "Epoch: 34\tFidelity = 0.500561\tKL_Divergence = 3.925260\n",
      "Epoch: 35\tFidelity = 0.500594\tKL_Divergence = 3.893197\n",
      "Epoch: 36\tFidelity = 0.500512\tKL_Divergence = 3.976028\n",
      "Epoch: 37\tFidelity = 0.500570\tKL_Divergence = 3.916029\n",
      "Epoch: 38\tFidelity = 0.500570\tKL_Divergence = 3.915943\n",
      "Epoch: 39\tFidelity = 0.500508\tKL_Divergence = 3.979717\n",
      "Epoch: 40\tFidelity = 0.500523\tKL_Divergence = 3.963586\n",
      "Epoch: 41\tFidelity = 0.500535\tKL_Divergence = 3.950857\n",
      "Epoch: 42\tFidelity = 0.500558\tKL_Divergence = 3.928081\n",
      "Epoch: 43\tFidelity = 0.500504\tKL_Divergence = 3.983929\n",
      "Epoch: 44\tFidelity = 0.500486\tKL_Divergence = 4.004899\n",
      "Epoch: 45\tFidelity = 0.500513\tKL_Divergence = 3.974188\n",
      "Epoch: 46\tFidelity = 0.500568\tKL_Divergence = 3.917962\n",
      "Epoch: 47\tFidelity = 0.500555\tKL_Divergence = 3.930576\n",
      "Epoch: 48\tFidelity = 0.500481\tKL_Divergence = 4.010742\n",
      "Epoch: 49\tFidelity = 0.500586\tKL_Divergence = 3.901055\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:49:31,516] Trial 552 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500530\tKL_Divergence = 3.956329\n",
      "Total time elapsed during training: 46.970 s\n",
      "Trial 552 pruned. \n",
      "Epoch: 1\tFidelity = 0.500587\tKL_Divergence = 3.899351\n",
      "Epoch: 2\tFidelity = 0.500532\tKL_Divergence = 3.954402\n",
      "Epoch: 3\tFidelity = 0.500498\tKL_Divergence = 3.991372\n",
      "Epoch: 4\tFidelity = 0.500535\tKL_Divergence = 3.951320\n",
      "Epoch: 5\tFidelity = 0.500511\tKL_Divergence = 3.976988\n",
      "Epoch: 6\tFidelity = 0.500538\tKL_Divergence = 3.948602\n",
      "Epoch: 7\tFidelity = 0.500556\tKL_Divergence = 3.930382\n",
      "Epoch: 8\tFidelity = 0.500567\tKL_Divergence = 3.919229\n",
      "Epoch: 9\tFidelity = 0.500544\tKL_Divergence = 3.941648\n",
      "Epoch: 10\tFidelity = 0.500550\tKL_Divergence = 3.935561\n",
      "Epoch: 11\tFidelity = 0.500491\tKL_Divergence = 3.999229\n",
      "Epoch: 12\tFidelity = 0.500549\tKL_Divergence = 3.937405\n",
      "Epoch: 13\tFidelity = 0.500588\tKL_Divergence = 3.898824\n",
      "Epoch: 14\tFidelity = 0.500522\tKL_Divergence = 3.964436\n",
      "Epoch: 15\tFidelity = 0.500513\tKL_Divergence = 3.974948\n",
      "Epoch: 16\tFidelity = 0.500560\tKL_Divergence = 3.926017\n",
      "Epoch: 17\tFidelity = 0.500533\tKL_Divergence = 3.953599\n",
      "Epoch: 18\tFidelity = 0.500455\tKL_Divergence = 4.040653\n",
      "Epoch: 19\tFidelity = 0.500517\tKL_Divergence = 3.969971\n",
      "Epoch: 20\tFidelity = 0.500593\tKL_Divergence = 3.894455\n",
      "Epoch: 21\tFidelity = 0.500556\tKL_Divergence = 3.929594\n",
      "Epoch: 22\tFidelity = 0.500574\tKL_Divergence = 3.912130\n",
      "Epoch: 23\tFidelity = 0.500547\tKL_Divergence = 3.938690\n",
      "Epoch: 24\tFidelity = 0.500557\tKL_Divergence = 3.928785\n",
      "Epoch: 25\tFidelity = 0.500563\tKL_Divergence = 3.923265\n",
      "Epoch: 26\tFidelity = 0.500557\tKL_Divergence = 3.929332\n",
      "Epoch: 27\tFidelity = 0.500594\tKL_Divergence = 3.892911\n",
      "Epoch: 28\tFidelity = 0.500516\tKL_Divergence = 3.971104\n",
      "Epoch: 29\tFidelity = 0.500499\tKL_Divergence = 3.989392\n",
      "Epoch: 30\tFidelity = 0.500513\tKL_Divergence = 3.974567\n",
      "Epoch: 31\tFidelity = 0.500510\tKL_Divergence = 3.978146\n",
      "Epoch: 32\tFidelity = 0.500546\tKL_Divergence = 3.939527\n",
      "Epoch: 33\tFidelity = 0.500641\tKL_Divergence = 3.851068\n",
      "Epoch: 34\tFidelity = 0.500531\tKL_Divergence = 3.955109\n",
      "Epoch: 35\tFidelity = 0.500553\tKL_Divergence = 3.933267\n",
      "Epoch: 36\tFidelity = 0.500506\tKL_Divergence = 3.981754\n",
      "Epoch: 37\tFidelity = 0.500573\tKL_Divergence = 3.913561\n",
      "Epoch: 38\tFidelity = 0.500566\tKL_Divergence = 3.920349\n",
      "Epoch: 39\tFidelity = 0.500538\tKL_Divergence = 3.948168\n",
      "Epoch: 40\tFidelity = 0.500552\tKL_Divergence = 3.934423\n",
      "Epoch: 41\tFidelity = 0.500573\tKL_Divergence = 3.913301\n",
      "Epoch: 42\tFidelity = 0.500577\tKL_Divergence = 3.909414\n",
      "Epoch: 43\tFidelity = 0.500568\tKL_Divergence = 3.918227\n",
      "Epoch: 44\tFidelity = 0.500555\tKL_Divergence = 3.931004\n",
      "Epoch: 45\tFidelity = 0.500561\tKL_Divergence = 3.925140\n",
      "Epoch: 46\tFidelity = 0.500553\tKL_Divergence = 3.933142\n",
      "Epoch: 47\tFidelity = 0.500622\tKL_Divergence = 3.867945\n",
      "Epoch: 48\tFidelity = 0.500542\tKL_Divergence = 3.943717\n",
      "Epoch: 49\tFidelity = 0.500547\tKL_Divergence = 3.938732\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:50:53,795] Trial 553 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500597\tKL_Divergence = 3.890805\n",
      "Total time elapsed during training: 82.098 s\n",
      "Trial 553 pruned. \n",
      "Epoch: 1\tFidelity = 0.500593\tKL_Divergence = 3.894218\n",
      "Epoch: 2\tFidelity = 0.500572\tKL_Divergence = 3.913771\n",
      "Epoch: 3\tFidelity = 0.500521\tKL_Divergence = 3.966078\n",
      "Epoch: 4\tFidelity = 0.500520\tKL_Divergence = 3.967201\n",
      "Epoch: 5\tFidelity = 0.500588\tKL_Divergence = 3.898932\n",
      "Epoch: 6\tFidelity = 0.500512\tKL_Divergence = 3.975481\n",
      "Epoch: 7\tFidelity = 0.500525\tKL_Divergence = 3.961225\n",
      "Epoch: 8\tFidelity = 0.500583\tKL_Divergence = 3.903352\n",
      "Epoch: 9\tFidelity = 0.500545\tKL_Divergence = 3.941158\n",
      "Epoch: 10\tFidelity = 0.500565\tKL_Divergence = 3.921042\n",
      "Epoch: 11\tFidelity = 0.500570\tKL_Divergence = 3.916430\n",
      "Epoch: 12\tFidelity = 0.500520\tKL_Divergence = 3.966488\n",
      "Epoch: 13\tFidelity = 0.500579\tKL_Divergence = 3.907059\n",
      "Epoch: 14\tFidelity = 0.500533\tKL_Divergence = 3.953405\n",
      "Epoch: 15\tFidelity = 0.500524\tKL_Divergence = 3.962469\n",
      "Epoch: 16\tFidelity = 0.500590\tKL_Divergence = 3.896727\n",
      "Epoch: 17\tFidelity = 0.500569\tKL_Divergence = 3.916815\n",
      "Epoch: 18\tFidelity = 0.500555\tKL_Divergence = 3.930646\n",
      "Epoch: 19\tFidelity = 0.500569\tKL_Divergence = 3.917140\n",
      "Epoch: 20\tFidelity = 0.500592\tKL_Divergence = 3.895202\n",
      "Epoch: 21\tFidelity = 0.500612\tKL_Divergence = 3.876551\n",
      "Epoch: 22\tFidelity = 0.500594\tKL_Divergence = 3.893393\n",
      "Epoch: 23\tFidelity = 0.500549\tKL_Divergence = 3.937319\n",
      "Epoch: 24\tFidelity = 0.500530\tKL_Divergence = 3.956131\n",
      "Epoch: 25\tFidelity = 0.500612\tKL_Divergence = 3.876248\n",
      "Epoch: 26\tFidelity = 0.500581\tKL_Divergence = 3.905256\n",
      "Epoch: 27\tFidelity = 0.500520\tKL_Divergence = 3.967390\n",
      "Epoch: 28\tFidelity = 0.500592\tKL_Divergence = 3.895025\n",
      "Epoch: 29\tFidelity = 0.500571\tKL_Divergence = 3.915227\n",
      "Epoch: 30\tFidelity = 0.500603\tKL_Divergence = 3.885286\n",
      "Epoch: 31\tFidelity = 0.500572\tKL_Divergence = 3.913802\n",
      "Epoch: 32\tFidelity = 0.500535\tKL_Divergence = 3.951262\n",
      "Epoch: 33\tFidelity = 0.500522\tKL_Divergence = 3.964792\n",
      "Epoch: 34\tFidelity = 0.500557\tKL_Divergence = 3.928755\n",
      "Epoch: 35\tFidelity = 0.500535\tKL_Divergence = 3.951737\n",
      "Epoch: 36\tFidelity = 0.500528\tKL_Divergence = 3.958783\n",
      "Epoch: 37\tFidelity = 0.500513\tKL_Divergence = 3.974773\n",
      "Epoch: 38\tFidelity = 0.500535\tKL_Divergence = 3.951164\n",
      "Epoch: 39\tFidelity = 0.500569\tKL_Divergence = 3.917281\n",
      "Epoch: 40\tFidelity = 0.500573\tKL_Divergence = 3.912716\n",
      "Epoch: 41\tFidelity = 0.500531\tKL_Divergence = 3.955924\n",
      "Epoch: 42\tFidelity = 0.500498\tKL_Divergence = 3.991373\n",
      "Epoch: 43\tFidelity = 0.500553\tKL_Divergence = 3.933367\n",
      "Epoch: 44\tFidelity = 0.500563\tKL_Divergence = 3.923406\n",
      "Epoch: 45\tFidelity = 0.500518\tKL_Divergence = 3.968712\n",
      "Epoch: 46\tFidelity = 0.500570\tKL_Divergence = 3.915848\n",
      "Epoch: 47\tFidelity = 0.500534\tKL_Divergence = 3.952199\n",
      "Epoch: 48\tFidelity = 0.500557\tKL_Divergence = 3.929008\n",
      "Epoch: 49\tFidelity = 0.500548\tKL_Divergence = 3.938418\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:51:33,730] Trial 554 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500551\tKL_Divergence = 3.935183\n",
      "Total time elapsed during training: 39.749 s\n",
      "Trial 554 pruned. \n",
      "Epoch: 1\tFidelity = 0.500546\tKL_Divergence = 3.939742\n",
      "Epoch: 2\tFidelity = 0.500540\tKL_Divergence = 3.946380\n",
      "Epoch: 3\tFidelity = 0.500587\tKL_Divergence = 3.899886\n",
      "Epoch: 4\tFidelity = 0.500508\tKL_Divergence = 3.979368\n",
      "Epoch: 5\tFidelity = 0.500515\tKL_Divergence = 3.972150\n",
      "Epoch: 6\tFidelity = 0.500658\tKL_Divergence = 3.835553\n",
      "Epoch: 7\tFidelity = 0.500464\tKL_Divergence = 4.030457\n",
      "Epoch: 8\tFidelity = 0.500684\tKL_Divergence = 3.814969\n",
      "Epoch: 9\tFidelity = 0.500538\tKL_Divergence = 3.948484\n",
      "Epoch: 10\tFidelity = 0.500506\tKL_Divergence = 3.982037\n",
      "Epoch: 11\tFidelity = 0.500646\tKL_Divergence = 3.846499\n",
      "Epoch: 12\tFidelity = 0.500539\tKL_Divergence = 3.947141\n",
      "Epoch: 13\tFidelity = 0.500584\tKL_Divergence = 3.901915\n",
      "Epoch: 14\tFidelity = 0.500549\tKL_Divergence = 3.935782\n",
      "Epoch: 15\tFidelity = 0.500562\tKL_Divergence = 3.923172\n",
      "Epoch: 16\tFidelity = 0.500607\tKL_Divergence = 3.881203\n",
      "Epoch: 17\tFidelity = 0.500691\tKL_Divergence = 3.808226\n",
      "Epoch: 18\tFidelity = 0.500512\tKL_Divergence = 3.975138\n",
      "Epoch: 19\tFidelity = 0.500671\tKL_Divergence = 3.825090\n",
      "Epoch: 20\tFidelity = 0.500481\tKL_Divergence = 4.009760\n",
      "Epoch: 21\tFidelity = 0.500698\tKL_Divergence = 3.802863\n",
      "Epoch: 22\tFidelity = 0.500652\tKL_Divergence = 3.841015\n",
      "Epoch: 23\tFidelity = 0.500653\tKL_Divergence = 3.840355\n",
      "Epoch: 24\tFidelity = 0.500577\tKL_Divergence = 3.908831\n",
      "Epoch: 25\tFidelity = 0.500584\tKL_Divergence = 3.902291\n",
      "Epoch: 26\tFidelity = 0.500608\tKL_Divergence = 3.879601\n",
      "Epoch: 27\tFidelity = 0.500436\tKL_Divergence = 4.064613\n",
      "Epoch: 28\tFidelity = 0.500525\tKL_Divergence = 3.961246\n",
      "Epoch: 29\tFidelity = 0.500487\tKL_Divergence = 4.003748\n",
      "Epoch: 30\tFidelity = 0.500463\tKL_Divergence = 4.031326\n",
      "Epoch: 31\tFidelity = 0.500520\tKL_Divergence = 3.967085\n",
      "Epoch: 32\tFidelity = 0.500518\tKL_Divergence = 3.969425\n",
      "Epoch: 33\tFidelity = 0.500512\tKL_Divergence = 3.975119\n",
      "Epoch: 34\tFidelity = 0.500599\tKL_Divergence = 3.888663\n",
      "Epoch: 35\tFidelity = 0.500540\tKL_Divergence = 3.946275\n",
      "Epoch: 36\tFidelity = 0.500507\tKL_Divergence = 3.980939\n",
      "Epoch: 37\tFidelity = 0.500600\tKL_Divergence = 3.887687\n",
      "Epoch: 38\tFidelity = 0.500647\tKL_Divergence = 3.846019\n",
      "Epoch: 39\tFidelity = 0.500526\tKL_Divergence = 3.961016\n",
      "Epoch: 40\tFidelity = 0.500544\tKL_Divergence = 3.941801\n",
      "Epoch: 41\tFidelity = 0.500626\tKL_Divergence = 3.864419\n",
      "Epoch: 42\tFidelity = 0.500574\tKL_Divergence = 3.911991\n",
      "Epoch: 43\tFidelity = 0.500622\tKL_Divergence = 3.867840\n",
      "Epoch: 44\tFidelity = 0.500585\tKL_Divergence = 3.901656\n",
      "Epoch: 45\tFidelity = 0.500622\tKL_Divergence = 3.867975\n",
      "Epoch: 46\tFidelity = 0.500605\tKL_Divergence = 3.883153\n",
      "Epoch: 47\tFidelity = 0.500669\tKL_Divergence = 3.827400\n",
      "Epoch: 48\tFidelity = 0.500547\tKL_Divergence = 3.938411\n",
      "Epoch: 49\tFidelity = 0.500582\tKL_Divergence = 3.904132\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:52:13,016] Trial 555 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500476\tKL_Divergence = 4.015569\n",
      "Total time elapsed during training: 39.100 s\n",
      "Trial 555 pruned. \n",
      "Epoch: 1\tFidelity = 0.500565\tKL_Divergence = 3.920993\n",
      "Epoch: 2\tFidelity = 0.500560\tKL_Divergence = 3.926198\n",
      "Epoch: 3\tFidelity = 0.500597\tKL_Divergence = 3.889918\n",
      "Epoch: 4\tFidelity = 0.500582\tKL_Divergence = 3.904953\n",
      "Epoch: 5\tFidelity = 0.500612\tKL_Divergence = 3.876565\n",
      "Epoch: 6\tFidelity = 0.500656\tKL_Divergence = 3.838045\n",
      "Epoch: 7\tFidelity = 0.500565\tKL_Divergence = 3.921232\n",
      "Epoch: 8\tFidelity = 0.500610\tKL_Divergence = 3.878224\n",
      "Epoch: 9\tFidelity = 0.500519\tKL_Divergence = 3.968374\n",
      "Epoch: 10\tFidelity = 0.500565\tKL_Divergence = 3.920885\n",
      "Epoch: 11\tFidelity = 0.500575\tKL_Divergence = 3.911460\n",
      "Epoch: 12\tFidelity = 0.500584\tKL_Divergence = 3.902822\n",
      "Epoch: 13\tFidelity = 0.500607\tKL_Divergence = 3.881149\n",
      "Epoch: 14\tFidelity = 0.500607\tKL_Divergence = 3.881332\n",
      "Epoch: 15\tFidelity = 0.500533\tKL_Divergence = 3.953206\n",
      "Epoch: 16\tFidelity = 0.500566\tKL_Divergence = 3.919554\n",
      "Epoch: 17\tFidelity = 0.500541\tKL_Divergence = 3.944785\n",
      "Epoch: 18\tFidelity = 0.500519\tKL_Divergence = 3.968193\n",
      "Epoch: 19\tFidelity = 0.500615\tKL_Divergence = 3.874082\n",
      "Epoch: 20\tFidelity = 0.500495\tKL_Divergence = 3.994913\n",
      "Epoch: 21\tFidelity = 0.500573\tKL_Divergence = 3.913623\n",
      "Epoch: 22\tFidelity = 0.500642\tKL_Divergence = 3.850196\n",
      "Epoch: 23\tFidelity = 0.500531\tKL_Divergence = 3.955808\n",
      "Epoch: 24\tFidelity = 0.500521\tKL_Divergence = 3.965922\n",
      "Epoch: 25\tFidelity = 0.500605\tKL_Divergence = 3.882721\n",
      "Epoch: 26\tFidelity = 0.500519\tKL_Divergence = 3.968549\n",
      "Epoch: 27\tFidelity = 0.500524\tKL_Divergence = 3.962902\n",
      "Epoch: 28\tFidelity = 0.500475\tKL_Divergence = 4.017690\n",
      "Epoch: 29\tFidelity = 0.500502\tKL_Divergence = 3.986341\n",
      "Epoch: 30\tFidelity = 0.500515\tKL_Divergence = 3.971855\n",
      "Epoch: 31\tFidelity = 0.500667\tKL_Divergence = 3.828921\n",
      "Epoch: 32\tFidelity = 0.500493\tKL_Divergence = 3.996243\n",
      "Epoch: 33\tFidelity = 0.500602\tKL_Divergence = 3.885503\n",
      "Epoch: 34\tFidelity = 0.500611\tKL_Divergence = 3.877659\n",
      "Epoch: 35\tFidelity = 0.500533\tKL_Divergence = 3.952556\n",
      "Epoch: 36\tFidelity = 0.500595\tKL_Divergence = 3.892028\n",
      "Epoch: 37\tFidelity = 0.500501\tKL_Divergence = 3.987736\n",
      "Epoch: 38\tFidelity = 0.500563\tKL_Divergence = 3.922446\n",
      "Epoch: 39\tFidelity = 0.500544\tKL_Divergence = 3.941329\n",
      "Epoch: 40\tFidelity = 0.500608\tKL_Divergence = 3.879473\n",
      "Epoch: 41\tFidelity = 0.500463\tKL_Divergence = 4.030944\n",
      "Epoch: 42\tFidelity = 0.500557\tKL_Divergence = 3.928003\n",
      "Epoch: 43\tFidelity = 0.500602\tKL_Divergence = 3.885663\n",
      "Epoch: 44\tFidelity = 0.500546\tKL_Divergence = 3.939988\n",
      "Epoch: 45\tFidelity = 0.500551\tKL_Divergence = 3.934450\n",
      "Epoch: 46\tFidelity = 0.500521\tKL_Divergence = 3.965587\n",
      "Epoch: 47\tFidelity = 0.500618\tKL_Divergence = 3.871004\n",
      "Epoch: 48\tFidelity = 0.500607\tKL_Divergence = 3.880852\n",
      "Epoch: 49\tFidelity = 0.500502\tKL_Divergence = 3.986404\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:53:14,503] Trial 556 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500479\tKL_Divergence = 4.013059\n",
      "Total time elapsed during training: 61.309 s\n",
      "Trial 556 pruned. \n",
      "Epoch: 1\tFidelity = 0.500548\tKL_Divergence = 3.937785\n",
      "Epoch: 2\tFidelity = 0.500587\tKL_Divergence = 3.899610\n",
      "Epoch: 3\tFidelity = 0.500571\tKL_Divergence = 3.915132\n",
      "Epoch: 4\tFidelity = 0.500509\tKL_Divergence = 3.979059\n",
      "Epoch: 5\tFidelity = 0.500532\tKL_Divergence = 3.954545\n",
      "Epoch: 6\tFidelity = 0.500529\tKL_Divergence = 3.956986\n",
      "Epoch: 7\tFidelity = 0.500568\tKL_Divergence = 3.917804\n",
      "Epoch: 8\tFidelity = 0.500545\tKL_Divergence = 3.940713\n",
      "Epoch: 9\tFidelity = 0.500494\tKL_Divergence = 3.995756\n",
      "Epoch: 10\tFidelity = 0.500531\tKL_Divergence = 3.955056\n",
      "Epoch: 11\tFidelity = 0.500565\tKL_Divergence = 3.921388\n",
      "Epoch: 12\tFidelity = 0.500597\tKL_Divergence = 3.890390\n",
      "Epoch: 13\tFidelity = 0.500502\tKL_Divergence = 3.986636\n",
      "Epoch: 14\tFidelity = 0.500542\tKL_Divergence = 3.944483\n",
      "Epoch: 15\tFidelity = 0.500593\tKL_Divergence = 3.894242\n",
      "Epoch: 16\tFidelity = 0.500514\tKL_Divergence = 3.973609\n",
      "Epoch: 17\tFidelity = 0.500583\tKL_Divergence = 3.903513\n",
      "Epoch: 18\tFidelity = 0.500541\tKL_Divergence = 3.944780\n",
      "Epoch: 19\tFidelity = 0.500526\tKL_Divergence = 3.960999\n",
      "Epoch: 20\tFidelity = 0.500540\tKL_Divergence = 3.946281\n",
      "Epoch: 21\tFidelity = 0.500540\tKL_Divergence = 3.946203\n",
      "Epoch: 22\tFidelity = 0.500563\tKL_Divergence = 3.922639\n",
      "Epoch: 23\tFidelity = 0.500515\tKL_Divergence = 3.972481\n",
      "Epoch: 24\tFidelity = 0.500547\tKL_Divergence = 3.938923\n",
      "Epoch: 25\tFidelity = 0.500562\tKL_Divergence = 3.924370\n",
      "Epoch: 26\tFidelity = 0.500565\tKL_Divergence = 3.920701\n",
      "Epoch: 27\tFidelity = 0.500515\tKL_Divergence = 3.972030\n",
      "Epoch: 28\tFidelity = 0.500536\tKL_Divergence = 3.950159\n",
      "Epoch: 29\tFidelity = 0.500500\tKL_Divergence = 3.988684\n",
      "Epoch: 30\tFidelity = 0.500597\tKL_Divergence = 3.889949\n",
      "Epoch: 31\tFidelity = 0.500609\tKL_Divergence = 3.879147\n",
      "Epoch: 32\tFidelity = 0.500537\tKL_Divergence = 3.949636\n",
      "Epoch: 33\tFidelity = 0.500509\tKL_Divergence = 3.979081\n",
      "Epoch: 34\tFidelity = 0.500650\tKL_Divergence = 3.842870\n",
      "Epoch: 35\tFidelity = 0.500512\tKL_Divergence = 3.976027\n",
      "Epoch: 36\tFidelity = 0.500522\tKL_Divergence = 3.964397\n",
      "Epoch: 37\tFidelity = 0.500616\tKL_Divergence = 3.872601\n",
      "Epoch: 38\tFidelity = 0.500537\tKL_Divergence = 3.948694\n",
      "Epoch: 39\tFidelity = 0.500564\tKL_Divergence = 3.922395\n",
      "Epoch: 40\tFidelity = 0.500544\tKL_Divergence = 3.942310\n",
      "Epoch: 41\tFidelity = 0.500465\tKL_Divergence = 4.028599\n",
      "Epoch: 42\tFidelity = 0.500548\tKL_Divergence = 3.938098\n",
      "Epoch: 43\tFidelity = 0.500591\tKL_Divergence = 3.896246\n",
      "Epoch: 44\tFidelity = 0.500528\tKL_Divergence = 3.958225\n",
      "Epoch: 45\tFidelity = 0.500615\tKL_Divergence = 3.873748\n",
      "Epoch: 46\tFidelity = 0.500612\tKL_Divergence = 3.876692\n",
      "Epoch: 47\tFidelity = 0.500526\tKL_Divergence = 3.960853\n",
      "Epoch: 48\tFidelity = 0.500579\tKL_Divergence = 3.907323\n",
      "Epoch: 49\tFidelity = 0.500585\tKL_Divergence = 3.901629\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:53:54,165] Trial 557 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500562\tKL_Divergence = 3.923873\n",
      "Total time elapsed during training: 39.469 s\n",
      "Trial 557 pruned. \n",
      "Epoch: 1\tFidelity = 0.500506\tKL_Divergence = 3.982506\n",
      "Epoch: 2\tFidelity = 0.500590\tKL_Divergence = 3.896745\n",
      "Epoch: 3\tFidelity = 0.500488\tKL_Divergence = 4.002064\n",
      "Epoch: 4\tFidelity = 0.500594\tKL_Divergence = 3.893031\n",
      "Epoch: 5\tFidelity = 0.500537\tKL_Divergence = 3.949567\n",
      "Epoch: 6\tFidelity = 0.500518\tKL_Divergence = 3.969401\n",
      "Epoch: 7\tFidelity = 0.500579\tKL_Divergence = 3.907475\n",
      "Epoch: 8\tFidelity = 0.500552\tKL_Divergence = 3.934294\n",
      "Epoch: 9\tFidelity = 0.500537\tKL_Divergence = 3.948863\n",
      "Epoch: 10\tFidelity = 0.500571\tKL_Divergence = 3.914843\n",
      "Epoch: 11\tFidelity = 0.500508\tKL_Divergence = 3.980309\n",
      "Epoch: 12\tFidelity = 0.500534\tKL_Divergence = 3.951826\n",
      "Epoch: 13\tFidelity = 0.500497\tKL_Divergence = 3.992291\n",
      "Epoch: 14\tFidelity = 0.500583\tKL_Divergence = 3.903390\n",
      "Epoch: 15\tFidelity = 0.500539\tKL_Divergence = 3.946893\n",
      "Epoch: 16\tFidelity = 0.500580\tKL_Divergence = 3.906792\n",
      "Epoch: 17\tFidelity = 0.500479\tKL_Divergence = 4.012965\n",
      "Epoch: 18\tFidelity = 0.500594\tKL_Divergence = 3.893006\n",
      "Epoch: 19\tFidelity = 0.500491\tKL_Divergence = 3.999403\n",
      "Epoch: 20\tFidelity = 0.500579\tKL_Divergence = 3.907572\n",
      "Epoch: 21\tFidelity = 0.500528\tKL_Divergence = 3.959096\n",
      "Epoch: 22\tFidelity = 0.500517\tKL_Divergence = 3.969848\n",
      "Epoch: 23\tFidelity = 0.500543\tKL_Divergence = 3.943043\n",
      "Epoch: 24\tFidelity = 0.500544\tKL_Divergence = 3.941830\n",
      "Epoch: 25\tFidelity = 0.500548\tKL_Divergence = 3.938337\n",
      "Epoch: 26\tFidelity = 0.500546\tKL_Divergence = 3.940301\n",
      "Epoch: 27\tFidelity = 0.500530\tKL_Divergence = 3.956697\n",
      "Epoch: 28\tFidelity = 0.500592\tKL_Divergence = 3.895510\n",
      "Epoch: 29\tFidelity = 0.500490\tKL_Divergence = 3.999541\n",
      "Epoch: 30\tFidelity = 0.500613\tKL_Divergence = 3.875738\n",
      "Epoch: 31\tFidelity = 0.500508\tKL_Divergence = 3.979839\n",
      "Epoch: 32\tFidelity = 0.500554\tKL_Divergence = 3.932418\n",
      "Epoch: 33\tFidelity = 0.500549\tKL_Divergence = 3.936961\n",
      "Epoch: 34\tFidelity = 0.500544\tKL_Divergence = 3.941625\n",
      "Epoch: 35\tFidelity = 0.500538\tKL_Divergence = 3.947918\n",
      "Epoch: 36\tFidelity = 0.500553\tKL_Divergence = 3.933116\n",
      "Epoch: 37\tFidelity = 0.500549\tKL_Divergence = 3.936779\n",
      "Epoch: 38\tFidelity = 0.500614\tKL_Divergence = 3.874547\n",
      "Epoch: 39\tFidelity = 0.500545\tKL_Divergence = 3.940576\n",
      "Epoch: 40\tFidelity = 0.500572\tKL_Divergence = 3.914085\n",
      "Epoch: 41\tFidelity = 0.500500\tKL_Divergence = 3.988516\n",
      "Epoch: 42\tFidelity = 0.500583\tKL_Divergence = 3.903330\n",
      "Epoch: 43\tFidelity = 0.500501\tKL_Divergence = 3.987197\n",
      "Epoch: 44\tFidelity = 0.500604\tKL_Divergence = 3.883933\n",
      "Epoch: 45\tFidelity = 0.500516\tKL_Divergence = 3.971656\n",
      "Epoch: 46\tFidelity = 0.500580\tKL_Divergence = 3.906834\n",
      "Epoch: 47\tFidelity = 0.500500\tKL_Divergence = 3.988846\n",
      "Epoch: 48\tFidelity = 0.500566\tKL_Divergence = 3.919610\n",
      "Epoch: 49\tFidelity = 0.500495\tKL_Divergence = 3.994006\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:54:26,834] Trial 558 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500590\tKL_Divergence = 3.897497\n",
      "Total time elapsed during training: 32.479 s\n",
      "Trial 558 pruned. \n",
      "Epoch: 1\tFidelity = 0.500508\tKL_Divergence = 3.980068\n",
      "Epoch: 2\tFidelity = 0.500577\tKL_Divergence = 3.908957\n",
      "Epoch: 3\tFidelity = 0.500560\tKL_Divergence = 3.925601\n",
      "Epoch: 4\tFidelity = 0.500580\tKL_Divergence = 3.906620\n",
      "Epoch: 5\tFidelity = 0.500498\tKL_Divergence = 3.990981\n",
      "Epoch: 6\tFidelity = 0.500535\tKL_Divergence = 3.950988\n",
      "Epoch: 7\tFidelity = 0.500588\tKL_Divergence = 3.898717\n",
      "Epoch: 8\tFidelity = 0.500491\tKL_Divergence = 3.999376\n",
      "Epoch: 9\tFidelity = 0.500595\tKL_Divergence = 3.892277\n",
      "Epoch: 10\tFidelity = 0.500502\tKL_Divergence = 3.986265\n",
      "Epoch: 11\tFidelity = 0.500570\tKL_Divergence = 3.915772\n",
      "Epoch: 12\tFidelity = 0.500534\tKL_Divergence = 3.951937\n",
      "Epoch: 13\tFidelity = 0.500475\tKL_Divergence = 4.017876\n",
      "Epoch: 14\tFidelity = 0.500642\tKL_Divergence = 3.850241\n",
      "Epoch: 15\tFidelity = 0.500579\tKL_Divergence = 3.907176\n",
      "Epoch: 16\tFidelity = 0.500560\tKL_Divergence = 3.926277\n",
      "Epoch: 17\tFidelity = 0.500586\tKL_Divergence = 3.900960\n",
      "Epoch: 18\tFidelity = 0.500556\tKL_Divergence = 3.929492\n",
      "Epoch: 19\tFidelity = 0.500525\tKL_Divergence = 3.962029\n",
      "Epoch: 20\tFidelity = 0.500476\tKL_Divergence = 4.015680\n",
      "Epoch: 21\tFidelity = 0.500462\tKL_Divergence = 4.032393\n",
      "Epoch: 22\tFidelity = 0.500552\tKL_Divergence = 3.934193\n",
      "Epoch: 23\tFidelity = 0.500523\tKL_Divergence = 3.963451\n",
      "Epoch: 24\tFidelity = 0.500574\tKL_Divergence = 3.912731\n",
      "Epoch: 25\tFidelity = 0.500561\tKL_Divergence = 3.924757\n",
      "Epoch: 26\tFidelity = 0.500543\tKL_Divergence = 3.943096\n",
      "Epoch: 27\tFidelity = 0.500559\tKL_Divergence = 3.926898\n",
      "Epoch: 28\tFidelity = 0.500495\tKL_Divergence = 3.994180\n",
      "Epoch: 29\tFidelity = 0.500559\tKL_Divergence = 3.927289\n",
      "Epoch: 30\tFidelity = 0.500534\tKL_Divergence = 3.952634\n",
      "Epoch: 31\tFidelity = 0.500520\tKL_Divergence = 3.966731\n",
      "Epoch: 32\tFidelity = 0.500565\tKL_Divergence = 3.921562\n",
      "Epoch: 33\tFidelity = 0.500500\tKL_Divergence = 3.989345\n",
      "Epoch: 34\tFidelity = 0.500616\tKL_Divergence = 3.872729\n",
      "Epoch: 35\tFidelity = 0.500505\tKL_Divergence = 3.983400\n",
      "Epoch: 36\tFidelity = 0.500571\tKL_Divergence = 3.915638\n",
      "Epoch: 37\tFidelity = 0.500458\tKL_Divergence = 4.037706\n",
      "Epoch: 38\tFidelity = 0.500592\tKL_Divergence = 3.895529\n",
      "Epoch: 39\tFidelity = 0.500554\tKL_Divergence = 3.932157\n",
      "Epoch: 40\tFidelity = 0.500553\tKL_Divergence = 3.933191\n",
      "Epoch: 41\tFidelity = 0.500458\tKL_Divergence = 4.037434\n",
      "Epoch: 42\tFidelity = 0.500601\tKL_Divergence = 3.887009\n",
      "Epoch: 43\tFidelity = 0.500611\tKL_Divergence = 3.877251\n",
      "Epoch: 44\tFidelity = 0.500486\tKL_Divergence = 4.004703\n",
      "Epoch: 45\tFidelity = 0.500590\tKL_Divergence = 3.896917\n",
      "Epoch: 46\tFidelity = 0.500590\tKL_Divergence = 3.896739\n",
      "Epoch: 47\tFidelity = 0.500484\tKL_Divergence = 4.007168\n",
      "Epoch: 48\tFidelity = 0.500555\tKL_Divergence = 3.931231\n",
      "Epoch: 49\tFidelity = 0.500591\tKL_Divergence = 3.896459\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:54:59,947] Trial 559 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500548\tKL_Divergence = 3.937540\n",
      "Total time elapsed during training: 32.929 s\n",
      "Trial 559 pruned. \n",
      "Epoch: 1\tFidelity = 0.500660\tKL_Divergence = 3.834518\n",
      "Epoch: 2\tFidelity = 0.500689\tKL_Divergence = 3.811003\n",
      "Epoch: 3\tFidelity = 0.500581\tKL_Divergence = 3.905171\n",
      "Epoch: 4\tFidelity = 0.500517\tKL_Divergence = 3.970055\n",
      "Epoch: 5\tFidelity = 0.500614\tKL_Divergence = 3.874781\n",
      "Epoch: 6\tFidelity = 0.500707\tKL_Divergence = 3.796351\n",
      "Epoch: 7\tFidelity = 0.500583\tKL_Divergence = 3.903468\n",
      "Epoch: 8\tFidelity = 0.500535\tKL_Divergence = 3.951620\n",
      "Epoch: 9\tFidelity = 0.500612\tKL_Divergence = 3.877037\n",
      "Epoch: 10\tFidelity = 0.500646\tKL_Divergence = 3.846268\n",
      "Epoch: 11\tFidelity = 0.500574\tKL_Divergence = 3.912083\n",
      "Epoch: 12\tFidelity = 0.500508\tKL_Divergence = 3.979882\n",
      "Epoch: 13\tFidelity = 0.500684\tKL_Divergence = 3.814723\n",
      "Epoch: 14\tFidelity = 0.500603\tKL_Divergence = 3.884451\n",
      "Epoch: 15\tFidelity = 0.500541\tKL_Divergence = 3.944597\n",
      "Epoch: 16\tFidelity = 0.500543\tKL_Divergence = 3.942724\n",
      "Epoch: 17\tFidelity = 0.500418\tKL_Divergence = 4.087827\n",
      "Epoch: 18\tFidelity = 0.500557\tKL_Divergence = 3.928874\n",
      "Epoch: 19\tFidelity = 0.500586\tKL_Divergence = 3.900537\n",
      "Epoch: 20\tFidelity = 0.500514\tKL_Divergence = 3.973397\n",
      "Epoch: 21\tFidelity = 0.500546\tKL_Divergence = 3.940269\n",
      "Epoch: 22\tFidelity = 0.500616\tKL_Divergence = 3.873526\n",
      "Epoch: 23\tFidelity = 0.500569\tKL_Divergence = 3.917341\n",
      "Epoch: 24\tFidelity = 0.500492\tKL_Divergence = 3.997875\n",
      "Epoch: 25\tFidelity = 0.500505\tKL_Divergence = 3.983221\n",
      "Epoch: 26\tFidelity = 0.500461\tKL_Divergence = 4.033410\n",
      "Epoch: 27\tFidelity = 0.500557\tKL_Divergence = 3.928610\n",
      "Epoch: 28\tFidelity = 0.500618\tKL_Divergence = 3.871029\n",
      "Epoch: 29\tFidelity = 0.500609\tKL_Divergence = 3.879704\n",
      "Epoch: 30\tFidelity = 0.500601\tKL_Divergence = 3.886969\n",
      "Epoch: 31\tFidelity = 0.500602\tKL_Divergence = 3.885855\n",
      "Epoch: 32\tFidelity = 0.500541\tKL_Divergence = 3.944701\n",
      "Epoch: 33\tFidelity = 0.500683\tKL_Divergence = 3.815658\n",
      "Epoch: 34\tFidelity = 0.500683\tKL_Divergence = 3.815906\n",
      "Epoch: 35\tFidelity = 0.500594\tKL_Divergence = 3.893030\n",
      "Epoch: 36\tFidelity = 0.500565\tKL_Divergence = 3.921347\n",
      "Epoch: 37\tFidelity = 0.500635\tKL_Divergence = 3.856090\n",
      "Epoch: 38\tFidelity = 0.500602\tKL_Divergence = 3.885529\n",
      "Epoch: 39\tFidelity = 0.500649\tKL_Divergence = 3.843669\n",
      "Epoch: 40\tFidelity = 0.500653\tKL_Divergence = 3.840388\n",
      "Epoch: 41\tFidelity = 0.500485\tKL_Divergence = 4.005350\n",
      "Epoch: 42\tFidelity = 0.500589\tKL_Divergence = 3.898265\n",
      "Epoch: 43\tFidelity = 0.500577\tKL_Divergence = 3.909526\n",
      "Epoch: 44\tFidelity = 0.500591\tKL_Divergence = 3.895823\n",
      "Epoch: 45\tFidelity = 0.500609\tKL_Divergence = 3.879689\n",
      "Epoch: 46\tFidelity = 0.500605\tKL_Divergence = 3.882730\n",
      "Epoch: 47\tFidelity = 0.500613\tKL_Divergence = 3.876033\n",
      "Epoch: 48\tFidelity = 0.500645\tKL_Divergence = 3.847375\n",
      "Epoch: 49\tFidelity = 0.500646\tKL_Divergence = 3.846399\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:56:22,599] Trial 560 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500605\tKL_Divergence = 3.882786\n",
      "Total time elapsed during training: 82.454 s\n",
      "Trial 560 pruned. \n",
      "Epoch: 1\tFidelity = 0.500642\tKL_Divergence = 3.850147\n",
      "Epoch: 2\tFidelity = 0.500628\tKL_Divergence = 3.862481\n",
      "Epoch: 3\tFidelity = 0.500601\tKL_Divergence = 3.886832\n",
      "Epoch: 4\tFidelity = 0.500618\tKL_Divergence = 3.871392\n",
      "Epoch: 5\tFidelity = 0.500623\tKL_Divergence = 3.867060\n",
      "Epoch: 6\tFidelity = 0.500635\tKL_Divergence = 3.855713\n",
      "Epoch: 7\tFidelity = 0.500646\tKL_Divergence = 3.846192\n",
      "Epoch: 8\tFidelity = 0.500637\tKL_Divergence = 3.854536\n",
      "Epoch: 9\tFidelity = 0.500622\tKL_Divergence = 3.867117\n",
      "Epoch: 10\tFidelity = 0.500646\tKL_Divergence = 3.846746\n",
      "Epoch: 11\tFidelity = 0.500585\tKL_Divergence = 3.901707\n",
      "Epoch: 12\tFidelity = 0.500594\tKL_Divergence = 3.892923\n",
      "Epoch: 13\tFidelity = 0.500592\tKL_Divergence = 3.895259\n",
      "Epoch: 14\tFidelity = 0.500580\tKL_Divergence = 3.906700\n",
      "Epoch: 15\tFidelity = 0.500597\tKL_Divergence = 3.890323\n",
      "Epoch: 16\tFidelity = 0.500607\tKL_Divergence = 3.880946\n",
      "Epoch: 17\tFidelity = 0.500622\tKL_Divergence = 3.867860\n",
      "Epoch: 18\tFidelity = 0.500613\tKL_Divergence = 3.875343\n",
      "Epoch: 19\tFidelity = 0.500556\tKL_Divergence = 3.929667\n",
      "Epoch: 20\tFidelity = 0.500608\tKL_Divergence = 3.880549\n",
      "Epoch: 21\tFidelity = 0.500623\tKL_Divergence = 3.866973\n",
      "Epoch: 22\tFidelity = 0.500577\tKL_Divergence = 3.908928\n",
      "Epoch: 23\tFidelity = 0.500598\tKL_Divergence = 3.889389\n",
      "Epoch: 24\tFidelity = 0.500600\tKL_Divergence = 3.887864\n",
      "Epoch: 25\tFidelity = 0.500571\tKL_Divergence = 3.915249\n",
      "Epoch: 26\tFidelity = 0.500583\tKL_Divergence = 3.903366\n",
      "Epoch: 27\tFidelity = 0.500576\tKL_Divergence = 3.910393\n",
      "Epoch: 28\tFidelity = 0.500602\tKL_Divergence = 3.885985\n",
      "Epoch: 29\tFidelity = 0.500597\tKL_Divergence = 3.890061\n",
      "Epoch: 30\tFidelity = 0.500573\tKL_Divergence = 3.912863\n",
      "Epoch: 31\tFidelity = 0.500586\tKL_Divergence = 3.900476\n",
      "Epoch: 32\tFidelity = 0.500595\tKL_Divergence = 3.892430\n",
      "Epoch: 33\tFidelity = 0.500563\tKL_Divergence = 3.922798\n",
      "Epoch: 34\tFidelity = 0.500600\tKL_Divergence = 3.887512\n",
      "Epoch: 35\tFidelity = 0.500578\tKL_Divergence = 3.908357\n",
      "Epoch: 36\tFidelity = 0.500605\tKL_Divergence = 3.883182\n",
      "Epoch: 37\tFidelity = 0.500577\tKL_Divergence = 3.909314\n",
      "Epoch: 38\tFidelity = 0.500610\tKL_Divergence = 3.878706\n",
      "Epoch: 39\tFidelity = 0.500565\tKL_Divergence = 3.920771\n",
      "Epoch: 40\tFidelity = 0.500587\tKL_Divergence = 3.899557\n",
      "Epoch: 41\tFidelity = 0.500655\tKL_Divergence = 3.839036\n",
      "Epoch: 42\tFidelity = 0.500599\tKL_Divergence = 3.888578\n",
      "Epoch: 43\tFidelity = 0.500625\tKL_Divergence = 3.864785\n",
      "Epoch: 44\tFidelity = 0.500593\tKL_Divergence = 3.893642\n",
      "Epoch: 45\tFidelity = 0.500633\tKL_Divergence = 3.858076\n",
      "Epoch: 46\tFidelity = 0.500612\tKL_Divergence = 3.876462\n",
      "Epoch: 47\tFidelity = 0.500606\tKL_Divergence = 3.881959\n",
      "Epoch: 48\tFidelity = 0.500650\tKL_Divergence = 3.842818\n",
      "Epoch: 49\tFidelity = 0.500580\tKL_Divergence = 3.906363\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:57:08,209] Trial 561 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500624\tKL_Divergence = 3.866236\n",
      "Total time elapsed during training: 45.426 s\n",
      "Trial 561 pruned. \n",
      "Epoch: 1\tFidelity = 0.500581\tKL_Divergence = 3.905408\n",
      "Epoch: 2\tFidelity = 0.500601\tKL_Divergence = 3.886359\n",
      "Epoch: 3\tFidelity = 0.500582\tKL_Divergence = 3.904299\n",
      "Epoch: 4\tFidelity = 0.500672\tKL_Divergence = 3.824334\n",
      "Epoch: 5\tFidelity = 0.500649\tKL_Divergence = 3.844023\n",
      "Epoch: 6\tFidelity = 0.500579\tKL_Divergence = 3.907315\n",
      "Epoch: 7\tFidelity = 0.500669\tKL_Divergence = 3.827124\n",
      "Epoch: 8\tFidelity = 0.500649\tKL_Divergence = 3.843406\n",
      "Epoch: 9\tFidelity = 0.500592\tKL_Divergence = 3.894408\n",
      "Epoch: 10\tFidelity = 0.500565\tKL_Divergence = 3.920317\n",
      "Epoch: 11\tFidelity = 0.500646\tKL_Divergence = 3.846658\n",
      "Epoch: 12\tFidelity = 0.500686\tKL_Divergence = 3.813313\n",
      "Epoch: 13\tFidelity = 0.500545\tKL_Divergence = 3.940893\n",
      "Epoch: 14\tFidelity = 0.500532\tKL_Divergence = 3.954490\n",
      "Epoch: 15\tFidelity = 0.500673\tKL_Divergence = 3.823626\n",
      "Epoch: 16\tFidelity = 0.500590\tKL_Divergence = 3.896721\n",
      "Epoch: 17\tFidelity = 0.500646\tKL_Divergence = 3.846701\n",
      "Epoch: 18\tFidelity = 0.500541\tKL_Divergence = 3.945002\n",
      "Epoch: 19\tFidelity = 0.500580\tKL_Divergence = 3.905986\n",
      "Epoch: 20\tFidelity = 0.500530\tKL_Divergence = 3.956537\n",
      "Epoch: 21\tFidelity = 0.500633\tKL_Divergence = 3.858001\n",
      "Epoch: 22\tFidelity = 0.500613\tKL_Divergence = 3.875421\n",
      "Epoch: 23\tFidelity = 0.500639\tKL_Divergence = 3.853043\n",
      "Epoch: 24\tFidelity = 0.500570\tKL_Divergence = 3.916104\n",
      "Epoch: 25\tFidelity = 0.500713\tKL_Divergence = 3.792247\n",
      "Epoch: 26\tFidelity = 0.500657\tKL_Divergence = 3.836971\n",
      "Epoch: 27\tFidelity = 0.500703\tKL_Divergence = 3.800011\n",
      "Epoch: 28\tFidelity = 0.500586\tKL_Divergence = 3.900889\n",
      "Epoch: 29\tFidelity = 0.500693\tKL_Divergence = 3.807761\n",
      "Epoch: 30\tFidelity = 0.500532\tKL_Divergence = 3.954482\n",
      "Epoch: 31\tFidelity = 0.500588\tKL_Divergence = 3.898446\n",
      "Epoch: 32\tFidelity = 0.500666\tKL_Divergence = 3.829206\n",
      "Epoch: 33\tFidelity = 0.500562\tKL_Divergence = 3.923480\n",
      "Epoch: 34\tFidelity = 0.500581\tKL_Divergence = 3.904535\n",
      "Epoch: 35\tFidelity = 0.500498\tKL_Divergence = 3.990911\n",
      "Epoch: 36\tFidelity = 0.500634\tKL_Divergence = 3.856582\n",
      "Epoch: 37\tFidelity = 0.500617\tKL_Divergence = 3.871418\n",
      "Epoch: 38\tFidelity = 0.500622\tKL_Divergence = 3.866953\n",
      "Epoch: 39\tFidelity = 0.500691\tKL_Divergence = 3.807973\n",
      "Epoch: 40\tFidelity = 0.500621\tKL_Divergence = 3.867111\n",
      "Epoch: 41\tFidelity = 0.500607\tKL_Divergence = 3.880443\n",
      "Epoch: 42\tFidelity = 0.500614\tKL_Divergence = 3.873751\n",
      "Epoch: 43\tFidelity = 0.500556\tKL_Divergence = 3.928118\n",
      "Epoch: 44\tFidelity = 0.500689\tKL_Divergence = 3.808797\n",
      "Epoch: 45\tFidelity = 0.500653\tKL_Divergence = 3.839091\n",
      "Epoch: 46\tFidelity = 0.500577\tKL_Divergence = 3.907700\n",
      "Epoch: 47\tFidelity = 0.500644\tKL_Divergence = 3.847709\n",
      "Epoch: 48\tFidelity = 0.500531\tKL_Divergence = 3.954850\n",
      "Epoch: 49\tFidelity = 0.500587\tKL_Divergence = 3.898970\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:57:46,620] Trial 562 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500661\tKL_Divergence = 3.833368\n",
      "Total time elapsed during training: 38.227 s\n",
      "Trial 562 pruned. \n",
      "Epoch: 1\tFidelity = 0.500725\tKL_Divergence = 3.782613\n",
      "Epoch: 2\tFidelity = 0.500743\tKL_Divergence = 3.768797\n",
      "Epoch: 3\tFidelity = 0.500537\tKL_Divergence = 3.949089\n",
      "Epoch: 4\tFidelity = 0.500578\tKL_Divergence = 3.907982\n",
      "Epoch: 5\tFidelity = 0.500559\tKL_Divergence = 3.926855\n",
      "Epoch: 6\tFidelity = 0.500501\tKL_Divergence = 3.988003\n",
      "Epoch: 7\tFidelity = 0.500698\tKL_Divergence = 3.803676\n",
      "Epoch: 8\tFidelity = 0.500546\tKL_Divergence = 3.939556\n",
      "Epoch: 9\tFidelity = 0.500740\tKL_Divergence = 3.770907\n",
      "Epoch: 10\tFidelity = 0.500703\tKL_Divergence = 3.799798\n",
      "Epoch: 11\tFidelity = 0.500707\tKL_Divergence = 3.796315\n",
      "Epoch: 12\tFidelity = 0.500576\tKL_Divergence = 3.910846\n",
      "Epoch: 13\tFidelity = 0.500431\tKL_Divergence = 4.070987\n",
      "Epoch: 14\tFidelity = 0.500398\tKL_Divergence = 4.115048\n",
      "Epoch: 15\tFidelity = 0.500564\tKL_Divergence = 3.922411\n",
      "Epoch: 16\tFidelity = 0.500659\tKL_Divergence = 3.836043\n",
      "Epoch: 17\tFidelity = 0.500571\tKL_Divergence = 3.915110\n",
      "Epoch: 18\tFidelity = 0.500414\tKL_Divergence = 4.093965\n",
      "Epoch: 19\tFidelity = 0.500603\tKL_Divergence = 3.884955\n",
      "Epoch: 20\tFidelity = 0.500472\tKL_Divergence = 4.020807\n",
      "Epoch: 21\tFidelity = 0.500617\tKL_Divergence = 3.871955\n",
      "Epoch: 22\tFidelity = 0.500605\tKL_Divergence = 3.883086\n",
      "Epoch: 23\tFidelity = 0.500582\tKL_Divergence = 3.904924\n",
      "Epoch: 24\tFidelity = 0.500702\tKL_Divergence = 3.800843\n",
      "Epoch: 25\tFidelity = 0.500468\tKL_Divergence = 4.025120\n",
      "Epoch: 26\tFidelity = 0.500589\tKL_Divergence = 3.897278\n",
      "Epoch: 27\tFidelity = 0.500589\tKL_Divergence = 3.897844\n",
      "Epoch: 28\tFidelity = 0.500563\tKL_Divergence = 3.923243\n",
      "Epoch: 29\tFidelity = 0.500590\tKL_Divergence = 3.897069\n",
      "Epoch: 30\tFidelity = 0.500589\tKL_Divergence = 3.898040\n",
      "Epoch: 31\tFidelity = 0.500501\tKL_Divergence = 3.987138\n",
      "Epoch: 32\tFidelity = 0.500678\tKL_Divergence = 3.819990\n",
      "Epoch: 33\tFidelity = 0.500565\tKL_Divergence = 3.920380\n",
      "Epoch: 34\tFidelity = 0.500648\tKL_Divergence = 3.844519\n",
      "Epoch: 35\tFidelity = 0.500454\tKL_Divergence = 4.041603\n",
      "Epoch: 36\tFidelity = 0.500569\tKL_Divergence = 3.917071\n",
      "Epoch: 37\tFidelity = 0.500562\tKL_Divergence = 3.923890\n",
      "Epoch: 38\tFidelity = 0.500515\tKL_Divergence = 3.972117\n",
      "Epoch: 39\tFidelity = 0.500477\tKL_Divergence = 4.014333\n",
      "Epoch: 40\tFidelity = 0.500611\tKL_Divergence = 3.877773\n",
      "Epoch: 41\tFidelity = 0.500438\tKL_Divergence = 4.061599\n",
      "Epoch: 42\tFidelity = 0.500549\tKL_Divergence = 3.936818\n",
      "Epoch: 43\tFidelity = 0.500520\tKL_Divergence = 3.966586\n",
      "Epoch: 44\tFidelity = 0.500574\tKL_Divergence = 3.912635\n",
      "Epoch: 45\tFidelity = 0.500521\tKL_Divergence = 3.965536\n",
      "Epoch: 46\tFidelity = 0.500647\tKL_Divergence = 3.846249\n",
      "Epoch: 47\tFidelity = 0.500659\tKL_Divergence = 3.835758\n",
      "Epoch: 48\tFidelity = 0.500699\tKL_Divergence = 3.803013\n",
      "Epoch: 49\tFidelity = 0.500678\tKL_Divergence = 3.820041\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:58:25,562] Trial 563 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500666\tKL_Divergence = 3.829337\n",
      "Total time elapsed during training: 38.764 s\n",
      "Trial 563 pruned. \n",
      "Epoch: 1\tFidelity = 0.500644\tKL_Divergence = 3.848561\n",
      "Epoch: 2\tFidelity = 0.500538\tKL_Divergence = 3.948323\n",
      "Epoch: 3\tFidelity = 0.500581\tKL_Divergence = 3.905905\n",
      "Epoch: 4\tFidelity = 0.500579\tKL_Divergence = 3.907126\n",
      "Epoch: 5\tFidelity = 0.500634\tKL_Divergence = 3.857052\n",
      "Epoch: 6\tFidelity = 0.500612\tKL_Divergence = 3.876463\n",
      "Epoch: 7\tFidelity = 0.500646\tKL_Divergence = 3.846281\n",
      "Epoch: 8\tFidelity = 0.500649\tKL_Divergence = 3.844164\n",
      "Epoch: 9\tFidelity = 0.500591\tKL_Divergence = 3.895689\n",
      "Epoch: 10\tFidelity = 0.500548\tKL_Divergence = 3.937883\n",
      "Epoch: 11\tFidelity = 0.500603\tKL_Divergence = 3.885292\n",
      "Epoch: 12\tFidelity = 0.500559\tKL_Divergence = 3.926651\n",
      "Epoch: 13\tFidelity = 0.500617\tKL_Divergence = 3.872594\n",
      "Epoch: 14\tFidelity = 0.500576\tKL_Divergence = 3.910123\n",
      "Epoch: 15\tFidelity = 0.500560\tKL_Divergence = 3.925723\n",
      "Epoch: 16\tFidelity = 0.500595\tKL_Divergence = 3.892382\n",
      "Epoch: 17\tFidelity = 0.500567\tKL_Divergence = 3.918685\n",
      "Epoch: 18\tFidelity = 0.500583\tKL_Divergence = 3.903632\n",
      "Epoch: 19\tFidelity = 0.500512\tKL_Divergence = 3.975747\n",
      "Epoch: 20\tFidelity = 0.500633\tKL_Divergence = 3.858092\n",
      "Epoch: 21\tFidelity = 0.500627\tKL_Divergence = 3.863360\n",
      "Epoch: 22\tFidelity = 0.500595\tKL_Divergence = 3.892257\n",
      "Epoch: 23\tFidelity = 0.500636\tKL_Divergence = 3.855009\n",
      "Epoch: 24\tFidelity = 0.500666\tKL_Divergence = 3.829922\n",
      "Epoch: 25\tFidelity = 0.500538\tKL_Divergence = 3.947785\n",
      "Epoch: 26\tFidelity = 0.500585\tKL_Divergence = 3.901775\n",
      "Epoch: 27\tFidelity = 0.500588\tKL_Divergence = 3.899208\n",
      "Epoch: 28\tFidelity = 0.500530\tKL_Divergence = 3.955915\n",
      "Epoch: 29\tFidelity = 0.500591\tKL_Divergence = 3.895179\n",
      "Epoch: 30\tFidelity = 0.500588\tKL_Divergence = 3.898125\n",
      "Epoch: 31\tFidelity = 0.500604\tKL_Divergence = 3.883811\n",
      "Epoch: 32\tFidelity = 0.500616\tKL_Divergence = 3.872285\n",
      "Epoch: 33\tFidelity = 0.500656\tKL_Divergence = 3.837723\n",
      "Epoch: 34\tFidelity = 0.500597\tKL_Divergence = 3.890485\n",
      "Epoch: 35\tFidelity = 0.500598\tKL_Divergence = 3.889122\n",
      "Epoch: 36\tFidelity = 0.500651\tKL_Divergence = 3.842001\n",
      "Epoch: 37\tFidelity = 0.500543\tKL_Divergence = 3.943087\n",
      "Epoch: 38\tFidelity = 0.500519\tKL_Divergence = 3.968182\n",
      "Epoch: 39\tFidelity = 0.500617\tKL_Divergence = 3.871841\n",
      "Epoch: 40\tFidelity = 0.500575\tKL_Divergence = 3.911374\n",
      "Epoch: 41\tFidelity = 0.500565\tKL_Divergence = 3.921135\n",
      "Epoch: 42\tFidelity = 0.500602\tKL_Divergence = 3.885807\n",
      "Epoch: 43\tFidelity = 0.500622\tKL_Divergence = 3.867739\n",
      "Epoch: 44\tFidelity = 0.500562\tKL_Divergence = 3.924323\n",
      "Epoch: 45\tFidelity = 0.500557\tKL_Divergence = 3.928326\n",
      "Epoch: 46\tFidelity = 0.500620\tKL_Divergence = 3.869131\n",
      "Epoch: 47\tFidelity = 0.500559\tKL_Divergence = 3.926994\n",
      "Epoch: 48\tFidelity = 0.500564\tKL_Divergence = 3.921695\n",
      "Epoch: 49\tFidelity = 0.500589\tKL_Divergence = 3.897365\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:59:10,721] Trial 564 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500586\tKL_Divergence = 3.900654\n",
      "Total time elapsed during training: 44.981 s\n",
      "Trial 564 pruned. \n",
      "Epoch: 1\tFidelity = 0.500622\tKL_Divergence = 3.867419\n",
      "Epoch: 2\tFidelity = 0.500606\tKL_Divergence = 3.881921\n",
      "Epoch: 3\tFidelity = 0.500638\tKL_Divergence = 3.853471\n",
      "Epoch: 4\tFidelity = 0.500588\tKL_Divergence = 3.898939\n",
      "Epoch: 5\tFidelity = 0.500563\tKL_Divergence = 3.922697\n",
      "Epoch: 6\tFidelity = 0.500588\tKL_Divergence = 3.898907\n",
      "Epoch: 7\tFidelity = 0.500610\tKL_Divergence = 3.878119\n",
      "Epoch: 8\tFidelity = 0.500563\tKL_Divergence = 3.922865\n",
      "Epoch: 9\tFidelity = 0.500623\tKL_Divergence = 3.866618\n",
      "Epoch: 10\tFidelity = 0.500575\tKL_Divergence = 3.911223\n",
      "Epoch: 11\tFidelity = 0.500623\tKL_Divergence = 3.866444\n",
      "Epoch: 12\tFidelity = 0.500525\tKL_Divergence = 3.961241\n",
      "Epoch: 13\tFidelity = 0.500743\tKL_Divergence = 3.768945\n",
      "Epoch: 14\tFidelity = 0.500577\tKL_Divergence = 3.909354\n",
      "Epoch: 15\tFidelity = 0.500580\tKL_Divergence = 3.905949\n",
      "Epoch: 16\tFidelity = 0.500667\tKL_Divergence = 3.828653\n",
      "Epoch: 17\tFidelity = 0.500664\tKL_Divergence = 3.831039\n",
      "Epoch: 18\tFidelity = 0.500616\tKL_Divergence = 3.872796\n",
      "Epoch: 19\tFidelity = 0.500634\tKL_Divergence = 3.856670\n",
      "Epoch: 20\tFidelity = 0.500563\tKL_Divergence = 3.922305\n",
      "Epoch: 21\tFidelity = 0.500575\tKL_Divergence = 3.911242\n",
      "Epoch: 22\tFidelity = 0.500594\tKL_Divergence = 3.892829\n",
      "Epoch: 23\tFidelity = 0.500533\tKL_Divergence = 3.952883\n",
      "Epoch: 24\tFidelity = 0.500640\tKL_Divergence = 3.851382\n",
      "Epoch: 25\tFidelity = 0.500645\tKL_Divergence = 3.847754\n",
      "Epoch: 26\tFidelity = 0.500590\tKL_Divergence = 3.896443\n",
      "Epoch: 27\tFidelity = 0.500618\tKL_Divergence = 3.871489\n",
      "Epoch: 28\tFidelity = 0.500649\tKL_Divergence = 3.843899\n",
      "Epoch: 29\tFidelity = 0.500716\tKL_Divergence = 3.789724\n",
      "Epoch: 30\tFidelity = 0.500693\tKL_Divergence = 3.807607\n",
      "Epoch: 31\tFidelity = 0.500689\tKL_Divergence = 3.810704\n",
      "Epoch: 32\tFidelity = 0.500647\tKL_Divergence = 3.845325\n",
      "Epoch: 33\tFidelity = 0.500689\tKL_Divergence = 3.810738\n",
      "Epoch: 34\tFidelity = 0.500737\tKL_Divergence = 3.773782\n",
      "Epoch: 35\tFidelity = 0.500571\tKL_Divergence = 3.914650\n",
      "Epoch: 36\tFidelity = 0.500590\tKL_Divergence = 3.896827\n",
      "Epoch: 37\tFidelity = 0.500603\tKL_Divergence = 3.884730\n",
      "Epoch: 38\tFidelity = 0.500664\tKL_Divergence = 3.831183\n",
      "Epoch: 39\tFidelity = 0.500655\tKL_Divergence = 3.839325\n",
      "Epoch: 40\tFidelity = 0.500582\tKL_Divergence = 3.904665\n",
      "Epoch: 41\tFidelity = 0.500677\tKL_Divergence = 3.820446\n",
      "Epoch: 42\tFidelity = 0.500652\tKL_Divergence = 3.841850\n",
      "Epoch: 43\tFidelity = 0.500609\tKL_Divergence = 3.879636\n",
      "Epoch: 44\tFidelity = 0.500596\tKL_Divergence = 3.891370\n",
      "Epoch: 45\tFidelity = 0.500648\tKL_Divergence = 3.844833\n",
      "Epoch: 46\tFidelity = 0.500603\tKL_Divergence = 3.884784\n",
      "Epoch: 47\tFidelity = 0.500621\tKL_Divergence = 3.868339\n",
      "Epoch: 48\tFidelity = 0.500626\tKL_Divergence = 3.863814\n",
      "Epoch: 49\tFidelity = 0.500616\tKL_Divergence = 3.872677\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 10:59:48,980] Trial 565 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500649\tKL_Divergence = 3.843821\n",
      "Total time elapsed during training: 38.078 s\n",
      "Trial 565 pruned. \n",
      "Epoch: 1\tFidelity = 0.500658\tKL_Divergence = 3.836040\n",
      "Epoch: 2\tFidelity = 0.500674\tKL_Divergence = 3.823059\n",
      "Epoch: 3\tFidelity = 0.500679\tKL_Divergence = 3.819140\n",
      "Epoch: 4\tFidelity = 0.500653\tKL_Divergence = 3.840648\n",
      "Epoch: 5\tFidelity = 0.500577\tKL_Divergence = 3.909010\n",
      "Epoch: 6\tFidelity = 0.500578\tKL_Divergence = 3.907820\n",
      "Epoch: 7\tFidelity = 0.500628\tKL_Divergence = 3.862342\n",
      "Epoch: 8\tFidelity = 0.500704\tKL_Divergence = 3.798830\n",
      "Epoch: 9\tFidelity = 0.500669\tKL_Divergence = 3.827182\n",
      "Epoch: 10\tFidelity = 0.500644\tKL_Divergence = 3.847592\n",
      "Epoch: 11\tFidelity = 0.500719\tKL_Divergence = 3.786499\n",
      "Epoch: 12\tFidelity = 0.500698\tKL_Divergence = 3.803080\n",
      "Epoch: 13\tFidelity = 0.500668\tKL_Divergence = 3.828201\n",
      "Epoch: 14\tFidelity = 0.500712\tKL_Divergence = 3.792677\n",
      "Epoch: 15\tFidelity = 0.500645\tKL_Divergence = 3.847769\n",
      "Epoch: 16\tFidelity = 0.500627\tKL_Divergence = 3.863271\n",
      "Epoch: 17\tFidelity = 0.500692\tKL_Divergence = 3.808783\n",
      "Epoch: 18\tFidelity = 0.500610\tKL_Divergence = 3.878057\n",
      "Epoch: 19\tFidelity = 0.500601\tKL_Divergence = 3.886488\n",
      "Epoch: 20\tFidelity = 0.500575\tKL_Divergence = 3.910918\n",
      "Epoch: 21\tFidelity = 0.500647\tKL_Divergence = 3.845791\n",
      "Epoch: 22\tFidelity = 0.500656\tKL_Divergence = 3.837844\n",
      "Epoch: 23\tFidelity = 0.500618\tKL_Divergence = 3.871255\n",
      "Epoch: 24\tFidelity = 0.500582\tKL_Divergence = 3.904286\n",
      "Epoch: 25\tFidelity = 0.500567\tKL_Divergence = 3.918609\n",
      "Epoch: 26\tFidelity = 0.500661\tKL_Divergence = 3.833803\n",
      "Epoch: 27\tFidelity = 0.500635\tKL_Divergence = 3.856094\n",
      "Epoch: 28\tFidelity = 0.500681\tKL_Divergence = 3.817256\n",
      "Epoch: 29\tFidelity = 0.500692\tKL_Divergence = 3.808376\n",
      "Epoch: 30\tFidelity = 0.500664\tKL_Divergence = 3.830647\n",
      "Epoch: 31\tFidelity = 0.500702\tKL_Divergence = 3.800243\n",
      "Epoch: 32\tFidelity = 0.500672\tKL_Divergence = 3.824036\n",
      "Epoch: 33\tFidelity = 0.500599\tKL_Divergence = 3.888151\n",
      "Epoch: 34\tFidelity = 0.500652\tKL_Divergence = 3.841591\n",
      "Epoch: 35\tFidelity = 0.500589\tKL_Divergence = 3.897867\n",
      "Epoch: 36\tFidelity = 0.500637\tKL_Divergence = 3.853903\n",
      "Epoch: 37\tFidelity = 0.500621\tKL_Divergence = 3.868482\n",
      "Epoch: 38\tFidelity = 0.500585\tKL_Divergence = 3.901607\n",
      "Epoch: 39\tFidelity = 0.500615\tKL_Divergence = 3.873965\n",
      "Epoch: 40\tFidelity = 0.500664\tKL_Divergence = 3.831065\n",
      "Epoch: 41\tFidelity = 0.500630\tKL_Divergence = 3.860644\n",
      "Epoch: 42\tFidelity = 0.500600\tKL_Divergence = 3.887020\n",
      "Epoch: 43\tFidelity = 0.500607\tKL_Divergence = 3.880863\n",
      "Epoch: 44\tFidelity = 0.500619\tKL_Divergence = 3.869484\n",
      "Epoch: 45\tFidelity = 0.500677\tKL_Divergence = 3.819831\n",
      "Epoch: 46\tFidelity = 0.500612\tKL_Divergence = 3.876003\n",
      "Epoch: 47\tFidelity = 0.500622\tKL_Divergence = 3.867440\n",
      "Epoch: 48\tFidelity = 0.500568\tKL_Divergence = 3.918132\n",
      "Epoch: 49\tFidelity = 0.500551\tKL_Divergence = 3.934402\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:00:27,221] Trial 566 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500561\tKL_Divergence = 3.925029\n",
      "Total time elapsed during training: 38.064 s\n",
      "Trial 566 pruned. \n",
      "Epoch: 1\tFidelity = 0.500588\tKL_Divergence = 3.898495\n",
      "Epoch: 2\tFidelity = 0.500579\tKL_Divergence = 3.907215\n",
      "Epoch: 3\tFidelity = 0.500658\tKL_Divergence = 3.836536\n",
      "Epoch: 4\tFidelity = 0.500567\tKL_Divergence = 3.919385\n",
      "Epoch: 5\tFidelity = 0.500656\tKL_Divergence = 3.838186\n",
      "Epoch: 6\tFidelity = 0.500577\tKL_Divergence = 3.909141\n",
      "Epoch: 7\tFidelity = 0.500646\tKL_Divergence = 3.846717\n",
      "Epoch: 8\tFidelity = 0.500582\tKL_Divergence = 3.904736\n",
      "Epoch: 9\tFidelity = 0.500643\tKL_Divergence = 3.849579\n",
      "Epoch: 10\tFidelity = 0.500583\tKL_Divergence = 3.903692\n",
      "Epoch: 11\tFidelity = 0.500622\tKL_Divergence = 3.867607\n",
      "Epoch: 12\tFidelity = 0.500739\tKL_Divergence = 3.772222\n",
      "Epoch: 13\tFidelity = 0.500616\tKL_Divergence = 3.873248\n",
      "Epoch: 14\tFidelity = 0.500602\tKL_Divergence = 3.885341\n",
      "Epoch: 15\tFidelity = 0.500618\tKL_Divergence = 3.871415\n",
      "Epoch: 16\tFidelity = 0.500550\tKL_Divergence = 3.935346\n",
      "Epoch: 17\tFidelity = 0.500549\tKL_Divergence = 3.936760\n",
      "Epoch: 18\tFidelity = 0.500639\tKL_Divergence = 3.852894\n",
      "Epoch: 19\tFidelity = 0.500622\tKL_Divergence = 3.867858\n",
      "Epoch: 20\tFidelity = 0.500592\tKL_Divergence = 3.895148\n",
      "Epoch: 21\tFidelity = 0.500608\tKL_Divergence = 3.880006\n",
      "Epoch: 22\tFidelity = 0.500572\tKL_Divergence = 3.914356\n",
      "Epoch: 23\tFidelity = 0.500572\tKL_Divergence = 3.913635\n",
      "Epoch: 24\tFidelity = 0.500571\tKL_Divergence = 3.915175\n",
      "Epoch: 25\tFidelity = 0.500590\tKL_Divergence = 3.897176\n",
      "Epoch: 26\tFidelity = 0.500557\tKL_Divergence = 3.928843\n",
      "Epoch: 27\tFidelity = 0.500584\tKL_Divergence = 3.902875\n",
      "Epoch: 28\tFidelity = 0.500636\tKL_Divergence = 3.855453\n",
      "Epoch: 29\tFidelity = 0.500632\tKL_Divergence = 3.858450\n",
      "Epoch: 30\tFidelity = 0.500658\tKL_Divergence = 3.836045\n",
      "Epoch: 31\tFidelity = 0.500562\tKL_Divergence = 3.923994\n",
      "Epoch: 32\tFidelity = 0.500636\tKL_Divergence = 3.855383\n",
      "Epoch: 33\tFidelity = 0.500569\tKL_Divergence = 3.917257\n",
      "Epoch: 34\tFidelity = 0.500593\tKL_Divergence = 3.894221\n",
      "Epoch: 35\tFidelity = 0.500591\tKL_Divergence = 3.895850\n",
      "Epoch: 36\tFidelity = 0.500565\tKL_Divergence = 3.920864\n",
      "Epoch: 37\tFidelity = 0.500540\tKL_Divergence = 3.945615\n",
      "Epoch: 38\tFidelity = 0.500567\tKL_Divergence = 3.918868\n",
      "Epoch: 39\tFidelity = 0.500531\tKL_Divergence = 3.954936\n",
      "Epoch: 40\tFidelity = 0.500638\tKL_Divergence = 3.853561\n",
      "Epoch: 41\tFidelity = 0.500611\tKL_Divergence = 3.877429\n",
      "Epoch: 42\tFidelity = 0.500527\tKL_Divergence = 3.959257\n",
      "Epoch: 43\tFidelity = 0.500566\tKL_Divergence = 3.919646\n",
      "Epoch: 44\tFidelity = 0.500582\tKL_Divergence = 3.904615\n",
      "Epoch: 45\tFidelity = 0.500571\tKL_Divergence = 3.915034\n",
      "Epoch: 46\tFidelity = 0.500511\tKL_Divergence = 3.976830\n",
      "Epoch: 47\tFidelity = 0.500600\tKL_Divergence = 3.887226\n",
      "Epoch: 48\tFidelity = 0.500620\tKL_Divergence = 3.869151\n",
      "Epoch: 49\tFidelity = 0.500631\tKL_Divergence = 3.859449\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:01:48,476] Trial 567 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500595\tKL_Divergence = 3.892003\n",
      "Total time elapsed during training: 81.073 s\n",
      "Trial 567 pruned. \n",
      "Epoch: 1\tFidelity = 0.500542\tKL_Divergence = 3.943546\n",
      "Epoch: 2\tFidelity = 0.500603\tKL_Divergence = 3.885121\n",
      "Epoch: 3\tFidelity = 0.500688\tKL_Divergence = 3.811549\n",
      "Epoch: 4\tFidelity = 0.500575\tKL_Divergence = 3.911490\n",
      "Epoch: 5\tFidelity = 0.500551\tKL_Divergence = 3.934950\n",
      "Epoch: 6\tFidelity = 0.500617\tKL_Divergence = 3.871732\n",
      "Epoch: 7\tFidelity = 0.500652\tKL_Divergence = 3.841416\n",
      "Epoch: 8\tFidelity = 0.500598\tKL_Divergence = 3.889885\n",
      "Epoch: 9\tFidelity = 0.500604\tKL_Divergence = 3.883577\n",
      "Epoch: 10\tFidelity = 0.500543\tKL_Divergence = 3.942725\n",
      "Epoch: 11\tFidelity = 0.500605\tKL_Divergence = 3.882718\n",
      "Epoch: 12\tFidelity = 0.500594\tKL_Divergence = 3.892936\n",
      "Epoch: 13\tFidelity = 0.500593\tKL_Divergence = 3.894269\n",
      "Epoch: 14\tFidelity = 0.500595\tKL_Divergence = 3.892361\n",
      "Epoch: 15\tFidelity = 0.500580\tKL_Divergence = 3.906138\n",
      "Epoch: 16\tFidelity = 0.500525\tKL_Divergence = 3.962067\n",
      "Epoch: 17\tFidelity = 0.500576\tKL_Divergence = 3.909859\n",
      "Epoch: 18\tFidelity = 0.500552\tKL_Divergence = 3.933616\n",
      "Epoch: 19\tFidelity = 0.500591\tKL_Divergence = 3.896234\n",
      "Epoch: 20\tFidelity = 0.500615\tKL_Divergence = 3.873551\n",
      "Epoch: 21\tFidelity = 0.500608\tKL_Divergence = 3.880379\n",
      "Epoch: 22\tFidelity = 0.500619\tKL_Divergence = 3.870025\n",
      "Epoch: 23\tFidelity = 0.500590\tKL_Divergence = 3.896851\n",
      "Epoch: 24\tFidelity = 0.500555\tKL_Divergence = 3.930528\n",
      "Epoch: 25\tFidelity = 0.500555\tKL_Divergence = 3.931183\n",
      "Epoch: 26\tFidelity = 0.500578\tKL_Divergence = 3.907968\n",
      "Epoch: 27\tFidelity = 0.500546\tKL_Divergence = 3.940172\n",
      "Epoch: 28\tFidelity = 0.500611\tKL_Divergence = 3.877496\n",
      "Epoch: 29\tFidelity = 0.500600\tKL_Divergence = 3.887319\n",
      "Epoch: 30\tFidelity = 0.500554\tKL_Divergence = 3.931850\n",
      "Epoch: 31\tFidelity = 0.500561\tKL_Divergence = 3.925147\n",
      "Epoch: 32\tFidelity = 0.500581\tKL_Divergence = 3.905111\n",
      "Epoch: 33\tFidelity = 0.500530\tKL_Divergence = 3.956127\n",
      "Epoch: 34\tFidelity = 0.500607\tKL_Divergence = 3.880858\n",
      "Epoch: 35\tFidelity = 0.500659\tKL_Divergence = 3.835322\n",
      "Epoch: 36\tFidelity = 0.500610\tKL_Divergence = 3.878710\n",
      "Epoch: 37\tFidelity = 0.500559\tKL_Divergence = 3.927307\n",
      "Epoch: 38\tFidelity = 0.500635\tKL_Divergence = 3.856108\n",
      "Epoch: 39\tFidelity = 0.500564\tKL_Divergence = 3.921795\n",
      "Epoch: 40\tFidelity = 0.500604\tKL_Divergence = 3.883826\n",
      "Epoch: 41\tFidelity = 0.500571\tKL_Divergence = 3.915242\n",
      "Epoch: 42\tFidelity = 0.500579\tKL_Divergence = 3.907119\n",
      "Epoch: 43\tFidelity = 0.500578\tKL_Divergence = 3.907881\n",
      "Epoch: 44\tFidelity = 0.500586\tKL_Divergence = 3.900555\n",
      "Epoch: 45\tFidelity = 0.500609\tKL_Divergence = 3.878952\n",
      "Epoch: 46\tFidelity = 0.500647\tKL_Divergence = 3.845876\n",
      "Epoch: 47\tFidelity = 0.500592\tKL_Divergence = 3.894811\n",
      "Epoch: 48\tFidelity = 0.500599\tKL_Divergence = 3.888428\n",
      "Epoch: 49\tFidelity = 0.500533\tKL_Divergence = 3.953043\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:02:21,068] Trial 568 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500609\tKL_Divergence = 3.879796\n",
      "Total time elapsed during training: 32.402 s\n",
      "Trial 568 pruned. \n",
      "Epoch: 1\tFidelity = 0.500522\tKL_Divergence = 3.965121\n",
      "Epoch: 2\tFidelity = 0.500572\tKL_Divergence = 3.914345\n",
      "Epoch: 3\tFidelity = 0.500635\tKL_Divergence = 3.856328\n",
      "Epoch: 4\tFidelity = 0.500561\tKL_Divergence = 3.925080\n",
      "Epoch: 5\tFidelity = 0.500655\tKL_Divergence = 3.839140\n",
      "Epoch: 6\tFidelity = 0.500598\tKL_Divergence = 3.889395\n",
      "Epoch: 7\tFidelity = 0.500621\tKL_Divergence = 3.868938\n",
      "Epoch: 8\tFidelity = 0.500633\tKL_Divergence = 3.858196\n",
      "Epoch: 9\tFidelity = 0.500656\tKL_Divergence = 3.838082\n",
      "Epoch: 10\tFidelity = 0.500526\tKL_Divergence = 3.960893\n",
      "Epoch: 11\tFidelity = 0.500606\tKL_Divergence = 3.881897\n",
      "Epoch: 12\tFidelity = 0.500623\tKL_Divergence = 3.866959\n",
      "Epoch: 13\tFidelity = 0.500679\tKL_Divergence = 3.819354\n",
      "Epoch: 14\tFidelity = 0.500647\tKL_Divergence = 3.845752\n",
      "Epoch: 15\tFidelity = 0.500643\tKL_Divergence = 3.849518\n",
      "Epoch: 16\tFidelity = 0.500504\tKL_Divergence = 3.984097\n",
      "Epoch: 17\tFidelity = 0.500566\tKL_Divergence = 3.919888\n",
      "Epoch: 18\tFidelity = 0.500522\tKL_Divergence = 3.964921\n",
      "Epoch: 19\tFidelity = 0.500610\tKL_Divergence = 3.878492\n",
      "Epoch: 20\tFidelity = 0.500560\tKL_Divergence = 3.926229\n",
      "Epoch: 21\tFidelity = 0.500671\tKL_Divergence = 3.825613\n",
      "Epoch: 22\tFidelity = 0.500536\tKL_Divergence = 3.950268\n",
      "Epoch: 23\tFidelity = 0.500716\tKL_Divergence = 3.789372\n",
      "Epoch: 24\tFidelity = 0.500519\tKL_Divergence = 3.968095\n",
      "Epoch: 25\tFidelity = 0.500552\tKL_Divergence = 3.934025\n",
      "Epoch: 26\tFidelity = 0.500524\tKL_Divergence = 3.962378\n",
      "Epoch: 27\tFidelity = 0.500570\tKL_Divergence = 3.916211\n",
      "Epoch: 28\tFidelity = 0.500614\tKL_Divergence = 3.875011\n",
      "Epoch: 29\tFidelity = 0.500608\tKL_Divergence = 3.879957\n",
      "Epoch: 30\tFidelity = 0.500544\tKL_Divergence = 3.942330\n",
      "Epoch: 31\tFidelity = 0.500634\tKL_Divergence = 3.857060\n",
      "Epoch: 32\tFidelity = 0.500505\tKL_Divergence = 3.982968\n",
      "Epoch: 33\tFidelity = 0.500626\tKL_Divergence = 3.864348\n",
      "Epoch: 34\tFidelity = 0.500690\tKL_Divergence = 3.809777\n",
      "Epoch: 35\tFidelity = 0.500543\tKL_Divergence = 3.942617\n",
      "Epoch: 36\tFidelity = 0.500594\tKL_Divergence = 3.893524\n",
      "Epoch: 37\tFidelity = 0.500587\tKL_Divergence = 3.899652\n",
      "Epoch: 38\tFidelity = 0.500621\tKL_Divergence = 3.868468\n",
      "Epoch: 39\tFidelity = 0.500645\tKL_Divergence = 3.847770\n",
      "Epoch: 40\tFidelity = 0.500509\tKL_Divergence = 3.978795\n",
      "Epoch: 41\tFidelity = 0.500510\tKL_Divergence = 3.977740\n",
      "Epoch: 42\tFidelity = 0.500558\tKL_Divergence = 3.927982\n",
      "Epoch: 43\tFidelity = 0.500484\tKL_Divergence = 4.006945\n",
      "Epoch: 44\tFidelity = 0.500547\tKL_Divergence = 3.939221\n",
      "Epoch: 45\tFidelity = 0.500572\tKL_Divergence = 3.914405\n",
      "Epoch: 46\tFidelity = 0.500579\tKL_Divergence = 3.907638\n",
      "Epoch: 47\tFidelity = 0.500522\tKL_Divergence = 3.964753\n",
      "Epoch: 48\tFidelity = 0.500611\tKL_Divergence = 3.877435\n",
      "Epoch: 49\tFidelity = 0.500585\tKL_Divergence = 3.902003\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:03:07,618] Trial 569 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500688\tKL_Divergence = 3.811645\n",
      "Total time elapsed during training: 46.361 s\n",
      "Trial 569 pruned. \n",
      "Epoch: 1\tFidelity = 0.500611\tKL_Divergence = 3.877829\n",
      "Epoch: 2\tFidelity = 0.500635\tKL_Divergence = 3.856197\n",
      "Epoch: 3\tFidelity = 0.500613\tKL_Divergence = 3.875428\n",
      "Epoch: 4\tFidelity = 0.500539\tKL_Divergence = 3.947142\n",
      "Epoch: 5\tFidelity = 0.500625\tKL_Divergence = 3.864970\n",
      "Epoch: 6\tFidelity = 0.500656\tKL_Divergence = 3.838107\n",
      "Epoch: 7\tFidelity = 0.500626\tKL_Divergence = 3.864312\n",
      "Epoch: 8\tFidelity = 0.500611\tKL_Divergence = 3.877084\n",
      "Epoch: 9\tFidelity = 0.500627\tKL_Divergence = 3.863247\n",
      "Epoch: 10\tFidelity = 0.500569\tKL_Divergence = 3.916500\n",
      "Epoch: 11\tFidelity = 0.500620\tKL_Divergence = 3.869411\n",
      "Epoch: 12\tFidelity = 0.500625\tKL_Divergence = 3.864974\n",
      "Epoch: 13\tFidelity = 0.500694\tKL_Divergence = 3.806969\n",
      "Epoch: 14\tFidelity = 0.500622\tKL_Divergence = 3.867797\n",
      "Epoch: 15\tFidelity = 0.500591\tKL_Divergence = 3.895768\n",
      "Epoch: 16\tFidelity = 0.500600\tKL_Divergence = 3.887655\n",
      "Epoch: 17\tFidelity = 0.500615\tKL_Divergence = 3.874141\n",
      "Epoch: 18\tFidelity = 0.500646\tKL_Divergence = 3.846811\n",
      "Epoch: 19\tFidelity = 0.500585\tKL_Divergence = 3.901808\n",
      "Epoch: 20\tFidelity = 0.500633\tKL_Divergence = 3.858166\n",
      "Epoch: 21\tFidelity = 0.500636\tKL_Divergence = 3.854744\n",
      "Epoch: 22\tFidelity = 0.500595\tKL_Divergence = 3.892393\n",
      "Epoch: 23\tFidelity = 0.500561\tKL_Divergence = 3.925197\n",
      "Epoch: 24\tFidelity = 0.500575\tKL_Divergence = 3.910674\n",
      "Epoch: 25\tFidelity = 0.500579\tKL_Divergence = 3.907001\n",
      "Epoch: 26\tFidelity = 0.500648\tKL_Divergence = 3.844644\n",
      "Epoch: 27\tFidelity = 0.500699\tKL_Divergence = 3.802860\n",
      "Epoch: 28\tFidelity = 0.500651\tKL_Divergence = 3.842232\n",
      "Epoch: 29\tFidelity = 0.500741\tKL_Divergence = 3.770633\n",
      "Epoch: 30\tFidelity = 0.500595\tKL_Divergence = 3.891939\n",
      "Epoch: 31\tFidelity = 0.500609\tKL_Divergence = 3.878848\n",
      "Epoch: 32\tFidelity = 0.500621\tKL_Divergence = 3.868548\n",
      "Epoch: 33\tFidelity = 0.500606\tKL_Divergence = 3.881546\n",
      "Epoch: 34\tFidelity = 0.500618\tKL_Divergence = 3.871390\n",
      "Epoch: 35\tFidelity = 0.500616\tKL_Divergence = 3.872592\n",
      "Epoch: 36\tFidelity = 0.500541\tKL_Divergence = 3.944906\n",
      "Epoch: 37\tFidelity = 0.500618\tKL_Divergence = 3.870854\n",
      "Epoch: 38\tFidelity = 0.500601\tKL_Divergence = 3.886239\n",
      "Epoch: 39\tFidelity = 0.500543\tKL_Divergence = 3.942582\n",
      "Epoch: 40\tFidelity = 0.500603\tKL_Divergence = 3.885097\n",
      "Epoch: 41\tFidelity = 0.500591\tKL_Divergence = 3.895535\n",
      "Epoch: 42\tFidelity = 0.500613\tKL_Divergence = 3.875718\n",
      "Epoch: 43\tFidelity = 0.500613\tKL_Divergence = 3.875602\n",
      "Epoch: 44\tFidelity = 0.500542\tKL_Divergence = 3.943869\n",
      "Epoch: 45\tFidelity = 0.500555\tKL_Divergence = 3.930406\n",
      "Epoch: 46\tFidelity = 0.500638\tKL_Divergence = 3.853733\n",
      "Epoch: 47\tFidelity = 0.500596\tKL_Divergence = 3.891242\n",
      "Epoch: 48\tFidelity = 0.500649\tKL_Divergence = 3.844015\n",
      "Epoch: 49\tFidelity = 0.500687\tKL_Divergence = 3.812714\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:03:46,319] Trial 570 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500608\tKL_Divergence = 3.880573\n",
      "Total time elapsed during training: 38.524 s\n",
      "Trial 570 pruned. \n",
      "Epoch: 1\tFidelity = 0.500682\tKL_Divergence = 3.816090\n",
      "Epoch: 2\tFidelity = 0.500583\tKL_Divergence = 3.903848\n",
      "Epoch: 3\tFidelity = 0.500659\tKL_Divergence = 3.835838\n",
      "Epoch: 4\tFidelity = 0.500585\tKL_Divergence = 3.901196\n",
      "Epoch: 5\tFidelity = 0.500606\tKL_Divergence = 3.882346\n",
      "Epoch: 6\tFidelity = 0.500690\tKL_Divergence = 3.809643\n",
      "Epoch: 7\tFidelity = 0.500585\tKL_Divergence = 3.901995\n",
      "Epoch: 8\tFidelity = 0.500598\tKL_Divergence = 3.889630\n",
      "Epoch: 9\tFidelity = 0.500631\tKL_Divergence = 3.859437\n",
      "Epoch: 10\tFidelity = 0.500574\tKL_Divergence = 3.912300\n",
      "Epoch: 11\tFidelity = 0.500592\tKL_Divergence = 3.894956\n",
      "Epoch: 12\tFidelity = 0.500596\tKL_Divergence = 3.891343\n",
      "Epoch: 13\tFidelity = 0.500636\tKL_Divergence = 3.854778\n",
      "Epoch: 14\tFidelity = 0.500599\tKL_Divergence = 3.888562\n",
      "Epoch: 15\tFidelity = 0.500676\tKL_Divergence = 3.821680\n",
      "Epoch: 16\tFidelity = 0.500566\tKL_Divergence = 3.919927\n",
      "Epoch: 17\tFidelity = 0.500584\tKL_Divergence = 3.902208\n",
      "Epoch: 18\tFidelity = 0.500642\tKL_Divergence = 3.849762\n",
      "Epoch: 19\tFidelity = 0.500581\tKL_Divergence = 3.905156\n",
      "Epoch: 20\tFidelity = 0.500687\tKL_Divergence = 3.812409\n",
      "Epoch: 21\tFidelity = 0.500568\tKL_Divergence = 3.918364\n",
      "Epoch: 22\tFidelity = 0.500619\tKL_Divergence = 3.870368\n",
      "Epoch: 23\tFidelity = 0.500582\tKL_Divergence = 3.904620\n",
      "Epoch: 24\tFidelity = 0.500665\tKL_Divergence = 3.830655\n",
      "Epoch: 25\tFidelity = 0.500641\tKL_Divergence = 3.850470\n",
      "Epoch: 26\tFidelity = 0.500553\tKL_Divergence = 3.932980\n",
      "Epoch: 27\tFidelity = 0.500653\tKL_Divergence = 3.840259\n",
      "Epoch: 28\tFidelity = 0.500590\tKL_Divergence = 3.896597\n",
      "Epoch: 29\tFidelity = 0.500635\tKL_Divergence = 3.856003\n",
      "Epoch: 30\tFidelity = 0.500574\tKL_Divergence = 3.911951\n",
      "Epoch: 31\tFidelity = 0.500608\tKL_Divergence = 3.880284\n",
      "Epoch: 32\tFidelity = 0.500686\tKL_Divergence = 3.813202\n",
      "Epoch: 33\tFidelity = 0.500618\tKL_Divergence = 3.871552\n",
      "Epoch: 34\tFidelity = 0.500610\tKL_Divergence = 3.878707\n",
      "Epoch: 35\tFidelity = 0.500554\tKL_Divergence = 3.931705\n",
      "Epoch: 36\tFidelity = 0.500605\tKL_Divergence = 3.882981\n",
      "Epoch: 37\tFidelity = 0.500562\tKL_Divergence = 3.923910\n",
      "Epoch: 38\tFidelity = 0.500616\tKL_Divergence = 3.872670\n",
      "Epoch: 39\tFidelity = 0.500636\tKL_Divergence = 3.855070\n",
      "Epoch: 40\tFidelity = 0.500587\tKL_Divergence = 3.899665\n",
      "Epoch: 41\tFidelity = 0.500617\tKL_Divergence = 3.871637\n",
      "Epoch: 42\tFidelity = 0.500589\tKL_Divergence = 3.897387\n",
      "Epoch: 43\tFidelity = 0.500592\tKL_Divergence = 3.895131\n",
      "Epoch: 44\tFidelity = 0.500626\tKL_Divergence = 3.863877\n",
      "Epoch: 45\tFidelity = 0.500582\tKL_Divergence = 3.904357\n",
      "Epoch: 46\tFidelity = 0.500613\tKL_Divergence = 3.875824\n",
      "Epoch: 47\tFidelity = 0.500582\tKL_Divergence = 3.904649\n",
      "Epoch: 48\tFidelity = 0.500608\tKL_Divergence = 3.879892\n",
      "Epoch: 49\tFidelity = 0.500622\tKL_Divergence = 3.867268\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:04:17,701] Trial 571 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500540\tKL_Divergence = 3.945919\n",
      "Total time elapsed during training: 31.201 s\n",
      "Trial 571 pruned. \n",
      "Epoch: 1\tFidelity = 0.500578\tKL_Divergence = 3.908810\n",
      "Epoch: 2\tFidelity = 0.500623\tKL_Divergence = 3.867003\n",
      "Epoch: 3\tFidelity = 0.500575\tKL_Divergence = 3.911708\n",
      "Epoch: 4\tFidelity = 0.500536\tKL_Divergence = 3.949737\n",
      "Epoch: 5\tFidelity = 0.500658\tKL_Divergence = 3.836263\n",
      "Epoch: 6\tFidelity = 0.500565\tKL_Divergence = 3.921129\n",
      "Epoch: 7\tFidelity = 0.500526\tKL_Divergence = 3.960472\n",
      "Epoch: 8\tFidelity = 0.500632\tKL_Divergence = 3.858422\n",
      "Epoch: 9\tFidelity = 0.500490\tKL_Divergence = 3.999590\n",
      "Epoch: 10\tFidelity = 0.500617\tKL_Divergence = 3.872489\n",
      "Epoch: 11\tFidelity = 0.500685\tKL_Divergence = 3.814316\n",
      "Epoch: 12\tFidelity = 0.500721\tKL_Divergence = 3.785687\n",
      "Epoch: 13\tFidelity = 0.500572\tKL_Divergence = 3.913758\n",
      "Epoch: 14\tFidelity = 0.500620\tKL_Divergence = 3.869014\n",
      "Epoch: 15\tFidelity = 0.500663\tKL_Divergence = 3.831807\n",
      "Epoch: 16\tFidelity = 0.500745\tKL_Divergence = 3.767719\n",
      "Epoch: 17\tFidelity = 0.500669\tKL_Divergence = 3.827103\n",
      "Epoch: 18\tFidelity = 0.500685\tKL_Divergence = 3.813967\n",
      "Epoch: 19\tFidelity = 0.500607\tKL_Divergence = 3.881075\n",
      "Epoch: 20\tFidelity = 0.500658\tKL_Divergence = 3.836333\n",
      "Epoch: 21\tFidelity = 0.500659\tKL_Divergence = 3.835639\n",
      "Epoch: 22\tFidelity = 0.500602\tKL_Divergence = 3.886094\n",
      "Epoch: 23\tFidelity = 0.500623\tKL_Divergence = 3.866949\n",
      "Epoch: 24\tFidelity = 0.500624\tKL_Divergence = 3.865444\n",
      "Epoch: 25\tFidelity = 0.500644\tKL_Divergence = 3.848027\n",
      "Epoch: 26\tFidelity = 0.500626\tKL_Divergence = 3.864357\n",
      "Epoch: 27\tFidelity = 0.500642\tKL_Divergence = 3.849727\n",
      "Epoch: 28\tFidelity = 0.500680\tKL_Divergence = 3.817828\n",
      "Epoch: 29\tFidelity = 0.500663\tKL_Divergence = 3.831865\n",
      "Epoch: 30\tFidelity = 0.500659\tKL_Divergence = 3.835893\n",
      "Epoch: 31\tFidelity = 0.500672\tKL_Divergence = 3.824749\n",
      "Epoch: 32\tFidelity = 0.500683\tKL_Divergence = 3.815804\n",
      "Epoch: 33\tFidelity = 0.500594\tKL_Divergence = 3.893302\n",
      "Epoch: 34\tFidelity = 0.500664\tKL_Divergence = 3.831471\n",
      "Epoch: 35\tFidelity = 0.500598\tKL_Divergence = 3.889941\n",
      "Epoch: 36\tFidelity = 0.500679\tKL_Divergence = 3.819408\n",
      "Epoch: 37\tFidelity = 0.500619\tKL_Divergence = 3.870436\n",
      "Epoch: 38\tFidelity = 0.500551\tKL_Divergence = 3.935074\n",
      "Epoch: 39\tFidelity = 0.500643\tKL_Divergence = 3.848997\n",
      "Epoch: 40\tFidelity = 0.500572\tKL_Divergence = 3.914374\n",
      "Epoch: 41\tFidelity = 0.500539\tKL_Divergence = 3.947226\n",
      "Epoch: 42\tFidelity = 0.500544\tKL_Divergence = 3.942034\n",
      "Epoch: 43\tFidelity = 0.500604\tKL_Divergence = 3.884232\n",
      "Epoch: 44\tFidelity = 0.500593\tKL_Divergence = 3.894284\n",
      "Epoch: 45\tFidelity = 0.500708\tKL_Divergence = 3.796065\n",
      "Epoch: 46\tFidelity = 0.500595\tKL_Divergence = 3.891889\n",
      "Epoch: 47\tFidelity = 0.500581\tKL_Divergence = 3.905162\n",
      "Epoch: 48\tFidelity = 0.500638\tKL_Divergence = 3.853866\n",
      "Epoch: 49\tFidelity = 0.500554\tKL_Divergence = 3.932322\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:05:37,155] Trial 572 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500616\tKL_Divergence = 3.873238\n",
      "Total time elapsed during training: 79.277 s\n",
      "Trial 572 pruned. \n",
      "Epoch: 1\tFidelity = 0.500579\tKL_Divergence = 3.907201\n",
      "Epoch: 2\tFidelity = 0.500689\tKL_Divergence = 3.810633\n",
      "Epoch: 3\tFidelity = 0.500634\tKL_Divergence = 3.856768\n",
      "Epoch: 4\tFidelity = 0.500626\tKL_Divergence = 3.864253\n",
      "Epoch: 5\tFidelity = 0.500551\tKL_Divergence = 3.934577\n",
      "Epoch: 6\tFidelity = 0.500558\tKL_Divergence = 3.927652\n",
      "Epoch: 7\tFidelity = 0.500504\tKL_Divergence = 3.984064\n",
      "Epoch: 8\tFidelity = 0.500520\tKL_Divergence = 3.967250\n",
      "Epoch: 9\tFidelity = 0.500556\tKL_Divergence = 3.929561\n",
      "Epoch: 10\tFidelity = 0.500662\tKL_Divergence = 3.833394\n",
      "Epoch: 11\tFidelity = 0.500481\tKL_Divergence = 4.010364\n",
      "Epoch: 12\tFidelity = 0.500676\tKL_Divergence = 3.821083\n",
      "Epoch: 13\tFidelity = 0.500606\tKL_Divergence = 3.881956\n",
      "Epoch: 14\tFidelity = 0.500639\tKL_Divergence = 3.852488\n",
      "Epoch: 15\tFidelity = 0.500597\tKL_Divergence = 3.890161\n",
      "Epoch: 16\tFidelity = 0.500726\tKL_Divergence = 3.781890\n",
      "Epoch: 17\tFidelity = 0.500650\tKL_Divergence = 3.843354\n",
      "Epoch: 18\tFidelity = 0.500670\tKL_Divergence = 3.826151\n",
      "Epoch: 19\tFidelity = 0.500683\tKL_Divergence = 3.815355\n",
      "Epoch: 20\tFidelity = 0.500702\tKL_Divergence = 3.800146\n",
      "Epoch: 21\tFidelity = 0.500665\tKL_Divergence = 3.830477\n",
      "Epoch: 22\tFidelity = 0.500538\tKL_Divergence = 3.948437\n",
      "Epoch: 23\tFidelity = 0.500558\tKL_Divergence = 3.927608\n",
      "Epoch: 24\tFidelity = 0.500627\tKL_Divergence = 3.862898\n",
      "Epoch: 25\tFidelity = 0.500813\tKL_Divergence = 3.718613\n",
      "Epoch: 26\tFidelity = 0.500801\tKL_Divergence = 3.727174\n",
      "Epoch: 27\tFidelity = 0.500646\tKL_Divergence = 3.846442\n",
      "Epoch: 28\tFidelity = 0.500682\tKL_Divergence = 3.815970\n",
      "Epoch: 29\tFidelity = 0.500538\tKL_Divergence = 3.947167\n",
      "Epoch: 30\tFidelity = 0.500634\tKL_Divergence = 3.856249\n",
      "Epoch: 31\tFidelity = 0.500579\tKL_Divergence = 3.906873\n",
      "Epoch: 32\tFidelity = 0.500634\tKL_Divergence = 3.856656\n",
      "Epoch: 33\tFidelity = 0.500812\tKL_Divergence = 3.718934\n",
      "Epoch: 34\tFidelity = 0.500758\tKL_Divergence = 3.757822\n",
      "Epoch: 35\tFidelity = 0.500669\tKL_Divergence = 3.826525\n",
      "Epoch: 36\tFidelity = 0.500678\tKL_Divergence = 3.819367\n",
      "Epoch: 37\tFidelity = 0.500550\tKL_Divergence = 3.935203\n",
      "Epoch: 38\tFidelity = 0.500629\tKL_Divergence = 3.860694\n",
      "Epoch: 39\tFidelity = 0.500571\tKL_Divergence = 3.914758\n",
      "Epoch: 40\tFidelity = 0.500649\tKL_Divergence = 3.843960\n",
      "Epoch: 41\tFidelity = 0.500616\tKL_Divergence = 3.872981\n",
      "Epoch: 42\tFidelity = 0.500735\tKL_Divergence = 3.774327\n",
      "Epoch: 43\tFidelity = 0.500683\tKL_Divergence = 3.814882\n",
      "Epoch: 44\tFidelity = 0.500561\tKL_Divergence = 3.924202\n",
      "Epoch: 45\tFidelity = 0.500651\tKL_Divergence = 3.841880\n",
      "Epoch: 46\tFidelity = 0.500630\tKL_Divergence = 3.859894\n",
      "Epoch: 47\tFidelity = 0.500547\tKL_Divergence = 3.938941\n",
      "Epoch: 48\tFidelity = 0.500701\tKL_Divergence = 3.800763\n",
      "Epoch: 49\tFidelity = 0.500631\tKL_Divergence = 3.859704\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:06:15,330] Trial 573 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500592\tKL_Divergence = 3.894994\n",
      "Total time elapsed during training: 37.997 s\n",
      "Trial 573 pruned. \n",
      "Epoch: 1\tFidelity = 0.500661\tKL_Divergence = 3.833798\n",
      "Epoch: 2\tFidelity = 0.500651\tKL_Divergence = 3.842076\n",
      "Epoch: 3\tFidelity = 0.500695\tKL_Divergence = 3.805582\n",
      "Epoch: 4\tFidelity = 0.500615\tKL_Divergence = 3.873383\n",
      "Epoch: 5\tFidelity = 0.500605\tKL_Divergence = 3.883228\n",
      "Epoch: 6\tFidelity = 0.500621\tKL_Divergence = 3.868341\n",
      "Epoch: 7\tFidelity = 0.500580\tKL_Divergence = 3.906088\n",
      "Epoch: 8\tFidelity = 0.500612\tKL_Divergence = 3.876528\n",
      "Epoch: 9\tFidelity = 0.500612\tKL_Divergence = 3.876432\n",
      "Epoch: 10\tFidelity = 0.500590\tKL_Divergence = 3.896666\n",
      "Epoch: 11\tFidelity = 0.500647\tKL_Divergence = 3.846067\n",
      "Epoch: 12\tFidelity = 0.500570\tKL_Divergence = 3.915593\n",
      "Epoch: 13\tFidelity = 0.500605\tKL_Divergence = 3.883280\n",
      "Epoch: 14\tFidelity = 0.500582\tKL_Divergence = 3.904448\n",
      "Epoch: 15\tFidelity = 0.500572\tKL_Divergence = 3.913553\n",
      "Epoch: 16\tFidelity = 0.500608\tKL_Divergence = 3.880141\n",
      "Epoch: 17\tFidelity = 0.500571\tKL_Divergence = 3.914937\n",
      "Epoch: 18\tFidelity = 0.500653\tKL_Divergence = 3.840848\n",
      "Epoch: 19\tFidelity = 0.500667\tKL_Divergence = 3.828762\n",
      "Epoch: 20\tFidelity = 0.500703\tKL_Divergence = 3.799934\n",
      "Epoch: 21\tFidelity = 0.500567\tKL_Divergence = 3.919309\n",
      "Epoch: 22\tFidelity = 0.500619\tKL_Divergence = 3.869936\n",
      "Epoch: 23\tFidelity = 0.500600\tKL_Divergence = 3.887440\n",
      "Epoch: 24\tFidelity = 0.500560\tKL_Divergence = 3.926194\n",
      "Epoch: 25\tFidelity = 0.500629\tKL_Divergence = 3.860883\n",
      "Epoch: 26\tFidelity = 0.500576\tKL_Divergence = 3.910421\n",
      "Epoch: 27\tFidelity = 0.500643\tKL_Divergence = 3.849396\n",
      "Epoch: 28\tFidelity = 0.500678\tKL_Divergence = 3.820032\n",
      "Epoch: 29\tFidelity = 0.500678\tKL_Divergence = 3.819348\n",
      "Epoch: 30\tFidelity = 0.500612\tKL_Divergence = 3.876256\n",
      "Epoch: 31\tFidelity = 0.500629\tKL_Divergence = 3.861464\n",
      "Epoch: 32\tFidelity = 0.500693\tKL_Divergence = 3.807757\n",
      "Epoch: 33\tFidelity = 0.500618\tKL_Divergence = 3.870954\n",
      "Epoch: 34\tFidelity = 0.500666\tKL_Divergence = 3.829299\n",
      "Epoch: 35\tFidelity = 0.500653\tKL_Divergence = 3.840553\n",
      "Epoch: 36\tFidelity = 0.500647\tKL_Divergence = 3.845640\n",
      "Epoch: 37\tFidelity = 0.500642\tKL_Divergence = 3.850134\n",
      "Epoch: 38\tFidelity = 0.500629\tKL_Divergence = 3.861701\n",
      "Epoch: 39\tFidelity = 0.500568\tKL_Divergence = 3.918126\n",
      "Epoch: 40\tFidelity = 0.500566\tKL_Divergence = 3.920233\n",
      "Epoch: 41\tFidelity = 0.500618\tKL_Divergence = 3.871468\n",
      "Epoch: 42\tFidelity = 0.500642\tKL_Divergence = 3.850137\n",
      "Epoch: 43\tFidelity = 0.500627\tKL_Divergence = 3.863267\n",
      "Epoch: 44\tFidelity = 0.500674\tKL_Divergence = 3.823259\n",
      "Epoch: 45\tFidelity = 0.500632\tKL_Divergence = 3.858506\n",
      "Epoch: 46\tFidelity = 0.500593\tKL_Divergence = 3.893943\n",
      "Epoch: 47\tFidelity = 0.500580\tKL_Divergence = 3.905883\n",
      "Epoch: 48\tFidelity = 0.500635\tKL_Divergence = 3.856252\n",
      "Epoch: 49\tFidelity = 0.500621\tKL_Divergence = 3.868493\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:06:52,759] Trial 574 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500660\tKL_Divergence = 3.834296\n",
      "Total time elapsed during training: 37.242 s\n",
      "Trial 574 pruned. \n",
      "Epoch: 1\tFidelity = 0.500667\tKL_Divergence = 3.829063\n",
      "Epoch: 2\tFidelity = 0.500629\tKL_Divergence = 3.860878\n",
      "Epoch: 3\tFidelity = 0.500576\tKL_Divergence = 3.909827\n",
      "Epoch: 4\tFidelity = 0.500688\tKL_Divergence = 3.811825\n",
      "Epoch: 5\tFidelity = 0.500553\tKL_Divergence = 3.932877\n",
      "Epoch: 6\tFidelity = 0.500547\tKL_Divergence = 3.939333\n",
      "Epoch: 7\tFidelity = 0.500784\tKL_Divergence = 3.739215\n",
      "Epoch: 8\tFidelity = 0.500647\tKL_Divergence = 3.845890\n",
      "Epoch: 9\tFidelity = 0.500548\tKL_Divergence = 3.937616\n",
      "Epoch: 10\tFidelity = 0.500716\tKL_Divergence = 3.789224\n",
      "Epoch: 11\tFidelity = 0.500725\tKL_Divergence = 3.782862\n",
      "Epoch: 12\tFidelity = 0.500560\tKL_Divergence = 3.925792\n",
      "Epoch: 13\tFidelity = 0.500664\tKL_Divergence = 3.831121\n",
      "Epoch: 14\tFidelity = 0.500515\tKL_Divergence = 3.972121\n",
      "Epoch: 15\tFidelity = 0.500505\tKL_Divergence = 3.983182\n",
      "Epoch: 16\tFidelity = 0.500525\tKL_Divergence = 3.961169\n",
      "Epoch: 17\tFidelity = 0.500593\tKL_Divergence = 3.893746\n",
      "Epoch: 18\tFidelity = 0.500587\tKL_Divergence = 3.900063\n",
      "Epoch: 19\tFidelity = 0.500610\tKL_Divergence = 3.878537\n",
      "Epoch: 20\tFidelity = 0.500769\tKL_Divergence = 3.750280\n",
      "Epoch: 21\tFidelity = 0.500622\tKL_Divergence = 3.867573\n",
      "Epoch: 22\tFidelity = 0.500612\tKL_Divergence = 3.876992\n",
      "Epoch: 23\tFidelity = 0.500651\tKL_Divergence = 3.842012\n",
      "Epoch: 24\tFidelity = 0.500639\tKL_Divergence = 3.852683\n",
      "Epoch: 25\tFidelity = 0.500540\tKL_Divergence = 3.945766\n",
      "Epoch: 26\tFidelity = 0.500594\tKL_Divergence = 3.893109\n",
      "Epoch: 27\tFidelity = 0.500570\tKL_Divergence = 3.916407\n",
      "Epoch: 28\tFidelity = 0.500571\tKL_Divergence = 3.914881\n",
      "Epoch: 29\tFidelity = 0.500614\tKL_Divergence = 3.874988\n",
      "Epoch: 30\tFidelity = 0.500541\tKL_Divergence = 3.944285\n",
      "Epoch: 31\tFidelity = 0.500515\tKL_Divergence = 3.971499\n",
      "Epoch: 32\tFidelity = 0.500605\tKL_Divergence = 3.883110\n",
      "Epoch: 33\tFidelity = 0.500581\tKL_Divergence = 3.905121\n",
      "Epoch: 34\tFidelity = 0.500565\tKL_Divergence = 3.920468\n",
      "Epoch: 35\tFidelity = 0.500596\tKL_Divergence = 3.891085\n",
      "Epoch: 36\tFidelity = 0.500617\tKL_Divergence = 3.871944\n",
      "Epoch: 37\tFidelity = 0.500630\tKL_Divergence = 3.860319\n",
      "Epoch: 38\tFidelity = 0.500624\tKL_Divergence = 3.865493\n",
      "Epoch: 39\tFidelity = 0.500478\tKL_Divergence = 4.013318\n",
      "Epoch: 40\tFidelity = 0.500582\tKL_Divergence = 3.904332\n",
      "Epoch: 41\tFidelity = 0.500638\tKL_Divergence = 3.853967\n",
      "Epoch: 42\tFidelity = 0.500594\tKL_Divergence = 3.893493\n",
      "Epoch: 43\tFidelity = 0.500579\tKL_Divergence = 3.907001\n",
      "Epoch: 44\tFidelity = 0.500501\tKL_Divergence = 3.987486\n",
      "Epoch: 45\tFidelity = 0.500580\tKL_Divergence = 3.906758\n",
      "Epoch: 46\tFidelity = 0.500578\tKL_Divergence = 3.908324\n",
      "Epoch: 47\tFidelity = 0.500649\tKL_Divergence = 3.844483\n",
      "Epoch: 48\tFidelity = 0.500582\tKL_Divergence = 3.904413\n",
      "Epoch: 49\tFidelity = 0.500578\tKL_Divergence = 3.908624\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:07:49,980] Trial 575 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500503\tKL_Divergence = 3.985112\n",
      "Total time elapsed during training: 57.039 s\n",
      "Trial 575 pruned. \n",
      "Epoch: 1\tFidelity = 0.500621\tKL_Divergence = 3.868381\n",
      "Epoch: 2\tFidelity = 0.500590\tKL_Divergence = 3.896938\n",
      "Epoch: 3\tFidelity = 0.500586\tKL_Divergence = 3.900236\n",
      "Epoch: 4\tFidelity = 0.500591\tKL_Divergence = 3.896115\n",
      "Epoch: 5\tFidelity = 0.500606\tKL_Divergence = 3.882147\n",
      "Epoch: 6\tFidelity = 0.500574\tKL_Divergence = 3.911811\n",
      "Epoch: 7\tFidelity = 0.500559\tKL_Divergence = 3.926547\n",
      "Epoch: 8\tFidelity = 0.500528\tKL_Divergence = 3.958497\n",
      "Epoch: 9\tFidelity = 0.500571\tKL_Divergence = 3.914826\n",
      "Epoch: 10\tFidelity = 0.500647\tKL_Divergence = 3.845802\n",
      "Epoch: 11\tFidelity = 0.500613\tKL_Divergence = 3.875816\n",
      "Epoch: 12\tFidelity = 0.500526\tKL_Divergence = 3.961127\n",
      "Epoch: 13\tFidelity = 0.500623\tKL_Divergence = 3.866549\n",
      "Epoch: 14\tFidelity = 0.500521\tKL_Divergence = 3.965912\n",
      "Epoch: 15\tFidelity = 0.500596\tKL_Divergence = 3.890890\n",
      "Epoch: 16\tFidelity = 0.500583\tKL_Divergence = 3.903869\n",
      "Epoch: 17\tFidelity = 0.500615\tKL_Divergence = 3.873934\n",
      "Epoch: 18\tFidelity = 0.500637\tKL_Divergence = 3.854408\n",
      "Epoch: 19\tFidelity = 0.500646\tKL_Divergence = 3.846728\n",
      "Epoch: 20\tFidelity = 0.500609\tKL_Divergence = 3.879809\n",
      "Epoch: 21\tFidelity = 0.500580\tKL_Divergence = 3.906397\n",
      "Epoch: 22\tFidelity = 0.500535\tKL_Divergence = 3.951099\n",
      "Epoch: 23\tFidelity = 0.500567\tKL_Divergence = 3.919374\n",
      "Epoch: 24\tFidelity = 0.500549\tKL_Divergence = 3.937252\n",
      "Epoch: 25\tFidelity = 0.500663\tKL_Divergence = 3.832552\n",
      "Epoch: 26\tFidelity = 0.500679\tKL_Divergence = 3.819168\n",
      "Epoch: 27\tFidelity = 0.500621\tKL_Divergence = 3.868846\n",
      "Epoch: 28\tFidelity = 0.500584\tKL_Divergence = 3.902171\n",
      "Epoch: 29\tFidelity = 0.500570\tKL_Divergence = 3.916285\n",
      "Epoch: 30\tFidelity = 0.500637\tKL_Divergence = 3.854124\n",
      "Epoch: 31\tFidelity = 0.500630\tKL_Divergence = 3.860475\n",
      "Epoch: 32\tFidelity = 0.500618\tKL_Divergence = 3.871226\n",
      "Epoch: 33\tFidelity = 0.500570\tKL_Divergence = 3.916257\n",
      "Epoch: 34\tFidelity = 0.500585\tKL_Divergence = 3.901617\n",
      "Epoch: 35\tFidelity = 0.500604\tKL_Divergence = 3.883587\n",
      "Epoch: 36\tFidelity = 0.500604\tKL_Divergence = 3.884315\n",
      "Epoch: 37\tFidelity = 0.500593\tKL_Divergence = 3.894416\n",
      "Epoch: 38\tFidelity = 0.500598\tKL_Divergence = 3.889894\n",
      "Epoch: 39\tFidelity = 0.500552\tKL_Divergence = 3.934107\n",
      "Epoch: 40\tFidelity = 0.500594\tKL_Divergence = 3.893430\n",
      "Epoch: 41\tFidelity = 0.500552\tKL_Divergence = 3.934290\n",
      "Epoch: 42\tFidelity = 0.500548\tKL_Divergence = 3.938222\n",
      "Epoch: 43\tFidelity = 0.500554\tKL_Divergence = 3.931695\n",
      "Epoch: 44\tFidelity = 0.500564\tKL_Divergence = 3.921919\n",
      "Epoch: 45\tFidelity = 0.500682\tKL_Divergence = 3.816249\n",
      "Epoch: 46\tFidelity = 0.500641\tKL_Divergence = 3.851189\n",
      "Epoch: 47\tFidelity = 0.500587\tKL_Divergence = 3.899955\n",
      "Epoch: 48\tFidelity = 0.500580\tKL_Divergence = 3.906077\n",
      "Epoch: 49\tFidelity = 0.500623\tKL_Divergence = 3.867029\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:08:27,867] Trial 576 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500645\tKL_Divergence = 3.847270\n",
      "Total time elapsed during training: 37.708 s\n",
      "Trial 576 pruned. \n",
      "Epoch: 1\tFidelity = 0.500563\tKL_Divergence = 3.922655\n",
      "Epoch: 2\tFidelity = 0.500653\tKL_Divergence = 3.841135\n",
      "Epoch: 3\tFidelity = 0.500578\tKL_Divergence = 3.908457\n",
      "Epoch: 4\tFidelity = 0.500614\tKL_Divergence = 3.875243\n",
      "Epoch: 5\tFidelity = 0.500727\tKL_Divergence = 3.781445\n",
      "Epoch: 6\tFidelity = 0.500692\tKL_Divergence = 3.808854\n",
      "Epoch: 7\tFidelity = 0.500558\tKL_Divergence = 3.927685\n",
      "Epoch: 8\tFidelity = 0.500524\tKL_Divergence = 3.963195\n",
      "Epoch: 9\tFidelity = 0.500592\tKL_Divergence = 3.895376\n",
      "Epoch: 10\tFidelity = 0.500565\tKL_Divergence = 3.920843\n",
      "Epoch: 11\tFidelity = 0.500522\tKL_Divergence = 3.965025\n",
      "Epoch: 12\tFidelity = 0.500667\tKL_Divergence = 3.829226\n",
      "Epoch: 13\tFidelity = 0.500628\tKL_Divergence = 3.862762\n",
      "Epoch: 14\tFidelity = 0.500663\tKL_Divergence = 3.832292\n",
      "Epoch: 15\tFidelity = 0.500602\tKL_Divergence = 3.885451\n",
      "Epoch: 16\tFidelity = 0.500569\tKL_Divergence = 3.916883\n",
      "Epoch: 17\tFidelity = 0.500683\tKL_Divergence = 3.815933\n",
      "Epoch: 18\tFidelity = 0.500601\tKL_Divergence = 3.886928\n",
      "Epoch: 19\tFidelity = 0.500616\tKL_Divergence = 3.873091\n",
      "Epoch: 20\tFidelity = 0.500599\tKL_Divergence = 3.888298\n",
      "Epoch: 21\tFidelity = 0.500534\tKL_Divergence = 3.952607\n",
      "Epoch: 22\tFidelity = 0.500632\tKL_Divergence = 3.859095\n",
      "Epoch: 23\tFidelity = 0.500608\tKL_Divergence = 3.880354\n",
      "Epoch: 24\tFidelity = 0.500664\tKL_Divergence = 3.831239\n",
      "Epoch: 25\tFidelity = 0.500640\tKL_Divergence = 3.852182\n",
      "Epoch: 26\tFidelity = 0.500626\tKL_Divergence = 3.864253\n",
      "Epoch: 27\tFidelity = 0.500631\tKL_Divergence = 3.860062\n",
      "Epoch: 28\tFidelity = 0.500626\tKL_Divergence = 3.864326\n",
      "Epoch: 29\tFidelity = 0.500646\tKL_Divergence = 3.846785\n",
      "Epoch: 30\tFidelity = 0.500558\tKL_Divergence = 3.928184\n",
      "Epoch: 31\tFidelity = 0.500545\tKL_Divergence = 3.941442\n",
      "Epoch: 32\tFidelity = 0.500554\tKL_Divergence = 3.932392\n",
      "Epoch: 33\tFidelity = 0.500553\tKL_Divergence = 3.933130\n",
      "Epoch: 34\tFidelity = 0.500585\tKL_Divergence = 3.901387\n",
      "Epoch: 35\tFidelity = 0.500565\tKL_Divergence = 3.921269\n",
      "Epoch: 36\tFidelity = 0.500570\tKL_Divergence = 3.916638\n",
      "Epoch: 37\tFidelity = 0.500566\tKL_Divergence = 3.919667\n",
      "Epoch: 38\tFidelity = 0.500656\tKL_Divergence = 3.838262\n",
      "Epoch: 39\tFidelity = 0.500654\tKL_Divergence = 3.840075\n",
      "Epoch: 40\tFidelity = 0.500541\tKL_Divergence = 3.944858\n",
      "Epoch: 41\tFidelity = 0.500511\tKL_Divergence = 3.976398\n",
      "Epoch: 42\tFidelity = 0.500572\tKL_Divergence = 3.914388\n",
      "Epoch: 43\tFidelity = 0.500579\tKL_Divergence = 3.907507\n",
      "Epoch: 44\tFidelity = 0.500589\tKL_Divergence = 3.897820\n",
      "Epoch: 45\tFidelity = 0.500589\tKL_Divergence = 3.897489\n",
      "Epoch: 46\tFidelity = 0.500575\tKL_Divergence = 3.911171\n",
      "Epoch: 47\tFidelity = 0.500636\tKL_Divergence = 3.855409\n",
      "Epoch: 48\tFidelity = 0.500518\tKL_Divergence = 3.969516\n",
      "Epoch: 49\tFidelity = 0.500615\tKL_Divergence = 3.873569\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:09:46,369] Trial 577 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500641\tKL_Divergence = 3.851202\n",
      "Total time elapsed during training: 78.319 s\n",
      "Trial 577 pruned. \n",
      "Epoch: 1\tFidelity = 0.500599\tKL_Divergence = 3.889034\n",
      "Epoch: 2\tFidelity = 0.500657\tKL_Divergence = 3.837403\n",
      "Epoch: 3\tFidelity = 0.500655\tKL_Divergence = 3.838906\n",
      "Epoch: 4\tFidelity = 0.500604\tKL_Divergence = 3.883612\n",
      "Epoch: 5\tFidelity = 0.500553\tKL_Divergence = 3.932614\n",
      "Epoch: 6\tFidelity = 0.500605\tKL_Divergence = 3.882869\n",
      "Epoch: 7\tFidelity = 0.500685\tKL_Divergence = 3.814067\n",
      "Epoch: 8\tFidelity = 0.500650\tKL_Divergence = 3.842947\n",
      "Epoch: 9\tFidelity = 0.500596\tKL_Divergence = 3.891050\n",
      "Epoch: 10\tFidelity = 0.500656\tKL_Divergence = 3.838363\n",
      "Epoch: 11\tFidelity = 0.500705\tKL_Divergence = 3.797903\n",
      "Epoch: 12\tFidelity = 0.500599\tKL_Divergence = 3.888204\n",
      "Epoch: 13\tFidelity = 0.500544\tKL_Divergence = 3.941287\n",
      "Epoch: 14\tFidelity = 0.500546\tKL_Divergence = 3.939547\n",
      "Epoch: 15\tFidelity = 0.500526\tKL_Divergence = 3.960280\n",
      "Epoch: 16\tFidelity = 0.500636\tKL_Divergence = 3.854793\n",
      "Epoch: 17\tFidelity = 0.500529\tKL_Divergence = 3.956630\n",
      "Epoch: 18\tFidelity = 0.500523\tKL_Divergence = 3.962878\n",
      "Epoch: 19\tFidelity = 0.500553\tKL_Divergence = 3.931718\n",
      "Epoch: 20\tFidelity = 0.500631\tKL_Divergence = 3.859507\n",
      "Epoch: 21\tFidelity = 0.500631\tKL_Divergence = 3.858829\n",
      "Epoch: 22\tFidelity = 0.500734\tKL_Divergence = 3.775393\n",
      "Epoch: 23\tFidelity = 0.500719\tKL_Divergence = 3.785986\n",
      "Epoch: 24\tFidelity = 0.500646\tKL_Divergence = 3.845918\n",
      "Epoch: 25\tFidelity = 0.500564\tKL_Divergence = 3.922049\n",
      "Epoch: 26\tFidelity = 0.500538\tKL_Divergence = 3.948238\n",
      "Epoch: 27\tFidelity = 0.500669\tKL_Divergence = 3.827013\n",
      "Epoch: 28\tFidelity = 0.500594\tKL_Divergence = 3.892528\n",
      "Epoch: 29\tFidelity = 0.500601\tKL_Divergence = 3.886469\n",
      "Epoch: 30\tFidelity = 0.500627\tKL_Divergence = 3.863139\n",
      "Epoch: 31\tFidelity = 0.500618\tKL_Divergence = 3.870847\n",
      "Epoch: 32\tFidelity = 0.500556\tKL_Divergence = 3.928614\n",
      "Epoch: 33\tFidelity = 0.500496\tKL_Divergence = 3.993233\n",
      "Epoch: 34\tFidelity = 0.500631\tKL_Divergence = 3.858847\n",
      "Epoch: 35\tFidelity = 0.500663\tKL_Divergence = 3.831524\n",
      "Epoch: 36\tFidelity = 0.500564\tKL_Divergence = 3.921052\n",
      "Epoch: 37\tFidelity = 0.500699\tKL_Divergence = 3.802155\n",
      "Epoch: 38\tFidelity = 0.500560\tKL_Divergence = 3.925405\n",
      "Epoch: 39\tFidelity = 0.500607\tKL_Divergence = 3.880876\n",
      "Epoch: 40\tFidelity = 0.500618\tKL_Divergence = 3.870960\n",
      "Epoch: 41\tFidelity = 0.500502\tKL_Divergence = 3.986302\n",
      "Epoch: 42\tFidelity = 0.500700\tKL_Divergence = 3.801301\n",
      "Epoch: 43\tFidelity = 0.500563\tKL_Divergence = 3.922844\n",
      "Epoch: 44\tFidelity = 0.500587\tKL_Divergence = 3.900009\n",
      "Epoch: 45\tFidelity = 0.500564\tKL_Divergence = 3.922215\n",
      "Epoch: 46\tFidelity = 0.500623\tKL_Divergence = 3.866396\n",
      "Epoch: 47\tFidelity = 0.500666\tKL_Divergence = 3.829898\n",
      "Epoch: 48\tFidelity = 0.500654\tKL_Divergence = 3.840255\n",
      "Epoch: 49\tFidelity = 0.500537\tKL_Divergence = 3.949673\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:10:24,379] Trial 578 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500473\tKL_Divergence = 4.019852\n",
      "Total time elapsed during training: 37.825 s\n",
      "Trial 578 pruned. \n",
      "Epoch: 1\tFidelity = 0.500635\tKL_Divergence = 3.856342\n",
      "Epoch: 2\tFidelity = 0.500625\tKL_Divergence = 3.865285\n",
      "Epoch: 3\tFidelity = 0.500577\tKL_Divergence = 3.909330\n",
      "Epoch: 4\tFidelity = 0.500560\tKL_Divergence = 3.925558\n",
      "Epoch: 5\tFidelity = 0.500515\tKL_Divergence = 3.972281\n",
      "Epoch: 6\tFidelity = 0.500552\tKL_Divergence = 3.933828\n",
      "Epoch: 7\tFidelity = 0.500623\tKL_Divergence = 3.867232\n",
      "Epoch: 8\tFidelity = 0.500540\tKL_Divergence = 3.946422\n",
      "Epoch: 9\tFidelity = 0.500551\tKL_Divergence = 3.935420\n",
      "Epoch: 10\tFidelity = 0.500517\tKL_Divergence = 3.970333\n",
      "Epoch: 11\tFidelity = 0.500551\tKL_Divergence = 3.935392\n",
      "Epoch: 12\tFidelity = 0.500548\tKL_Divergence = 3.938025\n",
      "Epoch: 13\tFidelity = 0.500601\tKL_Divergence = 3.887285\n",
      "Epoch: 14\tFidelity = 0.500668\tKL_Divergence = 3.828074\n",
      "Epoch: 15\tFidelity = 0.500548\tKL_Divergence = 3.937945\n",
      "Epoch: 16\tFidelity = 0.500590\tKL_Divergence = 3.897199\n",
      "Epoch: 17\tFidelity = 0.500643\tKL_Divergence = 3.849687\n",
      "Epoch: 18\tFidelity = 0.500592\tKL_Divergence = 3.895586\n",
      "Epoch: 19\tFidelity = 0.500541\tKL_Divergence = 3.945401\n",
      "Epoch: 20\tFidelity = 0.500684\tKL_Divergence = 3.814739\n",
      "Epoch: 21\tFidelity = 0.500701\tKL_Divergence = 3.801277\n",
      "Epoch: 22\tFidelity = 0.500770\tKL_Divergence = 3.749528\n",
      "Epoch: 23\tFidelity = 0.500617\tKL_Divergence = 3.872565\n",
      "Epoch: 24\tFidelity = 0.500545\tKL_Divergence = 3.940759\n",
      "Epoch: 25\tFidelity = 0.500644\tKL_Divergence = 3.848642\n",
      "Epoch: 26\tFidelity = 0.500585\tKL_Divergence = 3.902198\n",
      "Epoch: 27\tFidelity = 0.500663\tKL_Divergence = 3.832709\n",
      "Epoch: 28\tFidelity = 0.500528\tKL_Divergence = 3.958522\n",
      "Epoch: 29\tFidelity = 0.500653\tKL_Divergence = 3.840324\n",
      "Epoch: 30\tFidelity = 0.500505\tKL_Divergence = 3.983433\n",
      "Epoch: 31\tFidelity = 0.500687\tKL_Divergence = 3.812347\n",
      "Epoch: 32\tFidelity = 0.500503\tKL_Divergence = 3.985015\n",
      "Epoch: 33\tFidelity = 0.500774\tKL_Divergence = 3.746551\n",
      "Epoch: 34\tFidelity = 0.500583\tKL_Divergence = 3.903635\n",
      "Epoch: 35\tFidelity = 0.500513\tKL_Divergence = 3.974440\n",
      "Epoch: 36\tFidelity = 0.500563\tKL_Divergence = 3.922963\n",
      "Epoch: 37\tFidelity = 0.500642\tKL_Divergence = 3.850175\n",
      "Epoch: 38\tFidelity = 0.500614\tKL_Divergence = 3.875074\n",
      "Epoch: 39\tFidelity = 0.500572\tKL_Divergence = 3.913772\n",
      "Epoch: 40\tFidelity = 0.500590\tKL_Divergence = 3.897398\n",
      "Epoch: 41\tFidelity = 0.500575\tKL_Divergence = 3.910879\n",
      "Epoch: 42\tFidelity = 0.500642\tKL_Divergence = 3.850123\n",
      "Epoch: 43\tFidelity = 0.500608\tKL_Divergence = 3.880032\n",
      "Epoch: 44\tFidelity = 0.500642\tKL_Divergence = 3.849951\n",
      "Epoch: 45\tFidelity = 0.500637\tKL_Divergence = 3.854608\n",
      "Epoch: 46\tFidelity = 0.500551\tKL_Divergence = 3.934959\n",
      "Epoch: 47\tFidelity = 0.500647\tKL_Divergence = 3.846119\n",
      "Epoch: 48\tFidelity = 0.500576\tKL_Divergence = 3.910734\n",
      "Epoch: 49\tFidelity = 0.500691\tKL_Divergence = 3.809253\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:11:09,395] Trial 579 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500536\tKL_Divergence = 3.950392\n",
      "Total time elapsed during training: 44.830 s\n",
      "Trial 579 pruned. \n",
      "Epoch: 1\tFidelity = 0.500592\tKL_Divergence = 3.895183\n",
      "Epoch: 2\tFidelity = 0.500608\tKL_Divergence = 3.880475\n",
      "Epoch: 3\tFidelity = 0.500603\tKL_Divergence = 3.884489\n",
      "Epoch: 4\tFidelity = 0.500622\tKL_Divergence = 3.867689\n",
      "Epoch: 5\tFidelity = 0.500634\tKL_Divergence = 3.856741\n",
      "Epoch: 6\tFidelity = 0.500598\tKL_Divergence = 3.889520\n",
      "Epoch: 7\tFidelity = 0.500617\tKL_Divergence = 3.871918\n",
      "Epoch: 8\tFidelity = 0.500583\tKL_Divergence = 3.903380\n",
      "Epoch: 9\tFidelity = 0.500592\tKL_Divergence = 3.895132\n",
      "Epoch: 10\tFidelity = 0.500566\tKL_Divergence = 3.920461\n",
      "Epoch: 11\tFidelity = 0.500630\tKL_Divergence = 3.860311\n",
      "Epoch: 12\tFidelity = 0.500618\tKL_Divergence = 3.870974\n",
      "Epoch: 13\tFidelity = 0.500629\tKL_Divergence = 3.861809\n",
      "Epoch: 14\tFidelity = 0.500637\tKL_Divergence = 3.854643\n",
      "Epoch: 15\tFidelity = 0.500600\tKL_Divergence = 3.887878\n",
      "Epoch: 16\tFidelity = 0.500599\tKL_Divergence = 3.888952\n",
      "Epoch: 17\tFidelity = 0.500608\tKL_Divergence = 3.879967\n",
      "Epoch: 18\tFidelity = 0.500590\tKL_Divergence = 3.897354\n",
      "Epoch: 19\tFidelity = 0.500613\tKL_Divergence = 3.875828\n",
      "Epoch: 20\tFidelity = 0.500617\tKL_Divergence = 3.872357\n",
      "Epoch: 21\tFidelity = 0.500601\tKL_Divergence = 3.886514\n",
      "Epoch: 22\tFidelity = 0.500628\tKL_Divergence = 3.861987\n",
      "Epoch: 23\tFidelity = 0.500633\tKL_Divergence = 3.857689\n",
      "Epoch: 24\tFidelity = 0.500656\tKL_Divergence = 3.837793\n",
      "Epoch: 25\tFidelity = 0.500618\tKL_Divergence = 3.870826\n",
      "Epoch: 26\tFidelity = 0.500604\tKL_Divergence = 3.883968\n",
      "Epoch: 27\tFidelity = 0.500610\tKL_Divergence = 3.878647\n",
      "Epoch: 28\tFidelity = 0.500594\tKL_Divergence = 3.893532\n",
      "Epoch: 29\tFidelity = 0.500586\tKL_Divergence = 3.900924\n",
      "Epoch: 30\tFidelity = 0.500567\tKL_Divergence = 3.918561\n",
      "Epoch: 31\tFidelity = 0.500607\tKL_Divergence = 3.880719\n",
      "Epoch: 32\tFidelity = 0.500588\tKL_Divergence = 3.898715\n",
      "Epoch: 33\tFidelity = 0.500632\tKL_Divergence = 3.858709\n",
      "Epoch: 34\tFidelity = 0.500583\tKL_Divergence = 3.903544\n",
      "Epoch: 35\tFidelity = 0.500592\tKL_Divergence = 3.894914\n",
      "Epoch: 36\tFidelity = 0.500627\tKL_Divergence = 3.863438\n",
      "Epoch: 37\tFidelity = 0.500618\tKL_Divergence = 3.870872\n",
      "Epoch: 38\tFidelity = 0.500602\tKL_Divergence = 3.885821\n",
      "Epoch: 39\tFidelity = 0.500606\tKL_Divergence = 3.881777\n",
      "Epoch: 40\tFidelity = 0.500615\tKL_Divergence = 3.873779\n",
      "Epoch: 41\tFidelity = 0.500648\tKL_Divergence = 3.844585\n",
      "Epoch: 42\tFidelity = 0.500639\tKL_Divergence = 3.853062\n",
      "Epoch: 43\tFidelity = 0.500618\tKL_Divergence = 3.870953\n",
      "Epoch: 44\tFidelity = 0.500587\tKL_Divergence = 3.899567\n",
      "Epoch: 45\tFidelity = 0.500582\tKL_Divergence = 3.904436\n",
      "Epoch: 46\tFidelity = 0.500571\tKL_Divergence = 3.915142\n",
      "Epoch: 47\tFidelity = 0.500625\tKL_Divergence = 3.864888\n",
      "Epoch: 48\tFidelity = 0.500624\tKL_Divergence = 3.865706\n",
      "Epoch: 49\tFidelity = 0.500581\tKL_Divergence = 3.905816\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:11:47,550] Trial 580 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500560\tKL_Divergence = 3.925479\n",
      "Total time elapsed during training: 37.973 s\n",
      "Trial 580 pruned. \n",
      "Epoch: 1\tFidelity = 0.500606\tKL_Divergence = 3.882470\n",
      "Epoch: 2\tFidelity = 0.500614\tKL_Divergence = 3.875206\n",
      "Epoch: 3\tFidelity = 0.500600\tKL_Divergence = 3.887301\n",
      "Epoch: 4\tFidelity = 0.500622\tKL_Divergence = 3.867673\n",
      "Epoch: 5\tFidelity = 0.500632\tKL_Divergence = 3.858482\n",
      "Epoch: 6\tFidelity = 0.500637\tKL_Divergence = 3.854571\n",
      "Epoch: 7\tFidelity = 0.500599\tKL_Divergence = 3.888683\n",
      "Epoch: 8\tFidelity = 0.500641\tKL_Divergence = 3.850986\n",
      "Epoch: 9\tFidelity = 0.500650\tKL_Divergence = 3.843415\n",
      "Epoch: 10\tFidelity = 0.500592\tKL_Divergence = 3.895188\n",
      "Epoch: 11\tFidelity = 0.500595\tKL_Divergence = 3.892139\n",
      "Epoch: 12\tFidelity = 0.500557\tKL_Divergence = 3.928935\n",
      "Epoch: 13\tFidelity = 0.500593\tKL_Divergence = 3.894513\n",
      "Epoch: 14\tFidelity = 0.500612\tKL_Divergence = 3.876469\n",
      "Epoch: 15\tFidelity = 0.500598\tKL_Divergence = 3.889945\n",
      "Epoch: 16\tFidelity = 0.500653\tKL_Divergence = 3.840780\n",
      "Epoch: 17\tFidelity = 0.500663\tKL_Divergence = 3.832259\n",
      "Epoch: 18\tFidelity = 0.500601\tKL_Divergence = 3.886692\n",
      "Epoch: 19\tFidelity = 0.500597\tKL_Divergence = 3.890093\n",
      "Epoch: 20\tFidelity = 0.500652\tKL_Divergence = 3.841265\n",
      "Epoch: 21\tFidelity = 0.500625\tKL_Divergence = 3.865159\n",
      "Epoch: 22\tFidelity = 0.500618\tKL_Divergence = 3.871210\n",
      "Epoch: 23\tFidelity = 0.500560\tKL_Divergence = 3.925474\n",
      "Epoch: 24\tFidelity = 0.500598\tKL_Divergence = 3.889750\n",
      "Epoch: 25\tFidelity = 0.500631\tKL_Divergence = 3.860027\n",
      "Epoch: 26\tFidelity = 0.500620\tKL_Divergence = 3.869238\n",
      "Epoch: 27\tFidelity = 0.500571\tKL_Divergence = 3.915471\n",
      "Epoch: 28\tFidelity = 0.500617\tKL_Divergence = 3.871969\n",
      "Epoch: 29\tFidelity = 0.500621\tKL_Divergence = 3.868510\n",
      "Epoch: 30\tFidelity = 0.500606\tKL_Divergence = 3.882400\n",
      "Epoch: 31\tFidelity = 0.500626\tKL_Divergence = 3.863817\n",
      "Epoch: 32\tFidelity = 0.500572\tKL_Divergence = 3.914011\n",
      "Epoch: 33\tFidelity = 0.500548\tKL_Divergence = 3.938082\n",
      "Epoch: 34\tFidelity = 0.500627\tKL_Divergence = 3.863178\n",
      "Epoch: 35\tFidelity = 0.500606\tKL_Divergence = 3.882581\n",
      "Epoch: 36\tFidelity = 0.500607\tKL_Divergence = 3.881220\n",
      "Epoch: 37\tFidelity = 0.500642\tKL_Divergence = 3.850139\n",
      "Epoch: 38\tFidelity = 0.500598\tKL_Divergence = 3.889647\n",
      "Epoch: 39\tFidelity = 0.500533\tKL_Divergence = 3.952938\n",
      "Epoch: 40\tFidelity = 0.500611\tKL_Divergence = 3.878041\n",
      "Epoch: 41\tFidelity = 0.500572\tKL_Divergence = 3.914172\n",
      "Epoch: 42\tFidelity = 0.500535\tKL_Divergence = 3.951323\n",
      "Epoch: 43\tFidelity = 0.500622\tKL_Divergence = 3.867571\n",
      "Epoch: 44\tFidelity = 0.500595\tKL_Divergence = 3.892723\n",
      "Epoch: 45\tFidelity = 0.500581\tKL_Divergence = 3.905277\n",
      "Epoch: 46\tFidelity = 0.500578\tKL_Divergence = 3.908035\n",
      "Epoch: 47\tFidelity = 0.500643\tKL_Divergence = 3.849415\n",
      "Epoch: 48\tFidelity = 0.500637\tKL_Divergence = 3.854802\n",
      "Epoch: 49\tFidelity = 0.500622\tKL_Divergence = 3.867742\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:12:19,669] Trial 581 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500608\tKL_Divergence = 3.880204\n",
      "Total time elapsed during training: 31.931 s\n",
      "Trial 581 pruned. \n",
      "Epoch: 1\tFidelity = 0.500521\tKL_Divergence = 3.966067\n",
      "Epoch: 2\tFidelity = 0.500643\tKL_Divergence = 3.849668\n",
      "Epoch: 3\tFidelity = 0.500599\tKL_Divergence = 3.889040\n",
      "Epoch: 4\tFidelity = 0.500580\tKL_Divergence = 3.906678\n",
      "Epoch: 5\tFidelity = 0.500667\tKL_Divergence = 3.828828\n",
      "Epoch: 6\tFidelity = 0.500765\tKL_Divergence = 3.752699\n",
      "Epoch: 7\tFidelity = 0.500618\tKL_Divergence = 3.871500\n",
      "Epoch: 8\tFidelity = 0.500642\tKL_Divergence = 3.850505\n",
      "Epoch: 9\tFidelity = 0.500655\tKL_Divergence = 3.838786\n",
      "Epoch: 10\tFidelity = 0.500571\tKL_Divergence = 3.914703\n",
      "Epoch: 11\tFidelity = 0.500615\tKL_Divergence = 3.874325\n",
      "Epoch: 12\tFidelity = 0.500747\tKL_Divergence = 3.766011\n",
      "Epoch: 13\tFidelity = 0.500603\tKL_Divergence = 3.885321\n",
      "Epoch: 14\tFidelity = 0.500489\tKL_Divergence = 4.001822\n",
      "Epoch: 15\tFidelity = 0.500580\tKL_Divergence = 3.906907\n",
      "Epoch: 16\tFidelity = 0.500607\tKL_Divergence = 3.881051\n",
      "Epoch: 17\tFidelity = 0.500682\tKL_Divergence = 3.816393\n",
      "Epoch: 18\tFidelity = 0.500536\tKL_Divergence = 3.950171\n",
      "Epoch: 19\tFidelity = 0.500663\tKL_Divergence = 3.832030\n",
      "Epoch: 20\tFidelity = 0.500514\tKL_Divergence = 3.973685\n",
      "Epoch: 21\tFidelity = 0.500661\tKL_Divergence = 3.833831\n",
      "Epoch: 22\tFidelity = 0.500814\tKL_Divergence = 3.718639\n",
      "Epoch: 23\tFidelity = 0.500752\tKL_Divergence = 3.762432\n",
      "Epoch: 24\tFidelity = 0.500515\tKL_Divergence = 3.972930\n",
      "Epoch: 25\tFidelity = 0.500608\tKL_Divergence = 3.880368\n",
      "Epoch: 26\tFidelity = 0.500532\tKL_Divergence = 3.954516\n",
      "Epoch: 27\tFidelity = 0.500712\tKL_Divergence = 3.793074\n",
      "Epoch: 28\tFidelity = 0.500549\tKL_Divergence = 3.937190\n",
      "Epoch: 29\tFidelity = 0.500626\tKL_Divergence = 3.863879\n",
      "Epoch: 30\tFidelity = 0.500618\tKL_Divergence = 3.871530\n",
      "Epoch: 31\tFidelity = 0.500518\tKL_Divergence = 3.969451\n",
      "Epoch: 32\tFidelity = 0.500538\tKL_Divergence = 3.948067\n",
      "Epoch: 33\tFidelity = 0.500561\tKL_Divergence = 3.925064\n",
      "Epoch: 34\tFidelity = 0.500687\tKL_Divergence = 3.812916\n",
      "Epoch: 35\tFidelity = 0.500545\tKL_Divergence = 3.941494\n",
      "Epoch: 36\tFidelity = 0.500663\tKL_Divergence = 3.832024\n",
      "Epoch: 37\tFidelity = 0.500837\tKL_Divergence = 3.703267\n",
      "Epoch: 38\tFidelity = 0.500632\tKL_Divergence = 3.859163\n",
      "Epoch: 39\tFidelity = 0.500694\tKL_Divergence = 3.806667\n",
      "Epoch: 40\tFidelity = 0.500548\tKL_Divergence = 3.938137\n",
      "Epoch: 41\tFidelity = 0.500617\tKL_Divergence = 3.872290\n",
      "Epoch: 42\tFidelity = 0.500464\tKL_Divergence = 4.030763\n",
      "Epoch: 43\tFidelity = 0.500482\tKL_Divergence = 4.009205\n",
      "Epoch: 44\tFidelity = 0.500634\tKL_Divergence = 3.856744\n",
      "Epoch: 45\tFidelity = 0.500789\tKL_Divergence = 3.735461\n",
      "Epoch: 46\tFidelity = 0.500689\tKL_Divergence = 3.810858\n",
      "Epoch: 47\tFidelity = 0.500540\tKL_Divergence = 3.946408\n",
      "Epoch: 48\tFidelity = 0.500690\tKL_Divergence = 3.810424\n",
      "Epoch: 49\tFidelity = 0.500591\tKL_Divergence = 3.895715\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:12:51,012] Trial 582 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500684\tKL_Divergence = 3.815250\n",
      "Total time elapsed during training: 31.150 s\n",
      "Trial 582 pruned. \n",
      "Epoch: 1\tFidelity = 0.500658\tKL_Divergence = 3.836474\n",
      "Epoch: 2\tFidelity = 0.500648\tKL_Divergence = 3.844499\n",
      "Epoch: 3\tFidelity = 0.500557\tKL_Divergence = 3.929063\n",
      "Epoch: 4\tFidelity = 0.500657\tKL_Divergence = 3.837576\n",
      "Epoch: 5\tFidelity = 0.500649\tKL_Divergence = 3.844357\n",
      "Epoch: 6\tFidelity = 0.500686\tKL_Divergence = 3.812878\n",
      "Epoch: 7\tFidelity = 0.500663\tKL_Divergence = 3.832012\n",
      "Epoch: 8\tFidelity = 0.500638\tKL_Divergence = 3.853785\n",
      "Epoch: 9\tFidelity = 0.500529\tKL_Divergence = 3.957198\n",
      "Epoch: 10\tFidelity = 0.500697\tKL_Divergence = 3.804088\n",
      "Epoch: 11\tFidelity = 0.500543\tKL_Divergence = 3.943301\n",
      "Epoch: 12\tFidelity = 0.500646\tKL_Divergence = 3.846123\n",
      "Epoch: 13\tFidelity = 0.500624\tKL_Divergence = 3.865867\n",
      "Epoch: 14\tFidelity = 0.500630\tKL_Divergence = 3.859751\n",
      "Epoch: 15\tFidelity = 0.500569\tKL_Divergence = 3.916632\n",
      "Epoch: 16\tFidelity = 0.500632\tKL_Divergence = 3.858627\n",
      "Epoch: 17\tFidelity = 0.500618\tKL_Divergence = 3.870358\n",
      "Epoch: 18\tFidelity = 0.500617\tKL_Divergence = 3.871121\n",
      "Epoch: 19\tFidelity = 0.500589\tKL_Divergence = 3.897245\n",
      "Epoch: 20\tFidelity = 0.500580\tKL_Divergence = 3.906134\n",
      "Epoch: 21\tFidelity = 0.500602\tKL_Divergence = 3.884907\n",
      "Epoch: 22\tFidelity = 0.500600\tKL_Divergence = 3.887640\n",
      "Epoch: 23\tFidelity = 0.500585\tKL_Divergence = 3.901766\n",
      "Epoch: 24\tFidelity = 0.500618\tKL_Divergence = 3.871425\n",
      "Epoch: 25\tFidelity = 0.500654\tKL_Divergence = 3.839805\n",
      "Epoch: 26\tFidelity = 0.500632\tKL_Divergence = 3.858740\n",
      "Epoch: 27\tFidelity = 0.500575\tKL_Divergence = 3.910800\n",
      "Epoch: 28\tFidelity = 0.500558\tKL_Divergence = 3.927981\n",
      "Epoch: 29\tFidelity = 0.500632\tKL_Divergence = 3.858353\n",
      "Epoch: 30\tFidelity = 0.500623\tKL_Divergence = 3.867005\n",
      "Epoch: 31\tFidelity = 0.500637\tKL_Divergence = 3.853836\n",
      "Epoch: 32\tFidelity = 0.500646\tKL_Divergence = 3.846848\n",
      "Epoch: 33\tFidelity = 0.500639\tKL_Divergence = 3.852391\n",
      "Epoch: 34\tFidelity = 0.500639\tKL_Divergence = 3.852208\n",
      "Epoch: 35\tFidelity = 0.500615\tKL_Divergence = 3.874153\n",
      "Epoch: 36\tFidelity = 0.500657\tKL_Divergence = 3.837455\n",
      "Epoch: 37\tFidelity = 0.500633\tKL_Divergence = 3.857713\n",
      "Epoch: 38\tFidelity = 0.500650\tKL_Divergence = 3.843159\n",
      "Epoch: 39\tFidelity = 0.500663\tKL_Divergence = 3.832256\n",
      "Epoch: 40\tFidelity = 0.500681\tKL_Divergence = 3.817469\n",
      "Epoch: 41\tFidelity = 0.500617\tKL_Divergence = 3.871567\n",
      "Epoch: 42\tFidelity = 0.500666\tKL_Divergence = 3.829513\n",
      "Epoch: 43\tFidelity = 0.500660\tKL_Divergence = 3.834668\n",
      "Epoch: 44\tFidelity = 0.500596\tKL_Divergence = 3.891616\n",
      "Epoch: 45\tFidelity = 0.500553\tKL_Divergence = 3.932861\n",
      "Epoch: 46\tFidelity = 0.500555\tKL_Divergence = 3.930621\n",
      "Epoch: 47\tFidelity = 0.500620\tKL_Divergence = 3.869275\n",
      "Epoch: 48\tFidelity = 0.500571\tKL_Divergence = 3.914880\n",
      "Epoch: 49\tFidelity = 0.500629\tKL_Divergence = 3.861353\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:13:35,155] Trial 583 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500658\tKL_Divergence = 3.836256\n",
      "Total time elapsed during training: 43.954 s\n",
      "Trial 583 pruned. \n",
      "Epoch: 1\tFidelity = 0.500723\tKL_Divergence = 3.784047\n",
      "Epoch: 2\tFidelity = 0.500597\tKL_Divergence = 3.890852\n",
      "Epoch: 3\tFidelity = 0.500541\tKL_Divergence = 3.945039\n",
      "Epoch: 4\tFidelity = 0.500775\tKL_Divergence = 3.745752\n",
      "Epoch: 5\tFidelity = 0.500599\tKL_Divergence = 3.888797\n",
      "Epoch: 6\tFidelity = 0.500667\tKL_Divergence = 3.828755\n",
      "Epoch: 7\tFidelity = 0.500564\tKL_Divergence = 3.921676\n",
      "Epoch: 8\tFidelity = 0.500664\tKL_Divergence = 3.831676\n",
      "Epoch: 9\tFidelity = 0.500722\tKL_Divergence = 3.785263\n",
      "Epoch: 10\tFidelity = 0.500672\tKL_Divergence = 3.824621\n",
      "Epoch: 11\tFidelity = 0.500571\tKL_Divergence = 3.915430\n",
      "Epoch: 12\tFidelity = 0.500718\tKL_Divergence = 3.788040\n",
      "Epoch: 13\tFidelity = 0.500608\tKL_Divergence = 3.879976\n",
      "Epoch: 14\tFidelity = 0.500540\tKL_Divergence = 3.945947\n",
      "Epoch: 15\tFidelity = 0.500708\tKL_Divergence = 3.795969\n",
      "Epoch: 16\tFidelity = 0.500608\tKL_Divergence = 3.880597\n",
      "Epoch: 17\tFidelity = 0.500583\tKL_Divergence = 3.903402\n",
      "Epoch: 18\tFidelity = 0.500653\tKL_Divergence = 3.840245\n",
      "Epoch: 19\tFidelity = 0.500634\tKL_Divergence = 3.857325\n",
      "Epoch: 20\tFidelity = 0.500759\tKL_Divergence = 3.757046\n",
      "Epoch: 21\tFidelity = 0.500510\tKL_Divergence = 3.977370\n",
      "Epoch: 22\tFidelity = 0.500632\tKL_Divergence = 3.858565\n",
      "Epoch: 23\tFidelity = 0.500571\tKL_Divergence = 3.915071\n",
      "Epoch: 24\tFidelity = 0.500612\tKL_Divergence = 3.876881\n",
      "Epoch: 25\tFidelity = 0.500591\tKL_Divergence = 3.896252\n",
      "Epoch: 26\tFidelity = 0.500614\tKL_Divergence = 3.875017\n",
      "Epoch: 27\tFidelity = 0.500643\tKL_Divergence = 3.848945\n",
      "Epoch: 28\tFidelity = 0.500812\tKL_Divergence = 3.719838\n",
      "Epoch: 29\tFidelity = 0.500520\tKL_Divergence = 3.966981\n",
      "Epoch: 30\tFidelity = 0.500518\tKL_Divergence = 3.968556\n",
      "Epoch: 31\tFidelity = 0.500551\tKL_Divergence = 3.935015\n",
      "Epoch: 32\tFidelity = 0.500592\tKL_Divergence = 3.894826\n",
      "Epoch: 33\tFidelity = 0.500591\tKL_Divergence = 3.895742\n",
      "Epoch: 34\tFidelity = 0.500678\tKL_Divergence = 3.819447\n",
      "Epoch: 35\tFidelity = 0.500571\tKL_Divergence = 3.915439\n",
      "Epoch: 36\tFidelity = 0.500572\tKL_Divergence = 3.914196\n",
      "Epoch: 37\tFidelity = 0.500641\tKL_Divergence = 3.851128\n",
      "Epoch: 38\tFidelity = 0.500762\tKL_Divergence = 3.755317\n",
      "Epoch: 39\tFidelity = 0.500659\tKL_Divergence = 3.835295\n",
      "Epoch: 40\tFidelity = 0.500575\tKL_Divergence = 3.911617\n",
      "Epoch: 41\tFidelity = 0.500631\tKL_Divergence = 3.859979\n",
      "Epoch: 42\tFidelity = 0.500687\tKL_Divergence = 3.812559\n",
      "Epoch: 43\tFidelity = 0.500551\tKL_Divergence = 3.934401\n",
      "Epoch: 44\tFidelity = 0.500536\tKL_Divergence = 3.949971\n",
      "Epoch: 45\tFidelity = 0.500693\tKL_Divergence = 3.807775\n",
      "Epoch: 46\tFidelity = 0.500564\tKL_Divergence = 3.922342\n",
      "Epoch: 47\tFidelity = 0.500594\tKL_Divergence = 3.893490\n",
      "Epoch: 48\tFidelity = 0.500608\tKL_Divergence = 3.879819\n",
      "Epoch: 49\tFidelity = 0.500567\tKL_Divergence = 3.919209\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:14:12,996] Trial 584 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500769\tKL_Divergence = 3.749612\n",
      "Total time elapsed during training: 37.660 s\n",
      "Trial 584 pruned. \n",
      "Epoch: 1\tFidelity = 0.500588\tKL_Divergence = 3.898910\n",
      "Epoch: 2\tFidelity = 0.500577\tKL_Divergence = 3.909402\n",
      "Epoch: 3\tFidelity = 0.500634\tKL_Divergence = 3.857039\n",
      "Epoch: 4\tFidelity = 0.500595\tKL_Divergence = 3.892238\n",
      "Epoch: 5\tFidelity = 0.500644\tKL_Divergence = 3.848662\n",
      "Epoch: 6\tFidelity = 0.500552\tKL_Divergence = 3.933969\n",
      "Epoch: 7\tFidelity = 0.500599\tKL_Divergence = 3.888308\n",
      "Epoch: 8\tFidelity = 0.500611\tKL_Divergence = 3.877500\n",
      "Epoch: 9\tFidelity = 0.500652\tKL_Divergence = 3.841272\n",
      "Epoch: 10\tFidelity = 0.500640\tKL_Divergence = 3.851853\n",
      "Epoch: 11\tFidelity = 0.500631\tKL_Divergence = 3.860085\n",
      "Epoch: 12\tFidelity = 0.500635\tKL_Divergence = 3.856587\n",
      "Epoch: 13\tFidelity = 0.500598\tKL_Divergence = 3.889929\n",
      "Epoch: 14\tFidelity = 0.500580\tKL_Divergence = 3.906323\n",
      "Epoch: 15\tFidelity = 0.500585\tKL_Divergence = 3.901580\n",
      "Epoch: 16\tFidelity = 0.500591\tKL_Divergence = 3.896165\n",
      "Epoch: 17\tFidelity = 0.500536\tKL_Divergence = 3.950282\n",
      "Epoch: 18\tFidelity = 0.500648\tKL_Divergence = 3.844673\n",
      "Epoch: 19\tFidelity = 0.500609\tKL_Divergence = 3.879732\n",
      "Epoch: 20\tFidelity = 0.500607\tKL_Divergence = 3.880913\n",
      "Epoch: 21\tFidelity = 0.500641\tKL_Divergence = 3.850991\n",
      "Epoch: 22\tFidelity = 0.500646\tKL_Divergence = 3.846413\n",
      "Epoch: 23\tFidelity = 0.500534\tKL_Divergence = 3.952735\n",
      "Epoch: 24\tFidelity = 0.500624\tKL_Divergence = 3.865525\n",
      "Epoch: 25\tFidelity = 0.500670\tKL_Divergence = 3.826174\n",
      "Epoch: 26\tFidelity = 0.500590\tKL_Divergence = 3.896620\n",
      "Epoch: 27\tFidelity = 0.500579\tKL_Divergence = 3.907462\n",
      "Epoch: 28\tFidelity = 0.500621\tKL_Divergence = 3.868154\n",
      "Epoch: 29\tFidelity = 0.500602\tKL_Divergence = 3.886248\n",
      "Epoch: 30\tFidelity = 0.500690\tKL_Divergence = 3.809998\n",
      "Epoch: 31\tFidelity = 0.500614\tKL_Divergence = 3.874630\n",
      "Epoch: 32\tFidelity = 0.500648\tKL_Divergence = 3.845143\n",
      "Epoch: 33\tFidelity = 0.500606\tKL_Divergence = 3.882299\n",
      "Epoch: 34\tFidelity = 0.500614\tKL_Divergence = 3.874974\n",
      "Epoch: 35\tFidelity = 0.500530\tKL_Divergence = 3.956672\n",
      "Epoch: 36\tFidelity = 0.500696\tKL_Divergence = 3.805473\n",
      "Epoch: 37\tFidelity = 0.500665\tKL_Divergence = 3.830269\n",
      "Epoch: 38\tFidelity = 0.500560\tKL_Divergence = 3.925912\n",
      "Epoch: 39\tFidelity = 0.500576\tKL_Divergence = 3.910473\n",
      "Epoch: 40\tFidelity = 0.500560\tKL_Divergence = 3.925526\n",
      "Epoch: 41\tFidelity = 0.500598\tKL_Divergence = 3.889346\n",
      "Epoch: 42\tFidelity = 0.500528\tKL_Divergence = 3.958151\n",
      "Epoch: 43\tFidelity = 0.500563\tKL_Divergence = 3.923105\n",
      "Epoch: 44\tFidelity = 0.500606\tKL_Divergence = 3.882234\n",
      "Epoch: 45\tFidelity = 0.500599\tKL_Divergence = 3.889046\n",
      "Epoch: 46\tFidelity = 0.500605\tKL_Divergence = 3.882733\n",
      "Epoch: 47\tFidelity = 0.500556\tKL_Divergence = 3.930416\n",
      "Epoch: 48\tFidelity = 0.500617\tKL_Divergence = 3.872610\n",
      "Epoch: 49\tFidelity = 0.500577\tKL_Divergence = 3.908954\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:15:33,004] Trial 585 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500606\tKL_Divergence = 3.882121\n",
      "Total time elapsed during training: 79.830 s\n",
      "Trial 585 pruned. \n",
      "Epoch: 1\tFidelity = 0.500730\tKL_Divergence = 3.778715\n",
      "Epoch: 2\tFidelity = 0.500625\tKL_Divergence = 3.864860\n",
      "Epoch: 3\tFidelity = 0.500558\tKL_Divergence = 3.928132\n",
      "Epoch: 4\tFidelity = 0.500624\tKL_Divergence = 3.865534\n",
      "Epoch: 5\tFidelity = 0.500631\tKL_Divergence = 3.858976\n",
      "Epoch: 6\tFidelity = 0.500550\tKL_Divergence = 3.935103\n",
      "Epoch: 7\tFidelity = 0.500546\tKL_Divergence = 3.938860\n",
      "Epoch: 8\tFidelity = 0.500557\tKL_Divergence = 3.927679\n",
      "Epoch: 9\tFidelity = 0.500680\tKL_Divergence = 3.817232\n",
      "Epoch: 10\tFidelity = 0.500707\tKL_Divergence = 3.795722\n",
      "Epoch: 11\tFidelity = 0.500564\tKL_Divergence = 3.921003\n",
      "Epoch: 12\tFidelity = 0.500715\tKL_Divergence = 3.790203\n",
      "Epoch: 13\tFidelity = 0.500505\tKL_Divergence = 3.982633\n",
      "Epoch: 14\tFidelity = 0.500735\tKL_Divergence = 3.774407\n",
      "Epoch: 15\tFidelity = 0.500555\tKL_Divergence = 3.930263\n",
      "Epoch: 16\tFidelity = 0.500596\tKL_Divergence = 3.890453\n",
      "Epoch: 17\tFidelity = 0.500600\tKL_Divergence = 3.886466\n",
      "Epoch: 18\tFidelity = 0.500561\tKL_Divergence = 3.924434\n",
      "Epoch: 19\tFidelity = 0.500557\tKL_Divergence = 3.927422\n",
      "Epoch: 20\tFidelity = 0.500528\tKL_Divergence = 3.956076\n",
      "Epoch: 21\tFidelity = 0.500613\tKL_Divergence = 3.874078\n",
      "Epoch: 22\tFidelity = 0.500598\tKL_Divergence = 3.887074\n",
      "Epoch: 23\tFidelity = 0.500699\tKL_Divergence = 3.799331\n",
      "Epoch: 24\tFidelity = 0.500565\tKL_Divergence = 3.918171\n",
      "Epoch: 25\tFidelity = 0.500792\tKL_Divergence = 3.730745\n",
      "Epoch: 26\tFidelity = 0.500605\tKL_Divergence = 3.879956\n",
      "Epoch: 27\tFidelity = 0.500559\tKL_Divergence = 3.923324\n",
      "Epoch: 28\tFidelity = 0.500640\tKL_Divergence = 3.848454\n",
      "Epoch: 29\tFidelity = 0.500607\tKL_Divergence = 3.876912\n",
      "Epoch: 30\tFidelity = 0.500636\tKL_Divergence = 3.850607\n",
      "Epoch: 31\tFidelity = 0.500606\tKL_Divergence = 3.879068\n",
      "Epoch: 32\tFidelity = 0.500539\tKL_Divergence = 3.944441\n",
      "Epoch: 33\tFidelity = 0.500583\tKL_Divergence = 3.900939\n",
      "Epoch: 34\tFidelity = 0.500543\tKL_Divergence = 3.942557\n",
      "Epoch: 35\tFidelity = 0.500640\tKL_Divergence = 3.850457\n",
      "Epoch: 36\tFidelity = 0.500621\tKL_Divergence = 3.866761\n",
      "Epoch: 37\tFidelity = 0.500575\tKL_Divergence = 3.910011\n",
      "Epoch: 38\tFidelity = 0.500563\tKL_Divergence = 3.921170\n",
      "Epoch: 39\tFidelity = 0.500516\tKL_Divergence = 3.969835\n",
      "Epoch: 40\tFidelity = 0.500548\tKL_Divergence = 3.937873\n",
      "Epoch: 41\tFidelity = 0.500616\tKL_Divergence = 3.872043\n",
      "Epoch: 42\tFidelity = 0.500579\tKL_Divergence = 3.907115\n",
      "Epoch: 43\tFidelity = 0.500525\tKL_Divergence = 3.961148\n",
      "Epoch: 44\tFidelity = 0.500583\tKL_Divergence = 3.903537\n",
      "Epoch: 45\tFidelity = 0.500525\tKL_Divergence = 3.961247\n",
      "Epoch: 46\tFidelity = 0.500600\tKL_Divergence = 3.887581\n",
      "Epoch: 47\tFidelity = 0.500574\tKL_Divergence = 3.911799\n",
      "Epoch: 48\tFidelity = 0.500570\tKL_Divergence = 3.915005\n",
      "Epoch: 49\tFidelity = 0.500625\tKL_Divergence = 3.863578\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:16:10,831] Trial 586 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500722\tKL_Divergence = 3.783870\n",
      "Total time elapsed during training: 37.644 s\n",
      "Trial 586 pruned. \n",
      "Epoch: 1\tFidelity = 0.500590\tKL_Divergence = 3.895956\n",
      "Epoch: 2\tFidelity = 0.500575\tKL_Divergence = 3.910870\n",
      "Epoch: 3\tFidelity = 0.500594\tKL_Divergence = 3.892795\n",
      "Epoch: 4\tFidelity = 0.500605\tKL_Divergence = 3.882807\n",
      "Epoch: 5\tFidelity = 0.500621\tKL_Divergence = 3.868186\n",
      "Epoch: 6\tFidelity = 0.500600\tKL_Divergence = 3.887125\n",
      "Epoch: 7\tFidelity = 0.500627\tKL_Divergence = 3.862983\n",
      "Epoch: 8\tFidelity = 0.500600\tKL_Divergence = 3.887057\n",
      "Epoch: 9\tFidelity = 0.500637\tKL_Divergence = 3.853842\n",
      "Epoch: 10\tFidelity = 0.500594\tKL_Divergence = 3.893339\n",
      "Epoch: 11\tFidelity = 0.500621\tKL_Divergence = 3.868105\n",
      "Epoch: 12\tFidelity = 0.500569\tKL_Divergence = 3.917370\n",
      "Epoch: 13\tFidelity = 0.500653\tKL_Divergence = 3.840223\n",
      "Epoch: 14\tFidelity = 0.500691\tKL_Divergence = 3.809168\n",
      "Epoch: 15\tFidelity = 0.500633\tKL_Divergence = 3.857739\n",
      "Epoch: 16\tFidelity = 0.500546\tKL_Divergence = 3.939806\n",
      "Epoch: 17\tFidelity = 0.500597\tKL_Divergence = 3.890199\n",
      "Epoch: 18\tFidelity = 0.500555\tKL_Divergence = 3.931126\n",
      "Epoch: 19\tFidelity = 0.500593\tKL_Divergence = 3.894365\n",
      "Epoch: 20\tFidelity = 0.500578\tKL_Divergence = 3.908093\n",
      "Epoch: 21\tFidelity = 0.500626\tKL_Divergence = 3.864216\n",
      "Epoch: 22\tFidelity = 0.500591\tKL_Divergence = 3.895811\n",
      "Epoch: 23\tFidelity = 0.500557\tKL_Divergence = 3.928657\n",
      "Epoch: 24\tFidelity = 0.500676\tKL_Divergence = 3.821281\n",
      "Epoch: 25\tFidelity = 0.500549\tKL_Divergence = 3.936975\n",
      "Epoch: 26\tFidelity = 0.500529\tKL_Divergence = 3.957668\n",
      "Epoch: 27\tFidelity = 0.500587\tKL_Divergence = 3.899400\n",
      "Epoch: 28\tFidelity = 0.500601\tKL_Divergence = 3.886234\n",
      "Epoch: 29\tFidelity = 0.500546\tKL_Divergence = 3.939563\n",
      "Epoch: 30\tFidelity = 0.500644\tKL_Divergence = 3.847869\n",
      "Epoch: 31\tFidelity = 0.500540\tKL_Divergence = 3.946384\n",
      "Epoch: 32\tFidelity = 0.500521\tKL_Divergence = 3.966009\n",
      "Epoch: 33\tFidelity = 0.500644\tKL_Divergence = 3.848037\n",
      "Epoch: 34\tFidelity = 0.500665\tKL_Divergence = 3.830598\n",
      "Epoch: 35\tFidelity = 0.500577\tKL_Divergence = 3.909296\n",
      "Epoch: 36\tFidelity = 0.500676\tKL_Divergence = 3.821121\n",
      "Epoch: 37\tFidelity = 0.500606\tKL_Divergence = 3.882079\n",
      "Epoch: 38\tFidelity = 0.500615\tKL_Divergence = 3.874298\n",
      "Epoch: 39\tFidelity = 0.500547\tKL_Divergence = 3.939270\n",
      "Epoch: 40\tFidelity = 0.500652\tKL_Divergence = 3.841372\n",
      "Epoch: 41\tFidelity = 0.500679\tKL_Divergence = 3.818903\n",
      "Epoch: 42\tFidelity = 0.500683\tKL_Divergence = 3.815970\n",
      "Epoch: 43\tFidelity = 0.500643\tKL_Divergence = 3.849170\n",
      "Epoch: 44\tFidelity = 0.500581\tKL_Divergence = 3.905683\n",
      "Epoch: 45\tFidelity = 0.500614\tKL_Divergence = 3.874979\n",
      "Epoch: 46\tFidelity = 0.500522\tKL_Divergence = 3.964421\n",
      "Epoch: 47\tFidelity = 0.500659\tKL_Divergence = 3.835852\n",
      "Epoch: 48\tFidelity = 0.500591\tKL_Divergence = 3.896343\n",
      "Epoch: 49\tFidelity = 0.500541\tKL_Divergence = 3.944761\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:16:55,499] Trial 587 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500531\tKL_Divergence = 3.955118\n",
      "Total time elapsed during training: 44.487 s\n",
      "Trial 587 pruned. \n",
      "Epoch: 1\tFidelity = 0.500564\tKL_Divergence = 3.922265\n",
      "Epoch: 2\tFidelity = 0.500577\tKL_Divergence = 3.909468\n",
      "Epoch: 3\tFidelity = 0.500604\tKL_Divergence = 3.883631\n",
      "Epoch: 4\tFidelity = 0.500759\tKL_Divergence = 3.757088\n",
      "Epoch: 5\tFidelity = 0.500515\tKL_Divergence = 3.972639\n",
      "Epoch: 6\tFidelity = 0.500607\tKL_Divergence = 3.881141\n",
      "Epoch: 7\tFidelity = 0.500559\tKL_Divergence = 3.926956\n",
      "Epoch: 8\tFidelity = 0.500584\tKL_Divergence = 3.902252\n",
      "Epoch: 9\tFidelity = 0.500611\tKL_Divergence = 3.877765\n",
      "Epoch: 10\tFidelity = 0.500633\tKL_Divergence = 3.858109\n",
      "Epoch: 11\tFidelity = 0.500587\tKL_Divergence = 3.899783\n",
      "Epoch: 12\tFidelity = 0.500674\tKL_Divergence = 3.822652\n",
      "Epoch: 13\tFidelity = 0.500629\tKL_Divergence = 3.860976\n",
      "Epoch: 14\tFidelity = 0.500587\tKL_Divergence = 3.899493\n",
      "Epoch: 15\tFidelity = 0.500670\tKL_Divergence = 3.826293\n",
      "Epoch: 16\tFidelity = 0.500712\tKL_Divergence = 3.792248\n",
      "Epoch: 17\tFidelity = 0.500573\tKL_Divergence = 3.912638\n",
      "Epoch: 18\tFidelity = 0.500588\tKL_Divergence = 3.899079\n",
      "Epoch: 19\tFidelity = 0.500573\tKL_Divergence = 3.912662\n",
      "Epoch: 20\tFidelity = 0.500508\tKL_Divergence = 3.979378\n",
      "Epoch: 21\tFidelity = 0.500683\tKL_Divergence = 3.815537\n",
      "Epoch: 22\tFidelity = 0.500654\tKL_Divergence = 3.839719\n",
      "Epoch: 23\tFidelity = 0.500635\tKL_Divergence = 3.856151\n",
      "Epoch: 24\tFidelity = 0.500650\tKL_Divergence = 3.843400\n",
      "Epoch: 25\tFidelity = 0.500675\tKL_Divergence = 3.822154\n",
      "Epoch: 26\tFidelity = 0.500591\tKL_Divergence = 3.896213\n",
      "Epoch: 27\tFidelity = 0.500627\tKL_Divergence = 3.863400\n",
      "Epoch: 28\tFidelity = 0.500546\tKL_Divergence = 3.939625\n",
      "Epoch: 29\tFidelity = 0.500642\tKL_Divergence = 3.850072\n",
      "Epoch: 30\tFidelity = 0.500623\tKL_Divergence = 3.866565\n",
      "Epoch: 31\tFidelity = 0.500599\tKL_Divergence = 3.888536\n",
      "Epoch: 32\tFidelity = 0.500646\tKL_Divergence = 3.846443\n",
      "Epoch: 33\tFidelity = 0.500551\tKL_Divergence = 3.934276\n",
      "Epoch: 34\tFidelity = 0.500654\tKL_Divergence = 3.840030\n",
      "Epoch: 35\tFidelity = 0.500594\tKL_Divergence = 3.893168\n",
      "Epoch: 36\tFidelity = 0.500612\tKL_Divergence = 3.876150\n",
      "Epoch: 37\tFidelity = 0.500652\tKL_Divergence = 3.841344\n",
      "Epoch: 38\tFidelity = 0.500534\tKL_Divergence = 3.952382\n",
      "Epoch: 39\tFidelity = 0.500667\tKL_Divergence = 3.829208\n",
      "Epoch: 40\tFidelity = 0.500632\tKL_Divergence = 3.858450\n",
      "Epoch: 41\tFidelity = 0.500633\tKL_Divergence = 3.858073\n",
      "Epoch: 42\tFidelity = 0.500593\tKL_Divergence = 3.894023\n",
      "Epoch: 43\tFidelity = 0.500621\tKL_Divergence = 3.868101\n",
      "Epoch: 44\tFidelity = 0.500589\tKL_Divergence = 3.897479\n",
      "Epoch: 45\tFidelity = 0.500654\tKL_Divergence = 3.840175\n",
      "Epoch: 46\tFidelity = 0.500490\tKL_Divergence = 4.000269\n",
      "Epoch: 47\tFidelity = 0.500565\tKL_Divergence = 3.921052\n",
      "Epoch: 48\tFidelity = 0.500626\tKL_Divergence = 3.864453\n",
      "Epoch: 49\tFidelity = 0.500550\tKL_Divergence = 3.936012\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:18:15,508] Trial 588 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500661\tKL_Divergence = 3.834229\n",
      "Total time elapsed during training: 79.824 s\n",
      "Trial 588 pruned. \n",
      "Epoch: 1\tFidelity = 0.500543\tKL_Divergence = 3.942665\n",
      "Epoch: 2\tFidelity = 0.500665\tKL_Divergence = 3.830844\n",
      "Epoch: 3\tFidelity = 0.500584\tKL_Divergence = 3.902117\n",
      "Epoch: 4\tFidelity = 0.500648\tKL_Divergence = 3.845152\n",
      "Epoch: 5\tFidelity = 0.500622\tKL_Divergence = 3.867205\n",
      "Epoch: 6\tFidelity = 0.500586\tKL_Divergence = 3.901088\n",
      "Epoch: 7\tFidelity = 0.500641\tKL_Divergence = 3.850837\n",
      "Epoch: 8\tFidelity = 0.500648\tKL_Divergence = 3.845145\n",
      "Epoch: 9\tFidelity = 0.500654\tKL_Divergence = 3.840033\n",
      "Epoch: 10\tFidelity = 0.500658\tKL_Divergence = 3.836081\n",
      "Epoch: 11\tFidelity = 0.500611\tKL_Divergence = 3.877318\n",
      "Epoch: 12\tFidelity = 0.500617\tKL_Divergence = 3.872102\n",
      "Epoch: 13\tFidelity = 0.500651\tKL_Divergence = 3.842331\n",
      "Epoch: 14\tFidelity = 0.500593\tKL_Divergence = 3.894255\n",
      "Epoch: 15\tFidelity = 0.500645\tKL_Divergence = 3.847764\n",
      "Epoch: 16\tFidelity = 0.500662\tKL_Divergence = 3.832652\n",
      "Epoch: 17\tFidelity = 0.500574\tKL_Divergence = 3.912473\n",
      "Epoch: 18\tFidelity = 0.500600\tKL_Divergence = 3.887154\n",
      "Epoch: 19\tFidelity = 0.500519\tKL_Divergence = 3.968094\n",
      "Epoch: 20\tFidelity = 0.500586\tKL_Divergence = 3.901036\n",
      "Epoch: 21\tFidelity = 0.500558\tKL_Divergence = 3.928255\n",
      "Epoch: 22\tFidelity = 0.500532\tKL_Divergence = 3.954007\n",
      "Epoch: 23\tFidelity = 0.500614\tKL_Divergence = 3.874761\n",
      "Epoch: 24\tFidelity = 0.500687\tKL_Divergence = 3.812498\n",
      "Epoch: 25\tFidelity = 0.500621\tKL_Divergence = 3.868748\n",
      "Epoch: 26\tFidelity = 0.500634\tKL_Divergence = 3.856835\n",
      "Epoch: 27\tFidelity = 0.500500\tKL_Divergence = 3.988405\n",
      "Epoch: 28\tFidelity = 0.500637\tKL_Divergence = 3.854012\n",
      "Epoch: 29\tFidelity = 0.500677\tKL_Divergence = 3.820400\n",
      "Epoch: 30\tFidelity = 0.500660\tKL_Divergence = 3.835121\n",
      "Epoch: 31\tFidelity = 0.500573\tKL_Divergence = 3.913575\n",
      "Epoch: 32\tFidelity = 0.500620\tKL_Divergence = 3.869557\n",
      "Epoch: 33\tFidelity = 0.500554\tKL_Divergence = 3.931423\n",
      "Epoch: 34\tFidelity = 0.500522\tKL_Divergence = 3.964991\n",
      "Epoch: 35\tFidelity = 0.500546\tKL_Divergence = 3.939471\n",
      "Epoch: 36\tFidelity = 0.500498\tKL_Divergence = 3.991031\n",
      "Epoch: 37\tFidelity = 0.500546\tKL_Divergence = 3.940385\n",
      "Epoch: 38\tFidelity = 0.500493\tKL_Divergence = 3.996697\n",
      "Epoch: 39\tFidelity = 0.500619\tKL_Divergence = 3.870286\n",
      "Epoch: 40\tFidelity = 0.500646\tKL_Divergence = 3.846621\n",
      "Epoch: 41\tFidelity = 0.500615\tKL_Divergence = 3.873882\n",
      "Epoch: 42\tFidelity = 0.500688\tKL_Divergence = 3.811998\n",
      "Epoch: 43\tFidelity = 0.500585\tKL_Divergence = 3.902019\n",
      "Epoch: 44\tFidelity = 0.500603\tKL_Divergence = 3.884765\n",
      "Epoch: 45\tFidelity = 0.500566\tKL_Divergence = 3.920085\n",
      "Epoch: 46\tFidelity = 0.500657\tKL_Divergence = 3.837251\n",
      "Epoch: 47\tFidelity = 0.500647\tKL_Divergence = 3.845658\n",
      "Epoch: 48\tFidelity = 0.500545\tKL_Divergence = 3.940671\n",
      "Epoch: 49\tFidelity = 0.500637\tKL_Divergence = 3.854095\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:18:54,026] Trial 589 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500674\tKL_Divergence = 3.822706\n",
      "Total time elapsed during training: 38.332 s\n",
      "Trial 589 pruned. \n",
      "Epoch: 1\tFidelity = 0.500768\tKL_Divergence = 3.750618\n",
      "Epoch: 2\tFidelity = 0.500610\tKL_Divergence = 3.878143\n",
      "Epoch: 3\tFidelity = 0.500776\tKL_Divergence = 3.745228\n",
      "Epoch: 4\tFidelity = 0.500529\tKL_Divergence = 3.957216\n",
      "Epoch: 5\tFidelity = 0.500626\tKL_Divergence = 3.863855\n",
      "Epoch: 6\tFidelity = 0.500792\tKL_Divergence = 3.733530\n",
      "Epoch: 7\tFidelity = 0.500605\tKL_Divergence = 3.883435\n",
      "Epoch: 8\tFidelity = 0.500803\tKL_Divergence = 3.725785\n",
      "Epoch: 9\tFidelity = 0.500630\tKL_Divergence = 3.860915\n",
      "Epoch: 10\tFidelity = 0.500536\tKL_Divergence = 3.950302\n",
      "Epoch: 11\tFidelity = 0.500581\tKL_Divergence = 3.904844\n",
      "Epoch: 12\tFidelity = 0.500657\tKL_Divergence = 3.837578\n",
      "Epoch: 13\tFidelity = 0.500499\tKL_Divergence = 3.989985\n",
      "Epoch: 14\tFidelity = 0.500716\tKL_Divergence = 3.789229\n",
      "Epoch: 15\tFidelity = 0.500513\tKL_Divergence = 3.974276\n",
      "Epoch: 16\tFidelity = 0.500737\tKL_Divergence = 3.773520\n",
      "Epoch: 17\tFidelity = 0.500638\tKL_Divergence = 3.853732\n",
      "Epoch: 18\tFidelity = 0.500530\tKL_Divergence = 3.956048\n",
      "Epoch: 19\tFidelity = 0.500653\tKL_Divergence = 3.840431\n",
      "Epoch: 20\tFidelity = 0.500651\tKL_Divergence = 3.842194\n",
      "Epoch: 21\tFidelity = 0.500658\tKL_Divergence = 3.836697\n",
      "Epoch: 22\tFidelity = 0.500594\tKL_Divergence = 3.893071\n",
      "Epoch: 23\tFidelity = 0.500581\tKL_Divergence = 3.905311\n",
      "Epoch: 24\tFidelity = 0.500603\tKL_Divergence = 3.884657\n",
      "Epoch: 25\tFidelity = 0.500682\tKL_Divergence = 3.816678\n",
      "Epoch: 26\tFidelity = 0.500561\tKL_Divergence = 3.925108\n",
      "Epoch: 27\tFidelity = 0.500602\tKL_Divergence = 3.885439\n",
      "Epoch: 28\tFidelity = 0.500622\tKL_Divergence = 3.867681\n",
      "Epoch: 29\tFidelity = 0.500676\tKL_Divergence = 3.821162\n",
      "Epoch: 30\tFidelity = 0.500659\tKL_Divergence = 3.835052\n",
      "Epoch: 31\tFidelity = 0.500595\tKL_Divergence = 3.891792\n",
      "Epoch: 32\tFidelity = 0.500566\tKL_Divergence = 3.919837\n",
      "Epoch: 33\tFidelity = 0.500689\tKL_Divergence = 3.811253\n",
      "Epoch: 34\tFidelity = 0.500492\tKL_Divergence = 3.998322\n",
      "Epoch: 35\tFidelity = 0.500583\tKL_Divergence = 3.904091\n",
      "Epoch: 36\tFidelity = 0.500555\tKL_Divergence = 3.930923\n",
      "Epoch: 37\tFidelity = 0.500564\tKL_Divergence = 3.922508\n",
      "Epoch: 38\tFidelity = 0.500550\tKL_Divergence = 3.935878\n",
      "Epoch: 39\tFidelity = 0.500554\tKL_Divergence = 3.932062\n",
      "Epoch: 40\tFidelity = 0.500557\tKL_Divergence = 3.928314\n",
      "Epoch: 41\tFidelity = 0.500620\tKL_Divergence = 3.869545\n",
      "Epoch: 42\tFidelity = 0.500541\tKL_Divergence = 3.945210\n",
      "Epoch: 43\tFidelity = 0.500588\tKL_Divergence = 3.898794\n",
      "Epoch: 44\tFidelity = 0.500684\tKL_Divergence = 3.815071\n",
      "Epoch: 45\tFidelity = 0.500594\tKL_Divergence = 3.893500\n",
      "Epoch: 46\tFidelity = 0.500568\tKL_Divergence = 3.918610\n",
      "Epoch: 47\tFidelity = 0.500629\tKL_Divergence = 3.861744\n",
      "Epoch: 48\tFidelity = 0.500472\tKL_Divergence = 4.020502\n",
      "Epoch: 49\tFidelity = 0.500552\tKL_Divergence = 3.934160\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:19:52,363] Trial 590 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500585\tKL_Divergence = 3.901637\n",
      "Total time elapsed during training: 58.157 s\n",
      "Trial 590 pruned. \n",
      "Epoch: 1\tFidelity = 0.500562\tKL_Divergence = 3.923367\n",
      "Epoch: 2\tFidelity = 0.500673\tKL_Divergence = 3.823937\n",
      "Epoch: 3\tFidelity = 0.500534\tKL_Divergence = 3.951615\n",
      "Epoch: 4\tFidelity = 0.500596\tKL_Divergence = 3.890655\n",
      "Epoch: 5\tFidelity = 0.500591\tKL_Divergence = 3.896080\n",
      "Epoch: 6\tFidelity = 0.500593\tKL_Divergence = 3.893873\n",
      "Epoch: 7\tFidelity = 0.500627\tKL_Divergence = 3.862719\n",
      "Epoch: 8\tFidelity = 0.500677\tKL_Divergence = 3.820394\n",
      "Epoch: 9\tFidelity = 0.500585\tKL_Divergence = 3.901781\n",
      "Epoch: 10\tFidelity = 0.500546\tKL_Divergence = 3.940200\n",
      "Epoch: 11\tFidelity = 0.500509\tKL_Divergence = 3.978270\n",
      "Epoch: 12\tFidelity = 0.500612\tKL_Divergence = 3.875776\n",
      "Epoch: 13\tFidelity = 0.500518\tKL_Divergence = 3.968578\n",
      "Epoch: 14\tFidelity = 0.500612\tKL_Divergence = 3.875540\n",
      "Epoch: 15\tFidelity = 0.500583\tKL_Divergence = 3.903000\n",
      "Epoch: 16\tFidelity = 0.500633\tKL_Divergence = 3.857147\n",
      "Epoch: 17\tFidelity = 0.500604\tKL_Divergence = 3.883410\n",
      "Epoch: 18\tFidelity = 0.500652\tKL_Divergence = 3.841286\n",
      "Epoch: 19\tFidelity = 0.500531\tKL_Divergence = 3.955175\n",
      "Epoch: 20\tFidelity = 0.500513\tKL_Divergence = 3.974725\n",
      "Epoch: 21\tFidelity = 0.500502\tKL_Divergence = 3.986344\n",
      "Epoch: 22\tFidelity = 0.500529\tKL_Divergence = 3.957780\n",
      "Epoch: 23\tFidelity = 0.500533\tKL_Divergence = 3.953588\n",
      "Epoch: 24\tFidelity = 0.500565\tKL_Divergence = 3.920541\n",
      "Epoch: 25\tFidelity = 0.500620\tKL_Divergence = 3.869433\n",
      "Epoch: 26\tFidelity = 0.500535\tKL_Divergence = 3.951171\n",
      "Epoch: 27\tFidelity = 0.500545\tKL_Divergence = 3.941132\n",
      "Epoch: 28\tFidelity = 0.500601\tKL_Divergence = 3.886537\n",
      "Epoch: 29\tFidelity = 0.500637\tKL_Divergence = 3.854923\n",
      "Epoch: 30\tFidelity = 0.500609\tKL_Divergence = 3.879173\n",
      "Epoch: 31\tFidelity = 0.500595\tKL_Divergence = 3.892739\n",
      "Epoch: 32\tFidelity = 0.500572\tKL_Divergence = 3.913997\n",
      "Epoch: 33\tFidelity = 0.500572\tKL_Divergence = 3.914409\n",
      "Epoch: 34\tFidelity = 0.500607\tKL_Divergence = 3.881644\n",
      "Epoch: 35\tFidelity = 0.500604\tKL_Divergence = 3.884559\n",
      "Epoch: 36\tFidelity = 0.500564\tKL_Divergence = 3.922054\n",
      "Epoch: 37\tFidelity = 0.500600\tKL_Divergence = 3.887628\n",
      "Epoch: 38\tFidelity = 0.500533\tKL_Divergence = 3.953176\n",
      "Epoch: 39\tFidelity = 0.500634\tKL_Divergence = 3.856786\n",
      "Epoch: 40\tFidelity = 0.500538\tKL_Divergence = 3.948209\n",
      "Epoch: 41\tFidelity = 0.500585\tKL_Divergence = 3.901995\n",
      "Epoch: 42\tFidelity = 0.500528\tKL_Divergence = 3.958323\n",
      "Epoch: 43\tFidelity = 0.500541\tKL_Divergence = 3.945165\n",
      "Epoch: 44\tFidelity = 0.500549\tKL_Divergence = 3.936497\n",
      "Epoch: 45\tFidelity = 0.500527\tKL_Divergence = 3.959245\n",
      "Epoch: 46\tFidelity = 0.500540\tKL_Divergence = 3.946109\n",
      "Epoch: 47\tFidelity = 0.500642\tKL_Divergence = 3.849748\n",
      "Epoch: 48\tFidelity = 0.500615\tKL_Divergence = 3.873587\n",
      "Epoch: 49\tFidelity = 0.500613\tKL_Divergence = 3.875385\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:20:30,146] Trial 591 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500598\tKL_Divergence = 3.889662\n",
      "Total time elapsed during training: 37.530 s\n",
      "Trial 591 pruned. \n",
      "Epoch: 1\tFidelity = 0.500580\tKL_Divergence = 3.906538\n",
      "Epoch: 2\tFidelity = 0.500586\tKL_Divergence = 3.900848\n",
      "Epoch: 3\tFidelity = 0.500577\tKL_Divergence = 3.909777\n",
      "Epoch: 4\tFidelity = 0.500530\tKL_Divergence = 3.956926\n",
      "Epoch: 5\tFidelity = 0.500576\tKL_Divergence = 3.909862\n",
      "Epoch: 6\tFidelity = 0.500639\tKL_Divergence = 3.852807\n",
      "Epoch: 7\tFidelity = 0.500579\tKL_Divergence = 3.907239\n",
      "Epoch: 8\tFidelity = 0.500567\tKL_Divergence = 3.919148\n",
      "Epoch: 9\tFidelity = 0.500559\tKL_Divergence = 3.926884\n",
      "Epoch: 10\tFidelity = 0.500542\tKL_Divergence = 3.944660\n",
      "Epoch: 11\tFidelity = 0.500671\tKL_Divergence = 3.826015\n",
      "Epoch: 12\tFidelity = 0.500550\tKL_Divergence = 3.936379\n",
      "Epoch: 13\tFidelity = 0.500612\tKL_Divergence = 3.876906\n",
      "Epoch: 14\tFidelity = 0.500498\tKL_Divergence = 3.991661\n",
      "Epoch: 15\tFidelity = 0.500507\tKL_Divergence = 3.981066\n",
      "Epoch: 16\tFidelity = 0.500578\tKL_Divergence = 3.908134\n",
      "Epoch: 17\tFidelity = 0.500526\tKL_Divergence = 3.961079\n",
      "Epoch: 18\tFidelity = 0.500615\tKL_Divergence = 3.874484\n",
      "Epoch: 19\tFidelity = 0.500540\tKL_Divergence = 3.946802\n",
      "Epoch: 20\tFidelity = 0.500591\tKL_Divergence = 3.895848\n",
      "Epoch: 21\tFidelity = 0.500513\tKL_Divergence = 3.974626\n",
      "Epoch: 22\tFidelity = 0.500571\tKL_Divergence = 3.914868\n",
      "Epoch: 23\tFidelity = 0.500550\tKL_Divergence = 3.936601\n",
      "Epoch: 24\tFidelity = 0.500614\tKL_Divergence = 3.875346\n",
      "Epoch: 25\tFidelity = 0.500614\tKL_Divergence = 3.875136\n",
      "Epoch: 26\tFidelity = 0.500581\tKL_Divergence = 3.905425\n",
      "Epoch: 27\tFidelity = 0.500599\tKL_Divergence = 3.889126\n",
      "Epoch: 28\tFidelity = 0.500541\tKL_Divergence = 3.945314\n",
      "Epoch: 29\tFidelity = 0.500585\tKL_Divergence = 3.901792\n",
      "Epoch: 30\tFidelity = 0.500607\tKL_Divergence = 3.880987\n",
      "Epoch: 31\tFidelity = 0.500627\tKL_Divergence = 3.863166\n",
      "Epoch: 32\tFidelity = 0.500654\tKL_Divergence = 3.839902\n",
      "Epoch: 33\tFidelity = 0.500558\tKL_Divergence = 3.927789\n",
      "Epoch: 34\tFidelity = 0.500589\tKL_Divergence = 3.898215\n",
      "Epoch: 35\tFidelity = 0.500588\tKL_Divergence = 3.899428\n",
      "Epoch: 36\tFidelity = 0.500560\tKL_Divergence = 3.925849\n",
      "Epoch: 37\tFidelity = 0.500548\tKL_Divergence = 3.938300\n",
      "Epoch: 38\tFidelity = 0.500588\tKL_Divergence = 3.898567\n",
      "Epoch: 39\tFidelity = 0.500558\tKL_Divergence = 3.928319\n",
      "Epoch: 40\tFidelity = 0.500632\tKL_Divergence = 3.859232\n",
      "Epoch: 41\tFidelity = 0.500559\tKL_Divergence = 3.926644\n",
      "Epoch: 42\tFidelity = 0.500695\tKL_Divergence = 3.806031\n",
      "Epoch: 43\tFidelity = 0.500689\tKL_Divergence = 3.811046\n",
      "Epoch: 44\tFidelity = 0.500686\tKL_Divergence = 3.813472\n",
      "Epoch: 45\tFidelity = 0.500607\tKL_Divergence = 3.881727\n",
      "Epoch: 46\tFidelity = 0.500586\tKL_Divergence = 3.901133\n",
      "Epoch: 47\tFidelity = 0.500564\tKL_Divergence = 3.922441\n",
      "Epoch: 48\tFidelity = 0.500617\tKL_Divergence = 3.871922\n",
      "Epoch: 49\tFidelity = 0.500552\tKL_Divergence = 3.934097\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:21:49,778] Trial 592 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500628\tKL_Divergence = 3.862835\n",
      "Total time elapsed during training: 79.449 s\n",
      "Trial 592 pruned. \n",
      "Epoch: 1\tFidelity = 0.500636\tKL_Divergence = 3.855818\n",
      "Epoch: 2\tFidelity = 0.500603\tKL_Divergence = 3.885258\n",
      "Epoch: 3\tFidelity = 0.500612\tKL_Divergence = 3.876985\n",
      "Epoch: 4\tFidelity = 0.500579\tKL_Divergence = 3.907643\n",
      "Epoch: 5\tFidelity = 0.500609\tKL_Divergence = 3.879317\n",
      "Epoch: 6\tFidelity = 0.500606\tKL_Divergence = 3.881926\n",
      "Epoch: 7\tFidelity = 0.500620\tKL_Divergence = 3.869268\n",
      "Epoch: 8\tFidelity = 0.500624\tKL_Divergence = 3.865940\n",
      "Epoch: 9\tFidelity = 0.500576\tKL_Divergence = 3.910408\n",
      "Epoch: 10\tFidelity = 0.500603\tKL_Divergence = 3.884736\n",
      "Epoch: 11\tFidelity = 0.500631\tKL_Divergence = 3.859371\n",
      "Epoch: 12\tFidelity = 0.500604\tKL_Divergence = 3.883875\n",
      "Epoch: 13\tFidelity = 0.500638\tKL_Divergence = 3.853978\n",
      "Epoch: 14\tFidelity = 0.500649\tKL_Divergence = 3.844516\n",
      "Epoch: 15\tFidelity = 0.500626\tKL_Divergence = 3.864197\n",
      "Epoch: 16\tFidelity = 0.500595\tKL_Divergence = 3.892241\n",
      "Epoch: 17\tFidelity = 0.500603\tKL_Divergence = 3.885137\n",
      "Epoch: 18\tFidelity = 0.500574\tKL_Divergence = 3.912694\n",
      "Epoch: 19\tFidelity = 0.500594\tKL_Divergence = 3.893153\n",
      "Epoch: 20\tFidelity = 0.500601\tKL_Divergence = 3.886373\n",
      "Epoch: 21\tFidelity = 0.500638\tKL_Divergence = 3.854056\n",
      "Epoch: 22\tFidelity = 0.500600\tKL_Divergence = 3.887598\n",
      "Epoch: 23\tFidelity = 0.500610\tKL_Divergence = 3.878708\n",
      "Epoch: 24\tFidelity = 0.500554\tKL_Divergence = 3.931679\n",
      "Epoch: 25\tFidelity = 0.500563\tKL_Divergence = 3.922702\n",
      "Epoch: 26\tFidelity = 0.500587\tKL_Divergence = 3.899543\n",
      "Epoch: 27\tFidelity = 0.500592\tKL_Divergence = 3.894734\n",
      "Epoch: 28\tFidelity = 0.500595\tKL_Divergence = 3.892399\n",
      "Epoch: 29\tFidelity = 0.500615\tKL_Divergence = 3.874080\n",
      "Epoch: 30\tFidelity = 0.500612\tKL_Divergence = 3.877090\n",
      "Epoch: 31\tFidelity = 0.500607\tKL_Divergence = 3.881371\n",
      "Epoch: 32\tFidelity = 0.500582\tKL_Divergence = 3.904237\n",
      "Epoch: 33\tFidelity = 0.500564\tKL_Divergence = 3.921889\n",
      "Epoch: 34\tFidelity = 0.500597\tKL_Divergence = 3.890563\n",
      "Epoch: 35\tFidelity = 0.500566\tKL_Divergence = 3.920392\n",
      "Epoch: 36\tFidelity = 0.500608\tKL_Divergence = 3.879998\n",
      "Epoch: 37\tFidelity = 0.500616\tKL_Divergence = 3.873582\n",
      "Epoch: 38\tFidelity = 0.500582\tKL_Divergence = 3.904807\n",
      "Epoch: 39\tFidelity = 0.500568\tKL_Divergence = 3.917795\n",
      "Epoch: 40\tFidelity = 0.500548\tKL_Divergence = 3.937699\n",
      "Epoch: 41\tFidelity = 0.500632\tKL_Divergence = 3.859335\n",
      "Epoch: 42\tFidelity = 0.500620\tKL_Divergence = 3.869770\n",
      "Epoch: 43\tFidelity = 0.500571\tKL_Divergence = 3.915335\n",
      "Epoch: 44\tFidelity = 0.500600\tKL_Divergence = 3.887535\n",
      "Epoch: 45\tFidelity = 0.500589\tKL_Divergence = 3.897993\n",
      "Epoch: 46\tFidelity = 0.500614\tKL_Divergence = 3.874761\n",
      "Epoch: 47\tFidelity = 0.500586\tKL_Divergence = 3.900869\n",
      "Epoch: 48\tFidelity = 0.500582\tKL_Divergence = 3.904456\n",
      "Epoch: 49\tFidelity = 0.500593\tKL_Divergence = 3.893829\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:22:27,980] Trial 593 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500588\tKL_Divergence = 3.898838\n",
      "Total time elapsed during training: 38.017 s\n",
      "Trial 593 pruned. \n",
      "Epoch: 1\tFidelity = 0.500501\tKL_Divergence = 3.988085\n",
      "Epoch: 2\tFidelity = 0.500563\tKL_Divergence = 3.922988\n",
      "Epoch: 3\tFidelity = 0.500725\tKL_Divergence = 3.782454\n",
      "Epoch: 4\tFidelity = 0.500609\tKL_Divergence = 3.879917\n",
      "Epoch: 5\tFidelity = 0.500729\tKL_Divergence = 3.779418\n",
      "Epoch: 6\tFidelity = 0.500564\tKL_Divergence = 3.922142\n",
      "Epoch: 7\tFidelity = 0.500620\tKL_Divergence = 3.869933\n",
      "Epoch: 8\tFidelity = 0.500447\tKL_Divergence = 4.050749\n",
      "Epoch: 9\tFidelity = 0.500672\tKL_Divergence = 3.824530\n",
      "Epoch: 10\tFidelity = 0.500513\tKL_Divergence = 3.974958\n",
      "Epoch: 11\tFidelity = 0.500620\tKL_Divergence = 3.869836\n",
      "Epoch: 12\tFidelity = 0.500616\tKL_Divergence = 3.873254\n",
      "Epoch: 13\tFidelity = 0.500521\tKL_Divergence = 3.966288\n",
      "Epoch: 14\tFidelity = 0.500792\tKL_Divergence = 3.733582\n",
      "Epoch: 15\tFidelity = 0.500479\tKL_Divergence = 4.013130\n",
      "Epoch: 16\tFidelity = 0.500526\tKL_Divergence = 3.961204\n",
      "Epoch: 17\tFidelity = 0.500602\tKL_Divergence = 3.885885\n",
      "Epoch: 18\tFidelity = 0.500587\tKL_Divergence = 3.899579\n",
      "Epoch: 19\tFidelity = 0.500591\tKL_Divergence = 3.896459\n",
      "Epoch: 20\tFidelity = 0.500516\tKL_Divergence = 3.971925\n",
      "Epoch: 21\tFidelity = 0.500617\tKL_Divergence = 3.872747\n",
      "Epoch: 22\tFidelity = 0.500522\tKL_Divergence = 3.965054\n",
      "Epoch: 23\tFidelity = 0.500713\tKL_Divergence = 3.792306\n",
      "Epoch: 24\tFidelity = 0.500541\tKL_Divergence = 3.945293\n",
      "Epoch: 25\tFidelity = 0.500588\tKL_Divergence = 3.899385\n",
      "Epoch: 26\tFidelity = 0.500547\tKL_Divergence = 3.939125\n",
      "Epoch: 27\tFidelity = 0.500575\tKL_Divergence = 3.911567\n",
      "Epoch: 28\tFidelity = 0.500507\tKL_Divergence = 3.980826\n",
      "Epoch: 29\tFidelity = 0.500630\tKL_Divergence = 3.860346\n",
      "Epoch: 30\tFidelity = 0.500547\tKL_Divergence = 3.939401\n",
      "Epoch: 31\tFidelity = 0.500536\tKL_Divergence = 3.950879\n",
      "Epoch: 32\tFidelity = 0.500474\tKL_Divergence = 4.018536\n",
      "Epoch: 33\tFidelity = 0.500556\tKL_Divergence = 3.929657\n",
      "Epoch: 34\tFidelity = 0.500688\tKL_Divergence = 3.811805\n",
      "Epoch: 35\tFidelity = 0.500589\tKL_Divergence = 3.898449\n",
      "Epoch: 36\tFidelity = 0.500637\tKL_Divergence = 3.854455\n",
      "Epoch: 37\tFidelity = 0.500510\tKL_Divergence = 3.977657\n",
      "Epoch: 38\tFidelity = 0.500671\tKL_Divergence = 3.826030\n",
      "Epoch: 39\tFidelity = 0.500561\tKL_Divergence = 3.924775\n",
      "Epoch: 40\tFidelity = 0.500626\tKL_Divergence = 3.864042\n",
      "Epoch: 41\tFidelity = 0.500694\tKL_Divergence = 3.806824\n",
      "Epoch: 42\tFidelity = 0.500527\tKL_Divergence = 3.959778\n",
      "Epoch: 43\tFidelity = 0.500587\tKL_Divergence = 3.900390\n",
      "Epoch: 44\tFidelity = 0.500609\tKL_Divergence = 3.880064\n",
      "Epoch: 45\tFidelity = 0.500487\tKL_Divergence = 4.003596\n",
      "Epoch: 46\tFidelity = 0.500535\tKL_Divergence = 3.951284\n",
      "Epoch: 47\tFidelity = 0.500581\tKL_Divergence = 3.905639\n",
      "Epoch: 48\tFidelity = 0.500636\tKL_Divergence = 3.855766\n",
      "Epoch: 49\tFidelity = 0.500605\tKL_Divergence = 3.883070\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:22:59,969] Trial 594 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500584\tKL_Divergence = 3.902826\n",
      "Total time elapsed during training: 31.808 s\n",
      "Trial 594 pruned. \n",
      "Epoch: 1\tFidelity = 0.500526\tKL_Divergence = 3.960429\n",
      "Epoch: 2\tFidelity = 0.500594\tKL_Divergence = 3.893338\n",
      "Epoch: 3\tFidelity = 0.500579\tKL_Divergence = 3.907804\n",
      "Epoch: 4\tFidelity = 0.500579\tKL_Divergence = 3.907634\n",
      "Epoch: 5\tFidelity = 0.500568\tKL_Divergence = 3.918529\n",
      "Epoch: 6\tFidelity = 0.500576\tKL_Divergence = 3.910549\n",
      "Epoch: 7\tFidelity = 0.500560\tKL_Divergence = 3.926515\n",
      "Epoch: 8\tFidelity = 0.500645\tKL_Divergence = 3.847403\n",
      "Epoch: 9\tFidelity = 0.500568\tKL_Divergence = 3.918215\n",
      "Epoch: 10\tFidelity = 0.500613\tKL_Divergence = 3.875740\n",
      "Epoch: 11\tFidelity = 0.500561\tKL_Divergence = 3.925396\n",
      "Epoch: 12\tFidelity = 0.500572\tKL_Divergence = 3.914153\n",
      "Epoch: 13\tFidelity = 0.500538\tKL_Divergence = 3.948330\n",
      "Epoch: 14\tFidelity = 0.500621\tKL_Divergence = 3.868337\n",
      "Epoch: 15\tFidelity = 0.500594\tKL_Divergence = 3.893202\n",
      "Epoch: 16\tFidelity = 0.500530\tKL_Divergence = 3.957098\n",
      "Epoch: 17\tFidelity = 0.500582\tKL_Divergence = 3.904441\n",
      "Epoch: 18\tFidelity = 0.500595\tKL_Divergence = 3.892669\n",
      "Epoch: 19\tFidelity = 0.500621\tKL_Divergence = 3.869162\n",
      "Epoch: 20\tFidelity = 0.500609\tKL_Divergence = 3.879367\n",
      "Epoch: 21\tFidelity = 0.500539\tKL_Divergence = 3.947306\n",
      "Epoch: 22\tFidelity = 0.500613\tKL_Divergence = 3.876074\n",
      "Epoch: 23\tFidelity = 0.500594\tKL_Divergence = 3.893685\n",
      "Epoch: 24\tFidelity = 0.500564\tKL_Divergence = 3.921742\n",
      "Epoch: 25\tFidelity = 0.500593\tKL_Divergence = 3.894622\n",
      "Epoch: 26\tFidelity = 0.500538\tKL_Divergence = 3.948397\n",
      "Epoch: 27\tFidelity = 0.500616\tKL_Divergence = 3.872988\n",
      "Epoch: 28\tFidelity = 0.500555\tKL_Divergence = 3.930752\n",
      "Epoch: 29\tFidelity = 0.500565\tKL_Divergence = 3.921424\n",
      "Epoch: 30\tFidelity = 0.500528\tKL_Divergence = 3.958212\n",
      "Epoch: 31\tFidelity = 0.500573\tKL_Divergence = 3.913672\n",
      "Epoch: 32\tFidelity = 0.500553\tKL_Divergence = 3.933015\n",
      "Epoch: 33\tFidelity = 0.500600\tKL_Divergence = 3.887452\n",
      "Epoch: 34\tFidelity = 0.500600\tKL_Divergence = 3.887457\n",
      "Epoch: 35\tFidelity = 0.500657\tKL_Divergence = 3.837848\n",
      "Epoch: 36\tFidelity = 0.500595\tKL_Divergence = 3.892782\n",
      "Epoch: 37\tFidelity = 0.500531\tKL_Divergence = 3.955376\n",
      "Epoch: 38\tFidelity = 0.500594\tKL_Divergence = 3.892960\n",
      "Epoch: 39\tFidelity = 0.500520\tKL_Divergence = 3.966797\n",
      "Epoch: 40\tFidelity = 0.500653\tKL_Divergence = 3.840702\n",
      "Epoch: 41\tFidelity = 0.500554\tKL_Divergence = 3.932323\n",
      "Epoch: 42\tFidelity = 0.500600\tKL_Divergence = 3.887738\n",
      "Epoch: 43\tFidelity = 0.500530\tKL_Divergence = 3.956402\n",
      "Epoch: 44\tFidelity = 0.500600\tKL_Divergence = 3.888008\n",
      "Epoch: 45\tFidelity = 0.500608\tKL_Divergence = 3.880176\n",
      "Epoch: 46\tFidelity = 0.500647\tKL_Divergence = 3.846202\n",
      "Epoch: 47\tFidelity = 0.500656\tKL_Divergence = 3.838368\n",
      "Epoch: 48\tFidelity = 0.500580\tKL_Divergence = 3.906859\n",
      "Epoch: 49\tFidelity = 0.500637\tKL_Divergence = 3.854976\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:23:31,263] Trial 595 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500565\tKL_Divergence = 3.921280\n",
      "Total time elapsed during training: 31.115 s\n",
      "Trial 595 pruned. \n",
      "Epoch: 1\tFidelity = 0.500635\tKL_Divergence = 3.856668\n",
      "Epoch: 2\tFidelity = 0.500550\tKL_Divergence = 3.936185\n",
      "Epoch: 3\tFidelity = 0.500566\tKL_Divergence = 3.920496\n",
      "Epoch: 4\tFidelity = 0.500609\tKL_Divergence = 3.879415\n",
      "Epoch: 5\tFidelity = 0.500538\tKL_Divergence = 3.947850\n",
      "Epoch: 6\tFidelity = 0.500601\tKL_Divergence = 3.886872\n",
      "Epoch: 7\tFidelity = 0.500605\tKL_Divergence = 3.883503\n",
      "Epoch: 8\tFidelity = 0.500610\tKL_Divergence = 3.879046\n",
      "Epoch: 9\tFidelity = 0.500520\tKL_Divergence = 3.967255\n",
      "Epoch: 10\tFidelity = 0.500639\tKL_Divergence = 3.852815\n",
      "Epoch: 11\tFidelity = 0.500562\tKL_Divergence = 3.924379\n",
      "Epoch: 12\tFidelity = 0.500549\tKL_Divergence = 3.937114\n",
      "Epoch: 13\tFidelity = 0.500528\tKL_Divergence = 3.959278\n",
      "Epoch: 14\tFidelity = 0.500548\tKL_Divergence = 3.938002\n",
      "Epoch: 15\tFidelity = 0.500573\tKL_Divergence = 3.913437\n",
      "Epoch: 16\tFidelity = 0.500599\tKL_Divergence = 3.889188\n",
      "Epoch: 17\tFidelity = 0.500531\tKL_Divergence = 3.955991\n",
      "Epoch: 18\tFidelity = 0.500572\tKL_Divergence = 3.913947\n",
      "Epoch: 19\tFidelity = 0.500540\tKL_Divergence = 3.945942\n",
      "Epoch: 20\tFidelity = 0.500540\tKL_Divergence = 3.946780\n",
      "Epoch: 21\tFidelity = 0.500579\tKL_Divergence = 3.907551\n",
      "Epoch: 22\tFidelity = 0.500549\tKL_Divergence = 3.937203\n",
      "Epoch: 23\tFidelity = 0.500546\tKL_Divergence = 3.940468\n",
      "Epoch: 24\tFidelity = 0.500550\tKL_Divergence = 3.936504\n",
      "Epoch: 25\tFidelity = 0.500535\tKL_Divergence = 3.951552\n",
      "Epoch: 26\tFidelity = 0.500547\tKL_Divergence = 3.939552\n",
      "Epoch: 27\tFidelity = 0.500513\tKL_Divergence = 3.974445\n",
      "Epoch: 28\tFidelity = 0.500500\tKL_Divergence = 3.989105\n",
      "Epoch: 29\tFidelity = 0.500518\tKL_Divergence = 3.969667\n",
      "Epoch: 30\tFidelity = 0.500508\tKL_Divergence = 3.980610\n",
      "Epoch: 31\tFidelity = 0.500546\tKL_Divergence = 3.940167\n",
      "Epoch: 32\tFidelity = 0.500548\tKL_Divergence = 3.937772\n",
      "Epoch: 33\tFidelity = 0.500576\tKL_Divergence = 3.910817\n",
      "Epoch: 34\tFidelity = 0.500548\tKL_Divergence = 3.937745\n",
      "Epoch: 35\tFidelity = 0.500597\tKL_Divergence = 3.890580\n",
      "Epoch: 36\tFidelity = 0.500559\tKL_Divergence = 3.927051\n",
      "Epoch: 37\tFidelity = 0.500547\tKL_Divergence = 3.938804\n",
      "Epoch: 38\tFidelity = 0.500564\tKL_Divergence = 3.922291\n",
      "Epoch: 39\tFidelity = 0.500501\tKL_Divergence = 3.988517\n",
      "Epoch: 40\tFidelity = 0.500528\tKL_Divergence = 3.958507\n",
      "Epoch: 41\tFidelity = 0.500502\tKL_Divergence = 3.986786\n",
      "Epoch: 42\tFidelity = 0.500547\tKL_Divergence = 3.939160\n",
      "Epoch: 43\tFidelity = 0.500548\tKL_Divergence = 3.937952\n",
      "Epoch: 44\tFidelity = 0.500591\tKL_Divergence = 3.896300\n",
      "Epoch: 45\tFidelity = 0.500558\tKL_Divergence = 3.927715\n",
      "Epoch: 46\tFidelity = 0.500537\tKL_Divergence = 3.949277\n",
      "Epoch: 47\tFidelity = 0.500554\tKL_Divergence = 3.932084\n",
      "Epoch: 48\tFidelity = 0.500605\tKL_Divergence = 3.882869\n",
      "Epoch: 49\tFidelity = 0.500517\tKL_Divergence = 3.970722\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:24:15,968] Trial 596 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500540\tKL_Divergence = 3.946186\n",
      "Total time elapsed during training: 44.506 s\n",
      "Trial 596 pruned. \n",
      "Epoch: 1\tFidelity = 0.500599\tKL_Divergence = 3.888711\n",
      "Epoch: 2\tFidelity = 0.500561\tKL_Divergence = 3.925506\n",
      "Epoch: 3\tFidelity = 0.500529\tKL_Divergence = 3.958169\n",
      "Epoch: 4\tFidelity = 0.500529\tKL_Divergence = 3.957393\n",
      "Epoch: 5\tFidelity = 0.500560\tKL_Divergence = 3.926433\n",
      "Epoch: 6\tFidelity = 0.500596\tKL_Divergence = 3.891649\n",
      "Epoch: 7\tFidelity = 0.500578\tKL_Divergence = 3.908194\n",
      "Epoch: 8\tFidelity = 0.500562\tKL_Divergence = 3.924601\n",
      "Epoch: 9\tFidelity = 0.500596\tKL_Divergence = 3.891638\n",
      "Epoch: 10\tFidelity = 0.500567\tKL_Divergence = 3.919683\n",
      "Epoch: 11\tFidelity = 0.500532\tKL_Divergence = 3.955005\n",
      "Epoch: 12\tFidelity = 0.500631\tKL_Divergence = 3.859592\n",
      "Epoch: 13\tFidelity = 0.500516\tKL_Divergence = 3.971696\n",
      "Epoch: 14\tFidelity = 0.500559\tKL_Divergence = 3.927101\n",
      "Epoch: 15\tFidelity = 0.500588\tKL_Divergence = 3.898652\n",
      "Epoch: 16\tFidelity = 0.500607\tKL_Divergence = 3.881800\n",
      "Epoch: 17\tFidelity = 0.500492\tKL_Divergence = 3.998025\n",
      "Epoch: 18\tFidelity = 0.500525\tKL_Divergence = 3.962343\n",
      "Epoch: 19\tFidelity = 0.500552\tKL_Divergence = 3.934532\n",
      "Epoch: 20\tFidelity = 0.500599\tKL_Divergence = 3.888928\n",
      "Epoch: 21\tFidelity = 0.500525\tKL_Divergence = 3.962180\n",
      "Epoch: 22\tFidelity = 0.500565\tKL_Divergence = 3.921430\n",
      "Epoch: 23\tFidelity = 0.500502\tKL_Divergence = 3.986749\n",
      "Epoch: 24\tFidelity = 0.500504\tKL_Divergence = 3.985084\n",
      "Epoch: 25\tFidelity = 0.500543\tKL_Divergence = 3.942820\n",
      "Epoch: 26\tFidelity = 0.500590\tKL_Divergence = 3.897672\n",
      "Epoch: 27\tFidelity = 0.500578\tKL_Divergence = 3.908861\n",
      "Epoch: 28\tFidelity = 0.500546\tKL_Divergence = 3.940596\n",
      "Epoch: 29\tFidelity = 0.500604\tKL_Divergence = 3.883914\n",
      "Epoch: 30\tFidelity = 0.500554\tKL_Divergence = 3.932671\n",
      "Epoch: 31\tFidelity = 0.500536\tKL_Divergence = 3.950729\n",
      "Epoch: 32\tFidelity = 0.500501\tKL_Divergence = 3.987741\n",
      "Epoch: 33\tFidelity = 0.500518\tKL_Divergence = 3.968986\n",
      "Epoch: 34\tFidelity = 0.500549\tKL_Divergence = 3.937182\n",
      "Epoch: 35\tFidelity = 0.500546\tKL_Divergence = 3.940531\n",
      "Epoch: 36\tFidelity = 0.500501\tKL_Divergence = 3.987897\n",
      "Epoch: 37\tFidelity = 0.500545\tKL_Divergence = 3.941464\n",
      "Epoch: 38\tFidelity = 0.500539\tKL_Divergence = 3.946926\n",
      "Epoch: 39\tFidelity = 0.500555\tKL_Divergence = 3.930499\n",
      "Epoch: 40\tFidelity = 0.500512\tKL_Divergence = 3.976205\n",
      "Epoch: 41\tFidelity = 0.500581\tKL_Divergence = 3.905578\n",
      "Epoch: 42\tFidelity = 0.500545\tKL_Divergence = 3.941366\n",
      "Epoch: 43\tFidelity = 0.500511\tKL_Divergence = 3.976900\n",
      "Epoch: 44\tFidelity = 0.500555\tKL_Divergence = 3.930547\n",
      "Epoch: 45\tFidelity = 0.500528\tKL_Divergence = 3.958374\n",
      "Epoch: 46\tFidelity = 0.500543\tKL_Divergence = 3.942949\n",
      "Epoch: 47\tFidelity = 0.500539\tKL_Divergence = 3.947728\n",
      "Epoch: 48\tFidelity = 0.500498\tKL_Divergence = 3.991529\n",
      "Epoch: 49\tFidelity = 0.500543\tKL_Divergence = 3.943108\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:24:53,526] Trial 597 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500535\tKL_Divergence = 3.951598\n",
      "Total time elapsed during training: 37.376 s\n",
      "Trial 597 pruned. \n",
      "Epoch: 1\tFidelity = 0.500584\tKL_Divergence = 3.902494\n",
      "Epoch: 2\tFidelity = 0.500514\tKL_Divergence = 3.973338\n",
      "Epoch: 3\tFidelity = 0.500531\tKL_Divergence = 3.955738\n",
      "Epoch: 4\tFidelity = 0.500518\tKL_Divergence = 3.969074\n",
      "Epoch: 5\tFidelity = 0.500523\tKL_Divergence = 3.963884\n",
      "Epoch: 6\tFidelity = 0.500578\tKL_Divergence = 3.908273\n",
      "Epoch: 7\tFidelity = 0.500496\tKL_Divergence = 3.993641\n",
      "Epoch: 8\tFidelity = 0.500546\tKL_Divergence = 3.940580\n",
      "Epoch: 9\tFidelity = 0.500542\tKL_Divergence = 3.944171\n",
      "Epoch: 10\tFidelity = 0.500594\tKL_Divergence = 3.893329\n",
      "Epoch: 11\tFidelity = 0.500532\tKL_Divergence = 3.954636\n",
      "Epoch: 12\tFidelity = 0.500536\tKL_Divergence = 3.950378\n",
      "Epoch: 13\tFidelity = 0.500522\tKL_Divergence = 3.964940\n",
      "Epoch: 14\tFidelity = 0.500464\tKL_Divergence = 4.029983\n",
      "Epoch: 15\tFidelity = 0.500572\tKL_Divergence = 3.914526\n",
      "Epoch: 16\tFidelity = 0.500552\tKL_Divergence = 3.933764\n",
      "Epoch: 17\tFidelity = 0.500542\tKL_Divergence = 3.944524\n",
      "Epoch: 18\tFidelity = 0.500498\tKL_Divergence = 3.991241\n",
      "Epoch: 19\tFidelity = 0.500551\tKL_Divergence = 3.935183\n",
      "Epoch: 20\tFidelity = 0.500507\tKL_Divergence = 3.981700\n",
      "Epoch: 21\tFidelity = 0.500577\tKL_Divergence = 3.909642\n",
      "Epoch: 22\tFidelity = 0.500523\tKL_Divergence = 3.964613\n",
      "Epoch: 23\tFidelity = 0.500537\tKL_Divergence = 3.949209\n",
      "Epoch: 24\tFidelity = 0.500561\tKL_Divergence = 3.925570\n",
      "Epoch: 25\tFidelity = 0.500534\tKL_Divergence = 3.952256\n",
      "Epoch: 26\tFidelity = 0.500534\tKL_Divergence = 3.952589\n",
      "Epoch: 27\tFidelity = 0.500502\tKL_Divergence = 3.986798\n",
      "Epoch: 28\tFidelity = 0.500523\tKL_Divergence = 3.964392\n",
      "Epoch: 29\tFidelity = 0.500534\tKL_Divergence = 3.952153\n",
      "Epoch: 30\tFidelity = 0.500556\tKL_Divergence = 3.930226\n",
      "Epoch: 31\tFidelity = 0.500540\tKL_Divergence = 3.945924\n",
      "Epoch: 32\tFidelity = 0.500554\tKL_Divergence = 3.932247\n",
      "Epoch: 33\tFidelity = 0.500578\tKL_Divergence = 3.908636\n",
      "Epoch: 34\tFidelity = 0.500565\tKL_Divergence = 3.921452\n",
      "Epoch: 35\tFidelity = 0.500555\tKL_Divergence = 3.931375\n",
      "Epoch: 36\tFidelity = 0.500511\tKL_Divergence = 3.977364\n",
      "Epoch: 37\tFidelity = 0.500517\tKL_Divergence = 3.970049\n",
      "Epoch: 38\tFidelity = 0.500536\tKL_Divergence = 3.950600\n",
      "Epoch: 39\tFidelity = 0.500530\tKL_Divergence = 3.957178\n",
      "Epoch: 40\tFidelity = 0.500537\tKL_Divergence = 3.949787\n",
      "Epoch: 41\tFidelity = 0.500534\tKL_Divergence = 3.952367\n",
      "Epoch: 42\tFidelity = 0.500560\tKL_Divergence = 3.926216\n",
      "Epoch: 43\tFidelity = 0.500530\tKL_Divergence = 3.956544\n",
      "Epoch: 44\tFidelity = 0.500525\tKL_Divergence = 3.961575\n",
      "Epoch: 45\tFidelity = 0.500555\tKL_Divergence = 3.930699\n",
      "Epoch: 46\tFidelity = 0.500561\tKL_Divergence = 3.924857\n",
      "Epoch: 47\tFidelity = 0.500547\tKL_Divergence = 3.939298\n",
      "Epoch: 48\tFidelity = 0.500513\tKL_Divergence = 3.974753\n",
      "Epoch: 49\tFidelity = 0.500595\tKL_Divergence = 3.892573\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:25:31,562] Trial 598 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500591\tKL_Divergence = 3.896043\n",
      "Total time elapsed during training: 37.849 s\n",
      "Trial 598 pruned. \n",
      "Epoch: 1\tFidelity = 0.500584\tKL_Divergence = 3.902694\n",
      "Epoch: 2\tFidelity = 0.500508\tKL_Divergence = 3.980343\n",
      "Epoch: 3\tFidelity = 0.500535\tKL_Divergence = 3.952021\n",
      "Epoch: 4\tFidelity = 0.500567\tKL_Divergence = 3.919688\n",
      "Epoch: 5\tFidelity = 0.500527\tKL_Divergence = 3.959413\n",
      "Epoch: 6\tFidelity = 0.500572\tKL_Divergence = 3.914679\n",
      "Epoch: 7\tFidelity = 0.500577\tKL_Divergence = 3.909240\n",
      "Epoch: 8\tFidelity = 0.500522\tKL_Divergence = 3.964955\n",
      "Epoch: 9\tFidelity = 0.500556\tKL_Divergence = 3.929719\n",
      "Epoch: 10\tFidelity = 0.500541\tKL_Divergence = 3.945341\n",
      "Epoch: 11\tFidelity = 0.500532\tKL_Divergence = 3.954317\n",
      "Epoch: 12\tFidelity = 0.500572\tKL_Divergence = 3.914397\n",
      "Epoch: 13\tFidelity = 0.500546\tKL_Divergence = 3.939805\n",
      "Epoch: 14\tFidelity = 0.500538\tKL_Divergence = 3.948918\n",
      "Epoch: 15\tFidelity = 0.500579\tKL_Divergence = 3.907456\n",
      "Epoch: 16\tFidelity = 0.500570\tKL_Divergence = 3.916700\n",
      "Epoch: 17\tFidelity = 0.500581\tKL_Divergence = 3.905983\n",
      "Epoch: 18\tFidelity = 0.500518\tKL_Divergence = 3.969871\n",
      "Epoch: 19\tFidelity = 0.500526\tKL_Divergence = 3.961445\n",
      "Epoch: 20\tFidelity = 0.500574\tKL_Divergence = 3.912461\n",
      "Epoch: 21\tFidelity = 0.500550\tKL_Divergence = 3.936595\n",
      "Epoch: 22\tFidelity = 0.500565\tKL_Divergence = 3.921660\n",
      "Epoch: 23\tFidelity = 0.500533\tKL_Divergence = 3.953228\n",
      "Epoch: 24\tFidelity = 0.500511\tKL_Divergence = 3.977195\n",
      "Epoch: 25\tFidelity = 0.500527\tKL_Divergence = 3.959842\n",
      "Epoch: 26\tFidelity = 0.500570\tKL_Divergence = 3.915952\n",
      "Epoch: 27\tFidelity = 0.500563\tKL_Divergence = 3.923590\n",
      "Epoch: 28\tFidelity = 0.500609\tKL_Divergence = 3.879226\n",
      "Epoch: 29\tFidelity = 0.500563\tKL_Divergence = 3.922928\n",
      "Epoch: 30\tFidelity = 0.500558\tKL_Divergence = 3.928651\n",
      "Epoch: 31\tFidelity = 0.500513\tKL_Divergence = 3.974299\n",
      "Epoch: 32\tFidelity = 0.500533\tKL_Divergence = 3.953163\n",
      "Epoch: 33\tFidelity = 0.500533\tKL_Divergence = 3.953716\n",
      "Epoch: 34\tFidelity = 0.500539\tKL_Divergence = 3.947825\n",
      "Epoch: 35\tFidelity = 0.500521\tKL_Divergence = 3.966576\n",
      "Epoch: 36\tFidelity = 0.500512\tKL_Divergence = 3.976186\n",
      "Epoch: 37\tFidelity = 0.500584\tKL_Divergence = 3.902607\n",
      "Epoch: 38\tFidelity = 0.500601\tKL_Divergence = 3.887117\n",
      "Epoch: 39\tFidelity = 0.500587\tKL_Divergence = 3.900368\n",
      "Epoch: 40\tFidelity = 0.500530\tKL_Divergence = 3.956637\n",
      "Epoch: 41\tFidelity = 0.500513\tKL_Divergence = 3.974701\n",
      "Epoch: 42\tFidelity = 0.500551\tKL_Divergence = 3.935172\n",
      "Epoch: 43\tFidelity = 0.500588\tKL_Divergence = 3.899031\n",
      "Epoch: 44\tFidelity = 0.500559\tKL_Divergence = 3.927632\n",
      "Epoch: 45\tFidelity = 0.500536\tKL_Divergence = 3.950132\n",
      "Epoch: 46\tFidelity = 0.500534\tKL_Divergence = 3.952341\n",
      "Epoch: 47\tFidelity = 0.500556\tKL_Divergence = 3.929867\n",
      "Epoch: 48\tFidelity = 0.500522\tKL_Divergence = 3.964790\n",
      "Epoch: 49\tFidelity = 0.500543\tKL_Divergence = 3.942862\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:26:15,666] Trial 599 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500524\tKL_Divergence = 3.962891\n",
      "Total time elapsed during training: 43.923 s\n",
      "Trial 599 pruned. \n",
      "Epoch: 1\tFidelity = 0.500511\tKL_Divergence = 3.977280\n",
      "Epoch: 2\tFidelity = 0.500527\tKL_Divergence = 3.959894\n",
      "Epoch: 3\tFidelity = 0.500525\tKL_Divergence = 3.962306\n",
      "Epoch: 4\tFidelity = 0.500645\tKL_Divergence = 3.847791\n",
      "Epoch: 5\tFidelity = 0.500526\tKL_Divergence = 3.961146\n",
      "Epoch: 6\tFidelity = 0.500472\tKL_Divergence = 4.020760\n",
      "Epoch: 7\tFidelity = 0.500502\tKL_Divergence = 3.987115\n",
      "Epoch: 8\tFidelity = 0.500550\tKL_Divergence = 3.935807\n",
      "Epoch: 9\tFidelity = 0.500504\tKL_Divergence = 3.984092\n",
      "Epoch: 10\tFidelity = 0.500527\tKL_Divergence = 3.959750\n",
      "Epoch: 11\tFidelity = 0.500526\tKL_Divergence = 3.960960\n",
      "Epoch: 12\tFidelity = 0.500487\tKL_Divergence = 4.003127\n",
      "Epoch: 13\tFidelity = 0.500603\tKL_Divergence = 3.884724\n",
      "Epoch: 14\tFidelity = 0.500446\tKL_Divergence = 4.052541\n",
      "Epoch: 15\tFidelity = 0.500475\tKL_Divergence = 4.017820\n",
      "Epoch: 16\tFidelity = 0.500600\tKL_Divergence = 3.887960\n",
      "Epoch: 17\tFidelity = 0.500549\tKL_Divergence = 3.937470\n",
      "Epoch: 18\tFidelity = 0.500531\tKL_Divergence = 3.956159\n",
      "Epoch: 19\tFidelity = 0.500496\tKL_Divergence = 3.993246\n",
      "Epoch: 20\tFidelity = 0.500462\tKL_Divergence = 4.032410\n",
      "Epoch: 21\tFidelity = 0.500580\tKL_Divergence = 3.906992\n",
      "Epoch: 22\tFidelity = 0.500543\tKL_Divergence = 3.943413\n",
      "Epoch: 23\tFidelity = 0.500527\tKL_Divergence = 3.959576\n",
      "Epoch: 24\tFidelity = 0.500514\tKL_Divergence = 3.973938\n",
      "Epoch: 25\tFidelity = 0.500613\tKL_Divergence = 3.875825\n",
      "Epoch: 26\tFidelity = 0.500668\tKL_Divergence = 3.828599\n",
      "Epoch: 27\tFidelity = 0.500486\tKL_Divergence = 4.004861\n",
      "Epoch: 28\tFidelity = 0.500506\tKL_Divergence = 3.982002\n",
      "Epoch: 29\tFidelity = 0.500487\tKL_Divergence = 4.004099\n",
      "Epoch: 30\tFidelity = 0.500568\tKL_Divergence = 3.918151\n",
      "Epoch: 31\tFidelity = 0.500533\tKL_Divergence = 3.953105\n",
      "Epoch: 32\tFidelity = 0.500529\tKL_Divergence = 3.957733\n",
      "Epoch: 33\tFidelity = 0.500535\tKL_Divergence = 3.951882\n",
      "Epoch: 34\tFidelity = 0.500582\tKL_Divergence = 3.905279\n",
      "Epoch: 35\tFidelity = 0.500544\tKL_Divergence = 3.942013\n",
      "Epoch: 36\tFidelity = 0.500549\tKL_Divergence = 3.937203\n",
      "Epoch: 37\tFidelity = 0.500612\tKL_Divergence = 3.877003\n",
      "Epoch: 38\tFidelity = 0.500643\tKL_Divergence = 3.849677\n",
      "Epoch: 39\tFidelity = 0.500524\tKL_Divergence = 3.963457\n",
      "Epoch: 40\tFidelity = 0.500614\tKL_Divergence = 3.874784\n",
      "Epoch: 41\tFidelity = 0.500556\tKL_Divergence = 3.930605\n",
      "Epoch: 42\tFidelity = 0.500562\tKL_Divergence = 3.924067\n",
      "Epoch: 43\tFidelity = 0.500571\tKL_Divergence = 3.915214\n",
      "Epoch: 44\tFidelity = 0.500586\tKL_Divergence = 3.901003\n",
      "Epoch: 45\tFidelity = 0.500489\tKL_Divergence = 4.000825\n",
      "Epoch: 46\tFidelity = 0.500553\tKL_Divergence = 3.933248\n",
      "Epoch: 47\tFidelity = 0.500625\tKL_Divergence = 3.865461\n",
      "Epoch: 48\tFidelity = 0.500561\tKL_Divergence = 3.925461\n",
      "Epoch: 49\tFidelity = 0.500582\tKL_Divergence = 3.904413\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:26:53,520] Trial 600 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500554\tKL_Divergence = 3.932001\n",
      "Total time elapsed during training: 37.673 s\n",
      "Trial 600 pruned. \n",
      "Epoch: 1\tFidelity = 0.500566\tKL_Divergence = 3.920422\n",
      "Epoch: 2\tFidelity = 0.500590\tKL_Divergence = 3.897116\n",
      "Epoch: 3\tFidelity = 0.500595\tKL_Divergence = 3.892850\n",
      "Epoch: 4\tFidelity = 0.500467\tKL_Divergence = 4.026990\n",
      "Epoch: 5\tFidelity = 0.500596\tKL_Divergence = 3.891637\n",
      "Epoch: 6\tFidelity = 0.500549\tKL_Divergence = 3.936804\n",
      "Epoch: 7\tFidelity = 0.500551\tKL_Divergence = 3.935424\n",
      "Epoch: 8\tFidelity = 0.500513\tKL_Divergence = 3.974553\n",
      "Epoch: 9\tFidelity = 0.500590\tKL_Divergence = 3.897726\n",
      "Epoch: 10\tFidelity = 0.500532\tKL_Divergence = 3.955131\n",
      "Epoch: 11\tFidelity = 0.500536\tKL_Divergence = 3.950076\n",
      "Epoch: 12\tFidelity = 0.500603\tKL_Divergence = 3.885067\n",
      "Epoch: 13\tFidelity = 0.500605\tKL_Divergence = 3.882953\n",
      "Epoch: 14\tFidelity = 0.500550\tKL_Divergence = 3.936574\n",
      "Epoch: 15\tFidelity = 0.500550\tKL_Divergence = 3.936329\n",
      "Epoch: 16\tFidelity = 0.500610\tKL_Divergence = 3.878702\n",
      "Epoch: 17\tFidelity = 0.500583\tKL_Divergence = 3.903938\n",
      "Epoch: 18\tFidelity = 0.500569\tKL_Divergence = 3.917718\n",
      "Epoch: 19\tFidelity = 0.500588\tKL_Divergence = 3.898777\n",
      "Epoch: 20\tFidelity = 0.500567\tKL_Divergence = 3.919162\n",
      "Epoch: 21\tFidelity = 0.500512\tKL_Divergence = 3.976030\n",
      "Epoch: 22\tFidelity = 0.500498\tKL_Divergence = 3.990987\n",
      "Epoch: 23\tFidelity = 0.500569\tKL_Divergence = 3.917145\n",
      "Epoch: 24\tFidelity = 0.500538\tKL_Divergence = 3.948472\n",
      "Epoch: 25\tFidelity = 0.500578\tKL_Divergence = 3.908970\n",
      "Epoch: 26\tFidelity = 0.500582\tKL_Divergence = 3.904607\n",
      "Epoch: 27\tFidelity = 0.500600\tKL_Divergence = 3.887476\n",
      "Epoch: 28\tFidelity = 0.500548\tKL_Divergence = 3.937826\n",
      "Epoch: 29\tFidelity = 0.500557\tKL_Divergence = 3.928910\n",
      "Epoch: 30\tFidelity = 0.500551\tKL_Divergence = 3.935554\n",
      "Epoch: 31\tFidelity = 0.500581\tKL_Divergence = 3.906067\n",
      "Epoch: 32\tFidelity = 0.500485\tKL_Divergence = 4.006478\n",
      "Epoch: 33\tFidelity = 0.500569\tKL_Divergence = 3.917811\n",
      "Epoch: 34\tFidelity = 0.500589\tKL_Divergence = 3.898248\n",
      "Epoch: 35\tFidelity = 0.500616\tKL_Divergence = 3.873674\n",
      "Epoch: 36\tFidelity = 0.500499\tKL_Divergence = 3.990620\n",
      "Epoch: 37\tFidelity = 0.500559\tKL_Divergence = 3.927609\n",
      "Epoch: 38\tFidelity = 0.500560\tKL_Divergence = 3.926611\n",
      "Epoch: 39\tFidelity = 0.500605\tKL_Divergence = 3.883170\n",
      "Epoch: 40\tFidelity = 0.500583\tKL_Divergence = 3.903688\n",
      "Epoch: 41\tFidelity = 0.500617\tKL_Divergence = 3.872524\n",
      "Epoch: 42\tFidelity = 0.500613\tKL_Divergence = 3.876103\n",
      "Epoch: 43\tFidelity = 0.500630\tKL_Divergence = 3.860675\n",
      "Epoch: 44\tFidelity = 0.500536\tKL_Divergence = 3.950872\n",
      "Epoch: 45\tFidelity = 0.500576\tKL_Divergence = 3.910037\n",
      "Epoch: 46\tFidelity = 0.500632\tKL_Divergence = 3.859433\n",
      "Epoch: 47\tFidelity = 0.500562\tKL_Divergence = 3.924496\n",
      "Epoch: 48\tFidelity = 0.500590\tKL_Divergence = 3.896891\n",
      "Epoch: 49\tFidelity = 0.500586\tKL_Divergence = 3.901170\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:28:12,967] Trial 601 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500552\tKL_Divergence = 3.934088\n",
      "Total time elapsed during training: 79.263 s\n",
      "Trial 601 pruned. \n",
      "Epoch: 1\tFidelity = 0.500612\tKL_Divergence = 3.876462\n",
      "Epoch: 2\tFidelity = 0.500550\tKL_Divergence = 3.936512\n",
      "Epoch: 3\tFidelity = 0.500581\tKL_Divergence = 3.906063\n",
      "Epoch: 4\tFidelity = 0.500584\tKL_Divergence = 3.903041\n",
      "Epoch: 5\tFidelity = 0.500603\tKL_Divergence = 3.884896\n",
      "Epoch: 6\tFidelity = 0.500566\tKL_Divergence = 3.920274\n",
      "Epoch: 7\tFidelity = 0.500545\tKL_Divergence = 3.940795\n",
      "Epoch: 8\tFidelity = 0.500549\tKL_Divergence = 3.937525\n",
      "Epoch: 9\tFidelity = 0.500513\tKL_Divergence = 3.974909\n",
      "Epoch: 10\tFidelity = 0.500551\tKL_Divergence = 3.935568\n",
      "Epoch: 11\tFidelity = 0.500554\tKL_Divergence = 3.931805\n",
      "Epoch: 12\tFidelity = 0.500601\tKL_Divergence = 3.886434\n",
      "Epoch: 13\tFidelity = 0.500607\tKL_Divergence = 3.881105\n",
      "Epoch: 14\tFidelity = 0.500542\tKL_Divergence = 3.944525\n",
      "Epoch: 15\tFidelity = 0.500570\tKL_Divergence = 3.916238\n",
      "Epoch: 16\tFidelity = 0.500542\tKL_Divergence = 3.944511\n",
      "Epoch: 17\tFidelity = 0.500536\tKL_Divergence = 3.950338\n",
      "Epoch: 18\tFidelity = 0.500621\tKL_Divergence = 3.868571\n",
      "Epoch: 19\tFidelity = 0.500584\tKL_Divergence = 3.902928\n",
      "Epoch: 20\tFidelity = 0.500543\tKL_Divergence = 3.943385\n",
      "Epoch: 21\tFidelity = 0.500549\tKL_Divergence = 3.936779\n",
      "Epoch: 22\tFidelity = 0.500567\tKL_Divergence = 3.918741\n",
      "Epoch: 23\tFidelity = 0.500552\tKL_Divergence = 3.934426\n",
      "Epoch: 24\tFidelity = 0.500530\tKL_Divergence = 3.956488\n",
      "Epoch: 25\tFidelity = 0.500570\tKL_Divergence = 3.915887\n",
      "Epoch: 26\tFidelity = 0.500567\tKL_Divergence = 3.919357\n",
      "Epoch: 27\tFidelity = 0.500617\tKL_Divergence = 3.872167\n",
      "Epoch: 28\tFidelity = 0.500593\tKL_Divergence = 3.894109\n",
      "Epoch: 29\tFidelity = 0.500598\tKL_Divergence = 3.889493\n",
      "Epoch: 30\tFidelity = 0.500609\tKL_Divergence = 3.879782\n",
      "Epoch: 31\tFidelity = 0.500524\tKL_Divergence = 3.962547\n",
      "Epoch: 32\tFidelity = 0.500542\tKL_Divergence = 3.944363\n",
      "Epoch: 33\tFidelity = 0.500591\tKL_Divergence = 3.895766\n",
      "Epoch: 34\tFidelity = 0.500592\tKL_Divergence = 3.895003\n",
      "Epoch: 35\tFidelity = 0.500619\tKL_Divergence = 3.870571\n",
      "Epoch: 36\tFidelity = 0.500562\tKL_Divergence = 3.924147\n",
      "Epoch: 37\tFidelity = 0.500603\tKL_Divergence = 3.885402\n",
      "Epoch: 38\tFidelity = 0.500552\tKL_Divergence = 3.934301\n",
      "Epoch: 39\tFidelity = 0.500619\tKL_Divergence = 3.870905\n",
      "Epoch: 40\tFidelity = 0.500612\tKL_Divergence = 3.876480\n",
      "Epoch: 41\tFidelity = 0.500613\tKL_Divergence = 3.875691\n",
      "Epoch: 42\tFidelity = 0.500591\tKL_Divergence = 3.895935\n",
      "Epoch: 43\tFidelity = 0.500600\tKL_Divergence = 3.887984\n",
      "Epoch: 44\tFidelity = 0.500616\tKL_Divergence = 3.872935\n",
      "Epoch: 45\tFidelity = 0.500578\tKL_Divergence = 3.908350\n",
      "Epoch: 46\tFidelity = 0.500633\tKL_Divergence = 3.857917\n",
      "Epoch: 47\tFidelity = 0.500559\tKL_Divergence = 3.926742\n",
      "Epoch: 48\tFidelity = 0.500581\tKL_Divergence = 3.905644\n",
      "Epoch: 49\tFidelity = 0.500576\tKL_Divergence = 3.910440\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:28:51,188] Trial 602 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500584\tKL_Divergence = 3.902835\n",
      "Total time elapsed during training: 38.034 s\n",
      "Trial 602 pruned. \n",
      "Epoch: 1\tFidelity = 0.500618\tKL_Divergence = 3.871526\n",
      "Epoch: 2\tFidelity = 0.500577\tKL_Divergence = 3.909699\n",
      "Epoch: 3\tFidelity = 0.500550\tKL_Divergence = 3.936453\n",
      "Epoch: 4\tFidelity = 0.500473\tKL_Divergence = 4.019841\n",
      "Epoch: 5\tFidelity = 0.500511\tKL_Divergence = 3.976491\n",
      "Epoch: 6\tFidelity = 0.500556\tKL_Divergence = 3.928345\n",
      "Epoch: 7\tFidelity = 0.500558\tKL_Divergence = 3.927673\n",
      "Epoch: 8\tFidelity = 0.500593\tKL_Divergence = 3.893827\n",
      "Epoch: 9\tFidelity = 0.500598\tKL_Divergence = 3.889017\n",
      "Epoch: 10\tFidelity = 0.500694\tKL_Divergence = 3.806419\n",
      "Epoch: 11\tFidelity = 0.500460\tKL_Divergence = 4.034051\n",
      "Epoch: 12\tFidelity = 0.500599\tKL_Divergence = 3.886821\n",
      "Epoch: 13\tFidelity = 0.500496\tKL_Divergence = 3.992179\n",
      "Epoch: 14\tFidelity = 0.500634\tKL_Divergence = 3.854993\n",
      "Epoch: 15\tFidelity = 0.500558\tKL_Divergence = 3.925597\n",
      "Epoch: 16\tFidelity = 0.500660\tKL_Divergence = 3.831750\n",
      "Epoch: 17\tFidelity = 0.500700\tKL_Divergence = 3.797776\n",
      "Epoch: 18\tFidelity = 0.500598\tKL_Divergence = 3.886110\n",
      "Epoch: 19\tFidelity = 0.500476\tKL_Divergence = 4.011343\n",
      "Epoch: 20\tFidelity = 0.500568\tKL_Divergence = 3.912497\n",
      "Epoch: 21\tFidelity = 0.500467\tKL_Divergence = 4.021068\n",
      "Epoch: 22\tFidelity = 0.500675\tKL_Divergence = 3.817473\n",
      "Epoch: 23\tFidelity = 0.500599\tKL_Divergence = 3.884304\n",
      "Epoch: 24\tFidelity = 0.500433\tKL_Divergence = 4.063783\n",
      "Epoch: 25\tFidelity = 0.500563\tKL_Divergence = 3.920668\n",
      "Epoch: 26\tFidelity = 0.500593\tKL_Divergence = 3.889185\n",
      "Epoch: 27\tFidelity = 0.500560\tKL_Divergence = 3.921078\n",
      "Epoch: 28\tFidelity = 0.500534\tKL_Divergence = 3.949749\n",
      "Epoch: 29\tFidelity = 0.500736\tKL_Divergence = 3.771323\n",
      "Epoch: 30\tFidelity = 0.500692\tKL_Divergence = 3.804526\n",
      "Epoch: 31\tFidelity = 0.500544\tKL_Divergence = 3.938474\n",
      "Epoch: 32\tFidelity = 0.500443\tKL_Divergence = 4.053056\n",
      "Epoch: 33\tFidelity = 0.500486\tKL_Divergence = 4.001216\n",
      "Epoch: 34\tFidelity = 0.500473\tKL_Divergence = 4.016730\n",
      "Epoch: 35\tFidelity = 0.500720\tKL_Divergence = 3.784310\n",
      "Epoch: 36\tFidelity = 0.500624\tKL_Divergence = 3.864924\n",
      "Epoch: 37\tFidelity = 0.500582\tKL_Divergence = 3.903666\n",
      "Epoch: 38\tFidelity = 0.500683\tKL_Divergence = 3.813487\n",
      "Epoch: 39\tFidelity = 0.500573\tKL_Divergence = 3.911683\n",
      "Epoch: 40\tFidelity = 0.500482\tKL_Divergence = 4.006429\n",
      "Epoch: 41\tFidelity = 0.500653\tKL_Divergence = 3.839919\n",
      "Epoch: 42\tFidelity = 0.500586\tKL_Divergence = 3.899858\n",
      "Epoch: 43\tFidelity = 0.500625\tKL_Divergence = 3.864650\n",
      "Epoch: 44\tFidelity = 0.500563\tKL_Divergence = 3.921638\n",
      "Epoch: 45\tFidelity = 0.500603\tKL_Divergence = 3.884350\n",
      "Epoch: 46\tFidelity = 0.500650\tKL_Divergence = 3.841605\n",
      "Epoch: 47\tFidelity = 0.500720\tKL_Divergence = 3.784602\n",
      "Epoch: 48\tFidelity = 0.500612\tKL_Divergence = 3.875503\n",
      "Epoch: 49\tFidelity = 0.500607\tKL_Divergence = 3.879390\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:29:28,358] Trial 603 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500651\tKL_Divergence = 3.841105\n",
      "Total time elapsed during training: 36.980 s\n",
      "Trial 603 pruned. \n",
      "Epoch: 1\tFidelity = 0.500613\tKL_Divergence = 3.874613\n",
      "Epoch: 2\tFidelity = 0.500685\tKL_Divergence = 3.812960\n",
      "Epoch: 3\tFidelity = 0.500645\tKL_Divergence = 3.846654\n",
      "Epoch: 4\tFidelity = 0.500625\tKL_Divergence = 3.863504\n",
      "Epoch: 5\tFidelity = 0.500614\tKL_Divergence = 3.874099\n",
      "Epoch: 6\tFidelity = 0.500657\tKL_Divergence = 3.836113\n",
      "Epoch: 7\tFidelity = 0.500624\tKL_Divergence = 3.865021\n",
      "Epoch: 8\tFidelity = 0.500622\tKL_Divergence = 3.866415\n",
      "Epoch: 9\tFidelity = 0.500655\tKL_Divergence = 3.837916\n",
      "Epoch: 10\tFidelity = 0.500604\tKL_Divergence = 3.882609\n",
      "Epoch: 11\tFidelity = 0.500689\tKL_Divergence = 3.809819\n",
      "Epoch: 12\tFidelity = 0.500661\tKL_Divergence = 3.833299\n",
      "Epoch: 13\tFidelity = 0.500609\tKL_Divergence = 3.878920\n",
      "Epoch: 14\tFidelity = 0.500654\tKL_Divergence = 3.839249\n",
      "Epoch: 15\tFidelity = 0.500663\tKL_Divergence = 3.831476\n",
      "Epoch: 16\tFidelity = 0.500595\tKL_Divergence = 3.891871\n",
      "Epoch: 17\tFidelity = 0.500599\tKL_Divergence = 3.887982\n",
      "Epoch: 18\tFidelity = 0.500645\tKL_Divergence = 3.846549\n",
      "Epoch: 19\tFidelity = 0.500611\tKL_Divergence = 3.877208\n",
      "Epoch: 20\tFidelity = 0.500652\tKL_Divergence = 3.840457\n",
      "Epoch: 21\tFidelity = 0.500711\tKL_Divergence = 3.792674\n",
      "Epoch: 22\tFidelity = 0.500636\tKL_Divergence = 3.854559\n",
      "Epoch: 23\tFidelity = 0.500609\tKL_Divergence = 3.878730\n",
      "Epoch: 24\tFidelity = 0.500605\tKL_Divergence = 3.882618\n",
      "Epoch: 25\tFidelity = 0.500677\tKL_Divergence = 3.820111\n",
      "Epoch: 26\tFidelity = 0.500644\tKL_Divergence = 3.847820\n",
      "Epoch: 27\tFidelity = 0.500652\tKL_Divergence = 3.840950\n",
      "Epoch: 28\tFidelity = 0.500634\tKL_Divergence = 3.856512\n",
      "Epoch: 29\tFidelity = 0.500690\tKL_Divergence = 3.809436\n",
      "Epoch: 30\tFidelity = 0.500591\tKL_Divergence = 3.895316\n",
      "Epoch: 31\tFidelity = 0.500667\tKL_Divergence = 3.828502\n",
      "Epoch: 32\tFidelity = 0.500628\tKL_Divergence = 3.862261\n",
      "Epoch: 33\tFidelity = 0.500592\tKL_Divergence = 3.894822\n",
      "Epoch: 34\tFidelity = 0.500587\tKL_Divergence = 3.899115\n",
      "Epoch: 35\tFidelity = 0.500632\tKL_Divergence = 3.858305\n",
      "Epoch: 36\tFidelity = 0.500608\tKL_Divergence = 3.880053\n",
      "Epoch: 37\tFidelity = 0.500624\tKL_Divergence = 3.865832\n",
      "Epoch: 38\tFidelity = 0.500668\tKL_Divergence = 3.827590\n",
      "Epoch: 39\tFidelity = 0.500618\tKL_Divergence = 3.871218\n",
      "Epoch: 40\tFidelity = 0.500608\tKL_Divergence = 3.879683\n",
      "Epoch: 41\tFidelity = 0.500679\tKL_Divergence = 3.818337\n",
      "Epoch: 42\tFidelity = 0.500656\tKL_Divergence = 3.837688\n",
      "Epoch: 43\tFidelity = 0.500629\tKL_Divergence = 3.861527\n",
      "Epoch: 44\tFidelity = 0.500588\tKL_Divergence = 3.898585\n",
      "Epoch: 45\tFidelity = 0.500623\tKL_Divergence = 3.866702\n",
      "Epoch: 46\tFidelity = 0.500649\tKL_Divergence = 3.843412\n",
      "Epoch: 47\tFidelity = 0.500640\tKL_Divergence = 3.851518\n",
      "Epoch: 48\tFidelity = 0.500588\tKL_Divergence = 3.898938\n",
      "Epoch: 49\tFidelity = 0.500654\tKL_Divergence = 3.839822\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:29:59,853] Trial 604 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500603\tKL_Divergence = 3.884539\n",
      "Total time elapsed during training: 31.315 s\n",
      "Trial 604 pruned. \n",
      "Epoch: 1\tFidelity = 0.500753\tKL_Divergence = 3.761239\n",
      "Epoch: 2\tFidelity = 0.500553\tKL_Divergence = 3.932469\n",
      "Epoch: 3\tFidelity = 0.500595\tKL_Divergence = 3.892347\n",
      "Epoch: 4\tFidelity = 0.500615\tKL_Divergence = 3.873806\n",
      "Epoch: 5\tFidelity = 0.500623\tKL_Divergence = 3.866916\n",
      "Epoch: 6\tFidelity = 0.500621\tKL_Divergence = 3.868621\n",
      "Epoch: 7\tFidelity = 0.500603\tKL_Divergence = 3.884793\n",
      "Epoch: 8\tFidelity = 0.500728\tKL_Divergence = 3.780041\n",
      "Epoch: 9\tFidelity = 0.500551\tKL_Divergence = 3.934498\n",
      "Epoch: 10\tFidelity = 0.500647\tKL_Divergence = 3.845918\n",
      "Epoch: 11\tFidelity = 0.500553\tKL_Divergence = 3.932379\n",
      "Epoch: 12\tFidelity = 0.500674\tKL_Divergence = 3.822791\n",
      "Epoch: 13\tFidelity = 0.500533\tKL_Divergence = 3.953010\n",
      "Epoch: 14\tFidelity = 0.500643\tKL_Divergence = 3.848954\n",
      "Epoch: 15\tFidelity = 0.500639\tKL_Divergence = 3.852718\n",
      "Epoch: 16\tFidelity = 0.500526\tKL_Divergence = 3.960657\n",
      "Epoch: 17\tFidelity = 0.500645\tKL_Divergence = 3.847181\n",
      "Epoch: 18\tFidelity = 0.500587\tKL_Divergence = 3.900189\n",
      "Epoch: 19\tFidelity = 0.500594\tKL_Divergence = 3.892895\n",
      "Epoch: 20\tFidelity = 0.500623\tKL_Divergence = 3.866509\n",
      "Epoch: 21\tFidelity = 0.500609\tKL_Divergence = 3.879716\n",
      "Epoch: 22\tFidelity = 0.500519\tKL_Divergence = 3.968563\n",
      "Epoch: 23\tFidelity = 0.500659\tKL_Divergence = 3.835513\n",
      "Epoch: 24\tFidelity = 0.500524\tKL_Divergence = 3.963119\n",
      "Epoch: 25\tFidelity = 0.500635\tKL_Divergence = 3.855991\n",
      "Epoch: 26\tFidelity = 0.500539\tKL_Divergence = 3.947560\n",
      "Epoch: 27\tFidelity = 0.500654\tKL_Divergence = 3.839792\n",
      "Epoch: 28\tFidelity = 0.500566\tKL_Divergence = 3.920290\n",
      "Epoch: 29\tFidelity = 0.500615\tKL_Divergence = 3.873919\n",
      "Epoch: 30\tFidelity = 0.500607\tKL_Divergence = 3.880849\n",
      "Epoch: 31\tFidelity = 0.500566\tKL_Divergence = 3.919616\n",
      "Epoch: 32\tFidelity = 0.500620\tKL_Divergence = 3.869531\n",
      "Epoch: 33\tFidelity = 0.500512\tKL_Divergence = 3.975301\n",
      "Epoch: 34\tFidelity = 0.500701\tKL_Divergence = 3.801751\n",
      "Epoch: 35\tFidelity = 0.500563\tKL_Divergence = 3.923414\n",
      "Epoch: 36\tFidelity = 0.500593\tKL_Divergence = 3.894589\n",
      "Epoch: 37\tFidelity = 0.500619\tKL_Divergence = 3.870564\n",
      "Epoch: 38\tFidelity = 0.500649\tKL_Divergence = 3.844406\n",
      "Epoch: 39\tFidelity = 0.500560\tKL_Divergence = 3.925665\n",
      "Epoch: 40\tFidelity = 0.500640\tKL_Divergence = 3.852101\n",
      "Epoch: 41\tFidelity = 0.500593\tKL_Divergence = 3.894595\n",
      "Epoch: 42\tFidelity = 0.500656\tKL_Divergence = 3.838174\n",
      "Epoch: 43\tFidelity = 0.500611\tKL_Divergence = 3.877647\n",
      "Epoch: 44\tFidelity = 0.500593\tKL_Divergence = 3.894183\n",
      "Epoch: 45\tFidelity = 0.500611\tKL_Divergence = 3.877518\n",
      "Epoch: 46\tFidelity = 0.500573\tKL_Divergence = 3.913401\n",
      "Epoch: 47\tFidelity = 0.500626\tKL_Divergence = 3.864025\n",
      "Epoch: 48\tFidelity = 0.500526\tKL_Divergence = 3.960908\n",
      "Epoch: 49\tFidelity = 0.500623\tKL_Divergence = 3.866887\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:30:31,135] Trial 605 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500550\tKL_Divergence = 3.936185\n",
      "Total time elapsed during training: 31.102 s\n",
      "Trial 605 pruned. \n",
      "Epoch: 1\tFidelity = 0.500632\tKL_Divergence = 3.858964\n",
      "Epoch: 2\tFidelity = 0.500535\tKL_Divergence = 3.951590\n",
      "Epoch: 3\tFidelity = 0.500643\tKL_Divergence = 3.849563\n",
      "Epoch: 4\tFidelity = 0.500601\tKL_Divergence = 3.886566\n",
      "Epoch: 5\tFidelity = 0.500608\tKL_Divergence = 3.879948\n",
      "Epoch: 6\tFidelity = 0.500655\tKL_Divergence = 3.839384\n",
      "Epoch: 7\tFidelity = 0.500601\tKL_Divergence = 3.886690\n",
      "Epoch: 8\tFidelity = 0.500691\tKL_Divergence = 3.809086\n",
      "Epoch: 9\tFidelity = 0.500520\tKL_Divergence = 3.966541\n",
      "Epoch: 10\tFidelity = 0.500579\tKL_Divergence = 3.907621\n",
      "Epoch: 11\tFidelity = 0.500525\tKL_Divergence = 3.961703\n",
      "Epoch: 12\tFidelity = 0.500574\tKL_Divergence = 3.912243\n",
      "Epoch: 13\tFidelity = 0.500639\tKL_Divergence = 3.852976\n",
      "Epoch: 14\tFidelity = 0.500572\tKL_Divergence = 3.914034\n",
      "Epoch: 15\tFidelity = 0.500576\tKL_Divergence = 3.910162\n",
      "Epoch: 16\tFidelity = 0.500616\tKL_Divergence = 3.873291\n",
      "Epoch: 17\tFidelity = 0.500582\tKL_Divergence = 3.904892\n",
      "Epoch: 18\tFidelity = 0.500573\tKL_Divergence = 3.912951\n",
      "Epoch: 19\tFidelity = 0.500607\tKL_Divergence = 3.881289\n",
      "Epoch: 20\tFidelity = 0.500575\tKL_Divergence = 3.911130\n",
      "Epoch: 21\tFidelity = 0.500592\tKL_Divergence = 3.895204\n",
      "Epoch: 22\tFidelity = 0.500618\tKL_Divergence = 3.871242\n",
      "Epoch: 23\tFidelity = 0.500570\tKL_Divergence = 3.915973\n",
      "Epoch: 24\tFidelity = 0.500643\tKL_Divergence = 3.849315\n",
      "Epoch: 25\tFidelity = 0.500639\tKL_Divergence = 3.852710\n",
      "Epoch: 26\tFidelity = 0.500604\tKL_Divergence = 3.883908\n",
      "Epoch: 27\tFidelity = 0.500696\tKL_Divergence = 3.805223\n",
      "Epoch: 28\tFidelity = 0.500648\tKL_Divergence = 3.844975\n",
      "Epoch: 29\tFidelity = 0.500713\tKL_Divergence = 3.791733\n",
      "Epoch: 30\tFidelity = 0.500656\tKL_Divergence = 3.837928\n",
      "Epoch: 31\tFidelity = 0.500664\tKL_Divergence = 3.831725\n",
      "Epoch: 32\tFidelity = 0.500615\tKL_Divergence = 3.873494\n",
      "Epoch: 33\tFidelity = 0.500598\tKL_Divergence = 3.889578\n",
      "Epoch: 34\tFidelity = 0.500596\tKL_Divergence = 3.890873\n",
      "Epoch: 35\tFidelity = 0.500566\tKL_Divergence = 3.919752\n",
      "Epoch: 36\tFidelity = 0.500575\tKL_Divergence = 3.911102\n",
      "Epoch: 37\tFidelity = 0.500576\tKL_Divergence = 3.910544\n",
      "Epoch: 38\tFidelity = 0.500706\tKL_Divergence = 3.797622\n",
      "Epoch: 39\tFidelity = 0.500676\tKL_Divergence = 3.821770\n",
      "Epoch: 40\tFidelity = 0.500653\tKL_Divergence = 3.840313\n",
      "Epoch: 41\tFidelity = 0.500644\tKL_Divergence = 3.848432\n",
      "Epoch: 42\tFidelity = 0.500590\tKL_Divergence = 3.896835\n",
      "Epoch: 43\tFidelity = 0.500582\tKL_Divergence = 3.904760\n",
      "Epoch: 44\tFidelity = 0.500695\tKL_Divergence = 3.805763\n",
      "Epoch: 45\tFidelity = 0.500652\tKL_Divergence = 3.841589\n",
      "Epoch: 46\tFidelity = 0.500627\tKL_Divergence = 3.862570\n",
      "Epoch: 47\tFidelity = 0.500732\tKL_Divergence = 3.776853\n",
      "Epoch: 48\tFidelity = 0.500672\tKL_Divergence = 3.824220\n",
      "Epoch: 49\tFidelity = 0.500718\tKL_Divergence = 3.787485\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:31:15,616] Trial 606 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500579\tKL_Divergence = 3.906756\n",
      "Total time elapsed during training: 44.271 s\n",
      "Trial 606 pruned. \n",
      "Epoch: 1\tFidelity = 0.500592\tKL_Divergence = 3.894626\n",
      "Epoch: 2\tFidelity = 0.500660\tKL_Divergence = 3.834342\n",
      "Epoch: 3\tFidelity = 0.500691\tKL_Divergence = 3.809523\n",
      "Epoch: 4\tFidelity = 0.500669\tKL_Divergence = 3.827291\n",
      "Epoch: 5\tFidelity = 0.500644\tKL_Divergence = 3.848504\n",
      "Epoch: 6\tFidelity = 0.500615\tKL_Divergence = 3.873950\n",
      "Epoch: 7\tFidelity = 0.500643\tKL_Divergence = 3.848937\n",
      "Epoch: 8\tFidelity = 0.500664\tKL_Divergence = 3.831282\n",
      "Epoch: 9\tFidelity = 0.500623\tKL_Divergence = 3.866479\n",
      "Epoch: 10\tFidelity = 0.500665\tKL_Divergence = 3.830211\n",
      "Epoch: 11\tFidelity = 0.500616\tKL_Divergence = 3.872983\n",
      "Epoch: 12\tFidelity = 0.500608\tKL_Divergence = 3.880520\n",
      "Epoch: 13\tFidelity = 0.500623\tKL_Divergence = 3.866951\n",
      "Epoch: 14\tFidelity = 0.500585\tKL_Divergence = 3.902032\n",
      "Epoch: 15\tFidelity = 0.500616\tKL_Divergence = 3.872705\n",
      "Epoch: 16\tFidelity = 0.500615\tKL_Divergence = 3.874127\n",
      "Epoch: 17\tFidelity = 0.500592\tKL_Divergence = 3.895115\n",
      "Epoch: 18\tFidelity = 0.500568\tKL_Divergence = 3.917597\n",
      "Epoch: 19\tFidelity = 0.500614\tKL_Divergence = 3.874913\n",
      "Epoch: 20\tFidelity = 0.500582\tKL_Divergence = 3.904991\n",
      "Epoch: 21\tFidelity = 0.500598\tKL_Divergence = 3.889341\n",
      "Epoch: 22\tFidelity = 0.500605\tKL_Divergence = 3.883398\n",
      "Epoch: 23\tFidelity = 0.500586\tKL_Divergence = 3.901029\n",
      "Epoch: 24\tFidelity = 0.500624\tKL_Divergence = 3.865807\n",
      "Epoch: 25\tFidelity = 0.500529\tKL_Divergence = 3.957776\n",
      "Epoch: 26\tFidelity = 0.500615\tKL_Divergence = 3.873619\n",
      "Epoch: 27\tFidelity = 0.500655\tKL_Divergence = 3.838719\n",
      "Epoch: 28\tFidelity = 0.500559\tKL_Divergence = 3.927021\n",
      "Epoch: 29\tFidelity = 0.500643\tKL_Divergence = 3.848955\n",
      "Epoch: 30\tFidelity = 0.500652\tKL_Divergence = 3.841531\n",
      "Epoch: 31\tFidelity = 0.500587\tKL_Divergence = 3.900049\n",
      "Epoch: 32\tFidelity = 0.500594\tKL_Divergence = 3.893687\n",
      "Epoch: 33\tFidelity = 0.500609\tKL_Divergence = 3.879165\n",
      "Epoch: 34\tFidelity = 0.500565\tKL_Divergence = 3.920934\n",
      "Epoch: 35\tFidelity = 0.500572\tKL_Divergence = 3.914043\n",
      "Epoch: 36\tFidelity = 0.500573\tKL_Divergence = 3.913642\n",
      "Epoch: 37\tFidelity = 0.500595\tKL_Divergence = 3.892055\n",
      "Epoch: 38\tFidelity = 0.500575\tKL_Divergence = 3.911204\n",
      "Epoch: 39\tFidelity = 0.500581\tKL_Divergence = 3.905197\n",
      "Epoch: 40\tFidelity = 0.500612\tKL_Divergence = 3.876973\n",
      "Epoch: 41\tFidelity = 0.500611\tKL_Divergence = 3.877606\n",
      "Epoch: 42\tFidelity = 0.500575\tKL_Divergence = 3.911089\n",
      "Epoch: 43\tFidelity = 0.500568\tKL_Divergence = 3.918038\n",
      "Epoch: 44\tFidelity = 0.500551\tKL_Divergence = 3.935592\n",
      "Epoch: 45\tFidelity = 0.500531\tKL_Divergence = 3.955650\n",
      "Epoch: 46\tFidelity = 0.500574\tKL_Divergence = 3.912022\n",
      "Epoch: 47\tFidelity = 0.500566\tKL_Divergence = 3.920510\n",
      "Epoch: 48\tFidelity = 0.500604\tKL_Divergence = 3.884587\n",
      "Epoch: 49\tFidelity = 0.500548\tKL_Divergence = 3.938326\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:32:35,010] Trial 607 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500656\tKL_Divergence = 3.838098\n",
      "Total time elapsed during training: 79.218 s\n",
      "Trial 607 pruned. \n",
      "Epoch: 1\tFidelity = 0.500633\tKL_Divergence = 3.858312\n",
      "Epoch: 2\tFidelity = 0.500586\tKL_Divergence = 3.900705\n",
      "Epoch: 3\tFidelity = 0.500605\tKL_Divergence = 3.882855\n",
      "Epoch: 4\tFidelity = 0.500585\tKL_Divergence = 3.901540\n",
      "Epoch: 5\tFidelity = 0.500621\tKL_Divergence = 3.868496\n",
      "Epoch: 6\tFidelity = 0.500574\tKL_Divergence = 3.912481\n",
      "Epoch: 7\tFidelity = 0.500541\tKL_Divergence = 3.945142\n",
      "Epoch: 8\tFidelity = 0.500524\tKL_Divergence = 3.963119\n",
      "Epoch: 9\tFidelity = 0.500567\tKL_Divergence = 3.918714\n",
      "Epoch: 10\tFidelity = 0.500584\tKL_Divergence = 3.902713\n",
      "Epoch: 11\tFidelity = 0.500550\tKL_Divergence = 3.936248\n",
      "Epoch: 12\tFidelity = 0.500543\tKL_Divergence = 3.942892\n",
      "Epoch: 13\tFidelity = 0.500611\tKL_Divergence = 3.877639\n",
      "Epoch: 14\tFidelity = 0.500543\tKL_Divergence = 3.943511\n",
      "Epoch: 15\tFidelity = 0.500555\tKL_Divergence = 3.931413\n",
      "Epoch: 16\tFidelity = 0.500506\tKL_Divergence = 3.982262\n",
      "Epoch: 17\tFidelity = 0.500599\tKL_Divergence = 3.889100\n",
      "Epoch: 18\tFidelity = 0.500534\tKL_Divergence = 3.952341\n",
      "Epoch: 19\tFidelity = 0.500584\tKL_Divergence = 3.902477\n",
      "Epoch: 20\tFidelity = 0.500636\tKL_Divergence = 3.855283\n",
      "Epoch: 21\tFidelity = 0.500593\tKL_Divergence = 3.894502\n",
      "Epoch: 22\tFidelity = 0.500507\tKL_Divergence = 3.981239\n",
      "Epoch: 23\tFidelity = 0.500519\tKL_Divergence = 3.968242\n",
      "Epoch: 24\tFidelity = 0.500614\tKL_Divergence = 3.874994\n",
      "Epoch: 25\tFidelity = 0.500654\tKL_Divergence = 3.840293\n",
      "Epoch: 26\tFidelity = 0.500642\tKL_Divergence = 3.850224\n",
      "Epoch: 27\tFidelity = 0.500593\tKL_Divergence = 3.894133\n",
      "Epoch: 28\tFidelity = 0.500587\tKL_Divergence = 3.899669\n",
      "Epoch: 29\tFidelity = 0.500540\tKL_Divergence = 3.946306\n",
      "Epoch: 30\tFidelity = 0.500538\tKL_Divergence = 3.948023\n",
      "Epoch: 31\tFidelity = 0.500510\tKL_Divergence = 3.977740\n",
      "Epoch: 32\tFidelity = 0.500598\tKL_Divergence = 3.889398\n",
      "Epoch: 33\tFidelity = 0.500553\tKL_Divergence = 3.932675\n",
      "Epoch: 34\tFidelity = 0.500541\tKL_Divergence = 3.945202\n",
      "Epoch: 35\tFidelity = 0.500553\tKL_Divergence = 3.932796\n",
      "Epoch: 36\tFidelity = 0.500546\tKL_Divergence = 3.940021\n",
      "Epoch: 37\tFidelity = 0.500583\tKL_Divergence = 3.903853\n",
      "Epoch: 38\tFidelity = 0.500547\tKL_Divergence = 3.938938\n",
      "Epoch: 39\tFidelity = 0.500596\tKL_Divergence = 3.891861\n",
      "Epoch: 40\tFidelity = 0.500565\tKL_Divergence = 3.921283\n",
      "Epoch: 41\tFidelity = 0.500644\tKL_Divergence = 3.848881\n",
      "Epoch: 42\tFidelity = 0.500657\tKL_Divergence = 3.837057\n",
      "Epoch: 43\tFidelity = 0.500596\tKL_Divergence = 3.891519\n",
      "Epoch: 44\tFidelity = 0.500560\tKL_Divergence = 3.925786\n",
      "Epoch: 45\tFidelity = 0.500631\tKL_Divergence = 3.859550\n",
      "Epoch: 46\tFidelity = 0.500555\tKL_Divergence = 3.931163\n",
      "Epoch: 47\tFidelity = 0.500514\tKL_Divergence = 3.973144\n",
      "Epoch: 48\tFidelity = 0.500540\tKL_Divergence = 3.946019\n",
      "Epoch: 49\tFidelity = 0.500554\tKL_Divergence = 3.931974\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:33:12,845] Trial 608 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500527\tKL_Divergence = 3.959317\n",
      "Total time elapsed during training: 37.638 s\n",
      "Trial 608 pruned. \n",
      "Epoch: 1\tFidelity = 0.500528\tKL_Divergence = 3.958398\n",
      "Epoch: 2\tFidelity = 0.500526\tKL_Divergence = 3.961140\n",
      "Epoch: 3\tFidelity = 0.500589\tKL_Divergence = 3.897770\n",
      "Epoch: 4\tFidelity = 0.500620\tKL_Divergence = 3.869236\n",
      "Epoch: 5\tFidelity = 0.500511\tKL_Divergence = 3.976688\n",
      "Epoch: 6\tFidelity = 0.500607\tKL_Divergence = 3.881458\n",
      "Epoch: 7\tFidelity = 0.500564\tKL_Divergence = 3.921687\n",
      "Epoch: 8\tFidelity = 0.500569\tKL_Divergence = 3.917285\n",
      "Epoch: 9\tFidelity = 0.500564\tKL_Divergence = 3.921859\n",
      "Epoch: 10\tFidelity = 0.500619\tKL_Divergence = 3.870398\n",
      "Epoch: 11\tFidelity = 0.500616\tKL_Divergence = 3.873274\n",
      "Epoch: 12\tFidelity = 0.500585\tKL_Divergence = 3.901894\n",
      "Epoch: 13\tFidelity = 0.500546\tKL_Divergence = 3.939775\n",
      "Epoch: 14\tFidelity = 0.500548\tKL_Divergence = 3.937751\n",
      "Epoch: 15\tFidelity = 0.500563\tKL_Divergence = 3.923190\n",
      "Epoch: 16\tFidelity = 0.500622\tKL_Divergence = 3.867687\n",
      "Epoch: 17\tFidelity = 0.500576\tKL_Divergence = 3.910488\n",
      "Epoch: 18\tFidelity = 0.500637\tKL_Divergence = 3.854929\n",
      "Epoch: 19\tFidelity = 0.500626\tKL_Divergence = 3.864460\n",
      "Epoch: 20\tFidelity = 0.500628\tKL_Divergence = 3.862377\n",
      "Epoch: 21\tFidelity = 0.500586\tKL_Divergence = 3.900595\n",
      "Epoch: 22\tFidelity = 0.500522\tKL_Divergence = 3.964977\n",
      "Epoch: 23\tFidelity = 0.500595\tKL_Divergence = 3.892596\n",
      "Epoch: 24\tFidelity = 0.500622\tKL_Divergence = 3.867394\n",
      "Epoch: 25\tFidelity = 0.500565\tKL_Divergence = 3.921270\n",
      "Epoch: 26\tFidelity = 0.500558\tKL_Divergence = 3.927595\n",
      "Epoch: 27\tFidelity = 0.500611\tKL_Divergence = 3.877463\n",
      "Epoch: 28\tFidelity = 0.500568\tKL_Divergence = 3.917695\n",
      "Epoch: 29\tFidelity = 0.500641\tKL_Divergence = 3.850814\n",
      "Epoch: 30\tFidelity = 0.500580\tKL_Divergence = 3.906052\n",
      "Epoch: 31\tFidelity = 0.500627\tKL_Divergence = 3.863048\n",
      "Epoch: 32\tFidelity = 0.500672\tKL_Divergence = 3.825130\n",
      "Epoch: 33\tFidelity = 0.500547\tKL_Divergence = 3.939338\n",
      "Epoch: 34\tFidelity = 0.500564\tKL_Divergence = 3.922411\n",
      "Epoch: 35\tFidelity = 0.500583\tKL_Divergence = 3.903753\n",
      "Epoch: 36\tFidelity = 0.500649\tKL_Divergence = 3.843761\n",
      "Epoch: 37\tFidelity = 0.500601\tKL_Divergence = 3.886543\n",
      "Epoch: 38\tFidelity = 0.500569\tKL_Divergence = 3.916946\n",
      "Epoch: 39\tFidelity = 0.500561\tKL_Divergence = 3.924620\n",
      "Epoch: 40\tFidelity = 0.500629\tKL_Divergence = 3.861754\n",
      "Epoch: 41\tFidelity = 0.500537\tKL_Divergence = 3.948925\n",
      "Epoch: 42\tFidelity = 0.500597\tKL_Divergence = 3.890223\n",
      "Epoch: 43\tFidelity = 0.500547\tKL_Divergence = 3.938713\n",
      "Epoch: 44\tFidelity = 0.500571\tKL_Divergence = 3.915372\n",
      "Epoch: 45\tFidelity = 0.500561\tKL_Divergence = 3.924706\n",
      "Epoch: 46\tFidelity = 0.500643\tKL_Divergence = 3.849594\n",
      "Epoch: 47\tFidelity = 0.500631\tKL_Divergence = 3.859665\n",
      "Epoch: 48\tFidelity = 0.500584\tKL_Divergence = 3.902733\n",
      "Epoch: 49\tFidelity = 0.500609\tKL_Divergence = 3.879795\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:34:10,503] Trial 609 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500605\tKL_Divergence = 3.882967\n",
      "Total time elapsed during training: 57.479 s\n",
      "Trial 609 pruned. \n",
      "Epoch: 1\tFidelity = 0.500607\tKL_Divergence = 3.880920\n",
      "Epoch: 2\tFidelity = 0.500534\tKL_Divergence = 3.952254\n",
      "Epoch: 3\tFidelity = 0.500657\tKL_Divergence = 3.837015\n",
      "Epoch: 4\tFidelity = 0.500586\tKL_Divergence = 3.901240\n",
      "Epoch: 5\tFidelity = 0.500739\tKL_Divergence = 3.771884\n",
      "Epoch: 6\tFidelity = 0.500668\tKL_Divergence = 3.827911\n",
      "Epoch: 7\tFidelity = 0.500455\tKL_Divergence = 4.041542\n",
      "Epoch: 8\tFidelity = 0.500484\tKL_Divergence = 4.007094\n",
      "Epoch: 9\tFidelity = 0.500673\tKL_Divergence = 3.823874\n",
      "Epoch: 10\tFidelity = 0.500621\tKL_Divergence = 3.868491\n",
      "Epoch: 11\tFidelity = 0.500566\tKL_Divergence = 3.919956\n",
      "Epoch: 12\tFidelity = 0.500729\tKL_Divergence = 3.779249\n",
      "Epoch: 13\tFidelity = 0.500526\tKL_Divergence = 3.959661\n",
      "Epoch: 14\tFidelity = 0.500509\tKL_Divergence = 3.977980\n",
      "Epoch: 15\tFidelity = 0.500663\tKL_Divergence = 3.831750\n",
      "Epoch: 16\tFidelity = 0.500619\tKL_Divergence = 3.869890\n",
      "Epoch: 17\tFidelity = 0.500543\tKL_Divergence = 3.943368\n",
      "Epoch: 18\tFidelity = 0.500508\tKL_Divergence = 3.979881\n",
      "Epoch: 19\tFidelity = 0.500590\tKL_Divergence = 3.896533\n",
      "Epoch: 20\tFidelity = 0.500478\tKL_Divergence = 4.014020\n",
      "Epoch: 21\tFidelity = 0.500754\tKL_Divergence = 3.760680\n",
      "Epoch: 22\tFidelity = 0.500461\tKL_Divergence = 4.033026\n",
      "Epoch: 23\tFidelity = 0.500680\tKL_Divergence = 3.817948\n",
      "Epoch: 24\tFidelity = 0.500559\tKL_Divergence = 3.926736\n",
      "Epoch: 25\tFidelity = 0.500467\tKL_Divergence = 4.025930\n",
      "Epoch: 26\tFidelity = 0.500566\tKL_Divergence = 3.920119\n",
      "Epoch: 27\tFidelity = 0.500598\tKL_Divergence = 3.890043\n",
      "Epoch: 28\tFidelity = 0.500668\tKL_Divergence = 3.828229\n",
      "Epoch: 29\tFidelity = 0.500526\tKL_Divergence = 3.960340\n",
      "Epoch: 30\tFidelity = 0.500708\tKL_Divergence = 3.796281\n",
      "Epoch: 31\tFidelity = 0.500705\tKL_Divergence = 3.798388\n",
      "Epoch: 32\tFidelity = 0.500519\tKL_Divergence = 3.967822\n",
      "Epoch: 33\tFidelity = 0.500532\tKL_Divergence = 3.954867\n",
      "Epoch: 34\tFidelity = 0.500538\tKL_Divergence = 3.948327\n",
      "Epoch: 35\tFidelity = 0.500549\tKL_Divergence = 3.936993\n",
      "Epoch: 36\tFidelity = 0.500640\tKL_Divergence = 3.852122\n",
      "Epoch: 37\tFidelity = 0.500668\tKL_Divergence = 3.828119\n",
      "Epoch: 38\tFidelity = 0.500501\tKL_Divergence = 3.987002\n",
      "Epoch: 39\tFidelity = 0.500560\tKL_Divergence = 3.926040\n",
      "Epoch: 40\tFidelity = 0.500571\tKL_Divergence = 3.914739\n",
      "Epoch: 41\tFidelity = 0.500476\tKL_Divergence = 4.014953\n",
      "Epoch: 42\tFidelity = 0.500494\tKL_Divergence = 3.993536\n",
      "Epoch: 43\tFidelity = 0.500524\tKL_Divergence = 3.960483\n",
      "Epoch: 44\tFidelity = 0.500502\tKL_Divergence = 3.984124\n",
      "Epoch: 45\tFidelity = 0.500463\tKL_Divergence = 4.029087\n",
      "Epoch: 46\tFidelity = 0.500555\tKL_Divergence = 3.929698\n",
      "Epoch: 47\tFidelity = 0.500528\tKL_Divergence = 3.956768\n",
      "Epoch: 48\tFidelity = 0.500603\tKL_Divergence = 3.883701\n",
      "Epoch: 49\tFidelity = 0.500386\tKL_Divergence = 4.131824\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:34:47,790] Trial 610 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500503\tKL_Divergence = 3.985274\n",
      "Total time elapsed during training: 37.107 s\n",
      "Trial 610 pruned. \n",
      "Epoch: 1\tFidelity = 0.500519\tKL_Divergence = 3.968345\n",
      "Epoch: 2\tFidelity = 0.500529\tKL_Divergence = 3.958165\n",
      "Epoch: 3\tFidelity = 0.500526\tKL_Divergence = 3.960478\n",
      "Epoch: 4\tFidelity = 0.500591\tKL_Divergence = 3.896618\n",
      "Epoch: 5\tFidelity = 0.500527\tKL_Divergence = 3.959512\n",
      "Epoch: 6\tFidelity = 0.500584\tKL_Divergence = 3.902919\n",
      "Epoch: 7\tFidelity = 0.500521\tKL_Divergence = 3.966286\n",
      "Epoch: 8\tFidelity = 0.500547\tKL_Divergence = 3.938677\n",
      "Epoch: 9\tFidelity = 0.500517\tKL_Divergence = 3.970056\n",
      "Epoch: 10\tFidelity = 0.500577\tKL_Divergence = 3.909369\n",
      "Epoch: 11\tFidelity = 0.500518\tKL_Divergence = 3.968917\n",
      "Epoch: 12\tFidelity = 0.500617\tKL_Divergence = 3.872160\n",
      "Epoch: 13\tFidelity = 0.500604\tKL_Divergence = 3.884613\n",
      "Epoch: 14\tFidelity = 0.500561\tKL_Divergence = 3.925301\n",
      "Epoch: 15\tFidelity = 0.500561\tKL_Divergence = 3.925073\n",
      "Epoch: 16\tFidelity = 0.500469\tKL_Divergence = 4.024682\n",
      "Epoch: 17\tFidelity = 0.500591\tKL_Divergence = 3.895971\n",
      "Epoch: 18\tFidelity = 0.500562\tKL_Divergence = 3.923744\n",
      "Epoch: 19\tFidelity = 0.500567\tKL_Divergence = 3.919789\n",
      "Epoch: 20\tFidelity = 0.500526\tKL_Divergence = 3.961065\n",
      "Epoch: 21\tFidelity = 0.500478\tKL_Divergence = 4.014279\n",
      "Epoch: 22\tFidelity = 0.500499\tKL_Divergence = 3.990256\n",
      "Epoch: 23\tFidelity = 0.500500\tKL_Divergence = 3.989201\n",
      "Epoch: 24\tFidelity = 0.500542\tKL_Divergence = 3.944472\n",
      "Epoch: 25\tFidelity = 0.500503\tKL_Divergence = 3.986246\n",
      "Epoch: 26\tFidelity = 0.500514\tKL_Divergence = 3.973278\n",
      "Epoch: 27\tFidelity = 0.500514\tKL_Divergence = 3.974253\n",
      "Epoch: 28\tFidelity = 0.500505\tKL_Divergence = 3.983434\n",
      "Epoch: 29\tFidelity = 0.500538\tKL_Divergence = 3.948332\n",
      "Epoch: 30\tFidelity = 0.500519\tKL_Divergence = 3.968396\n",
      "Epoch: 31\tFidelity = 0.500592\tKL_Divergence = 3.895345\n",
      "Epoch: 32\tFidelity = 0.500546\tKL_Divergence = 3.939894\n",
      "Epoch: 33\tFidelity = 0.500584\tKL_Divergence = 3.902535\n",
      "Epoch: 34\tFidelity = 0.500487\tKL_Divergence = 4.003504\n",
      "Epoch: 35\tFidelity = 0.500553\tKL_Divergence = 3.932838\n",
      "Epoch: 36\tFidelity = 0.500515\tKL_Divergence = 3.972278\n",
      "Epoch: 37\tFidelity = 0.500570\tKL_Divergence = 3.916731\n",
      "Epoch: 38\tFidelity = 0.500538\tKL_Divergence = 3.948575\n",
      "Epoch: 39\tFidelity = 0.500544\tKL_Divergence = 3.942497\n",
      "Epoch: 40\tFidelity = 0.500532\tKL_Divergence = 3.955083\n",
      "Epoch: 41\tFidelity = 0.500495\tKL_Divergence = 3.995014\n",
      "Epoch: 42\tFidelity = 0.500542\tKL_Divergence = 3.944043\n",
      "Epoch: 43\tFidelity = 0.500549\tKL_Divergence = 3.937319\n",
      "Epoch: 44\tFidelity = 0.500515\tKL_Divergence = 3.973182\n",
      "Epoch: 45\tFidelity = 0.500535\tKL_Divergence = 3.951443\n",
      "Epoch: 46\tFidelity = 0.500529\tKL_Divergence = 3.957771\n",
      "Epoch: 47\tFidelity = 0.500548\tKL_Divergence = 3.938505\n",
      "Epoch: 48\tFidelity = 0.500544\tKL_Divergence = 3.941973\n",
      "Epoch: 49\tFidelity = 0.500573\tKL_Divergence = 3.913328\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:35:25,655] Trial 611 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500504\tKL_Divergence = 3.985146\n",
      "Total time elapsed during training: 37.686 s\n",
      "Trial 611 pruned. \n",
      "Epoch: 1\tFidelity = 0.500505\tKL_Divergence = 3.983953\n",
      "Epoch: 2\tFidelity = 0.500563\tKL_Divergence = 3.923459\n",
      "Epoch: 3\tFidelity = 0.500591\tKL_Divergence = 3.896548\n",
      "Epoch: 4\tFidelity = 0.500657\tKL_Divergence = 3.837705\n",
      "Epoch: 5\tFidelity = 0.500613\tKL_Divergence = 3.875770\n",
      "Epoch: 6\tFidelity = 0.500488\tKL_Divergence = 4.002720\n",
      "Epoch: 7\tFidelity = 0.500630\tKL_Divergence = 3.860635\n",
      "Epoch: 8\tFidelity = 0.500441\tKL_Divergence = 4.058221\n",
      "Epoch: 9\tFidelity = 0.500537\tKL_Divergence = 3.949721\n",
      "Epoch: 10\tFidelity = 0.500520\tKL_Divergence = 3.967251\n",
      "Epoch: 11\tFidelity = 0.500584\tKL_Divergence = 3.903242\n",
      "Epoch: 12\tFidelity = 0.500518\tKL_Divergence = 3.969431\n",
      "Epoch: 13\tFidelity = 0.500571\tKL_Divergence = 3.915850\n",
      "Epoch: 14\tFidelity = 0.500581\tKL_Divergence = 3.905430\n",
      "Epoch: 15\tFidelity = 0.500566\tKL_Divergence = 3.919997\n",
      "Epoch: 16\tFidelity = 0.500528\tKL_Divergence = 3.958401\n",
      "Epoch: 17\tFidelity = 0.500627\tKL_Divergence = 3.863587\n",
      "Epoch: 18\tFidelity = 0.500509\tKL_Divergence = 3.978615\n",
      "Epoch: 19\tFidelity = 0.500621\tKL_Divergence = 3.868813\n",
      "Epoch: 20\tFidelity = 0.500461\tKL_Divergence = 4.034087\n",
      "Epoch: 21\tFidelity = 0.500460\tKL_Divergence = 4.035587\n",
      "Epoch: 22\tFidelity = 0.500481\tKL_Divergence = 4.010309\n",
      "Epoch: 23\tFidelity = 0.500569\tKL_Divergence = 3.917712\n",
      "Epoch: 24\tFidelity = 0.500530\tKL_Divergence = 3.956511\n",
      "Epoch: 25\tFidelity = 0.500566\tKL_Divergence = 3.920461\n",
      "Epoch: 26\tFidelity = 0.500602\tKL_Divergence = 3.885937\n",
      "Epoch: 27\tFidelity = 0.500680\tKL_Divergence = 3.818088\n",
      "Epoch: 28\tFidelity = 0.500536\tKL_Divergence = 3.950628\n",
      "Epoch: 29\tFidelity = 0.500610\tKL_Divergence = 3.878544\n",
      "Epoch: 30\tFidelity = 0.500577\tKL_Divergence = 3.909449\n",
      "Epoch: 31\tFidelity = 0.500483\tKL_Divergence = 4.008133\n",
      "Epoch: 32\tFidelity = 0.500535\tKL_Divergence = 3.951830\n",
      "Epoch: 33\tFidelity = 0.500629\tKL_Divergence = 3.861784\n",
      "Epoch: 34\tFidelity = 0.500572\tKL_Divergence = 3.914151\n",
      "Epoch: 35\tFidelity = 0.500522\tKL_Divergence = 3.964787\n",
      "Epoch: 36\tFidelity = 0.500374\tKL_Divergence = 4.150705\n",
      "Epoch: 37\tFidelity = 0.500553\tKL_Divergence = 3.933497\n",
      "Epoch: 38\tFidelity = 0.500516\tKL_Divergence = 3.971536\n",
      "Epoch: 39\tFidelity = 0.500587\tKL_Divergence = 3.900508\n",
      "Epoch: 40\tFidelity = 0.500578\tKL_Divergence = 3.908326\n",
      "Epoch: 41\tFidelity = 0.500526\tKL_Divergence = 3.960583\n",
      "Epoch: 42\tFidelity = 0.500544\tKL_Divergence = 3.942206\n",
      "Epoch: 43\tFidelity = 0.500498\tKL_Divergence = 3.990822\n",
      "Epoch: 44\tFidelity = 0.500625\tKL_Divergence = 3.865173\n",
      "Epoch: 45\tFidelity = 0.500587\tKL_Divergence = 3.900296\n",
      "Epoch: 46\tFidelity = 0.500533\tKL_Divergence = 3.953073\n",
      "Epoch: 47\tFidelity = 0.500613\tKL_Divergence = 3.876400\n",
      "Epoch: 48\tFidelity = 0.500573\tKL_Divergence = 3.913078\n",
      "Epoch: 49\tFidelity = 0.500629\tKL_Divergence = 3.861837\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:36:45,171] Trial 612 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500494\tKL_Divergence = 3.995809\n",
      "Total time elapsed during training: 79.330 s\n",
      "Trial 612 pruned. \n",
      "Epoch: 1\tFidelity = 0.500504\tKL_Divergence = 3.984937\n",
      "Epoch: 2\tFidelity = 0.500526\tKL_Divergence = 3.961257\n",
      "Epoch: 3\tFidelity = 0.500539\tKL_Divergence = 3.947642\n",
      "Epoch: 4\tFidelity = 0.500529\tKL_Divergence = 3.958255\n",
      "Epoch: 5\tFidelity = 0.500492\tKL_Divergence = 3.998487\n",
      "Epoch: 6\tFidelity = 0.500582\tKL_Divergence = 3.904431\n",
      "Epoch: 7\tFidelity = 0.500546\tKL_Divergence = 3.939840\n",
      "Epoch: 8\tFidelity = 0.500508\tKL_Divergence = 3.979808\n",
      "Epoch: 9\tFidelity = 0.500606\tKL_Divergence = 3.882505\n",
      "Epoch: 10\tFidelity = 0.500564\tKL_Divergence = 3.921786\n",
      "Epoch: 11\tFidelity = 0.500562\tKL_Divergence = 3.924638\n",
      "Epoch: 12\tFidelity = 0.500556\tKL_Divergence = 3.930615\n",
      "Epoch: 13\tFidelity = 0.500524\tKL_Divergence = 3.963180\n",
      "Epoch: 14\tFidelity = 0.500524\tKL_Divergence = 3.963220\n",
      "Epoch: 15\tFidelity = 0.500535\tKL_Divergence = 3.952001\n",
      "Epoch: 16\tFidelity = 0.500483\tKL_Divergence = 4.007728\n",
      "Epoch: 17\tFidelity = 0.500565\tKL_Divergence = 3.921002\n",
      "Epoch: 18\tFidelity = 0.500571\tKL_Divergence = 3.914972\n",
      "Epoch: 19\tFidelity = 0.500571\tKL_Divergence = 3.915867\n",
      "Epoch: 20\tFidelity = 0.500621\tKL_Divergence = 3.868864\n",
      "Epoch: 21\tFidelity = 0.500556\tKL_Divergence = 3.930113\n",
      "Epoch: 22\tFidelity = 0.500560\tKL_Divergence = 3.926191\n",
      "Epoch: 23\tFidelity = 0.500618\tKL_Divergence = 3.871159\n",
      "Epoch: 24\tFidelity = 0.500543\tKL_Divergence = 3.943027\n",
      "Epoch: 25\tFidelity = 0.500546\tKL_Divergence = 3.939909\n",
      "Epoch: 26\tFidelity = 0.500546\tKL_Divergence = 3.940413\n",
      "Epoch: 27\tFidelity = 0.500526\tKL_Divergence = 3.961399\n",
      "Epoch: 28\tFidelity = 0.500572\tKL_Divergence = 3.914147\n",
      "Epoch: 29\tFidelity = 0.500612\tKL_Divergence = 3.876975\n",
      "Epoch: 30\tFidelity = 0.500576\tKL_Divergence = 3.910219\n",
      "Epoch: 31\tFidelity = 0.500522\tKL_Divergence = 3.965081\n",
      "Epoch: 32\tFidelity = 0.500584\tKL_Divergence = 3.902550\n",
      "Epoch: 33\tFidelity = 0.500551\tKL_Divergence = 3.935029\n",
      "Epoch: 34\tFidelity = 0.500533\tKL_Divergence = 3.953995\n",
      "Epoch: 35\tFidelity = 0.500540\tKL_Divergence = 3.946216\n",
      "Epoch: 36\tFidelity = 0.500549\tKL_Divergence = 3.937170\n",
      "Epoch: 37\tFidelity = 0.500572\tKL_Divergence = 3.914797\n",
      "Epoch: 38\tFidelity = 0.500569\tKL_Divergence = 3.917355\n",
      "Epoch: 39\tFidelity = 0.500526\tKL_Divergence = 3.961437\n",
      "Epoch: 40\tFidelity = 0.500523\tKL_Divergence = 3.964164\n",
      "Epoch: 41\tFidelity = 0.500582\tKL_Divergence = 3.904381\n",
      "Epoch: 42\tFidelity = 0.500550\tKL_Divergence = 3.936695\n",
      "Epoch: 43\tFidelity = 0.500556\tKL_Divergence = 3.930271\n",
      "Epoch: 44\tFidelity = 0.500542\tKL_Divergence = 3.944758\n",
      "Epoch: 45\tFidelity = 0.500546\tKL_Divergence = 3.939835\n",
      "Epoch: 46\tFidelity = 0.500608\tKL_Divergence = 3.880882\n",
      "Epoch: 47\tFidelity = 0.500537\tKL_Divergence = 3.949691\n",
      "Epoch: 48\tFidelity = 0.500564\tKL_Divergence = 3.922058\n",
      "Epoch: 49\tFidelity = 0.500547\tKL_Divergence = 3.938932\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:37:29,669] Trial 613 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500542\tKL_Divergence = 3.943819\n",
      "Total time elapsed during training: 44.311 s\n",
      "Trial 613 pruned. \n",
      "Epoch: 1\tFidelity = 0.500446\tKL_Divergence = 4.052257\n",
      "Epoch: 2\tFidelity = 0.500544\tKL_Divergence = 3.941964\n",
      "Epoch: 3\tFidelity = 0.500667\tKL_Divergence = 3.829104\n",
      "Epoch: 4\tFidelity = 0.500566\tKL_Divergence = 3.919968\n",
      "Epoch: 5\tFidelity = 0.500568\tKL_Divergence = 3.918523\n",
      "Epoch: 6\tFidelity = 0.500494\tKL_Divergence = 3.995533\n",
      "Epoch: 7\tFidelity = 0.500609\tKL_Divergence = 3.879256\n",
      "Epoch: 8\tFidelity = 0.500620\tKL_Divergence = 3.869733\n",
      "Epoch: 9\tFidelity = 0.500548\tKL_Divergence = 3.938154\n",
      "Epoch: 10\tFidelity = 0.500548\tKL_Divergence = 3.938329\n",
      "Epoch: 11\tFidelity = 0.500555\tKL_Divergence = 3.930749\n",
      "Epoch: 12\tFidelity = 0.500597\tKL_Divergence = 3.890821\n",
      "Epoch: 13\tFidelity = 0.500557\tKL_Divergence = 3.929068\n",
      "Epoch: 14\tFidelity = 0.500474\tKL_Divergence = 4.019158\n",
      "Epoch: 15\tFidelity = 0.500638\tKL_Divergence = 3.853801\n",
      "Epoch: 16\tFidelity = 0.500600\tKL_Divergence = 3.887959\n",
      "Epoch: 17\tFidelity = 0.500607\tKL_Divergence = 3.880936\n",
      "Epoch: 18\tFidelity = 0.500513\tKL_Divergence = 3.975075\n",
      "Epoch: 19\tFidelity = 0.500544\tKL_Divergence = 3.942308\n",
      "Epoch: 20\tFidelity = 0.500580\tKL_Divergence = 3.906132\n",
      "Epoch: 21\tFidelity = 0.500635\tKL_Divergence = 3.855704\n",
      "Epoch: 22\tFidelity = 0.500580\tKL_Divergence = 3.905466\n",
      "Epoch: 23\tFidelity = 0.500625\tKL_Divergence = 3.863773\n",
      "Epoch: 24\tFidelity = 0.500635\tKL_Divergence = 3.854971\n",
      "Epoch: 25\tFidelity = 0.500491\tKL_Divergence = 3.997736\n",
      "Epoch: 26\tFidelity = 0.500632\tKL_Divergence = 3.858688\n",
      "Epoch: 27\tFidelity = 0.500588\tKL_Divergence = 3.897949\n",
      "Epoch: 28\tFidelity = 0.500503\tKL_Divergence = 3.985411\n",
      "Epoch: 29\tFidelity = 0.500570\tKL_Divergence = 3.914522\n",
      "Epoch: 30\tFidelity = 0.500663\tKL_Divergence = 3.831191\n",
      "Epoch: 31\tFidelity = 0.500558\tKL_Divergence = 3.926359\n",
      "Epoch: 32\tFidelity = 0.500622\tKL_Divergence = 3.865944\n",
      "Epoch: 33\tFidelity = 0.500601\tKL_Divergence = 3.884008\n",
      "Epoch: 34\tFidelity = 0.500506\tKL_Divergence = 3.978827\n",
      "Epoch: 35\tFidelity = 0.500581\tKL_Divergence = 3.901937\n",
      "Epoch: 36\tFidelity = 0.500565\tKL_Divergence = 3.919177\n",
      "Epoch: 37\tFidelity = 0.500539\tKL_Divergence = 3.946337\n",
      "Epoch: 38\tFidelity = 0.500510\tKL_Divergence = 3.976928\n",
      "Epoch: 39\tFidelity = 0.500563\tKL_Divergence = 3.922900\n",
      "Epoch: 40\tFidelity = 0.500670\tKL_Divergence = 3.825763\n",
      "Epoch: 41\tFidelity = 0.500651\tKL_Divergence = 3.842123\n",
      "Epoch: 42\tFidelity = 0.500439\tKL_Divergence = 4.060878\n",
      "Epoch: 43\tFidelity = 0.500497\tKL_Divergence = 3.992504\n",
      "Epoch: 44\tFidelity = 0.500613\tKL_Divergence = 3.875641\n",
      "Epoch: 45\tFidelity = 0.500638\tKL_Divergence = 3.854144\n",
      "Epoch: 46\tFidelity = 0.500666\tKL_Divergence = 3.829865\n",
      "Epoch: 47\tFidelity = 0.500591\tKL_Divergence = 3.896231\n",
      "Epoch: 48\tFidelity = 0.500722\tKL_Divergence = 3.784912\n",
      "Epoch: 49\tFidelity = 0.500660\tKL_Divergence = 3.834909\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:38:06,832] Trial 614 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500496\tKL_Divergence = 3.993686\n",
      "Total time elapsed during training: 36.982 s\n",
      "Trial 614 pruned. \n",
      "Epoch: 1\tFidelity = 0.500536\tKL_Divergence = 3.950486\n",
      "Epoch: 2\tFidelity = 0.500549\tKL_Divergence = 3.936776\n",
      "Epoch: 3\tFidelity = 0.500534\tKL_Divergence = 3.952060\n",
      "Epoch: 4\tFidelity = 0.500555\tKL_Divergence = 3.931052\n",
      "Epoch: 5\tFidelity = 0.500536\tKL_Divergence = 3.950594\n",
      "Epoch: 6\tFidelity = 0.500544\tKL_Divergence = 3.942596\n",
      "Epoch: 7\tFidelity = 0.500539\tKL_Divergence = 3.947305\n",
      "Epoch: 8\tFidelity = 0.500549\tKL_Divergence = 3.937009\n",
      "Epoch: 9\tFidelity = 0.500560\tKL_Divergence = 3.926013\n",
      "Epoch: 10\tFidelity = 0.500548\tKL_Divergence = 3.938492\n",
      "Epoch: 11\tFidelity = 0.500553\tKL_Divergence = 3.933418\n",
      "Epoch: 12\tFidelity = 0.500567\tKL_Divergence = 3.919037\n",
      "Epoch: 13\tFidelity = 0.500583\tKL_Divergence = 3.903612\n",
      "Epoch: 14\tFidelity = 0.500554\tKL_Divergence = 3.931887\n",
      "Epoch: 15\tFidelity = 0.500588\tKL_Divergence = 3.899092\n",
      "Epoch: 16\tFidelity = 0.500566\tKL_Divergence = 3.920557\n",
      "Epoch: 17\tFidelity = 0.500600\tKL_Divergence = 3.887802\n",
      "Epoch: 18\tFidelity = 0.500569\tKL_Divergence = 3.917097\n",
      "Epoch: 19\tFidelity = 0.500552\tKL_Divergence = 3.933968\n",
      "Epoch: 20\tFidelity = 0.500539\tKL_Divergence = 3.947251\n",
      "Epoch: 21\tFidelity = 0.500561\tKL_Divergence = 3.924750\n",
      "Epoch: 22\tFidelity = 0.500541\tKL_Divergence = 3.945785\n",
      "Epoch: 23\tFidelity = 0.500563\tKL_Divergence = 3.923003\n",
      "Epoch: 24\tFidelity = 0.500561\tKL_Divergence = 3.925163\n",
      "Epoch: 25\tFidelity = 0.500574\tKL_Divergence = 3.912848\n",
      "Epoch: 26\tFidelity = 0.500559\tKL_Divergence = 3.927567\n",
      "Epoch: 27\tFidelity = 0.500559\tKL_Divergence = 3.926936\n",
      "Epoch: 28\tFidelity = 0.500559\tKL_Divergence = 3.926948\n",
      "Epoch: 29\tFidelity = 0.500593\tKL_Divergence = 3.894544\n",
      "Epoch: 30\tFidelity = 0.500562\tKL_Divergence = 3.924242\n",
      "Epoch: 31\tFidelity = 0.500560\tKL_Divergence = 3.926053\n",
      "Epoch: 32\tFidelity = 0.500565\tKL_Divergence = 3.921454\n",
      "Epoch: 33\tFidelity = 0.500577\tKL_Divergence = 3.910011\n",
      "Epoch: 34\tFidelity = 0.500563\tKL_Divergence = 3.923364\n",
      "Epoch: 35\tFidelity = 0.500534\tKL_Divergence = 3.952683\n",
      "Epoch: 36\tFidelity = 0.500584\tKL_Divergence = 3.902490\n",
      "Epoch: 37\tFidelity = 0.500578\tKL_Divergence = 3.908280\n",
      "Epoch: 38\tFidelity = 0.500549\tKL_Divergence = 3.937487\n",
      "Epoch: 39\tFidelity = 0.500563\tKL_Divergence = 3.923444\n",
      "Epoch: 40\tFidelity = 0.500582\tKL_Divergence = 3.904979\n",
      "Epoch: 41\tFidelity = 0.500589\tKL_Divergence = 3.898186\n",
      "Epoch: 42\tFidelity = 0.500619\tKL_Divergence = 3.870499\n",
      "Epoch: 43\tFidelity = 0.500587\tKL_Divergence = 3.900090\n",
      "Epoch: 44\tFidelity = 0.500587\tKL_Divergence = 3.899884\n",
      "Epoch: 45\tFidelity = 0.500547\tKL_Divergence = 3.939197\n",
      "Epoch: 46\tFidelity = 0.500542\tKL_Divergence = 3.944666\n",
      "Epoch: 47\tFidelity = 0.500564\tKL_Divergence = 3.922178\n",
      "Epoch: 48\tFidelity = 0.500561\tKL_Divergence = 3.924982\n",
      "Epoch: 49\tFidelity = 0.500532\tKL_Divergence = 3.954413\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:38:38,199] Trial 615 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500591\tKL_Divergence = 3.896710\n",
      "Total time elapsed during training: 31.185 s\n",
      "Trial 615 pruned. \n",
      "Epoch: 1\tFidelity = 0.500533\tKL_Divergence = 3.953563\n",
      "Epoch: 2\tFidelity = 0.500509\tKL_Divergence = 3.979152\n",
      "Epoch: 3\tFidelity = 0.500524\tKL_Divergence = 3.963460\n",
      "Epoch: 4\tFidelity = 0.500581\tKL_Divergence = 3.905878\n",
      "Epoch: 5\tFidelity = 0.500575\tKL_Divergence = 3.911816\n",
      "Epoch: 6\tFidelity = 0.500599\tKL_Divergence = 3.888962\n",
      "Epoch: 7\tFidelity = 0.500598\tKL_Divergence = 3.889632\n",
      "Epoch: 8\tFidelity = 0.500564\tKL_Divergence = 3.921865\n",
      "Epoch: 9\tFidelity = 0.500555\tKL_Divergence = 3.931274\n",
      "Epoch: 10\tFidelity = 0.500577\tKL_Divergence = 3.909229\n",
      "Epoch: 11\tFidelity = 0.500568\tKL_Divergence = 3.918533\n",
      "Epoch: 12\tFidelity = 0.500539\tKL_Divergence = 3.947355\n",
      "Epoch: 13\tFidelity = 0.500564\tKL_Divergence = 3.922702\n",
      "Epoch: 14\tFidelity = 0.500524\tKL_Divergence = 3.963519\n",
      "Epoch: 15\tFidelity = 0.500600\tKL_Divergence = 3.887908\n",
      "Epoch: 16\tFidelity = 0.500557\tKL_Divergence = 3.929485\n",
      "Epoch: 17\tFidelity = 0.500551\tKL_Divergence = 3.935129\n",
      "Epoch: 18\tFidelity = 0.500605\tKL_Divergence = 3.883259\n",
      "Epoch: 19\tFidelity = 0.500634\tKL_Divergence = 3.857304\n",
      "Epoch: 20\tFidelity = 0.500550\tKL_Divergence = 3.936473\n",
      "Epoch: 21\tFidelity = 0.500578\tKL_Divergence = 3.908294\n",
      "Epoch: 22\tFidelity = 0.500554\tKL_Divergence = 3.932224\n",
      "Epoch: 23\tFidelity = 0.500612\tKL_Divergence = 3.876857\n",
      "Epoch: 24\tFidelity = 0.500528\tKL_Divergence = 3.958543\n",
      "Epoch: 25\tFidelity = 0.500641\tKL_Divergence = 3.850814\n",
      "Epoch: 26\tFidelity = 0.500524\tKL_Divergence = 3.963062\n",
      "Epoch: 27\tFidelity = 0.500596\tKL_Divergence = 3.891205\n",
      "Epoch: 28\tFidelity = 0.500581\tKL_Divergence = 3.905598\n",
      "Epoch: 29\tFidelity = 0.500554\tKL_Divergence = 3.932473\n",
      "Epoch: 30\tFidelity = 0.500564\tKL_Divergence = 3.922195\n",
      "Epoch: 31\tFidelity = 0.500522\tKL_Divergence = 3.964630\n",
      "Epoch: 32\tFidelity = 0.500622\tKL_Divergence = 3.868121\n",
      "Epoch: 33\tFidelity = 0.500603\tKL_Divergence = 3.884957\n",
      "Epoch: 34\tFidelity = 0.500584\tKL_Divergence = 3.902646\n",
      "Epoch: 35\tFidelity = 0.500532\tKL_Divergence = 3.954706\n",
      "Epoch: 36\tFidelity = 0.500546\tKL_Divergence = 3.939684\n",
      "Epoch: 37\tFidelity = 0.500590\tKL_Divergence = 3.897487\n",
      "Epoch: 38\tFidelity = 0.500552\tKL_Divergence = 3.933625\n",
      "Epoch: 39\tFidelity = 0.500561\tKL_Divergence = 3.925185\n",
      "Epoch: 40\tFidelity = 0.500596\tKL_Divergence = 3.891873\n",
      "Epoch: 41\tFidelity = 0.500611\tKL_Divergence = 3.878044\n",
      "Epoch: 42\tFidelity = 0.500620\tKL_Divergence = 3.869437\n",
      "Epoch: 43\tFidelity = 0.500606\tKL_Divergence = 3.882133\n",
      "Epoch: 44\tFidelity = 0.500578\tKL_Divergence = 3.908638\n",
      "Epoch: 45\tFidelity = 0.500607\tKL_Divergence = 3.880980\n",
      "Epoch: 46\tFidelity = 0.500577\tKL_Divergence = 3.909099\n",
      "Epoch: 47\tFidelity = 0.500555\tKL_Divergence = 3.931021\n",
      "Epoch: 48\tFidelity = 0.500519\tKL_Divergence = 3.968235\n",
      "Epoch: 49\tFidelity = 0.500538\tKL_Divergence = 3.948382\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:39:17,678] Trial 616 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500520\tKL_Divergence = 3.967674\n",
      "Total time elapsed during training: 39.215 s\n",
      "Trial 616 pruned. \n",
      "Epoch: 1\tFidelity = 0.500573\tKL_Divergence = 3.913777\n",
      "Epoch: 2\tFidelity = 0.500539\tKL_Divergence = 3.947796\n",
      "Epoch: 3\tFidelity = 0.500611\tKL_Divergence = 3.877577\n",
      "Epoch: 4\tFidelity = 0.500666\tKL_Divergence = 3.829669\n",
      "Epoch: 5\tFidelity = 0.500574\tKL_Divergence = 3.912200\n",
      "Epoch: 6\tFidelity = 0.500494\tKL_Divergence = 3.995801\n",
      "Epoch: 7\tFidelity = 0.500483\tKL_Divergence = 4.008132\n",
      "Epoch: 8\tFidelity = 0.500568\tKL_Divergence = 3.918190\n",
      "Epoch: 9\tFidelity = 0.500527\tKL_Divergence = 3.960322\n",
      "Epoch: 10\tFidelity = 0.500581\tKL_Divergence = 3.906000\n",
      "Epoch: 11\tFidelity = 0.500636\tKL_Divergence = 3.855551\n",
      "Epoch: 12\tFidelity = 0.500605\tKL_Divergence = 3.883419\n",
      "Epoch: 13\tFidelity = 0.500574\tKL_Divergence = 3.911961\n",
      "Epoch: 14\tFidelity = 0.500482\tKL_Divergence = 4.008790\n",
      "Epoch: 15\tFidelity = 0.500527\tKL_Divergence = 3.959510\n",
      "Epoch: 16\tFidelity = 0.500636\tKL_Divergence = 3.855674\n",
      "Epoch: 17\tFidelity = 0.500723\tKL_Divergence = 3.784629\n",
      "Epoch: 18\tFidelity = 0.500585\tKL_Divergence = 3.901835\n",
      "Epoch: 19\tFidelity = 0.500489\tKL_Divergence = 4.001474\n",
      "Epoch: 20\tFidelity = 0.500570\tKL_Divergence = 3.916349\n",
      "Epoch: 21\tFidelity = 0.500553\tKL_Divergence = 3.933339\n",
      "Epoch: 22\tFidelity = 0.500511\tKL_Divergence = 3.976510\n",
      "Epoch: 23\tFidelity = 0.500483\tKL_Divergence = 4.008518\n",
      "Epoch: 24\tFidelity = 0.500596\tKL_Divergence = 3.891379\n",
      "Epoch: 25\tFidelity = 0.500578\tKL_Divergence = 3.908690\n",
      "Epoch: 26\tFidelity = 0.500561\tKL_Divergence = 3.925015\n",
      "Epoch: 27\tFidelity = 0.500596\tKL_Divergence = 3.891720\n",
      "Epoch: 28\tFidelity = 0.500563\tKL_Divergence = 3.923470\n",
      "Epoch: 29\tFidelity = 0.500543\tKL_Divergence = 3.942843\n",
      "Epoch: 30\tFidelity = 0.500627\tKL_Divergence = 3.863182\n",
      "Epoch: 31\tFidelity = 0.500661\tKL_Divergence = 3.834018\n",
      "Epoch: 32\tFidelity = 0.500619\tKL_Divergence = 3.870306\n",
      "Epoch: 33\tFidelity = 0.500732\tKL_Divergence = 3.777218\n",
      "Epoch: 34\tFidelity = 0.500622\tKL_Divergence = 3.867779\n",
      "Epoch: 35\tFidelity = 0.500555\tKL_Divergence = 3.930640\n",
      "Epoch: 36\tFidelity = 0.500611\tKL_Divergence = 3.877533\n",
      "Epoch: 37\tFidelity = 0.500630\tKL_Divergence = 3.861013\n",
      "Epoch: 38\tFidelity = 0.500663\tKL_Divergence = 3.832625\n",
      "Epoch: 39\tFidelity = 0.500536\tKL_Divergence = 3.950768\n",
      "Epoch: 40\tFidelity = 0.500600\tKL_Divergence = 3.887353\n",
      "Epoch: 41\tFidelity = 0.500597\tKL_Divergence = 3.890630\n",
      "Epoch: 42\tFidelity = 0.500642\tKL_Divergence = 3.850092\n",
      "Epoch: 43\tFidelity = 0.500559\tKL_Divergence = 3.927392\n",
      "Epoch: 44\tFidelity = 0.500624\tKL_Divergence = 3.865945\n",
      "Epoch: 45\tFidelity = 0.500597\tKL_Divergence = 3.890875\n",
      "Epoch: 46\tFidelity = 0.500610\tKL_Divergence = 3.878690\n",
      "Epoch: 47\tFidelity = 0.500619\tKL_Divergence = 3.870878\n",
      "Epoch: 48\tFidelity = 0.500546\tKL_Divergence = 3.940438\n",
      "Epoch: 49\tFidelity = 0.500608\tKL_Divergence = 3.880490\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:39:51,246] Trial 617 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500638\tKL_Divergence = 3.853893\n",
      "Total time elapsed during training: 33.374 s\n",
      "Trial 617 pruned. \n",
      "Epoch: 1\tFidelity = 0.500603\tKL_Divergence = 3.885153\n",
      "Epoch: 2\tFidelity = 0.500646\tKL_Divergence = 3.846588\n",
      "Epoch: 3\tFidelity = 0.500594\tKL_Divergence = 3.893666\n",
      "Epoch: 4\tFidelity = 0.500633\tKL_Divergence = 3.858353\n",
      "Epoch: 5\tFidelity = 0.500561\tKL_Divergence = 3.925101\n",
      "Epoch: 6\tFidelity = 0.500566\tKL_Divergence = 3.919855\n",
      "Epoch: 7\tFidelity = 0.500585\tKL_Divergence = 3.901536\n",
      "Epoch: 8\tFidelity = 0.500582\tKL_Divergence = 3.904287\n",
      "Epoch: 9\tFidelity = 0.500606\tKL_Divergence = 3.881936\n",
      "Epoch: 10\tFidelity = 0.500594\tKL_Divergence = 3.893398\n",
      "Epoch: 11\tFidelity = 0.500556\tKL_Divergence = 3.930017\n",
      "Epoch: 12\tFidelity = 0.500590\tKL_Divergence = 3.897137\n",
      "Epoch: 13\tFidelity = 0.500554\tKL_Divergence = 3.931959\n",
      "Epoch: 14\tFidelity = 0.500547\tKL_Divergence = 3.939458\n",
      "Epoch: 15\tFidelity = 0.500574\tKL_Divergence = 3.912104\n",
      "Epoch: 16\tFidelity = 0.500612\tKL_Divergence = 3.877055\n",
      "Epoch: 17\tFidelity = 0.500561\tKL_Divergence = 3.925375\n",
      "Epoch: 18\tFidelity = 0.500540\tKL_Divergence = 3.946751\n",
      "Epoch: 19\tFidelity = 0.500591\tKL_Divergence = 3.896641\n",
      "Epoch: 20\tFidelity = 0.500584\tKL_Divergence = 3.902688\n",
      "Epoch: 21\tFidelity = 0.500607\tKL_Divergence = 3.881398\n",
      "Epoch: 22\tFidelity = 0.500584\tKL_Divergence = 3.902874\n",
      "Epoch: 23\tFidelity = 0.500580\tKL_Divergence = 3.906961\n",
      "Epoch: 24\tFidelity = 0.500595\tKL_Divergence = 3.892051\n",
      "Epoch: 25\tFidelity = 0.500570\tKL_Divergence = 3.916095\n",
      "Epoch: 26\tFidelity = 0.500607\tKL_Divergence = 3.881832\n",
      "Epoch: 27\tFidelity = 0.500584\tKL_Divergence = 3.903180\n",
      "Epoch: 28\tFidelity = 0.500562\tKL_Divergence = 3.923806\n",
      "Epoch: 29\tFidelity = 0.500591\tKL_Divergence = 3.896566\n",
      "Epoch: 30\tFidelity = 0.500618\tKL_Divergence = 3.871851\n",
      "Epoch: 31\tFidelity = 0.500586\tKL_Divergence = 3.900792\n",
      "Epoch: 32\tFidelity = 0.500556\tKL_Divergence = 3.929716\n",
      "Epoch: 33\tFidelity = 0.500531\tKL_Divergence = 3.955152\n",
      "Epoch: 34\tFidelity = 0.500532\tKL_Divergence = 3.954365\n",
      "Epoch: 35\tFidelity = 0.500591\tKL_Divergence = 3.896475\n",
      "Epoch: 36\tFidelity = 0.500556\tKL_Divergence = 3.930269\n",
      "Epoch: 37\tFidelity = 0.500548\tKL_Divergence = 3.938645\n",
      "Epoch: 38\tFidelity = 0.500558\tKL_Divergence = 3.928608\n",
      "Epoch: 39\tFidelity = 0.500629\tKL_Divergence = 3.861941\n",
      "Epoch: 40\tFidelity = 0.500583\tKL_Divergence = 3.903883\n",
      "Epoch: 41\tFidelity = 0.500603\tKL_Divergence = 3.885381\n",
      "Epoch: 42\tFidelity = 0.500572\tKL_Divergence = 3.914660\n",
      "Epoch: 43\tFidelity = 0.500537\tKL_Divergence = 3.949341\n",
      "Epoch: 44\tFidelity = 0.500533\tKL_Divergence = 3.953577\n",
      "Epoch: 45\tFidelity = 0.500525\tKL_Divergence = 3.962479\n",
      "Epoch: 46\tFidelity = 0.500592\tKL_Divergence = 3.895684\n",
      "Epoch: 47\tFidelity = 0.500555\tKL_Divergence = 3.931569\n",
      "Epoch: 48\tFidelity = 0.500558\tKL_Divergence = 3.928478\n",
      "Epoch: 49\tFidelity = 0.500626\tKL_Divergence = 3.864212\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:40:31,773] Trial 618 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500575\tKL_Divergence = 3.911217\n",
      "Total time elapsed during training: 40.309 s\n",
      "Trial 618 pruned. \n",
      "Epoch: 1\tFidelity = 0.500635\tKL_Divergence = 3.856499\n",
      "Epoch: 2\tFidelity = 0.500534\tKL_Divergence = 3.952816\n",
      "Epoch: 3\tFidelity = 0.500638\tKL_Divergence = 3.853902\n",
      "Epoch: 4\tFidelity = 0.500549\tKL_Divergence = 3.936775\n",
      "Epoch: 5\tFidelity = 0.500624\tKL_Divergence = 3.864690\n",
      "Epoch: 6\tFidelity = 0.500648\tKL_Divergence = 3.844702\n",
      "Epoch: 7\tFidelity = 0.500610\tKL_Divergence = 3.879075\n",
      "Epoch: 8\tFidelity = 0.500491\tKL_Divergence = 3.998211\n",
      "Epoch: 9\tFidelity = 0.500599\tKL_Divergence = 3.888546\n",
      "Epoch: 10\tFidelity = 0.500586\tKL_Divergence = 3.901079\n",
      "Epoch: 11\tFidelity = 0.500606\tKL_Divergence = 3.882009\n",
      "Epoch: 12\tFidelity = 0.500557\tKL_Divergence = 3.929090\n",
      "Epoch: 13\tFidelity = 0.500777\tKL_Divergence = 3.744358\n",
      "Epoch: 14\tFidelity = 0.500618\tKL_Divergence = 3.871246\n",
      "Epoch: 15\tFidelity = 0.500509\tKL_Divergence = 3.979490\n",
      "Epoch: 16\tFidelity = 0.500546\tKL_Divergence = 3.940644\n",
      "Epoch: 17\tFidelity = 0.500584\tKL_Divergence = 3.902757\n",
      "Epoch: 18\tFidelity = 0.500627\tKL_Divergence = 3.863682\n",
      "Epoch: 19\tFidelity = 0.500499\tKL_Divergence = 3.989950\n",
      "Epoch: 20\tFidelity = 0.500430\tKL_Divergence = 4.072663\n",
      "Epoch: 21\tFidelity = 0.500426\tKL_Divergence = 4.077646\n",
      "Epoch: 22\tFidelity = 0.500633\tKL_Divergence = 3.857463\n",
      "Epoch: 23\tFidelity = 0.500514\tKL_Divergence = 3.972133\n",
      "Epoch: 24\tFidelity = 0.500675\tKL_Divergence = 3.820536\n",
      "Epoch: 25\tFidelity = 0.500584\tKL_Divergence = 3.900812\n",
      "Epoch: 26\tFidelity = 0.500544\tKL_Divergence = 3.940057\n",
      "Epoch: 27\tFidelity = 0.500601\tKL_Divergence = 3.885591\n",
      "Epoch: 28\tFidelity = 0.500614\tKL_Divergence = 3.874058\n",
      "Epoch: 29\tFidelity = 0.500512\tKL_Divergence = 3.974988\n",
      "Epoch: 30\tFidelity = 0.500564\tKL_Divergence = 3.922243\n",
      "Epoch: 31\tFidelity = 0.500594\tKL_Divergence = 3.893059\n",
      "Epoch: 32\tFidelity = 0.500564\tKL_Divergence = 3.922057\n",
      "Epoch: 33\tFidelity = 0.500665\tKL_Divergence = 3.831033\n",
      "Epoch: 34\tFidelity = 0.500622\tKL_Divergence = 3.868180\n",
      "Epoch: 35\tFidelity = 0.500692\tKL_Divergence = 3.807929\n",
      "Epoch: 36\tFidelity = 0.500513\tKL_Divergence = 3.974761\n",
      "Epoch: 37\tFidelity = 0.500678\tKL_Divergence = 3.820063\n",
      "Epoch: 38\tFidelity = 0.500568\tKL_Divergence = 3.918855\n",
      "Epoch: 39\tFidelity = 0.500449\tKL_Divergence = 4.048694\n",
      "Epoch: 40\tFidelity = 0.500524\tKL_Divergence = 3.962312\n",
      "Epoch: 41\tFidelity = 0.500644\tKL_Divergence = 3.848590\n",
      "Epoch: 42\tFidelity = 0.500637\tKL_Divergence = 3.853883\n",
      "Epoch: 43\tFidelity = 0.500613\tKL_Divergence = 3.876178\n",
      "Epoch: 44\tFidelity = 0.500535\tKL_Divergence = 3.951157\n",
      "Epoch: 45\tFidelity = 0.500579\tKL_Divergence = 3.907298\n",
      "Epoch: 46\tFidelity = 0.500468\tKL_Divergence = 4.025294\n",
      "Epoch: 47\tFidelity = 0.500453\tKL_Divergence = 4.043210\n",
      "Epoch: 48\tFidelity = 0.500505\tKL_Divergence = 3.983102\n",
      "Epoch: 49\tFidelity = 0.500539\tKL_Divergence = 3.946784\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:41:18,503] Trial 619 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500502\tKL_Divergence = 3.986829\n",
      "Total time elapsed during training: 46.528 s\n",
      "Trial 619 pruned. \n",
      "Epoch: 1\tFidelity = 0.500575\tKL_Divergence = 3.911794\n",
      "Epoch: 2\tFidelity = 0.500629\tKL_Divergence = 3.861565\n",
      "Epoch: 3\tFidelity = 0.500471\tKL_Divergence = 4.021770\n",
      "Epoch: 4\tFidelity = 0.500691\tKL_Divergence = 3.809729\n",
      "Epoch: 5\tFidelity = 0.500493\tKL_Divergence = 3.997210\n",
      "Epoch: 6\tFidelity = 0.500546\tKL_Divergence = 3.940434\n",
      "Epoch: 7\tFidelity = 0.500471\tKL_Divergence = 4.022237\n",
      "Epoch: 8\tFidelity = 0.500503\tKL_Divergence = 3.986379\n",
      "Epoch: 9\tFidelity = 0.500557\tKL_Divergence = 3.929442\n",
      "Epoch: 10\tFidelity = 0.500506\tKL_Divergence = 3.982252\n",
      "Epoch: 11\tFidelity = 0.500489\tKL_Divergence = 4.001121\n",
      "Epoch: 12\tFidelity = 0.500528\tKL_Divergence = 3.958785\n",
      "Epoch: 13\tFidelity = 0.500650\tKL_Divergence = 3.843701\n",
      "Epoch: 14\tFidelity = 0.500602\tKL_Divergence = 3.886053\n",
      "Epoch: 15\tFidelity = 0.500583\tKL_Divergence = 3.904010\n",
      "Epoch: 16\tFidelity = 0.500598\tKL_Divergence = 3.889589\n",
      "Epoch: 17\tFidelity = 0.500634\tKL_Divergence = 3.857843\n",
      "Epoch: 18\tFidelity = 0.500584\tKL_Divergence = 3.903145\n",
      "Epoch: 19\tFidelity = 0.500489\tKL_Divergence = 4.001282\n",
      "Epoch: 20\tFidelity = 0.500577\tKL_Divergence = 3.910104\n",
      "Epoch: 21\tFidelity = 0.500615\tKL_Divergence = 3.874455\n",
      "Epoch: 22\tFidelity = 0.500538\tKL_Divergence = 3.948331\n",
      "Epoch: 23\tFidelity = 0.500648\tKL_Divergence = 3.845228\n",
      "Epoch: 24\tFidelity = 0.500556\tKL_Divergence = 3.930819\n",
      "Epoch: 25\tFidelity = 0.500539\tKL_Divergence = 3.947459\n",
      "Epoch: 26\tFidelity = 0.500489\tKL_Divergence = 4.001395\n",
      "Epoch: 27\tFidelity = 0.500495\tKL_Divergence = 3.994944\n",
      "Epoch: 28\tFidelity = 0.500519\tKL_Divergence = 3.968418\n",
      "Epoch: 29\tFidelity = 0.500636\tKL_Divergence = 3.856025\n",
      "Epoch: 30\tFidelity = 0.500474\tKL_Divergence = 4.018424\n",
      "Epoch: 31\tFidelity = 0.500554\tKL_Divergence = 3.932488\n",
      "Epoch: 32\tFidelity = 0.500681\tKL_Divergence = 3.817696\n",
      "Epoch: 33\tFidelity = 0.500569\tKL_Divergence = 3.916875\n",
      "Epoch: 34\tFidelity = 0.500515\tKL_Divergence = 3.972641\n",
      "Epoch: 35\tFidelity = 0.500662\tKL_Divergence = 3.833277\n",
      "Epoch: 36\tFidelity = 0.500587\tKL_Divergence = 3.899715\n",
      "Epoch: 37\tFidelity = 0.500557\tKL_Divergence = 3.928732\n",
      "Epoch: 38\tFidelity = 0.500541\tKL_Divergence = 3.945717\n",
      "Epoch: 39\tFidelity = 0.500623\tKL_Divergence = 3.867107\n",
      "Epoch: 40\tFidelity = 0.500553\tKL_Divergence = 3.933077\n",
      "Epoch: 41\tFidelity = 0.500542\tKL_Divergence = 3.944401\n",
      "Epoch: 42\tFidelity = 0.500486\tKL_Divergence = 4.004755\n",
      "Epoch: 43\tFidelity = 0.500555\tKL_Divergence = 3.930875\n",
      "Epoch: 44\tFidelity = 0.500574\tKL_Divergence = 3.912663\n",
      "Epoch: 45\tFidelity = 0.500487\tKL_Divergence = 4.003751\n",
      "Epoch: 46\tFidelity = 0.500510\tKL_Divergence = 3.978204\n",
      "Epoch: 47\tFidelity = 0.500476\tKL_Divergence = 4.016427\n",
      "Epoch: 48\tFidelity = 0.500552\tKL_Divergence = 3.934564\n",
      "Epoch: 49\tFidelity = 0.500575\tKL_Divergence = 3.911602\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:42:46,723] Trial 620 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500561\tKL_Divergence = 3.925700\n",
      "Total time elapsed during training: 88.040 s\n",
      "Trial 620 pruned. \n",
      "Epoch: 1\tFidelity = 0.500599\tKL_Divergence = 3.888860\n",
      "Epoch: 2\tFidelity = 0.500555\tKL_Divergence = 3.931174\n",
      "Epoch: 3\tFidelity = 0.500599\tKL_Divergence = 3.889006\n",
      "Epoch: 4\tFidelity = 0.500517\tKL_Divergence = 3.970627\n",
      "Epoch: 5\tFidelity = 0.500551\tKL_Divergence = 3.935246\n",
      "Epoch: 6\tFidelity = 0.500449\tKL_Divergence = 4.049096\n",
      "Epoch: 7\tFidelity = 0.500513\tKL_Divergence = 3.974327\n",
      "Epoch: 8\tFidelity = 0.500697\tKL_Divergence = 3.804387\n",
      "Epoch: 9\tFidelity = 0.500543\tKL_Divergence = 3.942901\n",
      "Epoch: 10\tFidelity = 0.500486\tKL_Divergence = 4.004511\n",
      "Epoch: 11\tFidelity = 0.500549\tKL_Divergence = 3.937305\n",
      "Epoch: 12\tFidelity = 0.500577\tKL_Divergence = 3.909209\n",
      "Epoch: 13\tFidelity = 0.500624\tKL_Divergence = 3.866571\n",
      "Epoch: 14\tFidelity = 0.500568\tKL_Divergence = 3.918733\n",
      "Epoch: 15\tFidelity = 0.500490\tKL_Divergence = 4.000189\n",
      "Epoch: 16\tFidelity = 0.500509\tKL_Divergence = 3.978110\n",
      "Epoch: 17\tFidelity = 0.500505\tKL_Divergence = 3.983788\n",
      "Epoch: 18\tFidelity = 0.500543\tKL_Divergence = 3.942317\n",
      "Epoch: 19\tFidelity = 0.500517\tKL_Divergence = 3.969427\n",
      "Epoch: 20\tFidelity = 0.500665\tKL_Divergence = 3.829729\n",
      "Epoch: 21\tFidelity = 0.500507\tKL_Divergence = 3.980499\n",
      "Epoch: 22\tFidelity = 0.500553\tKL_Divergence = 3.932434\n",
      "Epoch: 23\tFidelity = 0.500606\tKL_Divergence = 3.882119\n",
      "Epoch: 24\tFidelity = 0.500518\tKL_Divergence = 3.969158\n",
      "Epoch: 25\tFidelity = 0.500550\tKL_Divergence = 3.935743\n",
      "Epoch: 26\tFidelity = 0.500619\tKL_Divergence = 3.869734\n",
      "Epoch: 27\tFidelity = 0.500575\tKL_Divergence = 3.911271\n",
      "Epoch: 28\tFidelity = 0.500477\tKL_Divergence = 4.015227\n",
      "Epoch: 29\tFidelity = 0.500542\tKL_Divergence = 3.943995\n",
      "Epoch: 30\tFidelity = 0.500529\tKL_Divergence = 3.956354\n",
      "Epoch: 31\tFidelity = 0.500459\tKL_Divergence = 4.035553\n",
      "Epoch: 32\tFidelity = 0.500564\tKL_Divergence = 3.922092\n",
      "Epoch: 33\tFidelity = 0.500504\tKL_Divergence = 3.984121\n",
      "Epoch: 34\tFidelity = 0.500505\tKL_Divergence = 3.983011\n",
      "Epoch: 35\tFidelity = 0.500597\tKL_Divergence = 3.888900\n",
      "Epoch: 36\tFidelity = 0.500642\tKL_Divergence = 3.850093\n",
      "Epoch: 37\tFidelity = 0.500511\tKL_Divergence = 3.976740\n",
      "Epoch: 38\tFidelity = 0.500606\tKL_Divergence = 3.880999\n",
      "Epoch: 39\tFidelity = 0.500512\tKL_Divergence = 3.975038\n",
      "Epoch: 40\tFidelity = 0.500683\tKL_Divergence = 3.814842\n",
      "Epoch: 41\tFidelity = 0.500592\tKL_Divergence = 3.894080\n",
      "Epoch: 42\tFidelity = 0.500583\tKL_Divergence = 3.903201\n",
      "Epoch: 43\tFidelity = 0.500483\tKL_Divergence = 4.007588\n",
      "Epoch: 44\tFidelity = 0.500478\tKL_Divergence = 4.013192\n",
      "Epoch: 45\tFidelity = 0.500619\tKL_Divergence = 3.869627\n",
      "Epoch: 46\tFidelity = 0.500526\tKL_Divergence = 3.960271\n",
      "Epoch: 47\tFidelity = 0.500528\tKL_Divergence = 3.958113\n",
      "Epoch: 48\tFidelity = 0.500516\tKL_Divergence = 3.970715\n",
      "Epoch: 49\tFidelity = 0.500470\tKL_Divergence = 4.022334\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:43:28,083] Trial 621 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500615\tKL_Divergence = 3.873340\n",
      "Total time elapsed during training: 41.167 s\n",
      "Trial 621 pruned. \n",
      "Epoch: 1\tFidelity = 0.500545\tKL_Divergence = 3.940049\n",
      "Epoch: 2\tFidelity = 0.500552\tKL_Divergence = 3.933171\n",
      "Epoch: 3\tFidelity = 0.500562\tKL_Divergence = 3.923989\n",
      "Epoch: 4\tFidelity = 0.500612\tKL_Divergence = 3.876269\n",
      "Epoch: 5\tFidelity = 0.500614\tKL_Divergence = 3.874122\n",
      "Epoch: 6\tFidelity = 0.500539\tKL_Divergence = 3.947149\n",
      "Epoch: 7\tFidelity = 0.500586\tKL_Divergence = 3.900830\n",
      "Epoch: 8\tFidelity = 0.500567\tKL_Divergence = 3.919037\n",
      "Epoch: 9\tFidelity = 0.500597\tKL_Divergence = 3.890000\n",
      "Epoch: 10\tFidelity = 0.500601\tKL_Divergence = 3.886591\n",
      "Epoch: 11\tFidelity = 0.500600\tKL_Divergence = 3.887677\n",
      "Epoch: 12\tFidelity = 0.500511\tKL_Divergence = 3.976327\n",
      "Epoch: 13\tFidelity = 0.500505\tKL_Divergence = 3.983095\n",
      "Epoch: 14\tFidelity = 0.500577\tKL_Divergence = 3.909285\n",
      "Epoch: 15\tFidelity = 0.500555\tKL_Divergence = 3.930878\n",
      "Epoch: 16\tFidelity = 0.500552\tKL_Divergence = 3.933980\n",
      "Epoch: 17\tFidelity = 0.500541\tKL_Divergence = 3.945313\n",
      "Epoch: 18\tFidelity = 0.500610\tKL_Divergence = 3.878476\n",
      "Epoch: 19\tFidelity = 0.500661\tKL_Divergence = 3.833773\n",
      "Epoch: 20\tFidelity = 0.500585\tKL_Divergence = 3.902164\n",
      "Epoch: 21\tFidelity = 0.500528\tKL_Divergence = 3.958955\n",
      "Epoch: 22\tFidelity = 0.500574\tKL_Divergence = 3.912458\n",
      "Epoch: 23\tFidelity = 0.500577\tKL_Divergence = 3.909705\n",
      "Epoch: 24\tFidelity = 0.500590\tKL_Divergence = 3.897703\n",
      "Epoch: 25\tFidelity = 0.500566\tKL_Divergence = 3.919861\n",
      "Epoch: 26\tFidelity = 0.500503\tKL_Divergence = 3.985326\n",
      "Epoch: 27\tFidelity = 0.500596\tKL_Divergence = 3.891821\n",
      "Epoch: 28\tFidelity = 0.500597\tKL_Divergence = 3.891088\n",
      "Epoch: 29\tFidelity = 0.500596\tKL_Divergence = 3.891462\n",
      "Epoch: 30\tFidelity = 0.500614\tKL_Divergence = 3.874763\n",
      "Epoch: 31\tFidelity = 0.500564\tKL_Divergence = 3.921810\n",
      "Epoch: 32\tFidelity = 0.500566\tKL_Divergence = 3.920532\n",
      "Epoch: 33\tFidelity = 0.500581\tKL_Divergence = 3.905379\n",
      "Epoch: 34\tFidelity = 0.500523\tKL_Divergence = 3.964455\n",
      "Epoch: 35\tFidelity = 0.500556\tKL_Divergence = 3.929944\n",
      "Epoch: 36\tFidelity = 0.500515\tKL_Divergence = 3.973021\n",
      "Epoch: 37\tFidelity = 0.500563\tKL_Divergence = 3.923018\n",
      "Epoch: 38\tFidelity = 0.500565\tKL_Divergence = 3.920827\n",
      "Epoch: 39\tFidelity = 0.500593\tKL_Divergence = 3.894470\n",
      "Epoch: 40\tFidelity = 0.500624\tKL_Divergence = 3.866397\n",
      "Epoch: 41\tFidelity = 0.500532\tKL_Divergence = 3.955021\n",
      "Epoch: 42\tFidelity = 0.500562\tKL_Divergence = 3.924307\n",
      "Epoch: 43\tFidelity = 0.500602\tKL_Divergence = 3.886353\n",
      "Epoch: 44\tFidelity = 0.500609\tKL_Divergence = 3.879270\n",
      "Epoch: 45\tFidelity = 0.500601\tKL_Divergence = 3.887133\n",
      "Epoch: 46\tFidelity = 0.500543\tKL_Divergence = 3.943325\n",
      "Epoch: 47\tFidelity = 0.500579\tKL_Divergence = 3.907709\n",
      "Epoch: 48\tFidelity = 0.500530\tKL_Divergence = 3.956625\n",
      "Epoch: 49\tFidelity = 0.500539\tKL_Divergence = 3.946956\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:44:17,906] Trial 622 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500551\tKL_Divergence = 3.935629\n",
      "Total time elapsed during training: 49.610 s\n",
      "Trial 622 pruned. \n",
      "Epoch: 1\tFidelity = 0.500557\tKL_Divergence = 3.929337\n",
      "Epoch: 2\tFidelity = 0.500457\tKL_Divergence = 4.038713\n",
      "Epoch: 3\tFidelity = 0.500463\tKL_Divergence = 4.032152\n",
      "Epoch: 4\tFidelity = 0.500587\tKL_Divergence = 3.900550\n",
      "Epoch: 5\tFidelity = 0.500501\tKL_Divergence = 3.988052\n",
      "Epoch: 6\tFidelity = 0.500651\tKL_Divergence = 3.842509\n",
      "Epoch: 7\tFidelity = 0.500482\tKL_Divergence = 4.010061\n",
      "Epoch: 8\tFidelity = 0.500515\tKL_Divergence = 3.972991\n",
      "Epoch: 9\tFidelity = 0.500536\tKL_Divergence = 3.950602\n",
      "Epoch: 10\tFidelity = 0.500573\tKL_Divergence = 3.913493\n",
      "Epoch: 11\tFidelity = 0.500483\tKL_Divergence = 4.008946\n",
      "Epoch: 12\tFidelity = 0.500629\tKL_Divergence = 3.861523\n",
      "Epoch: 13\tFidelity = 0.500543\tKL_Divergence = 3.943808\n",
      "Epoch: 14\tFidelity = 0.500596\tKL_Divergence = 3.891741\n",
      "Epoch: 15\tFidelity = 0.500583\tKL_Divergence = 3.903717\n",
      "Epoch: 16\tFidelity = 0.500579\tKL_Divergence = 3.907608\n",
      "Epoch: 17\tFidelity = 0.500553\tKL_Divergence = 3.933436\n",
      "Epoch: 18\tFidelity = 0.500514\tKL_Divergence = 3.974240\n",
      "Epoch: 19\tFidelity = 0.500550\tKL_Divergence = 3.936128\n",
      "Epoch: 20\tFidelity = 0.500547\tKL_Divergence = 3.939006\n",
      "Epoch: 21\tFidelity = 0.500603\tKL_Divergence = 3.885087\n",
      "Epoch: 22\tFidelity = 0.500567\tKL_Divergence = 3.919718\n",
      "Epoch: 23\tFidelity = 0.500662\tKL_Divergence = 3.833483\n",
      "Epoch: 24\tFidelity = 0.500584\tKL_Divergence = 3.903300\n",
      "Epoch: 25\tFidelity = 0.500583\tKL_Divergence = 3.903544\n",
      "Epoch: 26\tFidelity = 0.500573\tKL_Divergence = 3.913438\n",
      "Epoch: 27\tFidelity = 0.500500\tKL_Divergence = 3.988996\n",
      "Epoch: 28\tFidelity = 0.500574\tKL_Divergence = 3.912893\n",
      "Epoch: 29\tFidelity = 0.500622\tKL_Divergence = 3.867779\n",
      "Epoch: 30\tFidelity = 0.500485\tKL_Divergence = 4.005480\n",
      "Epoch: 31\tFidelity = 0.500534\tKL_Divergence = 3.952262\n",
      "Epoch: 32\tFidelity = 0.500542\tKL_Divergence = 3.944360\n",
      "Epoch: 33\tFidelity = 0.500565\tKL_Divergence = 3.921046\n",
      "Epoch: 34\tFidelity = 0.500607\tKL_Divergence = 3.881746\n",
      "Epoch: 35\tFidelity = 0.500620\tKL_Divergence = 3.869571\n",
      "Epoch: 36\tFidelity = 0.500621\tKL_Divergence = 3.869180\n",
      "Epoch: 37\tFidelity = 0.500465\tKL_Divergence = 4.029994\n",
      "Epoch: 38\tFidelity = 0.500570\tKL_Divergence = 3.916361\n",
      "Epoch: 39\tFidelity = 0.500521\tKL_Divergence = 3.966213\n",
      "Epoch: 40\tFidelity = 0.500519\tKL_Divergence = 3.968808\n",
      "Epoch: 41\tFidelity = 0.500558\tKL_Divergence = 3.928237\n",
      "Epoch: 42\tFidelity = 0.500566\tKL_Divergence = 3.920620\n",
      "Epoch: 43\tFidelity = 0.500486\tKL_Divergence = 4.004604\n",
      "Epoch: 44\tFidelity = 0.500549\tKL_Divergence = 3.936997\n",
      "Epoch: 45\tFidelity = 0.500612\tKL_Divergence = 3.877031\n",
      "Epoch: 46\tFidelity = 0.500588\tKL_Divergence = 3.899525\n",
      "Epoch: 47\tFidelity = 0.500535\tKL_Divergence = 3.951675\n",
      "Epoch: 48\tFidelity = 0.500530\tKL_Divergence = 3.956824\n",
      "Epoch: 49\tFidelity = 0.500593\tKL_Divergence = 3.894394\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:45:45,241] Trial 623 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500591\tKL_Divergence = 3.896655\n",
      "Total time elapsed during training: 87.143 s\n",
      "Trial 623 pruned. \n",
      "Epoch: 1\tFidelity = 0.500646\tKL_Divergence = 3.847312\n",
      "Epoch: 2\tFidelity = 0.500685\tKL_Divergence = 3.814361\n",
      "Epoch: 3\tFidelity = 0.500618\tKL_Divergence = 3.871420\n",
      "Epoch: 4\tFidelity = 0.500490\tKL_Divergence = 4.000866\n",
      "Epoch: 5\tFidelity = 0.500639\tKL_Divergence = 3.852646\n",
      "Epoch: 6\tFidelity = 0.500799\tKL_Divergence = 3.728965\n",
      "Epoch: 7\tFidelity = 0.500461\tKL_Divergence = 4.033764\n",
      "Epoch: 8\tFidelity = 0.500593\tKL_Divergence = 3.894508\n",
      "Epoch: 9\tFidelity = 0.500483\tKL_Divergence = 4.008530\n",
      "Epoch: 10\tFidelity = 0.500749\tKL_Divergence = 3.764751\n",
      "Epoch: 11\tFidelity = 0.500596\tKL_Divergence = 3.891622\n",
      "Epoch: 12\tFidelity = 0.500508\tKL_Divergence = 3.980274\n",
      "Epoch: 13\tFidelity = 0.500448\tKL_Divergence = 4.049479\n",
      "Epoch: 14\tFidelity = 0.500642\tKL_Divergence = 3.849472\n",
      "Epoch: 15\tFidelity = 0.500722\tKL_Divergence = 3.785112\n",
      "Epoch: 16\tFidelity = 0.500598\tKL_Divergence = 3.888056\n",
      "Epoch: 17\tFidelity = 0.500532\tKL_Divergence = 3.954573\n",
      "Epoch: 18\tFidelity = 0.500523\tKL_Divergence = 3.963650\n",
      "Epoch: 19\tFidelity = 0.500676\tKL_Divergence = 3.820697\n",
      "Epoch: 20\tFidelity = 0.500807\tKL_Divergence = 3.722098\n",
      "Epoch: 21\tFidelity = 0.500562\tKL_Divergence = 3.921112\n",
      "Epoch: 22\tFidelity = 0.500553\tKL_Divergence = 3.930240\n",
      "Epoch: 23\tFidelity = 0.500464\tKL_Divergence = 4.028685\n",
      "Epoch: 24\tFidelity = 0.500623\tKL_Divergence = 3.865324\n",
      "Epoch: 25\tFidelity = 0.500462\tKL_Divergence = 4.032925\n",
      "Epoch: 26\tFidelity = 0.500439\tKL_Divergence = 4.060537\n",
      "Epoch: 27\tFidelity = 0.500534\tKL_Divergence = 3.951394\n",
      "Epoch: 28\tFidelity = 0.500668\tKL_Divergence = 3.826394\n",
      "Epoch: 29\tFidelity = 0.500575\tKL_Divergence = 3.910597\n",
      "Epoch: 30\tFidelity = 0.500506\tKL_Divergence = 3.982087\n",
      "Epoch: 31\tFidelity = 0.500496\tKL_Divergence = 3.993147\n",
      "Epoch: 32\tFidelity = 0.500666\tKL_Divergence = 3.829608\n",
      "Epoch: 33\tFidelity = 0.500645\tKL_Divergence = 3.847399\n",
      "Epoch: 34\tFidelity = 0.500526\tKL_Divergence = 3.960256\n",
      "Epoch: 35\tFidelity = 0.500477\tKL_Divergence = 4.014566\n",
      "Epoch: 36\tFidelity = 0.500510\tKL_Divergence = 3.975667\n",
      "Epoch: 37\tFidelity = 0.500442\tKL_Divergence = 4.054314\n",
      "Epoch: 38\tFidelity = 0.500403\tKL_Divergence = 4.106008\n",
      "Epoch: 39\tFidelity = 0.500459\tKL_Divergence = 4.034757\n",
      "Epoch: 40\tFidelity = 0.500480\tKL_Divergence = 4.009782\n",
      "Epoch: 41\tFidelity = 0.500526\tKL_Divergence = 3.959192\n",
      "Epoch: 42\tFidelity = 0.500492\tKL_Divergence = 3.997530\n",
      "Epoch: 43\tFidelity = 0.500429\tKL_Divergence = 4.074145\n",
      "Epoch: 44\tFidelity = 0.500485\tKL_Divergence = 4.005785\n",
      "Epoch: 45\tFidelity = 0.500542\tKL_Divergence = 3.942534\n",
      "Epoch: 46\tFidelity = 0.500514\tKL_Divergence = 3.972220\n",
      "Epoch: 47\tFidelity = 0.500684\tKL_Divergence = 3.813161\n",
      "Epoch: 48\tFidelity = 0.500598\tKL_Divergence = 3.888166\n",
      "Epoch: 49\tFidelity = 0.500544\tKL_Divergence = 3.940627\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:46:25,107] Trial 624 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500708\tKL_Divergence = 3.794195\n",
      "Total time elapsed during training: 39.642 s\n",
      "Trial 624 pruned. \n",
      "Epoch: 1\tFidelity = 0.500606\tKL_Divergence = 3.880211\n",
      "Epoch: 2\tFidelity = 0.500561\tKL_Divergence = 3.923136\n",
      "Epoch: 3\tFidelity = 0.500541\tKL_Divergence = 3.943878\n",
      "Epoch: 4\tFidelity = 0.500559\tKL_Divergence = 3.925182\n",
      "Epoch: 5\tFidelity = 0.500552\tKL_Divergence = 3.932821\n",
      "Epoch: 6\tFidelity = 0.500555\tKL_Divergence = 3.929826\n",
      "Epoch: 7\tFidelity = 0.500531\tKL_Divergence = 3.954584\n",
      "Epoch: 8\tFidelity = 0.500532\tKL_Divergence = 3.953052\n",
      "Epoch: 9\tFidelity = 0.500528\tKL_Divergence = 3.957870\n",
      "Epoch: 10\tFidelity = 0.500541\tKL_Divergence = 3.944163\n",
      "Epoch: 11\tFidelity = 0.500554\tKL_Divergence = 3.931454\n",
      "Epoch: 12\tFidelity = 0.500547\tKL_Divergence = 3.937716\n",
      "Epoch: 13\tFidelity = 0.500554\tKL_Divergence = 3.931704\n",
      "Epoch: 14\tFidelity = 0.500548\tKL_Divergence = 3.937429\n",
      "Epoch: 15\tFidelity = 0.500557\tKL_Divergence = 3.928162\n",
      "Epoch: 16\tFidelity = 0.500566\tKL_Divergence = 3.919445\n",
      "Epoch: 17\tFidelity = 0.500591\tKL_Divergence = 3.895124\n",
      "Epoch: 18\tFidelity = 0.500527\tKL_Divergence = 3.959389\n",
      "Epoch: 19\tFidelity = 0.500533\tKL_Divergence = 3.953341\n",
      "Epoch: 20\tFidelity = 0.500565\tKL_Divergence = 3.920902\n",
      "Epoch: 21\tFidelity = 0.500542\tKL_Divergence = 3.943935\n",
      "Epoch: 22\tFidelity = 0.500532\tKL_Divergence = 3.954129\n",
      "Epoch: 23\tFidelity = 0.500558\tKL_Divergence = 3.927719\n",
      "Epoch: 24\tFidelity = 0.500520\tKL_Divergence = 3.967089\n",
      "Epoch: 25\tFidelity = 0.500536\tKL_Divergence = 3.950010\n",
      "Epoch: 26\tFidelity = 0.500547\tKL_Divergence = 3.938646\n",
      "Epoch: 27\tFidelity = 0.500526\tKL_Divergence = 3.960250\n",
      "Epoch: 28\tFidelity = 0.500500\tKL_Divergence = 3.988795\n",
      "Epoch: 29\tFidelity = 0.500546\tKL_Divergence = 3.939706\n",
      "Epoch: 30\tFidelity = 0.500571\tKL_Divergence = 3.915274\n",
      "Epoch: 31\tFidelity = 0.500539\tKL_Divergence = 3.946963\n",
      "Epoch: 32\tFidelity = 0.500512\tKL_Divergence = 3.975990\n",
      "Epoch: 33\tFidelity = 0.500528\tKL_Divergence = 3.958610\n",
      "Epoch: 34\tFidelity = 0.500502\tKL_Divergence = 3.987117\n",
      "Epoch: 35\tFidelity = 0.500533\tKL_Divergence = 3.953249\n",
      "Epoch: 36\tFidelity = 0.500545\tKL_Divergence = 3.941293\n",
      "Epoch: 37\tFidelity = 0.500534\tKL_Divergence = 3.952335\n",
      "Epoch: 38\tFidelity = 0.500495\tKL_Divergence = 3.994213\n",
      "Epoch: 39\tFidelity = 0.500525\tKL_Divergence = 3.961728\n",
      "Epoch: 40\tFidelity = 0.500547\tKL_Divergence = 3.938846\n",
      "Epoch: 41\tFidelity = 0.500555\tKL_Divergence = 3.930717\n",
      "Epoch: 42\tFidelity = 0.500570\tKL_Divergence = 3.916318\n",
      "Epoch: 43\tFidelity = 0.500544\tKL_Divergence = 3.942465\n",
      "Epoch: 44\tFidelity = 0.500558\tKL_Divergence = 3.928055\n",
      "Epoch: 45\tFidelity = 0.500572\tKL_Divergence = 3.914095\n",
      "Epoch: 46\tFidelity = 0.500556\tKL_Divergence = 3.929899\n",
      "Epoch: 47\tFidelity = 0.500571\tKL_Divergence = 3.915753\n",
      "Epoch: 48\tFidelity = 0.500602\tKL_Divergence = 3.886320\n",
      "Epoch: 49\tFidelity = 0.500542\tKL_Divergence = 3.944237\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:47:05,857] Trial 625 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500530\tKL_Divergence = 3.957213\n",
      "Total time elapsed during training: 40.554 s\n",
      "Trial 625 pruned. \n",
      "Epoch: 1\tFidelity = 0.500547\tKL_Divergence = 3.939637\n",
      "Epoch: 2\tFidelity = 0.500567\tKL_Divergence = 3.919165\n",
      "Epoch: 3\tFidelity = 0.500527\tKL_Divergence = 3.960035\n",
      "Epoch: 4\tFidelity = 0.500531\tKL_Divergence = 3.955945\n",
      "Epoch: 5\tFidelity = 0.500560\tKL_Divergence = 3.926445\n",
      "Epoch: 6\tFidelity = 0.500551\tKL_Divergence = 3.935037\n",
      "Epoch: 7\tFidelity = 0.500525\tKL_Divergence = 3.962120\n",
      "Epoch: 8\tFidelity = 0.500549\tKL_Divergence = 3.937428\n",
      "Epoch: 9\tFidelity = 0.500544\tKL_Divergence = 3.942757\n",
      "Epoch: 10\tFidelity = 0.500550\tKL_Divergence = 3.936090\n",
      "Epoch: 11\tFidelity = 0.500572\tKL_Divergence = 3.914334\n",
      "Epoch: 12\tFidelity = 0.500568\tKL_Divergence = 3.918122\n",
      "Epoch: 13\tFidelity = 0.500538\tKL_Divergence = 3.948649\n",
      "Epoch: 14\tFidelity = 0.500546\tKL_Divergence = 3.940404\n",
      "Epoch: 15\tFidelity = 0.500524\tKL_Divergence = 3.963026\n",
      "Epoch: 16\tFidelity = 0.500577\tKL_Divergence = 3.909995\n",
      "Epoch: 17\tFidelity = 0.500518\tKL_Divergence = 3.969692\n",
      "Epoch: 18\tFidelity = 0.500554\tKL_Divergence = 3.932507\n",
      "Epoch: 19\tFidelity = 0.500575\tKL_Divergence = 3.911361\n",
      "Epoch: 20\tFidelity = 0.500557\tKL_Divergence = 3.929114\n",
      "Epoch: 21\tFidelity = 0.500557\tKL_Divergence = 3.928871\n",
      "Epoch: 22\tFidelity = 0.500542\tKL_Divergence = 3.944506\n",
      "Epoch: 23\tFidelity = 0.500545\tKL_Divergence = 3.941856\n",
      "Epoch: 24\tFidelity = 0.500563\tKL_Divergence = 3.922864\n",
      "Epoch: 25\tFidelity = 0.500553\tKL_Divergence = 3.932810\n",
      "Epoch: 26\tFidelity = 0.500599\tKL_Divergence = 3.889236\n",
      "Epoch: 27\tFidelity = 0.500532\tKL_Divergence = 3.955157\n",
      "Epoch: 28\tFidelity = 0.500577\tKL_Divergence = 3.910030\n",
      "Epoch: 29\tFidelity = 0.500562\tKL_Divergence = 3.924110\n",
      "Epoch: 30\tFidelity = 0.500561\tKL_Divergence = 3.924978\n",
      "Epoch: 31\tFidelity = 0.500561\tKL_Divergence = 3.925637\n",
      "Epoch: 32\tFidelity = 0.500566\tKL_Divergence = 3.920782\n",
      "Epoch: 33\tFidelity = 0.500583\tKL_Divergence = 3.904267\n",
      "Epoch: 34\tFidelity = 0.500566\tKL_Divergence = 3.919988\n",
      "Epoch: 35\tFidelity = 0.500577\tKL_Divergence = 3.909748\n",
      "Epoch: 36\tFidelity = 0.500591\tKL_Divergence = 3.896704\n",
      "Epoch: 37\tFidelity = 0.500559\tKL_Divergence = 3.927234\n",
      "Epoch: 38\tFidelity = 0.500519\tKL_Divergence = 3.968755\n",
      "Epoch: 39\tFidelity = 0.500588\tKL_Divergence = 3.899315\n",
      "Epoch: 40\tFidelity = 0.500564\tKL_Divergence = 3.922480\n",
      "Epoch: 41\tFidelity = 0.500612\tKL_Divergence = 3.877016\n",
      "Epoch: 42\tFidelity = 0.500576\tKL_Divergence = 3.910707\n",
      "Epoch: 43\tFidelity = 0.500586\tKL_Divergence = 3.901049\n",
      "Epoch: 44\tFidelity = 0.500541\tKL_Divergence = 3.945904\n",
      "Epoch: 45\tFidelity = 0.500552\tKL_Divergence = 3.933905\n",
      "Epoch: 46\tFidelity = 0.500558\tKL_Divergence = 3.927958\n",
      "Epoch: 47\tFidelity = 0.500551\tKL_Divergence = 3.935178\n",
      "Epoch: 48\tFidelity = 0.500544\tKL_Divergence = 3.942871\n",
      "Epoch: 49\tFidelity = 0.500570\tKL_Divergence = 3.916852\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:47:39,544] Trial 626 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500567\tKL_Divergence = 3.919249\n",
      "Total time elapsed during training: 33.495 s\n",
      "Trial 626 pruned. \n",
      "Epoch: 1\tFidelity = 0.500550\tKL_Divergence = 3.935894\n",
      "Epoch: 2\tFidelity = 0.500470\tKL_Divergence = 4.023506\n",
      "Epoch: 3\tFidelity = 0.500483\tKL_Divergence = 4.008285\n",
      "Epoch: 4\tFidelity = 0.500530\tKL_Divergence = 3.956903\n",
      "Epoch: 5\tFidelity = 0.500435\tKL_Divergence = 4.066371\n",
      "Epoch: 6\tFidelity = 0.500536\tKL_Divergence = 3.949419\n",
      "Epoch: 7\tFidelity = 0.500446\tKL_Divergence = 4.052028\n",
      "Epoch: 8\tFidelity = 0.500522\tKL_Divergence = 3.963754\n",
      "Epoch: 9\tFidelity = 0.500451\tKL_Divergence = 4.045571\n",
      "Epoch: 10\tFidelity = 0.500523\tKL_Divergence = 3.964076\n",
      "Epoch: 11\tFidelity = 0.500447\tKL_Divergence = 4.050700\n",
      "Epoch: 12\tFidelity = 0.500555\tKL_Divergence = 3.930724\n",
      "Epoch: 13\tFidelity = 0.500472\tKL_Divergence = 4.020544\n",
      "Epoch: 14\tFidelity = 0.500588\tKL_Divergence = 3.898492\n",
      "Epoch: 15\tFidelity = 0.500539\tKL_Divergence = 3.947547\n",
      "Epoch: 16\tFidelity = 0.500613\tKL_Divergence = 3.876088\n",
      "Epoch: 17\tFidelity = 0.500463\tKL_Divergence = 4.032079\n",
      "Epoch: 18\tFidelity = 0.500612\tKL_Divergence = 3.877017\n",
      "Epoch: 19\tFidelity = 0.500707\tKL_Divergence = 3.797085\n",
      "Epoch: 20\tFidelity = 0.500690\tKL_Divergence = 3.810204\n",
      "Epoch: 21\tFidelity = 0.500617\tKL_Divergence = 3.872132\n",
      "Epoch: 22\tFidelity = 0.500613\tKL_Divergence = 3.876053\n",
      "Epoch: 23\tFidelity = 0.500515\tKL_Divergence = 3.972799\n",
      "Epoch: 24\tFidelity = 0.500617\tKL_Divergence = 3.872323\n",
      "Epoch: 25\tFidelity = 0.500493\tKL_Divergence = 3.996763\n",
      "Epoch: 26\tFidelity = 0.500519\tKL_Divergence = 3.968164\n",
      "Epoch: 27\tFidelity = 0.500530\tKL_Divergence = 3.956997\n",
      "Epoch: 28\tFidelity = 0.500497\tKL_Divergence = 3.992076\n",
      "Epoch: 29\tFidelity = 0.500648\tKL_Divergence = 3.845191\n",
      "Epoch: 30\tFidelity = 0.500596\tKL_Divergence = 3.891557\n",
      "Epoch: 31\tFidelity = 0.500527\tKL_Divergence = 3.960291\n",
      "Epoch: 32\tFidelity = 0.500650\tKL_Divergence = 3.843182\n",
      "Epoch: 33\tFidelity = 0.500606\tKL_Divergence = 3.882202\n",
      "Epoch: 34\tFidelity = 0.500590\tKL_Divergence = 3.896960\n",
      "Epoch: 35\tFidelity = 0.500594\tKL_Divergence = 3.893247\n",
      "Epoch: 36\tFidelity = 0.500446\tKL_Divergence = 4.052483\n",
      "Epoch: 37\tFidelity = 0.500570\tKL_Divergence = 3.916685\n",
      "Epoch: 38\tFidelity = 0.500559\tKL_Divergence = 3.927510\n",
      "Epoch: 39\tFidelity = 0.500494\tKL_Divergence = 3.995319\n",
      "Epoch: 40\tFidelity = 0.500598\tKL_Divergence = 3.889760\n",
      "Epoch: 41\tFidelity = 0.500494\tKL_Divergence = 3.995279\n",
      "Epoch: 42\tFidelity = 0.500616\tKL_Divergence = 3.873701\n",
      "Epoch: 43\tFidelity = 0.500639\tKL_Divergence = 3.853124\n",
      "Epoch: 44\tFidelity = 0.500524\tKL_Divergence = 3.962656\n",
      "Epoch: 45\tFidelity = 0.500564\tKL_Divergence = 3.921789\n",
      "Epoch: 46\tFidelity = 0.500464\tKL_Divergence = 4.030690\n",
      "Epoch: 47\tFidelity = 0.500473\tKL_Divergence = 4.020177\n",
      "Epoch: 48\tFidelity = 0.500710\tKL_Divergence = 3.794518\n",
      "Epoch: 49\tFidelity = 0.500625\tKL_Divergence = 3.865148\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:48:41,994] Trial 627 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500600\tKL_Divergence = 3.888182\n",
      "Total time elapsed during training: 62.258 s\n",
      "Trial 627 pruned. \n",
      "Epoch: 1\tFidelity = 0.500611\tKL_Divergence = 3.877654\n",
      "Epoch: 2\tFidelity = 0.500627\tKL_Divergence = 3.863640\n",
      "Epoch: 3\tFidelity = 0.500648\tKL_Divergence = 3.845592\n",
      "Epoch: 4\tFidelity = 0.500626\tKL_Divergence = 3.864753\n",
      "Epoch: 5\tFidelity = 0.500497\tKL_Divergence = 3.992903\n",
      "Epoch: 6\tFidelity = 0.500473\tKL_Divergence = 4.019448\n",
      "Epoch: 7\tFidelity = 0.500525\tKL_Divergence = 3.961978\n",
      "Epoch: 8\tFidelity = 0.500554\tKL_Divergence = 3.932624\n",
      "Epoch: 9\tFidelity = 0.500553\tKL_Divergence = 3.932832\n",
      "Epoch: 10\tFidelity = 0.500594\tKL_Divergence = 3.893124\n",
      "Epoch: 11\tFidelity = 0.500477\tKL_Divergence = 4.014990\n",
      "Epoch: 12\tFidelity = 0.500614\tKL_Divergence = 3.875326\n",
      "Epoch: 13\tFidelity = 0.500600\tKL_Divergence = 3.887903\n",
      "Epoch: 14\tFidelity = 0.500575\tKL_Divergence = 3.911722\n",
      "Epoch: 15\tFidelity = 0.500688\tKL_Divergence = 3.811972\n",
      "Epoch: 16\tFidelity = 0.500624\tKL_Divergence = 3.865691\n",
      "Epoch: 17\tFidelity = 0.500493\tKL_Divergence = 3.996808\n",
      "Epoch: 18\tFidelity = 0.500490\tKL_Divergence = 4.000602\n",
      "Epoch: 19\tFidelity = 0.500590\tKL_Divergence = 3.897144\n",
      "Epoch: 20\tFidelity = 0.500503\tKL_Divergence = 3.986000\n",
      "Epoch: 21\tFidelity = 0.500626\tKL_Divergence = 3.864563\n",
      "Epoch: 22\tFidelity = 0.500529\tKL_Divergence = 3.957623\n",
      "Epoch: 23\tFidelity = 0.500534\tKL_Divergence = 3.952416\n",
      "Epoch: 24\tFidelity = 0.500654\tKL_Divergence = 3.840234\n",
      "Epoch: 25\tFidelity = 0.500587\tKL_Divergence = 3.899558\n",
      "Epoch: 26\tFidelity = 0.500603\tKL_Divergence = 3.884847\n",
      "Epoch: 27\tFidelity = 0.500599\tKL_Divergence = 3.889100\n",
      "Epoch: 28\tFidelity = 0.500680\tKL_Divergence = 3.818148\n",
      "Epoch: 29\tFidelity = 0.500650\tKL_Divergence = 3.843635\n",
      "Epoch: 30\tFidelity = 0.500651\tKL_Divergence = 3.842432\n",
      "Epoch: 31\tFidelity = 0.500480\tKL_Divergence = 4.011731\n",
      "Epoch: 32\tFidelity = 0.500669\tKL_Divergence = 3.827168\n",
      "Epoch: 33\tFidelity = 0.500750\tKL_Divergence = 3.763718\n",
      "Epoch: 34\tFidelity = 0.500630\tKL_Divergence = 3.860281\n",
      "Epoch: 35\tFidelity = 0.500691\tKL_Divergence = 3.809044\n",
      "Epoch: 36\tFidelity = 0.500586\tKL_Divergence = 3.901148\n",
      "Epoch: 37\tFidelity = 0.500612\tKL_Divergence = 3.877069\n",
      "Epoch: 38\tFidelity = 0.500626\tKL_Divergence = 3.863883\n",
      "Epoch: 39\tFidelity = 0.500555\tKL_Divergence = 3.930623\n",
      "Epoch: 40\tFidelity = 0.500612\tKL_Divergence = 3.876918\n",
      "Epoch: 41\tFidelity = 0.500601\tKL_Divergence = 3.886954\n",
      "Epoch: 42\tFidelity = 0.500688\tKL_Divergence = 3.811508\n",
      "Epoch: 43\tFidelity = 0.500654\tKL_Divergence = 3.840278\n",
      "Epoch: 44\tFidelity = 0.500599\tKL_Divergence = 3.888577\n",
      "Epoch: 45\tFidelity = 0.500653\tKL_Divergence = 3.840728\n",
      "Epoch: 46\tFidelity = 0.500598\tKL_Divergence = 3.889419\n",
      "Epoch: 47\tFidelity = 0.500615\tKL_Divergence = 3.873583\n",
      "Epoch: 48\tFidelity = 0.500705\tKL_Divergence = 3.797848\n",
      "Epoch: 49\tFidelity = 0.500589\tKL_Divergence = 3.898058\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:49:22,967] Trial 628 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500552\tKL_Divergence = 3.933959\n",
      "Total time elapsed during training: 40.777 s\n",
      "Trial 628 pruned. \n",
      "Epoch: 1\tFidelity = 0.500653\tKL_Divergence = 3.840800\n",
      "Epoch: 2\tFidelity = 0.500844\tKL_Divergence = 3.698292\n",
      "Epoch: 3\tFidelity = 0.500652\tKL_Divergence = 3.840919\n",
      "Epoch: 4\tFidelity = 0.500668\tKL_Divergence = 3.827809\n",
      "Epoch: 5\tFidelity = 0.500927\tKL_Divergence = 3.646042\n",
      "Epoch: 6\tFidelity = 0.500715\tKL_Divergence = 3.790314\n",
      "Epoch: 7\tFidelity = 0.500708\tKL_Divergence = 3.795382\n",
      "Epoch: 8\tFidelity = 0.500576\tKL_Divergence = 3.910604\n",
      "Epoch: 9\tFidelity = 0.500751\tKL_Divergence = 3.762847\n",
      "Epoch: 10\tFidelity = 0.500690\tKL_Divergence = 3.810227\n",
      "Epoch: 11\tFidelity = 0.500743\tKL_Divergence = 3.769275\n",
      "Epoch: 12\tFidelity = 0.500571\tKL_Divergence = 3.915151\n",
      "Epoch: 13\tFidelity = 0.500730\tKL_Divergence = 3.779229\n",
      "Epoch: 14\tFidelity = 0.500696\tKL_Divergence = 3.804972\n",
      "Epoch: 15\tFidelity = 0.500779\tKL_Divergence = 3.742499\n",
      "Epoch: 16\tFidelity = 0.500457\tKL_Divergence = 4.038967\n",
      "Epoch: 17\tFidelity = 0.500689\tKL_Divergence = 3.810753\n",
      "Epoch: 18\tFidelity = 0.500607\tKL_Divergence = 3.881304\n",
      "Epoch: 19\tFidelity = 0.500725\tKL_Divergence = 3.782029\n",
      "Epoch: 20\tFidelity = 0.500719\tKL_Divergence = 3.786742\n",
      "Epoch: 21\tFidelity = 0.500892\tKL_Divergence = 3.667911\n",
      "Epoch: 22\tFidelity = 0.500779\tKL_Divergence = 3.742750\n",
      "Epoch: 23\tFidelity = 0.500593\tKL_Divergence = 3.894110\n",
      "Epoch: 24\tFidelity = 0.500685\tKL_Divergence = 3.814207\n",
      "Epoch: 25\tFidelity = 0.500578\tKL_Divergence = 3.908043\n",
      "Epoch: 26\tFidelity = 0.500477\tKL_Divergence = 4.014659\n",
      "Epoch: 27\tFidelity = 0.500763\tKL_Divergence = 3.754290\n",
      "Epoch: 28\tFidelity = 0.500758\tKL_Divergence = 3.757984\n",
      "Epoch: 29\tFidelity = 0.500568\tKL_Divergence = 3.918451\n",
      "Epoch: 30\tFidelity = 0.500737\tKL_Divergence = 3.773683\n",
      "Epoch: 31\tFidelity = 0.500828\tKL_Divergence = 3.708976\n",
      "Epoch: 32\tFidelity = 0.500804\tKL_Divergence = 3.725137\n",
      "Epoch: 33\tFidelity = 0.500766\tKL_Divergence = 3.751979\n",
      "Epoch: 34\tFidelity = 0.500588\tKL_Divergence = 3.897848\n",
      "Epoch: 35\tFidelity = 0.500695\tKL_Divergence = 3.806069\n",
      "Epoch: 36\tFidelity = 0.500703\tKL_Divergence = 3.799140\n",
      "Epoch: 37\tFidelity = 0.500613\tKL_Divergence = 3.875243\n",
      "Epoch: 38\tFidelity = 0.500481\tKL_Divergence = 4.010430\n",
      "Epoch: 39\tFidelity = 0.500491\tKL_Divergence = 3.999190\n",
      "Epoch: 40\tFidelity = 0.500733\tKL_Divergence = 3.776740\n",
      "Epoch: 41\tFidelity = 0.500545\tKL_Divergence = 3.940864\n",
      "Epoch: 42\tFidelity = 0.500607\tKL_Divergence = 3.881746\n",
      "Epoch: 43\tFidelity = 0.500576\tKL_Divergence = 3.910654\n",
      "Epoch: 44\tFidelity = 0.500508\tKL_Divergence = 3.980021\n",
      "Epoch: 45\tFidelity = 0.500753\tKL_Divergence = 3.761624\n",
      "Epoch: 46\tFidelity = 0.500771\tKL_Divergence = 3.748713\n",
      "Epoch: 47\tFidelity = 0.500556\tKL_Divergence = 3.930045\n",
      "Epoch: 48\tFidelity = 0.500908\tKL_Divergence = 3.658116\n",
      "Epoch: 49\tFidelity = 0.500553\tKL_Divergence = 3.932864\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:50:50,215] Trial 629 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500571\tKL_Divergence = 3.915323\n",
      "Total time elapsed during training: 87.056 s\n",
      "Trial 629 pruned. \n",
      "Epoch: 1\tFidelity = 0.500614\tKL_Divergence = 3.875590\n",
      "Epoch: 2\tFidelity = 0.500547\tKL_Divergence = 3.939323\n",
      "Epoch: 3\tFidelity = 0.500527\tKL_Divergence = 3.959647\n",
      "Epoch: 4\tFidelity = 0.500586\tKL_Divergence = 3.900761\n",
      "Epoch: 5\tFidelity = 0.500571\tKL_Divergence = 3.915296\n",
      "Epoch: 6\tFidelity = 0.500587\tKL_Divergence = 3.899994\n",
      "Epoch: 7\tFidelity = 0.500551\tKL_Divergence = 3.934996\n",
      "Epoch: 8\tFidelity = 0.500594\tKL_Divergence = 3.893419\n",
      "Epoch: 9\tFidelity = 0.500624\tKL_Divergence = 3.866017\n",
      "Epoch: 10\tFidelity = 0.500613\tKL_Divergence = 3.875959\n",
      "Epoch: 11\tFidelity = 0.500606\tKL_Divergence = 3.882610\n",
      "Epoch: 12\tFidelity = 0.500623\tKL_Divergence = 3.866657\n",
      "Epoch: 13\tFidelity = 0.500572\tKL_Divergence = 3.914530\n",
      "Epoch: 14\tFidelity = 0.500590\tKL_Divergence = 3.897072\n",
      "Epoch: 15\tFidelity = 0.500544\tKL_Divergence = 3.941892\n",
      "Epoch: 16\tFidelity = 0.500571\tKL_Divergence = 3.915604\n",
      "Epoch: 17\tFidelity = 0.500574\tKL_Divergence = 3.912900\n",
      "Epoch: 18\tFidelity = 0.500638\tKL_Divergence = 3.854171\n",
      "Epoch: 19\tFidelity = 0.500601\tKL_Divergence = 3.886989\n",
      "Epoch: 20\tFidelity = 0.500548\tKL_Divergence = 3.937988\n",
      "Epoch: 21\tFidelity = 0.500627\tKL_Divergence = 3.863622\n",
      "Epoch: 22\tFidelity = 0.500618\tKL_Divergence = 3.871135\n",
      "Epoch: 23\tFidelity = 0.500615\tKL_Divergence = 3.873826\n",
      "Epoch: 24\tFidelity = 0.500647\tKL_Divergence = 3.846269\n",
      "Epoch: 25\tFidelity = 0.500608\tKL_Divergence = 3.880780\n",
      "Epoch: 26\tFidelity = 0.500581\tKL_Divergence = 3.906148\n",
      "Epoch: 27\tFidelity = 0.500620\tKL_Divergence = 3.869547\n",
      "Epoch: 28\tFidelity = 0.500594\tKL_Divergence = 3.893034\n",
      "Epoch: 29\tFidelity = 0.500563\tKL_Divergence = 3.922768\n",
      "Epoch: 30\tFidelity = 0.500591\tKL_Divergence = 3.896258\n",
      "Epoch: 31\tFidelity = 0.500619\tKL_Divergence = 3.870619\n",
      "Epoch: 32\tFidelity = 0.500571\tKL_Divergence = 3.915638\n",
      "Epoch: 33\tFidelity = 0.500650\tKL_Divergence = 3.843135\n",
      "Epoch: 34\tFidelity = 0.500625\tKL_Divergence = 3.865409\n",
      "Epoch: 35\tFidelity = 0.500584\tKL_Divergence = 3.902751\n",
      "Epoch: 36\tFidelity = 0.500596\tKL_Divergence = 3.891931\n",
      "Epoch: 37\tFidelity = 0.500605\tKL_Divergence = 3.883698\n",
      "Epoch: 38\tFidelity = 0.500606\tKL_Divergence = 3.882773\n",
      "Epoch: 39\tFidelity = 0.500597\tKL_Divergence = 3.890366\n",
      "Epoch: 40\tFidelity = 0.500581\tKL_Divergence = 3.905498\n",
      "Epoch: 41\tFidelity = 0.500595\tKL_Divergence = 3.892759\n",
      "Epoch: 42\tFidelity = 0.500643\tKL_Divergence = 3.849262\n",
      "Epoch: 43\tFidelity = 0.500621\tKL_Divergence = 3.869143\n",
      "Epoch: 44\tFidelity = 0.500606\tKL_Divergence = 3.882215\n",
      "Epoch: 45\tFidelity = 0.500600\tKL_Divergence = 3.887897\n",
      "Epoch: 46\tFidelity = 0.500638\tKL_Divergence = 3.853885\n",
      "Epoch: 47\tFidelity = 0.500627\tKL_Divergence = 3.863397\n",
      "Epoch: 48\tFidelity = 0.500588\tKL_Divergence = 3.899066\n",
      "Epoch: 49\tFidelity = 0.500619\tKL_Divergence = 3.870597\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:51:22,142] Trial 630 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500660\tKL_Divergence = 3.835093\n",
      "Total time elapsed during training: 31.700 s\n",
      "Trial 630 pruned. \n",
      "Epoch: 1\tFidelity = 0.500644\tKL_Divergence = 3.848779\n",
      "Epoch: 2\tFidelity = 0.500738\tKL_Divergence = 3.772974\n",
      "Epoch: 3\tFidelity = 0.500632\tKL_Divergence = 3.859058\n",
      "Epoch: 4\tFidelity = 0.500613\tKL_Divergence = 3.875993\n",
      "Epoch: 5\tFidelity = 0.500592\tKL_Divergence = 3.895611\n",
      "Epoch: 6\tFidelity = 0.500739\tKL_Divergence = 3.772557\n",
      "Epoch: 7\tFidelity = 0.500757\tKL_Divergence = 3.758668\n",
      "Epoch: 8\tFidelity = 0.500514\tKL_Divergence = 3.973912\n",
      "Epoch: 9\tFidelity = 0.500609\tKL_Divergence = 3.879872\n",
      "Epoch: 10\tFidelity = 0.500772\tKL_Divergence = 3.747929\n",
      "Epoch: 11\tFidelity = 0.500568\tKL_Divergence = 3.918050\n",
      "Epoch: 12\tFidelity = 0.500631\tKL_Divergence = 3.860202\n",
      "Epoch: 13\tFidelity = 0.500802\tKL_Divergence = 3.726556\n",
      "Epoch: 14\tFidelity = 0.500721\tKL_Divergence = 3.786085\n",
      "Epoch: 15\tFidelity = 0.500669\tKL_Divergence = 3.827064\n",
      "Epoch: 16\tFidelity = 0.500733\tKL_Divergence = 3.776824\n",
      "Epoch: 17\tFidelity = 0.500567\tKL_Divergence = 3.919404\n",
      "Epoch: 18\tFidelity = 0.500674\tKL_Divergence = 3.823136\n",
      "Epoch: 19\tFidelity = 0.500805\tKL_Divergence = 3.724651\n",
      "Epoch: 20\tFidelity = 0.500696\tKL_Divergence = 3.805739\n",
      "Epoch: 21\tFidelity = 0.500532\tKL_Divergence = 3.954796\n",
      "Epoch: 22\tFidelity = 0.500741\tKL_Divergence = 3.770469\n",
      "Epoch: 23\tFidelity = 0.500718\tKL_Divergence = 3.787996\n",
      "Epoch: 24\tFidelity = 0.500639\tKL_Divergence = 3.852493\n",
      "Epoch: 25\tFidelity = 0.500623\tKL_Divergence = 3.867030\n",
      "Epoch: 26\tFidelity = 0.500790\tKL_Divergence = 3.735035\n",
      "Epoch: 27\tFidelity = 0.500548\tKL_Divergence = 3.938146\n",
      "Epoch: 28\tFidelity = 0.500661\tKL_Divergence = 3.834069\n",
      "Epoch: 29\tFidelity = 0.500553\tKL_Divergence = 3.933304\n",
      "Epoch: 30\tFidelity = 0.500728\tKL_Divergence = 3.780170\n",
      "Epoch: 31\tFidelity = 0.500647\tKL_Divergence = 3.845844\n",
      "Epoch: 32\tFidelity = 0.500609\tKL_Divergence = 3.879114\n",
      "Epoch: 33\tFidelity = 0.500788\tKL_Divergence = 3.736271\n",
      "Epoch: 34\tFidelity = 0.500614\tKL_Divergence = 3.874794\n",
      "Epoch: 35\tFidelity = 0.500746\tKL_Divergence = 3.767116\n",
      "Epoch: 36\tFidelity = 0.500660\tKL_Divergence = 3.834675\n",
      "Epoch: 37\tFidelity = 0.500648\tKL_Divergence = 3.845293\n",
      "Epoch: 38\tFidelity = 0.500742\tKL_Divergence = 3.769648\n",
      "Epoch: 39\tFidelity = 0.500511\tKL_Divergence = 3.977082\n",
      "Epoch: 40\tFidelity = 0.500636\tKL_Divergence = 3.855083\n",
      "Epoch: 41\tFidelity = 0.500721\tKL_Divergence = 3.785549\n",
      "Epoch: 42\tFidelity = 0.500585\tKL_Divergence = 3.902132\n",
      "Epoch: 43\tFidelity = 0.500807\tKL_Divergence = 3.723115\n",
      "Epoch: 44\tFidelity = 0.500679\tKL_Divergence = 3.819058\n",
      "Epoch: 45\tFidelity = 0.500611\tKL_Divergence = 3.877464\n",
      "Epoch: 46\tFidelity = 0.500683\tKL_Divergence = 3.815853\n",
      "Epoch: 47\tFidelity = 0.500533\tKL_Divergence = 3.953446\n",
      "Epoch: 48\tFidelity = 0.500651\tKL_Divergence = 3.842857\n",
      "Epoch: 49\tFidelity = 0.500681\tKL_Divergence = 3.817530\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:52:06,846] Trial 631 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500703\tKL_Divergence = 3.799958\n",
      "Total time elapsed during training: 44.516 s\n",
      "Trial 631 pruned. \n",
      "Epoch: 1\tFidelity = 0.500599\tKL_Divergence = 3.889180\n",
      "Epoch: 2\tFidelity = 0.500643\tKL_Divergence = 3.849291\n",
      "Epoch: 3\tFidelity = 0.500622\tKL_Divergence = 3.867811\n",
      "Epoch: 4\tFidelity = 0.500632\tKL_Divergence = 3.858601\n",
      "Epoch: 5\tFidelity = 0.500683\tKL_Divergence = 3.815913\n",
      "Epoch: 6\tFidelity = 0.500694\tKL_Divergence = 3.806920\n",
      "Epoch: 7\tFidelity = 0.500667\tKL_Divergence = 3.829351\n",
      "Epoch: 8\tFidelity = 0.500640\tKL_Divergence = 3.852233\n",
      "Epoch: 9\tFidelity = 0.500640\tKL_Divergence = 3.852087\n",
      "Epoch: 10\tFidelity = 0.500602\tKL_Divergence = 3.886015\n",
      "Epoch: 11\tFidelity = 0.500668\tKL_Divergence = 3.827985\n",
      "Epoch: 12\tFidelity = 0.500634\tKL_Divergence = 3.857412\n",
      "Epoch: 13\tFidelity = 0.500639\tKL_Divergence = 3.853202\n",
      "Epoch: 14\tFidelity = 0.500664\tKL_Divergence = 3.831716\n",
      "Epoch: 15\tFidelity = 0.500655\tKL_Divergence = 3.839198\n",
      "Epoch: 16\tFidelity = 0.500621\tKL_Divergence = 3.868293\n",
      "Epoch: 17\tFidelity = 0.500590\tKL_Divergence = 3.896981\n",
      "Epoch: 18\tFidelity = 0.500691\tKL_Divergence = 3.809208\n",
      "Epoch: 19\tFidelity = 0.500715\tKL_Divergence = 3.790609\n",
      "Epoch: 20\tFidelity = 0.500743\tKL_Divergence = 3.769101\n",
      "Epoch: 21\tFidelity = 0.500700\tKL_Divergence = 3.802414\n",
      "Epoch: 22\tFidelity = 0.500696\tKL_Divergence = 3.805079\n",
      "Epoch: 23\tFidelity = 0.500644\tKL_Divergence = 3.848326\n",
      "Epoch: 24\tFidelity = 0.500618\tKL_Divergence = 3.871144\n",
      "Epoch: 25\tFidelity = 0.500674\tKL_Divergence = 3.822832\n",
      "Epoch: 26\tFidelity = 0.500677\tKL_Divergence = 3.820939\n",
      "Epoch: 27\tFidelity = 0.500649\tKL_Divergence = 3.844219\n",
      "Epoch: 28\tFidelity = 0.500657\tKL_Divergence = 3.837278\n",
      "Epoch: 29\tFidelity = 0.500678\tKL_Divergence = 3.820011\n",
      "Epoch: 30\tFidelity = 0.500650\tKL_Divergence = 3.843220\n",
      "Epoch: 31\tFidelity = 0.500668\tKL_Divergence = 3.828010\n",
      "Epoch: 32\tFidelity = 0.500608\tKL_Divergence = 3.880427\n",
      "Epoch: 33\tFidelity = 0.500637\tKL_Divergence = 3.854471\n",
      "Epoch: 34\tFidelity = 0.500658\tKL_Divergence = 3.836401\n",
      "Epoch: 35\tFidelity = 0.500643\tKL_Divergence = 3.848967\n",
      "Epoch: 36\tFidelity = 0.500626\tKL_Divergence = 3.863886\n",
      "Epoch: 37\tFidelity = 0.500614\tKL_Divergence = 3.875019\n",
      "Epoch: 38\tFidelity = 0.500660\tKL_Divergence = 3.834457\n",
      "Epoch: 39\tFidelity = 0.500634\tKL_Divergence = 3.857448\n",
      "Epoch: 40\tFidelity = 0.500617\tKL_Divergence = 3.871787\n",
      "Epoch: 41\tFidelity = 0.500610\tKL_Divergence = 3.878108\n",
      "Epoch: 42\tFidelity = 0.500663\tKL_Divergence = 3.832333\n",
      "Epoch: 43\tFidelity = 0.500694\tKL_Divergence = 3.806753\n",
      "Epoch: 44\tFidelity = 0.500650\tKL_Divergence = 3.843348\n",
      "Epoch: 45\tFidelity = 0.500622\tKL_Divergence = 3.867624\n",
      "Epoch: 46\tFidelity = 0.500588\tKL_Divergence = 3.898334\n",
      "Epoch: 47\tFidelity = 0.500646\tKL_Divergence = 3.846010\n",
      "Epoch: 48\tFidelity = 0.500681\tKL_Divergence = 3.816857\n",
      "Epoch: 49\tFidelity = 0.500671\tKL_Divergence = 3.825585\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:52:44,387] Trial 632 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500691\tKL_Divergence = 3.808744\n",
      "Total time elapsed during training: 37.346 s\n",
      "Trial 632 pruned. \n",
      "Epoch: 1\tFidelity = 0.500672\tKL_Divergence = 3.824574\n",
      "Epoch: 2\tFidelity = 0.500622\tKL_Divergence = 3.867547\n",
      "Epoch: 3\tFidelity = 0.500631\tKL_Divergence = 3.859843\n",
      "Epoch: 4\tFidelity = 0.500610\tKL_Divergence = 3.878237\n",
      "Epoch: 5\tFidelity = 0.500603\tKL_Divergence = 3.884733\n",
      "Epoch: 6\tFidelity = 0.500637\tKL_Divergence = 3.853988\n",
      "Epoch: 7\tFidelity = 0.500640\tKL_Divergence = 3.851901\n",
      "Epoch: 8\tFidelity = 0.500643\tKL_Divergence = 3.848943\n",
      "Epoch: 9\tFidelity = 0.500632\tKL_Divergence = 3.858635\n",
      "Epoch: 10\tFidelity = 0.500686\tKL_Divergence = 3.813550\n",
      "Epoch: 11\tFidelity = 0.500694\tKL_Divergence = 3.806871\n",
      "Epoch: 12\tFidelity = 0.500654\tKL_Divergence = 3.839360\n",
      "Epoch: 13\tFidelity = 0.500590\tKL_Divergence = 3.897350\n",
      "Epoch: 14\tFidelity = 0.500593\tKL_Divergence = 3.893932\n",
      "Epoch: 15\tFidelity = 0.500628\tKL_Divergence = 3.862049\n",
      "Epoch: 16\tFidelity = 0.500653\tKL_Divergence = 3.840391\n",
      "Epoch: 17\tFidelity = 0.500639\tKL_Divergence = 3.852739\n",
      "Epoch: 18\tFidelity = 0.500572\tKL_Divergence = 3.914045\n",
      "Epoch: 19\tFidelity = 0.500638\tKL_Divergence = 3.853883\n",
      "Epoch: 20\tFidelity = 0.500645\tKL_Divergence = 3.847487\n",
      "Epoch: 21\tFidelity = 0.500619\tKL_Divergence = 3.870130\n",
      "Epoch: 22\tFidelity = 0.500596\tKL_Divergence = 3.891529\n",
      "Epoch: 23\tFidelity = 0.500653\tKL_Divergence = 3.840416\n",
      "Epoch: 24\tFidelity = 0.500598\tKL_Divergence = 3.889809\n",
      "Epoch: 25\tFidelity = 0.500609\tKL_Divergence = 3.879413\n",
      "Epoch: 26\tFidelity = 0.500649\tKL_Divergence = 3.844343\n",
      "Epoch: 27\tFidelity = 0.500687\tKL_Divergence = 3.812420\n",
      "Epoch: 28\tFidelity = 0.500666\tKL_Divergence = 3.830322\n",
      "Epoch: 29\tFidelity = 0.500633\tKL_Divergence = 3.858448\n",
      "Epoch: 30\tFidelity = 0.500668\tKL_Divergence = 3.827949\n",
      "Epoch: 31\tFidelity = 0.500603\tKL_Divergence = 3.884789\n",
      "Epoch: 32\tFidelity = 0.500682\tKL_Divergence = 3.816615\n",
      "Epoch: 33\tFidelity = 0.500613\tKL_Divergence = 3.876251\n",
      "Epoch: 34\tFidelity = 0.500623\tKL_Divergence = 3.867237\n",
      "Epoch: 35\tFidelity = 0.500641\tKL_Divergence = 3.851445\n",
      "Epoch: 36\tFidelity = 0.500581\tKL_Divergence = 3.905777\n",
      "Epoch: 37\tFidelity = 0.500629\tKL_Divergence = 3.861807\n",
      "Epoch: 38\tFidelity = 0.500582\tKL_Divergence = 3.905100\n",
      "Epoch: 39\tFidelity = 0.500647\tKL_Divergence = 3.845743\n",
      "Epoch: 40\tFidelity = 0.500673\tKL_Divergence = 3.824384\n",
      "Epoch: 41\tFidelity = 0.500666\tKL_Divergence = 3.829822\n",
      "Epoch: 42\tFidelity = 0.500603\tKL_Divergence = 3.885576\n",
      "Epoch: 43\tFidelity = 0.500668\tKL_Divergence = 3.828098\n",
      "Epoch: 44\tFidelity = 0.500688\tKL_Divergence = 3.812079\n",
      "Epoch: 45\tFidelity = 0.500596\tKL_Divergence = 3.891692\n",
      "Epoch: 46\tFidelity = 0.500650\tKL_Divergence = 3.843225\n",
      "Epoch: 47\tFidelity = 0.500675\tKL_Divergence = 3.822715\n",
      "Epoch: 48\tFidelity = 0.500611\tKL_Divergence = 3.877942\n",
      "Epoch: 49\tFidelity = 0.500578\tKL_Divergence = 3.908465\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:53:22,299] Trial 633 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500638\tKL_Divergence = 3.853964\n",
      "Total time elapsed during training: 37.721 s\n",
      "Trial 633 pruned. \n",
      "Epoch: 1\tFidelity = 0.500743\tKL_Divergence = 3.769519\n",
      "Epoch: 2\tFidelity = 0.500669\tKL_Divergence = 3.827492\n",
      "Epoch: 3\tFidelity = 0.500635\tKL_Divergence = 3.856474\n",
      "Epoch: 4\tFidelity = 0.500553\tKL_Divergence = 3.932738\n",
      "Epoch: 5\tFidelity = 0.500639\tKL_Divergence = 3.853011\n",
      "Epoch: 6\tFidelity = 0.500596\tKL_Divergence = 3.891233\n",
      "Epoch: 7\tFidelity = 0.500729\tKL_Divergence = 3.779320\n",
      "Epoch: 8\tFidelity = 0.500697\tKL_Divergence = 3.804717\n",
      "Epoch: 9\tFidelity = 0.500641\tKL_Divergence = 3.850903\n",
      "Epoch: 10\tFidelity = 0.500556\tKL_Divergence = 3.930325\n",
      "Epoch: 11\tFidelity = 0.500627\tKL_Divergence = 3.863583\n",
      "Epoch: 12\tFidelity = 0.500662\tKL_Divergence = 3.833651\n",
      "Epoch: 13\tFidelity = 0.500681\tKL_Divergence = 3.817473\n",
      "Epoch: 14\tFidelity = 0.500556\tKL_Divergence = 3.930339\n",
      "Epoch: 15\tFidelity = 0.500654\tKL_Divergence = 3.839767\n",
      "Epoch: 16\tFidelity = 0.500597\tKL_Divergence = 3.890487\n",
      "Epoch: 17\tFidelity = 0.500707\tKL_Divergence = 3.796934\n",
      "Epoch: 18\tFidelity = 0.500665\tKL_Divergence = 3.830533\n",
      "Epoch: 19\tFidelity = 0.500584\tKL_Divergence = 3.902775\n",
      "Epoch: 20\tFidelity = 0.500615\tKL_Divergence = 3.873907\n",
      "Epoch: 21\tFidelity = 0.500677\tKL_Divergence = 3.820618\n",
      "Epoch: 22\tFidelity = 0.500666\tKL_Divergence = 3.829721\n",
      "Epoch: 23\tFidelity = 0.500575\tKL_Divergence = 3.911294\n",
      "Epoch: 24\tFidelity = 0.500634\tKL_Divergence = 3.856434\n",
      "Epoch: 25\tFidelity = 0.500577\tKL_Divergence = 3.909070\n",
      "Epoch: 26\tFidelity = 0.500590\tKL_Divergence = 3.897338\n",
      "Epoch: 27\tFidelity = 0.500568\tKL_Divergence = 3.917970\n",
      "Epoch: 28\tFidelity = 0.500623\tKL_Divergence = 3.866897\n",
      "Epoch: 29\tFidelity = 0.500631\tKL_Divergence = 3.860047\n",
      "Epoch: 30\tFidelity = 0.500562\tKL_Divergence = 3.924470\n",
      "Epoch: 31\tFidelity = 0.500687\tKL_Divergence = 3.812939\n",
      "Epoch: 32\tFidelity = 0.500561\tKL_Divergence = 3.925351\n",
      "Epoch: 33\tFidelity = 0.500573\tKL_Divergence = 3.912883\n",
      "Epoch: 34\tFidelity = 0.500612\tKL_Divergence = 3.876584\n",
      "Epoch: 35\tFidelity = 0.500652\tKL_Divergence = 3.841257\n",
      "Epoch: 36\tFidelity = 0.500551\tKL_Divergence = 3.935017\n",
      "Epoch: 37\tFidelity = 0.500550\tKL_Divergence = 3.935983\n",
      "Epoch: 38\tFidelity = 0.500628\tKL_Divergence = 3.862187\n",
      "Epoch: 39\tFidelity = 0.500486\tKL_Divergence = 4.004919\n",
      "Epoch: 40\tFidelity = 0.500595\tKL_Divergence = 3.892197\n",
      "Epoch: 41\tFidelity = 0.500586\tKL_Divergence = 3.900387\n",
      "Epoch: 42\tFidelity = 0.500589\tKL_Divergence = 3.896886\n",
      "Epoch: 43\tFidelity = 0.500607\tKL_Divergence = 3.880597\n",
      "Epoch: 44\tFidelity = 0.500606\tKL_Divergence = 3.881784\n",
      "Epoch: 45\tFidelity = 0.500587\tKL_Divergence = 3.899664\n",
      "Epoch: 46\tFidelity = 0.500615\tKL_Divergence = 3.874051\n",
      "Epoch: 47\tFidelity = 0.500632\tKL_Divergence = 3.858127\n",
      "Epoch: 48\tFidelity = 0.500586\tKL_Divergence = 3.900342\n",
      "Epoch: 49\tFidelity = 0.500654\tKL_Divergence = 3.839506\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:54:06,317] Trial 634 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500612\tKL_Divergence = 3.876635\n",
      "Total time elapsed during training: 43.833 s\n",
      "Trial 634 pruned. \n",
      "Epoch: 1\tFidelity = 0.500568\tKL_Divergence = 3.917926\n",
      "Epoch: 2\tFidelity = 0.500642\tKL_Divergence = 3.850112\n",
      "Epoch: 3\tFidelity = 0.500614\tKL_Divergence = 3.875217\n",
      "Epoch: 4\tFidelity = 0.500607\tKL_Divergence = 3.880926\n",
      "Epoch: 5\tFidelity = 0.500617\tKL_Divergence = 3.872203\n",
      "Epoch: 6\tFidelity = 0.500602\tKL_Divergence = 3.886318\n",
      "Epoch: 7\tFidelity = 0.500613\tKL_Divergence = 3.875585\n",
      "Epoch: 8\tFidelity = 0.500594\tKL_Divergence = 3.893595\n",
      "Epoch: 9\tFidelity = 0.500575\tKL_Divergence = 3.911456\n",
      "Epoch: 10\tFidelity = 0.500623\tKL_Divergence = 3.866833\n",
      "Epoch: 11\tFidelity = 0.500572\tKL_Divergence = 3.914505\n",
      "Epoch: 12\tFidelity = 0.500640\tKL_Divergence = 3.851828\n",
      "Epoch: 13\tFidelity = 0.500661\tKL_Divergence = 3.834096\n",
      "Epoch: 14\tFidelity = 0.500597\tKL_Divergence = 3.890201\n",
      "Epoch: 15\tFidelity = 0.500619\tKL_Divergence = 3.870205\n",
      "Epoch: 16\tFidelity = 0.500647\tKL_Divergence = 3.846332\n",
      "Epoch: 17\tFidelity = 0.500630\tKL_Divergence = 3.861088\n",
      "Epoch: 18\tFidelity = 0.500652\tKL_Divergence = 3.841910\n",
      "Epoch: 19\tFidelity = 0.500575\tKL_Divergence = 3.911830\n",
      "Epoch: 20\tFidelity = 0.500658\tKL_Divergence = 3.836335\n",
      "Epoch: 21\tFidelity = 0.500590\tKL_Divergence = 3.897125\n",
      "Epoch: 22\tFidelity = 0.500624\tKL_Divergence = 3.866024\n",
      "Epoch: 23\tFidelity = 0.500585\tKL_Divergence = 3.902317\n",
      "Epoch: 24\tFidelity = 0.500631\tKL_Divergence = 3.859718\n",
      "Epoch: 25\tFidelity = 0.500595\tKL_Divergence = 3.892569\n",
      "Epoch: 26\tFidelity = 0.500631\tKL_Divergence = 3.860217\n",
      "Epoch: 27\tFidelity = 0.500596\tKL_Divergence = 3.891846\n",
      "Epoch: 28\tFidelity = 0.500584\tKL_Divergence = 3.903097\n",
      "Epoch: 29\tFidelity = 0.500584\tKL_Divergence = 3.903030\n",
      "Epoch: 30\tFidelity = 0.500555\tKL_Divergence = 3.930815\n",
      "Epoch: 31\tFidelity = 0.500579\tKL_Divergence = 3.907977\n",
      "Epoch: 32\tFidelity = 0.500596\tKL_Divergence = 3.891210\n",
      "Epoch: 33\tFidelity = 0.500635\tKL_Divergence = 3.856017\n",
      "Epoch: 34\tFidelity = 0.500610\tKL_Divergence = 3.878590\n",
      "Epoch: 35\tFidelity = 0.500607\tKL_Divergence = 3.881772\n",
      "Epoch: 36\tFidelity = 0.500573\tKL_Divergence = 3.913693\n",
      "Epoch: 37\tFidelity = 0.500554\tKL_Divergence = 3.932044\n",
      "Epoch: 38\tFidelity = 0.500592\tKL_Divergence = 3.895276\n",
      "Epoch: 39\tFidelity = 0.500616\tKL_Divergence = 3.873420\n",
      "Epoch: 40\tFidelity = 0.500632\tKL_Divergence = 3.859108\n",
      "Epoch: 41\tFidelity = 0.500559\tKL_Divergence = 3.926854\n",
      "Epoch: 42\tFidelity = 0.500547\tKL_Divergence = 3.939129\n",
      "Epoch: 43\tFidelity = 0.500596\tKL_Divergence = 3.891332\n",
      "Epoch: 44\tFidelity = 0.500540\tKL_Divergence = 3.946415\n",
      "Epoch: 45\tFidelity = 0.500547\tKL_Divergence = 3.938772\n",
      "Epoch: 46\tFidelity = 0.500596\tKL_Divergence = 3.891263\n",
      "Epoch: 47\tFidelity = 0.500668\tKL_Divergence = 3.828350\n",
      "Epoch: 48\tFidelity = 0.500621\tKL_Divergence = 3.868480\n",
      "Epoch: 49\tFidelity = 0.500599\tKL_Divergence = 3.889231\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:54:44,340] Trial 635 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500642\tKL_Divergence = 3.850124\n",
      "Total time elapsed during training: 37.836 s\n",
      "Trial 635 pruned. \n",
      "Epoch: 1\tFidelity = 0.500758\tKL_Divergence = 3.758467\n",
      "Epoch: 2\tFidelity = 0.500671\tKL_Divergence = 3.825952\n",
      "Epoch: 3\tFidelity = 0.500580\tKL_Divergence = 3.906783\n",
      "Epoch: 4\tFidelity = 0.500675\tKL_Divergence = 3.822746\n",
      "Epoch: 5\tFidelity = 0.500693\tKL_Divergence = 3.808146\n",
      "Epoch: 6\tFidelity = 0.500599\tKL_Divergence = 3.888435\n",
      "Epoch: 7\tFidelity = 0.500640\tKL_Divergence = 3.852261\n",
      "Epoch: 8\tFidelity = 0.500581\tKL_Divergence = 3.905935\n",
      "Epoch: 9\tFidelity = 0.500578\tKL_Divergence = 3.908556\n",
      "Epoch: 10\tFidelity = 0.500584\tKL_Divergence = 3.903065\n",
      "Epoch: 11\tFidelity = 0.500604\tKL_Divergence = 3.883894\n",
      "Epoch: 12\tFidelity = 0.500601\tKL_Divergence = 3.887353\n",
      "Epoch: 13\tFidelity = 0.500621\tKL_Divergence = 3.869001\n",
      "Epoch: 14\tFidelity = 0.500690\tKL_Divergence = 3.810451\n",
      "Epoch: 15\tFidelity = 0.500640\tKL_Divergence = 3.852334\n",
      "Epoch: 16\tFidelity = 0.500615\tKL_Divergence = 3.873822\n",
      "Epoch: 17\tFidelity = 0.500598\tKL_Divergence = 3.889770\n",
      "Epoch: 18\tFidelity = 0.500606\tKL_Divergence = 3.882604\n",
      "Epoch: 19\tFidelity = 0.500680\tKL_Divergence = 3.818667\n",
      "Epoch: 20\tFidelity = 0.500650\tKL_Divergence = 3.843488\n",
      "Epoch: 21\tFidelity = 0.500648\tKL_Divergence = 3.845183\n",
      "Epoch: 22\tFidelity = 0.500628\tKL_Divergence = 3.862550\n",
      "Epoch: 23\tFidelity = 0.500613\tKL_Divergence = 3.875814\n",
      "Epoch: 24\tFidelity = 0.500558\tKL_Divergence = 3.928362\n",
      "Epoch: 25\tFidelity = 0.500631\tKL_Divergence = 3.859940\n",
      "Epoch: 26\tFidelity = 0.500576\tKL_Divergence = 3.910880\n",
      "Epoch: 27\tFidelity = 0.500688\tKL_Divergence = 3.811967\n",
      "Epoch: 28\tFidelity = 0.500610\tKL_Divergence = 3.879055\n",
      "Epoch: 29\tFidelity = 0.500642\tKL_Divergence = 3.850739\n",
      "Epoch: 30\tFidelity = 0.500587\tKL_Divergence = 3.900076\n",
      "Epoch: 31\tFidelity = 0.500562\tKL_Divergence = 3.924592\n",
      "Epoch: 32\tFidelity = 0.500548\tKL_Divergence = 3.938367\n",
      "Epoch: 33\tFidelity = 0.500754\tKL_Divergence = 3.760903\n",
      "Epoch: 34\tFidelity = 0.500598\tKL_Divergence = 3.889422\n",
      "Epoch: 35\tFidelity = 0.500642\tKL_Divergence = 3.850659\n",
      "Epoch: 36\tFidelity = 0.500657\tKL_Divergence = 3.837626\n",
      "Epoch: 37\tFidelity = 0.500591\tKL_Divergence = 3.895939\n",
      "Epoch: 38\tFidelity = 0.500554\tKL_Divergence = 3.931865\n",
      "Epoch: 39\tFidelity = 0.500640\tKL_Divergence = 3.852478\n",
      "Epoch: 40\tFidelity = 0.500544\tKL_Divergence = 3.941964\n",
      "Epoch: 41\tFidelity = 0.500592\tKL_Divergence = 3.895185\n",
      "Epoch: 42\tFidelity = 0.500545\tKL_Divergence = 3.941270\n",
      "Epoch: 43\tFidelity = 0.500485\tKL_Divergence = 4.006235\n",
      "Epoch: 44\tFidelity = 0.500602\tKL_Divergence = 3.885811\n",
      "Epoch: 45\tFidelity = 0.500673\tKL_Divergence = 3.824448\n",
      "Epoch: 46\tFidelity = 0.500649\tKL_Divergence = 3.844756\n",
      "Epoch: 47\tFidelity = 0.500638\tKL_Divergence = 3.853713\n",
      "Epoch: 48\tFidelity = 0.500600\tKL_Divergence = 3.887739\n",
      "Epoch: 49\tFidelity = 0.500573\tKL_Divergence = 3.913356\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:56:02,661] Trial 636 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500643\tKL_Divergence = 3.849721\n",
      "Total time elapsed during training: 78.133 s\n",
      "Trial 636 pruned. \n",
      "Epoch: 1\tFidelity = 0.500627\tKL_Divergence = 3.863939\n",
      "Epoch: 2\tFidelity = 0.500793\tKL_Divergence = 3.732922\n",
      "Epoch: 3\tFidelity = 0.500522\tKL_Divergence = 3.965219\n",
      "Epoch: 4\tFidelity = 0.500541\tKL_Divergence = 3.945588\n",
      "Epoch: 5\tFidelity = 0.500462\tKL_Divergence = 4.032821\n",
      "Epoch: 6\tFidelity = 0.500608\tKL_Divergence = 3.880453\n",
      "Epoch: 7\tFidelity = 0.500600\tKL_Divergence = 3.887673\n",
      "Epoch: 8\tFidelity = 0.500610\tKL_Divergence = 3.878026\n",
      "Epoch: 9\tFidelity = 0.500499\tKL_Divergence = 3.989573\n",
      "Epoch: 10\tFidelity = 0.500693\tKL_Divergence = 3.807963\n",
      "Epoch: 11\tFidelity = 0.500619\tKL_Divergence = 3.870061\n",
      "Epoch: 12\tFidelity = 0.500522\tKL_Divergence = 3.964595\n",
      "Epoch: 13\tFidelity = 0.500537\tKL_Divergence = 3.949211\n",
      "Epoch: 14\tFidelity = 0.500524\tKL_Divergence = 3.963177\n",
      "Epoch: 15\tFidelity = 0.500502\tKL_Divergence = 3.986694\n",
      "Epoch: 16\tFidelity = 0.500530\tKL_Divergence = 3.956640\n",
      "Epoch: 17\tFidelity = 0.500463\tKL_Divergence = 4.031352\n",
      "Epoch: 18\tFidelity = 0.500421\tKL_Divergence = 4.084857\n",
      "Epoch: 19\tFidelity = 0.500462\tKL_Divergence = 4.032976\n",
      "Epoch: 20\tFidelity = 0.500603\tKL_Divergence = 3.885555\n",
      "Epoch: 21\tFidelity = 0.500596\tKL_Divergence = 3.891668\n",
      "Epoch: 22\tFidelity = 0.500580\tKL_Divergence = 3.907193\n",
      "Epoch: 23\tFidelity = 0.500773\tKL_Divergence = 3.747458\n",
      "Epoch: 24\tFidelity = 0.500646\tKL_Divergence = 3.847285\n",
      "Epoch: 25\tFidelity = 0.500553\tKL_Divergence = 3.932955\n",
      "Epoch: 26\tFidelity = 0.500488\tKL_Divergence = 4.002653\n",
      "Epoch: 27\tFidelity = 0.500585\tKL_Divergence = 3.902099\n",
      "Epoch: 28\tFidelity = 0.500605\tKL_Divergence = 3.883346\n",
      "Epoch: 29\tFidelity = 0.500461\tKL_Divergence = 4.034675\n",
      "Epoch: 30\tFidelity = 0.500535\tKL_Divergence = 3.951577\n",
      "Epoch: 31\tFidelity = 0.500541\tKL_Divergence = 3.945864\n",
      "Epoch: 32\tFidelity = 0.500737\tKL_Divergence = 3.773739\n",
      "Epoch: 33\tFidelity = 0.500522\tKL_Divergence = 3.965372\n",
      "Epoch: 34\tFidelity = 0.500528\tKL_Divergence = 3.959183\n",
      "Epoch: 35\tFidelity = 0.500574\tKL_Divergence = 3.912649\n",
      "Epoch: 36\tFidelity = 0.500615\tKL_Divergence = 3.874587\n",
      "Epoch: 37\tFidelity = 0.500531\tKL_Divergence = 3.955889\n",
      "Epoch: 38\tFidelity = 0.500561\tKL_Divergence = 3.925609\n",
      "Epoch: 39\tFidelity = 0.500463\tKL_Divergence = 4.031275\n",
      "Epoch: 40\tFidelity = 0.500574\tKL_Divergence = 3.912244\n",
      "Epoch: 41\tFidelity = 0.500625\tKL_Divergence = 3.864970\n",
      "Epoch: 42\tFidelity = 0.500620\tKL_Divergence = 3.869990\n",
      "Epoch: 43\tFidelity = 0.500586\tKL_Divergence = 3.900846\n",
      "Epoch: 44\tFidelity = 0.500682\tKL_Divergence = 3.816983\n",
      "Epoch: 45\tFidelity = 0.500498\tKL_Divergence = 3.991302\n",
      "Epoch: 46\tFidelity = 0.500505\tKL_Divergence = 3.983538\n",
      "Epoch: 47\tFidelity = 0.500581\tKL_Divergence = 3.905808\n",
      "Epoch: 48\tFidelity = 0.500497\tKL_Divergence = 3.991761\n",
      "Epoch: 49\tFidelity = 0.500387\tKL_Divergence = 4.130797\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:56:41,420] Trial 637 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500592\tKL_Divergence = 3.894583\n",
      "Total time elapsed during training: 38.566 s\n",
      "Trial 637 pruned. \n",
      "Epoch: 1\tFidelity = 0.500581\tKL_Divergence = 3.905687\n",
      "Epoch: 2\tFidelity = 0.500518\tKL_Divergence = 3.969853\n",
      "Epoch: 3\tFidelity = 0.500524\tKL_Divergence = 3.963050\n",
      "Epoch: 4\tFidelity = 0.500644\tKL_Divergence = 3.849138\n",
      "Epoch: 5\tFidelity = 0.500472\tKL_Divergence = 4.020780\n",
      "Epoch: 6\tFidelity = 0.500549\tKL_Divergence = 3.937373\n",
      "Epoch: 7\tFidelity = 0.500646\tKL_Divergence = 3.846659\n",
      "Epoch: 8\tFidelity = 0.500642\tKL_Divergence = 3.850589\n",
      "Epoch: 9\tFidelity = 0.500701\tKL_Divergence = 3.802098\n",
      "Epoch: 10\tFidelity = 0.500532\tKL_Divergence = 3.955302\n",
      "Epoch: 11\tFidelity = 0.500470\tKL_Divergence = 4.023111\n",
      "Epoch: 12\tFidelity = 0.500527\tKL_Divergence = 3.960306\n",
      "Epoch: 13\tFidelity = 0.500640\tKL_Divergence = 3.851992\n",
      "Epoch: 14\tFidelity = 0.500513\tKL_Divergence = 3.974802\n",
      "Epoch: 15\tFidelity = 0.500444\tKL_Divergence = 4.055603\n",
      "Epoch: 16\tFidelity = 0.500559\tKL_Divergence = 3.927506\n",
      "Epoch: 17\tFidelity = 0.500554\tKL_Divergence = 3.932876\n",
      "Epoch: 18\tFidelity = 0.500609\tKL_Divergence = 3.880301\n",
      "Epoch: 19\tFidelity = 0.500655\tKL_Divergence = 3.839536\n",
      "Epoch: 20\tFidelity = 0.500542\tKL_Divergence = 3.944783\n",
      "Epoch: 21\tFidelity = 0.500535\tKL_Divergence = 3.951755\n",
      "Epoch: 22\tFidelity = 0.500595\tKL_Divergence = 3.892815\n",
      "Epoch: 23\tFidelity = 0.500437\tKL_Divergence = 4.064278\n",
      "Epoch: 24\tFidelity = 0.500427\tKL_Divergence = 4.076806\n",
      "Epoch: 25\tFidelity = 0.500480\tKL_Divergence = 4.012061\n",
      "Epoch: 26\tFidelity = 0.500466\tKL_Divergence = 4.027720\n",
      "Epoch: 27\tFidelity = 0.500505\tKL_Divergence = 3.983206\n",
      "Epoch: 28\tFidelity = 0.500682\tKL_Divergence = 3.817202\n",
      "Epoch: 29\tFidelity = 0.500496\tKL_Divergence = 3.993344\n",
      "Epoch: 30\tFidelity = 0.500526\tKL_Divergence = 3.961546\n",
      "Epoch: 31\tFidelity = 0.500538\tKL_Divergence = 3.948892\n",
      "Epoch: 32\tFidelity = 0.500554\tKL_Divergence = 3.932415\n",
      "Epoch: 33\tFidelity = 0.500675\tKL_Divergence = 3.822492\n",
      "Epoch: 34\tFidelity = 0.500601\tKL_Divergence = 3.887525\n",
      "Epoch: 35\tFidelity = 0.500691\tKL_Divergence = 3.809250\n",
      "Epoch: 36\tFidelity = 0.500615\tKL_Divergence = 3.874087\n",
      "Epoch: 37\tFidelity = 0.500518\tKL_Divergence = 3.969340\n",
      "Epoch: 38\tFidelity = 0.500400\tKL_Divergence = 4.112613\n",
      "Epoch: 39\tFidelity = 0.500610\tKL_Divergence = 3.878650\n",
      "Epoch: 40\tFidelity = 0.500589\tKL_Divergence = 3.898308\n",
      "Epoch: 41\tFidelity = 0.500610\tKL_Divergence = 3.877855\n",
      "Epoch: 42\tFidelity = 0.500596\tKL_Divergence = 3.889745\n",
      "Epoch: 43\tFidelity = 0.500565\tKL_Divergence = 3.920203\n",
      "Epoch: 44\tFidelity = 0.500571\tKL_Divergence = 3.915049\n",
      "Epoch: 45\tFidelity = 0.500477\tKL_Divergence = 4.015257\n",
      "Epoch: 46\tFidelity = 0.500634\tKL_Divergence = 3.857105\n",
      "Epoch: 47\tFidelity = 0.500515\tKL_Divergence = 3.972533\n",
      "Epoch: 48\tFidelity = 0.500647\tKL_Divergence = 3.846616\n",
      "Epoch: 49\tFidelity = 0.500467\tKL_Divergence = 4.027174\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:57:19,226] Trial 638 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500546\tKL_Divergence = 3.939867\n",
      "Total time elapsed during training: 37.620 s\n",
      "Trial 638 pruned. \n",
      "Epoch: 1\tFidelity = 0.500593\tKL_Divergence = 3.894789\n",
      "Epoch: 2\tFidelity = 0.500537\tKL_Divergence = 3.949911\n",
      "Epoch: 3\tFidelity = 0.500544\tKL_Divergence = 3.942807\n",
      "Epoch: 4\tFidelity = 0.500516\tKL_Divergence = 3.972067\n",
      "Epoch: 5\tFidelity = 0.500572\tKL_Divergence = 3.914706\n",
      "Epoch: 6\tFidelity = 0.500569\tKL_Divergence = 3.917953\n",
      "Epoch: 7\tFidelity = 0.500533\tKL_Divergence = 3.953847\n",
      "Epoch: 8\tFidelity = 0.500541\tKL_Divergence = 3.945736\n",
      "Epoch: 9\tFidelity = 0.500550\tKL_Divergence = 3.936185\n",
      "Epoch: 10\tFidelity = 0.500544\tKL_Divergence = 3.942042\n",
      "Epoch: 11\tFidelity = 0.500577\tKL_Divergence = 3.910169\n",
      "Epoch: 12\tFidelity = 0.500532\tKL_Divergence = 3.954923\n",
      "Epoch: 13\tFidelity = 0.500544\tKL_Divergence = 3.942164\n",
      "Epoch: 14\tFidelity = 0.500553\tKL_Divergence = 3.933813\n",
      "Epoch: 15\tFidelity = 0.500560\tKL_Divergence = 3.926611\n",
      "Epoch: 16\tFidelity = 0.500565\tKL_Divergence = 3.921094\n",
      "Epoch: 17\tFidelity = 0.500558\tKL_Divergence = 3.928339\n",
      "Epoch: 18\tFidelity = 0.500522\tKL_Divergence = 3.965570\n",
      "Epoch: 19\tFidelity = 0.500568\tKL_Divergence = 3.918776\n",
      "Epoch: 20\tFidelity = 0.500516\tKL_Divergence = 3.971973\n",
      "Epoch: 21\tFidelity = 0.500555\tKL_Divergence = 3.931185\n",
      "Epoch: 22\tFidelity = 0.500543\tKL_Divergence = 3.943205\n",
      "Epoch: 23\tFidelity = 0.500548\tKL_Divergence = 3.938645\n",
      "Epoch: 24\tFidelity = 0.500551\tKL_Divergence = 3.935318\n",
      "Epoch: 25\tFidelity = 0.500507\tKL_Divergence = 3.981918\n",
      "Epoch: 26\tFidelity = 0.500550\tKL_Divergence = 3.936020\n",
      "Epoch: 27\tFidelity = 0.500588\tKL_Divergence = 3.899540\n",
      "Epoch: 28\tFidelity = 0.500565\tKL_Divergence = 3.921224\n",
      "Epoch: 29\tFidelity = 0.500562\tKL_Divergence = 3.924688\n",
      "Epoch: 30\tFidelity = 0.500526\tKL_Divergence = 3.960775\n",
      "Epoch: 31\tFidelity = 0.500562\tKL_Divergence = 3.924458\n",
      "Epoch: 32\tFidelity = 0.500528\tKL_Divergence = 3.959566\n",
      "Epoch: 33\tFidelity = 0.500570\tKL_Divergence = 3.917074\n",
      "Epoch: 34\tFidelity = 0.500563\tKL_Divergence = 3.923607\n",
      "Epoch: 35\tFidelity = 0.500526\tKL_Divergence = 3.961005\n",
      "Epoch: 36\tFidelity = 0.500605\tKL_Divergence = 3.883454\n",
      "Epoch: 37\tFidelity = 0.500557\tKL_Divergence = 3.929870\n",
      "Epoch: 38\tFidelity = 0.500549\tKL_Divergence = 3.937260\n",
      "Epoch: 39\tFidelity = 0.500602\tKL_Divergence = 3.886216\n",
      "Epoch: 40\tFidelity = 0.500561\tKL_Divergence = 3.924973\n",
      "Epoch: 41\tFidelity = 0.500561\tKL_Divergence = 3.925219\n",
      "Epoch: 42\tFidelity = 0.500586\tKL_Divergence = 3.901106\n",
      "Epoch: 43\tFidelity = 0.500549\tKL_Divergence = 3.937037\n",
      "Epoch: 44\tFidelity = 0.500611\tKL_Divergence = 3.877833\n",
      "Epoch: 45\tFidelity = 0.500530\tKL_Divergence = 3.956607\n",
      "Epoch: 46\tFidelity = 0.500575\tKL_Divergence = 3.911471\n",
      "Epoch: 47\tFidelity = 0.500552\tKL_Divergence = 3.934104\n",
      "Epoch: 48\tFidelity = 0.500617\tKL_Divergence = 3.872815\n",
      "Epoch: 49\tFidelity = 0.500568\tKL_Divergence = 3.918594\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:57:51,194] Trial 639 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500536\tKL_Divergence = 3.951026\n",
      "Total time elapsed during training: 31.771 s\n",
      "Trial 639 pruned. \n",
      "Epoch: 1\tFidelity = 0.500594\tKL_Divergence = 3.893483\n",
      "Epoch: 2\tFidelity = 0.500485\tKL_Divergence = 4.006591\n",
      "Epoch: 3\tFidelity = 0.500539\tKL_Divergence = 3.947176\n",
      "Epoch: 4\tFidelity = 0.500531\tKL_Divergence = 3.955614\n",
      "Epoch: 5\tFidelity = 0.500592\tKL_Divergence = 3.895388\n",
      "Epoch: 6\tFidelity = 0.500531\tKL_Divergence = 3.955761\n",
      "Epoch: 7\tFidelity = 0.500560\tKL_Divergence = 3.926261\n",
      "Epoch: 8\tFidelity = 0.500646\tKL_Divergence = 3.847534\n",
      "Epoch: 9\tFidelity = 0.500561\tKL_Divergence = 3.925843\n",
      "Epoch: 10\tFidelity = 0.500592\tKL_Divergence = 3.895580\n",
      "Epoch: 11\tFidelity = 0.500519\tKL_Divergence = 3.968425\n",
      "Epoch: 12\tFidelity = 0.500524\tKL_Divergence = 3.963551\n",
      "Epoch: 13\tFidelity = 0.500649\tKL_Divergence = 3.844953\n",
      "Epoch: 14\tFidelity = 0.500589\tKL_Divergence = 3.898238\n",
      "Epoch: 15\tFidelity = 0.500591\tKL_Divergence = 3.896951\n",
      "Epoch: 16\tFidelity = 0.500563\tKL_Divergence = 3.923678\n",
      "Epoch: 17\tFidelity = 0.500613\tKL_Divergence = 3.876619\n",
      "Epoch: 18\tFidelity = 0.500549\tKL_Divergence = 3.937655\n",
      "Epoch: 19\tFidelity = 0.500523\tKL_Divergence = 3.964370\n",
      "Epoch: 20\tFidelity = 0.500505\tKL_Divergence = 3.983671\n",
      "Epoch: 21\tFidelity = 0.500598\tKL_Divergence = 3.889600\n",
      "Epoch: 22\tFidelity = 0.500595\tKL_Divergence = 3.892343\n",
      "Epoch: 23\tFidelity = 0.500518\tKL_Divergence = 3.969486\n",
      "Epoch: 24\tFidelity = 0.500586\tKL_Divergence = 3.900854\n",
      "Epoch: 25\tFidelity = 0.500520\tKL_Divergence = 3.967812\n",
      "Epoch: 26\tFidelity = 0.500560\tKL_Divergence = 3.926863\n",
      "Epoch: 27\tFidelity = 0.500559\tKL_Divergence = 3.927584\n",
      "Epoch: 28\tFidelity = 0.500625\tKL_Divergence = 3.865306\n",
      "Epoch: 29\tFidelity = 0.500541\tKL_Divergence = 3.945862\n",
      "Epoch: 30\tFidelity = 0.500523\tKL_Divergence = 3.964136\n",
      "Epoch: 31\tFidelity = 0.500564\tKL_Divergence = 3.922634\n",
      "Epoch: 32\tFidelity = 0.500533\tKL_Divergence = 3.954189\n",
      "Epoch: 33\tFidelity = 0.500575\tKL_Divergence = 3.911714\n",
      "Epoch: 34\tFidelity = 0.500618\tKL_Divergence = 3.872090\n",
      "Epoch: 35\tFidelity = 0.500566\tKL_Divergence = 3.920602\n",
      "Epoch: 36\tFidelity = 0.500517\tKL_Divergence = 3.970638\n",
      "Epoch: 37\tFidelity = 0.500584\tKL_Divergence = 3.902868\n",
      "Epoch: 38\tFidelity = 0.500617\tKL_Divergence = 3.872524\n",
      "Epoch: 39\tFidelity = 0.500580\tKL_Divergence = 3.906768\n",
      "Epoch: 40\tFidelity = 0.500639\tKL_Divergence = 3.852753\n",
      "Epoch: 41\tFidelity = 0.500568\tKL_Divergence = 3.918745\n",
      "Epoch: 42\tFidelity = 0.500609\tKL_Divergence = 3.879625\n",
      "Epoch: 43\tFidelity = 0.500547\tKL_Divergence = 3.939326\n",
      "Epoch: 44\tFidelity = 0.500563\tKL_Divergence = 3.923102\n",
      "Epoch: 45\tFidelity = 0.500553\tKL_Divergence = 3.933747\n",
      "Epoch: 46\tFidelity = 0.500562\tKL_Divergence = 3.924694\n",
      "Epoch: 47\tFidelity = 0.500522\tKL_Divergence = 3.965751\n",
      "Epoch: 48\tFidelity = 0.500567\tKL_Divergence = 3.919563\n",
      "Epoch: 49\tFidelity = 0.500557\tKL_Divergence = 3.929190\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:58:36,814] Trial 640 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500542\tKL_Divergence = 3.944922\n",
      "Total time elapsed during training: 45.426 s\n",
      "Trial 640 pruned. \n",
      "Epoch: 1\tFidelity = 0.500537\tKL_Divergence = 3.949582\n",
      "Epoch: 2\tFidelity = 0.500643\tKL_Divergence = 3.849957\n",
      "Epoch: 3\tFidelity = 0.500583\tKL_Divergence = 3.903697\n",
      "Epoch: 4\tFidelity = 0.500557\tKL_Divergence = 3.929903\n",
      "Epoch: 5\tFidelity = 0.500523\tKL_Divergence = 3.964830\n",
      "Epoch: 6\tFidelity = 0.500555\tKL_Divergence = 3.931394\n",
      "Epoch: 7\tFidelity = 0.500581\tKL_Divergence = 3.905597\n",
      "Epoch: 8\tFidelity = 0.500576\tKL_Divergence = 3.910924\n",
      "Epoch: 9\tFidelity = 0.500544\tKL_Divergence = 3.942995\n",
      "Epoch: 10\tFidelity = 0.500483\tKL_Divergence = 4.008398\n",
      "Epoch: 11\tFidelity = 0.500574\tKL_Divergence = 3.912884\n",
      "Epoch: 12\tFidelity = 0.500495\tKL_Divergence = 3.994387\n",
      "Epoch: 13\tFidelity = 0.500611\tKL_Divergence = 3.878208\n",
      "Epoch: 14\tFidelity = 0.500560\tKL_Divergence = 3.926130\n",
      "Epoch: 15\tFidelity = 0.500581\tKL_Divergence = 3.905683\n",
      "Epoch: 16\tFidelity = 0.500606\tKL_Divergence = 3.882214\n",
      "Epoch: 17\tFidelity = 0.500597\tKL_Divergence = 3.890914\n",
      "Epoch: 18\tFidelity = 0.500592\tKL_Divergence = 3.895850\n",
      "Epoch: 19\tFidelity = 0.500520\tKL_Divergence = 3.967214\n",
      "Epoch: 20\tFidelity = 0.500601\tKL_Divergence = 3.887495\n",
      "Epoch: 21\tFidelity = 0.500552\tKL_Divergence = 3.934552\n",
      "Epoch: 22\tFidelity = 0.500474\tKL_Divergence = 4.019109\n",
      "Epoch: 23\tFidelity = 0.500462\tKL_Divergence = 4.033515\n",
      "Epoch: 24\tFidelity = 0.500530\tKL_Divergence = 3.957453\n",
      "Epoch: 25\tFidelity = 0.500559\tKL_Divergence = 3.927601\n",
      "Epoch: 26\tFidelity = 0.500512\tKL_Divergence = 3.976656\n",
      "Epoch: 27\tFidelity = 0.500449\tKL_Divergence = 4.049092\n",
      "Epoch: 28\tFidelity = 0.500643\tKL_Divergence = 3.849933\n",
      "Epoch: 29\tFidelity = 0.500550\tKL_Divergence = 3.936286\n",
      "Epoch: 30\tFidelity = 0.500547\tKL_Divergence = 3.939152\n",
      "Epoch: 31\tFidelity = 0.500649\tKL_Divergence = 3.844287\n",
      "Epoch: 32\tFidelity = 0.500505\tKL_Divergence = 3.984269\n",
      "Epoch: 33\tFidelity = 0.500669\tKL_Divergence = 3.827682\n",
      "Epoch: 34\tFidelity = 0.500566\tKL_Divergence = 3.919997\n",
      "Epoch: 35\tFidelity = 0.500522\tKL_Divergence = 3.965211\n",
      "Epoch: 36\tFidelity = 0.500608\tKL_Divergence = 3.880820\n",
      "Epoch: 37\tFidelity = 0.500587\tKL_Divergence = 3.900309\n",
      "Epoch: 38\tFidelity = 0.500608\tKL_Divergence = 3.880333\n",
      "Epoch: 39\tFidelity = 0.500549\tKL_Divergence = 3.937626\n",
      "Epoch: 40\tFidelity = 0.500549\tKL_Divergence = 3.937118\n",
      "Epoch: 41\tFidelity = 0.500602\tKL_Divergence = 3.885766\n",
      "Epoch: 42\tFidelity = 0.500596\tKL_Divergence = 3.891828\n",
      "Epoch: 43\tFidelity = 0.500484\tKL_Divergence = 4.006827\n",
      "Epoch: 44\tFidelity = 0.500644\tKL_Divergence = 3.849212\n",
      "Epoch: 45\tFidelity = 0.500611\tKL_Divergence = 3.877711\n",
      "Epoch: 46\tFidelity = 0.500679\tKL_Divergence = 3.819184\n",
      "Epoch: 47\tFidelity = 0.500603\tKL_Divergence = 3.885314\n",
      "Epoch: 48\tFidelity = 0.500504\tKL_Divergence = 3.984868\n",
      "Epoch: 49\tFidelity = 0.500611\tKL_Divergence = 3.878107\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 11:59:56,279] Trial 641 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500496\tKL_Divergence = 3.994182\n",
      "Total time elapsed during training: 79.284 s\n",
      "Trial 641 pruned. \n",
      "Epoch: 1\tFidelity = 0.500530\tKL_Divergence = 3.956531\n",
      "Epoch: 2\tFidelity = 0.500568\tKL_Divergence = 3.918140\n",
      "Epoch: 3\tFidelity = 0.500601\tKL_Divergence = 3.886781\n",
      "Epoch: 4\tFidelity = 0.500532\tKL_Divergence = 3.954377\n",
      "Epoch: 5\tFidelity = 0.500566\tKL_Divergence = 3.920465\n",
      "Epoch: 6\tFidelity = 0.500560\tKL_Divergence = 3.926286\n",
      "Epoch: 7\tFidelity = 0.500569\tKL_Divergence = 3.917479\n",
      "Epoch: 8\tFidelity = 0.500573\tKL_Divergence = 3.913823\n",
      "Epoch: 9\tFidelity = 0.500580\tKL_Divergence = 3.906703\n",
      "Epoch: 10\tFidelity = 0.500519\tKL_Divergence = 3.968485\n",
      "Epoch: 11\tFidelity = 0.500525\tKL_Divergence = 3.962140\n",
      "Epoch: 12\tFidelity = 0.500503\tKL_Divergence = 3.985452\n",
      "Epoch: 13\tFidelity = 0.500543\tKL_Divergence = 3.943288\n",
      "Epoch: 14\tFidelity = 0.500516\tKL_Divergence = 3.971457\n",
      "Epoch: 15\tFidelity = 0.500528\tKL_Divergence = 3.959175\n",
      "Epoch: 16\tFidelity = 0.500521\tKL_Divergence = 3.966197\n",
      "Epoch: 17\tFidelity = 0.500533\tKL_Divergence = 3.953622\n",
      "Epoch: 18\tFidelity = 0.500512\tKL_Divergence = 3.976001\n",
      "Epoch: 19\tFidelity = 0.500533\tKL_Divergence = 3.954241\n",
      "Epoch: 20\tFidelity = 0.500570\tKL_Divergence = 3.916466\n",
      "Epoch: 21\tFidelity = 0.500537\tKL_Divergence = 3.950140\n",
      "Epoch: 22\tFidelity = 0.500563\tKL_Divergence = 3.923091\n",
      "Epoch: 23\tFidelity = 0.500533\tKL_Divergence = 3.954269\n",
      "Epoch: 24\tFidelity = 0.500532\tKL_Divergence = 3.954336\n",
      "Epoch: 25\tFidelity = 0.500512\tKL_Divergence = 3.976380\n",
      "Epoch: 26\tFidelity = 0.500515\tKL_Divergence = 3.973317\n",
      "Epoch: 27\tFidelity = 0.500546\tKL_Divergence = 3.940673\n",
      "Epoch: 28\tFidelity = 0.500550\tKL_Divergence = 3.936357\n",
      "Epoch: 29\tFidelity = 0.500554\tKL_Divergence = 3.932018\n",
      "Epoch: 30\tFidelity = 0.500518\tKL_Divergence = 3.969777\n",
      "Epoch: 31\tFidelity = 0.500521\tKL_Divergence = 3.966806\n",
      "Epoch: 32\tFidelity = 0.500537\tKL_Divergence = 3.949819\n",
      "Epoch: 33\tFidelity = 0.500566\tKL_Divergence = 3.920277\n",
      "Epoch: 34\tFidelity = 0.500549\tKL_Divergence = 3.937250\n",
      "Epoch: 35\tFidelity = 0.500559\tKL_Divergence = 3.927345\n",
      "Epoch: 36\tFidelity = 0.500609\tKL_Divergence = 3.879914\n",
      "Epoch: 37\tFidelity = 0.500556\tKL_Divergence = 3.929982\n",
      "Epoch: 38\tFidelity = 0.500498\tKL_Divergence = 3.991285\n",
      "Epoch: 39\tFidelity = 0.500532\tKL_Divergence = 3.954629\n",
      "Epoch: 40\tFidelity = 0.500580\tKL_Divergence = 3.906593\n",
      "Epoch: 41\tFidelity = 0.500538\tKL_Divergence = 3.948852\n",
      "Epoch: 42\tFidelity = 0.500553\tKL_Divergence = 3.933108\n",
      "Epoch: 43\tFidelity = 0.500530\tKL_Divergence = 3.956529\n",
      "Epoch: 44\tFidelity = 0.500524\tKL_Divergence = 3.963719\n",
      "Epoch: 45\tFidelity = 0.500504\tKL_Divergence = 3.985115\n",
      "Epoch: 46\tFidelity = 0.500514\tKL_Divergence = 3.974312\n",
      "Epoch: 47\tFidelity = 0.500520\tKL_Divergence = 3.967620\n",
      "Epoch: 48\tFidelity = 0.500539\tKL_Divergence = 3.947827\n",
      "Epoch: 49\tFidelity = 0.500550\tKL_Divergence = 3.936186\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 12:00:27,739] Trial 642 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500499\tKL_Divergence = 3.990277\n",
      "Total time elapsed during training: 31.269 s\n",
      "Trial 642 pruned. \n",
      "Epoch: 1\tFidelity = 0.500538\tKL_Divergence = 3.948897\n",
      "Epoch: 2\tFidelity = 0.500563\tKL_Divergence = 3.923773\n",
      "Epoch: 3\tFidelity = 0.500549\tKL_Divergence = 3.937860\n",
      "Epoch: 4\tFidelity = 0.500512\tKL_Divergence = 3.976545\n",
      "Epoch: 5\tFidelity = 0.500506\tKL_Divergence = 3.983025\n",
      "Epoch: 6\tFidelity = 0.500580\tKL_Divergence = 3.906458\n",
      "Epoch: 7\tFidelity = 0.500532\tKL_Divergence = 3.955264\n",
      "Epoch: 8\tFidelity = 0.500530\tKL_Divergence = 3.957129\n",
      "Epoch: 9\tFidelity = 0.500595\tKL_Divergence = 3.892750\n",
      "Epoch: 10\tFidelity = 0.500589\tKL_Divergence = 3.898611\n",
      "Epoch: 11\tFidelity = 0.500563\tKL_Divergence = 3.923125\n",
      "Epoch: 12\tFidelity = 0.500578\tKL_Divergence = 3.908422\n",
      "Epoch: 13\tFidelity = 0.500568\tKL_Divergence = 3.918126\n",
      "Epoch: 14\tFidelity = 0.500606\tKL_Divergence = 3.882855\n",
      "Epoch: 15\tFidelity = 0.500604\tKL_Divergence = 3.884577\n",
      "Epoch: 16\tFidelity = 0.500476\tKL_Divergence = 4.016895\n",
      "Epoch: 17\tFidelity = 0.500527\tKL_Divergence = 3.960404\n",
      "Epoch: 18\tFidelity = 0.500530\tKL_Divergence = 3.956934\n",
      "Epoch: 19\tFidelity = 0.500464\tKL_Divergence = 4.031177\n",
      "Epoch: 20\tFidelity = 0.500586\tKL_Divergence = 3.901374\n",
      "Epoch: 21\tFidelity = 0.500607\tKL_Divergence = 3.881734\n",
      "Epoch: 22\tFidelity = 0.500547\tKL_Divergence = 3.938968\n",
      "Epoch: 23\tFidelity = 0.500523\tKL_Divergence = 3.964391\n",
      "Epoch: 24\tFidelity = 0.500600\tKL_Divergence = 3.887782\n",
      "Epoch: 25\tFidelity = 0.500582\tKL_Divergence = 3.905194\n",
      "Epoch: 26\tFidelity = 0.500499\tKL_Divergence = 3.990121\n",
      "Epoch: 27\tFidelity = 0.500551\tKL_Divergence = 3.935420\n",
      "Epoch: 28\tFidelity = 0.500514\tKL_Divergence = 3.974281\n",
      "Epoch: 29\tFidelity = 0.500509\tKL_Divergence = 3.979212\n",
      "Epoch: 30\tFidelity = 0.500493\tKL_Divergence = 3.997136\n",
      "Epoch: 31\tFidelity = 0.500494\tKL_Divergence = 3.995576\n",
      "Epoch: 32\tFidelity = 0.500658\tKL_Divergence = 3.836816\n",
      "Epoch: 33\tFidelity = 0.500551\tKL_Divergence = 3.935049\n",
      "Epoch: 34\tFidelity = 0.500463\tKL_Divergence = 4.032059\n",
      "Epoch: 35\tFidelity = 0.500538\tKL_Divergence = 3.948113\n",
      "Epoch: 36\tFidelity = 0.500509\tKL_Divergence = 3.978961\n",
      "Epoch: 37\tFidelity = 0.500542\tKL_Divergence = 3.944685\n",
      "Epoch: 38\tFidelity = 0.500618\tKL_Divergence = 3.871996\n",
      "Epoch: 39\tFidelity = 0.500589\tKL_Divergence = 3.897786\n",
      "Epoch: 40\tFidelity = 0.500528\tKL_Divergence = 3.958709\n",
      "Epoch: 41\tFidelity = 0.500472\tKL_Divergence = 4.020866\n",
      "Epoch: 42\tFidelity = 0.500534\tKL_Divergence = 3.952825\n",
      "Epoch: 43\tFidelity = 0.500561\tKL_Divergence = 3.925575\n",
      "Epoch: 44\tFidelity = 0.500570\tKL_Divergence = 3.916533\n",
      "Epoch: 45\tFidelity = 0.500488\tKL_Divergence = 4.002162\n",
      "Epoch: 46\tFidelity = 0.500551\tKL_Divergence = 3.935775\n",
      "Epoch: 47\tFidelity = 0.500522\tKL_Divergence = 3.964921\n",
      "Epoch: 48\tFidelity = 0.500515\tKL_Divergence = 3.973326\n",
      "Epoch: 49\tFidelity = 0.500534\tKL_Divergence = 3.952845\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 12:01:05,815] Trial 643 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500530\tKL_Divergence = 3.956846\n",
      "Total time elapsed during training: 37.883 s\n",
      "Trial 643 pruned. \n",
      "Epoch: 1\tFidelity = 0.500492\tKL_Divergence = 3.997847\n",
      "Epoch: 2\tFidelity = 0.500469\tKL_Divergence = 4.024493\n",
      "Epoch: 3\tFidelity = 0.500523\tKL_Divergence = 3.963782\n",
      "Epoch: 4\tFidelity = 0.500621\tKL_Divergence = 3.869222\n",
      "Epoch: 5\tFidelity = 0.500497\tKL_Divergence = 3.992434\n",
      "Epoch: 6\tFidelity = 0.500644\tKL_Divergence = 3.848082\n",
      "Epoch: 7\tFidelity = 0.500538\tKL_Divergence = 3.948610\n",
      "Epoch: 8\tFidelity = 0.500627\tKL_Divergence = 3.863946\n",
      "Epoch: 9\tFidelity = 0.500547\tKL_Divergence = 3.939018\n",
      "Epoch: 10\tFidelity = 0.500427\tKL_Divergence = 4.076626\n",
      "Epoch: 11\tFidelity = 0.500543\tKL_Divergence = 3.943631\n",
      "Epoch: 12\tFidelity = 0.500498\tKL_Divergence = 3.991213\n",
      "Epoch: 13\tFidelity = 0.500480\tKL_Divergence = 4.011115\n",
      "Epoch: 14\tFidelity = 0.500521\tKL_Divergence = 3.966558\n",
      "Epoch: 15\tFidelity = 0.500587\tKL_Divergence = 3.900238\n",
      "Epoch: 16\tFidelity = 0.500672\tKL_Divergence = 3.824741\n",
      "Epoch: 17\tFidelity = 0.500610\tKL_Divergence = 3.879247\n",
      "Epoch: 18\tFidelity = 0.500528\tKL_Divergence = 3.959203\n",
      "Epoch: 19\tFidelity = 0.500613\tKL_Divergence = 3.876140\n",
      "Epoch: 20\tFidelity = 0.500480\tKL_Divergence = 4.012165\n",
      "Epoch: 21\tFidelity = 0.500507\tKL_Divergence = 3.981274\n",
      "Epoch: 22\tFidelity = 0.500653\tKL_Divergence = 3.841056\n",
      "Epoch: 23\tFidelity = 0.500686\tKL_Divergence = 3.813517\n",
      "Epoch: 24\tFidelity = 0.500431\tKL_Divergence = 4.071863\n",
      "Epoch: 25\tFidelity = 0.500659\tKL_Divergence = 3.835885\n",
      "Epoch: 26\tFidelity = 0.500654\tKL_Divergence = 3.840148\n",
      "Epoch: 27\tFidelity = 0.500458\tKL_Divergence = 4.037945\n",
      "Epoch: 28\tFidelity = 0.500509\tKL_Divergence = 3.978757\n",
      "Epoch: 29\tFidelity = 0.500672\tKL_Divergence = 3.825386\n",
      "Epoch: 30\tFidelity = 0.500685\tKL_Divergence = 3.814395\n",
      "Epoch: 31\tFidelity = 0.500540\tKL_Divergence = 3.946430\n",
      "Epoch: 32\tFidelity = 0.500578\tKL_Divergence = 3.908512\n",
      "Epoch: 33\tFidelity = 0.500488\tKL_Divergence = 4.002138\n",
      "Epoch: 34\tFidelity = 0.500538\tKL_Divergence = 3.947411\n",
      "Epoch: 35\tFidelity = 0.500630\tKL_Divergence = 3.861089\n",
      "Epoch: 36\tFidelity = 0.500726\tKL_Divergence = 3.782202\n",
      "Epoch: 37\tFidelity = 0.500512\tKL_Divergence = 3.976045\n",
      "Epoch: 38\tFidelity = 0.500728\tKL_Divergence = 3.780723\n",
      "Epoch: 39\tFidelity = 0.500525\tKL_Divergence = 3.961621\n",
      "Epoch: 40\tFidelity = 0.500590\tKL_Divergence = 3.897252\n",
      "Epoch: 41\tFidelity = 0.500618\tKL_Divergence = 3.871230\n",
      "Epoch: 42\tFidelity = 0.500661\tKL_Divergence = 3.834159\n",
      "Epoch: 43\tFidelity = 0.500514\tKL_Divergence = 3.973735\n",
      "Epoch: 44\tFidelity = 0.500646\tKL_Divergence = 3.846671\n",
      "Epoch: 45\tFidelity = 0.500544\tKL_Divergence = 3.941114\n",
      "Epoch: 46\tFidelity = 0.500674\tKL_Divergence = 3.822546\n",
      "Epoch: 47\tFidelity = 0.500606\tKL_Divergence = 3.880852\n",
      "Epoch: 48\tFidelity = 0.500577\tKL_Divergence = 3.908322\n",
      "Epoch: 49\tFidelity = 0.500531\tKL_Divergence = 3.953804\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 12:01:43,392] Trial 644 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500541\tKL_Divergence = 3.943353\n",
      "Total time elapsed during training: 37.370 s\n",
      "Trial 644 pruned. \n",
      "Epoch: 1\tFidelity = 0.500526\tKL_Divergence = 3.959291\n",
      "Epoch: 2\tFidelity = 0.500581\tKL_Divergence = 3.904547\n",
      "Epoch: 3\tFidelity = 0.500596\tKL_Divergence = 3.890635\n",
      "Epoch: 4\tFidelity = 0.500546\tKL_Divergence = 3.939244\n",
      "Epoch: 5\tFidelity = 0.500562\tKL_Divergence = 3.923446\n",
      "Epoch: 6\tFidelity = 0.500532\tKL_Divergence = 3.953463\n",
      "Epoch: 7\tFidelity = 0.500538\tKL_Divergence = 3.947286\n",
      "Epoch: 8\tFidelity = 0.500573\tKL_Divergence = 3.912382\n",
      "Epoch: 9\tFidelity = 0.500597\tKL_Divergence = 3.890468\n",
      "Epoch: 10\tFidelity = 0.500567\tKL_Divergence = 3.918470\n",
      "Epoch: 11\tFidelity = 0.500621\tKL_Divergence = 3.868856\n",
      "Epoch: 12\tFidelity = 0.500606\tKL_Divergence = 3.882008\n",
      "Epoch: 13\tFidelity = 0.500580\tKL_Divergence = 3.906502\n",
      "Epoch: 14\tFidelity = 0.500601\tKL_Divergence = 3.886906\n",
      "Epoch: 15\tFidelity = 0.500545\tKL_Divergence = 3.941318\n",
      "Epoch: 16\tFidelity = 0.500588\tKL_Divergence = 3.898802\n",
      "Epoch: 17\tFidelity = 0.500533\tKL_Divergence = 3.953479\n",
      "Epoch: 18\tFidelity = 0.500596\tKL_Divergence = 3.891326\n",
      "Epoch: 19\tFidelity = 0.500573\tKL_Divergence = 3.912779\n",
      "Epoch: 20\tFidelity = 0.500613\tKL_Divergence = 3.875753\n",
      "Epoch: 21\tFidelity = 0.500589\tKL_Divergence = 3.897964\n",
      "Epoch: 22\tFidelity = 0.500538\tKL_Divergence = 3.948559\n",
      "Epoch: 23\tFidelity = 0.500573\tKL_Divergence = 3.912950\n",
      "Epoch: 24\tFidelity = 0.500588\tKL_Divergence = 3.899234\n",
      "Epoch: 25\tFidelity = 0.500542\tKL_Divergence = 3.944400\n",
      "Epoch: 26\tFidelity = 0.500536\tKL_Divergence = 3.950154\n",
      "Epoch: 27\tFidelity = 0.500578\tKL_Divergence = 3.908990\n",
      "Epoch: 28\tFidelity = 0.500540\tKL_Divergence = 3.946817\n",
      "Epoch: 29\tFidelity = 0.500552\tKL_Divergence = 3.934021\n",
      "Epoch: 30\tFidelity = 0.500570\tKL_Divergence = 3.916033\n",
      "Epoch: 31\tFidelity = 0.500555\tKL_Divergence = 3.930978\n",
      "Epoch: 32\tFidelity = 0.500592\tKL_Divergence = 3.894960\n",
      "Epoch: 33\tFidelity = 0.500610\tKL_Divergence = 3.878409\n",
      "Epoch: 34\tFidelity = 0.500574\tKL_Divergence = 3.912553\n",
      "Epoch: 35\tFidelity = 0.500583\tKL_Divergence = 3.904110\n",
      "Epoch: 36\tFidelity = 0.500557\tKL_Divergence = 3.929628\n",
      "Epoch: 37\tFidelity = 0.500576\tKL_Divergence = 3.910725\n",
      "Epoch: 38\tFidelity = 0.500555\tKL_Divergence = 3.930892\n",
      "Epoch: 39\tFidelity = 0.500593\tKL_Divergence = 3.894792\n",
      "Epoch: 40\tFidelity = 0.500580\tKL_Divergence = 3.906962\n",
      "Epoch: 41\tFidelity = 0.500566\tKL_Divergence = 3.919825\n",
      "Epoch: 42\tFidelity = 0.500518\tKL_Divergence = 3.969254\n",
      "Epoch: 43\tFidelity = 0.500626\tKL_Divergence = 3.864320\n",
      "Epoch: 44\tFidelity = 0.500558\tKL_Divergence = 3.928320\n",
      "Epoch: 45\tFidelity = 0.500591\tKL_Divergence = 3.896101\n",
      "Epoch: 46\tFidelity = 0.500603\tKL_Divergence = 3.885011\n",
      "Epoch: 47\tFidelity = 0.500605\tKL_Divergence = 3.883164\n",
      "Epoch: 48\tFidelity = 0.500575\tKL_Divergence = 3.911545\n",
      "Epoch: 49\tFidelity = 0.500545\tKL_Divergence = 3.941125\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 12:02:40,329] Trial 645 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500578\tKL_Divergence = 3.908729\n",
      "Total time elapsed during training: 56.759 s\n",
      "Trial 645 pruned. \n",
      "Epoch: 1\tFidelity = 0.500583\tKL_Divergence = 3.903929\n",
      "Epoch: 2\tFidelity = 0.500548\tKL_Divergence = 3.938689\n",
      "Epoch: 3\tFidelity = 0.500607\tKL_Divergence = 3.881586\n",
      "Epoch: 4\tFidelity = 0.500553\tKL_Divergence = 3.933317\n",
      "Epoch: 5\tFidelity = 0.500560\tKL_Divergence = 3.926644\n",
      "Epoch: 6\tFidelity = 0.500561\tKL_Divergence = 3.925247\n",
      "Epoch: 7\tFidelity = 0.500552\tKL_Divergence = 3.934663\n",
      "Epoch: 8\tFidelity = 0.500557\tKL_Divergence = 3.929208\n",
      "Epoch: 9\tFidelity = 0.500574\tKL_Divergence = 3.912985\n",
      "Epoch: 10\tFidelity = 0.500534\tKL_Divergence = 3.952920\n",
      "Epoch: 11\tFidelity = 0.500565\tKL_Divergence = 3.921654\n",
      "Epoch: 12\tFidelity = 0.500619\tKL_Divergence = 3.870786\n",
      "Epoch: 13\tFidelity = 0.500570\tKL_Divergence = 3.915993\n",
      "Epoch: 14\tFidelity = 0.500577\tKL_Divergence = 3.909694\n",
      "Epoch: 15\tFidelity = 0.500565\tKL_Divergence = 3.921428\n",
      "Epoch: 16\tFidelity = 0.500597\tKL_Divergence = 3.890889\n",
      "Epoch: 17\tFidelity = 0.500582\tKL_Divergence = 3.904550\n",
      "Epoch: 18\tFidelity = 0.500576\tKL_Divergence = 3.910543\n",
      "Epoch: 19\tFidelity = 0.500543\tKL_Divergence = 3.943645\n",
      "Epoch: 20\tFidelity = 0.500544\tKL_Divergence = 3.942714\n",
      "Epoch: 21\tFidelity = 0.500566\tKL_Divergence = 3.919947\n",
      "Epoch: 22\tFidelity = 0.500582\tKL_Divergence = 3.904836\n",
      "Epoch: 23\tFidelity = 0.500556\tKL_Divergence = 3.929951\n",
      "Epoch: 24\tFidelity = 0.500564\tKL_Divergence = 3.922358\n",
      "Epoch: 25\tFidelity = 0.500581\tKL_Divergence = 3.906250\n",
      "Epoch: 26\tFidelity = 0.500594\tKL_Divergence = 3.893337\n",
      "Epoch: 27\tFidelity = 0.500612\tKL_Divergence = 3.876805\n",
      "Epoch: 28\tFidelity = 0.500582\tKL_Divergence = 3.905205\n",
      "Epoch: 29\tFidelity = 0.500590\tKL_Divergence = 3.897531\n",
      "Epoch: 30\tFidelity = 0.500570\tKL_Divergence = 3.916697\n",
      "Epoch: 31\tFidelity = 0.500583\tKL_Divergence = 3.903695\n",
      "Epoch: 32\tFidelity = 0.500602\tKL_Divergence = 3.885774\n",
      "Epoch: 33\tFidelity = 0.500603\tKL_Divergence = 3.885383\n",
      "Epoch: 34\tFidelity = 0.500570\tKL_Divergence = 3.916828\n",
      "Epoch: 35\tFidelity = 0.500579\tKL_Divergence = 3.907737\n",
      "Epoch: 36\tFidelity = 0.500598\tKL_Divergence = 3.890194\n",
      "Epoch: 37\tFidelity = 0.500588\tKL_Divergence = 3.898971\n",
      "Epoch: 38\tFidelity = 0.500546\tKL_Divergence = 3.940777\n",
      "Epoch: 39\tFidelity = 0.500560\tKL_Divergence = 3.926408\n",
      "Epoch: 40\tFidelity = 0.500582\tKL_Divergence = 3.904882\n",
      "Epoch: 41\tFidelity = 0.500586\tKL_Divergence = 3.901330\n",
      "Epoch: 42\tFidelity = 0.500559\tKL_Divergence = 3.926934\n",
      "Epoch: 43\tFidelity = 0.500577\tKL_Divergence = 3.909256\n",
      "Epoch: 44\tFidelity = 0.500585\tKL_Divergence = 3.902196\n",
      "Epoch: 45\tFidelity = 0.500598\tKL_Divergence = 3.889677\n",
      "Epoch: 46\tFidelity = 0.500562\tKL_Divergence = 3.923978\n",
      "Epoch: 47\tFidelity = 0.500556\tKL_Divergence = 3.930732\n",
      "Epoch: 48\tFidelity = 0.500599\tKL_Divergence = 3.889094\n",
      "Epoch: 49\tFidelity = 0.500539\tKL_Divergence = 3.947907\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 12:03:18,157] Trial 646 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500583\tKL_Divergence = 3.903863\n",
      "Total time elapsed during training: 37.638 s\n",
      "Trial 646 pruned. \n",
      "Epoch: 1\tFidelity = 0.500582\tKL_Divergence = 3.904512\n",
      "Epoch: 2\tFidelity = 0.500598\tKL_Divergence = 3.889972\n",
      "Epoch: 3\tFidelity = 0.500590\tKL_Divergence = 3.897121\n",
      "Epoch: 4\tFidelity = 0.500539\tKL_Divergence = 3.947582\n",
      "Epoch: 5\tFidelity = 0.500577\tKL_Divergence = 3.909715\n",
      "Epoch: 6\tFidelity = 0.500676\tKL_Divergence = 3.821522\n",
      "Epoch: 7\tFidelity = 0.500573\tKL_Divergence = 3.913586\n",
      "Epoch: 8\tFidelity = 0.500588\tKL_Divergence = 3.898878\n",
      "Epoch: 9\tFidelity = 0.500607\tKL_Divergence = 3.881826\n",
      "Epoch: 10\tFidelity = 0.500575\tKL_Divergence = 3.911209\n",
      "Epoch: 11\tFidelity = 0.500525\tKL_Divergence = 3.961814\n",
      "Epoch: 12\tFidelity = 0.500541\tKL_Divergence = 3.945818\n",
      "Epoch: 13\tFidelity = 0.500543\tKL_Divergence = 3.943772\n",
      "Epoch: 14\tFidelity = 0.500508\tKL_Divergence = 3.980450\n",
      "Epoch: 15\tFidelity = 0.500580\tKL_Divergence = 3.906947\n",
      "Epoch: 16\tFidelity = 0.500540\tKL_Divergence = 3.946919\n",
      "Epoch: 17\tFidelity = 0.500523\tKL_Divergence = 3.964232\n",
      "Epoch: 18\tFidelity = 0.500546\tKL_Divergence = 3.940776\n",
      "Epoch: 19\tFidelity = 0.500513\tKL_Divergence = 3.975376\n",
      "Epoch: 20\tFidelity = 0.500523\tKL_Divergence = 3.964495\n",
      "Epoch: 21\tFidelity = 0.500514\tKL_Divergence = 3.974392\n",
      "Epoch: 22\tFidelity = 0.500503\tKL_Divergence = 3.985878\n",
      "Epoch: 23\tFidelity = 0.500502\tKL_Divergence = 3.987273\n",
      "Epoch: 24\tFidelity = 0.500505\tKL_Divergence = 3.984070\n",
      "Epoch: 25\tFidelity = 0.500519\tKL_Divergence = 3.968810\n",
      "Epoch: 26\tFidelity = 0.500552\tKL_Divergence = 3.934475\n",
      "Epoch: 27\tFidelity = 0.500529\tKL_Divergence = 3.958511\n",
      "Epoch: 28\tFidelity = 0.500586\tKL_Divergence = 3.901341\n",
      "Epoch: 29\tFidelity = 0.500531\tKL_Divergence = 3.955475\n",
      "Epoch: 30\tFidelity = 0.500532\tKL_Divergence = 3.954582\n",
      "Epoch: 31\tFidelity = 0.500554\tKL_Divergence = 3.932736\n",
      "Epoch: 32\tFidelity = 0.500489\tKL_Divergence = 4.001790\n",
      "Epoch: 33\tFidelity = 0.500512\tKL_Divergence = 3.976020\n",
      "Epoch: 34\tFidelity = 0.500591\tKL_Divergence = 3.896553\n",
      "Epoch: 35\tFidelity = 0.500493\tKL_Divergence = 3.996712\n",
      "Epoch: 36\tFidelity = 0.500670\tKL_Divergence = 3.826623\n",
      "Epoch: 37\tFidelity = 0.500574\tKL_Divergence = 3.912987\n",
      "Epoch: 38\tFidelity = 0.500608\tKL_Divergence = 3.881040\n",
      "Epoch: 39\tFidelity = 0.500547\tKL_Divergence = 3.939585\n",
      "Epoch: 40\tFidelity = 0.500621\tKL_Divergence = 3.868696\n",
      "Epoch: 41\tFidelity = 0.500541\tKL_Divergence = 3.945880\n",
      "Epoch: 42\tFidelity = 0.500618\tKL_Divergence = 3.871351\n",
      "Epoch: 43\tFidelity = 0.500576\tKL_Divergence = 3.910358\n",
      "Epoch: 44\tFidelity = 0.500541\tKL_Divergence = 3.945253\n",
      "Epoch: 45\tFidelity = 0.500603\tKL_Divergence = 3.885652\n",
      "Epoch: 46\tFidelity = 0.500566\tKL_Divergence = 3.920030\n",
      "Epoch: 47\tFidelity = 0.500568\tKL_Divergence = 3.918673\n",
      "Epoch: 48\tFidelity = 0.500604\tKL_Divergence = 3.884393\n",
      "Epoch: 49\tFidelity = 0.500599\tKL_Divergence = 3.889102\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 12:04:36,869] Trial 647 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500603\tKL_Divergence = 3.884826\n",
      "Total time elapsed during training: 78.515 s\n",
      "Trial 647 pruned. \n",
      "Epoch: 1\tFidelity = 0.500506\tKL_Divergence = 3.982127\n",
      "Epoch: 2\tFidelity = 0.500561\tKL_Divergence = 3.925036\n",
      "Epoch: 3\tFidelity = 0.500668\tKL_Divergence = 3.828608\n",
      "Epoch: 4\tFidelity = 0.500445\tKL_Divergence = 4.054308\n",
      "Epoch: 5\tFidelity = 0.500529\tKL_Divergence = 3.957928\n",
      "Epoch: 6\tFidelity = 0.500617\tKL_Divergence = 3.872946\n",
      "Epoch: 7\tFidelity = 0.500666\tKL_Divergence = 3.830079\n",
      "Epoch: 8\tFidelity = 0.500746\tKL_Divergence = 3.767363\n",
      "Epoch: 9\tFidelity = 0.500551\tKL_Divergence = 3.935049\n",
      "Epoch: 10\tFidelity = 0.500449\tKL_Divergence = 4.048976\n",
      "Epoch: 11\tFidelity = 0.500635\tKL_Divergence = 3.856120\n",
      "Epoch: 12\tFidelity = 0.500469\tKL_Divergence = 4.024998\n",
      "Epoch: 13\tFidelity = 0.500504\tKL_Divergence = 3.984225\n",
      "Epoch: 14\tFidelity = 0.500660\tKL_Divergence = 3.834907\n",
      "Epoch: 15\tFidelity = 0.500566\tKL_Divergence = 3.920772\n",
      "Epoch: 16\tFidelity = 0.500557\tKL_Divergence = 3.929459\n",
      "Epoch: 17\tFidelity = 0.500656\tKL_Divergence = 3.838758\n",
      "Epoch: 18\tFidelity = 0.500590\tKL_Divergence = 3.897435\n",
      "Epoch: 19\tFidelity = 0.500566\tKL_Divergence = 3.920274\n",
      "Epoch: 20\tFidelity = 0.500535\tKL_Divergence = 3.951311\n",
      "Epoch: 21\tFidelity = 0.500599\tKL_Divergence = 3.889073\n",
      "Epoch: 22\tFidelity = 0.500564\tKL_Divergence = 3.922203\n",
      "Epoch: 23\tFidelity = 0.500592\tKL_Divergence = 3.895622\n",
      "Epoch: 24\tFidelity = 0.500557\tKL_Divergence = 3.929055\n",
      "Epoch: 25\tFidelity = 0.500519\tKL_Divergence = 3.968799\n",
      "Epoch: 26\tFidelity = 0.500684\tKL_Divergence = 3.814923\n",
      "Epoch: 27\tFidelity = 0.500536\tKL_Divergence = 3.950418\n",
      "Epoch: 28\tFidelity = 0.500560\tKL_Divergence = 3.925670\n",
      "Epoch: 29\tFidelity = 0.500499\tKL_Divergence = 3.990533\n",
      "Epoch: 30\tFidelity = 0.500501\tKL_Divergence = 3.988406\n",
      "Epoch: 31\tFidelity = 0.500631\tKL_Divergence = 3.859902\n",
      "Epoch: 32\tFidelity = 0.500565\tKL_Divergence = 3.921730\n",
      "Epoch: 33\tFidelity = 0.500600\tKL_Divergence = 3.887936\n",
      "Epoch: 34\tFidelity = 0.500564\tKL_Divergence = 3.921912\n",
      "Epoch: 35\tFidelity = 0.500479\tKL_Divergence = 4.012934\n",
      "Epoch: 36\tFidelity = 0.500624\tKL_Divergence = 3.865840\n",
      "Epoch: 37\tFidelity = 0.500569\tKL_Divergence = 3.917630\n",
      "Epoch: 38\tFidelity = 0.500693\tKL_Divergence = 3.808269\n",
      "Epoch: 39\tFidelity = 0.500666\tKL_Divergence = 3.829907\n",
      "Epoch: 40\tFidelity = 0.500592\tKL_Divergence = 3.895137\n",
      "Epoch: 41\tFidelity = 0.500609\tKL_Divergence = 3.880057\n",
      "Epoch: 42\tFidelity = 0.500594\tKL_Divergence = 3.893151\n",
      "Epoch: 43\tFidelity = 0.500538\tKL_Divergence = 3.947882\n",
      "Epoch: 44\tFidelity = 0.500622\tKL_Divergence = 3.868274\n",
      "Epoch: 45\tFidelity = 0.500592\tKL_Divergence = 3.895488\n",
      "Epoch: 46\tFidelity = 0.500661\tKL_Divergence = 3.834290\n",
      "Epoch: 47\tFidelity = 0.500782\tKL_Divergence = 3.740557\n",
      "Epoch: 48\tFidelity = 0.500679\tKL_Divergence = 3.819349\n",
      "Epoch: 49\tFidelity = 0.500587\tKL_Divergence = 3.899670\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 12:05:21,001] Trial 648 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500574\tKL_Divergence = 3.912051\n",
      "Total time elapsed during training: 43.950 s\n",
      "Trial 648 pruned. \n",
      "Epoch: 1\tFidelity = 0.500617\tKL_Divergence = 3.872738\n",
      "Epoch: 2\tFidelity = 0.500637\tKL_Divergence = 3.854862\n",
      "Epoch: 3\tFidelity = 0.500558\tKL_Divergence = 3.927878\n",
      "Epoch: 4\tFidelity = 0.500594\tKL_Divergence = 3.893301\n",
      "Epoch: 5\tFidelity = 0.500599\tKL_Divergence = 3.889019\n",
      "Epoch: 6\tFidelity = 0.500550\tKL_Divergence = 3.935819\n",
      "Epoch: 7\tFidelity = 0.500729\tKL_Divergence = 3.780093\n",
      "Epoch: 8\tFidelity = 0.500563\tKL_Divergence = 3.922754\n",
      "Epoch: 9\tFidelity = 0.500600\tKL_Divergence = 3.887909\n",
      "Epoch: 10\tFidelity = 0.500559\tKL_Divergence = 3.927436\n",
      "Epoch: 11\tFidelity = 0.500573\tKL_Divergence = 3.913597\n",
      "Epoch: 12\tFidelity = 0.500685\tKL_Divergence = 3.814418\n",
      "Epoch: 13\tFidelity = 0.500623\tKL_Divergence = 3.866683\n",
      "Epoch: 14\tFidelity = 0.500612\tKL_Divergence = 3.877027\n",
      "Epoch: 15\tFidelity = 0.500608\tKL_Divergence = 3.880004\n",
      "Epoch: 16\tFidelity = 0.500635\tKL_Divergence = 3.856173\n",
      "Epoch: 17\tFidelity = 0.500527\tKL_Divergence = 3.959061\n",
      "Epoch: 18\tFidelity = 0.500695\tKL_Divergence = 3.805085\n",
      "Epoch: 19\tFidelity = 0.500648\tKL_Divergence = 3.843792\n",
      "Epoch: 20\tFidelity = 0.500753\tKL_Divergence = 3.759553\n",
      "Epoch: 21\tFidelity = 0.500577\tKL_Divergence = 3.907816\n",
      "Epoch: 22\tFidelity = 0.500628\tKL_Divergence = 3.861097\n",
      "Epoch: 23\tFidelity = 0.500615\tKL_Divergence = 3.873372\n",
      "Epoch: 24\tFidelity = 0.500576\tKL_Divergence = 3.908738\n",
      "Epoch: 25\tFidelity = 0.500643\tKL_Divergence = 3.848886\n",
      "Epoch: 26\tFidelity = 0.500768\tKL_Divergence = 3.749894\n",
      "Epoch: 27\tFidelity = 0.500691\tKL_Divergence = 3.809344\n",
      "Epoch: 28\tFidelity = 0.500577\tKL_Divergence = 3.909504\n",
      "Epoch: 29\tFidelity = 0.500682\tKL_Divergence = 3.816401\n",
      "Epoch: 30\tFidelity = 0.500687\tKL_Divergence = 3.812318\n",
      "Epoch: 31\tFidelity = 0.500734\tKL_Divergence = 3.775691\n",
      "Epoch: 32\tFidelity = 0.500747\tKL_Divergence = 3.766197\n",
      "Epoch: 33\tFidelity = 0.500596\tKL_Divergence = 3.891478\n",
      "Epoch: 34\tFidelity = 0.500539\tKL_Divergence = 3.946455\n",
      "Epoch: 35\tFidelity = 0.500655\tKL_Divergence = 3.838178\n",
      "Epoch: 36\tFidelity = 0.500639\tKL_Divergence = 3.851370\n",
      "Epoch: 37\tFidelity = 0.500685\tKL_Divergence = 3.813872\n",
      "Epoch: 38\tFidelity = 0.500722\tKL_Divergence = 3.784563\n",
      "Epoch: 39\tFidelity = 0.500568\tKL_Divergence = 3.917629\n",
      "Epoch: 40\tFidelity = 0.500619\tKL_Divergence = 3.870090\n",
      "Epoch: 41\tFidelity = 0.500680\tKL_Divergence = 3.817983\n",
      "Epoch: 42\tFidelity = 0.500544\tKL_Divergence = 3.942315\n",
      "Epoch: 43\tFidelity = 0.500691\tKL_Divergence = 3.808961\n",
      "Epoch: 44\tFidelity = 0.500621\tKL_Divergence = 3.868459\n",
      "Epoch: 45\tFidelity = 0.500674\tKL_Divergence = 3.822705\n",
      "Epoch: 46\tFidelity = 0.500658\tKL_Divergence = 3.836457\n",
      "Epoch: 47\tFidelity = 0.500635\tKL_Divergence = 3.856038\n",
      "Epoch: 48\tFidelity = 0.500739\tKL_Divergence = 3.772318\n",
      "Epoch: 49\tFidelity = 0.500644\tKL_Divergence = 3.848628\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 12:05:58,619] Trial 649 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500635\tKL_Divergence = 3.856165\n",
      "Total time elapsed during training: 37.439 s\n",
      "Trial 649 pruned. \n",
      "Epoch: 1\tFidelity = 0.500665\tKL_Divergence = 3.830901\n",
      "Epoch: 2\tFidelity = 0.500710\tKL_Divergence = 3.794052\n",
      "Epoch: 3\tFidelity = 0.500640\tKL_Divergence = 3.851425\n",
      "Epoch: 4\tFidelity = 0.500659\tKL_Divergence = 3.835886\n",
      "Epoch: 5\tFidelity = 0.500638\tKL_Divergence = 3.853410\n",
      "Epoch: 6\tFidelity = 0.500681\tKL_Divergence = 3.817106\n",
      "Epoch: 7\tFidelity = 0.500664\tKL_Divergence = 3.831339\n",
      "Epoch: 8\tFidelity = 0.500608\tKL_Divergence = 3.880496\n",
      "Epoch: 9\tFidelity = 0.500620\tKL_Divergence = 3.869172\n",
      "Epoch: 10\tFidelity = 0.500659\tKL_Divergence = 3.835526\n",
      "Epoch: 11\tFidelity = 0.500618\tKL_Divergence = 3.871649\n",
      "Epoch: 12\tFidelity = 0.500620\tKL_Divergence = 3.869266\n",
      "Epoch: 13\tFidelity = 0.500634\tKL_Divergence = 3.857217\n",
      "Epoch: 14\tFidelity = 0.500606\tKL_Divergence = 3.881943\n",
      "Epoch: 15\tFidelity = 0.500618\tKL_Divergence = 3.871481\n",
      "Epoch: 16\tFidelity = 0.500654\tKL_Divergence = 3.840104\n",
      "Epoch: 17\tFidelity = 0.500589\tKL_Divergence = 3.897976\n",
      "Epoch: 18\tFidelity = 0.500613\tKL_Divergence = 3.876149\n",
      "Epoch: 19\tFidelity = 0.500636\tKL_Divergence = 3.855086\n",
      "Epoch: 20\tFidelity = 0.500675\tKL_Divergence = 3.822110\n",
      "Epoch: 21\tFidelity = 0.500635\tKL_Divergence = 3.856003\n",
      "Epoch: 22\tFidelity = 0.500626\tKL_Divergence = 3.863805\n",
      "Epoch: 23\tFidelity = 0.500626\tKL_Divergence = 3.864029\n",
      "Epoch: 24\tFidelity = 0.500636\tKL_Divergence = 3.855799\n",
      "Epoch: 25\tFidelity = 0.500631\tKL_Divergence = 3.859375\n",
      "Epoch: 26\tFidelity = 0.500625\tKL_Divergence = 3.864873\n",
      "Epoch: 27\tFidelity = 0.500657\tKL_Divergence = 3.837810\n",
      "Epoch: 28\tFidelity = 0.500633\tKL_Divergence = 3.858222\n",
      "Epoch: 29\tFidelity = 0.500638\tKL_Divergence = 3.853326\n",
      "Epoch: 30\tFidelity = 0.500575\tKL_Divergence = 3.911417\n",
      "Epoch: 31\tFidelity = 0.500614\tKL_Divergence = 3.875198\n",
      "Epoch: 32\tFidelity = 0.500640\tKL_Divergence = 3.852032\n",
      "Epoch: 33\tFidelity = 0.500623\tKL_Divergence = 3.867338\n",
      "Epoch: 34\tFidelity = 0.500614\tKL_Divergence = 3.875328\n",
      "Epoch: 35\tFidelity = 0.500656\tKL_Divergence = 3.838254\n",
      "Epoch: 36\tFidelity = 0.500620\tKL_Divergence = 3.869610\n",
      "Epoch: 37\tFidelity = 0.500609\tKL_Divergence = 3.879722\n",
      "Epoch: 38\tFidelity = 0.500639\tKL_Divergence = 3.852754\n",
      "Epoch: 39\tFidelity = 0.500627\tKL_Divergence = 3.863535\n",
      "Epoch: 40\tFidelity = 0.500596\tKL_Divergence = 3.891541\n",
      "Epoch: 41\tFidelity = 0.500602\tKL_Divergence = 3.885867\n",
      "Epoch: 42\tFidelity = 0.500586\tKL_Divergence = 3.901352\n",
      "Epoch: 43\tFidelity = 0.500591\tKL_Divergence = 3.896654\n",
      "Epoch: 44\tFidelity = 0.500600\tKL_Divergence = 3.887961\n",
      "Epoch: 45\tFidelity = 0.500586\tKL_Divergence = 3.900869\n",
      "Epoch: 46\tFidelity = 0.500590\tKL_Divergence = 3.896762\n",
      "Epoch: 47\tFidelity = 0.500620\tKL_Divergence = 3.869224\n",
      "Epoch: 48\tFidelity = 0.500613\tKL_Divergence = 3.875815\n",
      "Epoch: 49\tFidelity = 0.500644\tKL_Divergence = 3.848572\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 12:06:30,274] Trial 650 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500587\tKL_Divergence = 3.899688\n",
      "Total time elapsed during training: 31.466 s\n",
      "Trial 650 pruned. \n",
      "Epoch: 1\tFidelity = 0.500621\tKL_Divergence = 3.868336\n",
      "Epoch: 2\tFidelity = 0.500660\tKL_Divergence = 3.834624\n",
      "Epoch: 3\tFidelity = 0.500610\tKL_Divergence = 3.879081\n",
      "Epoch: 4\tFidelity = 0.500622\tKL_Divergence = 3.868094\n",
      "Epoch: 5\tFidelity = 0.500599\tKL_Divergence = 3.889112\n",
      "Epoch: 6\tFidelity = 0.500614\tKL_Divergence = 3.874619\n",
      "Epoch: 7\tFidelity = 0.500619\tKL_Divergence = 3.870266\n",
      "Epoch: 8\tFidelity = 0.500585\tKL_Divergence = 3.901918\n",
      "Epoch: 9\tFidelity = 0.500650\tKL_Divergence = 3.843338\n",
      "Epoch: 10\tFidelity = 0.500628\tKL_Divergence = 3.862617\n",
      "Epoch: 11\tFidelity = 0.500680\tKL_Divergence = 3.818489\n",
      "Epoch: 12\tFidelity = 0.500620\tKL_Divergence = 3.869621\n",
      "Epoch: 13\tFidelity = 0.500629\tKL_Divergence = 3.861707\n",
      "Epoch: 14\tFidelity = 0.500679\tKL_Divergence = 3.818973\n",
      "Epoch: 15\tFidelity = 0.500595\tKL_Divergence = 3.892572\n",
      "Epoch: 16\tFidelity = 0.500654\tKL_Divergence = 3.839977\n",
      "Epoch: 17\tFidelity = 0.500626\tKL_Divergence = 3.863988\n",
      "Epoch: 18\tFidelity = 0.500687\tKL_Divergence = 3.813046\n",
      "Epoch: 19\tFidelity = 0.500598\tKL_Divergence = 3.889752\n",
      "Epoch: 20\tFidelity = 0.500644\tKL_Divergence = 3.848534\n",
      "Epoch: 21\tFidelity = 0.500549\tKL_Divergence = 3.937376\n",
      "Epoch: 22\tFidelity = 0.500647\tKL_Divergence = 3.846175\n",
      "Epoch: 23\tFidelity = 0.500648\tKL_Divergence = 3.845225\n",
      "Epoch: 24\tFidelity = 0.500609\tKL_Divergence = 3.879693\n",
      "Epoch: 25\tFidelity = 0.500662\tKL_Divergence = 3.833353\n",
      "Epoch: 26\tFidelity = 0.500622\tKL_Divergence = 3.867623\n",
      "Epoch: 27\tFidelity = 0.500641\tKL_Divergence = 3.851252\n",
      "Epoch: 28\tFidelity = 0.500650\tKL_Divergence = 3.843298\n",
      "Epoch: 29\tFidelity = 0.500600\tKL_Divergence = 3.887441\n",
      "Epoch: 30\tFidelity = 0.500641\tKL_Divergence = 3.850899\n",
      "Epoch: 31\tFidelity = 0.500607\tKL_Divergence = 3.881809\n",
      "Epoch: 32\tFidelity = 0.500686\tKL_Divergence = 3.813880\n",
      "Epoch: 33\tFidelity = 0.500581\tKL_Divergence = 3.905377\n",
      "Epoch: 34\tFidelity = 0.500635\tKL_Divergence = 3.856412\n",
      "Epoch: 35\tFidelity = 0.500683\tKL_Divergence = 3.816337\n",
      "Epoch: 36\tFidelity = 0.500607\tKL_Divergence = 3.881817\n",
      "Epoch: 37\tFidelity = 0.500600\tKL_Divergence = 3.888131\n",
      "Epoch: 38\tFidelity = 0.500635\tKL_Divergence = 3.856037\n",
      "Epoch: 39\tFidelity = 0.500615\tKL_Divergence = 3.874047\n",
      "Epoch: 40\tFidelity = 0.500648\tKL_Divergence = 3.844875\n",
      "Epoch: 41\tFidelity = 0.500623\tKL_Divergence = 3.866796\n",
      "Epoch: 42\tFidelity = 0.500666\tKL_Divergence = 3.829881\n",
      "Epoch: 43\tFidelity = 0.500562\tKL_Divergence = 3.924415\n",
      "Epoch: 44\tFidelity = 0.500629\tKL_Divergence = 3.861577\n",
      "Epoch: 45\tFidelity = 0.500645\tKL_Divergence = 3.847526\n",
      "Epoch: 46\tFidelity = 0.500596\tKL_Divergence = 3.892037\n",
      "Epoch: 47\tFidelity = 0.500635\tKL_Divergence = 3.856559\n",
      "Epoch: 48\tFidelity = 0.500594\tKL_Divergence = 3.893805\n",
      "Epoch: 49\tFidelity = 0.500639\tKL_Divergence = 3.853280\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 12:07:01,571] Trial 651 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500652\tKL_Divergence = 3.841972\n",
      "Total time elapsed during training: 31.115 s\n",
      "Trial 651 pruned. \n",
      "Epoch: 1\tFidelity = 0.500683\tKL_Divergence = 3.815906\n",
      "Epoch: 2\tFidelity = 0.500663\tKL_Divergence = 3.832389\n",
      "Epoch: 3\tFidelity = 0.500642\tKL_Divergence = 3.850260\n",
      "Epoch: 4\tFidelity = 0.500657\tKL_Divergence = 3.837262\n",
      "Epoch: 5\tFidelity = 0.500586\tKL_Divergence = 3.901052\n",
      "Epoch: 6\tFidelity = 0.500559\tKL_Divergence = 3.927408\n",
      "Epoch: 7\tFidelity = 0.500670\tKL_Divergence = 3.826682\n",
      "Epoch: 8\tFidelity = 0.500684\tKL_Divergence = 3.814921\n",
      "Epoch: 9\tFidelity = 0.500587\tKL_Divergence = 3.899739\n",
      "Epoch: 10\tFidelity = 0.500692\tKL_Divergence = 3.808959\n",
      "Epoch: 11\tFidelity = 0.500690\tKL_Divergence = 3.810669\n",
      "Epoch: 12\tFidelity = 0.500547\tKL_Divergence = 3.938763\n",
      "Epoch: 13\tFidelity = 0.500671\tKL_Divergence = 3.825842\n",
      "Epoch: 14\tFidelity = 0.500703\tKL_Divergence = 3.799630\n",
      "Epoch: 15\tFidelity = 0.500586\tKL_Divergence = 3.901096\n",
      "Epoch: 16\tFidelity = 0.500642\tKL_Divergence = 3.850257\n",
      "Epoch: 17\tFidelity = 0.500703\tKL_Divergence = 3.800093\n",
      "Epoch: 18\tFidelity = 0.500710\tKL_Divergence = 3.794193\n",
      "Epoch: 19\tFidelity = 0.500570\tKL_Divergence = 3.916219\n",
      "Epoch: 20\tFidelity = 0.500623\tKL_Divergence = 3.867095\n",
      "Epoch: 21\tFidelity = 0.500666\tKL_Divergence = 3.829767\n",
      "Epoch: 22\tFidelity = 0.500627\tKL_Divergence = 3.863511\n",
      "Epoch: 23\tFidelity = 0.500625\tKL_Divergence = 3.864681\n",
      "Epoch: 24\tFidelity = 0.500679\tKL_Divergence = 3.819176\n",
      "Epoch: 25\tFidelity = 0.500684\tKL_Divergence = 3.815045\n",
      "Epoch: 26\tFidelity = 0.500580\tKL_Divergence = 3.906763\n",
      "Epoch: 27\tFidelity = 0.500663\tKL_Divergence = 3.832683\n",
      "Epoch: 28\tFidelity = 0.500713\tKL_Divergence = 3.792029\n",
      "Epoch: 29\tFidelity = 0.500552\tKL_Divergence = 3.933715\n",
      "Epoch: 30\tFidelity = 0.500568\tKL_Divergence = 3.918482\n",
      "Epoch: 31\tFidelity = 0.500640\tKL_Divergence = 3.851636\n",
      "Epoch: 32\tFidelity = 0.500661\tKL_Divergence = 3.834320\n",
      "Epoch: 33\tFidelity = 0.500662\tKL_Divergence = 3.833626\n",
      "Epoch: 34\tFidelity = 0.500553\tKL_Divergence = 3.933608\n",
      "Epoch: 35\tFidelity = 0.500483\tKL_Divergence = 4.007745\n",
      "Epoch: 36\tFidelity = 0.500673\tKL_Divergence = 3.824039\n",
      "Epoch: 37\tFidelity = 0.500571\tKL_Divergence = 3.915223\n",
      "Epoch: 38\tFidelity = 0.500542\tKL_Divergence = 3.943894\n",
      "Epoch: 39\tFidelity = 0.500561\tKL_Divergence = 3.924950\n",
      "Epoch: 40\tFidelity = 0.500651\tKL_Divergence = 3.842437\n",
      "Epoch: 41\tFidelity = 0.500612\tKL_Divergence = 3.876407\n",
      "Epoch: 42\tFidelity = 0.500598\tKL_Divergence = 3.889558\n",
      "Epoch: 43\tFidelity = 0.500685\tKL_Divergence = 3.813797\n",
      "Epoch: 44\tFidelity = 0.500610\tKL_Divergence = 3.877868\n",
      "Epoch: 45\tFidelity = 0.500581\tKL_Divergence = 3.905517\n",
      "Epoch: 46\tFidelity = 0.500572\tKL_Divergence = 3.913393\n",
      "Epoch: 47\tFidelity = 0.500617\tKL_Divergence = 3.872237\n",
      "Epoch: 48\tFidelity = 0.500630\tKL_Divergence = 3.860165\n",
      "Epoch: 49\tFidelity = 0.500669\tKL_Divergence = 3.827117\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 12:07:46,589] Trial 652 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500524\tKL_Divergence = 3.962662\n",
      "Total time elapsed during training: 44.826 s\n",
      "Trial 652 pruned. \n",
      "Epoch: 1\tFidelity = 0.500538\tKL_Divergence = 3.947824\n",
      "Epoch: 2\tFidelity = 0.500589\tKL_Divergence = 3.897841\n",
      "Epoch: 3\tFidelity = 0.500568\tKL_Divergence = 3.918340\n",
      "Epoch: 4\tFidelity = 0.500623\tKL_Divergence = 3.866511\n",
      "Epoch: 5\tFidelity = 0.500642\tKL_Divergence = 3.850434\n",
      "Epoch: 6\tFidelity = 0.500580\tKL_Divergence = 3.906211\n",
      "Epoch: 7\tFidelity = 0.500572\tKL_Divergence = 3.914054\n",
      "Epoch: 8\tFidelity = 0.500547\tKL_Divergence = 3.938905\n",
      "Epoch: 9\tFidelity = 0.500586\tKL_Divergence = 3.901341\n",
      "Epoch: 10\tFidelity = 0.500652\tKL_Divergence = 3.841789\n",
      "Epoch: 11\tFidelity = 0.500620\tKL_Divergence = 3.869278\n",
      "Epoch: 12\tFidelity = 0.500556\tKL_Divergence = 3.930310\n",
      "Epoch: 13\tFidelity = 0.500555\tKL_Divergence = 3.930933\n",
      "Epoch: 14\tFidelity = 0.500570\tKL_Divergence = 3.916079\n",
      "Epoch: 15\tFidelity = 0.500637\tKL_Divergence = 3.854851\n",
      "Epoch: 16\tFidelity = 0.500655\tKL_Divergence = 3.838917\n",
      "Epoch: 17\tFidelity = 0.500622\tKL_Divergence = 3.867909\n",
      "Epoch: 18\tFidelity = 0.500607\tKL_Divergence = 3.881399\n",
      "Epoch: 19\tFidelity = 0.500657\tKL_Divergence = 3.837372\n",
      "Epoch: 20\tFidelity = 0.500623\tKL_Divergence = 3.867283\n",
      "Epoch: 21\tFidelity = 0.500588\tKL_Divergence = 3.899060\n",
      "Epoch: 22\tFidelity = 0.500558\tKL_Divergence = 3.928279\n",
      "Epoch: 23\tFidelity = 0.500561\tKL_Divergence = 3.924983\n",
      "Epoch: 24\tFidelity = 0.500600\tKL_Divergence = 3.887882\n",
      "Epoch: 25\tFidelity = 0.500538\tKL_Divergence = 3.948145\n",
      "Epoch: 26\tFidelity = 0.500586\tKL_Divergence = 3.901118\n",
      "Epoch: 27\tFidelity = 0.500632\tKL_Divergence = 3.859465\n",
      "Epoch: 28\tFidelity = 0.500577\tKL_Divergence = 3.909989\n",
      "Epoch: 29\tFidelity = 0.500583\tKL_Divergence = 3.903548\n",
      "Epoch: 30\tFidelity = 0.500654\tKL_Divergence = 3.840420\n",
      "Epoch: 31\tFidelity = 0.500690\tKL_Divergence = 3.810589\n",
      "Epoch: 32\tFidelity = 0.500612\tKL_Divergence = 3.876599\n",
      "Epoch: 33\tFidelity = 0.500589\tKL_Divergence = 3.898260\n",
      "Epoch: 34\tFidelity = 0.500591\tKL_Divergence = 3.896420\n",
      "Epoch: 35\tFidelity = 0.500533\tKL_Divergence = 3.953631\n",
      "Epoch: 36\tFidelity = 0.500557\tKL_Divergence = 3.929126\n",
      "Epoch: 37\tFidelity = 0.500596\tKL_Divergence = 3.891744\n",
      "Epoch: 38\tFidelity = 0.500633\tKL_Divergence = 3.858090\n",
      "Epoch: 39\tFidelity = 0.500614\tKL_Divergence = 3.875176\n",
      "Epoch: 40\tFidelity = 0.500549\tKL_Divergence = 3.937277\n",
      "Epoch: 41\tFidelity = 0.500589\tKL_Divergence = 3.898513\n",
      "Epoch: 42\tFidelity = 0.500578\tKL_Divergence = 3.908580\n",
      "Epoch: 43\tFidelity = 0.500611\tKL_Divergence = 3.877921\n",
      "Epoch: 44\tFidelity = 0.500544\tKL_Divergence = 3.941997\n",
      "Epoch: 45\tFidelity = 0.500582\tKL_Divergence = 3.904913\n",
      "Epoch: 46\tFidelity = 0.500633\tKL_Divergence = 3.857882\n",
      "Epoch: 47\tFidelity = 0.500594\tKL_Divergence = 3.893393\n",
      "Epoch: 48\tFidelity = 0.500657\tKL_Divergence = 3.837908\n",
      "Epoch: 49\tFidelity = 0.500579\tKL_Divergence = 3.907376\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 12:08:25,707] Trial 653 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500619\tKL_Divergence = 3.871054\n",
      "Total time elapsed during training: 38.923 s\n",
      "Trial 653 pruned. \n",
      "Epoch: 1\tFidelity = 0.500628\tKL_Divergence = 3.862840\n",
      "Epoch: 2\tFidelity = 0.500648\tKL_Divergence = 3.845467\n",
      "Epoch: 3\tFidelity = 0.500644\tKL_Divergence = 3.848743\n",
      "Epoch: 4\tFidelity = 0.500644\tKL_Divergence = 3.848760\n",
      "Epoch: 5\tFidelity = 0.500608\tKL_Divergence = 3.880294\n",
      "Epoch: 6\tFidelity = 0.500634\tKL_Divergence = 3.857465\n",
      "Epoch: 7\tFidelity = 0.500661\tKL_Divergence = 3.834007\n",
      "Epoch: 8\tFidelity = 0.500641\tKL_Divergence = 3.850880\n",
      "Epoch: 9\tFidelity = 0.500606\tKL_Divergence = 3.882795\n",
      "Epoch: 10\tFidelity = 0.500641\tKL_Divergence = 3.850951\n",
      "Epoch: 11\tFidelity = 0.500630\tKL_Divergence = 3.860625\n",
      "Epoch: 12\tFidelity = 0.500596\tKL_Divergence = 3.891163\n",
      "Epoch: 13\tFidelity = 0.500625\tKL_Divergence = 3.865603\n",
      "Epoch: 14\tFidelity = 0.500590\tKL_Divergence = 3.897149\n",
      "Epoch: 15\tFidelity = 0.500618\tKL_Divergence = 3.871535\n",
      "Epoch: 16\tFidelity = 0.500622\tKL_Divergence = 3.867605\n",
      "Epoch: 17\tFidelity = 0.500629\tKL_Divergence = 3.861780\n",
      "Epoch: 18\tFidelity = 0.500645\tKL_Divergence = 3.847711\n",
      "Epoch: 19\tFidelity = 0.500606\tKL_Divergence = 3.882289\n",
      "Epoch: 20\tFidelity = 0.500696\tKL_Divergence = 3.805177\n",
      "Epoch: 21\tFidelity = 0.500630\tKL_Divergence = 3.860541\n",
      "Epoch: 22\tFidelity = 0.500568\tKL_Divergence = 3.918569\n",
      "Epoch: 23\tFidelity = 0.500637\tKL_Divergence = 3.854911\n",
      "Epoch: 24\tFidelity = 0.500624\tKL_Divergence = 3.866397\n",
      "Epoch: 25\tFidelity = 0.500597\tKL_Divergence = 3.890652\n",
      "Epoch: 26\tFidelity = 0.500610\tKL_Divergence = 3.878949\n",
      "Epoch: 27\tFidelity = 0.500580\tKL_Divergence = 3.906522\n",
      "Epoch: 28\tFidelity = 0.500593\tKL_Divergence = 3.894065\n",
      "Epoch: 29\tFidelity = 0.500601\tKL_Divergence = 3.887375\n",
      "Epoch: 30\tFidelity = 0.500649\tKL_Divergence = 3.844683\n",
      "Epoch: 31\tFidelity = 0.500633\tKL_Divergence = 3.858251\n",
      "Epoch: 32\tFidelity = 0.500595\tKL_Divergence = 3.892671\n",
      "Epoch: 33\tFidelity = 0.500642\tKL_Divergence = 3.850648\n",
      "Epoch: 34\tFidelity = 0.500662\tKL_Divergence = 3.833211\n",
      "Epoch: 35\tFidelity = 0.500606\tKL_Divergence = 3.881910\n",
      "Epoch: 36\tFidelity = 0.500662\tKL_Divergence = 3.833105\n",
      "Epoch: 37\tFidelity = 0.500680\tKL_Divergence = 3.818493\n",
      "Epoch: 38\tFidelity = 0.500612\tKL_Divergence = 3.877084\n",
      "Epoch: 39\tFidelity = 0.500633\tKL_Divergence = 3.858388\n",
      "Epoch: 40\tFidelity = 0.500611\tKL_Divergence = 3.877774\n",
      "Epoch: 41\tFidelity = 0.500675\tKL_Divergence = 3.822179\n",
      "Epoch: 42\tFidelity = 0.500659\tKL_Divergence = 3.836214\n",
      "Epoch: 43\tFidelity = 0.500665\tKL_Divergence = 3.830520\n",
      "Epoch: 44\tFidelity = 0.500620\tKL_Divergence = 3.869696\n",
      "Epoch: 45\tFidelity = 0.500657\tKL_Divergence = 3.837558\n",
      "Epoch: 46\tFidelity = 0.500589\tKL_Divergence = 3.897748\n",
      "Epoch: 47\tFidelity = 0.500652\tKL_Divergence = 3.841728\n",
      "Epoch: 48\tFidelity = 0.500653\tKL_Divergence = 3.841148\n",
      "Epoch: 49\tFidelity = 0.500623\tKL_Divergence = 3.867045\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 12:09:05,104] Trial 654 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500636\tKL_Divergence = 3.855772\n",
      "Total time elapsed during training: 39.209 s\n",
      "Trial 654 pruned. \n",
      "Epoch: 1\tFidelity = 0.500705\tKL_Divergence = 3.798703\n",
      "Epoch: 2\tFidelity = 0.500574\tKL_Divergence = 3.912130\n",
      "Epoch: 3\tFidelity = 0.500776\tKL_Divergence = 3.745117\n",
      "Epoch: 4\tFidelity = 0.500651\tKL_Divergence = 3.842886\n",
      "Epoch: 5\tFidelity = 0.500697\tKL_Divergence = 3.804293\n",
      "Epoch: 6\tFidelity = 0.500706\tKL_Divergence = 3.797885\n",
      "Epoch: 7\tFidelity = 0.500598\tKL_Divergence = 3.889355\n",
      "Epoch: 8\tFidelity = 0.500810\tKL_Divergence = 3.721283\n",
      "Epoch: 9\tFidelity = 0.500719\tKL_Divergence = 3.787205\n",
      "Epoch: 10\tFidelity = 0.500802\tKL_Divergence = 3.726683\n",
      "Epoch: 11\tFidelity = 0.500643\tKL_Divergence = 3.849338\n",
      "Epoch: 12\tFidelity = 0.500556\tKL_Divergence = 3.929599\n",
      "Epoch: 13\tFidelity = 0.500651\tKL_Divergence = 3.842211\n",
      "Epoch: 14\tFidelity = 0.500730\tKL_Divergence = 3.778913\n",
      "Epoch: 15\tFidelity = 0.500661\tKL_Divergence = 3.834256\n",
      "Epoch: 16\tFidelity = 0.500622\tKL_Divergence = 3.867449\n",
      "Epoch: 17\tFidelity = 0.500677\tKL_Divergence = 3.820546\n",
      "Epoch: 18\tFidelity = 0.500758\tKL_Divergence = 3.758135\n",
      "Epoch: 19\tFidelity = 0.500546\tKL_Divergence = 3.939713\n",
      "Epoch: 20\tFidelity = 0.500598\tKL_Divergence = 3.889613\n",
      "Epoch: 21\tFidelity = 0.500553\tKL_Divergence = 3.933116\n",
      "Epoch: 22\tFidelity = 0.500608\tKL_Divergence = 3.880354\n",
      "Epoch: 23\tFidelity = 0.500571\tKL_Divergence = 3.915645\n",
      "Epoch: 24\tFidelity = 0.500621\tKL_Divergence = 3.868931\n",
      "Epoch: 25\tFidelity = 0.500671\tKL_Divergence = 3.826175\n",
      "Epoch: 26\tFidelity = 0.500652\tKL_Divergence = 3.841925\n",
      "Epoch: 27\tFidelity = 0.500649\tKL_Divergence = 3.844466\n",
      "Epoch: 28\tFidelity = 0.500627\tKL_Divergence = 3.863405\n",
      "Epoch: 29\tFidelity = 0.500673\tKL_Divergence = 3.823912\n",
      "Epoch: 30\tFidelity = 0.500674\tKL_Divergence = 3.823073\n",
      "Epoch: 31\tFidelity = 0.500617\tKL_Divergence = 3.872507\n",
      "Epoch: 32\tFidelity = 0.500673\tKL_Divergence = 3.823874\n",
      "Epoch: 33\tFidelity = 0.500611\tKL_Divergence = 3.877996\n",
      "Epoch: 34\tFidelity = 0.500636\tKL_Divergence = 3.855151\n",
      "Epoch: 35\tFidelity = 0.500570\tKL_Divergence = 3.916256\n",
      "Epoch: 36\tFidelity = 0.500565\tKL_Divergence = 3.920733\n",
      "Epoch: 37\tFidelity = 0.500633\tKL_Divergence = 3.857876\n",
      "Epoch: 38\tFidelity = 0.500582\tKL_Divergence = 3.904334\n",
      "Epoch: 39\tFidelity = 0.500664\tKL_Divergence = 3.831408\n",
      "Epoch: 40\tFidelity = 0.500643\tKL_Divergence = 3.849281\n",
      "Epoch: 41\tFidelity = 0.500670\tKL_Divergence = 3.826385\n",
      "Epoch: 42\tFidelity = 0.500697\tKL_Divergence = 3.804436\n",
      "Epoch: 43\tFidelity = 0.500570\tKL_Divergence = 3.916705\n",
      "Epoch: 44\tFidelity = 0.500641\tKL_Divergence = 3.851062\n",
      "Epoch: 45\tFidelity = 0.500644\tKL_Divergence = 3.848293\n",
      "Epoch: 46\tFidelity = 0.500506\tKL_Divergence = 3.982355\n",
      "Epoch: 47\tFidelity = 0.500689\tKL_Divergence = 3.811021\n",
      "Epoch: 48\tFidelity = 0.500719\tKL_Divergence = 3.787090\n",
      "Epoch: 49\tFidelity = 0.500584\tKL_Divergence = 3.902488\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 12:10:27,412] Trial 655 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500501\tKL_Divergence = 3.988049\n",
      "Total time elapsed during training: 82.123 s\n",
      "Trial 655 pruned. \n",
      "Epoch: 1\tFidelity = 0.500664\tKL_Divergence = 3.831763\n",
      "Epoch: 2\tFidelity = 0.500680\tKL_Divergence = 3.818715\n",
      "Epoch: 3\tFidelity = 0.500687\tKL_Divergence = 3.812791\n",
      "Epoch: 4\tFidelity = 0.500622\tKL_Divergence = 3.867922\n",
      "Epoch: 5\tFidelity = 0.500728\tKL_Divergence = 3.780626\n",
      "Epoch: 6\tFidelity = 0.500684\tKL_Divergence = 3.814708\n",
      "Epoch: 7\tFidelity = 0.500681\tKL_Divergence = 3.817310\n",
      "Epoch: 8\tFidelity = 0.500754\tKL_Divergence = 3.760921\n",
      "Epoch: 9\tFidelity = 0.500582\tKL_Divergence = 3.904517\n",
      "Epoch: 10\tFidelity = 0.500592\tKL_Divergence = 3.894745\n",
      "Epoch: 11\tFidelity = 0.500702\tKL_Divergence = 3.800659\n",
      "Epoch: 12\tFidelity = 0.500694\tKL_Divergence = 3.806823\n",
      "Epoch: 13\tFidelity = 0.500539\tKL_Divergence = 3.947053\n",
      "Epoch: 14\tFidelity = 0.500656\tKL_Divergence = 3.838476\n",
      "Epoch: 15\tFidelity = 0.500656\tKL_Divergence = 3.837905\n",
      "Epoch: 16\tFidelity = 0.500589\tKL_Divergence = 3.898217\n",
      "Epoch: 17\tFidelity = 0.500639\tKL_Divergence = 3.852907\n",
      "Epoch: 18\tFidelity = 0.500740\tKL_Divergence = 3.771347\n",
      "Epoch: 19\tFidelity = 0.500628\tKL_Divergence = 3.861887\n",
      "Epoch: 20\tFidelity = 0.500528\tKL_Divergence = 3.958281\n",
      "Epoch: 21\tFidelity = 0.500637\tKL_Divergence = 3.854106\n",
      "Epoch: 22\tFidelity = 0.500565\tKL_Divergence = 3.921639\n",
      "Epoch: 23\tFidelity = 0.500570\tKL_Divergence = 3.916160\n",
      "Epoch: 24\tFidelity = 0.500526\tKL_Divergence = 3.960578\n",
      "Epoch: 25\tFidelity = 0.500588\tKL_Divergence = 3.898813\n",
      "Epoch: 26\tFidelity = 0.500663\tKL_Divergence = 3.832549\n",
      "Epoch: 27\tFidelity = 0.500537\tKL_Divergence = 3.949270\n",
      "Epoch: 28\tFidelity = 0.500702\tKL_Divergence = 3.800802\n",
      "Epoch: 29\tFidelity = 0.500623\tKL_Divergence = 3.867042\n",
      "Epoch: 30\tFidelity = 0.500638\tKL_Divergence = 3.853464\n",
      "Epoch: 31\tFidelity = 0.500720\tKL_Divergence = 3.786441\n",
      "Epoch: 32\tFidelity = 0.500723\tKL_Divergence = 3.784076\n",
      "Epoch: 33\tFidelity = 0.500572\tKL_Divergence = 3.914092\n",
      "Epoch: 34\tFidelity = 0.500567\tKL_Divergence = 3.918903\n",
      "Epoch: 35\tFidelity = 0.500639\tKL_Divergence = 3.853178\n",
      "Epoch: 36\tFidelity = 0.500601\tKL_Divergence = 3.886989\n",
      "Epoch: 37\tFidelity = 0.500643\tKL_Divergence = 3.849526\n",
      "Epoch: 38\tFidelity = 0.500615\tKL_Divergence = 3.874381\n",
      "Epoch: 39\tFidelity = 0.500607\tKL_Divergence = 3.881535\n",
      "Epoch: 40\tFidelity = 0.500598\tKL_Divergence = 3.890054\n",
      "Epoch: 41\tFidelity = 0.500554\tKL_Divergence = 3.932260\n",
      "Epoch: 42\tFidelity = 0.500564\tKL_Divergence = 3.921582\n",
      "Epoch: 43\tFidelity = 0.500644\tKL_Divergence = 3.848572\n",
      "Epoch: 44\tFidelity = 0.500588\tKL_Divergence = 3.898769\n",
      "Epoch: 45\tFidelity = 0.500513\tKL_Divergence = 3.974737\n",
      "Epoch: 46\tFidelity = 0.500570\tKL_Divergence = 3.915726\n",
      "Epoch: 47\tFidelity = 0.500647\tKL_Divergence = 3.846409\n",
      "Epoch: 48\tFidelity = 0.500632\tKL_Divergence = 3.858613\n",
      "Epoch: 49\tFidelity = 0.500540\tKL_Divergence = 3.946341\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 12:11:06,493] Trial 656 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500636\tKL_Divergence = 3.855531\n",
      "Total time elapsed during training: 38.893 s\n",
      "Trial 656 pruned. \n",
      "Epoch: 1\tFidelity = 0.500587\tKL_Divergence = 3.900177\n",
      "Epoch: 2\tFidelity = 0.500645\tKL_Divergence = 3.847722\n",
      "Epoch: 3\tFidelity = 0.500580\tKL_Divergence = 3.907160\n",
      "Epoch: 4\tFidelity = 0.500591\tKL_Divergence = 3.896231\n",
      "Epoch: 5\tFidelity = 0.500626\tKL_Divergence = 3.864205\n",
      "Epoch: 6\tFidelity = 0.500600\tKL_Divergence = 3.888220\n",
      "Epoch: 7\tFidelity = 0.500534\tKL_Divergence = 3.952500\n",
      "Epoch: 8\tFidelity = 0.500564\tKL_Divergence = 3.922079\n",
      "Epoch: 9\tFidelity = 0.500630\tKL_Divergence = 3.860480\n",
      "Epoch: 10\tFidelity = 0.500604\tKL_Divergence = 3.884369\n",
      "Epoch: 11\tFidelity = 0.500592\tKL_Divergence = 3.895563\n",
      "Epoch: 12\tFidelity = 0.500649\tKL_Divergence = 3.844119\n",
      "Epoch: 13\tFidelity = 0.500514\tKL_Divergence = 3.973456\n",
      "Epoch: 14\tFidelity = 0.500627\tKL_Divergence = 3.863150\n",
      "Epoch: 15\tFidelity = 0.500591\tKL_Divergence = 3.896184\n",
      "Epoch: 16\tFidelity = 0.500594\tKL_Divergence = 3.893110\n",
      "Epoch: 17\tFidelity = 0.500626\tKL_Divergence = 3.864209\n",
      "Epoch: 18\tFidelity = 0.500644\tKL_Divergence = 3.848263\n",
      "Epoch: 19\tFidelity = 0.500541\tKL_Divergence = 3.945148\n",
      "Epoch: 20\tFidelity = 0.500647\tKL_Divergence = 3.846483\n",
      "Epoch: 21\tFidelity = 0.500611\tKL_Divergence = 3.878080\n",
      "Epoch: 22\tFidelity = 0.500635\tKL_Divergence = 3.856826\n",
      "Epoch: 23\tFidelity = 0.500505\tKL_Divergence = 3.983178\n",
      "Epoch: 24\tFidelity = 0.500565\tKL_Divergence = 3.921658\n",
      "Epoch: 25\tFidelity = 0.500583\tKL_Divergence = 3.904089\n",
      "Epoch: 26\tFidelity = 0.500665\tKL_Divergence = 3.830979\n",
      "Epoch: 27\tFidelity = 0.500652\tKL_Divergence = 3.841587\n",
      "Epoch: 28\tFidelity = 0.500536\tKL_Divergence = 3.950688\n",
      "Epoch: 29\tFidelity = 0.500624\tKL_Divergence = 3.865960\n",
      "Epoch: 30\tFidelity = 0.500577\tKL_Divergence = 3.910072\n",
      "Epoch: 31\tFidelity = 0.500563\tKL_Divergence = 3.923571\n",
      "Epoch: 32\tFidelity = 0.500644\tKL_Divergence = 3.848846\n",
      "Epoch: 33\tFidelity = 0.500630\tKL_Divergence = 3.861185\n",
      "Epoch: 34\tFidelity = 0.500574\tKL_Divergence = 3.912142\n",
      "Epoch: 35\tFidelity = 0.500544\tKL_Divergence = 3.942428\n",
      "Epoch: 36\tFidelity = 0.500672\tKL_Divergence = 3.825419\n",
      "Epoch: 37\tFidelity = 0.500720\tKL_Divergence = 3.787004\n",
      "Epoch: 38\tFidelity = 0.500572\tKL_Divergence = 3.914532\n",
      "Epoch: 39\tFidelity = 0.500558\tKL_Divergence = 3.928254\n",
      "Epoch: 40\tFidelity = 0.500673\tKL_Divergence = 3.824519\n",
      "Epoch: 41\tFidelity = 0.500632\tKL_Divergence = 3.859368\n",
      "Epoch: 42\tFidelity = 0.500561\tKL_Divergence = 3.925361\n",
      "Epoch: 43\tFidelity = 0.500639\tKL_Divergence = 3.852923\n",
      "Epoch: 44\tFidelity = 0.500632\tKL_Divergence = 3.858694\n",
      "Epoch: 45\tFidelity = 0.500649\tKL_Divergence = 3.844579\n",
      "Epoch: 46\tFidelity = 0.500570\tKL_Divergence = 3.916421\n",
      "Epoch: 47\tFidelity = 0.500692\tKL_Divergence = 3.808938\n",
      "Epoch: 48\tFidelity = 0.500578\tKL_Divergence = 3.909030\n",
      "Epoch: 49\tFidelity = 0.500665\tKL_Divergence = 3.831031\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 12:11:53,317] Trial 657 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500658\tKL_Divergence = 3.836369\n",
      "Total time elapsed during training: 46.621 s\n",
      "Trial 657 pruned. \n",
      "Epoch: 1\tFidelity = 0.500522\tKL_Divergence = 3.964762\n",
      "Epoch: 2\tFidelity = 0.500526\tKL_Divergence = 3.961261\n",
      "Epoch: 3\tFidelity = 0.500605\tKL_Divergence = 3.883230\n",
      "Epoch: 4\tFidelity = 0.500602\tKL_Divergence = 3.885376\n",
      "Epoch: 5\tFidelity = 0.500802\tKL_Divergence = 3.726879\n",
      "Epoch: 6\tFidelity = 0.500650\tKL_Divergence = 3.843059\n",
      "Epoch: 7\tFidelity = 0.500702\tKL_Divergence = 3.800480\n",
      "Epoch: 8\tFidelity = 0.500639\tKL_Divergence = 3.853089\n",
      "Epoch: 9\tFidelity = 0.500653\tKL_Divergence = 3.840493\n",
      "Epoch: 10\tFidelity = 0.500701\tKL_Divergence = 3.801388\n",
      "Epoch: 11\tFidelity = 0.500569\tKL_Divergence = 3.917106\n",
      "Epoch: 12\tFidelity = 0.500743\tKL_Divergence = 3.769249\n",
      "Epoch: 13\tFidelity = 0.500693\tKL_Divergence = 3.807421\n",
      "Epoch: 14\tFidelity = 0.500528\tKL_Divergence = 3.958501\n",
      "Epoch: 15\tFidelity = 0.500555\tKL_Divergence = 3.930956\n",
      "Epoch: 16\tFidelity = 0.500767\tKL_Divergence = 3.751836\n",
      "Epoch: 17\tFidelity = 0.500664\tKL_Divergence = 3.831799\n",
      "Epoch: 18\tFidelity = 0.500789\tKL_Divergence = 3.735504\n",
      "Epoch: 19\tFidelity = 0.500503\tKL_Divergence = 3.986095\n",
      "Epoch: 20\tFidelity = 0.500592\tKL_Divergence = 3.895432\n",
      "Epoch: 21\tFidelity = 0.500569\tKL_Divergence = 3.917538\n",
      "Epoch: 22\tFidelity = 0.500572\tKL_Divergence = 3.914766\n",
      "Epoch: 23\tFidelity = 0.500574\tKL_Divergence = 3.912350\n",
      "Epoch: 24\tFidelity = 0.500691\tKL_Divergence = 3.809480\n",
      "Epoch: 25\tFidelity = 0.500573\tKL_Divergence = 3.913658\n",
      "Epoch: 26\tFidelity = 0.500583\tKL_Divergence = 3.903383\n",
      "Epoch: 27\tFidelity = 0.500689\tKL_Divergence = 3.810747\n",
      "Epoch: 28\tFidelity = 0.500576\tKL_Divergence = 3.910408\n",
      "Epoch: 29\tFidelity = 0.500697\tKL_Divergence = 3.804411\n",
      "Epoch: 30\tFidelity = 0.500783\tKL_Divergence = 3.739964\n",
      "Epoch: 31\tFidelity = 0.500738\tKL_Divergence = 3.772696\n",
      "Epoch: 32\tFidelity = 0.500665\tKL_Divergence = 3.830671\n",
      "Epoch: 33\tFidelity = 0.500605\tKL_Divergence = 3.883322\n",
      "Epoch: 34\tFidelity = 0.500671\tKL_Divergence = 3.825878\n",
      "Epoch: 35\tFidelity = 0.500643\tKL_Divergence = 3.849396\n",
      "Epoch: 36\tFidelity = 0.500636\tKL_Divergence = 3.855198\n",
      "Epoch: 37\tFidelity = 0.500662\tKL_Divergence = 3.833421\n",
      "Epoch: 38\tFidelity = 0.500639\tKL_Divergence = 3.852775\n",
      "Epoch: 39\tFidelity = 0.500632\tKL_Divergence = 3.859371\n",
      "Epoch: 40\tFidelity = 0.500610\tKL_Divergence = 3.878616\n",
      "Epoch: 41\tFidelity = 0.500757\tKL_Divergence = 3.759036\n",
      "Epoch: 42\tFidelity = 0.500671\tKL_Divergence = 3.825396\n",
      "Epoch: 43\tFidelity = 0.500657\tKL_Divergence = 3.837621\n",
      "Epoch: 44\tFidelity = 0.500604\tKL_Divergence = 3.883775\n",
      "Epoch: 45\tFidelity = 0.500676\tKL_Divergence = 3.821528\n",
      "Epoch: 46\tFidelity = 0.500577\tKL_Divergence = 3.908965\n",
      "Epoch: 47\tFidelity = 0.500650\tKL_Divergence = 3.842925\n",
      "Epoch: 48\tFidelity = 0.500618\tKL_Divergence = 3.871547\n",
      "Epoch: 49\tFidelity = 0.500539\tKL_Divergence = 3.947136\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 12:12:52,501] Trial 658 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500655\tKL_Divergence = 3.839205\n",
      "Total time elapsed during training: 58.988 s\n",
      "Trial 658 pruned. \n",
      "Epoch: 1\tFidelity = 0.500605\tKL_Divergence = 3.882930\n",
      "Epoch: 2\tFidelity = 0.500553\tKL_Divergence = 3.933648\n",
      "Epoch: 3\tFidelity = 0.500656\tKL_Divergence = 3.838689\n",
      "Epoch: 4\tFidelity = 0.500641\tKL_Divergence = 3.851377\n",
      "Epoch: 5\tFidelity = 0.500634\tKL_Divergence = 3.857682\n",
      "Epoch: 6\tFidelity = 0.500611\tKL_Divergence = 3.877531\n",
      "Epoch: 7\tFidelity = 0.500652\tKL_Divergence = 3.841495\n",
      "Epoch: 8\tFidelity = 0.500639\tKL_Divergence = 3.853040\n",
      "Epoch: 9\tFidelity = 0.500653\tKL_Divergence = 3.840737\n",
      "Epoch: 10\tFidelity = 0.500609\tKL_Divergence = 3.879713\n",
      "Epoch: 11\tFidelity = 0.500600\tKL_Divergence = 3.887779\n",
      "Epoch: 12\tFidelity = 0.500686\tKL_Divergence = 3.813783\n",
      "Epoch: 13\tFidelity = 0.500652\tKL_Divergence = 3.841521\n",
      "Epoch: 14\tFidelity = 0.500613\tKL_Divergence = 3.875595\n",
      "Epoch: 15\tFidelity = 0.500607\tKL_Divergence = 3.881335\n",
      "Epoch: 16\tFidelity = 0.500631\tKL_Divergence = 3.859802\n",
      "Epoch: 17\tFidelity = 0.500669\tKL_Divergence = 3.827170\n",
      "Epoch: 18\tFidelity = 0.500559\tKL_Divergence = 3.927343\n",
      "Epoch: 19\tFidelity = 0.500580\tKL_Divergence = 3.907235\n",
      "Epoch: 20\tFidelity = 0.500651\tKL_Divergence = 3.842666\n",
      "Epoch: 21\tFidelity = 0.500537\tKL_Divergence = 3.949192\n",
      "Epoch: 22\tFidelity = 0.500568\tKL_Divergence = 3.918322\n",
      "Epoch: 23\tFidelity = 0.500603\tKL_Divergence = 3.884927\n",
      "Epoch: 24\tFidelity = 0.500613\tKL_Divergence = 3.876517\n",
      "Epoch: 25\tFidelity = 0.500600\tKL_Divergence = 3.888118\n",
      "Epoch: 26\tFidelity = 0.500591\tKL_Divergence = 3.896103\n",
      "Epoch: 27\tFidelity = 0.500593\tKL_Divergence = 3.894603\n",
      "Epoch: 28\tFidelity = 0.500528\tKL_Divergence = 3.958557\n",
      "Epoch: 29\tFidelity = 0.500610\tKL_Divergence = 3.878897\n",
      "Epoch: 30\tFidelity = 0.500568\tKL_Divergence = 3.918498\n",
      "Epoch: 31\tFidelity = 0.500551\tKL_Divergence = 3.935014\n",
      "Epoch: 32\tFidelity = 0.500563\tKL_Divergence = 3.922852\n",
      "Epoch: 33\tFidelity = 0.500624\tKL_Divergence = 3.866397\n",
      "Epoch: 34\tFidelity = 0.500589\tKL_Divergence = 3.898329\n",
      "Epoch: 35\tFidelity = 0.500594\tKL_Divergence = 3.893723\n",
      "Epoch: 36\tFidelity = 0.500576\tKL_Divergence = 3.910857\n",
      "Epoch: 37\tFidelity = 0.500614\tKL_Divergence = 3.875562\n",
      "Epoch: 38\tFidelity = 0.500554\tKL_Divergence = 3.932727\n",
      "Epoch: 39\tFidelity = 0.500613\tKL_Divergence = 3.876301\n",
      "Epoch: 40\tFidelity = 0.500581\tKL_Divergence = 3.905631\n",
      "Epoch: 41\tFidelity = 0.500577\tKL_Divergence = 3.910043\n",
      "Epoch: 42\tFidelity = 0.500499\tKL_Divergence = 3.990695\n",
      "Epoch: 43\tFidelity = 0.500648\tKL_Divergence = 3.845478\n",
      "Epoch: 44\tFidelity = 0.500613\tKL_Divergence = 3.875733\n",
      "Epoch: 45\tFidelity = 0.500535\tKL_Divergence = 3.951862\n",
      "Epoch: 46\tFidelity = 0.500577\tKL_Divergence = 3.909609\n",
      "Epoch: 47\tFidelity = 0.500567\tKL_Divergence = 3.919024\n",
      "Epoch: 48\tFidelity = 0.500607\tKL_Divergence = 3.881372\n",
      "Epoch: 49\tFidelity = 0.500562\tKL_Divergence = 3.924176\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 12:14:15,488] Trial 659 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500598\tKL_Divergence = 3.889988\n",
      "Total time elapsed during training: 82.796 s\n",
      "Trial 659 pruned. \n",
      "Epoch: 1\tFidelity = 0.500538\tKL_Divergence = 3.948742\n",
      "Epoch: 2\tFidelity = 0.500539\tKL_Divergence = 3.947813\n",
      "Epoch: 3\tFidelity = 0.500637\tKL_Divergence = 3.854907\n",
      "Epoch: 4\tFidelity = 0.500612\tKL_Divergence = 3.877386\n",
      "Epoch: 5\tFidelity = 0.500537\tKL_Divergence = 3.949664\n",
      "Epoch: 6\tFidelity = 0.500633\tKL_Divergence = 3.858018\n",
      "Epoch: 7\tFidelity = 0.500605\tKL_Divergence = 3.883363\n",
      "Epoch: 8\tFidelity = 0.500522\tKL_Divergence = 3.965724\n",
      "Epoch: 9\tFidelity = 0.500575\tKL_Divergence = 3.911323\n",
      "Epoch: 10\tFidelity = 0.500549\tKL_Divergence = 3.936998\n",
      "Epoch: 11\tFidelity = 0.500558\tKL_Divergence = 3.928205\n",
      "Epoch: 12\tFidelity = 0.500640\tKL_Divergence = 3.851715\n",
      "Epoch: 13\tFidelity = 0.500596\tKL_Divergence = 3.891847\n",
      "Epoch: 14\tFidelity = 0.500625\tKL_Divergence = 3.864914\n",
      "Epoch: 15\tFidelity = 0.500630\tKL_Divergence = 3.861063\n",
      "Epoch: 16\tFidelity = 0.500607\tKL_Divergence = 3.881290\n",
      "Epoch: 17\tFidelity = 0.500570\tKL_Divergence = 3.916452\n",
      "Epoch: 18\tFidelity = 0.500620\tKL_Divergence = 3.869710\n",
      "Epoch: 19\tFidelity = 0.500557\tKL_Divergence = 3.929541\n",
      "Epoch: 20\tFidelity = 0.500561\tKL_Divergence = 3.924824\n",
      "Epoch: 21\tFidelity = 0.500680\tKL_Divergence = 3.818634\n",
      "Epoch: 22\tFidelity = 0.500562\tKL_Divergence = 3.924747\n",
      "Epoch: 23\tFidelity = 0.500589\tKL_Divergence = 3.898711\n",
      "Epoch: 24\tFidelity = 0.500536\tKL_Divergence = 3.950442\n",
      "Epoch: 25\tFidelity = 0.500548\tKL_Divergence = 3.938262\n",
      "Epoch: 26\tFidelity = 0.500577\tKL_Divergence = 3.910014\n",
      "Epoch: 27\tFidelity = 0.500624\tKL_Divergence = 3.866252\n",
      "Epoch: 28\tFidelity = 0.500537\tKL_Divergence = 3.949970\n",
      "Epoch: 29\tFidelity = 0.500568\tKL_Divergence = 3.918705\n",
      "Epoch: 30\tFidelity = 0.500607\tKL_Divergence = 3.881811\n",
      "Epoch: 31\tFidelity = 0.500549\tKL_Divergence = 3.937484\n",
      "Epoch: 32\tFidelity = 0.500604\tKL_Divergence = 3.884480\n",
      "Epoch: 33\tFidelity = 0.500527\tKL_Divergence = 3.960153\n",
      "Epoch: 34\tFidelity = 0.500540\tKL_Divergence = 3.946129\n",
      "Epoch: 35\tFidelity = 0.500577\tKL_Divergence = 3.910086\n",
      "Epoch: 36\tFidelity = 0.500619\tKL_Divergence = 3.871072\n",
      "Epoch: 37\tFidelity = 0.500650\tKL_Divergence = 3.843352\n",
      "Epoch: 38\tFidelity = 0.500592\tKL_Divergence = 3.894991\n",
      "Epoch: 39\tFidelity = 0.500571\tKL_Divergence = 3.915213\n",
      "Epoch: 40\tFidelity = 0.500526\tKL_Divergence = 3.961446\n",
      "Epoch: 41\tFidelity = 0.500622\tKL_Divergence = 3.867641\n",
      "Epoch: 42\tFidelity = 0.500554\tKL_Divergence = 3.931855\n",
      "Epoch: 43\tFidelity = 0.500618\tKL_Divergence = 3.871522\n",
      "Epoch: 44\tFidelity = 0.500615\tKL_Divergence = 3.874464\n",
      "Epoch: 45\tFidelity = 0.500652\tKL_Divergence = 3.841895\n",
      "Epoch: 46\tFidelity = 0.500589\tKL_Divergence = 3.897879\n",
      "Epoch: 47\tFidelity = 0.500569\tKL_Divergence = 3.917242\n",
      "Epoch: 48\tFidelity = 0.500617\tKL_Divergence = 3.872227\n",
      "Epoch: 49\tFidelity = 0.500513\tKL_Divergence = 3.974601\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 12:14:55,155] Trial 660 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500506\tKL_Divergence = 3.982088\n",
      "Total time elapsed during training: 39.459 s\n",
      "Trial 660 pruned. \n",
      "Epoch: 1\tFidelity = 0.500541\tKL_Divergence = 3.945846\n",
      "Epoch: 2\tFidelity = 0.500549\tKL_Divergence = 3.936961\n",
      "Epoch: 3\tFidelity = 0.500554\tKL_Divergence = 3.932686\n",
      "Epoch: 4\tFidelity = 0.500553\tKL_Divergence = 3.933259\n",
      "Epoch: 5\tFidelity = 0.500585\tKL_Divergence = 3.901718\n",
      "Epoch: 6\tFidelity = 0.500579\tKL_Divergence = 3.907853\n",
      "Epoch: 7\tFidelity = 0.500562\tKL_Divergence = 3.924553\n",
      "Epoch: 8\tFidelity = 0.500559\tKL_Divergence = 3.926918\n",
      "Epoch: 9\tFidelity = 0.500581\tKL_Divergence = 3.905495\n",
      "Epoch: 10\tFidelity = 0.500563\tKL_Divergence = 3.922922\n",
      "Epoch: 11\tFidelity = 0.500568\tKL_Divergence = 3.918630\n",
      "Epoch: 12\tFidelity = 0.500572\tKL_Divergence = 3.914621\n",
      "Epoch: 13\tFidelity = 0.500590\tKL_Divergence = 3.897431\n",
      "Epoch: 14\tFidelity = 0.500565\tKL_Divergence = 3.921372\n",
      "Epoch: 15\tFidelity = 0.500572\tKL_Divergence = 3.914745\n",
      "Epoch: 16\tFidelity = 0.500585\tKL_Divergence = 3.902417\n",
      "Epoch: 17\tFidelity = 0.500545\tKL_Divergence = 3.941802\n",
      "Epoch: 18\tFidelity = 0.500571\tKL_Divergence = 3.915629\n",
      "Epoch: 19\tFidelity = 0.500582\tKL_Divergence = 3.905130\n",
      "Epoch: 20\tFidelity = 0.500587\tKL_Divergence = 3.900059\n",
      "Epoch: 21\tFidelity = 0.500575\tKL_Divergence = 3.911553\n",
      "Epoch: 22\tFidelity = 0.500581\tKL_Divergence = 3.905589\n",
      "Epoch: 23\tFidelity = 0.500569\tKL_Divergence = 3.917354\n",
      "Epoch: 24\tFidelity = 0.500555\tKL_Divergence = 3.930853\n",
      "Epoch: 25\tFidelity = 0.500586\tKL_Divergence = 3.901347\n",
      "Epoch: 26\tFidelity = 0.500578\tKL_Divergence = 3.908531\n",
      "Epoch: 27\tFidelity = 0.500572\tKL_Divergence = 3.914348\n",
      "Epoch: 28\tFidelity = 0.500571\tKL_Divergence = 3.915003\n",
      "Epoch: 29\tFidelity = 0.500598\tKL_Divergence = 3.890130\n",
      "Epoch: 30\tFidelity = 0.500598\tKL_Divergence = 3.889686\n",
      "Epoch: 31\tFidelity = 0.500566\tKL_Divergence = 3.920734\n",
      "Epoch: 32\tFidelity = 0.500556\tKL_Divergence = 3.930512\n",
      "Epoch: 33\tFidelity = 0.500597\tKL_Divergence = 3.890805\n",
      "Epoch: 34\tFidelity = 0.500612\tKL_Divergence = 3.876990\n",
      "Epoch: 35\tFidelity = 0.500574\tKL_Divergence = 3.912514\n",
      "Epoch: 36\tFidelity = 0.500595\tKL_Divergence = 3.892876\n",
      "Epoch: 37\tFidelity = 0.500572\tKL_Divergence = 3.914048\n",
      "Epoch: 38\tFidelity = 0.500558\tKL_Divergence = 3.928086\n",
      "Epoch: 39\tFidelity = 0.500554\tKL_Divergence = 3.932351\n",
      "Epoch: 40\tFidelity = 0.500563\tKL_Divergence = 3.923388\n",
      "Epoch: 41\tFidelity = 0.500567\tKL_Divergence = 3.918943\n",
      "Epoch: 42\tFidelity = 0.500567\tKL_Divergence = 3.919657\n",
      "Epoch: 43\tFidelity = 0.500566\tKL_Divergence = 3.920628\n",
      "Epoch: 44\tFidelity = 0.500565\tKL_Divergence = 3.920959\n",
      "Epoch: 45\tFidelity = 0.500562\tKL_Divergence = 3.924582\n",
      "Epoch: 46\tFidelity = 0.500590\tKL_Divergence = 3.897663\n",
      "Epoch: 47\tFidelity = 0.500610\tKL_Divergence = 3.878845\n",
      "Epoch: 48\tFidelity = 0.500585\tKL_Divergence = 3.902024\n",
      "Epoch: 49\tFidelity = 0.500552\tKL_Divergence = 3.934614\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 12:15:27,785] Trial 661 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500527\tKL_Divergence = 3.960410\n",
      "Total time elapsed during training: 32.435 s\n",
      "Trial 661 pruned. \n",
      "Epoch: 1\tFidelity = 0.500505\tKL_Divergence = 3.983930\n",
      "Epoch: 2\tFidelity = 0.500816\tKL_Divergence = 3.716513\n",
      "Epoch: 3\tFidelity = 0.500604\tKL_Divergence = 3.883636\n",
      "Epoch: 4\tFidelity = 0.500481\tKL_Divergence = 4.008836\n",
      "Epoch: 5\tFidelity = 0.500507\tKL_Divergence = 3.980784\n",
      "Epoch: 6\tFidelity = 0.500765\tKL_Divergence = 3.752469\n",
      "Epoch: 7\tFidelity = 0.500633\tKL_Divergence = 3.857056\n",
      "Epoch: 8\tFidelity = 0.500688\tKL_Divergence = 3.811266\n",
      "Epoch: 9\tFidelity = 0.500837\tKL_Divergence = 3.702237\n",
      "Epoch: 10\tFidelity = 0.500725\tKL_Divergence = 3.782229\n",
      "Epoch: 11\tFidelity = 0.500525\tKL_Divergence = 3.961348\n",
      "Epoch: 12\tFidelity = 0.500541\tKL_Divergence = 3.944133\n",
      "Epoch: 13\tFidelity = 0.500629\tKL_Divergence = 3.859346\n",
      "Epoch: 14\tFidelity = 0.500550\tKL_Divergence = 3.933544\n",
      "Epoch: 15\tFidelity = 0.500720\tKL_Divergence = 3.784432\n",
      "Epoch: 16\tFidelity = 0.500718\tKL_Divergence = 3.786159\n",
      "Epoch: 17\tFidelity = 0.500635\tKL_Divergence = 3.852619\n",
      "Epoch: 18\tFidelity = 0.500644\tKL_Divergence = 3.846369\n",
      "Epoch: 19\tFidelity = 0.500609\tKL_Divergence = 3.877960\n",
      "Epoch: 20\tFidelity = 0.500550\tKL_Divergence = 3.935223\n",
      "Epoch: 21\tFidelity = 0.500652\tKL_Divergence = 3.841015\n",
      "Epoch: 22\tFidelity = 0.500710\tKL_Divergence = 3.794034\n",
      "Epoch: 23\tFidelity = 0.500482\tKL_Divergence = 4.009011\n",
      "Epoch: 24\tFidelity = 0.500658\tKL_Divergence = 3.836147\n",
      "Epoch: 25\tFidelity = 0.500607\tKL_Divergence = 3.881620\n",
      "Epoch: 26\tFidelity = 0.500567\tKL_Divergence = 3.919033\n",
      "Epoch: 27\tFidelity = 0.500516\tKL_Divergence = 3.971379\n",
      "Epoch: 28\tFidelity = 0.500777\tKL_Divergence = 3.744717\n",
      "Epoch: 29\tFidelity = 0.500517\tKL_Divergence = 3.970477\n",
      "Epoch: 30\tFidelity = 0.500483\tKL_Divergence = 4.008300\n",
      "Epoch: 31\tFidelity = 0.500458\tKL_Divergence = 4.038360\n",
      "Epoch: 32\tFidelity = 0.500665\tKL_Divergence = 3.830911\n",
      "Epoch: 33\tFidelity = 0.500455\tKL_Divergence = 4.041740\n",
      "Epoch: 34\tFidelity = 0.500548\tKL_Divergence = 3.938663\n",
      "Epoch: 35\tFidelity = 0.500647\tKL_Divergence = 3.845979\n",
      "Epoch: 36\tFidelity = 0.500581\tKL_Divergence = 3.905514\n",
      "Epoch: 37\tFidelity = 0.500759\tKL_Divergence = 3.757553\n",
      "Epoch: 38\tFidelity = 0.500585\tKL_Divergence = 3.902334\n",
      "Epoch: 39\tFidelity = 0.500599\tKL_Divergence = 3.888942\n",
      "Epoch: 40\tFidelity = 0.500484\tKL_Divergence = 4.007088\n",
      "Epoch: 41\tFidelity = 0.500456\tKL_Divergence = 4.040733\n",
      "Epoch: 42\tFidelity = 0.500523\tKL_Divergence = 3.963607\n",
      "Epoch: 43\tFidelity = 0.500663\tKL_Divergence = 3.832228\n",
      "Epoch: 44\tFidelity = 0.500656\tKL_Divergence = 3.838666\n",
      "Epoch: 45\tFidelity = 0.500482\tKL_Divergence = 4.008486\n",
      "Epoch: 46\tFidelity = 0.500530\tKL_Divergence = 3.956467\n",
      "Epoch: 47\tFidelity = 0.500667\tKL_Divergence = 3.829367\n",
      "Epoch: 48\tFidelity = 0.500643\tKL_Divergence = 3.849577\n",
      "Epoch: 49\tFidelity = 0.500606\tKL_Divergence = 3.881483\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 12:16:07,119] Trial 662 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500664\tKL_Divergence = 3.831462\n",
      "Total time elapsed during training: 39.129 s\n",
      "Trial 662 pruned. \n",
      "Epoch: 1\tFidelity = 0.500622\tKL_Divergence = 3.867570\n",
      "Epoch: 2\tFidelity = 0.500575\tKL_Divergence = 3.910678\n",
      "Epoch: 3\tFidelity = 0.500640\tKL_Divergence = 3.851919\n",
      "Epoch: 4\tFidelity = 0.500635\tKL_Divergence = 3.855946\n",
      "Epoch: 5\tFidelity = 0.500564\tKL_Divergence = 3.921904\n",
      "Epoch: 6\tFidelity = 0.500595\tKL_Divergence = 3.892043\n",
      "Epoch: 7\tFidelity = 0.500600\tKL_Divergence = 3.887923\n",
      "Epoch: 8\tFidelity = 0.500591\tKL_Divergence = 3.896210\n",
      "Epoch: 9\tFidelity = 0.500560\tKL_Divergence = 3.926275\n",
      "Epoch: 10\tFidelity = 0.500595\tKL_Divergence = 3.892312\n",
      "Epoch: 11\tFidelity = 0.500611\tKL_Divergence = 3.878007\n",
      "Epoch: 12\tFidelity = 0.500538\tKL_Divergence = 3.947954\n",
      "Epoch: 13\tFidelity = 0.500580\tKL_Divergence = 3.906101\n",
      "Epoch: 14\tFidelity = 0.500609\tKL_Divergence = 3.879369\n",
      "Epoch: 15\tFidelity = 0.500537\tKL_Divergence = 3.948777\n",
      "Epoch: 16\tFidelity = 0.500576\tKL_Divergence = 3.910520\n",
      "Epoch: 17\tFidelity = 0.500619\tKL_Divergence = 3.870483\n",
      "Epoch: 18\tFidelity = 0.500595\tKL_Divergence = 3.892498\n",
      "Epoch: 19\tFidelity = 0.500556\tKL_Divergence = 3.930245\n",
      "Epoch: 20\tFidelity = 0.500601\tKL_Divergence = 3.886456\n",
      "Epoch: 21\tFidelity = 0.500494\tKL_Divergence = 3.995167\n",
      "Epoch: 22\tFidelity = 0.500577\tKL_Divergence = 3.910004\n",
      "Epoch: 23\tFidelity = 0.500643\tKL_Divergence = 3.849314\n",
      "Epoch: 24\tFidelity = 0.500579\tKL_Divergence = 3.907305\n",
      "Epoch: 25\tFidelity = 0.500585\tKL_Divergence = 3.902283\n",
      "Epoch: 26\tFidelity = 0.500644\tKL_Divergence = 3.848898\n",
      "Epoch: 27\tFidelity = 0.500624\tKL_Divergence = 3.865801\n",
      "Epoch: 28\tFidelity = 0.500627\tKL_Divergence = 3.863737\n",
      "Epoch: 29\tFidelity = 0.500491\tKL_Divergence = 3.999239\n",
      "Epoch: 30\tFidelity = 0.500554\tKL_Divergence = 3.932405\n",
      "Epoch: 31\tFidelity = 0.500519\tKL_Divergence = 3.968552\n",
      "Epoch: 32\tFidelity = 0.500514\tKL_Divergence = 3.973769\n",
      "Epoch: 33\tFidelity = 0.500542\tKL_Divergence = 3.944048\n",
      "Epoch: 34\tFidelity = 0.500529\tKL_Divergence = 3.957417\n",
      "Epoch: 35\tFidelity = 0.500526\tKL_Divergence = 3.961565\n",
      "Epoch: 36\tFidelity = 0.500619\tKL_Divergence = 3.870554\n",
      "Epoch: 37\tFidelity = 0.500559\tKL_Divergence = 3.927586\n",
      "Epoch: 38\tFidelity = 0.500514\tKL_Divergence = 3.973893\n",
      "Epoch: 39\tFidelity = 0.500509\tKL_Divergence = 3.978815\n",
      "Epoch: 40\tFidelity = 0.500578\tKL_Divergence = 3.908795\n",
      "Epoch: 41\tFidelity = 0.500469\tKL_Divergence = 4.025023\n",
      "Epoch: 42\tFidelity = 0.500455\tKL_Divergence = 4.041721\n",
      "Epoch: 43\tFidelity = 0.500563\tKL_Divergence = 3.923566\n",
      "Epoch: 44\tFidelity = 0.500592\tKL_Divergence = 3.895728\n",
      "Epoch: 45\tFidelity = 0.500650\tKL_Divergence = 3.843335\n",
      "Epoch: 46\tFidelity = 0.500533\tKL_Divergence = 3.953906\n",
      "Epoch: 47\tFidelity = 0.500524\tKL_Divergence = 3.963163\n",
      "Epoch: 48\tFidelity = 0.500576\tKL_Divergence = 3.910915\n",
      "Epoch: 49\tFidelity = 0.500545\tKL_Divergence = 3.941161\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 12:16:47,550] Trial 663 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500569\tKL_Divergence = 3.917683\n",
      "Total time elapsed during training: 40.223 s\n",
      "Trial 663 pruned. \n",
      "Epoch: 1\tFidelity = 0.500526\tKL_Divergence = 3.960573\n",
      "Epoch: 2\tFidelity = 0.500510\tKL_Divergence = 3.978283\n",
      "Epoch: 3\tFidelity = 0.500574\tKL_Divergence = 3.912259\n",
      "Epoch: 4\tFidelity = 0.500574\tKL_Divergence = 3.912725\n",
      "Epoch: 5\tFidelity = 0.500589\tKL_Divergence = 3.898302\n",
      "Epoch: 6\tFidelity = 0.500604\tKL_Divergence = 3.884630\n",
      "Epoch: 7\tFidelity = 0.500554\tKL_Divergence = 3.932576\n",
      "Epoch: 8\tFidelity = 0.500621\tKL_Divergence = 3.868959\n",
      "Epoch: 9\tFidelity = 0.500539\tKL_Divergence = 3.947717\n",
      "Epoch: 10\tFidelity = 0.500575\tKL_Divergence = 3.911595\n",
      "Epoch: 11\tFidelity = 0.500519\tKL_Divergence = 3.968513\n",
      "Epoch: 12\tFidelity = 0.500549\tKL_Divergence = 3.937710\n",
      "Epoch: 13\tFidelity = 0.500591\tKL_Divergence = 3.896237\n",
      "Epoch: 14\tFidelity = 0.500533\tKL_Divergence = 3.954195\n",
      "Epoch: 15\tFidelity = 0.500599\tKL_Divergence = 3.888453\n",
      "Epoch: 16\tFidelity = 0.500551\tKL_Divergence = 3.935638\n",
      "Epoch: 17\tFidelity = 0.500552\tKL_Divergence = 3.933965\n",
      "Epoch: 18\tFidelity = 0.500553\tKL_Divergence = 3.933285\n",
      "Epoch: 19\tFidelity = 0.500587\tKL_Divergence = 3.900492\n",
      "Epoch: 20\tFidelity = 0.500626\tKL_Divergence = 3.864467\n",
      "Epoch: 21\tFidelity = 0.500545\tKL_Divergence = 3.941240\n",
      "Epoch: 22\tFidelity = 0.500555\tKL_Divergence = 3.931546\n",
      "Epoch: 23\tFidelity = 0.500537\tKL_Divergence = 3.949914\n",
      "Epoch: 24\tFidelity = 0.500547\tKL_Divergence = 3.939474\n",
      "Epoch: 25\tFidelity = 0.500548\tKL_Divergence = 3.938390\n",
      "Epoch: 26\tFidelity = 0.500529\tKL_Divergence = 3.958325\n",
      "Epoch: 27\tFidelity = 0.500623\tKL_Divergence = 3.866862\n",
      "Epoch: 28\tFidelity = 0.500564\tKL_Divergence = 3.922232\n",
      "Epoch: 29\tFidelity = 0.500630\tKL_Divergence = 3.860817\n",
      "Epoch: 30\tFidelity = 0.500540\tKL_Divergence = 3.946823\n",
      "Epoch: 31\tFidelity = 0.500591\tKL_Divergence = 3.895888\n",
      "Epoch: 32\tFidelity = 0.500578\tKL_Divergence = 3.908569\n",
      "Epoch: 33\tFidelity = 0.500539\tKL_Divergence = 3.947025\n",
      "Epoch: 34\tFidelity = 0.500605\tKL_Divergence = 3.883396\n",
      "Epoch: 35\tFidelity = 0.500548\tKL_Divergence = 3.938530\n",
      "Epoch: 36\tFidelity = 0.500589\tKL_Divergence = 3.898192\n",
      "Epoch: 37\tFidelity = 0.500570\tKL_Divergence = 3.916276\n",
      "Epoch: 38\tFidelity = 0.500525\tKL_Divergence = 3.961583\n",
      "Epoch: 39\tFidelity = 0.500608\tKL_Divergence = 3.880353\n",
      "Epoch: 40\tFidelity = 0.500611\tKL_Divergence = 3.878184\n",
      "Epoch: 41\tFidelity = 0.500565\tKL_Divergence = 3.921154\n",
      "Epoch: 42\tFidelity = 0.500548\tKL_Divergence = 3.938169\n",
      "Epoch: 43\tFidelity = 0.500627\tKL_Divergence = 3.863386\n",
      "Epoch: 44\tFidelity = 0.500528\tKL_Divergence = 3.959363\n",
      "Epoch: 45\tFidelity = 0.500543\tKL_Divergence = 3.943473\n",
      "Epoch: 46\tFidelity = 0.500547\tKL_Divergence = 3.938842\n",
      "Epoch: 47\tFidelity = 0.500568\tKL_Divergence = 3.918672\n",
      "Epoch: 48\tFidelity = 0.500557\tKL_Divergence = 3.928804\n",
      "Epoch: 49\tFidelity = 0.500554\tKL_Divergence = 3.932495\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 12:17:20,891] Trial 664 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500633\tKL_Divergence = 3.858111\n",
      "Total time elapsed during training: 33.069 s\n",
      "Trial 664 pruned. \n",
      "Epoch: 1\tFidelity = 0.500524\tKL_Divergence = 3.962892\n",
      "Epoch: 2\tFidelity = 0.500642\tKL_Divergence = 3.850411\n",
      "Epoch: 3\tFidelity = 0.500496\tKL_Divergence = 3.993535\n",
      "Epoch: 4\tFidelity = 0.500601\tKL_Divergence = 3.886732\n",
      "Epoch: 5\tFidelity = 0.500527\tKL_Divergence = 3.960041\n",
      "Epoch: 6\tFidelity = 0.500481\tKL_Divergence = 4.010282\n",
      "Epoch: 7\tFidelity = 0.500563\tKL_Divergence = 3.922838\n",
      "Epoch: 8\tFidelity = 0.500548\tKL_Divergence = 3.938121\n",
      "Epoch: 9\tFidelity = 0.500594\tKL_Divergence = 3.893215\n",
      "Epoch: 10\tFidelity = 0.500531\tKL_Divergence = 3.955536\n",
      "Epoch: 11\tFidelity = 0.500633\tKL_Divergence = 3.857682\n",
      "Epoch: 12\tFidelity = 0.500708\tKL_Divergence = 3.795768\n",
      "Epoch: 13\tFidelity = 0.500756\tKL_Divergence = 3.759546\n",
      "Epoch: 14\tFidelity = 0.500668\tKL_Divergence = 3.828300\n",
      "Epoch: 15\tFidelity = 0.500582\tKL_Divergence = 3.904634\n",
      "Epoch: 16\tFidelity = 0.500532\tKL_Divergence = 3.954635\n",
      "Epoch: 17\tFidelity = 0.500682\tKL_Divergence = 3.816468\n",
      "Epoch: 18\tFidelity = 0.500701\tKL_Divergence = 3.801127\n",
      "Epoch: 19\tFidelity = 0.500598\tKL_Divergence = 3.889701\n",
      "Epoch: 20\tFidelity = 0.500466\tKL_Divergence = 4.028352\n",
      "Epoch: 21\tFidelity = 0.500541\tKL_Divergence = 3.945560\n",
      "Epoch: 22\tFidelity = 0.500651\tKL_Divergence = 3.842574\n",
      "Epoch: 23\tFidelity = 0.500440\tKL_Divergence = 4.059910\n",
      "Epoch: 24\tFidelity = 0.500522\tKL_Divergence = 3.964978\n",
      "Epoch: 25\tFidelity = 0.500465\tKL_Divergence = 4.029082\n",
      "Epoch: 26\tFidelity = 0.500552\tKL_Divergence = 3.934525\n",
      "Epoch: 27\tFidelity = 0.500566\tKL_Divergence = 3.920116\n",
      "Epoch: 28\tFidelity = 0.500478\tKL_Divergence = 4.013670\n",
      "Epoch: 29\tFidelity = 0.500472\tKL_Divergence = 4.020800\n",
      "Epoch: 30\tFidelity = 0.500523\tKL_Divergence = 3.963816\n",
      "Epoch: 31\tFidelity = 0.500535\tKL_Divergence = 3.951970\n",
      "Epoch: 32\tFidelity = 0.500513\tKL_Divergence = 3.975039\n",
      "Epoch: 33\tFidelity = 0.500466\tKL_Divergence = 4.027814\n",
      "Epoch: 34\tFidelity = 0.500607\tKL_Divergence = 3.881365\n",
      "Epoch: 35\tFidelity = 0.500548\tKL_Divergence = 3.938674\n",
      "Epoch: 36\tFidelity = 0.500495\tKL_Divergence = 3.995376\n",
      "Epoch: 37\tFidelity = 0.500410\tKL_Divergence = 4.099248\n",
      "Epoch: 38\tFidelity = 0.500416\tKL_Divergence = 4.091828\n",
      "Epoch: 39\tFidelity = 0.500456\tKL_Divergence = 4.040552\n",
      "Epoch: 40\tFidelity = 0.500517\tKL_Divergence = 3.970557\n",
      "Epoch: 41\tFidelity = 0.500447\tKL_Divergence = 4.050896\n",
      "Epoch: 42\tFidelity = 0.500484\tKL_Divergence = 4.006894\n",
      "Epoch: 43\tFidelity = 0.500575\tKL_Divergence = 3.911460\n",
      "Epoch: 44\tFidelity = 0.500592\tKL_Divergence = 3.895458\n",
      "Epoch: 45\tFidelity = 0.500658\tKL_Divergence = 3.836540\n",
      "Epoch: 46\tFidelity = 0.500592\tKL_Divergence = 3.895182\n",
      "Epoch: 47\tFidelity = 0.500608\tKL_Divergence = 3.880496\n",
      "Epoch: 48\tFidelity = 0.500674\tKL_Divergence = 3.823156\n",
      "Epoch: 49\tFidelity = 0.500505\tKL_Divergence = 3.984050\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 12:18:45,144] Trial 665 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500529\tKL_Divergence = 3.957319\n",
      "Total time elapsed during training: 84.057 s\n",
      "Trial 665 pruned. \n",
      "Epoch: 1\tFidelity = 0.500571\tKL_Divergence = 3.915396\n",
      "Epoch: 2\tFidelity = 0.500456\tKL_Divergence = 4.039646\n",
      "Epoch: 3\tFidelity = 0.500645\tKL_Divergence = 3.848150\n",
      "Epoch: 4\tFidelity = 0.500612\tKL_Divergence = 3.876674\n",
      "Epoch: 5\tFidelity = 0.500588\tKL_Divergence = 3.898949\n",
      "Epoch: 6\tFidelity = 0.500576\tKL_Divergence = 3.910954\n",
      "Epoch: 7\tFidelity = 0.500622\tKL_Divergence = 3.867872\n",
      "Epoch: 8\tFidelity = 0.500634\tKL_Divergence = 3.857543\n",
      "Epoch: 9\tFidelity = 0.500486\tKL_Divergence = 4.005190\n",
      "Epoch: 10\tFidelity = 0.500563\tKL_Divergence = 3.922926\n",
      "Epoch: 11\tFidelity = 0.500554\tKL_Divergence = 3.932366\n",
      "Epoch: 12\tFidelity = 0.500462\tKL_Divergence = 4.033140\n",
      "Epoch: 13\tFidelity = 0.500577\tKL_Divergence = 3.910092\n",
      "Epoch: 14\tFidelity = 0.500587\tKL_Divergence = 3.900150\n",
      "Epoch: 15\tFidelity = 0.500592\tKL_Divergence = 3.895514\n",
      "Epoch: 16\tFidelity = 0.500622\tKL_Divergence = 3.868220\n",
      "Epoch: 17\tFidelity = 0.500546\tKL_Divergence = 3.940427\n",
      "Epoch: 18\tFidelity = 0.500496\tKL_Divergence = 3.993577\n",
      "Epoch: 19\tFidelity = 0.500470\tKL_Divergence = 4.023151\n",
      "Epoch: 20\tFidelity = 0.500526\tKL_Divergence = 3.961280\n",
      "Epoch: 21\tFidelity = 0.500508\tKL_Divergence = 3.980348\n",
      "Epoch: 22\tFidelity = 0.500529\tKL_Divergence = 3.957938\n",
      "Epoch: 23\tFidelity = 0.500592\tKL_Divergence = 3.895099\n",
      "Epoch: 24\tFidelity = 0.500570\tKL_Divergence = 3.916150\n",
      "Epoch: 25\tFidelity = 0.500502\tKL_Divergence = 3.987122\n",
      "Epoch: 26\tFidelity = 0.500529\tKL_Divergence = 3.957765\n",
      "Epoch: 27\tFidelity = 0.500477\tKL_Divergence = 4.015158\n",
      "Epoch: 28\tFidelity = 0.500527\tKL_Divergence = 3.960122\n",
      "Epoch: 29\tFidelity = 0.500502\tKL_Divergence = 3.987211\n",
      "Epoch: 30\tFidelity = 0.500603\tKL_Divergence = 3.884825\n",
      "Epoch: 31\tFidelity = 0.500530\tKL_Divergence = 3.956335\n",
      "Epoch: 32\tFidelity = 0.500600\tKL_Divergence = 3.888207\n",
      "Epoch: 33\tFidelity = 0.500511\tKL_Divergence = 3.976832\n",
      "Epoch: 34\tFidelity = 0.500472\tKL_Divergence = 4.021378\n",
      "Epoch: 35\tFidelity = 0.500574\tKL_Divergence = 3.912726\n",
      "Epoch: 36\tFidelity = 0.500620\tKL_Divergence = 3.869399\n",
      "Epoch: 37\tFidelity = 0.500460\tKL_Divergence = 4.035030\n",
      "Epoch: 38\tFidelity = 0.500537\tKL_Divergence = 3.950016\n",
      "Epoch: 39\tFidelity = 0.500516\tKL_Divergence = 3.971142\n",
      "Epoch: 40\tFidelity = 0.500506\tKL_Divergence = 3.982920\n",
      "Epoch: 41\tFidelity = 0.500583\tKL_Divergence = 3.904169\n",
      "Epoch: 42\tFidelity = 0.500521\tKL_Divergence = 3.966502\n",
      "Epoch: 43\tFidelity = 0.500445\tKL_Divergence = 4.053996\n",
      "Epoch: 44\tFidelity = 0.500507\tKL_Divergence = 3.981381\n",
      "Epoch: 45\tFidelity = 0.500652\tKL_Divergence = 3.841706\n",
      "Epoch: 46\tFidelity = 0.500631\tKL_Divergence = 3.859981\n",
      "Epoch: 47\tFidelity = 0.500490\tKL_Divergence = 4.000299\n",
      "Epoch: 48\tFidelity = 0.500545\tKL_Divergence = 3.941318\n",
      "Epoch: 49\tFidelity = 0.500519\tKL_Divergence = 3.968307\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 12:19:32,499] Trial 666 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500565\tKL_Divergence = 3.921607\n",
      "Total time elapsed during training: 47.141 s\n",
      "Trial 666 pruned. \n",
      "Epoch: 1\tFidelity = 0.500581\tKL_Divergence = 3.905435\n",
      "Epoch: 2\tFidelity = 0.500501\tKL_Divergence = 3.988297\n",
      "Epoch: 3\tFidelity = 0.500629\tKL_Divergence = 3.861624\n",
      "Epoch: 4\tFidelity = 0.500553\tKL_Divergence = 3.933231\n",
      "Epoch: 5\tFidelity = 0.500545\tKL_Divergence = 3.941016\n",
      "Epoch: 6\tFidelity = 0.500519\tKL_Divergence = 3.968675\n",
      "Epoch: 7\tFidelity = 0.500594\tKL_Divergence = 3.893295\n",
      "Epoch: 8\tFidelity = 0.500589\tKL_Divergence = 3.898341\n",
      "Epoch: 9\tFidelity = 0.500525\tKL_Divergence = 3.961805\n",
      "Epoch: 10\tFidelity = 0.500563\tKL_Divergence = 3.923527\n",
      "Epoch: 11\tFidelity = 0.500576\tKL_Divergence = 3.910150\n",
      "Epoch: 12\tFidelity = 0.500537\tKL_Divergence = 3.949595\n",
      "Epoch: 13\tFidelity = 0.500589\tKL_Divergence = 3.898471\n",
      "Epoch: 14\tFidelity = 0.500534\tKL_Divergence = 3.952939\n",
      "Epoch: 15\tFidelity = 0.500559\tKL_Divergence = 3.927629\n",
      "Epoch: 16\tFidelity = 0.500549\tKL_Divergence = 3.937448\n",
      "Epoch: 17\tFidelity = 0.500544\tKL_Divergence = 3.941889\n",
      "Epoch: 18\tFidelity = 0.500589\tKL_Divergence = 3.898072\n",
      "Epoch: 19\tFidelity = 0.500600\tKL_Divergence = 3.887770\n",
      "Epoch: 20\tFidelity = 0.500606\tKL_Divergence = 3.881950\n",
      "Epoch: 21\tFidelity = 0.500570\tKL_Divergence = 3.916601\n",
      "Epoch: 22\tFidelity = 0.500583\tKL_Divergence = 3.903982\n",
      "Epoch: 23\tFidelity = 0.500566\tKL_Divergence = 3.920232\n",
      "Epoch: 24\tFidelity = 0.500634\tKL_Divergence = 3.857182\n",
      "Epoch: 25\tFidelity = 0.500580\tKL_Divergence = 3.906423\n",
      "Epoch: 26\tFidelity = 0.500569\tKL_Divergence = 3.917091\n",
      "Epoch: 27\tFidelity = 0.500608\tKL_Divergence = 3.880727\n",
      "Epoch: 28\tFidelity = 0.500581\tKL_Divergence = 3.905994\n",
      "Epoch: 29\tFidelity = 0.500581\tKL_Divergence = 3.906108\n",
      "Epoch: 30\tFidelity = 0.500568\tKL_Divergence = 3.917796\n",
      "Epoch: 31\tFidelity = 0.500523\tKL_Divergence = 3.964150\n",
      "Epoch: 32\tFidelity = 0.500568\tKL_Divergence = 3.918187\n",
      "Epoch: 33\tFidelity = 0.500528\tKL_Divergence = 3.958909\n",
      "Epoch: 34\tFidelity = 0.500581\tKL_Divergence = 3.905217\n",
      "Epoch: 35\tFidelity = 0.500574\tKL_Divergence = 3.912617\n",
      "Epoch: 36\tFidelity = 0.500583\tKL_Divergence = 3.903839\n",
      "Epoch: 37\tFidelity = 0.500564\tKL_Divergence = 3.922378\n",
      "Epoch: 38\tFidelity = 0.500558\tKL_Divergence = 3.928024\n",
      "Epoch: 39\tFidelity = 0.500564\tKL_Divergence = 3.921843\n",
      "Epoch: 40\tFidelity = 0.500584\tKL_Divergence = 3.902532\n",
      "Epoch: 41\tFidelity = 0.500588\tKL_Divergence = 3.899223\n",
      "Epoch: 42\tFidelity = 0.500638\tKL_Divergence = 3.854026\n",
      "Epoch: 43\tFidelity = 0.500522\tKL_Divergence = 3.965454\n",
      "Epoch: 44\tFidelity = 0.500571\tKL_Divergence = 3.915750\n",
      "Epoch: 45\tFidelity = 0.500571\tKL_Divergence = 3.915376\n",
      "Epoch: 46\tFidelity = 0.500595\tKL_Divergence = 3.892906\n",
      "Epoch: 47\tFidelity = 0.500543\tKL_Divergence = 3.942747\n",
      "Epoch: 48\tFidelity = 0.500545\tKL_Divergence = 3.941048\n",
      "Epoch: 49\tFidelity = 0.500569\tKL_Divergence = 3.917458\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 12:20:12,534] Trial 667 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500680\tKL_Divergence = 3.818656\n",
      "Total time elapsed during training: 39.835 s\n",
      "Trial 667 pruned. \n",
      "Epoch: 1\tFidelity = 0.500585\tKL_Divergence = 3.901601\n",
      "Epoch: 2\tFidelity = 0.500588\tKL_Divergence = 3.899123\n",
      "Epoch: 3\tFidelity = 0.500596\tKL_Divergence = 3.891507\n",
      "Epoch: 4\tFidelity = 0.500584\tKL_Divergence = 3.902433\n",
      "Epoch: 5\tFidelity = 0.500597\tKL_Divergence = 3.890829\n",
      "Epoch: 6\tFidelity = 0.500530\tKL_Divergence = 3.956678\n",
      "Epoch: 7\tFidelity = 0.500589\tKL_Divergence = 3.898548\n",
      "Epoch: 8\tFidelity = 0.500571\tKL_Divergence = 3.915079\n",
      "Epoch: 9\tFidelity = 0.500542\tKL_Divergence = 3.943839\n",
      "Epoch: 10\tFidelity = 0.500561\tKL_Divergence = 3.924685\n",
      "Epoch: 11\tFidelity = 0.500597\tKL_Divergence = 3.891025\n",
      "Epoch: 12\tFidelity = 0.500558\tKL_Divergence = 3.927848\n",
      "Epoch: 13\tFidelity = 0.500570\tKL_Divergence = 3.915923\n",
      "Epoch: 14\tFidelity = 0.500586\tKL_Divergence = 3.900962\n",
      "Epoch: 15\tFidelity = 0.500634\tKL_Divergence = 3.857122\n",
      "Epoch: 16\tFidelity = 0.500580\tKL_Divergence = 3.906253\n",
      "Epoch: 17\tFidelity = 0.500591\tKL_Divergence = 3.895821\n",
      "Epoch: 18\tFidelity = 0.500572\tKL_Divergence = 3.913911\n",
      "Epoch: 19\tFidelity = 0.500583\tKL_Divergence = 3.904224\n",
      "Epoch: 20\tFidelity = 0.500541\tKL_Divergence = 3.945357\n",
      "Epoch: 21\tFidelity = 0.500618\tKL_Divergence = 3.871084\n",
      "Epoch: 22\tFidelity = 0.500573\tKL_Divergence = 3.913821\n",
      "Epoch: 23\tFidelity = 0.500625\tKL_Divergence = 3.864944\n",
      "Epoch: 24\tFidelity = 0.500579\tKL_Divergence = 3.907762\n",
      "Epoch: 25\tFidelity = 0.500603\tKL_Divergence = 3.884726\n",
      "Epoch: 26\tFidelity = 0.500593\tKL_Divergence = 3.893928\n",
      "Epoch: 27\tFidelity = 0.500542\tKL_Divergence = 3.944090\n",
      "Epoch: 28\tFidelity = 0.500516\tKL_Divergence = 3.971937\n",
      "Epoch: 29\tFidelity = 0.500567\tKL_Divergence = 3.919688\n",
      "Epoch: 30\tFidelity = 0.500530\tKL_Divergence = 3.956203\n",
      "Epoch: 31\tFidelity = 0.500620\tKL_Divergence = 3.869423\n",
      "Epoch: 32\tFidelity = 0.500558\tKL_Divergence = 3.928419\n",
      "Epoch: 33\tFidelity = 0.500543\tKL_Divergence = 3.942724\n",
      "Epoch: 34\tFidelity = 0.500611\tKL_Divergence = 3.878125\n",
      "Epoch: 35\tFidelity = 0.500620\tKL_Divergence = 3.869280\n",
      "Epoch: 36\tFidelity = 0.500604\tKL_Divergence = 3.884367\n",
      "Epoch: 37\tFidelity = 0.500542\tKL_Divergence = 3.944369\n",
      "Epoch: 38\tFidelity = 0.500606\tKL_Divergence = 3.882673\n",
      "Epoch: 39\tFidelity = 0.500576\tKL_Divergence = 3.910487\n",
      "Epoch: 40\tFidelity = 0.500630\tKL_Divergence = 3.861091\n",
      "Epoch: 41\tFidelity = 0.500627\tKL_Divergence = 3.863775\n",
      "Epoch: 42\tFidelity = 0.500603\tKL_Divergence = 3.884745\n",
      "Epoch: 43\tFidelity = 0.500573\tKL_Divergence = 3.913876\n",
      "Epoch: 44\tFidelity = 0.500576\tKL_Divergence = 3.910616\n",
      "Epoch: 45\tFidelity = 0.500570\tKL_Divergence = 3.915912\n",
      "Epoch: 46\tFidelity = 0.500578\tKL_Divergence = 3.908349\n",
      "Epoch: 47\tFidelity = 0.500621\tKL_Divergence = 3.868925\n",
      "Epoch: 48\tFidelity = 0.500567\tKL_Divergence = 3.919387\n",
      "Epoch: 49\tFidelity = 0.500612\tKL_Divergence = 3.877274\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 12:20:51,923] Trial 668 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500574\tKL_Divergence = 3.912163\n",
      "Total time elapsed during training: 39.195 s\n",
      "Trial 668 pruned. \n",
      "Epoch: 1\tFidelity = 0.500548\tKL_Divergence = 3.937804\n",
      "Epoch: 2\tFidelity = 0.500544\tKL_Divergence = 3.941932\n",
      "Epoch: 3\tFidelity = 0.500541\tKL_Divergence = 3.945401\n",
      "Epoch: 4\tFidelity = 0.500537\tKL_Divergence = 3.949448\n",
      "Epoch: 5\tFidelity = 0.500587\tKL_Divergence = 3.900066\n",
      "Epoch: 6\tFidelity = 0.500590\tKL_Divergence = 3.897280\n",
      "Epoch: 7\tFidelity = 0.500576\tKL_Divergence = 3.910312\n",
      "Epoch: 8\tFidelity = 0.500541\tKL_Divergence = 3.944803\n",
      "Epoch: 9\tFidelity = 0.500632\tKL_Divergence = 3.858614\n",
      "Epoch: 10\tFidelity = 0.500536\tKL_Divergence = 3.950229\n",
      "Epoch: 11\tFidelity = 0.500583\tKL_Divergence = 3.904019\n",
      "Epoch: 12\tFidelity = 0.500527\tKL_Divergence = 3.960309\n",
      "Epoch: 13\tFidelity = 0.500627\tKL_Divergence = 3.863866\n",
      "Epoch: 14\tFidelity = 0.500504\tKL_Divergence = 3.984929\n",
      "Epoch: 15\tFidelity = 0.500549\tKL_Divergence = 3.936862\n",
      "Epoch: 16\tFidelity = 0.500581\tKL_Divergence = 3.905667\n",
      "Epoch: 17\tFidelity = 0.500522\tKL_Divergence = 3.964663\n",
      "Epoch: 18\tFidelity = 0.500616\tKL_Divergence = 3.873654\n",
      "Epoch: 19\tFidelity = 0.500676\tKL_Divergence = 3.821803\n",
      "Epoch: 20\tFidelity = 0.500601\tKL_Divergence = 3.886552\n",
      "Epoch: 21\tFidelity = 0.500473\tKL_Divergence = 4.020062\n",
      "Epoch: 22\tFidelity = 0.500605\tKL_Divergence = 3.883048\n",
      "Epoch: 23\tFidelity = 0.500561\tKL_Divergence = 3.924903\n",
      "Epoch: 24\tFidelity = 0.500614\tKL_Divergence = 3.874906\n",
      "Epoch: 25\tFidelity = 0.500658\tKL_Divergence = 3.836426\n",
      "Epoch: 26\tFidelity = 0.500555\tKL_Divergence = 3.931611\n",
      "Epoch: 27\tFidelity = 0.500502\tKL_Divergence = 3.987111\n",
      "Epoch: 28\tFidelity = 0.500674\tKL_Divergence = 3.823434\n",
      "Epoch: 29\tFidelity = 0.500561\tKL_Divergence = 3.925648\n",
      "Epoch: 30\tFidelity = 0.500540\tKL_Divergence = 3.946756\n",
      "Epoch: 31\tFidelity = 0.500555\tKL_Divergence = 3.931392\n",
      "Epoch: 32\tFidelity = 0.500557\tKL_Divergence = 3.928903\n",
      "Epoch: 33\tFidelity = 0.500529\tKL_Divergence = 3.958221\n",
      "Epoch: 34\tFidelity = 0.500606\tKL_Divergence = 3.881829\n",
      "Epoch: 35\tFidelity = 0.500559\tKL_Divergence = 3.927050\n",
      "Epoch: 36\tFidelity = 0.500604\tKL_Divergence = 3.883955\n",
      "Epoch: 37\tFidelity = 0.500592\tKL_Divergence = 3.895333\n",
      "Epoch: 38\tFidelity = 0.500575\tKL_Divergence = 3.911802\n",
      "Epoch: 39\tFidelity = 0.500596\tKL_Divergence = 3.891994\n",
      "Epoch: 40\tFidelity = 0.500547\tKL_Divergence = 3.939530\n",
      "Epoch: 41\tFidelity = 0.500642\tKL_Divergence = 3.850144\n",
      "Epoch: 42\tFidelity = 0.500574\tKL_Divergence = 3.911919\n",
      "Epoch: 43\tFidelity = 0.500540\tKL_Divergence = 3.946250\n",
      "Epoch: 44\tFidelity = 0.500612\tKL_Divergence = 3.876874\n",
      "Epoch: 45\tFidelity = 0.500607\tKL_Divergence = 3.881336\n",
      "Epoch: 46\tFidelity = 0.500561\tKL_Divergence = 3.925405\n",
      "Epoch: 47\tFidelity = 0.500588\tKL_Divergence = 3.899369\n",
      "Epoch: 48\tFidelity = 0.500531\tKL_Divergence = 3.955875\n",
      "Epoch: 49\tFidelity = 0.500544\tKL_Divergence = 3.941774\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 12:21:37,516] Trial 669 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500561\tKL_Divergence = 3.925048\n",
      "Total time elapsed during training: 45.405 s\n",
      "Trial 669 pruned. \n",
      "Epoch: 1\tFidelity = 0.500570\tKL_Divergence = 3.916572\n",
      "Epoch: 2\tFidelity = 0.500544\tKL_Divergence = 3.942130\n",
      "Epoch: 3\tFidelity = 0.500541\tKL_Divergence = 3.945437\n",
      "Epoch: 4\tFidelity = 0.500518\tKL_Divergence = 3.969573\n",
      "Epoch: 5\tFidelity = 0.500566\tKL_Divergence = 3.919840\n",
      "Epoch: 6\tFidelity = 0.500570\tKL_Divergence = 3.916528\n",
      "Epoch: 7\tFidelity = 0.500552\tKL_Divergence = 3.933755\n",
      "Epoch: 8\tFidelity = 0.500566\tKL_Divergence = 3.919907\n",
      "Epoch: 9\tFidelity = 0.500528\tKL_Divergence = 3.959260\n",
      "Epoch: 10\tFidelity = 0.500501\tKL_Divergence = 3.987398\n",
      "Epoch: 11\tFidelity = 0.500552\tKL_Divergence = 3.934244\n",
      "Epoch: 12\tFidelity = 0.500529\tKL_Divergence = 3.957888\n",
      "Epoch: 13\tFidelity = 0.500567\tKL_Divergence = 3.919656\n",
      "Epoch: 14\tFidelity = 0.500557\tKL_Divergence = 3.929362\n",
      "Epoch: 15\tFidelity = 0.500586\tKL_Divergence = 3.900684\n",
      "Epoch: 16\tFidelity = 0.500520\tKL_Divergence = 3.967308\n",
      "Epoch: 17\tFidelity = 0.500563\tKL_Divergence = 3.923642\n",
      "Epoch: 18\tFidelity = 0.500598\tKL_Divergence = 3.889365\n",
      "Epoch: 19\tFidelity = 0.500558\tKL_Divergence = 3.928266\n",
      "Epoch: 20\tFidelity = 0.500592\tKL_Divergence = 3.894882\n",
      "Epoch: 21\tFidelity = 0.500544\tKL_Divergence = 3.942598\n",
      "Epoch: 22\tFidelity = 0.500560\tKL_Divergence = 3.926197\n",
      "Epoch: 23\tFidelity = 0.500547\tKL_Divergence = 3.939331\n",
      "Epoch: 24\tFidelity = 0.500545\tKL_Divergence = 3.941617\n",
      "Epoch: 25\tFidelity = 0.500588\tKL_Divergence = 3.898920\n",
      "Epoch: 26\tFidelity = 0.500565\tKL_Divergence = 3.920902\n",
      "Epoch: 27\tFidelity = 0.500550\tKL_Divergence = 3.935973\n",
      "Epoch: 28\tFidelity = 0.500521\tKL_Divergence = 3.965883\n",
      "Epoch: 29\tFidelity = 0.500511\tKL_Divergence = 3.977282\n",
      "Epoch: 30\tFidelity = 0.500567\tKL_Divergence = 3.919174\n",
      "Epoch: 31\tFidelity = 0.500580\tKL_Divergence = 3.906384\n",
      "Epoch: 32\tFidelity = 0.500567\tKL_Divergence = 3.919164\n",
      "Epoch: 33\tFidelity = 0.500537\tKL_Divergence = 3.949313\n",
      "Epoch: 34\tFidelity = 0.500537\tKL_Divergence = 3.949362\n",
      "Epoch: 35\tFidelity = 0.500546\tKL_Divergence = 3.940113\n",
      "Epoch: 36\tFidelity = 0.500588\tKL_Divergence = 3.899413\n",
      "Epoch: 37\tFidelity = 0.500591\tKL_Divergence = 3.896181\n",
      "Epoch: 38\tFidelity = 0.500567\tKL_Divergence = 3.919585\n",
      "Epoch: 39\tFidelity = 0.500509\tKL_Divergence = 3.979672\n",
      "Epoch: 40\tFidelity = 0.500546\tKL_Divergence = 3.940522\n",
      "Epoch: 41\tFidelity = 0.500507\tKL_Divergence = 3.981818\n",
      "Epoch: 42\tFidelity = 0.500534\tKL_Divergence = 3.952255\n",
      "Epoch: 43\tFidelity = 0.500547\tKL_Divergence = 3.939030\n",
      "Epoch: 44\tFidelity = 0.500511\tKL_Divergence = 3.976619\n",
      "Epoch: 45\tFidelity = 0.500580\tKL_Divergence = 3.906420\n",
      "Epoch: 46\tFidelity = 0.500564\tKL_Divergence = 3.922145\n",
      "Epoch: 47\tFidelity = 0.500569\tKL_Divergence = 3.917033\n",
      "Epoch: 48\tFidelity = 0.500547\tKL_Divergence = 3.939684\n",
      "Epoch: 49\tFidelity = 0.500528\tKL_Divergence = 3.959223\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 12:22:16,082] Trial 670 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500537\tKL_Divergence = 3.949844\n",
      "Total time elapsed during training: 38.339 s\n",
      "Trial 670 pruned. \n",
      "Epoch: 1\tFidelity = 0.500452\tKL_Divergence = 4.045474\n",
      "Epoch: 2\tFidelity = 0.500581\tKL_Divergence = 3.906237\n",
      "Epoch: 3\tFidelity = 0.500667\tKL_Divergence = 3.828977\n",
      "Epoch: 4\tFidelity = 0.500511\tKL_Divergence = 3.977095\n",
      "Epoch: 5\tFidelity = 0.500507\tKL_Divergence = 3.981307\n",
      "Epoch: 6\tFidelity = 0.500603\tKL_Divergence = 3.884713\n",
      "Epoch: 7\tFidelity = 0.500537\tKL_Divergence = 3.949737\n",
      "Epoch: 8\tFidelity = 0.500596\tKL_Divergence = 3.891118\n",
      "Epoch: 9\tFidelity = 0.500747\tKL_Divergence = 3.766576\n",
      "Epoch: 10\tFidelity = 0.500573\tKL_Divergence = 3.912927\n",
      "Epoch: 11\tFidelity = 0.500630\tKL_Divergence = 3.860964\n",
      "Epoch: 12\tFidelity = 0.500643\tKL_Divergence = 3.849086\n",
      "Epoch: 13\tFidelity = 0.500615\tKL_Divergence = 3.873798\n",
      "Epoch: 14\tFidelity = 0.500584\tKL_Divergence = 3.902387\n",
      "Epoch: 15\tFidelity = 0.500544\tKL_Divergence = 3.942088\n",
      "Epoch: 16\tFidelity = 0.500540\tKL_Divergence = 3.946638\n",
      "Epoch: 17\tFidelity = 0.500586\tKL_Divergence = 3.900998\n",
      "Epoch: 18\tFidelity = 0.500573\tKL_Divergence = 3.913360\n",
      "Epoch: 19\tFidelity = 0.500533\tKL_Divergence = 3.954008\n",
      "Epoch: 20\tFidelity = 0.500582\tKL_Divergence = 3.904802\n",
      "Epoch: 21\tFidelity = 0.500486\tKL_Divergence = 4.004686\n",
      "Epoch: 22\tFidelity = 0.500653\tKL_Divergence = 3.841231\n",
      "Epoch: 23\tFidelity = 0.500675\tKL_Divergence = 3.822396\n",
      "Epoch: 24\tFidelity = 0.500652\tKL_Divergence = 3.841648\n",
      "Epoch: 25\tFidelity = 0.500688\tKL_Divergence = 3.812031\n",
      "Epoch: 26\tFidelity = 0.500627\tKL_Divergence = 3.863644\n",
      "Epoch: 27\tFidelity = 0.500493\tKL_Divergence = 3.996757\n",
      "Epoch: 28\tFidelity = 0.500568\tKL_Divergence = 3.918698\n",
      "Epoch: 29\tFidelity = 0.500560\tKL_Divergence = 3.926424\n",
      "Epoch: 30\tFidelity = 0.500420\tKL_Divergence = 4.085341\n",
      "Epoch: 31\tFidelity = 0.500530\tKL_Divergence = 3.957213\n",
      "Epoch: 32\tFidelity = 0.500524\tKL_Divergence = 3.962883\n",
      "Epoch: 33\tFidelity = 0.500499\tKL_Divergence = 3.990024\n",
      "Epoch: 34\tFidelity = 0.500498\tKL_Divergence = 3.991084\n",
      "Epoch: 35\tFidelity = 0.500646\tKL_Divergence = 3.846757\n",
      "Epoch: 36\tFidelity = 0.500453\tKL_Divergence = 4.043558\n",
      "Epoch: 37\tFidelity = 0.500506\tKL_Divergence = 3.982346\n",
      "Epoch: 38\tFidelity = 0.500554\tKL_Divergence = 3.932127\n",
      "Epoch: 39\tFidelity = 0.500545\tKL_Divergence = 3.940874\n",
      "Epoch: 40\tFidelity = 0.500562\tKL_Divergence = 3.923926\n",
      "Epoch: 41\tFidelity = 0.500602\tKL_Divergence = 3.885944\n",
      "Epoch: 42\tFidelity = 0.500534\tKL_Divergence = 3.952084\n",
      "Epoch: 43\tFidelity = 0.500561\tKL_Divergence = 3.925231\n",
      "Epoch: 44\tFidelity = 0.500544\tKL_Divergence = 3.941985\n",
      "Epoch: 45\tFidelity = 0.500628\tKL_Divergence = 3.862774\n",
      "Epoch: 46\tFidelity = 0.500589\tKL_Divergence = 3.898043\n",
      "Epoch: 47\tFidelity = 0.500525\tKL_Divergence = 3.961543\n",
      "Epoch: 48\tFidelity = 0.500560\tKL_Divergence = 3.926448\n",
      "Epoch: 49\tFidelity = 0.500559\tKL_Divergence = 3.927652\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 12:23:35,965] Trial 671 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500528\tKL_Divergence = 3.958746\n",
      "Total time elapsed during training: 79.694 s\n",
      "Trial 671 pruned. \n",
      "Epoch: 1\tFidelity = 0.500563\tKL_Divergence = 3.923319\n",
      "Epoch: 2\tFidelity = 0.500589\tKL_Divergence = 3.898388\n",
      "Epoch: 3\tFidelity = 0.500613\tKL_Divergence = 3.876255\n",
      "Epoch: 4\tFidelity = 0.500655\tKL_Divergence = 3.839035\n",
      "Epoch: 5\tFidelity = 0.500613\tKL_Divergence = 3.876379\n",
      "Epoch: 6\tFidelity = 0.500620\tKL_Divergence = 3.869791\n",
      "Epoch: 7\tFidelity = 0.500605\tKL_Divergence = 3.882987\n",
      "Epoch: 8\tFidelity = 0.500620\tKL_Divergence = 3.869922\n",
      "Epoch: 9\tFidelity = 0.500605\tKL_Divergence = 3.883381\n",
      "Epoch: 10\tFidelity = 0.500608\tKL_Divergence = 3.880583\n",
      "Epoch: 11\tFidelity = 0.500621\tKL_Divergence = 3.869252\n",
      "Epoch: 12\tFidelity = 0.500596\tKL_Divergence = 3.891911\n",
      "Epoch: 13\tFidelity = 0.500558\tKL_Divergence = 3.928519\n",
      "Epoch: 14\tFidelity = 0.500524\tKL_Divergence = 3.963468\n",
      "Epoch: 15\tFidelity = 0.500518\tKL_Divergence = 3.969360\n",
      "Epoch: 16\tFidelity = 0.500565\tKL_Divergence = 3.921208\n",
      "Epoch: 17\tFidelity = 0.500561\tKL_Divergence = 3.924929\n",
      "Epoch: 18\tFidelity = 0.500594\tKL_Divergence = 3.893752\n",
      "Epoch: 19\tFidelity = 0.500591\tKL_Divergence = 3.896368\n",
      "Epoch: 20\tFidelity = 0.500602\tKL_Divergence = 3.886126\n",
      "Epoch: 21\tFidelity = 0.500566\tKL_Divergence = 3.920654\n",
      "Epoch: 22\tFidelity = 0.500531\tKL_Divergence = 3.955352\n",
      "Epoch: 23\tFidelity = 0.500570\tKL_Divergence = 3.916253\n",
      "Epoch: 24\tFidelity = 0.500603\tKL_Divergence = 3.885154\n",
      "Epoch: 25\tFidelity = 0.500596\tKL_Divergence = 3.891458\n",
      "Epoch: 26\tFidelity = 0.500580\tKL_Divergence = 3.907148\n",
      "Epoch: 27\tFidelity = 0.500590\tKL_Divergence = 3.897245\n",
      "Epoch: 28\tFidelity = 0.500547\tKL_Divergence = 3.939312\n",
      "Epoch: 29\tFidelity = 0.500608\tKL_Divergence = 3.880213\n",
      "Epoch: 30\tFidelity = 0.500581\tKL_Divergence = 3.905318\n",
      "Epoch: 31\tFidelity = 0.500611\tKL_Divergence = 3.878146\n",
      "Epoch: 32\tFidelity = 0.500624\tKL_Divergence = 3.865858\n",
      "Epoch: 33\tFidelity = 0.500570\tKL_Divergence = 3.915988\n",
      "Epoch: 34\tFidelity = 0.500526\tKL_Divergence = 3.961282\n",
      "Epoch: 35\tFidelity = 0.500533\tKL_Divergence = 3.953741\n",
      "Epoch: 36\tFidelity = 0.500593\tKL_Divergence = 3.894796\n",
      "Epoch: 37\tFidelity = 0.500566\tKL_Divergence = 3.920402\n",
      "Epoch: 38\tFidelity = 0.500542\tKL_Divergence = 3.943998\n",
      "Epoch: 39\tFidelity = 0.500527\tKL_Divergence = 3.959395\n",
      "Epoch: 40\tFidelity = 0.500551\tKL_Divergence = 3.934911\n",
      "Epoch: 41\tFidelity = 0.500584\tKL_Divergence = 3.903074\n",
      "Epoch: 42\tFidelity = 0.500557\tKL_Divergence = 3.929116\n",
      "Epoch: 43\tFidelity = 0.500550\tKL_Divergence = 3.936567\n",
      "Epoch: 44\tFidelity = 0.500579\tKL_Divergence = 3.907723\n",
      "Epoch: 45\tFidelity = 0.500585\tKL_Divergence = 3.902050\n",
      "Epoch: 46\tFidelity = 0.500584\tKL_Divergence = 3.903176\n",
      "Epoch: 47\tFidelity = 0.500574\tKL_Divergence = 3.912274\n",
      "Epoch: 48\tFidelity = 0.500592\tKL_Divergence = 3.895473\n",
      "Epoch: 49\tFidelity = 0.500565\tKL_Divergence = 3.921493\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 12:24:08,217] Trial 672 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500611\tKL_Divergence = 3.877546\n",
      "Total time elapsed during training: 32.062 s\n",
      "Trial 672 pruned. \n",
      "Epoch: 1\tFidelity = 0.500625\tKL_Divergence = 3.865069\n",
      "Epoch: 2\tFidelity = 0.500587\tKL_Divergence = 3.900326\n",
      "Epoch: 3\tFidelity = 0.500551\tKL_Divergence = 3.934618\n",
      "Epoch: 4\tFidelity = 0.500575\tKL_Divergence = 3.911095\n",
      "Epoch: 5\tFidelity = 0.500611\tKL_Divergence = 3.877951\n",
      "Epoch: 6\tFidelity = 0.500601\tKL_Divergence = 3.887350\n",
      "Epoch: 7\tFidelity = 0.500590\tKL_Divergence = 3.897127\n",
      "Epoch: 8\tFidelity = 0.500590\tKL_Divergence = 3.896915\n",
      "Epoch: 9\tFidelity = 0.500608\tKL_Divergence = 3.880597\n",
      "Epoch: 10\tFidelity = 0.500573\tKL_Divergence = 3.913293\n",
      "Epoch: 11\tFidelity = 0.500541\tKL_Divergence = 3.944855\n",
      "Epoch: 12\tFidelity = 0.500537\tKL_Divergence = 3.948927\n",
      "Epoch: 13\tFidelity = 0.500610\tKL_Divergence = 3.879027\n",
      "Epoch: 14\tFidelity = 0.500567\tKL_Divergence = 3.918897\n",
      "Epoch: 15\tFidelity = 0.500598\tKL_Divergence = 3.889864\n",
      "Epoch: 16\tFidelity = 0.500529\tKL_Divergence = 3.957725\n",
      "Epoch: 17\tFidelity = 0.500548\tKL_Divergence = 3.937914\n",
      "Epoch: 18\tFidelity = 0.500540\tKL_Divergence = 3.946730\n",
      "Epoch: 19\tFidelity = 0.500593\tKL_Divergence = 3.894805\n",
      "Epoch: 20\tFidelity = 0.500551\tKL_Divergence = 3.935039\n",
      "Epoch: 21\tFidelity = 0.500587\tKL_Divergence = 3.900075\n",
      "Epoch: 22\tFidelity = 0.500503\tKL_Divergence = 3.986063\n",
      "Epoch: 23\tFidelity = 0.500598\tKL_Divergence = 3.889512\n",
      "Epoch: 24\tFidelity = 0.500554\tKL_Divergence = 3.932221\n",
      "Epoch: 25\tFidelity = 0.500547\tKL_Divergence = 3.939174\n",
      "Epoch: 26\tFidelity = 0.500587\tKL_Divergence = 3.900290\n",
      "Epoch: 27\tFidelity = 0.500612\tKL_Divergence = 3.877021\n",
      "Epoch: 28\tFidelity = 0.500534\tKL_Divergence = 3.952146\n",
      "Epoch: 29\tFidelity = 0.500632\tKL_Divergence = 3.859221\n",
      "Epoch: 30\tFidelity = 0.500553\tKL_Divergence = 3.933189\n",
      "Epoch: 31\tFidelity = 0.500644\tKL_Divergence = 3.848383\n",
      "Epoch: 32\tFidelity = 0.500607\tKL_Divergence = 3.881599\n",
      "Epoch: 33\tFidelity = 0.500565\tKL_Divergence = 3.921664\n",
      "Epoch: 34\tFidelity = 0.500541\tKL_Divergence = 3.945130\n",
      "Epoch: 35\tFidelity = 0.500553\tKL_Divergence = 3.933142\n",
      "Epoch: 36\tFidelity = 0.500551\tKL_Divergence = 3.934873\n",
      "Epoch: 37\tFidelity = 0.500567\tKL_Divergence = 3.919820\n",
      "Epoch: 38\tFidelity = 0.500532\tKL_Divergence = 3.954558\n",
      "Epoch: 39\tFidelity = 0.500522\tKL_Divergence = 3.964967\n",
      "Epoch: 40\tFidelity = 0.500525\tKL_Divergence = 3.961681\n",
      "Epoch: 41\tFidelity = 0.500611\tKL_Divergence = 3.877755\n",
      "Epoch: 42\tFidelity = 0.500582\tKL_Divergence = 3.904420\n",
      "Epoch: 43\tFidelity = 0.500562\tKL_Divergence = 3.924255\n",
      "Epoch: 44\tFidelity = 0.500638\tKL_Divergence = 3.853424\n",
      "Epoch: 45\tFidelity = 0.500594\tKL_Divergence = 3.893702\n",
      "Epoch: 46\tFidelity = 0.500565\tKL_Divergence = 3.920829\n",
      "Epoch: 47\tFidelity = 0.500622\tKL_Divergence = 3.868223\n",
      "Epoch: 48\tFidelity = 0.500557\tKL_Divergence = 3.928966\n",
      "Epoch: 49\tFidelity = 0.500571\tKL_Divergence = 3.915092\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 12:24:47,343] Trial 673 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500612\tKL_Divergence = 3.877130\n",
      "Total time elapsed during training: 38.929 s\n",
      "Trial 673 pruned. \n",
      "Epoch: 1\tFidelity = 0.500637\tKL_Divergence = 3.854612\n",
      "Epoch: 2\tFidelity = 0.500590\tKL_Divergence = 3.897175\n",
      "Epoch: 3\tFidelity = 0.500608\tKL_Divergence = 3.880554\n",
      "Epoch: 4\tFidelity = 0.500667\tKL_Divergence = 3.829468\n",
      "Epoch: 5\tFidelity = 0.500489\tKL_Divergence = 4.000770\n",
      "Epoch: 6\tFidelity = 0.500572\tKL_Divergence = 3.913614\n",
      "Epoch: 7\tFidelity = 0.500532\tKL_Divergence = 3.954375\n",
      "Epoch: 8\tFidelity = 0.500554\tKL_Divergence = 3.930887\n",
      "Epoch: 9\tFidelity = 0.500575\tKL_Divergence = 3.910420\n",
      "Epoch: 10\tFidelity = 0.500603\tKL_Divergence = 3.885065\n",
      "Epoch: 11\tFidelity = 0.500509\tKL_Divergence = 3.979040\n",
      "Epoch: 12\tFidelity = 0.500605\tKL_Divergence = 3.883710\n",
      "Epoch: 13\tFidelity = 0.500537\tKL_Divergence = 3.949876\n",
      "Epoch: 14\tFidelity = 0.500635\tKL_Divergence = 3.856298\n",
      "Epoch: 15\tFidelity = 0.500598\tKL_Divergence = 3.889578\n",
      "Epoch: 16\tFidelity = 0.500502\tKL_Divergence = 3.986492\n",
      "Epoch: 17\tFidelity = 0.500586\tKL_Divergence = 3.900848\n",
      "Epoch: 18\tFidelity = 0.500506\tKL_Divergence = 3.982224\n",
      "Epoch: 19\tFidelity = 0.500554\tKL_Divergence = 3.932414\n",
      "Epoch: 20\tFidelity = 0.500539\tKL_Divergence = 3.947260\n",
      "Epoch: 21\tFidelity = 0.500588\tKL_Divergence = 3.898809\n",
      "Epoch: 22\tFidelity = 0.500564\tKL_Divergence = 3.921957\n",
      "Epoch: 23\tFidelity = 0.500572\tKL_Divergence = 3.914252\n",
      "Epoch: 24\tFidelity = 0.500650\tKL_Divergence = 3.843405\n",
      "Epoch: 25\tFidelity = 0.500636\tKL_Divergence = 3.855391\n",
      "Epoch: 26\tFidelity = 0.500623\tKL_Divergence = 3.867399\n",
      "Epoch: 27\tFidelity = 0.500493\tKL_Divergence = 3.997470\n",
      "Epoch: 28\tFidelity = 0.500504\tKL_Divergence = 3.984598\n",
      "Epoch: 29\tFidelity = 0.500493\tKL_Divergence = 3.996741\n",
      "Epoch: 30\tFidelity = 0.500531\tKL_Divergence = 3.956022\n",
      "Epoch: 31\tFidelity = 0.500587\tKL_Divergence = 3.899750\n",
      "Epoch: 32\tFidelity = 0.500552\tKL_Divergence = 3.933964\n",
      "Epoch: 33\tFidelity = 0.500534\tKL_Divergence = 3.952311\n",
      "Epoch: 34\tFidelity = 0.500546\tKL_Divergence = 3.940168\n",
      "Epoch: 35\tFidelity = 0.500514\tKL_Divergence = 3.973470\n",
      "Epoch: 36\tFidelity = 0.500525\tKL_Divergence = 3.961947\n",
      "Epoch: 37\tFidelity = 0.500571\tKL_Divergence = 3.915573\n",
      "Epoch: 38\tFidelity = 0.500616\tKL_Divergence = 3.872970\n",
      "Epoch: 39\tFidelity = 0.500573\tKL_Divergence = 3.913202\n",
      "Epoch: 40\tFidelity = 0.500574\tKL_Divergence = 3.912271\n",
      "Epoch: 41\tFidelity = 0.500598\tKL_Divergence = 3.889382\n",
      "Epoch: 42\tFidelity = 0.500558\tKL_Divergence = 3.926932\n",
      "Epoch: 43\tFidelity = 0.500630\tKL_Divergence = 3.860112\n",
      "Epoch: 44\tFidelity = 0.500592\tKL_Divergence = 3.894859\n",
      "Epoch: 45\tFidelity = 0.500572\tKL_Divergence = 3.913706\n",
      "Epoch: 46\tFidelity = 0.500488\tKL_Divergence = 4.001557\n",
      "Epoch: 47\tFidelity = 0.500542\tKL_Divergence = 3.943629\n",
      "Epoch: 48\tFidelity = 0.500489\tKL_Divergence = 4.000329\n",
      "Epoch: 49\tFidelity = 0.500509\tKL_Divergence = 3.978761\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 12:25:25,797] Trial 674 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500591\tKL_Divergence = 3.895360\n",
      "Total time elapsed during training: 38.264 s\n",
      "Trial 674 pruned. \n",
      "Epoch: 1\tFidelity = 0.500556\tKL_Divergence = 3.929427\n",
      "Epoch: 2\tFidelity = 0.500559\tKL_Divergence = 3.926760\n",
      "Epoch: 3\tFidelity = 0.500621\tKL_Divergence = 3.868549\n",
      "Epoch: 4\tFidelity = 0.500539\tKL_Divergence = 3.947076\n",
      "Epoch: 5\tFidelity = 0.500534\tKL_Divergence = 3.951636\n",
      "Epoch: 6\tFidelity = 0.500535\tKL_Divergence = 3.951527\n",
      "Epoch: 7\tFidelity = 0.500597\tKL_Divergence = 3.890521\n",
      "Epoch: 8\tFidelity = 0.500582\tKL_Divergence = 3.904515\n",
      "Epoch: 9\tFidelity = 0.500537\tKL_Divergence = 3.948820\n",
      "Epoch: 10\tFidelity = 0.500543\tKL_Divergence = 3.943124\n",
      "Epoch: 11\tFidelity = 0.500541\tKL_Divergence = 3.945035\n",
      "Epoch: 12\tFidelity = 0.500509\tKL_Divergence = 3.978840\n",
      "Epoch: 13\tFidelity = 0.500521\tKL_Divergence = 3.965915\n",
      "Epoch: 14\tFidelity = 0.500531\tKL_Divergence = 3.955200\n",
      "Epoch: 15\tFidelity = 0.500527\tKL_Divergence = 3.960312\n",
      "Epoch: 16\tFidelity = 0.500537\tKL_Divergence = 3.949559\n",
      "Epoch: 17\tFidelity = 0.500568\tKL_Divergence = 3.918496\n",
      "Epoch: 18\tFidelity = 0.500535\tKL_Divergence = 3.951830\n",
      "Epoch: 19\tFidelity = 0.500528\tKL_Divergence = 3.958386\n",
      "Epoch: 20\tFidelity = 0.500507\tKL_Divergence = 3.981352\n",
      "Epoch: 21\tFidelity = 0.500514\tKL_Divergence = 3.973925\n",
      "Epoch: 22\tFidelity = 0.500560\tKL_Divergence = 3.926148\n",
      "Epoch: 23\tFidelity = 0.500536\tKL_Divergence = 3.950073\n",
      "Epoch: 24\tFidelity = 0.500550\tKL_Divergence = 3.936527\n",
      "Epoch: 25\tFidelity = 0.500542\tKL_Divergence = 3.944428\n",
      "Epoch: 26\tFidelity = 0.500530\tKL_Divergence = 3.956559\n",
      "Epoch: 27\tFidelity = 0.500524\tKL_Divergence = 3.962687\n",
      "Epoch: 28\tFidelity = 0.500536\tKL_Divergence = 3.950682\n",
      "Epoch: 29\tFidelity = 0.500516\tKL_Divergence = 3.971142\n",
      "Epoch: 30\tFidelity = 0.500536\tKL_Divergence = 3.950603\n",
      "Epoch: 31\tFidelity = 0.500564\tKL_Divergence = 3.921938\n",
      "Epoch: 32\tFidelity = 0.500524\tKL_Divergence = 3.963360\n",
      "Epoch: 33\tFidelity = 0.500525\tKL_Divergence = 3.961872\n",
      "Epoch: 34\tFidelity = 0.500571\tKL_Divergence = 3.915131\n",
      "Epoch: 35\tFidelity = 0.500565\tKL_Divergence = 3.921182\n",
      "Epoch: 36\tFidelity = 0.500537\tKL_Divergence = 3.949530\n",
      "Epoch: 37\tFidelity = 0.500582\tKL_Divergence = 3.904478\n",
      "Epoch: 38\tFidelity = 0.500514\tKL_Divergence = 3.973660\n",
      "Epoch: 39\tFidelity = 0.500506\tKL_Divergence = 3.982823\n",
      "Epoch: 40\tFidelity = 0.500579\tKL_Divergence = 3.908047\n",
      "Epoch: 41\tFidelity = 0.500551\tKL_Divergence = 3.934856\n",
      "Epoch: 42\tFidelity = 0.500563\tKL_Divergence = 3.923433\n",
      "Epoch: 43\tFidelity = 0.500555\tKL_Divergence = 3.931465\n",
      "Epoch: 44\tFidelity = 0.500582\tKL_Divergence = 3.905203\n",
      "Epoch: 45\tFidelity = 0.500567\tKL_Divergence = 3.919754\n",
      "Epoch: 46\tFidelity = 0.500600\tKL_Divergence = 3.888355\n",
      "Epoch: 47\tFidelity = 0.500576\tKL_Divergence = 3.910569\n",
      "Epoch: 48\tFidelity = 0.500579\tKL_Divergence = 3.907974\n",
      "Epoch: 49\tFidelity = 0.500605\tKL_Divergence = 3.882950\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 12:26:11,132] Trial 675 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500564\tKL_Divergence = 3.921878\n",
      "Total time elapsed during training: 45.133 s\n",
      "Trial 675 pruned. \n",
      "Epoch: 1\tFidelity = 0.500611\tKL_Divergence = 3.878097\n",
      "Epoch: 2\tFidelity = 0.500570\tKL_Divergence = 3.916621\n",
      "Epoch: 3\tFidelity = 0.500620\tKL_Divergence = 3.869420\n",
      "Epoch: 4\tFidelity = 0.500551\tKL_Divergence = 3.935134\n",
      "Epoch: 5\tFidelity = 0.500641\tKL_Divergence = 3.851601\n",
      "Epoch: 6\tFidelity = 0.500609\tKL_Divergence = 3.879986\n",
      "Epoch: 7\tFidelity = 0.500623\tKL_Divergence = 3.866690\n",
      "Epoch: 8\tFidelity = 0.500593\tKL_Divergence = 3.894061\n",
      "Epoch: 9\tFidelity = 0.500641\tKL_Divergence = 3.851222\n",
      "Epoch: 10\tFidelity = 0.500558\tKL_Divergence = 3.928463\n",
      "Epoch: 11\tFidelity = 0.500545\tKL_Divergence = 3.941530\n",
      "Epoch: 12\tFidelity = 0.500628\tKL_Divergence = 3.862796\n",
      "Epoch: 13\tFidelity = 0.500581\tKL_Divergence = 3.905427\n",
      "Epoch: 14\tFidelity = 0.500544\tKL_Divergence = 3.942683\n",
      "Epoch: 15\tFidelity = 0.500573\tKL_Divergence = 3.913495\n",
      "Epoch: 16\tFidelity = 0.500628\tKL_Divergence = 3.862932\n",
      "Epoch: 17\tFidelity = 0.500598\tKL_Divergence = 3.889979\n",
      "Epoch: 18\tFidelity = 0.500631\tKL_Divergence = 3.859980\n",
      "Epoch: 19\tFidelity = 0.500628\tKL_Divergence = 3.862584\n",
      "Epoch: 20\tFidelity = 0.500541\tKL_Divergence = 3.945833\n",
      "Epoch: 21\tFidelity = 0.500575\tKL_Divergence = 3.911686\n",
      "Epoch: 22\tFidelity = 0.500518\tKL_Divergence = 3.969074\n",
      "Epoch: 23\tFidelity = 0.500550\tKL_Divergence = 3.936528\n",
      "Epoch: 24\tFidelity = 0.500570\tKL_Divergence = 3.916780\n",
      "Epoch: 25\tFidelity = 0.500590\tKL_Divergence = 3.897444\n",
      "Epoch: 26\tFidelity = 0.500672\tKL_Divergence = 3.824769\n",
      "Epoch: 27\tFidelity = 0.500614\tKL_Divergence = 3.875334\n",
      "Epoch: 28\tFidelity = 0.500637\tKL_Divergence = 3.854888\n",
      "Epoch: 29\tFidelity = 0.500584\tKL_Divergence = 3.903238\n",
      "Epoch: 30\tFidelity = 0.500552\tKL_Divergence = 3.934054\n",
      "Epoch: 31\tFidelity = 0.500566\tKL_Divergence = 3.920670\n",
      "Epoch: 32\tFidelity = 0.500513\tKL_Divergence = 3.974708\n",
      "Epoch: 33\tFidelity = 0.500523\tKL_Divergence = 3.964617\n",
      "Epoch: 34\tFidelity = 0.500493\tKL_Divergence = 3.996888\n",
      "Epoch: 35\tFidelity = 0.500504\tKL_Divergence = 3.984803\n",
      "Epoch: 36\tFidelity = 0.500518\tKL_Divergence = 3.969332\n",
      "Epoch: 37\tFidelity = 0.500561\tKL_Divergence = 3.925089\n",
      "Epoch: 38\tFidelity = 0.500582\tKL_Divergence = 3.904463\n",
      "Epoch: 39\tFidelity = 0.500545\tKL_Divergence = 3.941053\n",
      "Epoch: 40\tFidelity = 0.500582\tKL_Divergence = 3.905111\n",
      "Epoch: 41\tFidelity = 0.500531\tKL_Divergence = 3.955289\n",
      "Epoch: 42\tFidelity = 0.500627\tKL_Divergence = 3.863898\n",
      "Epoch: 43\tFidelity = 0.500579\tKL_Divergence = 3.907761\n",
      "Epoch: 44\tFidelity = 0.500550\tKL_Divergence = 3.936315\n",
      "Epoch: 45\tFidelity = 0.500512\tKL_Divergence = 3.976483\n",
      "Epoch: 46\tFidelity = 0.500483\tKL_Divergence = 4.008076\n",
      "Epoch: 47\tFidelity = 0.500583\tKL_Divergence = 3.904229\n",
      "Epoch: 48\tFidelity = 0.500609\tKL_Divergence = 3.879946\n",
      "Epoch: 49\tFidelity = 0.500562\tKL_Divergence = 3.924179\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 12:26:43,741] Trial 676 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500541\tKL_Divergence = 3.945800\n",
      "Total time elapsed during training: 32.419 s\n",
      "Trial 676 pruned. \n",
      "Epoch: 1\tFidelity = 0.500574\tKL_Divergence = 3.912863\n",
      "Epoch: 2\tFidelity = 0.500559\tKL_Divergence = 3.926930\n",
      "Epoch: 3\tFidelity = 0.500542\tKL_Divergence = 3.944299\n",
      "Epoch: 4\tFidelity = 0.500548\tKL_Divergence = 3.938107\n",
      "Epoch: 5\tFidelity = 0.500589\tKL_Divergence = 3.898005\n",
      "Epoch: 6\tFidelity = 0.500535\tKL_Divergence = 3.951172\n",
      "Epoch: 7\tFidelity = 0.500560\tKL_Divergence = 3.926144\n",
      "Epoch: 8\tFidelity = 0.500530\tKL_Divergence = 3.957302\n",
      "Epoch: 9\tFidelity = 0.500512\tKL_Divergence = 3.975364\n",
      "Epoch: 10\tFidelity = 0.500646\tKL_Divergence = 3.847219\n",
      "Epoch: 11\tFidelity = 0.500549\tKL_Divergence = 3.937694\n",
      "Epoch: 12\tFidelity = 0.500510\tKL_Divergence = 3.978278\n",
      "Epoch: 13\tFidelity = 0.500522\tKL_Divergence = 3.965536\n",
      "Epoch: 14\tFidelity = 0.500577\tKL_Divergence = 3.909278\n",
      "Epoch: 15\tFidelity = 0.500555\tKL_Divergence = 3.930903\n",
      "Epoch: 16\tFidelity = 0.500585\tKL_Divergence = 3.902204\n",
      "Epoch: 17\tFidelity = 0.500504\tKL_Divergence = 3.984199\n",
      "Epoch: 18\tFidelity = 0.500627\tKL_Divergence = 3.863274\n",
      "Epoch: 19\tFidelity = 0.500489\tKL_Divergence = 4.000887\n",
      "Epoch: 20\tFidelity = 0.500577\tKL_Divergence = 3.909733\n",
      "Epoch: 21\tFidelity = 0.500501\tKL_Divergence = 3.988209\n",
      "Epoch: 22\tFidelity = 0.500656\tKL_Divergence = 3.838647\n",
      "Epoch: 23\tFidelity = 0.500543\tKL_Divergence = 3.943857\n",
      "Epoch: 24\tFidelity = 0.500679\tKL_Divergence = 3.819389\n",
      "Epoch: 25\tFidelity = 0.500580\tKL_Divergence = 3.906522\n",
      "Epoch: 26\tFidelity = 0.500522\tKL_Divergence = 3.965281\n",
      "Epoch: 27\tFidelity = 0.500576\tKL_Divergence = 3.910779\n",
      "Epoch: 28\tFidelity = 0.500573\tKL_Divergence = 3.912991\n",
      "Epoch: 29\tFidelity = 0.500514\tKL_Divergence = 3.973898\n",
      "Epoch: 30\tFidelity = 0.500636\tKL_Divergence = 3.855825\n",
      "Epoch: 31\tFidelity = 0.500588\tKL_Divergence = 3.899231\n",
      "Epoch: 32\tFidelity = 0.500633\tKL_Divergence = 3.857868\n",
      "Epoch: 33\tFidelity = 0.500623\tKL_Divergence = 3.867268\n",
      "Epoch: 34\tFidelity = 0.500587\tKL_Divergence = 3.899680\n",
      "Epoch: 35\tFidelity = 0.500471\tKL_Divergence = 4.022352\n",
      "Epoch: 36\tFidelity = 0.500493\tKL_Divergence = 3.996813\n",
      "Epoch: 37\tFidelity = 0.500468\tKL_Divergence = 4.026013\n",
      "Epoch: 38\tFidelity = 0.500449\tKL_Divergence = 4.049139\n",
      "Epoch: 39\tFidelity = 0.500541\tKL_Divergence = 3.945100\n",
      "Epoch: 40\tFidelity = 0.500565\tKL_Divergence = 3.921042\n",
      "Epoch: 41\tFidelity = 0.500499\tKL_Divergence = 3.990892\n",
      "Epoch: 42\tFidelity = 0.500578\tKL_Divergence = 3.908898\n",
      "Epoch: 43\tFidelity = 0.500558\tKL_Divergence = 3.928126\n",
      "Epoch: 44\tFidelity = 0.500587\tKL_Divergence = 3.900173\n",
      "Epoch: 45\tFidelity = 0.500492\tKL_Divergence = 3.998356\n",
      "Epoch: 46\tFidelity = 0.500515\tKL_Divergence = 3.972885\n",
      "Epoch: 47\tFidelity = 0.500576\tKL_Divergence = 3.910610\n",
      "Epoch: 48\tFidelity = 0.500521\tKL_Divergence = 3.965965\n",
      "Epoch: 49\tFidelity = 0.500455\tKL_Divergence = 4.042004\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 12:28:05,526] Trial 677 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500496\tKL_Divergence = 3.993330\n",
      "Total time elapsed during training: 81.586 s\n",
      "Trial 677 pruned. \n",
      "Epoch: 1\tFidelity = 0.500461\tKL_Divergence = 4.033930\n",
      "Epoch: 2\tFidelity = 0.500596\tKL_Divergence = 3.891405\n",
      "Epoch: 3\tFidelity = 0.500473\tKL_Divergence = 4.019196\n",
      "Epoch: 4\tFidelity = 0.500639\tKL_Divergence = 3.852967\n",
      "Epoch: 5\tFidelity = 0.500536\tKL_Divergence = 3.950553\n",
      "Epoch: 6\tFidelity = 0.500676\tKL_Divergence = 3.821878\n",
      "Epoch: 7\tFidelity = 0.500560\tKL_Divergence = 3.925874\n",
      "Epoch: 8\tFidelity = 0.500559\tKL_Divergence = 3.926889\n",
      "Epoch: 9\tFidelity = 0.500493\tKL_Divergence = 3.996688\n",
      "Epoch: 10\tFidelity = 0.500519\tKL_Divergence = 3.968522\n",
      "Epoch: 11\tFidelity = 0.500669\tKL_Divergence = 3.827774\n",
      "Epoch: 12\tFidelity = 0.500491\tKL_Divergence = 3.998760\n",
      "Epoch: 13\tFidelity = 0.500528\tKL_Divergence = 3.959327\n",
      "Epoch: 14\tFidelity = 0.500663\tKL_Divergence = 3.832311\n",
      "Epoch: 15\tFidelity = 0.500562\tKL_Divergence = 3.924075\n",
      "Epoch: 16\tFidelity = 0.500552\tKL_Divergence = 3.934261\n",
      "Epoch: 17\tFidelity = 0.500502\tKL_Divergence = 3.986754\n",
      "Epoch: 18\tFidelity = 0.500573\tKL_Divergence = 3.913885\n",
      "Epoch: 19\tFidelity = 0.500512\tKL_Divergence = 3.976386\n",
      "Epoch: 20\tFidelity = 0.500678\tKL_Divergence = 3.819920\n",
      "Epoch: 21\tFidelity = 0.500499\tKL_Divergence = 3.990020\n",
      "Epoch: 22\tFidelity = 0.500473\tKL_Divergence = 4.020245\n",
      "Epoch: 23\tFidelity = 0.500666\tKL_Divergence = 3.829679\n",
      "Epoch: 24\tFidelity = 0.500609\tKL_Divergence = 3.879612\n",
      "Epoch: 25\tFidelity = 0.500517\tKL_Divergence = 3.970839\n",
      "Epoch: 26\tFidelity = 0.500473\tKL_Divergence = 4.020002\n",
      "Epoch: 27\tFidelity = 0.500544\tKL_Divergence = 3.942723\n",
      "Epoch: 28\tFidelity = 0.500587\tKL_Divergence = 3.900039\n",
      "Epoch: 29\tFidelity = 0.500692\tKL_Divergence = 3.808857\n",
      "Epoch: 30\tFidelity = 0.500438\tKL_Divergence = 4.063156\n",
      "Epoch: 31\tFidelity = 0.500664\tKL_Divergence = 3.831675\n",
      "Epoch: 32\tFidelity = 0.500586\tKL_Divergence = 3.900874\n",
      "Epoch: 33\tFidelity = 0.500647\tKL_Divergence = 3.845503\n",
      "Epoch: 34\tFidelity = 0.500603\tKL_Divergence = 3.884518\n",
      "Epoch: 35\tFidelity = 0.500582\tKL_Divergence = 3.904188\n",
      "Epoch: 36\tFidelity = 0.500620\tKL_Divergence = 3.869399\n",
      "Epoch: 37\tFidelity = 0.500600\tKL_Divergence = 3.888226\n",
      "Epoch: 38\tFidelity = 0.500580\tKL_Divergence = 3.906348\n",
      "Epoch: 39\tFidelity = 0.500447\tKL_Divergence = 4.051137\n",
      "Epoch: 40\tFidelity = 0.500451\tKL_Divergence = 4.046102\n",
      "Epoch: 41\tFidelity = 0.500526\tKL_Divergence = 3.960293\n",
      "Epoch: 42\tFidelity = 0.500497\tKL_Divergence = 3.992846\n",
      "Epoch: 43\tFidelity = 0.500428\tKL_Divergence = 4.075525\n",
      "Epoch: 44\tFidelity = 0.500639\tKL_Divergence = 3.852749\n",
      "Epoch: 45\tFidelity = 0.500458\tKL_Divergence = 4.036868\n",
      "Epoch: 46\tFidelity = 0.500510\tKL_Divergence = 3.976652\n",
      "Epoch: 47\tFidelity = 0.500510\tKL_Divergence = 3.978105\n",
      "Epoch: 48\tFidelity = 0.500657\tKL_Divergence = 3.836995\n",
      "Epoch: 49\tFidelity = 0.500549\tKL_Divergence = 3.936877\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 12:29:04,933] Trial 678 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500567\tKL_Divergence = 3.919188\n",
      "Total time elapsed during training: 59.204 s\n",
      "Trial 678 pruned. \n",
      "Epoch: 1\tFidelity = 0.500616\tKL_Divergence = 3.873490\n",
      "Epoch: 2\tFidelity = 0.500570\tKL_Divergence = 3.916086\n",
      "Epoch: 3\tFidelity = 0.500594\tKL_Divergence = 3.892785\n",
      "Epoch: 4\tFidelity = 0.500554\tKL_Divergence = 3.931929\n",
      "Epoch: 5\tFidelity = 0.500542\tKL_Divergence = 3.944071\n",
      "Epoch: 6\tFidelity = 0.500576\tKL_Divergence = 3.910212\n",
      "Epoch: 7\tFidelity = 0.500644\tKL_Divergence = 3.848259\n",
      "Epoch: 8\tFidelity = 0.500595\tKL_Divergence = 3.892278\n",
      "Epoch: 9\tFidelity = 0.500548\tKL_Divergence = 3.938280\n",
      "Epoch: 10\tFidelity = 0.500579\tKL_Divergence = 3.907093\n",
      "Epoch: 11\tFidelity = 0.500559\tKL_Divergence = 3.926700\n",
      "Epoch: 12\tFidelity = 0.500560\tKL_Divergence = 3.925767\n",
      "Epoch: 13\tFidelity = 0.500530\tKL_Divergence = 3.956656\n",
      "Epoch: 14\tFidelity = 0.500550\tKL_Divergence = 3.935782\n",
      "Epoch: 15\tFidelity = 0.500525\tKL_Divergence = 3.961640\n",
      "Epoch: 16\tFidelity = 0.500576\tKL_Divergence = 3.910222\n",
      "Epoch: 17\tFidelity = 0.500566\tKL_Divergence = 3.920402\n",
      "Epoch: 18\tFidelity = 0.500616\tKL_Divergence = 3.873608\n",
      "Epoch: 19\tFidelity = 0.500560\tKL_Divergence = 3.926506\n",
      "Epoch: 20\tFidelity = 0.500605\tKL_Divergence = 3.883085\n",
      "Epoch: 21\tFidelity = 0.500591\tKL_Divergence = 3.895976\n",
      "Epoch: 22\tFidelity = 0.500569\tKL_Divergence = 3.917227\n",
      "Epoch: 23\tFidelity = 0.500586\tKL_Divergence = 3.900534\n",
      "Epoch: 24\tFidelity = 0.500617\tKL_Divergence = 3.872597\n",
      "Epoch: 25\tFidelity = 0.500634\tKL_Divergence = 3.857423\n",
      "Epoch: 26\tFidelity = 0.500551\tKL_Divergence = 3.934802\n",
      "Epoch: 27\tFidelity = 0.500537\tKL_Divergence = 3.949352\n",
      "Epoch: 28\tFidelity = 0.500552\tKL_Divergence = 3.933569\n",
      "Epoch: 29\tFidelity = 0.500592\tKL_Divergence = 3.895249\n",
      "Epoch: 30\tFidelity = 0.500594\tKL_Divergence = 3.893260\n",
      "Epoch: 31\tFidelity = 0.500556\tKL_Divergence = 3.929679\n",
      "Epoch: 32\tFidelity = 0.500506\tKL_Divergence = 3.982186\n",
      "Epoch: 33\tFidelity = 0.500548\tKL_Divergence = 3.937524\n",
      "Epoch: 34\tFidelity = 0.500685\tKL_Divergence = 3.813983\n",
      "Epoch: 35\tFidelity = 0.500545\tKL_Divergence = 3.940791\n",
      "Epoch: 36\tFidelity = 0.500596\tKL_Divergence = 3.891608\n",
      "Epoch: 37\tFidelity = 0.500635\tKL_Divergence = 3.856651\n",
      "Epoch: 38\tFidelity = 0.500568\tKL_Divergence = 3.917828\n",
      "Epoch: 39\tFidelity = 0.500544\tKL_Divergence = 3.941920\n",
      "Epoch: 40\tFidelity = 0.500622\tKL_Divergence = 3.867817\n",
      "Epoch: 41\tFidelity = 0.500607\tKL_Divergence = 3.881141\n",
      "Epoch: 42\tFidelity = 0.500627\tKL_Divergence = 3.863044\n",
      "Epoch: 43\tFidelity = 0.500586\tKL_Divergence = 3.900946\n",
      "Epoch: 44\tFidelity = 0.500572\tKL_Divergence = 3.913970\n",
      "Epoch: 45\tFidelity = 0.500566\tKL_Divergence = 3.920030\n",
      "Epoch: 46\tFidelity = 0.500553\tKL_Divergence = 3.932773\n",
      "Epoch: 47\tFidelity = 0.500596\tKL_Divergence = 3.891432\n",
      "Epoch: 48\tFidelity = 0.500656\tKL_Divergence = 3.838253\n",
      "Epoch: 49\tFidelity = 0.500573\tKL_Divergence = 3.913647\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 12:29:44,366] Trial 679 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500614\tKL_Divergence = 3.875109\n",
      "Total time elapsed during training: 39.219 s\n",
      "Trial 679 pruned. \n",
      "Epoch: 1\tFidelity = 0.500628\tKL_Divergence = 3.861904\n",
      "Epoch: 2\tFidelity = 0.500559\tKL_Divergence = 3.926775\n",
      "Epoch: 3\tFidelity = 0.500628\tKL_Divergence = 3.862380\n",
      "Epoch: 4\tFidelity = 0.500539\tKL_Divergence = 3.947431\n",
      "Epoch: 5\tFidelity = 0.500544\tKL_Divergence = 3.941627\n",
      "Epoch: 6\tFidelity = 0.500645\tKL_Divergence = 3.847529\n",
      "Epoch: 7\tFidelity = 0.500652\tKL_Divergence = 3.841359\n",
      "Epoch: 8\tFidelity = 0.500578\tKL_Divergence = 3.907670\n",
      "Epoch: 9\tFidelity = 0.500617\tKL_Divergence = 3.871564\n",
      "Epoch: 10\tFidelity = 0.500591\tKL_Divergence = 3.895874\n",
      "Epoch: 11\tFidelity = 0.500641\tKL_Divergence = 3.851066\n",
      "Epoch: 12\tFidelity = 0.500629\tKL_Divergence = 3.861652\n",
      "Epoch: 13\tFidelity = 0.500601\tKL_Divergence = 3.886668\n",
      "Epoch: 14\tFidelity = 0.500591\tKL_Divergence = 3.896022\n",
      "Epoch: 15\tFidelity = 0.500643\tKL_Divergence = 3.848345\n",
      "Epoch: 16\tFidelity = 0.500644\tKL_Divergence = 3.847609\n",
      "Epoch: 17\tFidelity = 0.500581\tKL_Divergence = 3.905297\n",
      "Epoch: 18\tFidelity = 0.500596\tKL_Divergence = 3.890767\n",
      "Epoch: 19\tFidelity = 0.500635\tKL_Divergence = 3.855914\n",
      "Epoch: 20\tFidelity = 0.500565\tKL_Divergence = 3.920683\n",
      "Epoch: 21\tFidelity = 0.500656\tKL_Divergence = 3.838197\n",
      "Epoch: 22\tFidelity = 0.500575\tKL_Divergence = 3.910920\n",
      "Epoch: 23\tFidelity = 0.500585\tKL_Divergence = 3.901321\n",
      "Epoch: 24\tFidelity = 0.500624\tKL_Divergence = 3.866125\n",
      "Epoch: 25\tFidelity = 0.500542\tKL_Divergence = 3.943799\n",
      "Epoch: 26\tFidelity = 0.500623\tKL_Divergence = 3.867317\n",
      "Epoch: 27\tFidelity = 0.500568\tKL_Divergence = 3.918193\n",
      "Epoch: 28\tFidelity = 0.500547\tKL_Divergence = 3.939095\n",
      "Epoch: 29\tFidelity = 0.500577\tKL_Divergence = 3.909218\n",
      "Epoch: 30\tFidelity = 0.500588\tKL_Divergence = 3.899242\n",
      "Epoch: 31\tFidelity = 0.500554\tKL_Divergence = 3.931740\n",
      "Epoch: 32\tFidelity = 0.500567\tKL_Divergence = 3.919019\n",
      "Epoch: 33\tFidelity = 0.500635\tKL_Divergence = 3.856375\n",
      "Epoch: 34\tFidelity = 0.500598\tKL_Divergence = 3.889044\n",
      "Epoch: 35\tFidelity = 0.500552\tKL_Divergence = 3.933309\n",
      "Epoch: 36\tFidelity = 0.500552\tKL_Divergence = 3.933714\n",
      "Epoch: 37\tFidelity = 0.500557\tKL_Divergence = 3.929096\n",
      "Epoch: 38\tFidelity = 0.500586\tKL_Divergence = 3.900180\n",
      "Epoch: 39\tFidelity = 0.500584\tKL_Divergence = 3.902852\n",
      "Epoch: 40\tFidelity = 0.500554\tKL_Divergence = 3.931623\n",
      "Epoch: 41\tFidelity = 0.500603\tKL_Divergence = 3.885278\n",
      "Epoch: 42\tFidelity = 0.500614\tKL_Divergence = 3.875185\n",
      "Epoch: 43\tFidelity = 0.500541\tKL_Divergence = 3.945220\n",
      "Epoch: 44\tFidelity = 0.500534\tKL_Divergence = 3.952767\n",
      "Epoch: 45\tFidelity = 0.500536\tKL_Divergence = 3.950586\n",
      "Epoch: 46\tFidelity = 0.500577\tKL_Divergence = 3.908393\n",
      "Epoch: 47\tFidelity = 0.500576\tKL_Divergence = 3.910031\n",
      "Epoch: 48\tFidelity = 0.500556\tKL_Divergence = 3.929534\n",
      "Epoch: 49\tFidelity = 0.500592\tKL_Divergence = 3.895186\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 12:30:23,343] Trial 680 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500558\tKL_Divergence = 3.927134\n",
      "Total time elapsed during training: 38.782 s\n",
      "Trial 680 pruned. \n",
      "Epoch: 1\tFidelity = 0.500565\tKL_Divergence = 3.920373\n",
      "Epoch: 2\tFidelity = 0.500586\tKL_Divergence = 3.900333\n",
      "Epoch: 3\tFidelity = 0.500552\tKL_Divergence = 3.933686\n",
      "Epoch: 4\tFidelity = 0.500552\tKL_Divergence = 3.934086\n",
      "Epoch: 5\tFidelity = 0.500571\tKL_Divergence = 3.914437\n",
      "Epoch: 6\tFidelity = 0.500572\tKL_Divergence = 3.913690\n",
      "Epoch: 7\tFidelity = 0.500618\tKL_Divergence = 3.871184\n",
      "Epoch: 8\tFidelity = 0.500596\tKL_Divergence = 3.891234\n",
      "Epoch: 9\tFidelity = 0.500575\tKL_Divergence = 3.911045\n",
      "Epoch: 10\tFidelity = 0.500563\tKL_Divergence = 3.922846\n",
      "Epoch: 11\tFidelity = 0.500553\tKL_Divergence = 3.932506\n",
      "Epoch: 12\tFidelity = 0.500563\tKL_Divergence = 3.922952\n",
      "Epoch: 13\tFidelity = 0.500535\tKL_Divergence = 3.951650\n",
      "Epoch: 14\tFidelity = 0.500586\tKL_Divergence = 3.900963\n",
      "Epoch: 15\tFidelity = 0.500551\tKL_Divergence = 3.935110\n",
      "Epoch: 16\tFidelity = 0.500576\tKL_Divergence = 3.910175\n",
      "Epoch: 17\tFidelity = 0.500565\tKL_Divergence = 3.921008\n",
      "Epoch: 18\tFidelity = 0.500590\tKL_Divergence = 3.896898\n",
      "Epoch: 19\tFidelity = 0.500590\tKL_Divergence = 3.897255\n",
      "Epoch: 20\tFidelity = 0.500578\tKL_Divergence = 3.908115\n",
      "Epoch: 21\tFidelity = 0.500536\tKL_Divergence = 3.949921\n",
      "Epoch: 22\tFidelity = 0.500555\tKL_Divergence = 3.931371\n",
      "Epoch: 23\tFidelity = 0.500606\tKL_Divergence = 3.882565\n",
      "Epoch: 24\tFidelity = 0.500548\tKL_Divergence = 3.937843\n",
      "Epoch: 25\tFidelity = 0.500579\tKL_Divergence = 3.907162\n",
      "Epoch: 26\tFidelity = 0.500599\tKL_Divergence = 3.888163\n",
      "Epoch: 27\tFidelity = 0.500542\tKL_Divergence = 3.943895\n",
      "Epoch: 28\tFidelity = 0.500541\tKL_Divergence = 3.945133\n",
      "Epoch: 29\tFidelity = 0.500572\tKL_Divergence = 3.914233\n",
      "Epoch: 30\tFidelity = 0.500585\tKL_Divergence = 3.902005\n",
      "Epoch: 31\tFidelity = 0.500570\tKL_Divergence = 3.916517\n",
      "Epoch: 32\tFidelity = 0.500543\tKL_Divergence = 3.943172\n",
      "Epoch: 33\tFidelity = 0.500566\tKL_Divergence = 3.919806\n",
      "Epoch: 34\tFidelity = 0.500599\tKL_Divergence = 3.889013\n",
      "Epoch: 35\tFidelity = 0.500542\tKL_Divergence = 3.943829\n",
      "Epoch: 36\tFidelity = 0.500515\tKL_Divergence = 3.972118\n",
      "Epoch: 37\tFidelity = 0.500574\tKL_Divergence = 3.911917\n",
      "Epoch: 38\tFidelity = 0.500566\tKL_Divergence = 3.919965\n",
      "Epoch: 39\tFidelity = 0.500573\tKL_Divergence = 3.912873\n",
      "Epoch: 40\tFidelity = 0.500590\tKL_Divergence = 3.897203\n",
      "Epoch: 41\tFidelity = 0.500614\tKL_Divergence = 3.874983\n",
      "Epoch: 42\tFidelity = 0.500553\tKL_Divergence = 3.933288\n",
      "Epoch: 43\tFidelity = 0.500520\tKL_Divergence = 3.967658\n",
      "Epoch: 44\tFidelity = 0.500530\tKL_Divergence = 3.956846\n",
      "Epoch: 45\tFidelity = 0.500545\tKL_Divergence = 3.941513\n",
      "Epoch: 46\tFidelity = 0.500563\tKL_Divergence = 3.922823\n",
      "Epoch: 47\tFidelity = 0.500599\tKL_Divergence = 3.888873\n",
      "Epoch: 48\tFidelity = 0.500555\tKL_Divergence = 3.930608\n",
      "Epoch: 49\tFidelity = 0.500578\tKL_Divergence = 3.908129\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 12:31:02,622] Trial 681 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500605\tKL_Divergence = 3.883025\n",
      "Total time elapsed during training: 39.089 s\n",
      "Trial 681 pruned. \n",
      "Epoch: 1\tFidelity = 0.500537\tKL_Divergence = 3.949167\n",
      "Epoch: 2\tFidelity = 0.500541\tKL_Divergence = 3.944952\n",
      "Epoch: 3\tFidelity = 0.500559\tKL_Divergence = 3.927618\n",
      "Epoch: 4\tFidelity = 0.500557\tKL_Divergence = 3.929120\n",
      "Epoch: 5\tFidelity = 0.500532\tKL_Divergence = 3.954495\n",
      "Epoch: 6\tFidelity = 0.500583\tKL_Divergence = 3.903540\n",
      "Epoch: 7\tFidelity = 0.500532\tKL_Divergence = 3.954568\n",
      "Epoch: 8\tFidelity = 0.500578\tKL_Divergence = 3.908608\n",
      "Epoch: 9\tFidelity = 0.500576\tKL_Divergence = 3.910147\n",
      "Epoch: 10\tFidelity = 0.500459\tKL_Divergence = 4.037090\n",
      "Epoch: 11\tFidelity = 0.500532\tKL_Divergence = 3.954244\n",
      "Epoch: 12\tFidelity = 0.500559\tKL_Divergence = 3.926944\n",
      "Epoch: 13\tFidelity = 0.500619\tKL_Divergence = 3.870965\n",
      "Epoch: 14\tFidelity = 0.500553\tKL_Divergence = 3.932753\n",
      "Epoch: 15\tFidelity = 0.500621\tKL_Divergence = 3.869264\n",
      "Epoch: 16\tFidelity = 0.500538\tKL_Divergence = 3.948653\n",
      "Epoch: 17\tFidelity = 0.500571\tKL_Divergence = 3.915689\n",
      "Epoch: 18\tFidelity = 0.500600\tKL_Divergence = 3.887620\n",
      "Epoch: 19\tFidelity = 0.500518\tKL_Divergence = 3.969481\n",
      "Epoch: 20\tFidelity = 0.500588\tKL_Divergence = 3.899102\n",
      "Epoch: 21\tFidelity = 0.500487\tKL_Divergence = 4.004217\n",
      "Epoch: 22\tFidelity = 0.500524\tKL_Divergence = 3.962723\n",
      "Epoch: 23\tFidelity = 0.500574\tKL_Divergence = 3.912173\n",
      "Epoch: 24\tFidelity = 0.500533\tKL_Divergence = 3.953231\n",
      "Epoch: 25\tFidelity = 0.500569\tKL_Divergence = 3.916952\n",
      "Epoch: 26\tFidelity = 0.500609\tKL_Divergence = 3.879697\n",
      "Epoch: 27\tFidelity = 0.500564\tKL_Divergence = 3.922522\n",
      "Epoch: 28\tFidelity = 0.500623\tKL_Divergence = 3.867057\n",
      "Epoch: 29\tFidelity = 0.500581\tKL_Divergence = 3.906053\n",
      "Epoch: 30\tFidelity = 0.500675\tKL_Divergence = 3.822153\n",
      "Epoch: 31\tFidelity = 0.500552\tKL_Divergence = 3.933695\n",
      "Epoch: 32\tFidelity = 0.500573\tKL_Divergence = 3.912939\n",
      "Epoch: 33\tFidelity = 0.500588\tKL_Divergence = 3.898779\n",
      "Epoch: 34\tFidelity = 0.500549\tKL_Divergence = 3.937562\n",
      "Epoch: 35\tFidelity = 0.500535\tKL_Divergence = 3.951816\n",
      "Epoch: 36\tFidelity = 0.500573\tKL_Divergence = 3.913274\n",
      "Epoch: 37\tFidelity = 0.500497\tKL_Divergence = 3.992113\n",
      "Epoch: 38\tFidelity = 0.500572\tKL_Divergence = 3.914373\n",
      "Epoch: 39\tFidelity = 0.500504\tKL_Divergence = 3.984749\n",
      "Epoch: 40\tFidelity = 0.500546\tKL_Divergence = 3.940312\n",
      "Epoch: 41\tFidelity = 0.500557\tKL_Divergence = 3.929000\n",
      "Epoch: 42\tFidelity = 0.500567\tKL_Divergence = 3.919052\n",
      "Epoch: 43\tFidelity = 0.500499\tKL_Divergence = 3.990086\n",
      "Epoch: 44\tFidelity = 0.500561\tKL_Divergence = 3.925659\n",
      "Epoch: 45\tFidelity = 0.500611\tKL_Divergence = 3.877772\n",
      "Epoch: 46\tFidelity = 0.500558\tKL_Divergence = 3.928482\n",
      "Epoch: 47\tFidelity = 0.500602\tKL_Divergence = 3.885833\n",
      "Epoch: 48\tFidelity = 0.500546\tKL_Divergence = 3.940461\n",
      "Epoch: 49\tFidelity = 0.500560\tKL_Divergence = 3.926080\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 12:32:25,024] Trial 682 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500496\tKL_Divergence = 3.993570\n",
      "Total time elapsed during training: 82.202 s\n",
      "Trial 682 pruned. \n",
      "Epoch: 1\tFidelity = 0.500553\tKL_Divergence = 3.932898\n",
      "Epoch: 2\tFidelity = 0.500572\tKL_Divergence = 3.914585\n",
      "Epoch: 3\tFidelity = 0.500576\tKL_Divergence = 3.910627\n",
      "Epoch: 4\tFidelity = 0.500500\tKL_Divergence = 3.989491\n",
      "Epoch: 5\tFidelity = 0.500548\tKL_Divergence = 3.938648\n",
      "Epoch: 6\tFidelity = 0.500578\tKL_Divergence = 3.908870\n",
      "Epoch: 7\tFidelity = 0.500588\tKL_Divergence = 3.899473\n",
      "Epoch: 8\tFidelity = 0.500570\tKL_Divergence = 3.916438\n",
      "Epoch: 9\tFidelity = 0.500519\tKL_Divergence = 3.968119\n",
      "Epoch: 10\tFidelity = 0.500496\tKL_Divergence = 3.993239\n",
      "Epoch: 11\tFidelity = 0.500450\tKL_Divergence = 4.047938\n",
      "Epoch: 12\tFidelity = 0.500491\tKL_Divergence = 3.999220\n",
      "Epoch: 13\tFidelity = 0.500518\tKL_Divergence = 3.969080\n",
      "Epoch: 14\tFidelity = 0.500544\tKL_Divergence = 3.942689\n",
      "Epoch: 15\tFidelity = 0.500504\tKL_Divergence = 3.985138\n",
      "Epoch: 16\tFidelity = 0.500504\tKL_Divergence = 3.985056\n",
      "Epoch: 17\tFidelity = 0.500557\tKL_Divergence = 3.929395\n",
      "Epoch: 18\tFidelity = 0.500541\tKL_Divergence = 3.945962\n",
      "Epoch: 19\tFidelity = 0.500519\tKL_Divergence = 3.968873\n",
      "Epoch: 20\tFidelity = 0.500482\tKL_Divergence = 4.010040\n",
      "Epoch: 21\tFidelity = 0.500567\tKL_Divergence = 3.919384\n",
      "Epoch: 22\tFidelity = 0.500540\tKL_Divergence = 3.946328\n",
      "Epoch: 23\tFidelity = 0.500533\tKL_Divergence = 3.953542\n",
      "Epoch: 24\tFidelity = 0.500499\tKL_Divergence = 3.990322\n",
      "Epoch: 25\tFidelity = 0.500546\tKL_Divergence = 3.940806\n",
      "Epoch: 26\tFidelity = 0.500514\tKL_Divergence = 3.973570\n",
      "Epoch: 27\tFidelity = 0.500522\tKL_Divergence = 3.965020\n",
      "Epoch: 28\tFidelity = 0.500489\tKL_Divergence = 4.001380\n",
      "Epoch: 29\tFidelity = 0.500504\tKL_Divergence = 3.984664\n",
      "Epoch: 30\tFidelity = 0.500520\tKL_Divergence = 3.967709\n",
      "Epoch: 31\tFidelity = 0.500550\tKL_Divergence = 3.936167\n",
      "Epoch: 32\tFidelity = 0.500585\tKL_Divergence = 3.901774\n",
      "Epoch: 33\tFidelity = 0.500464\tKL_Divergence = 4.030118\n",
      "Epoch: 34\tFidelity = 0.500507\tKL_Divergence = 3.981768\n",
      "Epoch: 35\tFidelity = 0.500554\tKL_Divergence = 3.932737\n",
      "Epoch: 36\tFidelity = 0.500492\tKL_Divergence = 3.998121\n",
      "Epoch: 37\tFidelity = 0.500483\tKL_Divergence = 4.008033\n",
      "Epoch: 38\tFidelity = 0.500502\tKL_Divergence = 3.987437\n",
      "Epoch: 39\tFidelity = 0.500494\tKL_Divergence = 3.995931\n",
      "Epoch: 40\tFidelity = 0.500502\tKL_Divergence = 3.986788\n",
      "Epoch: 41\tFidelity = 0.500508\tKL_Divergence = 3.980750\n",
      "Epoch: 42\tFidelity = 0.500524\tKL_Divergence = 3.963267\n",
      "Epoch: 43\tFidelity = 0.500505\tKL_Divergence = 3.983532\n",
      "Epoch: 44\tFidelity = 0.500535\tKL_Divergence = 3.952089\n",
      "Epoch: 45\tFidelity = 0.500518\tKL_Divergence = 3.969651\n",
      "Epoch: 46\tFidelity = 0.500467\tKL_Divergence = 4.027413\n",
      "Epoch: 47\tFidelity = 0.500546\tKL_Divergence = 3.940223\n",
      "Epoch: 48\tFidelity = 0.500509\tKL_Divergence = 3.978951\n",
      "Epoch: 49\tFidelity = 0.500487\tKL_Divergence = 4.003269\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 12:33:10,921] Trial 683 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500564\tKL_Divergence = 3.922521\n",
      "Total time elapsed during training: 45.705 s\n",
      "Trial 683 pruned. \n",
      "Epoch: 1\tFidelity = 0.500532\tKL_Divergence = 3.955144\n",
      "Epoch: 2\tFidelity = 0.500466\tKL_Divergence = 4.027784\n",
      "Epoch: 3\tFidelity = 0.500546\tKL_Divergence = 3.940094\n",
      "Epoch: 4\tFidelity = 0.500545\tKL_Divergence = 3.941518\n",
      "Epoch: 5\tFidelity = 0.500492\tKL_Divergence = 3.997851\n",
      "Epoch: 6\tFidelity = 0.500595\tKL_Divergence = 3.893002\n",
      "Epoch: 7\tFidelity = 0.500482\tKL_Divergence = 4.009738\n",
      "Epoch: 8\tFidelity = 0.500491\tKL_Divergence = 3.998702\n",
      "Epoch: 9\tFidelity = 0.500560\tKL_Divergence = 3.926523\n",
      "Epoch: 10\tFidelity = 0.500516\tKL_Divergence = 3.971990\n",
      "Epoch: 11\tFidelity = 0.500544\tKL_Divergence = 3.942151\n",
      "Epoch: 12\tFidelity = 0.500542\tKL_Divergence = 3.944226\n",
      "Epoch: 13\tFidelity = 0.500588\tKL_Divergence = 3.898829\n",
      "Epoch: 14\tFidelity = 0.500574\tKL_Divergence = 3.912498\n",
      "Epoch: 15\tFidelity = 0.500538\tKL_Divergence = 3.948635\n",
      "Epoch: 16\tFidelity = 0.500506\tKL_Divergence = 3.983006\n",
      "Epoch: 17\tFidelity = 0.500510\tKL_Divergence = 3.978583\n",
      "Epoch: 18\tFidelity = 0.500473\tKL_Divergence = 4.020111\n",
      "Epoch: 19\tFidelity = 0.500556\tKL_Divergence = 3.930682\n",
      "Epoch: 20\tFidelity = 0.500493\tKL_Divergence = 3.996937\n",
      "Epoch: 21\tFidelity = 0.500559\tKL_Divergence = 3.927128\n",
      "Epoch: 22\tFidelity = 0.500517\tKL_Divergence = 3.970696\n",
      "Epoch: 23\tFidelity = 0.500592\tKL_Divergence = 3.895347\n",
      "Epoch: 24\tFidelity = 0.500503\tKL_Divergence = 3.985943\n",
      "Epoch: 25\tFidelity = 0.500585\tKL_Divergence = 3.902193\n",
      "Epoch: 26\tFidelity = 0.500555\tKL_Divergence = 3.931587\n",
      "Epoch: 27\tFidelity = 0.500550\tKL_Divergence = 3.936705\n",
      "Epoch: 28\tFidelity = 0.500598\tKL_Divergence = 3.889447\n",
      "Epoch: 29\tFidelity = 0.500509\tKL_Divergence = 3.979715\n",
      "Epoch: 30\tFidelity = 0.500576\tKL_Divergence = 3.910583\n",
      "Epoch: 31\tFidelity = 0.500514\tKL_Divergence = 3.974038\n",
      "Epoch: 32\tFidelity = 0.500549\tKL_Divergence = 3.937642\n",
      "Epoch: 33\tFidelity = 0.500556\tKL_Divergence = 3.930485\n",
      "Epoch: 34\tFidelity = 0.500542\tKL_Divergence = 3.944774\n",
      "Epoch: 35\tFidelity = 0.500570\tKL_Divergence = 3.916589\n",
      "Epoch: 36\tFidelity = 0.500579\tKL_Divergence = 3.907846\n",
      "Epoch: 37\tFidelity = 0.500532\tKL_Divergence = 3.955039\n",
      "Epoch: 38\tFidelity = 0.500584\tKL_Divergence = 3.902910\n",
      "Epoch: 39\tFidelity = 0.500535\tKL_Divergence = 3.951721\n",
      "Epoch: 40\tFidelity = 0.500501\tKL_Divergence = 3.988201\n",
      "Epoch: 41\tFidelity = 0.500562\tKL_Divergence = 3.924042\n",
      "Epoch: 42\tFidelity = 0.500488\tKL_Divergence = 4.002984\n",
      "Epoch: 43\tFidelity = 0.500587\tKL_Divergence = 3.900148\n",
      "Epoch: 44\tFidelity = 0.500528\tKL_Divergence = 3.959131\n",
      "Epoch: 45\tFidelity = 0.500633\tKL_Divergence = 3.858155\n",
      "Epoch: 46\tFidelity = 0.500526\tKL_Divergence = 3.961092\n",
      "Epoch: 47\tFidelity = 0.500485\tKL_Divergence = 4.006573\n",
      "Epoch: 48\tFidelity = 0.500554\tKL_Divergence = 3.932157\n",
      "Epoch: 49\tFidelity = 0.500594\tKL_Divergence = 3.893399\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 12:33:43,403] Trial 684 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500610\tKL_Divergence = 3.878442\n",
      "Total time elapsed during training: 32.281 s\n",
      "Trial 684 pruned. \n",
      "Epoch: 1\tFidelity = 0.500596\tKL_Divergence = 3.892044\n",
      "Epoch: 2\tFidelity = 0.500573\tKL_Divergence = 3.913393\n",
      "Epoch: 3\tFidelity = 0.500564\tKL_Divergence = 3.921931\n",
      "Epoch: 4\tFidelity = 0.500611\tKL_Divergence = 3.877271\n",
      "Epoch: 5\tFidelity = 0.500579\tKL_Divergence = 3.907774\n",
      "Epoch: 6\tFidelity = 0.500603\tKL_Divergence = 3.885514\n",
      "Epoch: 7\tFidelity = 0.500589\tKL_Divergence = 3.898300\n",
      "Epoch: 8\tFidelity = 0.500484\tKL_Divergence = 4.007635\n",
      "Epoch: 9\tFidelity = 0.500594\tKL_Divergence = 3.893251\n",
      "Epoch: 10\tFidelity = 0.500596\tKL_Divergence = 3.891921\n",
      "Epoch: 11\tFidelity = 0.500522\tKL_Divergence = 3.965643\n",
      "Epoch: 12\tFidelity = 0.500558\tKL_Divergence = 3.927911\n",
      "Epoch: 13\tFidelity = 0.500560\tKL_Divergence = 3.926176\n",
      "Epoch: 14\tFidelity = 0.500574\tKL_Divergence = 3.912138\n",
      "Epoch: 15\tFidelity = 0.500508\tKL_Divergence = 3.980171\n",
      "Epoch: 16\tFidelity = 0.500504\tKL_Divergence = 3.984239\n",
      "Epoch: 17\tFidelity = 0.500501\tKL_Divergence = 3.987166\n",
      "Epoch: 18\tFidelity = 0.500601\tKL_Divergence = 3.886327\n",
      "Epoch: 19\tFidelity = 0.500510\tKL_Divergence = 3.978297\n",
      "Epoch: 20\tFidelity = 0.500584\tKL_Divergence = 3.902855\n",
      "Epoch: 21\tFidelity = 0.500660\tKL_Divergence = 3.835138\n",
      "Epoch: 22\tFidelity = 0.500543\tKL_Divergence = 3.943590\n",
      "Epoch: 23\tFidelity = 0.500551\tKL_Divergence = 3.934585\n",
      "Epoch: 24\tFidelity = 0.500511\tKL_Divergence = 3.976730\n",
      "Epoch: 25\tFidelity = 0.500503\tKL_Divergence = 3.985399\n",
      "Epoch: 26\tFidelity = 0.500551\tKL_Divergence = 3.934423\n",
      "Epoch: 27\tFidelity = 0.500515\tKL_Divergence = 3.972612\n",
      "Epoch: 28\tFidelity = 0.500637\tKL_Divergence = 3.854627\n",
      "Epoch: 29\tFidelity = 0.500501\tKL_Divergence = 3.987563\n",
      "Epoch: 30\tFidelity = 0.500649\tKL_Divergence = 3.843804\n",
      "Epoch: 31\tFidelity = 0.500639\tKL_Divergence = 3.853014\n",
      "Epoch: 32\tFidelity = 0.500591\tKL_Divergence = 3.895772\n",
      "Epoch: 33\tFidelity = 0.500493\tKL_Divergence = 3.996370\n",
      "Epoch: 34\tFidelity = 0.500563\tKL_Divergence = 3.923188\n",
      "Epoch: 35\tFidelity = 0.500489\tKL_Divergence = 4.000610\n",
      "Epoch: 36\tFidelity = 0.500550\tKL_Divergence = 3.936115\n",
      "Epoch: 37\tFidelity = 0.500514\tKL_Divergence = 3.974067\n",
      "Epoch: 38\tFidelity = 0.500570\tKL_Divergence = 3.916412\n",
      "Epoch: 39\tFidelity = 0.500547\tKL_Divergence = 3.938658\n",
      "Epoch: 40\tFidelity = 0.500591\tKL_Divergence = 3.895934\n",
      "Epoch: 41\tFidelity = 0.500553\tKL_Divergence = 3.932836\n",
      "Epoch: 42\tFidelity = 0.500549\tKL_Divergence = 3.937111\n",
      "Epoch: 43\tFidelity = 0.500584\tKL_Divergence = 3.903242\n",
      "Epoch: 44\tFidelity = 0.500607\tKL_Divergence = 3.881392\n",
      "Epoch: 45\tFidelity = 0.500583\tKL_Divergence = 3.904104\n",
      "Epoch: 46\tFidelity = 0.500526\tKL_Divergence = 3.961234\n",
      "Epoch: 47\tFidelity = 0.500503\tKL_Divergence = 3.986214\n",
      "Epoch: 48\tFidelity = 0.500542\tKL_Divergence = 3.944566\n",
      "Epoch: 49\tFidelity = 0.500641\tKL_Divergence = 3.851478\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 12:34:29,290] Trial 685 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500567\tKL_Divergence = 3.919664\n",
      "Total time elapsed during training: 45.678 s\n",
      "Trial 685 pruned. \n",
      "Epoch: 1\tFidelity = 0.500534\tKL_Divergence = 3.952877\n",
      "Epoch: 2\tFidelity = 0.500463\tKL_Divergence = 4.032180\n",
      "Epoch: 3\tFidelity = 0.500574\tKL_Divergence = 3.912283\n",
      "Epoch: 4\tFidelity = 0.500424\tKL_Divergence = 4.080677\n",
      "Epoch: 5\tFidelity = 0.500464\tKL_Divergence = 4.029990\n",
      "Epoch: 6\tFidelity = 0.500393\tKL_Divergence = 4.121865\n",
      "Epoch: 7\tFidelity = 0.500541\tKL_Divergence = 3.944734\n",
      "Epoch: 8\tFidelity = 0.500555\tKL_Divergence = 3.931074\n",
      "Epoch: 9\tFidelity = 0.500420\tKL_Divergence = 4.085221\n",
      "Epoch: 10\tFidelity = 0.500486\tKL_Divergence = 4.004952\n",
      "Epoch: 11\tFidelity = 0.500605\tKL_Divergence = 3.882662\n",
      "Epoch: 12\tFidelity = 0.500584\tKL_Divergence = 3.902628\n",
      "Epoch: 13\tFidelity = 0.500597\tKL_Divergence = 3.890375\n",
      "Epoch: 14\tFidelity = 0.500558\tKL_Divergence = 3.927945\n",
      "Epoch: 15\tFidelity = 0.500481\tKL_Divergence = 4.010503\n",
      "Epoch: 16\tFidelity = 0.500632\tKL_Divergence = 3.858711\n",
      "Epoch: 17\tFidelity = 0.500473\tKL_Divergence = 4.019765\n",
      "Epoch: 18\tFidelity = 0.500513\tKL_Divergence = 3.974640\n",
      "Epoch: 19\tFidelity = 0.500608\tKL_Divergence = 3.879970\n",
      "Epoch: 20\tFidelity = 0.500570\tKL_Divergence = 3.916231\n",
      "Epoch: 21\tFidelity = 0.500580\tKL_Divergence = 3.906617\n",
      "Epoch: 22\tFidelity = 0.500473\tKL_Divergence = 4.019358\n",
      "Epoch: 23\tFidelity = 0.500519\tKL_Divergence = 3.967832\n",
      "Epoch: 24\tFidelity = 0.500525\tKL_Divergence = 3.961570\n",
      "Epoch: 25\tFidelity = 0.500646\tKL_Divergence = 3.845662\n",
      "Epoch: 26\tFidelity = 0.500474\tKL_Divergence = 4.018002\n",
      "Epoch: 27\tFidelity = 0.500630\tKL_Divergence = 3.860302\n",
      "Epoch: 28\tFidelity = 0.500470\tKL_Divergence = 4.021985\n",
      "Epoch: 29\tFidelity = 0.500523\tKL_Divergence = 3.963873\n",
      "Epoch: 30\tFidelity = 0.500524\tKL_Divergence = 3.962493\n",
      "Epoch: 31\tFidelity = 0.500645\tKL_Divergence = 3.846840\n",
      "Epoch: 32\tFidelity = 0.500667\tKL_Divergence = 3.829241\n",
      "Epoch: 33\tFidelity = 0.500605\tKL_Divergence = 3.883460\n",
      "Epoch: 34\tFidelity = 0.500632\tKL_Divergence = 3.858925\n",
      "Epoch: 35\tFidelity = 0.500558\tKL_Divergence = 3.928601\n",
      "Epoch: 36\tFidelity = 0.500464\tKL_Divergence = 4.029990\n",
      "Epoch: 37\tFidelity = 0.500594\tKL_Divergence = 3.893475\n",
      "Epoch: 38\tFidelity = 0.500608\tKL_Divergence = 3.879531\n",
      "Epoch: 39\tFidelity = 0.500583\tKL_Divergence = 3.903046\n",
      "Epoch: 40\tFidelity = 0.500599\tKL_Divergence = 3.887704\n",
      "Epoch: 41\tFidelity = 0.500613\tKL_Divergence = 3.873067\n",
      "Epoch: 42\tFidelity = 0.500498\tKL_Divergence = 3.989400\n",
      "Epoch: 43\tFidelity = 0.500570\tKL_Divergence = 3.914397\n",
      "Epoch: 44\tFidelity = 0.500694\tKL_Divergence = 3.804764\n",
      "Epoch: 45\tFidelity = 0.500692\tKL_Divergence = 3.807017\n",
      "Epoch: 46\tFidelity = 0.500475\tKL_Divergence = 4.016248\n",
      "Epoch: 47\tFidelity = 0.500537\tKL_Divergence = 3.948829\n",
      "Epoch: 48\tFidelity = 0.500689\tKL_Divergence = 3.810348\n",
      "Epoch: 49\tFidelity = 0.500537\tKL_Divergence = 3.948760\n",
      "Epoch: 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-25 12:35:06,971] Trial 686 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity = 0.500605\tKL_Divergence = 3.882374\n",
      "Total time elapsed during training: 37.498 s\n",
      "Trial 686 pruned. \n",
      "Epoch: 1\tFidelity = 0.500476\tKL_Divergence = 4.015322\n",
      "Epoch: 2\tFidelity = 0.500622\tKL_Divergence = 3.867332\n",
      "Epoch: 3\tFidelity = 0.500497\tKL_Divergence = 3.992077\n",
      "Epoch: 4\tFidelity = 0.500671\tKL_Divergence = 3.825623\n",
      "Epoch: 5\tFidelity = 0.500474\tKL_Divergence = 4.017796\n",
      "Epoch: 6\tFidelity = 0.500547\tKL_Divergence = 3.938779\n",
      "Epoch: 7\tFidelity = 0.500565\tKL_Divergence = 3.920939\n",
      "Epoch: 8\tFidelity = 0.500545\tKL_Divergence = 3.940763\n",
      "Epoch: 9\tFidelity = 0.500559\tKL_Divergence = 3.927127\n",
      "Epoch: 10\tFidelity = 0.500538\tKL_Divergence = 3.947952\n",
      "Epoch: 11\tFidelity = 0.500526\tKL_Divergence = 3.961000\n",
      "Epoch: 12\tFidelity = 0.500580\tKL_Divergence = 3.906596\n",
      "Epoch: 13\tFidelity = 0.500471\tKL_Divergence = 4.021703\n",
      "Epoch: 14\tFidelity = 0.500637\tKL_Divergence = 3.854356\n",
      "Epoch: 15\tFidelity = 0.500514\tKL_Divergence = 3.973430\n",
      "Epoch: 16\tFidelity = 0.500640\tKL_Divergence = 3.851593\n",
      "Epoch: 17\tFidelity = 0.500585\tKL_Divergence = 3.901478\n",
      "Epoch: 18\tFidelity = 0.500503\tKL_Divergence = 3.985358\n",
      "Epoch: 19\tFidelity = 0.500664\tKL_Divergence = 3.831515\n",
      "Epoch: 20\tFidelity = 0.500442\tKL_Divergence = 4.057802\n",
      "Epoch: 21\tFidelity = 0.500616\tKL_Divergence = 3.872980\n",
      "Epoch: 22\tFidelity = 0.500455\tKL_Divergence = 4.041813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-08-25 12:35:21,710] Trial 687 failed with parameters: {'lr': 19.31220073304095, 'pbs': 9000, 'nbs': 10000} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_39495/1699494747.py\", line 15, in objective\n",
      "    nn_state_dm.fit(data = meas_result,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/density_matrix.py\", line 354, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/neural_state.py\", line 614, in fit\n",
      "    all_grads = self.compute_batch_gradients(k, *batch)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/neural_state.py\", line 439, in compute_batch_gradients\n",
      "    grad = self.positive_phase_gradients(samples_batch, bases_batch=bases_batch)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/neural_state.py\", line 382, in positive_phase_gradients\n",
      "    grad = self.gradient(samples_batch, bases=bases_batch)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/neural_state.py\", line 359, in gradient\n",
      "    sample_grad = self.rotated_gradient(basis, samples[indices == i, :])\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/density_matrix.py\", line 298, in rotated_gradient\n",
      "    raw_grads = [self.am_grads(v), self.ph_grads(v)]\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/density_matrix.py\", line 330, in ph_grads\n",
      "    ) + self.pi_grad(v, v, phase=True, expand=True)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/density_matrix.py\", line 194, in pi_grad\n",
      "    sig = cplx.sigmoid(arg_real, arg_imag)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/utils/cplx.py\", line 332, in sigmoid\n",
      "    out = torch.tensor([np.real(out), np.imag(out)]).to(x)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 687 failed with parameters: {'lr': 19.31220073304095, 'pbs': 9000, 'nbs': 10000} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_39495/1699494747.py\", line 15, in objective\n",
      "    nn_state_dm.fit(data = meas_result,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/density_matrix.py\", line 354, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/neural_state.py\", line 614, in fit\n",
      "    all_grads = self.compute_batch_gradients(k, *batch)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/neural_state.py\", line 439, in compute_batch_gradients\n",
      "    grad = self.positive_phase_gradients(samples_batch, bases_batch=bases_batch)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/neural_state.py\", line 382, in positive_phase_gradients\n",
      "    grad = self.gradient(samples_batch, bases=bases_batch)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/neural_state.py\", line 359, in gradient\n",
      "    sample_grad = self.rotated_gradient(basis, samples[indices == i, :])\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/density_matrix.py\", line 298, in rotated_gradient\n",
      "    raw_grads = [self.am_grads(v), self.ph_grads(v)]\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/density_matrix.py\", line 330, in ph_grads\n",
      "    ) + self.pi_grad(v, v, phase=True, expand=True)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/density_matrix.py\", line 194, in pi_grad\n",
      "    sig = cplx.sigmoid(arg_real, arg_imag)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/qucumber/utils/cplx.py\", line 332, in sigmoid\n",
      "    out = torch.tensor([np.real(out), np.imag(out)]).to(x)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-08-25 12:35:21,716] Trial 687 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 687 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m optuna\u001b[38;5;241m.\u001b[39mlogging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptuna\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39maddHandler(logging\u001b[38;5;241m.\u001b[39mStreamHandler(sys\u001b[38;5;241m.\u001b[39mstdout))\n\u001b[1;32m      2\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(pruner\u001b[38;5;241m=\u001b[39moptuna\u001b[38;5;241m.\u001b[39mpruners\u001b[38;5;241m.\u001b[39mMedianPruner())\n\u001b[0;32m----> 3\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/optuna/study/study.py:442\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    341\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    349\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \n\u001b[1;32m    352\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 442\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     12\u001b[0m pbs \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39msuggest_categorical(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpbs\u001b[39m\u001b[38;5;124m\"\u001b[39m, [\u001b[38;5;241m1000\u001b[39m, \u001b[38;5;241m2000\u001b[39m, \u001b[38;5;241m3000\u001b[39m, \u001b[38;5;241m4000\u001b[39m, \u001b[38;5;241m5000\u001b[39m, \u001b[38;5;241m6000\u001b[39m, \u001b[38;5;241m7000\u001b[39m, \u001b[38;5;241m8000\u001b[39m, \u001b[38;5;241m9000\u001b[39m, \u001b[38;5;241m10000\u001b[39m])\n\u001b[1;32m     13\u001b[0m nbs \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39msuggest_categorical(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnbs\u001b[39m\u001b[38;5;124m\"\u001b[39m, [\u001b[38;5;241m1000\u001b[39m, \u001b[38;5;241m2000\u001b[39m, \u001b[38;5;241m3000\u001b[39m, \u001b[38;5;241m4000\u001b[39m, \u001b[38;5;241m5000\u001b[39m, \u001b[38;5;241m6000\u001b[39m, \u001b[38;5;241m7000\u001b[39m, \u001b[38;5;241m8000\u001b[39m, \u001b[38;5;241m9000\u001b[39m, \u001b[38;5;241m10000\u001b[39m])\n\u001b[0;32m---> 15\u001b[0m \u001b[43mnn_state_dm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmeas_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                        \u001b[49m\u001b[43minput_bases\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmeas_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpos_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpbs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mneg_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnbs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_gibbs_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mbases\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmeas_pattern\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m                        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdadelta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mschexduler\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_scheduler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStepLR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mscheduler_args\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstep_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_drop_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgamma\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_drop_factor\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m                        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m loss \u001b[38;5;241m=\u001b[39m callbacks[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKL_Divergence\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     31\u001b[0m trial\u001b[38;5;241m.\u001b[39mreport(loss, epoch)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/density_matrix.py:354\u001b[0m, in \u001b[0;36mDensityMatrix.fit\u001b[0;34m(self, data, epochs, pos_batch_size, neg_batch_size, k, lr, input_bases, progbar, starting_epoch, time, callbacks, optimizer, optimizer_args, scheduler, scheduler_args, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_bases must be provided to train a DensityMatrix!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 354\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneg_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneg_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_bases\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_bases\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstarting_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstarting_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtime\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscheduler_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/neural_state.py:614\u001b[0m, in \u001b[0;36mNeuralStateBase.fit\u001b[0;34m(self, data, epochs, pos_batch_size, neg_batch_size, k, lr, input_bases, progbar, starting_epoch, time, callbacks, optimizer, optimizer_args, scheduler, scheduler_args, **kwargs)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m b, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_iterator):\n\u001b[1;32m    612\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_batch_start(\u001b[38;5;28mself\u001b[39m, ep, b)\n\u001b[0;32m--> 614\u001b[0m     all_grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_batch_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    616\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()  \u001b[38;5;66;03m# clear any cached gradients\u001b[39;00m\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;66;03m# assign gradients to corresponding parameters\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/neural_state.py:439\u001b[0m, in \u001b[0;36mNeuralStateBase.compute_batch_gradients\u001b[0;34m(self, k, samples_batch, neg_batch, bases_batch)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;124;03m\"\"\"Compute the gradients of a batch of the training data (`samples_batch`).\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \n\u001b[1;32m    420\u001b[0m \u001b[38;5;124;03mIf measurements are taken in bases other than the reference basis,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;124;03m:rtype: list[torch.Tensor]\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;66;03m# Positive phase: learning signal driven by the data (and bases)\u001b[39;00m\n\u001b[0;32m--> 439\u001b[0m grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpositive_phase_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbases_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbases_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;66;03m# Negative phase: learning signal driven by the amplitude RBM of\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;66;03m# the NN state\u001b[39;00m\n\u001b[1;32m    443\u001b[0m vk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrbm_am\u001b[38;5;241m.\u001b[39mgibbs_steps(k, neg_batch)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/neural_state.py:382\u001b[0m, in \u001b[0;36mNeuralStateBase.positive_phase_gradients\u001b[0;34m(self, samples_batch, bases_batch)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpositive_phase_gradients\u001b[39m(\u001b[38;5;28mself\u001b[39m, samples_batch, bases_batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Computes the positive phase of the gradients of the parameters.\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \n\u001b[1;32m    374\u001b[0m \u001b[38;5;124;03m    :param samples_batch: The measurements\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;124;03m    :rtype: list[torch.Tensor]\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 382\u001b[0m     grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbases\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbases_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    383\u001b[0m     grad \u001b[38;5;241m=\u001b[39m [gr \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mfloat\u001b[39m(samples_batch\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m gr \u001b[38;5;129;01min\u001b[39;00m grad]\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m grad\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/neural_state.py:359\u001b[0m, in \u001b[0;36mNeuralStateBase.gradient\u001b[0;34m(self, samples, bases)\u001b[0m\n\u001b[1;32m    356\u001b[0m rot_sites \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(basis \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZ\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rot_sites\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 359\u001b[0m     sample_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrotated_gradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbasis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    361\u001b[0m     sample_grad \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    362\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrbm_am\u001b[38;5;241m.\u001b[39meffective_energy_gradient(samples[indices \u001b[38;5;241m==\u001b[39m i, :]),\n\u001b[1;32m    363\u001b[0m         \u001b[38;5;241m0.0\u001b[39m,\n\u001b[1;32m    364\u001b[0m     ]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/density_matrix.py:298\u001b[0m, in \u001b[0;36mDensityMatrix.rotated_gradient\u001b[0;34m(self, basis, sample)\u001b[0m\n\u001b[1;32m    293\u001b[0m UrhoU, UrhoU_v, v \u001b[38;5;241m=\u001b[39m unitaries\u001b[38;5;241m.\u001b[39mrotate_rho_probs(\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28mself\u001b[39m, basis, sample, include_extras\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    295\u001b[0m )\n\u001b[1;32m    296\u001b[0m inv_UrhoU \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m (UrhoU \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-8\u001b[39m)  \u001b[38;5;66;03m# avoid dividing by zero\u001b[39;00m\n\u001b[0;32m--> 298\u001b[0m raw_grads \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mam_grads(v), \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mph_grads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m    300\u001b[0m rotated_grad \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;241m-\u001b[39mcplx\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mijb,ijbg->bg\u001b[39m\u001b[38;5;124m\"\u001b[39m, UrhoU_v, g, imag_part\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m raw_grads\n\u001b[1;32m    302\u001b[0m ]\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [torch\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb,bg->g\u001b[39m\u001b[38;5;124m\"\u001b[39m, inv_UrhoU, g) \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m rotated_grad]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/density_matrix.py:330\u001b[0m, in \u001b[0;36mDensityMatrix.ph_grads\u001b[0;34m(self, v)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mph_grads\u001b[39m(\u001b[38;5;28mself\u001b[39m, v):\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Computes the gradients of the phase RBM for given input states\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \n\u001b[1;32m    322\u001b[0m \u001b[38;5;124;03m    :param v: The first input state, :math:`\\sigma`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;124;03m    :rtype: torch.Tensor\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cplx\u001b[38;5;241m.\u001b[39mscalar_mult(  \u001b[38;5;66;03m# need to multiply Gamma- by i\u001b[39;00m\n\u001b[1;32m    329\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrbm_ph\u001b[38;5;241m.\u001b[39mgamma_grad(v, v, eta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, expand\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), cplx\u001b[38;5;241m.\u001b[39mI\n\u001b[0;32m--> 330\u001b[0m     ) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpi_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/density_matrix.py:194\u001b[0m, in \u001b[0;36mDensityMatrix.pi_grad\u001b[0;34m(self, v, vp, phase, expand)\u001b[0m\n\u001b[1;32m    191\u001b[0m     arg_real \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrbm_am\u001b[38;5;241m.\u001b[39mmixing_term(v \u001b[38;5;241m+\u001b[39m vp)\n\u001b[1;32m    192\u001b[0m     arg_imag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrbm_ph\u001b[38;5;241m.\u001b[39mmixing_term(v \u001b[38;5;241m-\u001b[39m vp)\n\u001b[0;32m--> 194\u001b[0m sig \u001b[38;5;241m=\u001b[39m \u001b[43mcplx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_real\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg_imag\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    196\u001b[0m batch_sizes \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    197\u001b[0m     (v\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], vp\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39mv\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m expand \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;241m*\u001b[39mv\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],)\n\u001b[1;32m    198\u001b[0m )\n\u001b[1;32m    200\u001b[0m W_grad \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrbm_am\u001b[38;5;241m.\u001b[39mweights_W)\u001b[38;5;241m.\u001b[39mexpand(\u001b[38;5;241m*\u001b[39mbatch_sizes, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/qucumber/utils/cplx.py:332\u001b[0m, in \u001b[0;36msigmoid\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    329\u001b[0m z \u001b[38;5;241m=\u001b[39m (x\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39mj \u001b[38;5;241m*\u001b[39m (y\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m    331\u001b[0m out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(z) \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(z))\n\u001b[0;32m--> 332\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(x)\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optuna.logging.get_logger(\"optuna\").addHandler(logging.StreamHandler(sys.stdout))\n",
    "study = optuna.create_study(pruner=optuna.pruners.MedianPruner())\n",
    "study.optimize(objective, n_trials=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692cbf2f-73bf-4083-a38d-c35e80122b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2f49de-d6fc-4d83-be19-0989fb55df12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best params\n",
    "params[\"train_info\"][\"lr\"] = study.best_params[\"lr\"]\n",
    "params[\"train_info\"][\"n_gibbs_step\"] = study.best_params[\"k\"]\n",
    "\n",
    "with open('./best_params_setting.yaml', 'w') as yml:\n",
    "    yaml.dump(params, yml, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf0a60e-bc40-4443-a898-9fd6aa923712",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
