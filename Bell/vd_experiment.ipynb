{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "052aaffa-d670-4d3f-bed9-c07e12c063cf",
   "metadata": {},
   "source": [
    "## Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "732c2405-3fcb-489a-b931-15d9a7eb7845",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "from tqdm.notebook import tqdm\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "from qucumber.nn_states import DensityMatrix\n",
    "from qucumber.nn_states import ComplexWaveFunction\n",
    "from qucumber.callbacks import MetricEvaluator\n",
    "import qucumber.utils.unitaries as unitaries\n",
    "import qucumber.utils.training_statistics as ts\n",
    "import qucumber.utils.cplx as cplx\n",
    "import qucumber.utils.data as data\n",
    "from qucumber.observables import ObservableBase, to_pm1\n",
    "from qucumber.observables.pauli import flip_spin\n",
    "import qucumber\n",
    "\n",
    "from qulacs.gate import Pauli\n",
    "\n",
    "with open('./params_setting.yaml', 'r') as yml:\n",
    "    params = yaml.safe_load(yml)\n",
    "    \n",
    "# quantum circuit parameter\n",
    "n_qubit = params[\"circuit_info\"][\"n_qubit\"]\n",
    "n_data = params[\"circuit_info\"][\"n_data\"]\n",
    "each_n_shot = int(n_data / 3**n_qubit)\n",
    "state_name = params[\"circuit_info\"][\"state_name\"]\n",
    "error_model = params[\"circuit_info\"][\"error_model\"]\n",
    "error_rate = params[\"circuit_info\"][\"error_rate\"]\n",
    "# RBM architecture parameter\n",
    "n_visible_unit = params[\"architecture_info\"][\"n_visible_unit\"]\n",
    "n_hidden_unit = params[\"architecture_info\"][\"n_hidden_unit\"] \n",
    "n_aux_unit = params[\"architecture_info\"][\"n_aux_unit\"]\n",
    "# train parameter\n",
    "lr = params[\"train_info\"][\"lr\"]\n",
    "pbs = params[\"train_info\"][\"positive_batch_size\"]\n",
    "nbs = params[\"train_info\"][\"negative_batch_size\"]\n",
    "n_gibbs_step = params[\"train_info\"][\"n_gibbs_step\"]\n",
    "period = 1\n",
    "epoch = params[\"train_info\"][\"n_epoch\"]\n",
    "lr_drop_epoch = params[\"train_info\"][\"lr_drop_epoch\"]\n",
    "lr_drop_factor = params[\"train_info\"][\"lr_drop_factor\"]\n",
    "seed = params[\"train_info\"][\"seed\"]\n",
    "# sampling parameter\n",
    "n_sampling = params[\"sampling_info\"][\"n_sample\"]\n",
    "n_copy = params[\"sampling_info\"][\"n_copy\"]\n",
    "# data path info\n",
    "train_data_path = f\"./data/{noise_model}/error_prob_{100*error_rate}%/num_of_data_{n_data}/\"\n",
    "ideal_state_path = f\"./target_state/\"\n",
    "\n",
    "# settings\n",
    "## warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "## seaborn layout\n",
    "sns.set()\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "## seed\n",
    "def seed_settings(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    qucumber.set_random_seed(seed, cpu=True, gpu=False)\n",
    "\n",
    "seed_settings(seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f117e73d-0af0-430e-8a7c-3b2d47ef109a",
   "metadata": {},
   "source": [
    "## caluculate ideal state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d800bd19-5c39-4fcf-9f48-49451f4574a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ideal state data is exsisted !\n"
     ]
    }
   ],
   "source": [
    "# calculate ideal state\n",
    "is_ideal_state_file = os.path.exists(ideal_state_path)\n",
    "if is_ideal_state_file:\n",
    "    print(\"ideal state data is exsisted !\")\n",
    "else:\n",
    "    print(\"caluculate ideal state data ...\")\n",
    "    subprocess.run(\"python caluculate_ideal_state.py\", shell=True)\n",
    "    print(\"ideal state data is ready !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3a9677-cd6b-41d8-92a1-47a74a019756",
   "metadata": {},
   "source": [
    "## generate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c8227038-435d-419b-a558-f30b8643125e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data is exsisted !\n"
     ]
    }
   ],
   "source": [
    "# generate train data\n",
    "is_train_data_file = os.path.exists(train_data_path)\n",
    "if is_train_data_file:\n",
    "    print(\"train data is exsisted !\")\n",
    "else:\n",
    "    print(\"generate directries & train data ...\")\n",
    "    os.makedirs(train_data_path, exist_ok = True)\n",
    "    subprocess.run(\"python generate_dataset.py\", shell=True)\n",
    "    print(\"train data is ready !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ca5da5-599e-4904-b098-e7674898d406",
   "metadata": {},
   "source": [
    "## load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8cabc549-042c-4d1d-874e-8442ae6c1015",
   "metadata": {},
   "outputs": [],
   "source": [
    "meas_pattern_path = train_data_path + \"/measurement_pattern.txt\"\n",
    "meas_label_path = train_data_path + \"/measurement_label.txt\"\n",
    "meas_result_path = train_data_path + \"/measurement_result.txt\"\n",
    "ideal_rho_re_path = ideal_state_path + \"/rho_real.txt\"\n",
    "ideal_rho_im_path = ideal_state_path + \"/rho_imag.txt\"\n",
    "meas_result, ideal_rho, meas_label, meas_pattern = data.load_data_DM(meas_result_path,\n",
    "                                                                     ideal_rho_re_path,\n",
    "                                                                     ideal_rho_im_path,\n",
    "                                                                     meas_label_path,\n",
    "                                                                     meas_pattern_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb62003-cef3-4391-b9af-b4ba2d362c81",
   "metadata": {},
   "source": [
    "## build RBM architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dac2e9bd-139a-4f69-a567-060113f429d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_state_dm = DensityMatrix(\n",
    "    num_visible = n_visible_unit, \n",
    "    num_hidden = n_hidden_unit, \n",
    "    num_aux = n_aux_unit, \n",
    "    unitary_dict = unitaries.create_dict(),\n",
    "    gpu = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b90a855-f64f-4d31-9dff-25973fd5bbfb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## estimate observable expectation value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8f385a22-df7a-49b0-880d-39dadb7f6922",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneralPauliDistill(ObservableBase):\n",
    "    def __init__(self, pauli_dict: dict, m: int) -> None:\n",
    "        self.name = \"distilled_pauli\"\n",
    "        self.symbol = \"distilled_general_pauli\"\n",
    "        self.pauli_dict = pauli_dict\n",
    "        self.num_copy = m\n",
    "        \n",
    "    def apply(self, nn_state, samples):\n",
    "        \"\"\"\n",
    "        This function calcualte <x1 x2 ... xm | rho^{\\otimes m} O | xm x1 x2 ... xm-1> / <x1 x2 ... xm | rho^{\\otimes m} | x1 x2 ... xm>\n",
    "        where O acts only on the first register.\n",
    "        \"\"\"\n",
    "        \n",
    "        # [num_sample, num_visible_node]\n",
    "        # samples = [s1, s2, s3 ... sN]\n",
    "        #  where num_sample = N, and si is num_visible_node-bits\n",
    "        samples = samples.to(device=nn_state.device)\n",
    "        \n",
    "        num_sample, num_visible_node = samples.shape\n",
    "        \n",
    "        # [num_sample, num_visible_node * num_copy]\n",
    "        # samples_array = [[s1 sN sN-1], [s2 s1 sN], [s3 s2 s1],.. [sN sN-1 sN-2]]\n",
    "        #  each row is num_copy*num_visible_node bits the above example is for num_copy=3\n",
    "        samples_array = []\n",
    "        for copy_index in range(self.num_copy):\n",
    "            rolled_samples = torch.roll(samples, shifts=copy_index, dims=0)\n",
    "            samples_array.append(rolled_samples)\n",
    "        samples_array = torch.hstack(samples_array)\n",
    "        assert(samples_array.shape[0] == num_sample)\n",
    "        assert(samples_array.shape[1] == num_visible_node * self.num_copy)\n",
    "        \n",
    "        # roll second dim of [num_sample, num_visible_node * num_copy] by num_visible_node\n",
    "        # swapped_samples_array = [[sN-1 s1 sN], [sN s2 s1], [s1 s3 s2],.. [sN-2 sN sN-1]]\n",
    "        swapped_samples_array = torch.roll(samples_array, shifts = num_visible_node, dims=1)\n",
    "\n",
    "        # pick copy of first block\n",
    "        #  first_block_sample = [sN-1, sN, s1, s2, ... sN-2]\n",
    "        first_block_sample = swapped_samples_array[:, :num_visible_node].clone()\n",
    "\n",
    "        # calculate coefficient for first block [num_samples, 0:num_visible_node]\n",
    "        total_prod = cplx.make_complex(torch.ones_like(samples[:,0]), torch.zeros_like(samples[:,0]))\n",
    "        for index, pauli in self.pauli_dict.items():\n",
    "            assert(index < num_visible_node)\n",
    "            coeff = to_pm1(first_block_sample[:, index])\n",
    "            if pauli == \"Z\":\n",
    "                coeff = cplx.make_complex(coeff, torch.zeros_like(coeff))\n",
    "                total_prod = cplx.elementwise_mult(coeff, total_prod)\n",
    "            elif pauli == \"Y\":\n",
    "                coeff = cplx.make_complex(torch.zeros_like(coeff), coeff)\n",
    "                total_prod = cplx.elementwise_mult(coeff, total_prod)\n",
    "        \n",
    "        # flip samples for for first block [num_samples, 0:num_visible_node]\n",
    "        # first_block_sample -> [OsN-1, OsN, Os1, Os2, ... OsN-2]\n",
    "        #  where Osi is bit array after Pauli bit-flips \n",
    "        for index, pauli in self.pauli_dict.items():\n",
    "            assert(index < num_visible_node)\n",
    "            if pauli in [\"X\", \"Y\"]:\n",
    "                first_block_sample = flip_spin(index, first_block_sample)\n",
    "\n",
    "\n",
    "        # store flipped first block\n",
    "        swapped_samples_array[:, :num_visible_node] = first_block_sample\n",
    "\n",
    "        # calculate product of coefficients\n",
    "        # samples_array = [[s1 sN sN-1], [s2 s1 sN], [s3 s2 s1],.. [sN sN-1 sN-2]]\n",
    "        # swapped_samples_array = [[OsN-1 s1 sN], [OsN s2 s1], [Os1 s3 s2],.. [OsN-2 sN sN-1]]\n",
    "        \"\"\"\n",
    "        total_prod = [\n",
    "            <s1 sN sN-1 | rho^{\\otimes 3} | OsN-1 s1 sN> / <s1 sN sN-1 | rho^{\\otimes 3} | s1 sN sN-1> , \n",
    "            <s2 s1 sN   | rho^{\\otimes 3} | OsN s2 s1>   / <s2 s1 sN   | rho^{\\otimes 3} | s2 s1 sN> , \n",
    "            <s3 s2 s1   | rho^{\\otimes 3} | Os1 s3 s2>   / <s3 s2 s1   | rho^{\\otimes 3} | s3 s2 s1> , \n",
    "\n",
    "        e.g. \n",
    "        <s3 s2 s1   | rho^{\\otimes 3} | Os1 s3 s2>   / <s3 s2 s1   | rho^{\\otimes 3} | s3 s2 s1>\n",
    "         = <s3 | rho | Os1> <s2 | rho | s3> < s1| rho | s2> / (<s3 | rho | s3> <s2 | rho | s2> < s1| rho | s1>)\n",
    "         =  (<s3 | rho | Os1> / <s3 | rho | s3>)\n",
    "          * (<s2 | rho | s3> / <s2 | rho | s2> )\n",
    "          * (< s1| rho | s2> / < s1| rho | s1>)\n",
    "         \n",
    "        importance_sampling_numerator(s3, Os1)  provides <s3 | rho | Os1>\n",
    "        importance_sampling_denominator(s3)     provides <s3 | rho | s3>\n",
    "        \"\"\"\n",
    "        for copy_index in range(self.num_copy):\n",
    "            st = copy_index * samples.shape[1]\n",
    "            en = (copy_index+1) * samples.shape[1]\n",
    "            # numerator is []\n",
    "            numerator = nn_state.importance_sampling_numerator(swapped_samples_array[:, st:en], samples_array[:, st:en])\n",
    "            denominator = nn_state.importance_sampling_denominator(samples_array[:, st:en])\n",
    "            values = cplx.elementwise_division(numerator, denominator)\n",
    "            total_prod = cplx.elementwise_mult(total_prod, values)\n",
    "\n",
    "        value = cplx.real(total_prod)\n",
    "        return value\n",
    "\n",
    "def calculate_distilled_expectation_value(pauli_dict: dict, num_samples: int, num_copies: int):\n",
    "    obs_num = GeneralPauliDistill(pauli_dict, num_copies)\n",
    "    obs_div = GeneralPauliDistill({}, num_copies)\n",
    "    num_stat = obs_num.statistics(nn_state_dm, num_samples=num_samples)\n",
    "    div_stat = obs_div.statistics(nn_state_dm, num_samples=num_samples)\n",
    "\n",
    "    from uncertainties import ufloat\n",
    "    num = ufloat(num_stat[\"mean\"], num_stat[\"std_error\"])\n",
    "    div = ufloat(div_stat[\"mean\"], div_stat[\"std_error\"])\n",
    "    val = num/div\n",
    "    result_dict = {\"mean\": val.n , \"std_error\": val.s, \"num_samples\": num_samples, \"num_copies\": num_copies}\n",
    "    return result_dict\n",
    "\n",
    "def get_density_matrix(nn_state):\n",
    "    space = nn_state.generate_hilbert_space()\n",
    "    Z = nn_state.normalization(space)\n",
    "    tensor = nn_state.rho(space, space)/Z\n",
    "    matrix = cplx.numpy(tensor)\n",
    "    return matrix\n",
    "\n",
    "def get_max_eigvec(matrix):\n",
    "    e_val, e_vec = np.linalg.eigh(matrix)\n",
    "    me_val = e_val[-1]\n",
    "    me_vec = e_vec[:,-1]\n",
    "    return me_vec\n",
    "\n",
    "def get_eigvec(nn_state, obs, space, **kwargs):\n",
    "    dm = get_density_matrix(nn_state)\n",
    "    ev = get_max_eigvec(dm)\n",
    "    ev = np.atleast_2d(ev)\n",
    "    val = ev@obs@ev.T.conj()\n",
    "    val = val[0,0].real\n",
    "    return val\n",
    "\n",
    "def observable_XX():\n",
    "    target_list = [0, 1]\n",
    "    pauli_index = [1, 1] # 1:X , 2:Y, 3:Z\n",
    "    gate = Pauli(target_list, pauli_index) # = X_1 X_2\n",
    "    return gate.get_matrix()\n",
    "\n",
    "def observable_XZ():\n",
    "    target_list = [0, 1]\n",
    "    pauli_index = [1, 3] # 1:X , 2:Y, 3:Z\n",
    "    gate = Pauli(target_list, pauli_index) # = X_1 Z_2\n",
    "    return gate.get_matrix()\n",
    "\n",
    "def observable_XX_ev(nn_state, **kwargs):\n",
    "    obs_stat = calculate_distilled_expectation_value({0: \"X\", 1: \"X\"}, n_sampling, n_copy)\n",
    "    return obs_stat[\"mean\"]\n",
    "\n",
    "def observable_XZ_ev(nn_state, **kwargs):\n",
    "    obs_stat = calculate_distilled_expectation_value({0: \"X\", 1: \"Z\"}, n_sampling, n_copy)\n",
    "    return obs_stat[\"mean\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064b4095-4a33-4938-9e25-f9d6cce67c73",
   "metadata": {},
   "source": [
    "## callback setting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6433a987-cec4-4698-8170-cf2955012fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_callback_dm(nn_state):\n",
    "    metric_dict = {\n",
    "        \"Fidelity\": ts.fidelity,\n",
    "        \"KL_Divergence\": ts.KL,\n",
    "        \"Observable_XX_ev\": observable_XX_ev,\n",
    "        \"Observable_XZ_ev\": observable_XZ_ev,\n",
    "    }\n",
    "\n",
    "    space = nn_state.generate_hilbert_space()\n",
    "    callbacks = [\n",
    "        MetricEvaluator(\n",
    "            period,\n",
    "            metric_dict,\n",
    "            target = ideal_rho,\n",
    "            bases = meas_pattern,\n",
    "            verbose = True,\n",
    "            space = space,\n",
    "        )\n",
    "    ]\n",
    "    return callbacks\n",
    "\n",
    "callbacks = create_callback_dm(nn_state_dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fd8047-5824-410e-a1cb-1851fcfc3f35",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990cd783-aada-493b-b806-c64e330c1c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\tFidelity = 0.204047\tKL_Divergence = 0.452568\tObservable_XX_ev = 0.336506\tObservable_XZ_ev = 0.175218\n",
      "Epoch: 2\tFidelity = 0.181683\tKL_Divergence = 0.403944\tObservable_XX_ev = 0.347023\tObservable_XZ_ev = -0.133544\n",
      "Epoch: 3\tFidelity = 0.179693\tKL_Divergence = 0.368460\tObservable_XX_ev = 0.219898\tObservable_XZ_ev = 0.043856\n",
      "Epoch: 4\tFidelity = 0.169603\tKL_Divergence = 0.350721\tObservable_XX_ev = 0.167267\tObservable_XZ_ev = 0.032746\n",
      "Epoch: 5\tFidelity = 0.181387\tKL_Divergence = 0.325344\tObservable_XX_ev = 0.184938\tObservable_XZ_ev = -0.107885\n",
      "Epoch: 6\tFidelity = 0.188134\tKL_Divergence = 0.311848\tObservable_XX_ev = 0.102614\tObservable_XZ_ev = 0.012636\n",
      "Epoch: 7\tFidelity = 0.198838\tKL_Divergence = 0.301780\tObservable_XX_ev = 0.104480\tObservable_XZ_ev = 0.033041\n",
      "Epoch: 8\tFidelity = 0.211668\tKL_Divergence = 0.280663\tObservable_XX_ev = 0.078321\tObservable_XZ_ev = -0.009465\n"
     ]
    }
   ],
   "source": [
    "nn_state_dm.fit(\n",
    "    data = meas_result,\n",
    "    input_bases = meas_label,\n",
    "    epochs = epoch,\n",
    "    pos_batch_size = pbs,\n",
    "    neg_batch_size = nbs,\n",
    "    lr = lr,\n",
    "    k = n_gibbs_step,\n",
    "    bases = meas_pattern,\n",
    "    callbacks = callbacks,\n",
    "    time = True,\n",
    "    optimizer = torch.optim.Adadelta,\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR,\n",
    "    scheduler_args = {\"step_size\": lr_drop_epoch, \"gamma\": lr_drop_factor},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd929000-b451-4c82-b6e8-1704360eac66",
   "metadata": {},
   "source": [
    "## save model & train log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00c5ebc-98b0-4c46-a472-49df305499a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "\n",
    "# save train log\n",
    "train_log_df = pd.DataFrame()\n",
    "train_log_df[\"epoch\"] = np.arange(CFG.period, CFG.epochs + 1, CFG.period)\n",
    "train_log_df[\"Fidelity\"] = callbacks[0][\"Fidelity\"]\n",
    "train_log_df[\"KL_Divergence\"] = callbacks[0][\"KL_Divergence\"]\n",
    "train_log_df[\"Observable_XX_ev\"] = callbacks[0][\"Observable_XX_ev\"]\n",
    "train_log_df[\"Observable_XZ_ev\"] = callbacks[0][\"Observable_XZ_ev\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f06c23-3673-4844-91cf-b983c128cdf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
