{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "052aaffa-d670-4d3f-bed9-c07e12c063cf",
   "metadata": {},
   "source": [
    "## Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "732c2405-3fcb-489a-b931-15d9a7eb7845",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "from tqdm.notebook import tqdm\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "from qucumber.nn_states import DensityMatrix\n",
    "from qucumber.nn_states import ComplexWaveFunction\n",
    "from qucumber.callbacks import MetricEvaluator\n",
    "import qucumber.utils.unitaries as unitaries\n",
    "import qucumber.utils.training_statistics as ts\n",
    "import qucumber.utils.cplx as cplx\n",
    "import qucumber.utils.data as data\n",
    "from qucumber.observables import ObservableBase, to_pm1\n",
    "from qucumber.observables.pauli import flip_spin\n",
    "import qucumber\n",
    "\n",
    "from qulacs.gate import Pauli\n",
    "\n",
    "with open('./params_setting.yaml', 'r') as yml:\n",
    "    params = yaml.safe_load(yml)\n",
    "    \n",
    "# quantum circuit parameter\n",
    "n_qubit = params[\"circuit_info\"][\"n_qubit\"]\n",
    "n_data = params[\"circuit_info\"][\"n_data\"]\n",
    "each_n_shot = int(n_data / 3**n_qubit)\n",
    "state_name = params[\"circuit_info\"][\"state_name\"]\n",
    "error_model = params[\"circuit_info\"][\"error_model\"]\n",
    "error_rate = params[\"circuit_info\"][\"error_rate\"]\n",
    "# RBM architecture parameter\n",
    "n_visible_unit = params[\"architecture_info\"][\"n_visible_unit\"]\n",
    "n_hidden_unit = params[\"architecture_info\"][\"n_hidden_unit\"] \n",
    "n_aux_unit = params[\"architecture_info\"][\"n_aux_unit\"]\n",
    "# train parameter\n",
    "lr = params[\"train_info\"][\"lr\"]\n",
    "pbs = params[\"train_info\"][\"positive_batch_size\"]\n",
    "nbs = params[\"train_info\"][\"negative_batch_size\"]\n",
    "n_gibbs_step = params[\"train_info\"][\"n_gibbs_step\"]\n",
    "period = 1\n",
    "epoch = params[\"train_info\"][\"n_epoch\"]\n",
    "lr_drop_epoch = params[\"train_info\"][\"lr_drop_epoch\"]\n",
    "lr_drop_factor = params[\"train_info\"][\"lr_drop_factor\"]\n",
    "seed = params[\"train_info\"][\"seed\"]\n",
    "# sampling parameter\n",
    "n_sampling = params[\"sampling_info\"][\"n_sample\"]\n",
    "n_copy = params[\"sampling_info\"][\"n_copy\"]\n",
    "# data path info\n",
    "train_data_path = f\"./data/{noise_model}/error_prob_{100*error_rate}%/num_of_data_{n_data}/\"\n",
    "ideal_state_path = f\"./target_state/\"\n",
    "\n",
    "# settings\n",
    "## warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "## seaborn layout\n",
    "sns.set()\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "## seed\n",
    "def seed_settings(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    qucumber.set_random_seed(seed, cpu=True, gpu=False)\n",
    "\n",
    "seed_settings(seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f117e73d-0af0-430e-8a7c-3b2d47ef109a",
   "metadata": {},
   "source": [
    "## caluculate ideal state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d800bd19-5c39-4fcf-9f48-49451f4574a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ideal state data is exsisted !\n"
     ]
    }
   ],
   "source": [
    "# calculate ideal state\n",
    "is_ideal_state_file = os.path.exists(ideal_state_path)\n",
    "if is_ideal_state_file:\n",
    "    print(\"ideal state data is exsisted !\")\n",
    "else:\n",
    "    print(\"caluculate ideal state data ...\")\n",
    "    subprocess.run(\"python caluculate_ideal_state.py\", shell=True)\n",
    "    print(\"ideal state data is ready !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3a9677-cd6b-41d8-92a1-47a74a019756",
   "metadata": {},
   "source": [
    "## generate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c8227038-435d-419b-a558-f30b8643125e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate directries & train data ...\n",
      "0it [00:00, ?it/s]\n",
      "measurement pattern 0 : ('X', 'X')\n",
      "  0%|          | 0/1111 [00:00<?, ?it/s]\n",
      "measurement pattern 1 : ('X', 'Y')\n",
      "  0%|          | 0/1111 [00:00<?, ?it/s]\n",
      "measurement pattern 2 : ('X', 'Z')\n",
      "  0%|          | 0/1111 [00:00<?, ?it/s]\n",
      "measurement pattern 3 : ('Y', 'X')\n",
      "  0%|          | 0/1111 [00:00<?, ?it/s]\n",
      "measurement pattern 4 : ('Y', 'Y')\n",
      "  0%|          | 0/1111 [00:00<?, ?it/s]\n",
      "measurement pattern 5 : ('Y', 'Z')\n",
      "  0%|          | 0/1111 [00:00<?, ?it/s]\n",
      "measurement pattern 6 : ('Z', 'X')\n",
      "  0%|          | 0/1111 [00:00<?, ?it/s]\n",
      "measurement pattern 7 : ('Z', 'Y')\n",
      "  0%|          | 0/1111 [00:00<?, ?it/s]\n",
      "measurement pattern 8 : ('Z', 'Z')\n",
      "  0%|          | 0/1111 [00:00<?, ?it/s]\n",
      "train data is ready !\n"
     ]
    }
   ],
   "source": [
    "# generate train data\n",
    "is_train_data_file = os.path.exists(train_data_path)\n",
    "if is_train_data_file:\n",
    "    print(\"train data is exsisted !\")\n",
    "else:\n",
    "    print(\"generate directries & train data ...\")\n",
    "    os.makedirs(train_data_path, exist_ok = True)\n",
    "    subprocess.run(\"python generate_dataset.py\", shell=True)\n",
    "    print(\"train data is ready !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ca5da5-599e-4904-b098-e7674898d406",
   "metadata": {},
   "source": [
    "## load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8cabc549-042c-4d1d-874e-8442ae6c1015",
   "metadata": {},
   "outputs": [],
   "source": [
    "meas_pattern_path = train_data_path + \"/measurement_pattern.txt\"\n",
    "meas_label_path = train_data_path + \"/measurement_label.txt\"\n",
    "meas_result_path = train_data_path + \"/measurement_result.txt\"\n",
    "ideal_rho_re_path = ideal_state_path + \"/rho_real.txt\"\n",
    "ideal_rho_im_path = ideal_state_path + \"/rho_imag.txt\"\n",
    "meas_result, ideal_rho, meas_label, meas_pattern = data.load_data_DM(meas_result_path,\n",
    "                                                                     ideal_rho_re_path,\n",
    "                                                                     ideal_rho_im_path,\n",
    "                                                                     meas_label_path,\n",
    "                                                                     meas_pattern_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb62003-cef3-4391-b9af-b4ba2d362c81",
   "metadata": {},
   "source": [
    "## build RBM architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "dac2e9bd-139a-4f69-a567-060113f429d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_state_dm = DensityMatrix(\n",
    "    num_visible = n_visible_unit, \n",
    "    num_hidden = n_hidden_unit, \n",
    "    num_aux = n_aux_unit, \n",
    "    unitary_dict = unitaries.create_dict(),\n",
    "    gpu = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b90a855-f64f-4d31-9dff-25973fd5bbfb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## estimate observable expectation value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8f385a22-df7a-49b0-880d-39dadb7f6922",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneralPauliDistill(ObservableBase):\n",
    "    def __init__(self, pauli_dict: dict, m: int) -> None:\n",
    "        self.name = \"distilled_pauli\"\n",
    "        self.symbol = \"distilled_general_pauli\"\n",
    "        self.pauli_dict = pauli_dict\n",
    "        self.num_copy = m\n",
    "        \n",
    "    def apply(self, nn_state, samples):\n",
    "        \"\"\"\n",
    "        This function calcualte <x1 x2 ... xm | rho^{\\otimes m} O | xm x1 x2 ... xm-1> / <x1 x2 ... xm | rho^{\\otimes m} | x1 x2 ... xm>\n",
    "        where O acts only on the first register.\n",
    "        \"\"\"\n",
    "        \n",
    "        # [num_sample, num_visible_node]\n",
    "        # samples = [s1, s2, s3 ... sN]\n",
    "        #  where num_sample = N, and si is num_visible_node-bits\n",
    "        samples = samples.to(device=nn_state.device)\n",
    "        \n",
    "        num_sample, num_visible_node = samples.shape\n",
    "        \n",
    "        # [num_sample, num_visible_node * num_copy]\n",
    "        # samples_array = [[s1 sN sN-1], [s2 s1 sN], [s3 s2 s1],.. [sN sN-1 sN-2]]\n",
    "        #  each row is num_copy*num_visible_node bits the above example is for num_copy=3\n",
    "        samples_array = []\n",
    "        for copy_index in range(self.num_copy):\n",
    "            rolled_samples = torch.roll(samples, shifts=copy_index, dims=0)\n",
    "            samples_array.append(rolled_samples)\n",
    "        samples_array = torch.hstack(samples_array)\n",
    "        assert(samples_array.shape[0] == num_sample)\n",
    "        assert(samples_array.shape[1] == num_visible_node * self.num_copy)\n",
    "        \n",
    "        # roll second dim of [num_sample, num_visible_node * num_copy] by num_visible_node\n",
    "        # swapped_samples_array = [[sN-1 s1 sN], [sN s2 s1], [s1 s3 s2],.. [sN-2 sN sN-1]]\n",
    "        swapped_samples_array = torch.roll(samples_array, shifts = num_visible_node, dims=1)\n",
    "\n",
    "        # pick copy of first block\n",
    "        #  first_block_sample = [sN-1, sN, s1, s2, ... sN-2]\n",
    "        first_block_sample = swapped_samples_array[:, :num_visible_node].clone()\n",
    "\n",
    "        # calculate coefficient for first block [num_samples, 0:num_visible_node]\n",
    "        total_prod = cplx.make_complex(torch.ones_like(samples[:,0]), torch.zeros_like(samples[:,0]))\n",
    "        for index, pauli in self.pauli_dict.items():\n",
    "            assert(index < num_visible_node)\n",
    "            coeff = to_pm1(first_block_sample[:, index])\n",
    "            if pauli == \"Z\":\n",
    "                coeff = cplx.make_complex(coeff, torch.zeros_like(coeff))\n",
    "                total_prod = cplx.elementwise_mult(coeff, total_prod)\n",
    "            elif pauli == \"Y\":\n",
    "                coeff = cplx.make_complex(torch.zeros_like(coeff), coeff)\n",
    "                total_prod = cplx.elementwise_mult(coeff, total_prod)\n",
    "        \n",
    "        # flip samples for for first block [num_samples, 0:num_visible_node]\n",
    "        # first_block_sample -> [OsN-1, OsN, Os1, Os2, ... OsN-2]\n",
    "        #  where Osi is bit array after Pauli bit-flips \n",
    "        for index, pauli in self.pauli_dict.items():\n",
    "            assert(index < num_visible_node)\n",
    "            if pauli in [\"X\", \"Y\"]:\n",
    "                first_block_sample = flip_spin(index, first_block_sample)\n",
    "\n",
    "\n",
    "        # store flipped first block\n",
    "        swapped_samples_array[:, :num_visible_node] = first_block_sample\n",
    "\n",
    "        # calculate product of coefficients\n",
    "        # samples_array = [[s1 sN sN-1], [s2 s1 sN], [s3 s2 s1],.. [sN sN-1 sN-2]]\n",
    "        # swapped_samples_array = [[OsN-1 s1 sN], [OsN s2 s1], [Os1 s3 s2],.. [OsN-2 sN sN-1]]\n",
    "        \"\"\"\n",
    "        total_prod = [\n",
    "            <s1 sN sN-1 | rho^{\\otimes 3} | OsN-1 s1 sN> / <s1 sN sN-1 | rho^{\\otimes 3} | s1 sN sN-1> , \n",
    "            <s2 s1 sN   | rho^{\\otimes 3} | OsN s2 s1>   / <s2 s1 sN   | rho^{\\otimes 3} | s2 s1 sN> , \n",
    "            <s3 s2 s1   | rho^{\\otimes 3} | Os1 s3 s2>   / <s3 s2 s1   | rho^{\\otimes 3} | s3 s2 s1> , \n",
    "\n",
    "        e.g. \n",
    "        <s3 s2 s1   | rho^{\\otimes 3} | Os1 s3 s2>   / <s3 s2 s1   | rho^{\\otimes 3} | s3 s2 s1>\n",
    "         = <s3 | rho | Os1> <s2 | rho | s3> < s1| rho | s2> / (<s3 | rho | s3> <s2 | rho | s2> < s1| rho | s1>)\n",
    "         =  (<s3 | rho | Os1> / <s3 | rho | s3>)\n",
    "          * (<s2 | rho | s3> / <s2 | rho | s2> )\n",
    "          * (< s1| rho | s2> / < s1| rho | s1>)\n",
    "         \n",
    "        importance_sampling_numerator(s3, Os1)  provides <s3 | rho | Os1>\n",
    "        importance_sampling_denominator(s3)     provides <s3 | rho | s3>\n",
    "        \"\"\"\n",
    "        for copy_index in range(self.num_copy):\n",
    "            st = copy_index * samples.shape[1]\n",
    "            en = (copy_index+1) * samples.shape[1]\n",
    "            # numerator is []\n",
    "            numerator = nn_state.importance_sampling_numerator(swapped_samples_array[:, st:en], samples_array[:, st:en])\n",
    "            denominator = nn_state.importance_sampling_denominator(samples_array[:, st:en])\n",
    "            values = cplx.elementwise_division(numerator, denominator)\n",
    "            total_prod = cplx.elementwise_mult(total_prod, values)\n",
    "\n",
    "        value = cplx.real(total_prod)\n",
    "        return value\n",
    "\n",
    "def calculate_distilled_expectation_value(pauli_dict: dict, num_samples: int, num_copies: int):\n",
    "    obs_num = GeneralPauliDistill(pauli_dict, num_copies)\n",
    "    obs_div = GeneralPauliDistill({}, num_copies)\n",
    "    num_stat = obs_num.statistics(nn_state_dm, num_samples=num_samples)\n",
    "    div_stat = obs_div.statistics(nn_state_dm, num_samples=num_samples)\n",
    "\n",
    "    from uncertainties import ufloat\n",
    "    num = ufloat(num_stat[\"mean\"], num_stat[\"std_error\"])\n",
    "    div = ufloat(div_stat[\"mean\"], div_stat[\"std_error\"])\n",
    "    val = num/div\n",
    "    result_dict = {\"mean\": val.n , \"std_error\": val.s, \"num_samples\": num_samples, \"num_copies\": num_copies}\n",
    "    return result_dict\n",
    "\n",
    "def get_density_matrix(nn_state):\n",
    "    space = nn_state.generate_hilbert_space()\n",
    "    Z = nn_state.normalization(space)\n",
    "    tensor = nn_state.rho(space, space)/Z\n",
    "    matrix = cplx.numpy(tensor)\n",
    "    return matrix\n",
    "\n",
    "def get_max_eigvec(matrix):\n",
    "    e_val, e_vec = np.linalg.eigh(matrix)\n",
    "    me_val = e_val[-1]\n",
    "    me_vec = e_vec[:,-1]\n",
    "    return me_vec\n",
    "\n",
    "def get_eigvec(nn_state, obs, space, **kwargs):\n",
    "    dm = get_density_matrix(nn_state)\n",
    "    ev = get_max_eigvec(dm)\n",
    "    ev = np.atleast_2d(ev)\n",
    "    val = ev@obs@ev.T.conj()\n",
    "    val = val[0,0].real\n",
    "    return val\n",
    "\n",
    "def observable_XX():\n",
    "    target_list = [0, 1]\n",
    "    pauli_index = [1, 1] # 1:X , 2:Y, 3:Z\n",
    "    gate = Pauli(target_list, pauli_index) # = X_1 X_2\n",
    "    return gate.get_matrix()\n",
    "\n",
    "def observable_XZ():\n",
    "    target_list = [0, 1]\n",
    "    pauli_index = [1, 3] # 1:X , 2:Y, 3:Z\n",
    "    gate = Pauli(target_list, pauli_index) # = X_1 Z_2\n",
    "    return gate.get_matrix()\n",
    "\n",
    "def observable_XX_ev(nn_state, **kwargs):\n",
    "    obs_stat = calculate_distilled_expectation_value({0: \"X\", 1: \"X\"}, n_sampling, n_copy)\n",
    "    return obs_stat[\"mean\"]\n",
    "\n",
    "def observable_XZ_ev(nn_state, **kwargs):\n",
    "    obs_stat = calculate_distilled_expectation_value({0: \"X\", 1: \"Z\"}, n_sampling, n_copy)\n",
    "    return obs_stat[\"mean\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064b4095-4a33-4938-9e25-f9d6cce67c73",
   "metadata": {},
   "source": [
    "## callback setting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6433a987-cec4-4698-8170-cf2955012fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_callback_dm(nn_state):\n",
    "    metric_dict = {\n",
    "        \"Fidelity\": ts.fidelity,\n",
    "        \"KL_Divergence\": ts.KL,\n",
    "        \"Observable_XX_ev\": observable_XX_ev,\n",
    "        \"Observable_XZ_ev\": observable_XZ_ev,\n",
    "    }\n",
    "\n",
    "    space = nn_state.generate_hilbert_space()\n",
    "    callbacks = [\n",
    "        MetricEvaluator(\n",
    "            period,\n",
    "            metric_dict,\n",
    "            target = ideal_rho,\n",
    "            bases = meas_pattern,\n",
    "            verbose = True,\n",
    "            space = space,\n",
    "        )\n",
    "    ]\n",
    "    return callbacks\n",
    "\n",
    "callbacks = create_callback_dm(nn_state_dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fd8047-5824-410e-a1cb-1851fcfc3f35",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "990cd783-aada-493b-b806-c64e330c1c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\tFidelity = 0.265495\tKL_Divergence = 0.512433\tObservable_XX_ev = 0.335303\tObservable_XZ_ev = 0.149640\n",
      "Epoch: 2\tFidelity = 0.228323\tKL_Divergence = 0.451013\tObservable_XX_ev = 0.455181\tObservable_XZ_ev = 0.114847\n",
      "Epoch: 3\tFidelity = 0.212612\tKL_Divergence = 0.398336\tObservable_XX_ev = 0.378688\tObservable_XZ_ev = -0.003447\n",
      "Epoch: 4\tFidelity = 0.201834\tKL_Divergence = 0.358751\tObservable_XX_ev = 0.274222\tObservable_XZ_ev = -0.215161\n",
      "Epoch: 5\tFidelity = 0.193229\tKL_Divergence = 0.331349\tObservable_XX_ev = 0.199053\tObservable_XZ_ev = -0.067179\n",
      "Epoch: 6\tFidelity = 0.194108\tKL_Divergence = 0.312975\tObservable_XX_ev = 0.108467\tObservable_XZ_ev = -0.207531\n",
      "Epoch: 7\tFidelity = 0.195864\tKL_Divergence = 0.299752\tObservable_XX_ev = 0.024019\tObservable_XZ_ev = -0.348139\n",
      "Epoch: 8\tFidelity = 0.200164\tKL_Divergence = 0.286990\tObservable_XX_ev = 0.033102\tObservable_XZ_ev = -0.187527\n",
      "Epoch: 9\tFidelity = 0.200029\tKL_Divergence = 0.285860\tObservable_XX_ev = -0.002734\tObservable_XZ_ev = -0.135493\n",
      "Epoch: 10\tFidelity = 0.211792\tKL_Divergence = 0.269944\tObservable_XX_ev = -0.016052\tObservable_XZ_ev = -0.324179\n",
      "Epoch: 11\tFidelity = 0.219882\tKL_Divergence = 0.262838\tObservable_XX_ev = -0.010290\tObservable_XZ_ev = -0.314619\n",
      "Epoch: 12\tFidelity = 0.224023\tKL_Divergence = 0.256894\tObservable_XX_ev = -0.052169\tObservable_XZ_ev = -0.247554\n",
      "Epoch: 13\tFidelity = 0.230358\tKL_Divergence = 0.252616\tObservable_XX_ev = -0.028030\tObservable_XZ_ev = -0.279424\n",
      "Epoch: 14\tFidelity = 0.235309\tKL_Divergence = 0.248212\tObservable_XX_ev = -0.010658\tObservable_XZ_ev = -0.300933\n",
      "Epoch: 15\tFidelity = 0.243040\tKL_Divergence = 0.252573\tObservable_XX_ev = -0.015221\tObservable_XZ_ev = -0.353377\n",
      "Epoch: 16\tFidelity = 0.256487\tKL_Divergence = 0.241213\tObservable_XX_ev = -0.025778\tObservable_XZ_ev = -0.311617\n",
      "Epoch: 17\tFidelity = 0.251748\tKL_Divergence = 0.236280\tObservable_XX_ev = 0.027654\tObservable_XZ_ev = -0.146560\n",
      "Epoch: 18\tFidelity = 0.256344\tKL_Divergence = 0.233318\tObservable_XX_ev = 0.015834\tObservable_XZ_ev = -0.248454\n",
      "Epoch: 19\tFidelity = 0.260486\tKL_Divergence = 0.231561\tObservable_XX_ev = 0.000584\tObservable_XZ_ev = -0.253745\n",
      "Epoch: 20\tFidelity = 0.261397\tKL_Divergence = 0.229672\tObservable_XX_ev = 0.004196\tObservable_XZ_ev = -0.200462\n",
      "Epoch: 21\tFidelity = 0.258043\tKL_Divergence = 0.231658\tObservable_XX_ev = 0.009007\tObservable_XZ_ev = -0.167966\n",
      "Epoch: 22\tFidelity = 0.256516\tKL_Divergence = 0.231447\tObservable_XX_ev = 0.007858\tObservable_XZ_ev = -0.194511\n",
      "Epoch: 23\tFidelity = 0.255272\tKL_Divergence = 0.232915\tObservable_XX_ev = 0.011432\tObservable_XZ_ev = -0.147710\n",
      "Epoch: 24\tFidelity = 0.253997\tKL_Divergence = 0.237622\tObservable_XX_ev = 0.000775\tObservable_XZ_ev = -0.148607\n",
      "Epoch: 25\tFidelity = 0.250205\tKL_Divergence = 0.233306\tObservable_XX_ev = 0.011109\tObservable_XZ_ev = -0.152498\n",
      "Epoch: 26\tFidelity = 0.257028\tKL_Divergence = 0.230777\tObservable_XX_ev = 0.015395\tObservable_XZ_ev = -0.158302\n",
      "Epoch: 27\tFidelity = 0.267575\tKL_Divergence = 0.238164\tObservable_XX_ev = 0.005132\tObservable_XZ_ev = -0.110071\n",
      "Epoch: 28\tFidelity = 0.259930\tKL_Divergence = 0.229786\tObservable_XX_ev = 0.014694\tObservable_XZ_ev = -0.077111\n",
      "Epoch: 29\tFidelity = 0.256107\tKL_Divergence = 0.230930\tObservable_XX_ev = 0.005147\tObservable_XZ_ev = -0.124697\n",
      "Epoch: 30\tFidelity = 0.256410\tKL_Divergence = 0.229742\tObservable_XX_ev = 0.009866\tObservable_XZ_ev = -0.234999\n",
      "Epoch: 31\tFidelity = 0.258825\tKL_Divergence = 0.228781\tObservable_XX_ev = 0.008850\tObservable_XZ_ev = -0.083247\n",
      "Epoch: 32\tFidelity = 0.264090\tKL_Divergence = 0.226450\tObservable_XX_ev = 0.010102\tObservable_XZ_ev = -0.080569\n",
      "Epoch: 33\tFidelity = 0.261949\tKL_Divergence = 0.232903\tObservable_XX_ev = 0.003739\tObservable_XZ_ev = -0.084346\n",
      "Epoch: 34\tFidelity = 0.257828\tKL_Divergence = 0.231393\tObservable_XX_ev = 0.006379\tObservable_XZ_ev = -0.074436\n",
      "Epoch: 35\tFidelity = 0.260663\tKL_Divergence = 0.231591\tObservable_XX_ev = 0.009490\tObservable_XZ_ev = -0.081089\n",
      "Epoch: 36\tFidelity = 0.254596\tKL_Divergence = 0.231731\tObservable_XX_ev = 0.009517\tObservable_XZ_ev = -0.127724\n",
      "Epoch: 37\tFidelity = 0.255846\tKL_Divergence = 0.231462\tObservable_XX_ev = 0.006061\tObservable_XZ_ev = -0.121895\n",
      "Epoch: 38\tFidelity = 0.257209\tKL_Divergence = 0.229648\tObservable_XX_ev = 0.004202\tObservable_XZ_ev = -0.123844\n",
      "Epoch: 39\tFidelity = 0.260561\tKL_Divergence = 0.229173\tObservable_XX_ev = 0.001601\tObservable_XZ_ev = -0.080224\n",
      "Epoch: 40\tFidelity = 0.262010\tKL_Divergence = 0.228188\tObservable_XX_ev = 0.000572\tObservable_XZ_ev = -0.071742\n",
      "Epoch: 41\tFidelity = 0.260422\tKL_Divergence = 0.227565\tObservable_XX_ev = 0.001282\tObservable_XZ_ev = -0.089746\n",
      "Epoch: 42\tFidelity = 0.265158\tKL_Divergence = 0.226723\tObservable_XX_ev = 0.001816\tObservable_XZ_ev = -0.056090\n",
      "Epoch: 43\tFidelity = 0.267156\tKL_Divergence = 0.225809\tObservable_XX_ev = 0.001481\tObservable_XZ_ev = -0.061208\n",
      "Epoch: 44\tFidelity = 0.261853\tKL_Divergence = 0.227581\tObservable_XX_ev = 0.000558\tObservable_XZ_ev = -0.065666\n",
      "Epoch: 45\tFidelity = 0.259864\tKL_Divergence = 0.228578\tObservable_XX_ev = 0.001569\tObservable_XZ_ev = -0.075034\n",
      "Epoch: 46\tFidelity = 0.259727\tKL_Divergence = 0.232040\tObservable_XX_ev = -0.002332\tObservable_XZ_ev = -0.063282\n",
      "Epoch: 47\tFidelity = 0.260649\tKL_Divergence = 0.227760\tObservable_XX_ev = -0.002372\tObservable_XZ_ev = -0.084427\n",
      "Epoch: 48\tFidelity = 0.262762\tKL_Divergence = 0.226804\tObservable_XX_ev = -0.003901\tObservable_XZ_ev = -0.052253\n",
      "Epoch: 49\tFidelity = 0.264651\tKL_Divergence = 0.225599\tObservable_XX_ev = -0.002184\tObservable_XZ_ev = -0.066129\n",
      "Epoch: 50\tFidelity = 0.264730\tKL_Divergence = 0.226529\tObservable_XX_ev = -0.002530\tObservable_XZ_ev = -0.046715\n",
      "Total time elapsed during training: 1341.344 s\n"
     ]
    }
   ],
   "source": [
    "nn_state_dm.fit(\n",
    "    data = meas_result,\n",
    "    input_bases = meas_label,\n",
    "    epochs = epoch,\n",
    "    pos_batch_size = pbs,\n",
    "    neg_batch_size = nbs,\n",
    "    lr = lr,\n",
    "    k = n_gibbs_step,\n",
    "    bases = meas_pattern,\n",
    "    callbacks = callbacks,\n",
    "    time = True,\n",
    "    optimizer = torch.optim.Adadelta,\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR,\n",
    "    scheduler_args = {\"step_size\": lr_drop_epoch, \"gamma\": lr_drop_factor},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd929000-b451-4c82-b6e8-1704360eac66",
   "metadata": {},
   "source": [
    "## save model & train log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d00c5ebc-98b0-4c46-a472-49df305499a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CFG' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [86]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# save train log\u001b[39;00m\n\u001b[1;32m      2\u001b[0m train_log_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[0;32m----> 3\u001b[0m train_log_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[43mCFG\u001b[49m\u001b[38;5;241m.\u001b[39mperiod, CFG\u001b[38;5;241m.\u001b[39mepochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, CFG\u001b[38;5;241m.\u001b[39mperiod)\n\u001b[1;32m      4\u001b[0m train_log_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFidelity\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m callbacks[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFidelity\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      5\u001b[0m train_log_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKL_Divergence\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m callbacks[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKL_Divergence\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CFG' is not defined"
     ]
    }
   ],
   "source": [
    "# save model\n",
    "\n",
    "# save train log\n",
    "train_log_df = pd.DataFrame()\n",
    "train_log_df[\"epoch\"] = np.arange(CFG.period, CFG.epochs + 1, CFG.period)\n",
    "train_log_df[\"Fidelity\"] = callbacks[0][\"Fidelity\"]\n",
    "train_log_df[\"KL_Divergence\"] = callbacks[0][\"KL_Divergence\"]\n",
    "train_log_df[\"Observable_XX_ev\"] = callbacks[0][\"Observable_XX_ev\"]\n",
    "train_log_df[\"Observable_XZ_ev\"] = callbacks[0][\"Observable_XZ_ev\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f06c23-3673-4844-91cf-b983c128cdf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
