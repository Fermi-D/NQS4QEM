{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "052aaffa-d670-4d3f-bed9-c07e12c063cf",
   "metadata": {},
   "source": [
    "## Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "732c2405-3fcb-489a-b931-15d9a7eb7845",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "from tqdm.notebook import tqdm\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "from qucumber.nn_states import DensityMatrix\n",
    "from qucumber.nn_states import ComplexWaveFunction\n",
    "from qucumber.callbacks import MetricEvaluator\n",
    "import qucumber.utils.unitaries as unitaries\n",
    "import qucumber.utils.training_statistics as ts\n",
    "import qucumber.utils.cplx as cplx\n",
    "import qucumber.utils.data as data\n",
    "from qucumber.observables import ObservableBase, to_pm1\n",
    "from qucumber.observables.pauli import flip_spin\n",
    "import qucumber\n",
    "\n",
    "from qulacs.gate import Pauli\n",
    "\n",
    "with open('./params_setting.yaml', 'r') as yml:\n",
    "    params = yaml.safe_load(yml)\n",
    "    \n",
    "# quantum circuit parameter\n",
    "n_qubit = params[\"circuit_info\"][\"n_qubit\"]\n",
    "each_n_shot = params[\"circuit_info\"][\"each_n_shot\"]\n",
    "state_name = params[\"circuit_info\"][\"state_name\"]\n",
    "error_model = params[\"circuit_info\"][\"error_model\"]\n",
    "error_rate = params[\"circuit_info\"][\"error_rate\"]\n",
    "# RBM architecture parameter\n",
    "n_visible_unit = params[\"architecture_info\"][\"n_visible_unit\"]\n",
    "n_hidden_unit = params[\"architecture_info\"][\"n_hidden_unit\"] \n",
    "n_aux_unit = params[\"architecture_info\"][\"n_aux_unit\"]\n",
    "# train parameter\n",
    "lr = params[\"train_info\"][\"lr\"]\n",
    "pbs = params[\"train_info\"][\"positive_batch_size\"]\n",
    "nbs = params[\"train_info\"][\"negative_batch_size\"]\n",
    "n_gibbs_step = params[\"train_info\"][\"n_gibbs_step\"]\n",
    "period = 1\n",
    "epoch = params[\"train_info\"][\"n_epoch\"]\n",
    "lr_drop_epoch = params[\"train_info\"][\"lr_drop_epoch\"]\n",
    "lr_drop_factor = params[\"train_info\"][\"lr_drop_factor\"]\n",
    "seed = params[\"train_info\"][\"seed\"]\n",
    "# sampling parameter\n",
    "n_sampling = params[\"sampling_info\"][\"n_sample\"]\n",
    "n_copy = params[\"sampling_info\"][\"n_copy\"]\n",
    "# data path info\n",
    "environment = \"local\"\n",
    "if environment == \"local\":\n",
    "    train_data_path = f\"./data/{error_model}/error_prob_{100*error_rate}%/num_of_data_{each_n_shot}/\"\n",
    "    ideal_state_path = f\"./target_state/\"\n",
    "if environment == \"colab\":\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive/\")\n",
    "    rive_path = \"/content/drive/MyDrive/NQS4QEM/Bell\"\n",
    "    train_data_path = drive_path + f\"/data/{error_model}/error_prob_{100*error_rate}%/num_of_data_{each_n_shot}/\"\n",
    "    ideal_state_path = drive_path + f\"/target_state/\"\n",
    "\n",
    "# settings\n",
    "## warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "## seaborn layout\n",
    "sns.set()\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "## seed\n",
    "def seed_settings(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    qucumber.set_random_seed(seed, cpu=True, gpu=False)\n",
    "\n",
    "seed_settings(seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f117e73d-0af0-430e-8a7c-3b2d47ef109a",
   "metadata": {},
   "source": [
    "## caluculate ideal state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d800bd19-5c39-4fcf-9f48-49451f4574a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ideal state data is exsisted !\n"
     ]
    }
   ],
   "source": [
    "# calculate ideal state\n",
    "is_ideal_state_file = os.path.exists(ideal_state_path)\n",
    "if is_ideal_state_file:\n",
    "    print(\"ideal state data is exsisted !\")\n",
    "else:\n",
    "    print(\"caluculate ideal state data ...\")\n",
    "    subprocess.run(\"python caluculate_ideal_state.py\", shell=True)\n",
    "    print(\"ideal state data is ready !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3a9677-cd6b-41d8-92a1-47a74a019756",
   "metadata": {},
   "source": [
    "## generate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8227038-435d-419b-a558-f30b8643125e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data is exsisted !\n"
     ]
    }
   ],
   "source": [
    "# generate train data\n",
    "is_train_data_file = os.path.exists(train_data_path)\n",
    "if is_train_data_file:\n",
    "    print(\"train data is exsisted !\")\n",
    "else:\n",
    "    print(\"generate directries & train data ...\")\n",
    "    os.makedirs(train_data_path, exist_ok = True)\n",
    "    subprocess.run(\"python generate_dataset.py\", shell=True)\n",
    "    print(\"train data is ready !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b90a855-f64f-4d31-9dff-25973fd5bbfb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## estimate observable expectation value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f385a22-df7a-49b0-880d-39dadb7f6922",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneralPauliDistill(ObservableBase):\n",
    "    def __init__(self, pauli_dict: dict, m: int) -> None:\n",
    "        self.name = \"distilled_pauli\"\n",
    "        self.symbol = \"distilled_general_pauli\"\n",
    "        self.pauli_dict = pauli_dict\n",
    "        self.num_copy = m\n",
    "        \n",
    "    def apply(self, nn_state, samples):\n",
    "        \"\"\"\n",
    "        This function calcualte <x1 x2 ... xm | rho^{\\otimes m} O | xm x1 x2 ... xm-1> / <x1 x2 ... xm | rho^{\\otimes m} | x1 x2 ... xm>\n",
    "        where O acts only on the first register.\n",
    "        \"\"\"\n",
    "        \n",
    "        # [num_sample, num_visible_node]\n",
    "        # samples = [s1, s2, s3 ... sN]\n",
    "        #  where num_sample = N, and si is num_visible_node-bits\n",
    "        samples = samples.to(device=nn_state.device)\n",
    "        \n",
    "        num_sample, num_visible_node = samples.shape\n",
    "        \n",
    "        # [num_sample, num_visible_node * num_copy]\n",
    "        # samples_array = [[s1 sN sN-1], [s2 s1 sN], [s3 s2 s1],.. [sN sN-1 sN-2]]\n",
    "        #  each row is num_copy*num_visible_node bits the above example is for num_copy=3\n",
    "        samples_array = []\n",
    "        for copy_index in range(self.num_copy):\n",
    "            rolled_samples = torch.roll(samples, shifts=copy_index, dims=0)\n",
    "            samples_array.append(rolled_samples)\n",
    "        samples_array = torch.hstack(samples_array)\n",
    "        assert(samples_array.shape[0] == num_sample)\n",
    "        assert(samples_array.shape[1] == num_visible_node * self.num_copy)\n",
    "        \n",
    "        # roll second dim of [num_sample, num_visible_node * num_copy] by num_visible_node\n",
    "        # swapped_samples_array = [[sN-1 s1 sN], [sN s2 s1], [s1 s3 s2],.. [sN-2 sN sN-1]]\n",
    "        swapped_samples_array = torch.roll(samples_array, shifts = num_visible_node, dims=1)\n",
    "\n",
    "        # pick copy of first block\n",
    "        #  first_block_sample = [sN-1, sN, s1, s2, ... sN-2]\n",
    "        first_block_sample = swapped_samples_array[:, :num_visible_node].clone()\n",
    "\n",
    "        # calculate coefficient for first block [num_samples, 0:num_visible_node]\n",
    "        total_prod = cplx.make_complex(torch.ones_like(samples[:,0]), torch.zeros_like(samples[:,0]))\n",
    "        for index, pauli in self.pauli_dict.items():\n",
    "            assert(index < num_visible_node)\n",
    "            coeff = to_pm1(first_block_sample[:, index])\n",
    "            if pauli == \"Z\":\n",
    "                coeff = cplx.make_complex(coeff, torch.zeros_like(coeff))\n",
    "                total_prod = cplx.elementwise_mult(coeff, total_prod)\n",
    "            elif pauli == \"Y\":\n",
    "                coeff = cplx.make_complex(torch.zeros_like(coeff), coeff)\n",
    "                total_prod = cplx.elementwise_mult(coeff, total_prod)\n",
    "        \n",
    "        # flip samples for for first block [num_samples, 0:num_visible_node]\n",
    "        # first_block_sample -> [OsN-1, OsN, Os1, Os2, ... OsN-2]\n",
    "        #  where Osi is bit array after Pauli bit-flips \n",
    "        for index, pauli in self.pauli_dict.items():\n",
    "            assert(index < num_visible_node)\n",
    "            if pauli in [\"X\", \"Y\"]:\n",
    "                first_block_sample = flip_spin(index, first_block_sample)\n",
    "\n",
    "\n",
    "        # store flipped first block\n",
    "        swapped_samples_array[:, :num_visible_node] = first_block_sample\n",
    "\n",
    "        # calculate product of coefficients\n",
    "        # samples_array = [[s1 sN sN-1], [s2 s1 sN], [s3 s2 s1],.. [sN sN-1 sN-2]]\n",
    "        # swapped_samples_array = [[OsN-1 s1 sN], [OsN s2 s1], [Os1 s3 s2],.. [OsN-2 sN sN-1]]\n",
    "        \"\"\"\n",
    "        total_prod = [\n",
    "            <s1 sN sN-1 | rho^{\\otimes 3} | OsN-1 s1 sN> / <s1 sN sN-1 | rho^{\\otimes 3} | s1 sN sN-1> , \n",
    "            <s2 s1 sN   | rho^{\\otimes 3} | OsN s2 s1>   / <s2 s1 sN   | rho^{\\otimes 3} | s2 s1 sN> , \n",
    "            <s3 s2 s1   | rho^{\\otimes 3} | Os1 s3 s2>   / <s3 s2 s1   | rho^{\\otimes 3} | s3 s2 s1> , \n",
    "\n",
    "        e.g. \n",
    "        <s3 s2 s1   | rho^{\\otimes 3} | Os1 s3 s2>   / <s3 s2 s1   | rho^{\\otimes 3} | s3 s2 s1>\n",
    "         = <s3 | rho | Os1> <s2 | rho | s3> < s1| rho | s2> / (<s3 | rho | s3> <s2 | rho | s2> < s1| rho | s1>)\n",
    "         =  (<s3 | rho | Os1> / <s3 | rho | s3>)\n",
    "          * (<s2 | rho | s3> / <s2 | rho | s2> )\n",
    "          * (< s1| rho | s2> / < s1| rho | s1>)\n",
    "         \n",
    "        importance_sampling_numerator(s3, Os1)  provides <s3 | rho | Os1>\n",
    "        importance_sampling_denominator(s3)     provides <s3 | rho | s3>\n",
    "        \"\"\"\n",
    "        for copy_index in range(self.num_copy):\n",
    "            st = copy_index * samples.shape[1]\n",
    "            en = (copy_index+1) * samples.shape[1]\n",
    "            # numerator is []\n",
    "            numerator = nn_state.importance_sampling_numerator(swapped_samples_array[:, st:en], samples_array[:, st:en])\n",
    "            denominator = nn_state.importance_sampling_denominator(samples_array[:, st:en])\n",
    "            values = cplx.elementwise_division(numerator, denominator)\n",
    "            total_prod = cplx.elementwise_mult(total_prod, values)\n",
    "\n",
    "        value = cplx.real(total_prod)\n",
    "        return value\n",
    "\n",
    "def calculate_distilled_expectation_value(pauli_dict: dict, num_samples: int, num_copies: int):\n",
    "    obs_num = GeneralPauliDistill(pauli_dict, num_copies)\n",
    "    obs_div = GeneralPauliDistill({}, num_copies)\n",
    "    num_stat = obs_num.statistics(nn_state_dm, num_samples=num_samples)\n",
    "    div_stat = obs_div.statistics(nn_state_dm, num_samples=num_samples)\n",
    "\n",
    "    from uncertainties import ufloat\n",
    "    num = ufloat(num_stat[\"mean\"], num_stat[\"std_error\"])\n",
    "    div = ufloat(div_stat[\"mean\"], div_stat[\"std_error\"])\n",
    "    val = num/div\n",
    "    result_dict = {\"mean\": val.n , \"std_error\": val.s, \"num_samples\": num_samples, \"num_copies\": num_copies}\n",
    "    return result_dict\n",
    "\n",
    "def get_density_matrix(nn_state):\n",
    "    space = nn_state.generate_hilbert_space()\n",
    "    Z = nn_state.normalization(space)\n",
    "    tensor = nn_state.rho(space, space)/Z\n",
    "    matrix = cplx.numpy(tensor)\n",
    "    return matrix\n",
    "\n",
    "def get_max_eigvec(matrix):\n",
    "    e_val, e_vec = np.linalg.eigh(matrix)\n",
    "    me_val = e_val[-1]\n",
    "    me_vec = e_vec[:,-1]\n",
    "    return me_vec\n",
    "\n",
    "def get_eigvec(nn_state, obs, space, **kwargs):\n",
    "    dm = get_density_matrix(nn_state)\n",
    "    ev = get_max_eigvec(dm)\n",
    "    ev = np.atleast_2d(ev)\n",
    "    val = ev@obs@ev.T.conj()\n",
    "    val = val[0,0].real\n",
    "    return val\n",
    "\n",
    "def observable_XX():\n",
    "    target_list = [0, 1]\n",
    "    pauli_index = [1, 1] # 1:X , 2:Y, 3:Z\n",
    "    gate = Pauli(target_list, pauli_index) # = X_1 X_2\n",
    "    return gate.get_matrix()\n",
    "\n",
    "def observable_XZ():\n",
    "    target_list = [0, 1]\n",
    "    pauli_index = [1, 3] # 1:X , 2:Y, 3:Z\n",
    "    gate = Pauli(target_list, pauli_index) # = X_1 Z_2\n",
    "    return gate.get_matrix()\n",
    "\n",
    "def observable_XX_ev(nn_state, **kwargs):\n",
    "    obs_stat = calculate_distilled_expectation_value({0: \"X\", 1: \"X\"}, n_sampling, n_copy)\n",
    "    return obs_stat[\"mean\"]\n",
    "\n",
    "def observable_XZ_ev(nn_state, **kwargs):\n",
    "    obs_stat = calculate_distilled_expectation_value({0: \"X\", 1: \"Z\"}, n_sampling, n_copy)\n",
    "    return obs_stat[\"mean\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064b4095-4a33-4938-9e25-f9d6cce67c73",
   "metadata": {},
   "source": [
    "## callback setting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6433a987-cec4-4698-8170-cf2955012fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_callback_dm(nn_state):\n",
    "    metric_dict = {\n",
    "        \"Fidelity\": ts.fidelity,\n",
    "        \"KL_Divergence\": ts.KL,\n",
    "        #\"Observable_XX_ev\": observable_XX_ev,\n",
    "        #\"Observable_XZ_ev\": observable_XZ_ev,\n",
    "    }\n",
    "\n",
    "    space = nn_state.generate_hilbert_space()\n",
    "    callbacks = [\n",
    "        MetricEvaluator(\n",
    "            period,\n",
    "            metric_dict,\n",
    "            target = ideal_rho,\n",
    "            bases = meas_pattern,\n",
    "            verbose = True,\n",
    "            space = space,\n",
    "        )\n",
    "    ]\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fd8047-5824-410e-a1cb-1851fcfc3f35",
   "metadata": {},
   "source": [
    "## experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "990cd783-aada-493b-b806-c64e330c1c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error_model : depolarizing, each_n_shot : 1000\n",
      "Epoch: 1\tFidelity = 0.396704\tKL_Divergence = 0.644484\n",
      "Epoch: 2\tFidelity = 0.396416\tKL_Divergence = 0.639505\n",
      "Epoch: 3\tFidelity = 0.395735\tKL_Divergence = 0.634779\n",
      "Epoch: 4\tFidelity = 0.394695\tKL_Divergence = 0.630345\n",
      "Epoch: 5\tFidelity = 0.393977\tKL_Divergence = 0.625970\n",
      "Epoch: 6\tFidelity = 0.392917\tKL_Divergence = 0.621690\n",
      "Epoch: 7\tFidelity = 0.391216\tKL_Divergence = 0.617530\n",
      "Epoch: 8\tFidelity = 0.389584\tKL_Divergence = 0.613567\n",
      "Epoch: 9\tFidelity = 0.388273\tKL_Divergence = 0.609749\n",
      "Epoch: 10\tFidelity = 0.386677\tKL_Divergence = 0.605895\n",
      "Epoch: 11\tFidelity = 0.385503\tKL_Divergence = 0.602601\n",
      "Epoch: 12\tFidelity = 0.384054\tKL_Divergence = 0.599528\n",
      "Epoch: 13\tFidelity = 0.382178\tKL_Divergence = 0.596539\n",
      "Epoch: 14\tFidelity = 0.380156\tKL_Divergence = 0.593625\n",
      "Epoch: 15\tFidelity = 0.377944\tKL_Divergence = 0.590944\n",
      "Epoch: 16\tFidelity = 0.375923\tKL_Divergence = 0.588116\n",
      "Epoch: 17\tFidelity = 0.373910\tKL_Divergence = 0.585551\n",
      "Epoch: 18\tFidelity = 0.371450\tKL_Divergence = 0.582902\n",
      "Epoch: 19\tFidelity = 0.368905\tKL_Divergence = 0.580320\n",
      "Epoch: 20\tFidelity = 0.366523\tKL_Divergence = 0.577994\n",
      "Epoch: 21\tFidelity = 0.364471\tKL_Divergence = 0.575919\n",
      "Epoch: 22\tFidelity = 0.362316\tKL_Divergence = 0.573801\n",
      "Epoch: 23\tFidelity = 0.359711\tKL_Divergence = 0.571689\n",
      "Epoch: 24\tFidelity = 0.357417\tKL_Divergence = 0.569743\n",
      "Epoch: 25\tFidelity = 0.355153\tKL_Divergence = 0.567993\n",
      "Epoch: 26\tFidelity = 0.352844\tKL_Divergence = 0.566165\n",
      "Epoch: 27\tFidelity = 0.350520\tKL_Divergence = 0.564449\n",
      "Epoch: 28\tFidelity = 0.348542\tKL_Divergence = 0.562837\n",
      "Epoch: 29\tFidelity = 0.346439\tKL_Divergence = 0.561355\n",
      "Epoch: 30\tFidelity = 0.344186\tKL_Divergence = 0.559760\n",
      "Epoch: 31\tFidelity = 0.342066\tKL_Divergence = 0.558354\n",
      "Epoch: 32\tFidelity = 0.339795\tKL_Divergence = 0.557105\n",
      "Epoch: 33\tFidelity = 0.337496\tKL_Divergence = 0.555843\n",
      "Epoch: 34\tFidelity = 0.335345\tKL_Divergence = 0.554502\n",
      "Epoch: 35\tFidelity = 0.332942\tKL_Divergence = 0.553122\n",
      "Epoch: 36\tFidelity = 0.330655\tKL_Divergence = 0.551958\n",
      "Epoch: 37\tFidelity = 0.328306\tKL_Divergence = 0.550764\n",
      "Epoch: 38\tFidelity = 0.326142\tKL_Divergence = 0.549699\n",
      "Epoch: 39\tFidelity = 0.324323\tKL_Divergence = 0.548590\n",
      "Epoch: 40\tFidelity = 0.322132\tKL_Divergence = 0.547428\n",
      "Epoch: 41\tFidelity = 0.320331\tKL_Divergence = 0.546460\n",
      "Epoch: 42\tFidelity = 0.318637\tKL_Divergence = 0.545591\n",
      "Epoch: 43\tFidelity = 0.316975\tKL_Divergence = 0.544749\n",
      "Epoch: 44\tFidelity = 0.315394\tKL_Divergence = 0.543914\n",
      "Epoch: 45\tFidelity = 0.314036\tKL_Divergence = 0.543030\n",
      "Epoch: 46\tFidelity = 0.312617\tKL_Divergence = 0.542254\n",
      "Epoch: 47\tFidelity = 0.311357\tKL_Divergence = 0.541458\n",
      "Epoch: 48\tFidelity = 0.309715\tKL_Divergence = 0.540674\n",
      "Epoch: 49\tFidelity = 0.308461\tKL_Divergence = 0.539906\n",
      "Epoch: 50\tFidelity = 0.307135\tKL_Divergence = 0.539205\n",
      "Epoch: 51\tFidelity = 0.305782\tKL_Divergence = 0.538493\n",
      "Epoch: 52\tFidelity = 0.304505\tKL_Divergence = 0.537792\n",
      "Epoch: 53\tFidelity = 0.303268\tKL_Divergence = 0.537114\n",
      "Epoch: 54\tFidelity = 0.302236\tKL_Divergence = 0.536465\n",
      "Epoch: 55\tFidelity = 0.301030\tKL_Divergence = 0.535827\n",
      "Epoch: 56\tFidelity = 0.300084\tKL_Divergence = 0.535244\n",
      "Epoch: 57\tFidelity = 0.299122\tKL_Divergence = 0.534578\n",
      "Epoch: 58\tFidelity = 0.298112\tKL_Divergence = 0.533957\n",
      "Epoch: 59\tFidelity = 0.297009\tKL_Divergence = 0.533278\n",
      "Epoch: 60\tFidelity = 0.296141\tKL_Divergence = 0.532738\n",
      "Epoch: 61\tFidelity = 0.295638\tKL_Divergence = 0.532265\n",
      "Epoch: 62\tFidelity = 0.294817\tKL_Divergence = 0.531748\n",
      "Epoch: 63\tFidelity = 0.294040\tKL_Divergence = 0.531227\n",
      "Epoch: 64\tFidelity = 0.293250\tKL_Divergence = 0.530729\n",
      "Epoch: 65\tFidelity = 0.292521\tKL_Divergence = 0.530232\n",
      "Epoch: 66\tFidelity = 0.291592\tKL_Divergence = 0.529685\n",
      "Epoch: 67\tFidelity = 0.290566\tKL_Divergence = 0.529189\n",
      "Epoch: 68\tFidelity = 0.290012\tKL_Divergence = 0.528688\n",
      "Epoch: 69\tFidelity = 0.289535\tKL_Divergence = 0.528238\n",
      "Epoch: 70\tFidelity = 0.288649\tKL_Divergence = 0.527738\n",
      "Epoch: 71\tFidelity = 0.288022\tKL_Divergence = 0.527305\n",
      "Epoch: 72\tFidelity = 0.287460\tKL_Divergence = 0.526824\n",
      "Epoch: 73\tFidelity = 0.286951\tKL_Divergence = 0.526431\n",
      "Epoch: 74\tFidelity = 0.286345\tKL_Divergence = 0.525970\n",
      "Epoch: 75\tFidelity = 0.285893\tKL_Divergence = 0.525534\n",
      "Epoch: 76\tFidelity = 0.285172\tKL_Divergence = 0.525086\n",
      "Epoch: 77\tFidelity = 0.284412\tKL_Divergence = 0.524648\n",
      "Epoch: 78\tFidelity = 0.283854\tKL_Divergence = 0.524261\n",
      "Epoch: 79\tFidelity = 0.283496\tKL_Divergence = 0.523849\n",
      "Epoch: 80\tFidelity = 0.283049\tKL_Divergence = 0.523393\n",
      "Epoch: 81\tFidelity = 0.282402\tKL_Divergence = 0.522970\n",
      "Epoch: 82\tFidelity = 0.281940\tKL_Divergence = 0.522581\n",
      "Epoch: 83\tFidelity = 0.281571\tKL_Divergence = 0.522186\n",
      "Epoch: 84\tFidelity = 0.281127\tKL_Divergence = 0.521799\n",
      "Epoch: 85\tFidelity = 0.280645\tKL_Divergence = 0.521409\n",
      "Epoch: 86\tFidelity = 0.280171\tKL_Divergence = 0.521019\n",
      "Epoch: 87\tFidelity = 0.279704\tKL_Divergence = 0.520625\n",
      "Epoch: 88\tFidelity = 0.279428\tKL_Divergence = 0.520272\n",
      "Epoch: 89\tFidelity = 0.279171\tKL_Divergence = 0.519907\n",
      "Epoch: 90\tFidelity = 0.278695\tKL_Divergence = 0.519507\n",
      "Epoch: 91\tFidelity = 0.278411\tKL_Divergence = 0.519156\n",
      "Epoch: 92\tFidelity = 0.277948\tKL_Divergence = 0.518788\n",
      "Epoch: 93\tFidelity = 0.277688\tKL_Divergence = 0.518496\n",
      "Epoch: 94\tFidelity = 0.277340\tKL_Divergence = 0.518182\n",
      "Epoch: 95\tFidelity = 0.277011\tKL_Divergence = 0.517840\n",
      "Epoch: 96\tFidelity = 0.276815\tKL_Divergence = 0.517533\n",
      "Epoch: 97\tFidelity = 0.276577\tKL_Divergence = 0.517200\n",
      "Epoch: 98\tFidelity = 0.276276\tKL_Divergence = 0.516842\n",
      "Epoch: 99\tFidelity = 0.275886\tKL_Divergence = 0.516480\n",
      "Epoch: 100\tFidelity = 0.275572\tKL_Divergence = 0.516148\n",
      "Epoch: 101\tFidelity = 0.275356\tKL_Divergence = 0.515857\n",
      "Epoch: 102\tFidelity = 0.275109\tKL_Divergence = 0.515555\n",
      "Epoch: 103\tFidelity = 0.274907\tKL_Divergence = 0.515241\n",
      "Epoch: 104\tFidelity = 0.274569\tKL_Divergence = 0.514908\n",
      "Epoch: 105\tFidelity = 0.274362\tKL_Divergence = 0.514625\n",
      "Epoch: 106\tFidelity = 0.274045\tKL_Divergence = 0.514306\n",
      "Epoch: 107\tFidelity = 0.273755\tKL_Divergence = 0.513993\n",
      "Epoch: 108\tFidelity = 0.273574\tKL_Divergence = 0.513685\n",
      "Epoch: 109\tFidelity = 0.273208\tKL_Divergence = 0.513383\n",
      "Epoch: 110\tFidelity = 0.272980\tKL_Divergence = 0.513086\n",
      "Epoch: 111\tFidelity = 0.272662\tKL_Divergence = 0.512796\n",
      "Epoch: 112\tFidelity = 0.272523\tKL_Divergence = 0.512526\n",
      "Epoch: 113\tFidelity = 0.272327\tKL_Divergence = 0.512243\n",
      "Epoch: 114\tFidelity = 0.272243\tKL_Divergence = 0.511970\n",
      "Epoch: 115\tFidelity = 0.271945\tKL_Divergence = 0.511675\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m nn_state_dm \u001b[38;5;241m=\u001b[39m DensityMatrix(num_visible \u001b[38;5;241m=\u001b[39m n_visible_unit, \n\u001b[1;32m     22\u001b[0m                             num_hidden \u001b[38;5;241m=\u001b[39m n_hidden_unit, \n\u001b[1;32m     23\u001b[0m                             num_aux \u001b[38;5;241m=\u001b[39m n_aux_unit, \n\u001b[1;32m     24\u001b[0m                             unitary_dict \u001b[38;5;241m=\u001b[39m unitaries\u001b[38;5;241m.\u001b[39mcreate_dict(),\n\u001b[1;32m     25\u001b[0m                             gpu \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     27\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m create_callback_dm(nn_state_dm)\n\u001b[0;32m---> 29\u001b[0m \u001b[43mnn_state_dm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmeas_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m                \u001b[49m\u001b[43minput_bases\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmeas_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m                \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m                \u001b[49m\u001b[43mpos_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpbs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m                \u001b[49m\u001b[43mneg_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnbs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m                \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m                \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_gibbs_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m                \u001b[49m\u001b[43mbases\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmeas_pattern\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m                \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdadelta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m                \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_scheduler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStepLR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m                \u001b[49m\u001b[43mscheduler_args\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstep_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_drop_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgamma\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_drop_factor\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m               \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# save model\u001b[39;00m\n\u001b[1;32m     45\u001b[0m nn_state_dm\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./exp_mixed_state_varying_n_shot/model_n_pattern_shot=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00meach_n_shot\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_model\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_5%.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/density_matrix.py:354\u001b[0m, in \u001b[0;36mDensityMatrix.fit\u001b[0;34m(self, data, epochs, pos_batch_size, neg_batch_size, k, lr, input_bases, progbar, starting_epoch, time, callbacks, optimizer, optimizer_args, scheduler, scheduler_args, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_bases must be provided to train a DensityMatrix!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 354\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneg_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneg_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_bases\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_bases\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstarting_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstarting_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtime\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscheduler_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/neural_state.py:614\u001b[0m, in \u001b[0;36mNeuralStateBase.fit\u001b[0;34m(self, data, epochs, pos_batch_size, neg_batch_size, k, lr, input_bases, progbar, starting_epoch, time, callbacks, optimizer, optimizer_args, scheduler, scheduler_args, **kwargs)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m b, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_iterator):\n\u001b[1;32m    612\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_batch_start(\u001b[38;5;28mself\u001b[39m, ep, b)\n\u001b[0;32m--> 614\u001b[0m     all_grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_batch_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    616\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()  \u001b[38;5;66;03m# clear any cached gradients\u001b[39;00m\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;66;03m# assign gradients to corresponding parameters\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/neural_state.py:439\u001b[0m, in \u001b[0;36mNeuralStateBase.compute_batch_gradients\u001b[0;34m(self, k, samples_batch, neg_batch, bases_batch)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;124;03m\"\"\"Compute the gradients of a batch of the training data (`samples_batch`).\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \n\u001b[1;32m    420\u001b[0m \u001b[38;5;124;03mIf measurements are taken in bases other than the reference basis,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;124;03m:rtype: list[torch.Tensor]\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;66;03m# Positive phase: learning signal driven by the data (and bases)\u001b[39;00m\n\u001b[0;32m--> 439\u001b[0m grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpositive_phase_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbases_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbases_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;66;03m# Negative phase: learning signal driven by the amplitude RBM of\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;66;03m# the NN state\u001b[39;00m\n\u001b[1;32m    443\u001b[0m vk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrbm_am\u001b[38;5;241m.\u001b[39mgibbs_steps(k, neg_batch)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/neural_state.py:382\u001b[0m, in \u001b[0;36mNeuralStateBase.positive_phase_gradients\u001b[0;34m(self, samples_batch, bases_batch)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpositive_phase_gradients\u001b[39m(\u001b[38;5;28mself\u001b[39m, samples_batch, bases_batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Computes the positive phase of the gradients of the parameters.\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \n\u001b[1;32m    374\u001b[0m \u001b[38;5;124;03m    :param samples_batch: The measurements\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;124;03m    :rtype: list[torch.Tensor]\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 382\u001b[0m     grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbases\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbases_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    383\u001b[0m     grad \u001b[38;5;241m=\u001b[39m [gr \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mfloat\u001b[39m(samples_batch\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m gr \u001b[38;5;129;01min\u001b[39;00m grad]\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m grad\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/neural_state.py:359\u001b[0m, in \u001b[0;36mNeuralStateBase.gradient\u001b[0;34m(self, samples, bases)\u001b[0m\n\u001b[1;32m    356\u001b[0m rot_sites \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(basis \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZ\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rot_sites\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 359\u001b[0m     sample_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrotated_gradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbasis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    361\u001b[0m     sample_grad \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    362\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrbm_am\u001b[38;5;241m.\u001b[39meffective_energy_gradient(samples[indices \u001b[38;5;241m==\u001b[39m i, :]),\n\u001b[1;32m    363\u001b[0m         \u001b[38;5;241m0.0\u001b[39m,\n\u001b[1;32m    364\u001b[0m     ]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/density_matrix.py:293\u001b[0m, in \u001b[0;36mDensityMatrix.rotated_gradient\u001b[0;34m(self, basis, sample)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrotated_gradient\u001b[39m(\u001b[38;5;28mself\u001b[39m, basis, sample):\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Computes the gradients rotated into the measurement basis\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \n\u001b[1;32m    284\u001b[0m \u001b[38;5;124;03m    :param basis: The bases in which the measurement is made\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m    :rtype: list[torch.Tensor, torch.Tensor]\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m     UrhoU, UrhoU_v, v \u001b[38;5;241m=\u001b[39m \u001b[43munitaries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrotate_rho_probs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbasis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_extras\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m     inv_UrhoU \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m (UrhoU \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-8\u001b[39m)  \u001b[38;5;66;03m# avoid dividing by zero\u001b[39;00m\n\u001b[1;32m    298\u001b[0m     raw_grads \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mam_grads(v), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mph_grads(v)]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/qucumber/utils/unitaries.py:266\u001b[0m, in \u001b[0;36mrotate_rho_probs\u001b[0;34m(nn_state, basis, states, unitaries, rho, include_extras)\u001b[0m\n\u001b[1;32m    263\u001b[0m Ut \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mib,jb->ijb\u001b[39m\u001b[38;5;124m\"\u001b[39m, Ut, np\u001b[38;5;241m.\u001b[39mconj(Ut))\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rho \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 266\u001b[0m     rho \u001b[38;5;241m=\u001b[39m \u001b[43mnn_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrho\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;66;03m# pick out the entries of rho that we actually need\u001b[39;00m\n\u001b[1;32m    269\u001b[0m     idx \u001b[38;5;241m=\u001b[39m _convert_basis_element_to_index(v)\u001b[38;5;241m.\u001b[39mlong()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/qucumber/nn_states/density_matrix.py:270\u001b[0m, in \u001b[0;36mDensityMatrix.rho\u001b[0;34m(self, v, vp, expand)\u001b[0m\n\u001b[1;32m    267\u001b[0m     vp \u001b[38;5;241m=\u001b[39m v\n\u001b[1;32m    269\u001b[0m pi_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpi(v, vp, expand\u001b[38;5;241m=\u001b[39mexpand)\n\u001b[0;32m--> 270\u001b[0m amp \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrbm_am\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgamma\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcplx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpi_\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m phase \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrbm_ph\u001b[38;5;241m.\u001b[39mgamma(v, vp, eta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, expand\u001b[38;5;241m=\u001b[39mexpand) \u001b[38;5;241m+\u001b[39m cplx\u001b[38;5;241m.\u001b[39mimag(pi_)\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cplx\u001b[38;5;241m.\u001b[39mmake_complex(amp \u001b[38;5;241m*\u001b[39m phase\u001b[38;5;241m.\u001b[39mcos(), amp \u001b[38;5;241m*\u001b[39m phase\u001b[38;5;241m.\u001b[39msin())\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# experiment params\n",
    "#each_n_shot_list = [10, 50, 100, 500, 1000, 5000, 10000]\n",
    "each_n_shot_list = [1000]\n",
    "error_model_list = [\"depolarizing\", \"unitary\", \"depolarizing&unitary\"]\n",
    "\n",
    "for error_model in error_model_list:\n",
    "    for each_n_shot in each_n_shot_list:\n",
    "        print(f\"error_model : {error_model}, each_n_shot : {each_n_shot}\")\n",
    "        train_data_path = f\"./data/{error_model}/error_prob_{100*error_rate}%/num_of_data_{each_n_shot}/\"\n",
    "        meas_pattern_path = train_data_path + \"/measurement_pattern.txt\"\n",
    "        meas_label_path = train_data_path + \"/measurement_label.txt\"\n",
    "        meas_result_path = train_data_path + \"/measurement_result.txt\"\n",
    "        ideal_rho_re_path = ideal_state_path + \"/rho_real.txt\"\n",
    "        ideal_rho_im_path = ideal_state_path + \"/rho_imag.txt\"\n",
    "        meas_result, ideal_rho, meas_label, meas_pattern = data.load_data_DM(meas_result_path,\n",
    "                                                                             ideal_rho_re_path,\n",
    "                                                                             ideal_rho_im_path,\n",
    "                                                                             meas_label_path,\n",
    "                                                                             meas_pattern_path)\n",
    "        \n",
    "        nn_state_dm = DensityMatrix(num_visible = n_visible_unit, \n",
    "                                    num_hidden = n_hidden_unit, \n",
    "                                    num_aux = n_aux_unit, \n",
    "                                    unitary_dict = unitaries.create_dict(),\n",
    "                                    gpu = False)\n",
    "        \n",
    "        callbacks = create_callback_dm(nn_state_dm)\n",
    "        \n",
    "        nn_state_dm.fit(data = meas_result,\n",
    "                        input_bases = meas_label,\n",
    "                        epochs = epoch,\n",
    "                        pos_batch_size = pbs,\n",
    "                        neg_batch_size = nbs,\n",
    "                        lr = lr,\n",
    "                        k = n_gibbs_step,\n",
    "                        bases = meas_pattern,\n",
    "                        callbacks = callbacks,\n",
    "                        time = True,\n",
    "                        optimizer = torch.optim.Adadelta,\n",
    "                        scheduler = torch.optim.lr_scheduler.StepLR,\n",
    "                        scheduler_args = {\"step_size\": lr_drop_epoch, \"gamma\": lr_drop_factor},\n",
    "                       )\n",
    "        \n",
    "        # save model\n",
    "        nn_state_dm.save(f\"./exp_mixed_state_varying_n_shot/model_n_pattern_shot={each_n_shot}_{error_model}_5%.pt\")\n",
    "        # save train log\n",
    "        train_log_df = pd.DataFrame()\n",
    "        train_log_df[\"epoch\"] = np.arange(period, epoch+1, period)\n",
    "        train_log_df[\"Fidelity\"] = callbacks[0][\"Fidelity\"]\n",
    "        train_log_df[\"KL_Divergence\"] = callbacks[0][\"KL_Divergence\"]\n",
    "        #train_log_df[\"Observable_XX_ev\"] = callbacks[0][\"Observable_XX_ev\"]\n",
    "        #train_log_df[\"Observable_ZZ_ev\"] = callbacks[0][\"Observable_ZZ_ev\"]\n",
    "        train_log_df.to_csv(f\"./exp_mixed_state_varying_n_shot/model_n_pattern_shot={each_n_shot}_{error_model}_5%.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db257420-43c9-4fbb-881e-3d5618e037fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
